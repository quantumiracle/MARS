Traceback (most recent call last):
  File "/home/zihan/research/MARS/general_train.py", line 1, in <module>
    from mars.utils.func import LoadYAML2Dict
  File "/home/zihan/research/MARS/mars/utils/func.py", line 7, in <module>
    from mars.rl.agents  import *
  File "/home/zihan/research/MARS/mars/rl/agents/__init__.py", line 1, in <module>
    from .dqn import DQN
  File "/home/zihan/research/MARS/mars/rl/agents/dqn.py", line 1, in <module>
    import torch
ModuleNotFoundError: No module named 'torch'
pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
boxing_v1 pettingzoo
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
random seed: [23, 24]
<SubprocVectorEnv instance>
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
No agent are not learnable.
Arguments:  {'env_name': 'boxing_v1', 'env_type': 'pettingzoo', 'num_envs': 2, 'ram': True, 'seed': 'random', 'algorithm': 'NashDQNFactorized', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 1000000}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 50000, 'max_steps_per_episode': 150, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn_factorized', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}}
Save models to : /home/zihan/research/MARS/data/model/20220328_0432/pettingzoo_boxing_v1_nash_dqn_factorized. 
 Save logs to: /home/zihan/research/MARS/data/log/20220328_0432/pettingzoo_boxing_v1_nash_dqn_factorized.
Episode: 1/50000 (0.0020%),                 avg. length: 149.0,                last time consumption/overall running time: 2.6024s / 2.6024 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0040
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0051
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 21/50000 (0.0420%),                 avg. length: 149.0,                last time consumption/overall running time: 219.3076s / 221.9101 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0053
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0055
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 41/50000 (0.0820%),                 avg. length: 149.0,                last time consumption/overall running time: 223.8062s / 445.7163 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0068
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0072
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 61/50000 (0.1220%),                 avg. length: 149.0,                last time consumption/overall running time: 224.1566s / 669.8728 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0070
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0078
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 81/50000 (0.1620%),                 avg. length: 149.0,                last time consumption/overall running time: 222.2645s / 892.1373 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0069
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0077
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 101/50000 (0.2020%),                 avg. length: 149.0,                last time consumption/overall running time: 223.2072s / 1115.3446 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0076
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0092
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 121/50000 (0.2420%),                 avg. length: 149.0,                last time consumption/overall running time: 225.3374s / 1340.6820 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0080
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0098
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 141/50000 (0.2820%),                 avg. length: 149.0,                last time consumption/overall running time: 224.0499s / 1564.7319 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0086
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0098
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 161/50000 (0.3220%),                 avg. length: 149.0,                last time consumption/overall running time: 224.7549s / 1789.4867 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0092
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0098
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 181/50000 (0.3620%),                 avg. length: 149.0,                last time consumption/overall running time: 225.6810s / 2015.1677 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0100
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0113
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 201/50000 (0.4020%),                 avg. length: 149.0,                last time consumption/overall running time: 224.5128s / 2239.6805 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0123
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0133
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 221/50000 (0.4420%),                 avg. length: 149.0,                last time consumption/overall running time: 225.9454s / 2465.6259 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0132
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0145
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 241/50000 (0.4820%),                 avg. length: 149.0,                last time consumption/overall running time: 226.4116s / 2692.0375 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0135
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0155
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 261/50000 (0.5220%),                 avg. length: 149.0,                last time consumption/overall running time: 227.8556s / 2919.8931 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0134
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0158
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 281/50000 (0.5620%),                 avg. length: 149.0,                last time consumption/overall running time: 228.2236s / 3148.1167 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0135
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0146
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 301/50000 (0.6020%),                 avg. length: 149.0,                last time consumption/overall running time: 228.9049s / 3377.0216 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0142
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0138
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 321/50000 (0.6420%),                 avg. length: 149.0,                last time consumption/overall running time: 230.4152s / 3607.4368 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0148
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0140
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 341/50000 (0.6820%),                 avg. length: 149.0,                last time consumption/overall running time: 230.3357s / 3837.7725 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0158
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0156
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 361/50000 (0.7220%),                 avg. length: 149.0,                last time consumption/overall running time: 230.0152s / 4067.7877 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0172
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0226
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 381/50000 (0.7620%),                 avg. length: 149.0,                last time consumption/overall running time: 232.6071s / 4300.3949 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0203
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0315
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 401/50000 (0.8020%),                 avg. length: 149.0,                last time consumption/overall running time: 234.8933s / 4535.2882 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0222
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0194
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 421/50000 (0.8420%),                 avg. length: 149.0,                last time consumption/overall running time: 232.2646s / 4767.5528 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0263
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0226
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 441/50000 (0.8820%),                 avg. length: 149.0,                last time consumption/overall running time: 233.9430s / 5001.4958 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0307
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0324
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 461/50000 (0.9220%),                 avg. length: 149.0,                last time consumption/overall running time: 233.7588s / 5235.2546 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0357
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0373
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 481/50000 (0.9620%),                 avg. length: 149.0,                last time consumption/overall running time: 233.7301s / 5468.9847 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0389
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0403
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 501/50000 (1.0020%),                 avg. length: 149.0,                last time consumption/overall running time: 236.5803s / 5705.5650 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0374
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0396
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 521/50000 (1.0420%),                 avg. length: 149.0,                last time consumption/overall running time: 238.5808s / 5944.1458 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0405
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0255
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 541/50000 (1.0820%),                 avg. length: 149.0,                last time consumption/overall running time: 238.8653s / 6183.0111 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0390
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0259
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 561/50000 (1.1220%),                 avg. length: 149.0,                last time consumption/overall running time: 237.9792s / 6420.9903 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0391
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0208
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 581/50000 (1.1620%),                 avg. length: 149.0,                last time consumption/overall running time: 241.8341s / 6662.8244 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0398
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0212
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 601/50000 (1.2020%),                 avg. length: 149.0,                last time consumption/overall running time: 240.7672s / 6903.5916 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0394
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0262
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 621/50000 (1.2420%),                 avg. length: 149.0,                last time consumption/overall running time: 242.5736s / 7146.1652 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0386
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0418
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 641/50000 (1.2820%),                 avg. length: 149.0,                last time consumption/overall running time: 245.0465s / 7391.2116 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0393
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0985
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 661/50000 (1.3220%),                 avg. length: 149.0,                last time consumption/overall running time: 244.2342s / 7635.4459 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0405
env0_second_0:                 episode reward: 0.1500,                 loss: 0.1732
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 681/50000 (1.3620%),                 avg. length: 149.0,                last time consumption/overall running time: 244.4802s / 7879.9261 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0425
env0_second_0:                 episode reward: -0.4000,                 loss: 0.3913
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 701/50000 (1.4020%),                 avg. length: 149.0,                last time consumption/overall running time: 246.8367s / 8126.7628 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0423
env0_second_0:                 episode reward: 0.2000,                 loss: 0.4111
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 721/50000 (1.4420%),                 avg. length: 149.0,                last time consumption/overall running time: 246.6309s / 8373.3937 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0436
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2374
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 741/50000 (1.4820%),                 avg. length: 149.0,                last time consumption/overall running time: 251.8091s / 8625.2028 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0446
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2298
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 761/50000 (1.5220%),                 avg. length: 149.0,                last time consumption/overall running time: 251.1938s / 8876.3966 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0439
env0_second_0:                 episode reward: 0.2000,                 loss: 0.3932
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 781/50000 (1.5620%),                 avg. length: 149.0,                last time consumption/overall running time: 252.5660s / 9128.9626 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0453
env0_second_0:                 episode reward: 0.3000,                 loss: 0.3211
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 801/50000 (1.6020%),                 avg. length: 149.0,                last time consumption/overall running time: 251.8616s / 9380.8241 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0462
env0_second_0:                 episode reward: 0.4500,                 loss: 0.3421
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 821/50000 (1.6420%),                 avg. length: 149.0,                last time consumption/overall running time: 250.7266s / 9631.5507 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0489
env0_second_0:                 episode reward: -0.4500,                 loss: 0.3792
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 841/50000 (1.6820%),                 avg. length: 149.0,                last time consumption/overall running time: 252.6486s / 9884.1994 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0497
env0_second_0:                 episode reward: -0.2500,                 loss: 0.6092
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 861/50000 (1.7220%),                 avg. length: 149.0,                last time consumption/overall running time: 249.5593s / 10133.7587 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0496
env0_second_0:                 episode reward: 0.2500,                 loss: 0.8870
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 881/50000 (1.7620%),                 avg. length: 149.0,                last time consumption/overall running time: 252.1778s / 10385.9365 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0506
env0_second_0:                 episode reward: -0.2000,                 loss: 0.8498
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 901/50000 (1.8020%),                 avg. length: 149.0,                last time consumption/overall running time: 252.3990s / 10638.3355 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0546
env0_second_0:                 episode reward: -0.0500,                 loss: 0.8840
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 921/50000 (1.8420%),                 avg. length: 149.0,                last time consumption/overall running time: 250.2616s / 10888.5971 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0561
env0_second_0:                 episode reward: 0.4000,                 loss: 0.9415
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 941/50000 (1.8820%),                 avg. length: 149.0,                last time consumption/overall running time: 252.7417s / 11141.3388 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0600
env0_second_0:                 episode reward: 0.0500,                 loss: 1.0998
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 961/50000 (1.9220%),                 avg. length: 149.0,                last time consumption/overall running time: 249.7636s / 11391.1024 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0599
env0_second_0:                 episode reward: 0.3500,                 loss: 1.3402
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 981/50000 (1.9620%),                 avg. length: 149.0,                last time consumption/overall running time: 252.8250s / 11643.9274 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0621
env0_second_0:                 episode reward: 0.1000,                 loss: 1.6778
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 1001/50000 (2.0020%),                 avg. length: 149.0,                last time consumption/overall running time: 251.5862s / 11895.5136 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0660
env0_second_0:                 episode reward: -0.1500,                 loss: 1.9146
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 1021/50000 (2.0420%),                 avg. length: 149.0,                last time consumption/overall running time: 255.1055s / 12150.6191 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0675
env0_second_0:                 episode reward: 0.0500,                 loss: 2.3052
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 1041/50000 (2.0820%),                 avg. length: 149.0,                last time consumption/overall running time: 250.4357s / 12401.0548 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0704
env0_second_0:                 episode reward: -0.2500,                 loss: 2.7366
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 1061/50000 (2.1220%),                 avg. length: 149.0,                last time consumption/overall running time: 252.3082s / 12653.3630 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0756
env0_second_0:                 episode reward: 0.1500,                 loss: 3.0327
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 1081/50000 (2.1620%),                 avg. length: 149.0,                last time consumption/overall running time: 253.5212s / 12906.8843 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0821
env0_second_0:                 episode reward: -0.0500,                 loss: 3.2143
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 1101/50000 (2.2020%),                 avg. length: 149.0,                last time consumption/overall running time: 252.5217s / 13159.4060 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0895
env0_second_0:                 episode reward: 0.1000,                 loss: 3.5694
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 1121/50000 (2.2420%),                 avg. length: 149.0,                last time consumption/overall running time: 254.5004s / 13413.9063 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.1064
env0_second_0:                 episode reward: 0.4000,                 loss: 3.8980
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1141/50000 (2.2820%),                 avg. length: 149.0,                last time consumption/overall running time: 251.6780s / 13665.5844 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.1155
env0_second_0:                 episode reward: 0.2000,                 loss: 4.1659
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1161/50000 (2.3220%),                 avg. length: 149.0,                last time consumption/overall running time: 253.3579s / 13918.9422 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.1227
env0_second_0:                 episode reward: 0.4000,                 loss: 4.3366
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1181/50000 (2.3620%),                 avg. length: 149.0,                last time consumption/overall running time: 254.2009s / 14173.1431 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.1342
env0_second_0:                 episode reward: 0.0000,                 loss: 4.3981
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 1201/50000 (2.4020%),                 avg. length: 149.0,                last time consumption/overall running time: 256.6777s / 14429.8208 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.1541
env0_second_0:                 episode reward: -0.3500,                 loss: 4.1906
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 1221/50000 (2.4420%),                 avg. length: 149.0,                last time consumption/overall running time: 253.3652s / 14683.1861 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.1607
env0_second_0:                 episode reward: 0.3000,                 loss: 4.1574
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 1241/50000 (2.4820%),                 avg. length: 149.0,                last time consumption/overall running time: 253.0210s / 14936.2070 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.1713
env0_second_0:                 episode reward: -0.0500,                 loss: 4.0834
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 1261/50000 (2.5220%),                 avg. length: 149.0,                last time consumption/overall running time: 255.3787s / 15191.5857 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.1821
env0_second_0:                 episode reward: 0.0500,                 loss: 4.1134
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 1281/50000 (2.5620%),                 avg. length: 149.0,                last time consumption/overall running time: 251.9572s / 15443.5429 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.1938
env0_second_0:                 episode reward: 0.0000,                 loss: 3.9648
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 1301/50000 (2.6020%),                 avg. length: 149.0,                last time consumption/overall running time: 257.7202s / 15701.2631 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.1982
env0_second_0:                 episode reward: -0.1500,                 loss: 4.0082
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 1321/50000 (2.6420%),                 avg. length: 149.0,                last time consumption/overall running time: 253.5242s / 15954.7873 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2119
env0_second_0:                 episode reward: -0.0500,                 loss: 3.7524
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 1341/50000 (2.6820%),                 avg. length: 149.0,                last time consumption/overall running time: 254.8200s / 16209.6072 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2256
env0_second_0:                 episode reward: -0.1500,                 loss: 3.6108
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 1361/50000 (2.7220%),                 avg. length: 149.0,                last time consumption/overall running time: 252.1488s / 16461.7560 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2253
env0_second_0:                 episode reward: -0.1500,                 loss: 3.5273
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 1381/50000 (2.7620%),                 avg. length: 149.0,                last time consumption/overall running time: 252.8734s / 16714.6294 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2267
env0_second_0:                 episode reward: 0.0500,                 loss: 3.6610
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 1401/50000 (2.8020%),                 avg. length: 149.0,                last time consumption/overall running time: 251.3742s / 16966.0036 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2253
env0_second_0:                 episode reward: 0.0500,                 loss: 3.5751
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1421/50000 (2.8420%),                 avg. length: 149.0,                last time consumption/overall running time: 255.1483s / 17221.1520 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2068
env0_second_0:                 episode reward: 0.1000,                 loss: 3.4714
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 1441/50000 (2.8820%),                 avg. length: 149.0,                last time consumption/overall running time: 256.4090s / 17477.5610 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.1932
env0_second_0:                 episode reward: -0.0500,                 loss: 3.3489
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 1461/50000 (2.9220%),                 avg. length: 149.0,                last time consumption/overall running time: 255.6200s / 17733.1810 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.1874
env0_second_0:                 episode reward: 0.1000,                 loss: 3.1923
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 1481/50000 (2.9620%),                 avg. length: 149.0,                last time consumption/overall running time: 254.8464s / 17988.0275 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.1908
env0_second_0:                 episode reward: -0.2000,                 loss: 3.2575
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1501/50000 (3.0020%),                 avg. length: 149.0,                last time consumption/overall running time: 251.5982s / 18239.6256 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.1840
env0_second_0:                 episode reward: -0.1000,                 loss: 3.2855
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 1521/50000 (3.0420%),                 avg. length: 149.0,                last time consumption/overall running time: 249.5851s / 18489.2108 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.1776
env0_second_0:                 episode reward: -0.2000,                 loss: 3.3502
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 1541/50000 (3.0820%),                 avg. length: 149.0,                last time consumption/overall running time: 250.3986s / 18739.6094 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.1698
env0_second_0:                 episode reward: -0.0500,                 loss: 3.4848
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 1561/50000 (3.1220%),                 avg. length: 149.0,                last time consumption/overall running time: 251.0691s / 18990.6785 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.1755
env0_second_0:                 episode reward: 0.0500,                 loss: 3.5881
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 1581/50000 (3.1620%),                 avg. length: 149.0,                last time consumption/overall running time: 255.3197s / 19245.9982 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.1778
env0_second_0:                 episode reward: -0.5500,                 loss: 3.5982
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 1601/50000 (3.2020%),                 avg. length: 149.0,                last time consumption/overall running time: 255.1329s / 19501.1311 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.1876
env0_second_0:                 episode reward: 0.0500,                 loss: 3.6970
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1621/50000 (3.2420%),                 avg. length: 149.0,                last time consumption/overall running time: 255.8035s / 19756.9346 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.1799
env0_second_0:                 episode reward: -0.7500,                 loss: 3.8821
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 1641/50000 (3.2820%),                 avg. length: 149.0,                last time consumption/overall running time: 251.4634s / 20008.3980 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.1726
env0_second_0:                 episode reward: 0.1500,                 loss: 3.9745
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 1661/50000 (3.3220%),                 avg. length: 149.0,                last time consumption/overall running time: 250.3955s / 20258.7935 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.1633
env0_second_0:                 episode reward: 0.1500,                 loss: 4.2481
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 1681/50000 (3.3620%),                 avg. length: 149.0,                last time consumption/overall running time: 255.7891s / 20514.5826 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.1545
env0_second_0:                 episode reward: 0.5000,                 loss: 4.2884
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1701/50000 (3.4020%),                 avg. length: 149.0,                last time consumption/overall running time: 255.2613s / 20769.8438 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.1515
env0_second_0:                 episode reward: 0.1500,                 loss: 4.2445
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 1721/50000 (3.4420%),                 avg. length: 149.0,                last time consumption/overall running time: 256.0952s / 21025.9390 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.1466
env0_second_0:                 episode reward: 0.2000,                 loss: 4.0958
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 1741/50000 (3.4820%),                 avg. length: 149.0,                last time consumption/overall running time: 254.8228s / 21280.7619 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.1453
env0_second_0:                 episode reward: 0.8500,                 loss: 4.0472
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 1761/50000 (3.5220%),                 avg. length: 149.0,                last time consumption/overall running time: 249.0208s / 21529.7827 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.1574
env0_second_0:                 episode reward: 0.5000,                 loss: 3.8932
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1781/50000 (3.5620%),                 avg. length: 149.0,                last time consumption/overall running time: 250.7805s / 21780.5632 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.1514
env0_second_0:                 episode reward: 0.3000,                 loss: 3.9100
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 1801/50000 (3.6020%),                 avg. length: 149.0,                last time consumption/overall running time: 256.8273s / 22037.3905 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.1648
env0_second_0:                 episode reward: 0.3000,                 loss: 3.9467
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 1821/50000 (3.6420%),                 avg. length: 149.0,                last time consumption/overall running time: 254.4962s / 22291.8867 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.1682
env0_second_0:                 episode reward: 0.0000,                 loss: 3.7851
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 1841/50000 (3.6820%),                 avg. length: 149.0,                last time consumption/overall running time: 252.4976s / 22544.3843 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.1770
env0_second_0:                 episode reward: -0.1500,                 loss: 3.4025
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1861/50000 (3.7220%),                 avg. length: 149.0,                last time consumption/overall running time: 249.2722s / 22793.6565 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.1845
env0_second_0:                 episode reward: 0.2500,                 loss: 3.0598
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 1881/50000 (3.7620%),                 avg. length: 149.0,                last time consumption/overall running time: 256.9506s / 23050.6071 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.1827
env0_second_0:                 episode reward: 0.2000,                 loss: 2.7550
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 1901/50000 (3.8020%),                 avg. length: 149.0,                last time consumption/overall running time: 250.2941s / 23300.9012 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.1859
env0_second_0:                 episode reward: 0.6000,                 loss: 2.4714
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 1921/50000 (3.8420%),                 avg. length: 149.0,                last time consumption/overall running time: 254.9203s / 23555.8215 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.1959
env0_second_0:                 episode reward: 0.4500,                 loss: 2.2756
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1941/50000 (3.8820%),                 avg. length: 149.0,                last time consumption/overall running time: 253.8434s / 23809.6649 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2110
env0_second_0:                 episode reward: 0.2000,                 loss: 2.1172
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 1961/50000 (3.9220%),                 avg. length: 149.0,                last time consumption/overall running time: 255.1360s / 24064.8009 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2068
env0_second_0:                 episode reward: 0.2000,                 loss: 1.9585
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1981/50000 (3.9620%),                 avg. length: 149.0,                last time consumption/overall running time: 254.9166s / 24319.7175 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.1932
env0_second_0:                 episode reward: -0.2000,                 loss: 1.9977
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 2001/50000 (4.0020%),                 avg. length: 149.0,                last time consumption/overall running time: 254.9401s / 24574.6576 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.1806
env0_second_0:                 episode reward: -0.2000,                 loss: 1.8115
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 2021/50000 (4.0420%),                 avg. length: 149.0,                last time consumption/overall running time: 252.5998s / 24827.2573 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.1819
env0_second_0:                 episode reward: 0.0000,                 loss: 1.7787
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 2041/50000 (4.0820%),                 avg. length: 149.0,                last time consumption/overall running time: 249.9828s / 25077.2401 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.1659
env0_second_0:                 episode reward: 0.3000,                 loss: 1.7616
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 2061/50000 (4.1220%),                 avg. length: 149.0,                last time consumption/overall running time: 249.1246s / 25326.3648 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.1628
env0_second_0:                 episode reward: 0.6500,                 loss: 1.8274
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 2081/50000 (4.1620%),                 avg. length: 149.0,                last time consumption/overall running time: 252.5138s / 25578.8786 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.1616
env0_second_0:                 episode reward: 0.2000,                 loss: 1.8616
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 2101/50000 (4.2020%),                 avg. length: 149.0,                last time consumption/overall running time: 253.9370s / 25832.8156 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.1564
env0_second_0:                 episode reward: -0.3000,                 loss: 1.9110
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 2121/50000 (4.2420%),                 avg. length: 149.0,                last time consumption/overall running time: 254.4799s / 26087.2955 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.1488
env0_second_0:                 episode reward: 0.2500,                 loss: 2.0594
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 2141/50000 (4.2820%),                 avg. length: 149.0,                last time consumption/overall running time: 255.2690s / 26342.5645 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.1430
env0_second_0:                 episode reward: -0.1000,                 loss: 2.1339
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 2161/50000 (4.3220%),                 avg. length: 149.0,                last time consumption/overall running time: 254.5298s / 26597.0943 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.1355
env0_second_0:                 episode reward: 0.6500,                 loss: 2.4103
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 2181/50000 (4.3620%),                 avg. length: 149.0,                last time consumption/overall running time: 256.4995s / 26853.5938 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.1377
env0_second_0:                 episode reward: 0.1500,                 loss: 2.8535
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 2201/50000 (4.4020%),                 avg. length: 149.0,                last time consumption/overall running time: 256.5558s / 27110.1496 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.1350
env0_second_0:                 episode reward: 0.9500,                 loss: 3.3590
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 2221/50000 (4.4420%),                 avg. length: 149.0,                last time consumption/overall running time: 251.3636s / 27361.5132 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.1275
env0_second_0:                 episode reward: 0.0500,                 loss: 3.6290
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 2241/50000 (4.4820%),                 avg. length: 149.0,                last time consumption/overall running time: 253.1182s / 27614.6314 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.1234
env0_second_0:                 episode reward: 0.4500,                 loss: 4.0164
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 2261/50000 (4.5220%),                 avg. length: 149.0,                last time consumption/overall running time: 253.9266s / 27868.5580 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.1244
env0_second_0:                 episode reward: 0.0000,                 loss: 4.7258
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 2281/50000 (4.5620%),                 avg. length: 149.0,                last time consumption/overall running time: 253.5850s / 28122.1430 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.1258
env0_second_0:                 episode reward: 0.3000,                 loss: 5.6651
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 2301/50000 (4.6020%),                 avg. length: 149.0,                last time consumption/overall running time: 255.8469s / 28377.9899 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.1227
env0_second_0:                 episode reward: -0.1000,                 loss: 6.2627
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 2321/50000 (4.6420%),                 avg. length: 149.0,                last time consumption/overall running time: 254.2744s / 28632.2643 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.1226
env0_second_0:                 episode reward: 0.7000,                 loss: 7.5186
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 2341/50000 (4.6820%),                 avg. length: 149.0,                last time consumption/overall running time: 253.3977s / 28885.6620 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.1263
env0_second_0:                 episode reward: 0.6500,                 loss: 8.0575
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 2361/50000 (4.7220%),                 avg. length: 149.0,                last time consumption/overall running time: 251.6039s / 29137.2659 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.1254
env0_second_0:                 episode reward: 0.7500,                 loss: 8.8858
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 2381/50000 (4.7620%),                 avg. length: 149.0,                last time consumption/overall running time: 253.9699s / 29391.2358 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.1252
env0_second_0:                 episode reward: 0.4000,                 loss: 9.4839
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 2401/50000 (4.8020%),                 avg. length: 149.0,                last time consumption/overall running time: 251.7282s / 29642.9640 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.1342
env0_second_0:                 episode reward: 0.6500,                 loss: 10.6302
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 2421/50000 (4.8420%),                 avg. length: 149.0,                last time consumption/overall running time: 250.8889s / 29893.8529 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.1320
env0_second_0:                 episode reward: 0.0500,                 loss: 10.4884
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 2441/50000 (4.8820%),                 avg. length: 149.0,                last time consumption/overall running time: 251.0303s / 30144.8832 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.1265
env0_second_0:                 episode reward: 0.5000,                 loss: 10.4954
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 2461/50000 (4.9220%),                 avg. length: 149.0,                last time consumption/overall running time: 254.2838s / 30399.1671 s
env0_first_0:                 episode reward: -1.5000,                 loss: 0.1158
env0_second_0:                 episode reward: 1.5000,                 loss: 9.9679
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 2481/50000 (4.9620%),                 avg. length: 149.0,                last time consumption/overall running time: 251.6506s / 30650.8177 s
env0_first_0:                 episode reward: -1.6500,                 loss: 0.1120
env0_second_0:                 episode reward: 1.6500,                 loss: 9.5809
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 2501/50000 (5.0020%),                 avg. length: 149.0,                last time consumption/overall running time: 254.7477s / 30905.5655 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.1109
env0_second_0:                 episode reward: 0.5000,                 loss: 9.0483
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 2521/50000 (5.0420%),                 avg. length: 149.0,                last time consumption/overall running time: 254.6717s / 31160.2372 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.1124
env0_second_0:                 episode reward: 1.3500,                 loss: 8.1015
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 2541/50000 (5.0820%),                 avg. length: 149.0,                last time consumption/overall running time: 256.2607s / 31416.4979 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.1119
env0_second_0:                 episode reward: 0.4000,                 loss: 7.7288
env1_first_0:                 episode reward: -1.8500,                 loss: nan
env1_second_0:                 episode reward: 1.8500,                 loss: nan
Episode: 2561/50000 (5.1220%),                 avg. length: 149.0,                last time consumption/overall running time: 258.8936s / 31675.3916 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.1147
env0_second_0:                 episode reward: 0.5500,                 loss: 7.1011
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 2581/50000 (5.1620%),                 avg. length: 149.0,                last time consumption/overall running time: 255.6707s / 31931.0623 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.1148
env0_second_0:                 episode reward: 0.7500,                 loss: 6.9045
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 2601/50000 (5.2020%),                 avg. length: 149.0,                last time consumption/overall running time: 256.2236s / 32187.2859 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.1127
env0_second_0:                 episode reward: 0.3000,                 loss: 6.4537
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 2621/50000 (5.2420%),                 avg. length: 149.0,                last time consumption/overall running time: 253.8847s / 32441.1706 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.1064
env0_second_0:                 episode reward: 0.5500,                 loss: 5.9918
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 2641/50000 (5.2820%),                 avg. length: 149.0,                last time consumption/overall running time: 253.2704s / 32694.4410 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.1012
env0_second_0:                 episode reward: 0.8000,                 loss: 5.9196
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 2661/50000 (5.3220%),                 avg. length: 149.0,                last time consumption/overall running time: 251.2528s / 32945.6938 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.1031
env0_second_0:                 episode reward: -0.1500,                 loss: 5.5662
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 2681/50000 (5.3620%),                 avg. length: 149.0,                last time consumption/overall running time: 250.8968s / 33196.5905 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0983
env0_second_0:                 episode reward: 0.5000,                 loss: 5.6815
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 2701/50000 (5.4020%),                 avg. length: 149.0,                last time consumption/overall running time: 252.6476s / 33449.2382 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0949
env0_second_0:                 episode reward: 0.7500,                 loss: 6.1782
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 2721/50000 (5.4420%),                 avg. length: 149.0,                last time consumption/overall running time: 255.0486s / 33704.2868 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0951
env0_second_0:                 episode reward: -0.2500,                 loss: 7.9689
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2741/50000 (5.4820%),                 avg. length: 149.0,                last time consumption/overall running time: 256.5868s / 33960.8736 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0989
env0_second_0:                 episode reward: 0.4000,                 loss: 10.4061
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 2761/50000 (5.5220%),                 avg. length: 149.0,                last time consumption/overall running time: 257.4053s / 34218.2789 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.1048
env0_second_0:                 episode reward: -0.2500,                 loss: 11.0253
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 2781/50000 (5.5620%),                 avg. length: 149.0,                last time consumption/overall running time: 254.7646s / 34473.0435 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.1084
env0_second_0:                 episode reward: 0.6500,                 loss: 10.3544
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 2801/50000 (5.6020%),                 avg. length: 149.0,                last time consumption/overall running time: 258.5850s / 34731.6286 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.1205
env0_second_0:                 episode reward: 0.3500,                 loss: 14.4639
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 2821/50000 (5.6420%),                 avg. length: 149.0,                last time consumption/overall running time: 259.3597s / 34990.9883 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.1260
env0_second_0:                 episode reward: 0.0500,                 loss: 14.4383
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 2841/50000 (5.6820%),                 avg. length: 149.0,                last time consumption/overall running time: 256.6706s / 35247.6588 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.1324
env0_second_0:                 episode reward: -0.1000,                 loss: 20.1720
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 2861/50000 (5.7220%),                 avg. length: 149.0,                last time consumption/overall running time: 255.0799s / 35502.7388 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.1434
env0_second_0:                 episode reward: -0.4500,                 loss: 20.0573
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 2881/50000 (5.7620%),                 avg. length: 149.0,                last time consumption/overall running time: 256.4740s / 35759.2128 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.1523
env0_second_0:                 episode reward: 0.2000,                 loss: 17.6364
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 2901/50000 (5.8020%),                 avg. length: 149.0,                last time consumption/overall running time: 257.2550s / 36016.4678 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.1551
env0_second_0:                 episode reward: 0.1000,                 loss: 14.7313
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 2921/50000 (5.8420%),                 avg. length: 149.0,                last time consumption/overall running time: 255.9504s / 36272.4182 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.1843
env0_second_0:                 episode reward: -0.0500,                 loss: 14.6704
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 2941/50000 (5.8820%),                 avg. length: 149.0,                last time consumption/overall running time: 266.2966s / 36538.7148 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.1978
env0_second_0:                 episode reward: 0.1000,                 loss: 13.8477
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 2961/50000 (5.9220%),                 avg. length: 149.0,                last time consumption/overall running time: 266.1868s / 36804.9016 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2099
env0_second_0:                 episode reward: 0.0500,                 loss: 14.8977
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 2981/50000 (5.9620%),                 avg. length: 149.0,                last time consumption/overall running time: 264.9847s / 37069.8863 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2339
env0_second_0:                 episode reward: 0.5500,                 loss: 16.2729
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 3001/50000 (6.0020%),                 avg. length: 149.0,                last time consumption/overall running time: 266.4150s / 37336.3013 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.2454
env0_second_0:                 episode reward: 0.6000,                 loss: 16.3569
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 3021/50000 (6.0420%),                 avg. length: 149.0,                last time consumption/overall running time: 266.1282s / 37602.4295 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2542
env0_second_0:                 episode reward: -0.3500,                 loss: 15.7272
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3041/50000 (6.0820%),                 avg. length: 149.0,                last time consumption/overall running time: 265.4978s / 37867.9273 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2584
env0_second_0:                 episode reward: 0.3000,                 loss: 15.1066
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 3061/50000 (6.1220%),                 avg. length: 149.0,                last time consumption/overall running time: 268.0826s / 38136.0099 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.2508
env0_second_0:                 episode reward: 0.9500,                 loss: 14.3437
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 3081/50000 (6.1620%),                 avg. length: 149.0,                last time consumption/overall running time: 270.9977s / 38407.0077 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2563
env0_second_0:                 episode reward: 0.5000,                 loss: 12.6710
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 3101/50000 (6.2020%),                 avg. length: 149.0,                last time consumption/overall running time: 270.7371s / 38677.7447 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.2462
env0_second_0:                 episode reward: 1.0000,                 loss: 10.7335
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 3121/50000 (6.2420%),                 avg. length: 149.0,                last time consumption/overall running time: 270.2813s / 38948.0260 s
env0_first_0:                 episode reward: -2.0000,                 loss: 0.2365
env0_second_0:                 episode reward: 2.0000,                 loss: 9.0281
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 3141/50000 (6.2820%),                 avg. length: 149.0,                last time consumption/overall running time: 271.0799s / 39219.1059 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2299
env0_second_0:                 episode reward: -0.2000,                 loss: 8.4578
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 3161/50000 (6.3220%),                 avg. length: 149.0,                last time consumption/overall running time: 270.0464s / 39489.1523 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.2131
env0_second_0:                 episode reward: 1.1500,                 loss: 7.7814
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 3181/50000 (6.3620%),                 avg. length: 149.0,                last time consumption/overall running time: 270.3782s / 39759.5306 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.1903
env0_second_0:                 episode reward: -0.0500,                 loss: 7.2410
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 3201/50000 (6.4020%),                 avg. length: 149.0,                last time consumption/overall running time: 267.8258s / 40027.3564 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.1841
env0_second_0:                 episode reward: 1.0000,                 loss: 6.3988
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 3221/50000 (6.4420%),                 avg. length: 149.0,                last time consumption/overall running time: 268.2582s / 40295.6146 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.1546
env0_second_0:                 episode reward: 0.2000,                 loss: 6.0851
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 3241/50000 (6.4820%),                 avg. length: 149.0,                last time consumption/overall running time: 267.2411s / 40562.8557 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.1430
env0_second_0:                 episode reward: 0.3000,                 loss: 5.5058
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 3261/50000 (6.5220%),                 avg. length: 149.0,                last time consumption/overall running time: 265.9325s / 40828.7881 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.1458
env0_second_0:                 episode reward: 0.3500,                 loss: 5.4053
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 3281/50000 (6.5620%),                 avg. length: 149.0,                last time consumption/overall running time: 267.2621s / 41096.0502 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.1434
env0_second_0:                 episode reward: 0.0000,                 loss: 5.3274
env1_first_0:                 episode reward: -1.9500,                 loss: nan
env1_second_0:                 episode reward: 1.9500,                 loss: nan
Episode: 3301/50000 (6.6020%),                 avg. length: 149.0,                last time consumption/overall running time: 268.6441s / 41364.6943 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.1427
env0_second_0:                 episode reward: 0.1500,                 loss: 5.0094
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 3321/50000 (6.6420%),                 avg. length: 149.0,                last time consumption/overall running time: 268.7020s / 41633.3963 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.1354
env0_second_0:                 episode reward: 0.3000,                 loss: 4.8251
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 3341/50000 (6.6820%),                 avg. length: 149.0,                last time consumption/overall running time: 269.5203s / 41902.9166 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.1172
env0_second_0:                 episode reward: 0.2500,                 loss: 4.7412
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 3361/50000 (6.7220%),                 avg. length: 149.0,                last time consumption/overall running time: 267.6456s / 42170.5622 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.1102
env0_second_0:                 episode reward: -0.1000,                 loss: 4.9670
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 3381/50000 (6.7620%),                 avg. length: 149.0,                last time consumption/overall running time: 268.3282s / 42438.8904 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.1042
env0_second_0:                 episode reward: 0.5500,                 loss: 4.7798
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 3401/50000 (6.8020%),                 avg. length: 149.0,                last time consumption/overall running time: 267.8772s / 42706.7676 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.1070
env0_second_0:                 episode reward: 0.0000,                 loss: 4.5135
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 3421/50000 (6.8420%),                 avg. length: 149.0,                last time consumption/overall running time: 269.4381s / 42976.2056 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.1046
env0_second_0:                 episode reward: -0.1500,                 loss: 4.5346
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 3441/50000 (6.8820%),                 avg. length: 149.0,                last time consumption/overall running time: 266.6632s / 43242.8689 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.1005
env0_second_0:                 episode reward: 0.1000,                 loss: 4.1716
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 3461/50000 (6.9220%),                 avg. length: 149.0,                last time consumption/overall running time: 267.1709s / 43510.0397 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.1041
env0_second_0:                 episode reward: -0.0500,                 loss: 4.4469
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 3481/50000 (6.9620%),                 avg. length: 149.0,                last time consumption/overall running time: 266.7101s / 43776.7499 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0991
env0_second_0:                 episode reward: 0.1500,                 loss: 4.5734
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 3501/50000 (7.0020%),                 avg. length: 149.0,                last time consumption/overall running time: 267.0743s / 44043.8242 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0932
env0_second_0:                 episode reward: 0.6000,                 loss: 3.9883
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 3521/50000 (7.0420%),                 avg. length: 149.0,                last time consumption/overall running time: 267.3455s / 44311.1697 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0867
env0_second_0:                 episode reward: 0.0500,                 loss: 3.7610
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 3541/50000 (7.0820%),                 avg. length: 149.0,                last time consumption/overall running time: 265.2759s / 44576.4457 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0804
env0_second_0:                 episode reward: 0.4500,                 loss: 3.6141
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3561/50000 (7.1220%),                 avg. length: 149.0,                last time consumption/overall running time: 268.5949s / 44845.0406 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0820
env0_second_0:                 episode reward: 0.4500,                 loss: 3.5038
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 3581/50000 (7.1620%),                 avg. length: 149.0,                last time consumption/overall running time: 266.6805s / 45111.7212 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0757
env0_second_0:                 episode reward: -0.0500,                 loss: 3.2009
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 3601/50000 (7.2020%),                 avg. length: 149.0,                last time consumption/overall running time: 268.0971s / 45379.8183 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0725
env0_second_0:                 episode reward: 0.2000,                 loss: 3.3171
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 3621/50000 (7.2420%),                 avg. length: 149.0,                last time consumption/overall running time: 268.4591s / 45648.2774 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0674
env0_second_0:                 episode reward: 0.2000,                 loss: 3.2169
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 3641/50000 (7.2820%),                 avg. length: 149.0,                last time consumption/overall running time: 268.4400s / 45916.7174 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0632
env0_second_0:                 episode reward: -0.2000,                 loss: 3.2366
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 3661/50000 (7.3220%),                 avg. length: 149.0,                last time consumption/overall running time: 268.9139s / 46185.6313 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0636
env0_second_0:                 episode reward: 0.0500,                 loss: 3.2375
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 3681/50000 (7.3620%),                 avg. length: 149.0,                last time consumption/overall running time: 269.1701s / 46454.8014 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0608
env0_second_0:                 episode reward: 0.1500,                 loss: 3.3197
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 3701/50000 (7.4020%),                 avg. length: 149.0,                last time consumption/overall running time: 269.2620s / 46724.0634 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0574
env0_second_0:                 episode reward: -0.3000,                 loss: 3.3107
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 3721/50000 (7.4420%),                 avg. length: 149.0,                last time consumption/overall running time: 269.4483s / 46993.5117 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0543
env0_second_0:                 episode reward: -0.0500,                 loss: 3.3289
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 3741/50000 (7.4820%),                 avg. length: 149.0,                last time consumption/overall running time: 268.7871s / 47262.2988 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0559
env0_second_0:                 episode reward: 0.3000,                 loss: 3.2472
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 3761/50000 (7.5220%),                 avg. length: 149.0,                last time consumption/overall running time: 263.8964s / 47526.1952 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0589
env0_second_0:                 episode reward: 0.4500,                 loss: 3.0011
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 3781/50000 (7.5620%),                 avg. length: 149.0,                last time consumption/overall running time: 270.4307s / 47796.6259 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0565
env0_second_0:                 episode reward: 0.2000,                 loss: 2.8350
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 3801/50000 (7.6020%),                 avg. length: 149.0,                last time consumption/overall running time: 267.4129s / 48064.0388 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0565
env0_second_0:                 episode reward: 0.0500,                 loss: 2.6120
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 3821/50000 (7.6420%),                 avg. length: 149.0,                last time consumption/overall running time: 269.6910s / 48333.7299 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0595
env0_second_0:                 episode reward: 0.7000,                 loss: 2.5199
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 3841/50000 (7.6820%),                 avg. length: 149.0,                last time consumption/overall running time: 268.2927s / 48602.0225 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0595
env0_second_0:                 episode reward: 0.0500,                 loss: 2.2666
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3861/50000 (7.7220%),                 avg. length: 149.0,                last time consumption/overall running time: 267.4811s / 48869.5036 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0618
env0_second_0:                 episode reward: 0.8000,                 loss: 2.1074
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 3881/50000 (7.7620%),                 avg. length: 149.0,                last time consumption/overall running time: 268.6306s / 49138.1342 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0611
env0_second_0:                 episode reward: -0.4500,                 loss: 1.9364
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3901/50000 (7.8020%),                 avg. length: 149.0,                last time consumption/overall running time: 270.0122s / 49408.1465 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0616
env0_second_0:                 episode reward: 0.3500,                 loss: 1.8616
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 3921/50000 (7.8420%),                 avg. length: 149.0,                last time consumption/overall running time: 269.8364s / 49677.9829 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0604
env0_second_0:                 episode reward: 0.3500,                 loss: 1.8105
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 3941/50000 (7.8820%),                 avg. length: 149.0,                last time consumption/overall running time: 262.8218s / 49940.8047 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0603
env0_second_0:                 episode reward: -0.2000,                 loss: 1.7932
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 3961/50000 (7.9220%),                 avg. length: 149.0,                last time consumption/overall running time: 266.8644s / 50207.6691 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0593
env0_second_0:                 episode reward: 0.4000,                 loss: 1.7583
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 3981/50000 (7.9620%),                 avg. length: 149.0,                last time consumption/overall running time: 267.2106s / 50474.8797 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0582
env0_second_0:                 episode reward: 0.1500,                 loss: 1.8183
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 4001/50000 (8.0020%),                 avg. length: 149.0,                last time consumption/overall running time: 266.4126s / 50741.2923 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0576
env0_second_0:                 episode reward: 0.6500,                 loss: 1.8564
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 4021/50000 (8.0420%),                 avg. length: 149.0,                last time consumption/overall running time: 267.4665s / 51008.7588 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0577
env0_second_0:                 episode reward: 0.5000,                 loss: 1.8413
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 4041/50000 (8.0820%),                 avg. length: 149.0,                last time consumption/overall running time: 268.6174s / 51277.3762 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0561
env0_second_0:                 episode reward: 0.8500,                 loss: 1.8720
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 4061/50000 (8.1220%),                 avg. length: 149.0,                last time consumption/overall running time: 269.7938s / 51547.1701 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0567
env0_second_0:                 episode reward: 0.2000,                 loss: 1.9967
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 4081/50000 (8.1620%),                 avg. length: 149.0,                last time consumption/overall running time: 266.9201s / 51814.0902 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0561
env0_second_0:                 episode reward: 0.2000,                 loss: 1.9526
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4101/50000 (8.2020%),                 avg. length: 149.0,                last time consumption/overall running time: 267.8887s / 52081.9789 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0538
env0_second_0:                 episode reward: 0.0000,                 loss: 2.0935
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4121/50000 (8.2420%),                 avg. length: 149.0,                last time consumption/overall running time: 266.2680s / 52348.2468 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0533
env0_second_0:                 episode reward: -0.1500,                 loss: 2.0337
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 4141/50000 (8.2820%),                 avg. length: 149.0,                last time consumption/overall running time: 265.8709s / 52614.1177 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0534
env0_second_0:                 episode reward: -0.2000,                 loss: 2.0260
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 4161/50000 (8.3220%),                 avg. length: 149.0,                last time consumption/overall running time: 265.5626s / 52879.6803 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0594
env0_second_0:                 episode reward: 0.1000,                 loss: 2.1752
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 4181/50000 (8.3620%),                 avg. length: 149.0,                last time consumption/overall running time: 264.4709s / 53144.1513 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0606
env0_second_0:                 episode reward: -0.2000,                 loss: 2.3874
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 4201/50000 (8.4020%),                 avg. length: 149.0,                last time consumption/overall running time: 267.0916s / 53411.2428 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0651
env0_second_0:                 episode reward: -0.3500,                 loss: 2.5346
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 4221/50000 (8.4420%),                 avg. length: 149.0,                last time consumption/overall running time: 268.6219s / 53679.8647 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0697
env0_second_0:                 episode reward: 0.3000,                 loss: 2.5543
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 4241/50000 (8.4820%),                 avg. length: 149.0,                last time consumption/overall running time: 266.4519s / 53946.3167 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0725
env0_second_0:                 episode reward: -0.1500,                 loss: 2.6115
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 4261/50000 (8.5220%),                 avg. length: 149.0,                last time consumption/overall running time: 263.8895s / 54210.2062 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0736
env0_second_0:                 episode reward: 0.5500,                 loss: 2.7513
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 4281/50000 (8.5620%),                 avg. length: 149.0,                last time consumption/overall running time: 265.2667s / 54475.4729 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0673
env0_second_0:                 episode reward: 0.3000,                 loss: 2.8419
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 4301/50000 (8.6020%),                 avg. length: 149.0,                last time consumption/overall running time: 264.1047s / 54739.5776 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0665
env0_second_0:                 episode reward: 0.0000,                 loss: 3.1730
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 4321/50000 (8.6420%),                 avg. length: 149.0,                last time consumption/overall running time: 267.3188s / 55006.8963 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0670
env0_second_0:                 episode reward: 0.1000,                 loss: 3.6602
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 4341/50000 (8.6820%),                 avg. length: 149.0,                last time consumption/overall running time: 266.1102s / 55273.0065 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0639
env0_second_0:                 episode reward: 0.1500,                 loss: 3.7561
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 4361/50000 (8.7220%),                 avg. length: 149.0,                last time consumption/overall running time: 265.7516s / 55538.7581 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0633
env0_second_0:                 episode reward: 0.2500,                 loss: 3.8079
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 4381/50000 (8.7620%),                 avg. length: 149.0,                last time consumption/overall running time: 268.3932s / 55807.1514 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0595
env0_second_0:                 episode reward: 0.1500,                 loss: 4.1312
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 4401/50000 (8.8020%),                 avg. length: 149.0,                last time consumption/overall running time: 265.2612s / 56072.4125 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0561
env0_second_0:                 episode reward: -0.0500,                 loss: 4.3794
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 4421/50000 (8.8420%),                 avg. length: 149.0,                last time consumption/overall running time: 263.4227s / 56335.8353 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0531
env0_second_0:                 episode reward: 0.6500,                 loss: 4.3108
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 4441/50000 (8.8820%),                 avg. length: 149.0,                last time consumption/overall running time: 263.9042s / 56599.7395 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0498
env0_second_0:                 episode reward: -0.1500,                 loss: 4.1146
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 4461/50000 (8.9220%),                 avg. length: 149.0,                last time consumption/overall running time: 264.0405s / 56863.7800 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0454
env0_second_0:                 episode reward: -0.1000,                 loss: 4.1101
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 4481/50000 (8.9620%),                 avg. length: 149.0,                last time consumption/overall running time: 265.1187s / 57128.8988 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0432
env0_second_0:                 episode reward: 0.1000,                 loss: 4.1715
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 4501/50000 (9.0020%),                 avg. length: 149.0,                last time consumption/overall running time: 263.9370s / 57392.8358 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0471
env0_second_0:                 episode reward: 0.3500,                 loss: 4.2183
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 4521/50000 (9.0420%),                 avg. length: 149.0,                last time consumption/overall running time: 267.1654s / 57660.0012 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0444
env0_second_0:                 episode reward: 0.1500,                 loss: 4.5515
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 4541/50000 (9.0820%),                 avg. length: 149.0,                last time consumption/overall running time: 266.1422s / 57926.1434 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0392
env0_second_0:                 episode reward: 0.1000,                 loss: 4.3997
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 4561/50000 (9.1220%),                 avg. length: 149.0,                last time consumption/overall running time: 265.0931s / 58191.2365 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0360
env0_second_0:                 episode reward: -0.0500,                 loss: 4.5115
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 4581/50000 (9.1620%),                 avg. length: 149.0,                last time consumption/overall running time: 264.4452s / 58455.6817 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0349
env0_second_0:                 episode reward: 0.2000,                 loss: 5.6075
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 4601/50000 (9.2020%),                 avg. length: 149.0,                last time consumption/overall running time: 269.2377s / 58724.9195 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0359
env0_second_0:                 episode reward: 0.0500,                 loss: 7.2797
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 4621/50000 (9.2420%),                 avg. length: 149.0,                last time consumption/overall running time: 265.7641s / 58990.6835 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0341
env0_second_0:                 episode reward: -0.3500,                 loss: 7.8726
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 4641/50000 (9.2820%),                 avg. length: 149.0,                last time consumption/overall running time: 268.6785s / 59259.3620 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0316
env0_second_0:                 episode reward: -0.3000,                 loss: 7.9153
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 4661/50000 (9.3220%),                 avg. length: 149.0,                last time consumption/overall running time: 267.5325s / 59526.8945 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0328
env0_second_0:                 episode reward: -0.1000,                 loss: 8.4892
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 4681/50000 (9.3620%),                 avg. length: 149.0,                last time consumption/overall running time: 266.9607s / 59793.8553 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0337
env0_second_0:                 episode reward: 0.1000,                 loss: 11.5256
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 4701/50000 (9.4020%),                 avg. length: 149.0,                last time consumption/overall running time: 268.0971s / 60061.9523 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0353
env0_second_0:                 episode reward: 0.3500,                 loss: 10.8719
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 4721/50000 (9.4420%),                 avg. length: 149.0,                last time consumption/overall running time: 267.0750s / 60329.0273 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0376
env0_second_0:                 episode reward: 0.2000,                 loss: 8.5507
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 4741/50000 (9.4820%),                 avg. length: 149.0,                last time consumption/overall running time: 261.4376s / 60590.4649 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.0395
env0_second_0:                 episode reward: 1.0500,                 loss: 8.5786
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 4761/50000 (9.5220%),                 avg. length: 149.0,                last time consumption/overall running time: 253.8979s / 60844.3628 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0464
env0_second_0:                 episode reward: 0.2000,                 loss: 15.2278
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 4781/50000 (9.5620%),                 avg. length: 149.0,                last time consumption/overall running time: 255.2264s / 61099.5892 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0526
env0_second_0:                 episode reward: -0.1000,                 loss: 19.4845
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 4801/50000 (9.6020%),                 avg. length: 149.0,                last time consumption/overall running time: 253.0371s / 61352.6263 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0572
env0_second_0:                 episode reward: 0.5000,                 loss: 17.3779
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 4821/50000 (9.6420%),                 avg. length: 149.0,                last time consumption/overall running time: 253.6958s / 61606.3222 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0634
env0_second_0:                 episode reward: 0.6000,                 loss: 15.0367
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 4841/50000 (9.6820%),                 avg. length: 149.0,                last time consumption/overall running time: 252.4597s / 61858.7819 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0785
env0_second_0:                 episode reward: -0.1000,                 loss: 19.7512
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 4861/50000 (9.7220%),                 avg. length: 149.0,                last time consumption/overall running time: 252.2263s / 62111.0082 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0892
env0_second_0:                 episode reward: 0.4000,                 loss: 18.8446
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 4881/50000 (9.7620%),                 avg. length: 149.0,                last time consumption/overall running time: 252.6376s / 62363.6457 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0971
env0_second_0:                 episode reward: 0.4000,                 loss: 20.4661
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 4901/50000 (9.8020%),                 avg. length: 149.0,                last time consumption/overall running time: 252.9146s / 62616.5603 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.1118
env0_second_0:                 episode reward: 0.0500,                 loss: 18.6925
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 4921/50000 (9.8420%),                 avg. length: 149.0,                last time consumption/overall running time: 253.7980s / 62870.3583 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.1035
env0_second_0:                 episode reward: -0.0500,                 loss: 18.6170
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 4941/50000 (9.8820%),                 avg. length: 149.0,                last time consumption/overall running time: 252.5577s / 63122.9160 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.1003
env0_second_0:                 episode reward: 0.5000,                 loss: 19.9340
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 4961/50000 (9.9220%),                 avg. length: 149.0,                last time consumption/overall running time: 252.3975s / 63375.3136 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0939
env0_second_0:                 episode reward: 0.2500,                 loss: 24.1990
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 4981/50000 (9.9620%),                 avg. length: 149.0,                last time consumption/overall running time: 252.8501s / 63628.1637 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0970
env0_second_0:                 episode reward: -0.1500,                 loss: 22.9580
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 5001/50000 (10.0020%),                 avg. length: 149.0,                last time consumption/overall running time: 252.3658s / 63880.5294 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0938
env0_second_0:                 episode reward: 0.1000,                 loss: 27.5881
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 5021/50000 (10.0420%),                 avg. length: 149.0,                last time consumption/overall running time: 251.8036s / 64132.3330 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0921
env0_second_0:                 episode reward: 0.1500,                 loss: 33.1760
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 5041/50000 (10.0820%),                 avg. length: 149.0,                last time consumption/overall running time: 253.8088s / 64386.1418 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0788
env0_second_0:                 episode reward: 0.3000,                 loss: 34.1655
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 5061/50000 (10.1220%),                 avg. length: 149.0,                last time consumption/overall running time: 252.8516s / 64638.9934 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0732
env0_second_0:                 episode reward: -0.3000,                 loss: 42.0244
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 5081/50000 (10.1620%),                 avg. length: 149.0,                last time consumption/overall running time: 253.9028s / 64892.8961 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.0727
env0_second_0:                 episode reward: 1.2000,                 loss: 45.0850
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 5101/50000 (10.2020%),                 avg. length: 149.0,                last time consumption/overall running time: 252.1561s / 65145.0522 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0703
env0_second_0:                 episode reward: 0.1000,                 loss: 44.8506
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 5121/50000 (10.2420%),                 avg. length: 149.0,                last time consumption/overall running time: 254.1426s / 65399.1948 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0686
env0_second_0:                 episode reward: 0.1000,                 loss: 46.4288
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 5141/50000 (10.2820%),                 avg. length: 149.0,                last time consumption/overall running time: 253.5154s / 65652.7102 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0671
env0_second_0:                 episode reward: 0.4000,                 loss: 56.7382
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 5161/50000 (10.3220%),                 avg. length: 149.0,                last time consumption/overall running time: 254.1905s / 65906.9006 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0641
env0_second_0:                 episode reward: -0.2000,                 loss: 55.9070
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 5181/50000 (10.3620%),                 avg. length: 149.0,                last time consumption/overall running time: 254.5562s / 66161.4568 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0561
env0_second_0:                 episode reward: -0.2000,                 loss: 62.7320
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 5201/50000 (10.4020%),                 avg. length: 149.0,                last time consumption/overall running time: 254.3860s / 66415.8428 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0611
env0_second_0:                 episode reward: 0.5000,                 loss: 63.9209
env1_first_0:                 episode reward: -1.5000,                 loss: nan
env1_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 5221/50000 (10.4420%),                 avg. length: 149.0,                last time consumption/overall running time: 253.4082s / 66669.2510 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0589
env0_second_0:                 episode reward: 0.2000,                 loss: 85.9747
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 5241/50000 (10.4820%),                 avg. length: 149.0,                last time consumption/overall running time: 254.2603s / 66923.5113 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0560
env0_second_0:                 episode reward: -0.1000,                 loss: 78.7844
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 5261/50000 (10.5220%),                 avg. length: 149.0,                last time consumption/overall running time: 253.4636s / 67176.9749 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0533
env0_second_0:                 episode reward: 0.0000,                 loss: 90.4522
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 5281/50000 (10.5620%),                 avg. length: 149.0,                last time consumption/overall running time: 254.2628s / 67431.2377 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0495
env0_second_0:                 episode reward: 0.5000,                 loss: 105.2021
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 5301/50000 (10.6020%),                 avg. length: 149.0,                last time consumption/overall running time: 252.8046s / 67684.0423 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0533
env0_second_0:                 episode reward: 0.2500,                 loss: 108.3014
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 5321/50000 (10.6420%),                 avg. length: 149.0,                last time consumption/overall running time: 252.3768s / 67936.4190 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0587
env0_second_0:                 episode reward: -0.0500,                 loss: 115.0550
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 5341/50000 (10.6820%),                 avg. length: 149.0,                last time consumption/overall running time: 250.0737s / 68186.4927 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0558
env0_second_0:                 episode reward: 0.5000,                 loss: 125.5670
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 5361/50000 (10.7220%),                 avg. length: 149.0,                last time consumption/overall running time: 251.8656s / 68438.3583 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0537
env0_second_0:                 episode reward: 0.1500,                 loss: 112.4635
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 5381/50000 (10.7620%),                 avg. length: 149.0,                last time consumption/overall running time: 253.0047s / 68691.3630 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0542
env0_second_0:                 episode reward: 0.3000,                 loss: 120.6633
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 5401/50000 (10.8020%),                 avg. length: 149.0,                last time consumption/overall running time: 253.8777s / 68945.2407 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0593
env0_second_0:                 episode reward: 0.2500,                 loss: 155.8875
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 5421/50000 (10.8420%),                 avg. length: 149.0,                last time consumption/overall running time: 255.0559s / 69200.2966 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0662
env0_second_0:                 episode reward: 0.0000,                 loss: 132.3036
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 5441/50000 (10.8820%),                 avg. length: 149.0,                last time consumption/overall running time: 254.4990s / 69454.7956 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0678
env0_second_0:                 episode reward: 0.0500,                 loss: 158.7889
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5461/50000 (10.9220%),                 avg. length: 149.0,                last time consumption/overall running time: 251.9066s / 69706.7022 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0716
env0_second_0:                 episode reward: 0.0000,                 loss: 194.4534
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 5481/50000 (10.9620%),                 avg. length: 149.0,                last time consumption/overall running time: 253.3908s / 69960.0930 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0716
env0_second_0:                 episode reward: 0.5000,                 loss: 186.2955
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 5501/50000 (11.0020%),                 avg. length: 149.0,                last time consumption/overall running time: 254.5104s / 70214.6034 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0764
env0_second_0:                 episode reward: 0.1500,                 loss: 193.3052
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 5521/50000 (11.0420%),                 avg. length: 149.0,                last time consumption/overall running time: 253.9876s / 70468.5910 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0782
env0_second_0:                 episode reward: 0.5500,                 loss: 176.4655
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 5541/50000 (11.0820%),                 avg. length: 149.0,                last time consumption/overall running time: 255.7259s / 70724.3169 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0871
env0_second_0:                 episode reward: 0.0000,                 loss: 196.1271
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 5561/50000 (11.1220%),                 avg. length: 149.0,                last time consumption/overall running time: 253.4635s / 70977.7804 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0820
env0_second_0:                 episode reward: 0.7500,                 loss: 210.2373
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 5581/50000 (11.1620%),                 avg. length: 149.0,                last time consumption/overall running time: 252.6446s / 71230.4250 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0775
env0_second_0:                 episode reward: 0.0000,                 loss: 214.6247
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 5601/50000 (11.2020%),                 avg. length: 149.0,                last time consumption/overall running time: 251.2544s / 71481.6795 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0760
env0_second_0:                 episode reward: -0.0500,                 loss: 269.2847
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 5621/50000 (11.2420%),                 avg. length: 149.0,                last time consumption/overall running time: 252.7004s / 71734.3799 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0897
env0_second_0:                 episode reward: 0.4500,                 loss: 254.4457
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 5641/50000 (11.2820%),                 avg. length: 149.0,                last time consumption/overall running time: 253.3850s / 71987.7648 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.1037
env0_second_0:                 episode reward: -0.0500,                 loss: 249.6905
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 5661/50000 (11.3220%),                 avg. length: 149.0,                last time consumption/overall running time: 251.8879s / 72239.6527 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.1246
env0_second_0:                 episode reward: 0.3000,                 loss: 348.4300
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 5681/50000 (11.3620%),                 avg. length: 149.0,                last time consumption/overall running time: 252.7793s / 72492.4321 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.1397
env0_second_0:                 episode reward: 0.4500,                 loss: 301.2430
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 5701/50000 (11.4020%),                 avg. length: 149.0,                last time consumption/overall running time: 252.4604s / 72744.8924 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.1677
env0_second_0:                 episode reward: 0.0500,                 loss: 350.4373
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 5721/50000 (11.4420%),                 avg. length: 149.0,                last time consumption/overall running time: 254.9217s / 72999.8141 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.2068
env0_second_0:                 episode reward: 0.7000,                 loss: 320.5626
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan