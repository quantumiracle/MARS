pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 12.0, (1,), float32) action space: Discrete(3)
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7fbcde837c18>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
Error: no exploited model index given!
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  data/model/20220518033032/mdp_arbitrary_mdp_nfsp/40000_0
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': '1i', 'algorithm': 'NFSP', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.0, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 640, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 10000, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220518033032/mdp_arbitrary_mdp_nfsp/40000_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False, 'policy': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': 'Softmax'}}, 'marl_method': 'nfsp', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'eta': 0.1}, 'against_baseline': False}
Save models to : /home/zihan/research/MARS/data/model/20220518033032_exploit_40000/mdp_arbitrary_mdp_nfsp. 
 Save logs to: /home/zihan/research/MARS/data/log/20220518033032_exploit_40000/mdp_arbitrary_mdp_nfsp.
Episode: 1/30000 (0.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6813s / 0.6813 s
agent0:                 episode reward: -0.5509,                 loss: nan
agent1:                 episode reward: 0.5509,                 loss: nan
Episode: 21/30000 (0.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2017s / 0.8829 s
agent0:                 episode reward: -0.3524,                 loss: nan
agent1:                 episode reward: 0.3524,                 loss: nan
Episode: 41/30000 (0.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2000s / 1.0829 s
agent0:                 episode reward: 0.1313,                 loss: nan
agent1:                 episode reward: -0.1313,                 loss: nan
Episode: 61/30000 (0.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1978s / 1.2808 s
agent0:                 episode reward: -0.2285,                 loss: nan
agent1:                 episode reward: 0.2285,                 loss: nan
Episode: 81/30000 (0.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2037s / 1.4844 s
agent0:                 episode reward: 0.5027,                 loss: nan
agent1:                 episode reward: -0.5027,                 loss: nan
Episode: 101/30000 (0.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1959s / 1.6803 s
agent0:                 episode reward: -0.4359,                 loss: nan
agent1:                 episode reward: 0.4359,                 loss: nan
Episode: 121/30000 (0.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2015s / 1.8818 s
agent0:                 episode reward: 0.0295,                 loss: nan
agent1:                 episode reward: -0.0295,                 loss: nan
Episode: 141/30000 (0.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1957s / 2.0775 s
agent0:                 episode reward: 0.0547,                 loss: nan
agent1:                 episode reward: -0.0547,                 loss: nan
Episode: 161/30000 (0.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1951s / 2.2727 s
agent0:                 episode reward: 0.4032,                 loss: nan
agent1:                 episode reward: -0.4032,                 loss: nan
Episode: 181/30000 (0.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1948s / 2.4674 s
agent0:                 episode reward: -0.0499,                 loss: nan
agent1:                 episode reward: 0.0499,                 loss: nan
Episode: 201/30000 (0.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1982s / 2.6656 s
agent0:                 episode reward: 0.0521,                 loss: nan
agent1:                 episode reward: -0.0521,                 loss: nan
Episode: 221/30000 (0.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1955s / 2.8611 s
agent0:                 episode reward: 0.0827,                 loss: nan
agent1:                 episode reward: -0.0827,                 loss: nan
Episode: 241/30000 (0.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1931s / 3.0542 s
agent0:                 episode reward: 0.2480,                 loss: nan
agent1:                 episode reward: -0.2480,                 loss: nan
Episode: 261/30000 (0.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1957s / 3.2500 s
agent0:                 episode reward: 0.0888,                 loss: nan
agent1:                 episode reward: -0.0888,                 loss: nan
Episode: 281/30000 (0.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2021s / 3.4521 s
agent0:                 episode reward: 0.1524,                 loss: nan
agent1:                 episode reward: -0.1524,                 loss: nan
Episode: 301/30000 (1.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1942s / 3.6463 s
agent0:                 episode reward: 0.0592,                 loss: nan
agent1:                 episode reward: -0.0592,                 loss: nan
Episode: 321/30000 (1.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1966s / 3.8429 s
agent0:                 episode reward: 0.4634,                 loss: nan
agent1:                 episode reward: -0.4634,                 loss: nan
Episode: 341/30000 (1.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1982s / 4.0411 s
agent0:                 episode reward: 0.1514,                 loss: nan
agent1:                 episode reward: -0.1514,                 loss: nan
Episode: 361/30000 (1.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2073s / 4.2483 s
agent0:                 episode reward: -0.4535,                 loss: nan
agent1:                 episode reward: 0.4535,                 loss: nan
Episode: 381/30000 (1.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1983s / 4.4466 s
agent0:                 episode reward: -0.0611,                 loss: nan
agent1:                 episode reward: 0.0611,                 loss: nan
Episode: 401/30000 (1.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1993s / 4.6460 s
agent0:                 episode reward: 0.2334,                 loss: nan
agent1:                 episode reward: -0.2334,                 loss: nan
Episode: 421/30000 (1.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1986s / 4.8445 s
agent0:                 episode reward: -0.0747,                 loss: nan
agent1:                 episode reward: 0.0747,                 loss: nan
Episode: 441/30000 (1.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1991s / 5.0436 s
agent0:                 episode reward: 0.2098,                 loss: nan
agent1:                 episode reward: -0.2098,                 loss: nan
Episode: 461/30000 (1.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1972s / 5.2408 s
agent0:                 episode reward: -0.2008,                 loss: nan
agent1:                 episode reward: 0.2008,                 loss: nan
Episode: 481/30000 (1.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1969s / 5.4377 s
agent0:                 episode reward: 0.3843,                 loss: nan
agent1:                 episode reward: -0.3843,                 loss: nan
Episode: 501/30000 (1.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1979s / 5.6356 s
agent0:                 episode reward: -0.1458,                 loss: nan
agent1:                 episode reward: 0.1458,                 loss: nan
Episode: 521/30000 (1.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2013s / 5.8369 s
agent0:                 episode reward: 0.1808,                 loss: nan
agent1:                 episode reward: -0.1808,                 loss: nan
Episode: 541/30000 (1.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1999s / 6.0368 s
agent0:                 episode reward: 0.3930,                 loss: nan
agent1:                 episode reward: -0.3930,                 loss: nan
Episode: 561/30000 (1.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1969s / 6.2337 s
agent0:                 episode reward: 0.0979,                 loss: nan
agent1:                 episode reward: -0.0979,                 loss: nan
Episode: 581/30000 (1.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1945s / 6.4282 s
agent0:                 episode reward: -0.2510,                 loss: nan
agent1:                 episode reward: 0.2510,                 loss: nan
Episode: 601/30000 (2.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1968s / 6.6250 s
agent0:                 episode reward: -0.1159,                 loss: nan
agent1:                 episode reward: 0.1159,                 loss: nan
Episode: 621/30000 (2.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1994s / 6.8243 s
agent0:                 episode reward: 0.1167,                 loss: nan
agent1:                 episode reward: -0.1167,                 loss: nan
Episode: 641/30000 (2.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1972s / 7.0215 s
agent0:                 episode reward: -0.1179,                 loss: nan
agent1:                 episode reward: 0.1179,                 loss: nan
Episode: 661/30000 (2.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1975s / 7.2190 s
agent0:                 episode reward: 0.0874,                 loss: nan
agent1:                 episode reward: -0.0874,                 loss: nan
Episode: 681/30000 (2.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1996s / 7.4186 s
agent0:                 episode reward: 0.1234,                 loss: nan
agent1:                 episode reward: -0.1234,                 loss: nan
Episode: 701/30000 (2.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1993s / 7.6179 s
agent0:                 episode reward: -0.2637,                 loss: nan
agent1:                 episode reward: 0.2637,                 loss: nan
Episode: 721/30000 (2.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1991s / 7.8169 s
agent0:                 episode reward: -0.1647,                 loss: nan
agent1:                 episode reward: 0.1647,                 loss: nan
Episode: 741/30000 (2.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1959s / 8.0128 s
agent0:                 episode reward: -0.5416,                 loss: nan
agent1:                 episode reward: 0.5416,                 loss: nan
Episode: 761/30000 (2.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2006s / 8.2134 s
agent0:                 episode reward: -0.0330,                 loss: nan
agent1:                 episode reward: 0.0330,                 loss: nan
Episode: 781/30000 (2.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2027s / 8.4161 s
agent0:                 episode reward: 0.1471,                 loss: nan
agent1:                 episode reward: -0.1471,                 loss: nan
Episode: 801/30000 (2.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1954s / 8.6116 s
agent0:                 episode reward: -0.0410,                 loss: nan
agent1:                 episode reward: 0.0410,                 loss: nan
Episode: 821/30000 (2.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1976s / 8.8092 s
agent0:                 episode reward: -0.3595,                 loss: nan
agent1:                 episode reward: 0.3595,                 loss: nan
Episode: 841/30000 (2.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1982s / 9.0074 s
agent0:                 episode reward: -0.3010,                 loss: nan
agent1:                 episode reward: 0.3010,                 loss: nan
Episode: 861/30000 (2.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1973s / 9.2047 s
agent0:                 episode reward: -0.1801,                 loss: nan
agent1:                 episode reward: 0.1801,                 loss: nan
Episode: 881/30000 (2.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1935s / 9.3982 s
agent0:                 episode reward: -0.5364,                 loss: nan
agent1:                 episode reward: 0.5364,                 loss: nan
Episode: 901/30000 (3.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1937s / 9.5919 s
agent0:                 episode reward: 0.2833,                 loss: nan
agent1:                 episode reward: -0.2833,                 loss: nan
Episode: 921/30000 (3.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2027s / 9.7946 s
agent0:                 episode reward: -0.7264,                 loss: nan
agent1:                 episode reward: 0.7264,                 loss: nan
Episode: 941/30000 (3.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2017s / 9.9963 s
agent0:                 episode reward: -0.2551,                 loss: nan
agent1:                 episode reward: 0.2551,                 loss: nan
Episode: 961/30000 (3.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1969s / 10.1932 s
agent0:                 episode reward: -0.1666,                 loss: nan
agent1:                 episode reward: 0.1666,                 loss: nan
Episode: 981/30000 (3.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2023s / 10.3955 s
agent0:                 episode reward: 0.0753,                 loss: nan
agent1:                 episode reward: -0.0753,                 loss: nan
Episode: 1001/30000 (3.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1987s / 10.5942 s
agent0:                 episode reward: 0.0419,                 loss: nan
agent1:                 episode reward: -0.0419,                 loss: nan
Episode: 1021/30000 (3.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1989s / 10.7932 s
agent0:                 episode reward: -0.1148,                 loss: nan
agent1:                 episode reward: 0.1148,                 loss: nan
Episode: 1041/30000 (3.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1963s / 10.9895 s
agent0:                 episode reward: 0.0909,                 loss: nan
agent1:                 episode reward: -0.0909,                 loss: nan
Episode: 1061/30000 (3.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2007s / 11.1901 s
agent0:                 episode reward: 0.0915,                 loss: nan
agent1:                 episode reward: -0.0915,                 loss: nan
Episode: 1081/30000 (3.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1925s / 11.3827 s
agent0:                 episode reward: 0.5043,                 loss: nan
agent1:                 episode reward: -0.5043,                 loss: nan
Episode: 1101/30000 (3.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1973s / 11.5800 s
agent0:                 episode reward: -0.1399,                 loss: nan
agent1:                 episode reward: 0.1399,                 loss: nan
Episode: 1121/30000 (3.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1975s / 11.7774 s
agent0:                 episode reward: 0.0401,                 loss: nan
agent1:                 episode reward: -0.0401,                 loss: nan
Episode: 1141/30000 (3.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2018s / 11.9792 s
agent0:                 episode reward: -0.1725,                 loss: nan
agent1:                 episode reward: 0.1725,                 loss: nan
Episode: 1161/30000 (3.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1959s / 12.1751 s
agent0:                 episode reward: 0.0405,                 loss: nan
agent1:                 episode reward: -0.0405,                 loss: nan
Episode: 1181/30000 (3.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2011s / 12.3763 s
agent0:                 episode reward: -0.2632,                 loss: nan
agent1:                 episode reward: 0.2632,                 loss: nan
Episode: 1201/30000 (4.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1993s / 12.5756 s
agent0:                 episode reward: -0.1568,                 loss: nan
agent1:                 episode reward: 0.1568,                 loss: nan
Episode: 1221/30000 (4.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2008s / 12.7763 s
agent0:                 episode reward: 0.0610,                 loss: nan
agent1:                 episode reward: -0.0610,                 loss: nan
Episode: 1241/30000 (4.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1994s / 12.9758 s
agent0:                 episode reward: 0.3492,                 loss: nan
agent1:                 episode reward: -0.3492,                 loss: nan
Episode: 1261/30000 (4.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2019s / 13.1776 s
agent0:                 episode reward: 0.1721,                 loss: nan
agent1:                 episode reward: -0.1721,                 loss: nan
Episode: 1281/30000 (4.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1965s / 13.3741 s
agent0:                 episode reward: 0.0404,                 loss: nan
agent1:                 episode reward: -0.0404,                 loss: nan
Episode: 1301/30000 (4.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1969s / 13.5710 s
agent0:                 episode reward: -0.2540,                 loss: nan
agent1:                 episode reward: 0.2540,                 loss: nan
Episode: 1321/30000 (4.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2015s / 13.7725 s
agent0:                 episode reward: 0.0702,                 loss: nan
agent1:                 episode reward: -0.0702,                 loss: nan
Episode: 1341/30000 (4.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1958s / 13.9683 s
agent0:                 episode reward: 0.1497,                 loss: nan
agent1:                 episode reward: -0.1497,                 loss: nan
Episode: 1361/30000 (4.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1982s / 14.1665 s
agent0:                 episode reward: -0.1342,                 loss: nan
agent1:                 episode reward: 0.1342,                 loss: nan
Episode: 1381/30000 (4.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1913s / 14.3578 s
agent0:                 episode reward: 0.0012,                 loss: nan
agent1:                 episode reward: -0.0012,                 loss: nan
Episode: 1401/30000 (4.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2001s / 14.5579 s
agent0:                 episode reward: 0.3152,                 loss: nan
agent1:                 episode reward: -0.3152,                 loss: nan
Episode: 1421/30000 (4.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1955s / 14.7534 s
agent0:                 episode reward: 0.1945,                 loss: nan
agent1:                 episode reward: -0.1945,                 loss: nan
Episode: 1441/30000 (4.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2044s / 14.9578 s
agent0:                 episode reward: 0.3382,                 loss: nan
agent1:                 episode reward: -0.3382,                 loss: nan
Episode: 1461/30000 (4.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1990s / 15.1568 s
agent0:                 episode reward: 0.3127,                 loss: nan
agent1:                 episode reward: -0.3127,                 loss: nan
Episode: 1481/30000 (4.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1929s / 15.3496 s
agent0:                 episode reward: 0.1070,                 loss: nan
agent1:                 episode reward: -0.1070,                 loss: nan
Episode: 1501/30000 (5.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1955s / 15.5451 s
agent0:                 episode reward: -0.4020,                 loss: nan
agent1:                 episode reward: 0.4020,                 loss: nan
Episode: 1521/30000 (5.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1992s / 15.7442 s
agent0:                 episode reward: 0.5803,                 loss: nan
agent1:                 episode reward: -0.5803,                 loss: nan
Episode: 1541/30000 (5.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2012s / 15.9455 s
agent0:                 episode reward: 0.0469,                 loss: nan
agent1:                 episode reward: -0.0469,                 loss: nan
Episode: 1561/30000 (5.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1994s / 16.1448 s
agent0:                 episode reward: 0.1480,                 loss: nan
agent1:                 episode reward: -0.1480,                 loss: nan
Episode: 1581/30000 (5.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1920s / 16.3368 s
agent0:                 episode reward: -0.6633,                 loss: nan
agent1:                 episode reward: 0.6633,                 loss: nan
Episode: 1601/30000 (5.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1999s / 16.5367 s
agent0:                 episode reward: -0.0727,                 loss: nan
agent1:                 episode reward: 0.0727,                 loss: nan
Episode: 1621/30000 (5.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1981s / 16.7348 s
agent0:                 episode reward: 0.1265,                 loss: nan
agent1:                 episode reward: -0.1265,                 loss: nan
Episode: 1641/30000 (5.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2013s / 16.9361 s
agent0:                 episode reward: -0.4997,                 loss: nan
agent1:                 episode reward: 0.4997,                 loss: nan
Episode: 1661/30000 (5.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1970s / 17.1330 s
agent0:                 episode reward: 0.1628,                 loss: nan
agent1:                 episode reward: -0.1628,                 loss: nan
Episode: 1681/30000 (5.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1919s / 17.3249 s
agent0:                 episode reward: -0.0941,                 loss: nan
agent1:                 episode reward: 0.0941,                 loss: nan
Episode: 1701/30000 (5.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2014s / 17.5263 s
agent0:                 episode reward: 0.1204,                 loss: nan
agent1:                 episode reward: -0.1204,                 loss: nan
Episode: 1721/30000 (5.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1919s / 17.7182 s
agent0:                 episode reward: 0.1079,                 loss: nan
agent1:                 episode reward: -0.1079,                 loss: nan
Episode: 1741/30000 (5.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1995s / 17.9177 s
agent0:                 episode reward: -0.0438,                 loss: nan
agent1:                 episode reward: 0.0438,                 loss: nan
Episode: 1761/30000 (5.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1983s / 18.1161 s
agent0:                 episode reward: 0.1079,                 loss: nan
agent1:                 episode reward: -0.1079,                 loss: nan
Episode: 1781/30000 (5.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2020s / 18.3181 s
agent0:                 episode reward: -0.1622,                 loss: nan
agent1:                 episode reward: 0.1622,                 loss: nan
Episode: 1801/30000 (6.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1970s / 18.5151 s
agent0:                 episode reward: -0.2077,                 loss: nan
agent1:                 episode reward: 0.2077,                 loss: nan
Episode: 1821/30000 (6.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1959s / 18.7110 s
agent0:                 episode reward: 0.3773,                 loss: nan
agent1:                 episode reward: -0.3773,                 loss: nan
Episode: 1841/30000 (6.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1985s / 18.9094 s
agent0:                 episode reward: -0.1312,                 loss: nan
agent1:                 episode reward: 0.1312,                 loss: nan
Episode: 1861/30000 (6.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2024s / 19.1119 s
agent0:                 episode reward: 0.1154,                 loss: nan
agent1:                 episode reward: -0.1154,                 loss: nan
Episode: 1881/30000 (6.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2010s / 19.3129 s
agent0:                 episode reward: 0.2407,                 loss: nan
agent1:                 episode reward: -0.2407,                 loss: nan
Episode: 1901/30000 (6.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2019s / 19.5148 s
agent0:                 episode reward: 0.0700,                 loss: nan
agent1:                 episode reward: -0.0700,                 loss: nan
Episode: 1921/30000 (6.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1991s / 19.7139 s
agent0:                 episode reward: -0.2208,                 loss: nan
agent1:                 episode reward: 0.2208,                 loss: nan
Episode: 1941/30000 (6.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1962s / 19.9101 s
agent0:                 episode reward: -0.4167,                 loss: nan
agent1:                 episode reward: 0.4167,                 loss: nan
Episode: 1961/30000 (6.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1930s / 20.1031 s
agent0:                 episode reward: -0.4392,                 loss: nan
agent1:                 episode reward: 0.4392,                 loss: nan
Episode: 1981/30000 (6.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1980s / 20.3012 s
agent0:                 episode reward: -0.1956,                 loss: nan
agent1:                 episode reward: 0.1956,                 loss: nan
Episode: 2001/30000 (6.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1998s / 20.5010 s
agent0:                 episode reward: -0.2180,                 loss: nan
agent1:                 episode reward: 0.2180,                 loss: nan
Episode: 2021/30000 (6.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2032s / 20.7042 s
agent0:                 episode reward: 0.1674,                 loss: nan
agent1:                 episode reward: -0.1674,                 loss: nan
Episode: 2041/30000 (6.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1971s / 20.9013 s
agent0:                 episode reward: 0.3412,                 loss: nan
agent1:                 episode reward: -0.3412,                 loss: nan
Episode: 2061/30000 (6.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1993s / 21.1006 s
agent0:                 episode reward: 0.2018,                 loss: nan
agent1:                 episode reward: -0.2018,                 loss: nan
Episode: 2081/30000 (6.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2025s / 21.3031 s
agent0:                 episode reward: 0.2625,                 loss: nan
agent1:                 episode reward: -0.2625,                 loss: nan
Episode: 2101/30000 (7.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2024s / 21.5055 s
agent0:                 episode reward: -0.1760,                 loss: nan
agent1:                 episode reward: 0.1760,                 loss: nan
Episode: 2121/30000 (7.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1964s / 21.7019 s
agent0:                 episode reward: 0.2015,                 loss: nan
agent1:                 episode reward: -0.2015,                 loss: nan
Episode: 2141/30000 (7.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2010s / 21.9029 s
agent0:                 episode reward: 0.2241,                 loss: nan
agent1:                 episode reward: -0.2241,                 loss: nan
Episode: 2161/30000 (7.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1990s / 22.1020 s
agent0:                 episode reward: 0.2629,                 loss: nan
agent1:                 episode reward: -0.2629,                 loss: nan
Episode: 2181/30000 (7.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2012s / 22.3032 s
agent0:                 episode reward: 0.2315,                 loss: nan
agent1:                 episode reward: -0.2315,                 loss: nan
Episode: 2201/30000 (7.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2006s / 22.5038 s
agent0:                 episode reward: -0.1953,                 loss: nan
agent1:                 episode reward: 0.1953,                 loss: nan
Episode: 2221/30000 (7.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1948s / 22.6986 s
agent0:                 episode reward: 0.1094,                 loss: nan
agent1:                 episode reward: -0.1094,                 loss: nan
Episode: 2241/30000 (7.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2024s / 22.9010 s
agent0:                 episode reward: -0.0909,                 loss: nan
agent1:                 episode reward: 0.0909,                 loss: nan
Episode: 2261/30000 (7.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1947s / 23.0957 s
agent0:                 episode reward: -0.3958,                 loss: nan
agent1:                 episode reward: 0.3958,                 loss: nan
Episode: 2281/30000 (7.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1996s / 23.2953 s
agent0:                 episode reward: -0.6103,                 loss: nan
agent1:                 episode reward: 0.6103,                 loss: nan
Episode: 2301/30000 (7.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1985s / 23.4939 s
agent0:                 episode reward: 0.2868,                 loss: nan
agent1:                 episode reward: -0.2868,                 loss: nan
Episode: 2321/30000 (7.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1967s / 23.6906 s
agent0:                 episode reward: 0.1137,                 loss: nan
agent1:                 episode reward: -0.1137,                 loss: nan
Episode: 2341/30000 (7.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1994s / 23.8899 s
agent0:                 episode reward: -0.0324,                 loss: nan
agent1:                 episode reward: 0.0324,                 loss: nan
Episode: 2361/30000 (7.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2025s / 24.0924 s
agent0:                 episode reward: -0.0632,                 loss: nan
agent1:                 episode reward: 0.0632,                 loss: nan
Episode: 2381/30000 (7.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1982s / 24.2906 s
agent0:                 episode reward: -0.1509,                 loss: nan
agent1:                 episode reward: 0.1509,                 loss: nan
Episode: 2401/30000 (8.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1947s / 24.4853 s
agent0:                 episode reward: 0.1284,                 loss: nan
agent1:                 episode reward: -0.1284,                 loss: nan
Episode: 2421/30000 (8.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1993s / 24.6845 s
agent0:                 episode reward: -0.3166,                 loss: nan
agent1:                 episode reward: 0.3166,                 loss: nan
Episode: 2441/30000 (8.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1970s / 24.8815 s
agent0:                 episode reward: -0.0977,                 loss: nan
agent1:                 episode reward: 0.0977,                 loss: nan
Episode: 2461/30000 (8.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2016s / 25.0831 s
agent0:                 episode reward: 0.1122,                 loss: nan
agent1:                 episode reward: -0.1122,                 loss: nan
Episode: 2481/30000 (8.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1960s / 25.2791 s
agent0:                 episode reward: 0.0217,                 loss: nan
agent1:                 episode reward: -0.0217,                 loss: nan
Episode: 2501/30000 (8.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2014s / 25.4805 s
agent0:                 episode reward: -0.0179,                 loss: nan
agent1:                 episode reward: 0.0179,                 loss: nan
Episode: 2521/30000 (8.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1989s / 25.6795 s
agent0:                 episode reward: 0.0342,                 loss: nan
agent1:                 episode reward: -0.0342,                 loss: nan
Episode: 2541/30000 (8.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1955s / 25.8750 s
agent0:                 episode reward: -0.0998,                 loss: nan
agent1:                 episode reward: 0.0998,                 loss: nan
Episode: 2561/30000 (8.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2038s / 26.0788 s
agent0:                 episode reward: 0.0823,                 loss: nan
agent1:                 episode reward: -0.0823,                 loss: nan
Episode: 2581/30000 (8.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1919s / 26.2707 s
agent0:                 episode reward: 0.4456,                 loss: nan
agent1:                 episode reward: -0.4456,                 loss: nan
Episode: 2601/30000 (8.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1901s / 26.4608 s
agent0:                 episode reward: -0.1656,                 loss: nan
agent1:                 episode reward: 0.1656,                 loss: nan
Episode: 2621/30000 (8.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1950s / 26.6558 s
agent0:                 episode reward: 0.0202,                 loss: nan
agent1:                 episode reward: -0.0202,                 loss: nan
Episode: 2641/30000 (8.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1967s / 26.8525 s
agent0:                 episode reward: 0.1009,                 loss: nan
agent1:                 episode reward: -0.1009,                 loss: nan
Episode: 2661/30000 (8.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1858s / 27.0383 s
agent0:                 episode reward: -0.2393,                 loss: nan
agent1:                 episode reward: 0.2393,                 loss: nan
Episode: 2681/30000 (8.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1995s / 27.2378 s
agent0:                 episode reward: 0.0028,                 loss: nan
agent1:                 episode reward: -0.0028,                 loss: nan
Episode: 2701/30000 (9.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2002s / 27.4380 s
agent0:                 episode reward: -0.0978,                 loss: nan
agent1:                 episode reward: 0.0978,                 loss: nan
Episode: 2721/30000 (9.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1988s / 27.6368 s
agent0:                 episode reward: -0.0719,                 loss: nan
agent1:                 episode reward: 0.0719,                 loss: nan
Episode: 2741/30000 (9.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1987s / 27.8355 s
agent0:                 episode reward: -0.4263,                 loss: nan
agent1:                 episode reward: 0.4263,                 loss: nan
Episode: 2761/30000 (9.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2297s / 28.0651 s
agent0:                 episode reward: 0.0429,                 loss: nan
agent1:                 episode reward: -0.0429,                 loss: nan
Episode: 2781/30000 (9.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1977s / 28.2628 s
agent0:                 episode reward: 0.0192,                 loss: nan
agent1:                 episode reward: -0.0192,                 loss: nan
Episode: 2801/30000 (9.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1960s / 28.4589 s
agent0:                 episode reward: -0.2786,                 loss: nan
agent1:                 episode reward: 0.2786,                 loss: nan
Episode: 2821/30000 (9.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1977s / 28.6565 s
agent0:                 episode reward: 0.1962,                 loss: nan
agent1:                 episode reward: -0.1962,                 loss: nan
Episode: 2841/30000 (9.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1939s / 28.8504 s
agent0:                 episode reward: -0.3974,                 loss: nan
agent1:                 episode reward: 0.3974,                 loss: nan
Episode: 2861/30000 (9.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1971s / 29.0475 s
agent0:                 episode reward: 0.2524,                 loss: nan
agent1:                 episode reward: -0.2524,                 loss: nan
Episode: 2881/30000 (9.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1976s / 29.2451 s
agent0:                 episode reward: 0.0898,                 loss: nan
agent1:                 episode reward: -0.0898,                 loss: nan
Episode: 2901/30000 (9.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1937s / 29.4388 s
agent0:                 episode reward: -0.1120,                 loss: nan
agent1:                 episode reward: 0.1120,                 loss: nan
Episode: 2921/30000 (9.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1952s / 29.6340 s
agent0:                 episode reward: -0.2327,                 loss: nan
agent1:                 episode reward: 0.2327,                 loss: nan
Episode: 2941/30000 (9.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1952s / 29.8292 s
agent0:                 episode reward: -0.2036,                 loss: nan
agent1:                 episode reward: 0.2036,                 loss: nan
Episode: 2961/30000 (9.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1962s / 30.0254 s
agent0:                 episode reward: 0.0325,                 loss: nan
agent1:                 episode reward: -0.0325,                 loss: nan
Episode: 2981/30000 (9.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1987s / 30.2241 s
agent0:                 episode reward: 0.3478,                 loss: nan
agent1:                 episode reward: -0.3478,                 loss: nan
Episode: 3001/30000 (10.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1964s / 30.4206 s
agent0:                 episode reward: 0.5867,                 loss: nan
agent1:                 episode reward: -0.5867,                 loss: nan
Episode: 3021/30000 (10.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1996s / 30.6201 s
agent0:                 episode reward: 0.2482,                 loss: nan
agent1:                 episode reward: -0.2482,                 loss: nan
Episode: 3041/30000 (10.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1970s / 30.8171 s
agent0:                 episode reward: 0.2547,                 loss: nan
agent1:                 episode reward: -0.2547,                 loss: nan
Episode: 3061/30000 (10.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1959s / 31.0130 s
agent0:                 episode reward: 0.1596,                 loss: nan
agent1:                 episode reward: -0.1596,                 loss: nan
Episode: 3081/30000 (10.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1949s / 31.2079 s
agent0:                 episode reward: 0.0582,                 loss: nan
agent1:                 episode reward: -0.0582,                 loss: nan
Episode: 3101/30000 (10.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1972s / 31.4052 s
agent0:                 episode reward: -0.2504,                 loss: nan
agent1:                 episode reward: 0.2504,                 loss: nan
Episode: 3121/30000 (10.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1991s / 31.6043 s
agent0:                 episode reward: -0.1183,                 loss: nan
agent1:                 episode reward: 0.1183,                 loss: nan
Episode: 3141/30000 (10.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1994s / 31.8037 s
agent0:                 episode reward: -0.3434,                 loss: nan
agent1:                 episode reward: 0.3434,                 loss: nan
Episode: 3161/30000 (10.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1977s / 32.0014 s
agent0:                 episode reward: 0.2818,                 loss: nan
agent1:                 episode reward: -0.2818,                 loss: nan
Episode: 3181/30000 (10.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2022s / 32.2036 s
agent0:                 episode reward: 0.4341,                 loss: nan
agent1:                 episode reward: -0.4341,                 loss: nan
Episode: 3201/30000 (10.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1987s / 32.4023 s
agent0:                 episode reward: -0.1893,                 loss: nan
agent1:                 episode reward: 0.1893,                 loss: nan
Episode: 3221/30000 (10.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2011s / 32.6035 s
agent0:                 episode reward: -0.2982,                 loss: nan
agent1:                 episode reward: 0.2982,                 loss: nan
Episode: 3241/30000 (10.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1989s / 32.8024 s
agent0:                 episode reward: -0.3644,                 loss: nan
agent1:                 episode reward: 0.3644,                 loss: nan
Episode: 3261/30000 (10.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2012s / 33.0036 s
agent0:                 episode reward: 0.4211,                 loss: nan
agent1:                 episode reward: -0.4211,                 loss: nan
Episode: 3281/30000 (10.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1957s / 33.1992 s
agent0:                 episode reward: -0.1040,                 loss: nan
agent1:                 episode reward: 0.1040,                 loss: nan
Episode: 3301/30000 (11.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1998s / 33.3990 s
agent0:                 episode reward: 0.0331,                 loss: nan
agent1:                 episode reward: -0.0331,                 loss: nan
Episode: 3321/30000 (11.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1965s / 33.5955 s
agent0:                 episode reward: 0.0324,                 loss: nan
agent1:                 episode reward: -0.0324,                 loss: nan
Episode: 3341/30000 (11.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3490s / 33.9445 s
agent0:                 episode reward: 0.1981,                 loss: nan
agent1:                 episode reward: -0.1981,                 loss: 0.4568
Episode: 3361/30000 (11.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5764s / 34.5209 s
agent0:                 episode reward: 0.3165,                 loss: nan
agent1:                 episode reward: -0.3165,                 loss: 0.4479
Episode: 3381/30000 (11.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5768s / 35.0977 s
agent0:                 episode reward: -0.1197,                 loss: nan
agent1:                 episode reward: 0.1197,                 loss: 0.4369
Episode: 3401/30000 (11.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5793s / 35.6770 s
agent0:                 episode reward: -0.1955,                 loss: nan
agent1:                 episode reward: 0.1955,                 loss: 0.4227
Episode: 3421/30000 (11.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5698s / 36.2469 s
agent0:                 episode reward: -0.2618,                 loss: nan
agent1:                 episode reward: 0.2618,                 loss: 0.4029
Episode: 3441/30000 (11.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5751s / 36.8219 s
agent0:                 episode reward: -0.5744,                 loss: nan
agent1:                 episode reward: 0.5744,                 loss: 0.3882
Episode: 3461/30000 (11.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5772s / 37.3991 s
agent0:                 episode reward: -0.2110,                 loss: nan
agent1:                 episode reward: 0.2110,                 loss: 0.3737
Episode: 3481/30000 (11.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5674s / 37.9665 s
agent0:                 episode reward: -0.2827,                 loss: nan
agent1:                 episode reward: 0.2827,                 loss: 0.3672
Episode: 3501/30000 (11.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5804s / 38.5469 s
agent0:                 episode reward: -0.3665,                 loss: nan
agent1:                 episode reward: 0.3665,                 loss: 0.3670
Episode: 3521/30000 (11.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5734s / 39.1202 s
agent0:                 episode reward: -0.2396,                 loss: nan
agent1:                 episode reward: 0.2396,                 loss: 0.3680
Episode: 3541/30000 (11.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5789s / 39.6992 s
agent0:                 episode reward: -0.1629,                 loss: nan
agent1:                 episode reward: 0.1629,                 loss: 0.3678
Episode: 3561/30000 (11.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5859s / 40.2850 s
agent0:                 episode reward: -0.2270,                 loss: nan
agent1:                 episode reward: 0.2270,                 loss: 0.3671
Episode: 3581/30000 (11.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5822s / 40.8672 s
agent0:                 episode reward: -0.4163,                 loss: nan
agent1:                 episode reward: 0.4163,                 loss: 0.3640
Episode: 3601/30000 (12.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5812s / 41.4484 s
agent0:                 episode reward: -0.0256,                 loss: nan
agent1:                 episode reward: 0.0256,                 loss: 0.3629
Episode: 3621/30000 (12.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5754s / 42.0239 s
agent0:                 episode reward: -0.2585,                 loss: nan
agent1:                 episode reward: 0.2585,                 loss: 0.3661
Episode: 3641/30000 (12.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5844s / 42.6083 s
agent0:                 episode reward: -0.2718,                 loss: nan
agent1:                 episode reward: 0.2718,                 loss: 0.3677
Episode: 3661/30000 (12.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5870s / 43.1953 s
agent0:                 episode reward: 0.0946,                 loss: nan
agent1:                 episode reward: -0.0946,                 loss: 0.3642
Episode: 3681/30000 (12.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5836s / 43.7788 s
agent0:                 episode reward: -0.4266,                 loss: nan
agent1:                 episode reward: 0.4266,                 loss: 0.3585
Episode: 3701/30000 (12.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5782s / 44.3570 s
agent0:                 episode reward: -0.3763,                 loss: nan
agent1:                 episode reward: 0.3763,                 loss: 0.3485
Episode: 3721/30000 (12.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5776s / 44.9346 s
agent0:                 episode reward: -0.6363,                 loss: nan
agent1:                 episode reward: 0.6363,                 loss: 0.3469
Episode: 3741/30000 (12.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5868s / 45.5214 s
agent0:                 episode reward: -0.6862,                 loss: nan
agent1:                 episode reward: 0.6862,                 loss: 0.3407
Episode: 3761/30000 (12.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5823s / 46.1037 s
agent0:                 episode reward: -0.0838,                 loss: nan
agent1:                 episode reward: 0.0838,                 loss: 0.3433
Episode: 3781/30000 (12.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5793s / 46.6830 s
agent0:                 episode reward: -0.2759,                 loss: nan
agent1:                 episode reward: 0.2759,                 loss: 0.3458
Episode: 3801/30000 (12.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5808s / 47.2638 s
agent0:                 episode reward: -0.6818,                 loss: nan
agent1:                 episode reward: 0.6818,                 loss: 0.3470
Episode: 3821/30000 (12.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5821s / 47.8459 s
agent0:                 episode reward: -0.1396,                 loss: nan
agent1:                 episode reward: 0.1396,                 loss: 0.3392
Episode: 3841/30000 (12.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5813s / 48.4272 s
agent0:                 episode reward: -0.4143,                 loss: nan
agent1:                 episode reward: 0.4143,                 loss: 0.3413
Episode: 3861/30000 (12.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5769s / 49.0041 s
agent0:                 episode reward: -0.5452,                 loss: nan
agent1:                 episode reward: 0.5452,                 loss: 0.3372
Episode: 3881/30000 (12.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5833s / 49.5874 s
agent0:                 episode reward: -0.2091,                 loss: nan
agent1:                 episode reward: 0.2091,                 loss: 0.3361
Episode: 3901/30000 (13.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5821s / 50.1695 s
agent0:                 episode reward: -0.5212,                 loss: nan
agent1:                 episode reward: 0.5212,                 loss: 0.3388
Episode: 3921/30000 (13.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5842s / 50.7537 s
agent0:                 episode reward: -0.6903,                 loss: nan
agent1:                 episode reward: 0.6903,                 loss: 0.3384
Episode: 3941/30000 (13.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5769s / 51.3306 s
agent0:                 episode reward: -0.4136,                 loss: nan
agent1:                 episode reward: 0.4136,                 loss: 0.3373
Episode: 3961/30000 (13.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5770s / 51.9077 s
agent0:                 episode reward: -0.7750,                 loss: nan
agent1:                 episode reward: 0.7750,                 loss: 0.3395
Episode: 3981/30000 (13.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5774s / 52.4851 s
agent0:                 episode reward: -0.5924,                 loss: nan
agent1:                 episode reward: 0.5924,                 loss: 0.3357
Episode: 4001/30000 (13.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5771s / 53.0622 s
agent0:                 episode reward: -0.2516,                 loss: nan
agent1:                 episode reward: 0.2516,                 loss: 0.3371
Episode: 4021/30000 (13.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5872s / 53.6494 s
agent0:                 episode reward: -0.2746,                 loss: nan
agent1:                 episode reward: 0.2746,                 loss: 0.3552
Episode: 4041/30000 (13.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5797s / 54.2291 s
agent0:                 episode reward: -0.3626,                 loss: nan
agent1:                 episode reward: 0.3626,                 loss: 0.3497
Episode: 4061/30000 (13.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5790s / 54.8081 s
agent0:                 episode reward: -0.1071,                 loss: nan
agent1:                 episode reward: 0.1071,                 loss: 0.3512
Episode: 4081/30000 (13.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5868s / 55.3949 s
agent0:                 episode reward: -0.7529,                 loss: nan
agent1:                 episode reward: 0.7529,                 loss: 0.3513
Episode: 4101/30000 (13.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5891s / 55.9840 s
agent0:                 episode reward: -0.7548,                 loss: nan
agent1:                 episode reward: 0.7548,                 loss: 0.3515
Episode: 4121/30000 (13.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5869s / 56.5709 s
agent0:                 episode reward: -0.0846,                 loss: nan
agent1:                 episode reward: 0.0846,                 loss: 0.3541
Episode: 4141/30000 (13.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5800s / 57.1509 s
agent0:                 episode reward: -0.1699,                 loss: nan
agent1:                 episode reward: 0.1699,                 loss: 0.3537
Episode: 4161/30000 (13.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5790s / 57.7300 s
agent0:                 episode reward: -0.6984,                 loss: nan
agent1:                 episode reward: 0.6984,                 loss: 0.3497
Episode: 4181/30000 (13.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5807s / 58.3107 s
agent0:                 episode reward: -0.0826,                 loss: nan
agent1:                 episode reward: 0.0826,                 loss: 0.3516
Episode: 4201/30000 (14.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5863s / 58.8970 s
agent0:                 episode reward: -0.4361,                 loss: nan
agent1:                 episode reward: 0.4361,                 loss: 0.3513
Episode: 4221/30000 (14.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5879s / 59.4849 s
agent0:                 episode reward: -0.1056,                 loss: nan
agent1:                 episode reward: 0.1056,                 loss: 0.3512
Episode: 4241/30000 (14.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5982s / 60.0831 s
agent0:                 episode reward: -0.4296,                 loss: nan
agent1:                 episode reward: 0.4296,                 loss: 0.3522
Episode: 4261/30000 (14.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6148s / 60.6979 s
agent0:                 episode reward: -0.2540,                 loss: nan
agent1:                 episode reward: 0.2540,                 loss: 0.3495
Episode: 4281/30000 (14.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5920s / 61.2899 s
agent0:                 episode reward: -0.2371,                 loss: nan
agent1:                 episode reward: 0.2371,                 loss: 0.3483
Episode: 4301/30000 (14.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5943s / 61.8842 s
agent0:                 episode reward: 0.1431,                 loss: nan
agent1:                 episode reward: -0.1431,                 loss: 0.3524
Episode: 4321/30000 (14.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5911s / 62.4754 s
agent0:                 episode reward: -0.4365,                 loss: nan
agent1:                 episode reward: 0.4365,                 loss: 0.3501
Episode: 4341/30000 (14.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5944s / 63.0697 s
agent0:                 episode reward: -0.0712,                 loss: nan
agent1:                 episode reward: 0.0712,                 loss: 0.3472
Episode: 4361/30000 (14.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5917s / 63.6614 s
agent0:                 episode reward: -0.5194,                 loss: nan
agent1:                 episode reward: 0.5194,                 loss: 0.3412
Episode: 4381/30000 (14.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5906s / 64.2520 s
agent0:                 episode reward: -0.5803,                 loss: nan
agent1:                 episode reward: 0.5803,                 loss: 0.3380
Episode: 4401/30000 (14.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5825s / 64.8345 s
agent0:                 episode reward: -0.5069,                 loss: nan
agent1:                 episode reward: 0.5069,                 loss: 0.3361
Episode: 4421/30000 (14.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5911s / 65.4256 s
agent0:                 episode reward: -0.2917,                 loss: nan
agent1:                 episode reward: 0.2917,                 loss: 0.3366
Episode: 4441/30000 (14.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5941s / 66.0197 s
agent0:                 episode reward: -0.5828,                 loss: nan
agent1:                 episode reward: 0.5828,                 loss: 0.3389
Episode: 4461/30000 (14.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5920s / 66.6117 s
agent0:                 episode reward: -0.1487,                 loss: nan
agent1:                 episode reward: 0.1487,                 loss: 0.3380
Episode: 4481/30000 (14.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5953s / 67.2070 s
agent0:                 episode reward: -0.2730,                 loss: nan
agent1:                 episode reward: 0.2730,                 loss: 0.3370
Episode: 4501/30000 (15.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5953s / 67.8023 s
agent0:                 episode reward: -0.2834,                 loss: nan
agent1:                 episode reward: 0.2834,                 loss: 0.3400
Episode: 4521/30000 (15.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5942s / 68.3965 s
agent0:                 episode reward: -0.5498,                 loss: nan
agent1:                 episode reward: 0.5498,                 loss: 0.3371
Episode: 4541/30000 (15.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5927s / 68.9893 s
agent0:                 episode reward: -0.3361,                 loss: nan
agent1:                 episode reward: 0.3361,                 loss: 0.3408
Episode: 4561/30000 (15.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5885s / 69.5777 s
agent0:                 episode reward: -0.6367,                 loss: nan
agent1:                 episode reward: 0.6367,                 loss: 0.3399
Episode: 4581/30000 (15.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5866s / 70.1643 s
agent0:                 episode reward: -0.1559,                 loss: nan
agent1:                 episode reward: 0.1559,                 loss: 0.3368
Episode: 4601/30000 (15.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5859s / 70.7502 s
agent0:                 episode reward: -0.4872,                 loss: nan
agent1:                 episode reward: 0.4872,                 loss: 0.3334
Episode: 4621/30000 (15.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5923s / 71.3425 s
agent0:                 episode reward: -0.3652,                 loss: nan
agent1:                 episode reward: 0.3652,                 loss: 0.3378
Episode: 4641/30000 (15.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5886s / 71.9311 s
agent0:                 episode reward: -0.4394,                 loss: nan
agent1:                 episode reward: 0.4394,                 loss: 0.3391
Episode: 4661/30000 (15.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5899s / 72.5209 s
agent0:                 episode reward: -0.2737,                 loss: nan
agent1:                 episode reward: 0.2737,                 loss: 0.3358
Episode: 4681/30000 (15.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5885s / 73.1094 s
agent0:                 episode reward: -0.6585,                 loss: nan
agent1:                 episode reward: 0.6585,                 loss: 0.3429
Episode: 4701/30000 (15.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5981s / 73.7075 s
agent0:                 episode reward: -0.4014,                 loss: nan
agent1:                 episode reward: 0.4014,                 loss: 0.3403
Episode: 4721/30000 (15.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5970s / 74.3045 s
agent0:                 episode reward: -0.3803,                 loss: nan
agent1:                 episode reward: 0.3803,                 loss: 0.3404
Episode: 4741/30000 (15.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5918s / 74.8963 s
agent0:                 episode reward: -0.2698,                 loss: nan
agent1:                 episode reward: 0.2698,                 loss: 0.3382
Episode: 4761/30000 (15.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5833s / 75.4796 s
agent0:                 episode reward: -0.0477,                 loss: nan
agent1:                 episode reward: 0.0477,                 loss: 0.3396
Episode: 4781/30000 (15.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5883s / 76.0679 s
agent0:                 episode reward: -0.5362,                 loss: nan
agent1:                 episode reward: 0.5362,                 loss: 0.3398
Episode: 4801/30000 (16.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5893s / 76.6572 s
agent0:                 episode reward: -0.1925,                 loss: nan
agent1:                 episode reward: 0.1925,                 loss: 0.3373
Episode: 4821/30000 (16.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5853s / 77.2426 s
agent0:                 episode reward: -0.2364,                 loss: nan
agent1:                 episode reward: 0.2364,                 loss: 0.3355
Episode: 4841/30000 (16.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5908s / 77.8333 s
agent0:                 episode reward: -0.3833,                 loss: nan
agent1:                 episode reward: 0.3833,                 loss: 0.3363
Episode: 4861/30000 (16.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5866s / 78.4199 s
agent0:                 episode reward: -0.1298,                 loss: nan
agent1:                 episode reward: 0.1298,                 loss: 0.3408
Episode: 4881/30000 (16.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5973s / 79.0172 s
agent0:                 episode reward: -0.3452,                 loss: nan
agent1:                 episode reward: 0.3452,                 loss: 0.3389
Episode: 4901/30000 (16.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5926s / 79.6098 s
agent0:                 episode reward: -0.2290,                 loss: nan
agent1:                 episode reward: 0.2290,                 loss: 0.3393
Episode: 4921/30000 (16.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5838s / 80.1936 s
agent0:                 episode reward: -0.2506,                 loss: nan
agent1:                 episode reward: 0.2506,                 loss: 0.3367
Episode: 4941/30000 (16.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5923s / 80.7859 s
agent0:                 episode reward: -0.4395,                 loss: nan
agent1:                 episode reward: 0.4395,                 loss: 0.3377
Episode: 4961/30000 (16.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5848s / 81.3707 s
agent0:                 episode reward: -0.3010,                 loss: nan
agent1:                 episode reward: 0.3010,                 loss: 0.3394
Episode: 4981/30000 (16.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5904s / 81.9611 s
agent0:                 episode reward: -0.2513,                 loss: nan
agent1:                 episode reward: 0.2513,                 loss: 0.3406
Episode: 5001/30000 (16.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5905s / 82.5516 s
agent0:                 episode reward: -0.3616,                 loss: nan
agent1:                 episode reward: 0.3616,                 loss: 0.3410
Episode: 5021/30000 (16.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5918s / 83.1435 s
agent0:                 episode reward: -0.3306,                 loss: nan
agent1:                 episode reward: 0.3306,                 loss: 0.3481
Episode: 5041/30000 (16.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5894s / 83.7329 s
agent0:                 episode reward: -0.3247,                 loss: nan
agent1:                 episode reward: 0.3247,                 loss: 0.3523
Episode: 5061/30000 (16.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5968s / 84.3297 s
agent0:                 episode reward: -0.2073,                 loss: nan
agent1:                 episode reward: 0.2073,                 loss: 0.3494
Episode: 5081/30000 (16.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5963s / 84.9260 s
agent0:                 episode reward: -0.1449,                 loss: nan
agent1:                 episode reward: 0.1449,                 loss: 0.3506
Episode: 5101/30000 (17.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5978s / 85.5238 s
agent0:                 episode reward: -0.3918,                 loss: nan
agent1:                 episode reward: 0.3918,                 loss: 0.3493
Episode: 5121/30000 (17.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5953s / 86.1191 s
agent0:                 episode reward: -0.4514,                 loss: nan
agent1:                 episode reward: 0.4514,                 loss: 0.3519
Episode: 5141/30000 (17.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5990s / 86.7181 s
agent0:                 episode reward: -0.4964,                 loss: nan
agent1:                 episode reward: 0.4964,                 loss: 0.3504
Episode: 5161/30000 (17.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5918s / 87.3099 s
agent0:                 episode reward: -0.3850,                 loss: nan
agent1:                 episode reward: 0.3850,                 loss: 0.3491
Episode: 5181/30000 (17.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5921s / 87.9020 s
agent0:                 episode reward: -0.3543,                 loss: nan
agent1:                 episode reward: 0.3543,                 loss: 0.3492
Episode: 5201/30000 (17.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5878s / 88.4898 s
agent0:                 episode reward: -0.5255,                 loss: nan
agent1:                 episode reward: 0.5255,                 loss: 0.3532
Episode: 5221/30000 (17.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5941s / 89.0839 s
agent0:                 episode reward: -0.4525,                 loss: nan
agent1:                 episode reward: 0.4525,                 loss: 0.3505
Episode: 5241/30000 (17.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5916s / 89.6755 s
agent0:                 episode reward: -0.5737,                 loss: nan
agent1:                 episode reward: 0.5737,                 loss: 0.3511
Episode: 5261/30000 (17.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5870s / 90.2625 s
agent0:                 episode reward: -0.3876,                 loss: nan
agent1:                 episode reward: 0.3876,                 loss: 0.3478
Episode: 5281/30000 (17.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5920s / 90.8545 s
agent0:                 episode reward: -0.3585,                 loss: nan
agent1:                 episode reward: 0.3585,                 loss: 0.3503
Episode: 5301/30000 (17.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5962s / 91.4507 s
agent0:                 episode reward: -0.4057,                 loss: nan
agent1:                 episode reward: 0.4057,                 loss: 0.3505
Episode: 5321/30000 (17.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5985s / 92.0492 s
agent0:                 episode reward: -0.5832,                 loss: nan
agent1:                 episode reward: 0.5832,                 loss: 0.3492
Episode: 5341/30000 (17.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5991s / 92.6484 s
agent0:                 episode reward: -0.2768,                 loss: nan
agent1:                 episode reward: 0.2768,                 loss: 0.3470
Episode: 5361/30000 (17.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5967s / 93.2450 s
agent0:                 episode reward: -0.3426,                 loss: nan
agent1:                 episode reward: 0.3426,                 loss: 0.3424
Episode: 5381/30000 (17.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5916s / 93.8367 s
agent0:                 episode reward: -0.2971,                 loss: nan
agent1:                 episode reward: 0.2971,                 loss: 0.3440
Episode: 5401/30000 (18.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5951s / 94.4318 s
agent0:                 episode reward: -0.5983,                 loss: nan
agent1:                 episode reward: 0.5983,                 loss: 0.3408
Episode: 5421/30000 (18.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5990s / 95.0308 s
agent0:                 episode reward: -0.5295,                 loss: nan
agent1:                 episode reward: 0.5295,                 loss: 0.3410
Episode: 5441/30000 (18.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5873s / 95.6181 s
agent0:                 episode reward: -0.3795,                 loss: nan
agent1:                 episode reward: 0.3795,                 loss: 0.3423
Episode: 5461/30000 (18.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5923s / 96.2103 s
agent0:                 episode reward: -0.2765,                 loss: nan
agent1:                 episode reward: 0.2765,                 loss: 0.3365
Episode: 5481/30000 (18.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5924s / 96.8028 s
agent0:                 episode reward: -0.1411,                 loss: nan
agent1:                 episode reward: 0.1411,                 loss: 0.3426
Episode: 5501/30000 (18.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5965s / 97.3993 s
agent0:                 episode reward: -0.3594,                 loss: nan
agent1:                 episode reward: 0.3594,                 loss: 0.3390
Episode: 5521/30000 (18.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5917s / 97.9910 s
agent0:                 episode reward: -0.3790,                 loss: nan
agent1:                 episode reward: 0.3790,                 loss: 0.3421
Episode: 5541/30000 (18.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5952s / 98.5862 s
agent0:                 episode reward: -0.4671,                 loss: nan
agent1:                 episode reward: 0.4671,                 loss: 0.3397
Episode: 5561/30000 (18.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5911s / 99.1772 s
agent0:                 episode reward: -0.1533,                 loss: nan
agent1:                 episode reward: 0.1533,                 loss: 0.3403
Episode: 5581/30000 (18.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5916s / 99.7688 s
agent0:                 episode reward: -0.0536,                 loss: nan
agent1:                 episode reward: 0.0536,                 loss: 0.3393
Episode: 5601/30000 (18.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5943s / 100.3632 s
agent0:                 episode reward: -0.2917,                 loss: nan
agent1:                 episode reward: 0.2917,                 loss: 0.3399
Episode: 5621/30000 (18.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5885s / 100.9516 s
agent0:                 episode reward: -0.6304,                 loss: nan
agent1:                 episode reward: 0.6304,                 loss: 0.3404
Episode: 5641/30000 (18.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5838s / 101.5354 s
agent0:                 episode reward: -0.4091,                 loss: nan
agent1:                 episode reward: 0.4091,                 loss: 0.3416
Episode: 5661/30000 (18.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5919s / 102.1273 s
agent0:                 episode reward: -0.2644,                 loss: nan
agent1:                 episode reward: 0.2644,                 loss: 0.3439
Episode: 5681/30000 (18.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5954s / 102.7227 s
agent0:                 episode reward: -0.3603,                 loss: nan
agent1:                 episode reward: 0.3603,                 loss: 0.3464
Episode: 5701/30000 (19.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5898s / 103.3125 s
agent0:                 episode reward: -0.2526,                 loss: nan
agent1:                 episode reward: 0.2526,                 loss: 0.3500
Episode: 5721/30000 (19.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5973s / 103.9098 s
agent0:                 episode reward: -0.4755,                 loss: nan
agent1:                 episode reward: 0.4755,                 loss: 0.3486
Episode: 5741/30000 (19.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5876s / 104.4975 s
agent0:                 episode reward: -0.2648,                 loss: nan
agent1:                 episode reward: 0.2648,                 loss: 0.3490
Episode: 5761/30000 (19.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6015s / 105.0989 s
agent0:                 episode reward: -0.6426,                 loss: nan
agent1:                 episode reward: 0.6426,                 loss: 0.3479
Episode: 5781/30000 (19.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5973s / 105.6963 s
agent0:                 episode reward: -0.0520,                 loss: nan
agent1:                 episode reward: 0.0520,                 loss: 0.3492
Episode: 5801/30000 (19.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5977s / 106.2940 s
agent0:                 episode reward: -0.2600,                 loss: nan
agent1:                 episode reward: 0.2600,                 loss: 0.3503
Episode: 5821/30000 (19.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6011s / 106.8951 s
agent0:                 episode reward: -0.4956,                 loss: nan
agent1:                 episode reward: 0.4956,                 loss: 0.3478
Episode: 5841/30000 (19.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5949s / 107.4900 s
agent0:                 episode reward: -0.3237,                 loss: nan
agent1:                 episode reward: 0.3237,                 loss: 0.3510
Episode: 5861/30000 (19.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6022s / 108.0922 s
agent0:                 episode reward: 0.0961,                 loss: nan
agent1:                 episode reward: -0.0961,                 loss: 0.3461
Episode: 5881/30000 (19.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5951s / 108.6874 s
agent0:                 episode reward: -0.3795,                 loss: nan
agent1:                 episode reward: 0.3795,                 loss: 0.3496
Episode: 5901/30000 (19.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6009s / 109.2883 s
agent0:                 episode reward: -0.1982,                 loss: nan
agent1:                 episode reward: 0.1982,                 loss: 0.3485
Episode: 5921/30000 (19.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5936s / 109.8819 s
agent0:                 episode reward: -0.0920,                 loss: nan
agent1:                 episode reward: 0.0920,                 loss: 0.3478
Episode: 5941/30000 (19.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6003s / 110.4822 s
agent0:                 episode reward: -0.4556,                 loss: nan
agent1:                 episode reward: 0.4556,                 loss: 0.3510
Episode: 5961/30000 (19.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5954s / 111.0776 s
agent0:                 episode reward: -0.3178,                 loss: nan
agent1:                 episode reward: 0.3178,                 loss: 0.3498
Episode: 5981/30000 (19.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5910s / 111.6686 s
agent0:                 episode reward: -0.2418,                 loss: nan
agent1:                 episode reward: 0.2418,                 loss: 0.3486
Episode: 6001/30000 (20.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6013s / 112.2699 s
agent0:                 episode reward: -0.2454,                 loss: nan
agent1:                 episode reward: 0.2454,                 loss: 0.3502
Episode: 6021/30000 (20.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6069s / 112.8768 s
agent0:                 episode reward: -0.1947,                 loss: nan
agent1:                 episode reward: 0.1947,                 loss: 0.3436
Episode: 6041/30000 (20.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5943s / 113.4711 s
agent0:                 episode reward: -0.5113,                 loss: nan
agent1:                 episode reward: 0.5113,                 loss: 0.3435
Episode: 6061/30000 (20.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6021s / 114.0732 s
agent0:                 episode reward: -0.6077,                 loss: nan
agent1:                 episode reward: 0.6077,                 loss: 0.3447
Episode: 6081/30000 (20.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6086s / 114.6817 s
agent0:                 episode reward: -0.4884,                 loss: nan
agent1:                 episode reward: 0.4884,                 loss: 0.3427
Episode: 6101/30000 (20.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5928s / 115.2746 s
agent0:                 episode reward: -0.5219,                 loss: nan
agent1:                 episode reward: 0.5219,                 loss: 0.3452
Episode: 6121/30000 (20.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5990s / 115.8735 s
agent0:                 episode reward: -0.2394,                 loss: nan
agent1:                 episode reward: 0.2394,                 loss: 0.3439
Episode: 6141/30000 (20.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5915s / 116.4651 s
agent0:                 episode reward: -0.2331,                 loss: nan
agent1:                 episode reward: 0.2331,                 loss: 0.3435
Episode: 6161/30000 (20.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5838s / 117.0488 s
agent0:                 episode reward: -0.5998,                 loss: nan
agent1:                 episode reward: 0.5998,                 loss: 0.3459
Episode: 6181/30000 (20.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5883s / 117.6371 s
agent0:                 episode reward: -0.2847,                 loss: nan
agent1:                 episode reward: 0.2847,                 loss: 0.3469
Episode: 6201/30000 (20.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5981s / 118.2353 s
agent0:                 episode reward: -0.5873,                 loss: nan
agent1:                 episode reward: 0.5873,                 loss: 0.3443
Episode: 6221/30000 (20.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5914s / 118.8266 s
agent0:                 episode reward: -0.3247,                 loss: nan
agent1:                 episode reward: 0.3247,                 loss: 0.3432
Episode: 6241/30000 (20.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5951s / 119.4217 s
agent0:                 episode reward: -0.3212,                 loss: nan
agent1:                 episode reward: 0.3212,                 loss: 0.3418
Episode: 6261/30000 (20.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6012s / 120.0230 s
agent0:                 episode reward: -0.5129,                 loss: nan
agent1:                 episode reward: 0.5129,                 loss: 0.3456
Episode: 6281/30000 (20.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5907s / 120.6136 s
agent0:                 episode reward: -0.4314,                 loss: nan
agent1:                 episode reward: 0.4314,                 loss: 0.3427
Episode: 6301/30000 (21.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5974s / 121.2110 s
agent0:                 episode reward: -0.3916,                 loss: nan
agent1:                 episode reward: 0.3916,                 loss: 0.3443
Episode: 6321/30000 (21.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6008s / 121.8119 s
agent0:                 episode reward: -0.1427,                 loss: nan
agent1:                 episode reward: 0.1427,                 loss: 0.3445
Episode: 6341/30000 (21.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5954s / 122.4073 s
agent0:                 episode reward: -0.2052,                 loss: nan
agent1:                 episode reward: 0.2052,                 loss: 0.3442
Episode: 6361/30000 (21.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5972s / 123.0045 s
agent0:                 episode reward: -0.3488,                 loss: nan
agent1:                 episode reward: 0.3488,                 loss: 0.3484
Episode: 6381/30000 (21.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6044s / 123.6089 s
agent0:                 episode reward: -0.0422,                 loss: nan
agent1:                 episode reward: 0.0422,                 loss: 0.3476
Episode: 6401/30000 (21.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6032s / 124.2121 s
agent0:                 episode reward: 0.1569,                 loss: nan
agent1:                 episode reward: -0.1569,                 loss: 0.3503
Episode: 6421/30000 (21.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6013s / 124.8133 s
agent0:                 episode reward: -0.5279,                 loss: nan
agent1:                 episode reward: 0.5279,                 loss: 0.3485
Episode: 6441/30000 (21.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6039s / 125.4172 s
agent0:                 episode reward: -0.4022,                 loss: nan
agent1:                 episode reward: 0.4022,                 loss: 0.3482
Episode: 6461/30000 (21.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5994s / 126.0166 s
agent0:                 episode reward: -0.5299,                 loss: nan
agent1:                 episode reward: 0.5299,                 loss: 0.3494
Episode: 6481/30000 (21.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5966s / 126.6132 s
agent0:                 episode reward: -0.0939,                 loss: nan
agent1:                 episode reward: 0.0939,                 loss: 0.3486
Episode: 6501/30000 (21.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5895s / 127.2027 s
agent0:                 episode reward: -0.4283,                 loss: nan
agent1:                 episode reward: 0.4283,                 loss: 0.3463
Episode: 6521/30000 (21.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5986s / 127.8013 s
agent0:                 episode reward: 0.0256,                 loss: nan
agent1:                 episode reward: -0.0256,                 loss: 0.3480
Episode: 6541/30000 (21.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5991s / 128.4003 s
agent0:                 episode reward: -0.4140,                 loss: nan
agent1:                 episode reward: 0.4140,                 loss: 0.3477
Episode: 6561/30000 (21.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5987s / 128.9990 s
agent0:                 episode reward: -0.2578,                 loss: nan
agent1:                 episode reward: 0.2578,                 loss: 0.3500
Episode: 6581/30000 (21.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6042s / 129.6032 s
agent0:                 episode reward: -0.3730,                 loss: nan
agent1:                 episode reward: 0.3730,                 loss: 0.3501
Episode: 6601/30000 (22.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6051s / 130.2083 s
agent0:                 episode reward: -0.3785,                 loss: nan
agent1:                 episode reward: 0.3785,                 loss: 0.3486
Episode: 6621/30000 (22.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6013s / 130.8096 s
agent0:                 episode reward: -0.7914,                 loss: nan
agent1:                 episode reward: 0.7914,                 loss: 0.3468
Episode: 6641/30000 (22.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6007s / 131.4104 s
agent0:                 episode reward: -0.3759,                 loss: nan
agent1:                 episode reward: 0.3759,                 loss: 0.3461
Episode: 6661/30000 (22.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5913s / 132.0017 s
agent0:                 episode reward: -0.7248,                 loss: nan
agent1:                 episode reward: 0.7248,                 loss: 0.3474
Episode: 6681/30000 (22.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6011s / 132.6028 s
agent0:                 episode reward: -0.2929,                 loss: nan
agent1:                 episode reward: 0.2929,                 loss: 0.3429
Episode: 6701/30000 (22.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6036s / 133.2065 s
agent0:                 episode reward: -0.1009,                 loss: nan
agent1:                 episode reward: 0.1009,                 loss: 0.3482
Episode: 6721/30000 (22.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6015s / 133.8079 s
agent0:                 episode reward: -0.1477,                 loss: nan
agent1:                 episode reward: 0.1477,                 loss: 0.3480
Episode: 6741/30000 (22.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6059s / 134.4139 s
agent0:                 episode reward: -0.2683,                 loss: nan
agent1:                 episode reward: 0.2683,                 loss: 0.3460
Episode: 6761/30000 (22.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6039s / 135.0178 s
agent0:                 episode reward: -0.3554,                 loss: nan
agent1:                 episode reward: 0.3554,                 loss: 0.3456
Episode: 6781/30000 (22.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5965s / 135.6142 s
agent0:                 episode reward: -0.2805,                 loss: nan
agent1:                 episode reward: 0.2805,                 loss: 0.3437
Episode: 6801/30000 (22.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5987s / 136.2129 s
agent0:                 episode reward: -0.3953,                 loss: nan
agent1:                 episode reward: 0.3953,                 loss: 0.3460
Episode: 6821/30000 (22.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5935s / 136.8065 s
agent0:                 episode reward: -0.7311,                 loss: nan
agent1:                 episode reward: 0.7311,                 loss: 0.3474
Episode: 6841/30000 (22.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5950s / 137.4015 s
agent0:                 episode reward: -0.2114,                 loss: nan
agent1:                 episode reward: 0.2114,                 loss: 0.3468
Episode: 6861/30000 (22.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5984s / 137.9998 s
agent0:                 episode reward: -0.1721,                 loss: nan
agent1:                 episode reward: 0.1721,                 loss: 0.3453
Episode: 6881/30000 (22.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5973s / 138.5972 s
agent0:                 episode reward: -0.3842,                 loss: nan
agent1:                 episode reward: 0.3842,                 loss: 0.3473
Episode: 6901/30000 (23.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6033s / 139.2005 s
agent0:                 episode reward: -0.1536,                 loss: nan
agent1:                 episode reward: 0.1536,                 loss: 0.3454
Episode: 6921/30000 (23.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6045s / 139.8050 s
agent0:                 episode reward: -0.4658,                 loss: nan
agent1:                 episode reward: 0.4658,                 loss: 0.3468
Episode: 6941/30000 (23.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5950s / 140.4000 s
agent0:                 episode reward: -0.4371,                 loss: nan
agent1:                 episode reward: 0.4371,                 loss: 0.3476
Episode: 6961/30000 (23.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5966s / 140.9966 s
agent0:                 episode reward: -0.3948,                 loss: nan
agent1:                 episode reward: 0.3948,                 loss: 0.3491
Episode: 6981/30000 (23.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6007s / 141.5973 s
agent0:                 episode reward: -0.0625,                 loss: nan
agent1:                 episode reward: 0.0625,                 loss: 0.3455
Episode: 7001/30000 (23.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5988s / 142.1961 s
agent0:                 episode reward: -0.5820,                 loss: nan
agent1:                 episode reward: 0.5820,                 loss: 0.3474
Episode: 7021/30000 (23.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6040s / 142.8002 s
agent0:                 episode reward: -0.3392,                 loss: nan
agent1:                 episode reward: 0.3392,                 loss: 0.3499
Episode: 7041/30000 (23.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5966s / 143.3967 s
agent0:                 episode reward: -0.5661,                 loss: nan
agent1:                 episode reward: 0.5661,                 loss: 0.3481
Episode: 7061/30000 (23.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5958s / 143.9925 s
agent0:                 episode reward: -0.5998,                 loss: nan
agent1:                 episode reward: 0.5998,                 loss: 0.3491
Episode: 7081/30000 (23.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5928s / 144.5853 s
agent0:                 episode reward: -0.5425,                 loss: nan
agent1:                 episode reward: 0.5425,                 loss: 0.3455
Episode: 7101/30000 (23.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5982s / 145.1836 s
agent0:                 episode reward: -0.0784,                 loss: nan
agent1:                 episode reward: 0.0784,                 loss: 0.3483
Episode: 7121/30000 (23.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5868s / 145.7704 s
agent0:                 episode reward: -0.1691,                 loss: nan
agent1:                 episode reward: 0.1691,                 loss: 0.3484
Episode: 7141/30000 (23.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5963s / 146.3667 s
agent0:                 episode reward: -0.0912,                 loss: nan
agent1:                 episode reward: 0.0912,                 loss: 0.3495
Episode: 7161/30000 (23.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6009s / 146.9676 s
agent0:                 episode reward: -0.2323,                 loss: nan
agent1:                 episode reward: 0.2323,                 loss: 0.3470
Episode: 7181/30000 (23.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5991s / 147.5667 s
agent0:                 episode reward: -0.3307,                 loss: nan
agent1:                 episode reward: 0.3307,                 loss: 0.3505
Episode: 7201/30000 (24.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5931s / 148.1597 s
agent0:                 episode reward: -0.4873,                 loss: nan
agent1:                 episode reward: 0.4873,                 loss: 0.3464
Episode: 7221/30000 (24.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5981s / 148.7578 s
agent0:                 episode reward: -0.4188,                 loss: nan
agent1:                 episode reward: 0.4188,                 loss: 0.3505
Episode: 7241/30000 (24.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6094s / 149.3672 s
agent0:                 episode reward: -0.4729,                 loss: nan
agent1:                 episode reward: 0.4729,                 loss: 0.3482
Episode: 7261/30000 (24.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6016s / 149.9688 s
agent0:                 episode reward: -0.4012,                 loss: nan
agent1:                 episode reward: 0.4012,                 loss: 0.3476
Episode: 7281/30000 (24.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5925s / 150.5613 s
agent0:                 episode reward: -0.2289,                 loss: nan
agent1:                 episode reward: 0.2289,                 loss: 0.3508
Episode: 7301/30000 (24.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5874s / 151.1488 s
agent0:                 episode reward: -0.9128,                 loss: nan
agent1:                 episode reward: 0.9128,                 loss: 0.3464
Episode: 7321/30000 (24.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5953s / 151.7440 s
agent0:                 episode reward: -0.5265,                 loss: nan
agent1:                 episode reward: 0.5265,                 loss: 0.3468
Episode: 7341/30000 (24.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5862s / 152.3302 s
agent0:                 episode reward: -0.3477,                 loss: nan
agent1:                 episode reward: 0.3477,                 loss: 0.3495
Episode: 7361/30000 (24.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5882s / 152.9184 s
agent0:                 episode reward: -0.3789,                 loss: nan
agent1:                 episode reward: 0.3789,                 loss: 0.3512
Episode: 7381/30000 (24.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6012s / 153.5196 s
agent0:                 episode reward: -0.7164,                 loss: nan
agent1:                 episode reward: 0.7164,                 loss: 0.3492
Episode: 7401/30000 (24.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5960s / 154.1156 s
agent0:                 episode reward: -0.4286,                 loss: nan
agent1:                 episode reward: 0.4286,                 loss: 0.3498
Episode: 7421/30000 (24.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5848s / 154.7004 s
agent0:                 episode reward: -0.4959,                 loss: nan
agent1:                 episode reward: 0.4959,                 loss: 0.3500
Episode: 7441/30000 (24.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6026s / 155.3030 s
agent0:                 episode reward: -0.7329,                 loss: nan
agent1:                 episode reward: 0.7329,                 loss: 0.3486
Episode: 7461/30000 (24.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5967s / 155.8997 s
agent0:                 episode reward: -0.0825,                 loss: nan
agent1:                 episode reward: 0.0825,                 loss: 0.3492
Episode: 7481/30000 (24.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5967s / 156.4964 s
agent0:                 episode reward: -0.5348,                 loss: nan
agent1:                 episode reward: 0.5348,                 loss: 0.3504
Episode: 7501/30000 (25.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6095s / 157.1060 s
agent0:                 episode reward: -0.2578,                 loss: nan
agent1:                 episode reward: 0.2578,                 loss: 0.3443
Episode: 7521/30000 (25.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5922s / 157.6982 s
agent0:                 episode reward: -0.6917,                 loss: nan
agent1:                 episode reward: 0.6917,                 loss: 0.3487
Episode: 7541/30000 (25.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6026s / 158.3007 s
agent0:                 episode reward: -0.2342,                 loss: nan
agent1:                 episode reward: 0.2342,                 loss: 0.3502
Episode: 7561/30000 (25.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5951s / 158.8959 s
agent0:                 episode reward: -0.6504,                 loss: nan
agent1:                 episode reward: 0.6504,                 loss: 0.3476
Episode: 7581/30000 (25.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6028s / 159.4987 s
agent0:                 episode reward: -0.3703,                 loss: nan
agent1:                 episode reward: 0.3703,                 loss: 0.3500
Episode: 7601/30000 (25.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6021s / 160.1008 s
agent0:                 episode reward: -0.7544,                 loss: nan
agent1:                 episode reward: 0.7544,                 loss: 0.3511
Episode: 7621/30000 (25.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6107s / 160.7115 s
agent0:                 episode reward: -0.3253,                 loss: nan
agent1:                 episode reward: 0.3253,                 loss: 0.3484
Episode: 7641/30000 (25.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5976s / 161.3091 s
agent0:                 episode reward: -0.3588,                 loss: nan
agent1:                 episode reward: 0.3588,                 loss: 0.3493
Episode: 7661/30000 (25.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5893s / 161.8985 s
agent0:                 episode reward: -0.5354,                 loss: nan
agent1:                 episode reward: 0.5354,                 loss: 0.3501
Episode: 7681/30000 (25.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6129s / 162.5113 s
agent0:                 episode reward: -0.2685,                 loss: nan
agent1:                 episode reward: 0.2685,                 loss: 0.3447
Episode: 7701/30000 (25.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5989s / 163.1102 s
agent0:                 episode reward: -0.2961,                 loss: nan
agent1:                 episode reward: 0.2961,                 loss: 0.3394
Episode: 7721/30000 (25.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5903s / 163.7005 s
agent0:                 episode reward: -0.8709,                 loss: nan
agent1:                 episode reward: 0.8709,                 loss: 0.3388
Episode: 7741/30000 (25.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5952s / 164.2957 s
agent0:                 episode reward: -0.1938,                 loss: nan
agent1:                 episode reward: 0.1938,                 loss: 0.3395
Episode: 7761/30000 (25.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5920s / 164.8877 s
agent0:                 episode reward: -0.5820,                 loss: nan
agent1:                 episode reward: 0.5820,                 loss: 0.3403
Episode: 7781/30000 (25.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5961s / 165.4838 s
agent0:                 episode reward: -0.6649,                 loss: nan
agent1:                 episode reward: 0.6649,                 loss: 0.3433
Episode: 7801/30000 (26.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5971s / 166.0809 s
agent0:                 episode reward: -0.0537,                 loss: nan
agent1:                 episode reward: 0.0537,                 loss: 0.3419
Episode: 7821/30000 (26.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5970s / 166.6779 s
agent0:                 episode reward: -0.2481,                 loss: nan
agent1:                 episode reward: 0.2481,                 loss: 0.3404
Episode: 7841/30000 (26.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6004s / 167.2783 s
agent0:                 episode reward: -0.1122,                 loss: nan
agent1:                 episode reward: 0.1122,                 loss: 0.3390
Episode: 7861/30000 (26.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6015s / 167.8798 s
agent0:                 episode reward: -0.4445,                 loss: nan
agent1:                 episode reward: 0.4445,                 loss: 0.3414
Episode: 7881/30000 (26.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5986s / 168.4784 s
agent0:                 episode reward: -0.1587,                 loss: nan
agent1:                 episode reward: 0.1587,                 loss: 0.3389
Episode: 7901/30000 (26.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6014s / 169.0798 s
agent0:                 episode reward: -0.2319,                 loss: nan
agent1:                 episode reward: 0.2319,                 loss: 0.3409
Episode: 7921/30000 (26.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6012s / 169.6810 s
agent0:                 episode reward: -0.7190,                 loss: nan
agent1:                 episode reward: 0.7190,                 loss: 0.3419
Episode: 7941/30000 (26.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6021s / 170.2831 s
agent0:                 episode reward: -0.6548,                 loss: nan
agent1:                 episode reward: 0.6548,                 loss: 0.3416
Episode: 7961/30000 (26.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6025s / 170.8856 s
agent0:                 episode reward: -0.4450,                 loss: nan
agent1:                 episode reward: 0.4450,                 loss: 0.3413
Episode: 7981/30000 (26.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6065s / 171.4920 s
agent0:                 episode reward: -0.5757,                 loss: nan
agent1:                 episode reward: 0.5757,                 loss: 0.3411
Episode: 8001/30000 (26.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6095s / 172.1016 s
agent0:                 episode reward: -0.5284,                 loss: nan
agent1:                 episode reward: 0.5284,                 loss: 0.3433
Episode: 8021/30000 (26.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6096s / 172.7111 s
agent0:                 episode reward: -0.5688,                 loss: nan
agent1:                 episode reward: 0.5688,                 loss: 0.3616
Episode: 8041/30000 (26.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6071s / 173.3183 s
agent0:                 episode reward: -0.2084,                 loss: nan
agent1:                 episode reward: 0.2084,                 loss: 0.3595
Episode: 8061/30000 (26.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6056s / 173.9239 s
agent0:                 episode reward: -0.7409,                 loss: nan
agent1:                 episode reward: 0.7409,                 loss: 0.3594
Episode: 8081/30000 (26.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6084s / 174.5322 s
agent0:                 episode reward: -0.0355,                 loss: nan
agent1:                 episode reward: 0.0355,                 loss: 0.3585
Episode: 8101/30000 (27.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5965s / 175.1288 s
agent0:                 episode reward: -0.5388,                 loss: nan
agent1:                 episode reward: 0.5388,                 loss: 0.3613
Episode: 8121/30000 (27.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6096s / 175.7384 s
agent0:                 episode reward: -0.3492,                 loss: nan
agent1:                 episode reward: 0.3492,                 loss: 0.3607
Episode: 8141/30000 (27.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6041s / 176.3425 s
agent0:                 episode reward: -0.5654,                 loss: nan
agent1:                 episode reward: 0.5654,                 loss: 0.3605
Episode: 8161/30000 (27.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6031s / 176.9456 s
agent0:                 episode reward: -0.7496,                 loss: nan
agent1:                 episode reward: 0.7496,                 loss: 0.3599
Episode: 8181/30000 (27.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6091s / 177.5548 s
agent0:                 episode reward: -0.3130,                 loss: nan
agent1:                 episode reward: 0.3130,                 loss: 0.3593
Episode: 8201/30000 (27.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6052s / 178.1600 s
agent0:                 episode reward: -0.5355,                 loss: nan
agent1:                 episode reward: 0.5355,                 loss: 0.3605
Episode: 8221/30000 (27.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6033s / 178.7633 s
agent0:                 episode reward: -0.1918,                 loss: nan
agent1:                 episode reward: 0.1918,                 loss: 0.3602
Episode: 8241/30000 (27.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6199s / 179.3831 s
agent0:                 episode reward: -0.5567,                 loss: nan
agent1:                 episode reward: 0.5567,                 loss: 0.3590
Episode: 8261/30000 (27.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6082s / 179.9913 s
agent0:                 episode reward: -0.4007,                 loss: nan
agent1:                 episode reward: 0.4007,                 loss: 0.3602
Episode: 8281/30000 (27.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6041s / 180.5954 s
agent0:                 episode reward: -0.6357,                 loss: nan
agent1:                 episode reward: 0.6357,                 loss: 0.3573
Episode: 8301/30000 (27.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5985s / 181.1940 s
agent0:                 episode reward: -0.8751,                 loss: nan
agent1:                 episode reward: 0.8751,                 loss: 0.3601
Episode: 8321/30000 (27.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6084s / 181.8023 s
agent0:                 episode reward: -0.3788,                 loss: nan
agent1:                 episode reward: 0.3788,                 loss: 0.3644
Episode: 8341/30000 (27.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5991s / 182.4015 s
agent0:                 episode reward: -0.2264,                 loss: nan
agent1:                 episode reward: 0.2264,                 loss: 0.3555
Episode: 8361/30000 (27.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6043s / 183.0058 s
agent0:                 episode reward: -0.4777,                 loss: nan
agent1:                 episode reward: 0.4777,                 loss: 0.3499
Episode: 8381/30000 (27.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6039s / 183.6097 s
agent0:                 episode reward: -0.7799,                 loss: nan
agent1:                 episode reward: 0.7799,                 loss: 0.3486
Episode: 8401/30000 (28.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6087s / 184.2184 s
agent0:                 episode reward: -0.2995,                 loss: nan
agent1:                 episode reward: 0.2995,                 loss: 0.3480
Episode: 8421/30000 (28.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6009s / 184.8193 s
agent0:                 episode reward: -0.5424,                 loss: nan
agent1:                 episode reward: 0.5424,                 loss: 0.3504
Episode: 8441/30000 (28.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6058s / 185.4252 s
agent0:                 episode reward: -0.4669,                 loss: nan
agent1:                 episode reward: 0.4669,                 loss: 0.3516
Episode: 8461/30000 (28.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6048s / 186.0300 s
agent0:                 episode reward: -0.3806,                 loss: nan
agent1:                 episode reward: 0.3806,                 loss: 0.3531
Episode: 8481/30000 (28.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6032s / 186.6332 s
agent0:                 episode reward: -0.4221,                 loss: nan
agent1:                 episode reward: 0.4221,                 loss: 0.3515
Episode: 8501/30000 (28.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6062s / 187.2394 s
agent0:                 episode reward: -0.6191,                 loss: nan
agent1:                 episode reward: 0.6191,                 loss: 0.3523
Episode: 8521/30000 (28.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6043s / 187.8437 s
agent0:                 episode reward: -0.5678,                 loss: nan
agent1:                 episode reward: 0.5678,                 loss: 0.3501
Episode: 8541/30000 (28.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6030s / 188.4467 s
agent0:                 episode reward: -0.1577,                 loss: nan
agent1:                 episode reward: 0.1577,                 loss: 0.3508
Episode: 8561/30000 (28.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6013s / 189.0480 s
agent0:                 episode reward: -0.3051,                 loss: nan
agent1:                 episode reward: 0.3051,                 loss: 0.3525
Episode: 8581/30000 (28.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6021s / 189.6501 s
agent0:                 episode reward: -0.1153,                 loss: nan
agent1:                 episode reward: 0.1153,                 loss: 0.3491
Episode: 8601/30000 (28.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6065s / 190.2566 s
agent0:                 episode reward: -0.1596,                 loss: nan
agent1:                 episode reward: 0.1596,                 loss: 0.3520
Episode: 8621/30000 (28.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6182s / 190.8748 s
agent0:                 episode reward: -0.5702,                 loss: nan
agent1:                 episode reward: 0.5702,                 loss: 0.3477
Episode: 8641/30000 (28.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6045s / 191.4793 s
agent0:                 episode reward: -0.3595,                 loss: nan
agent1:                 episode reward: 0.3595,                 loss: 0.3494
Episode: 8661/30000 (28.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6005s / 192.0798 s
agent0:                 episode reward: -0.5890,                 loss: nan
agent1:                 episode reward: 0.5890,                 loss: 0.3511
Episode: 8681/30000 (28.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6088s / 192.6886 s
agent0:                 episode reward: -0.2424,                 loss: nan
agent1:                 episode reward: 0.2424,                 loss: 0.3477
Episode: 8701/30000 (29.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6036s / 193.2922 s
agent0:                 episode reward: -0.5207,                 loss: nan
agent1:                 episode reward: 0.5207,                 loss: 0.3429
Episode: 8721/30000 (29.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6042s / 193.8964 s
agent0:                 episode reward: -0.3643,                 loss: nan
agent1:                 episode reward: 0.3643,                 loss: 0.3413
Episode: 8741/30000 (29.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6038s / 194.5002 s
agent0:                 episode reward: -0.4675,                 loss: nan
agent1:                 episode reward: 0.4675,                 loss: 0.3418
Episode: 8761/30000 (29.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6077s / 195.1079 s
agent0:                 episode reward: -0.7439,                 loss: nan
agent1:                 episode reward: 0.7439,                 loss: 0.3403
Episode: 8781/30000 (29.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6018s / 195.7097 s
agent0:                 episode reward: 0.0962,                 loss: nan
agent1:                 episode reward: -0.0962,                 loss: 0.3440
Episode: 8801/30000 (29.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6075s / 196.3172 s
agent0:                 episode reward: -0.3080,                 loss: nan
agent1:                 episode reward: 0.3080,                 loss: 0.3413
Episode: 8821/30000 (29.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6150s / 196.9321 s
agent0:                 episode reward: -0.4455,                 loss: nan
agent1:                 episode reward: 0.4455,                 loss: 0.3462
Episode: 8841/30000 (29.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6127s / 197.5448 s
agent0:                 episode reward: -0.7025,                 loss: nan
agent1:                 episode reward: 0.7025,                 loss: 0.3424
Episode: 8861/30000 (29.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6060s / 198.1509 s
agent0:                 episode reward: -0.3689,                 loss: nan
agent1:                 episode reward: 0.3689,                 loss: 0.3426
Episode: 8881/30000 (29.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6110s / 198.7618 s
agent0:                 episode reward: -0.4391,                 loss: nan
agent1:                 episode reward: 0.4391,                 loss: 0.3416
Episode: 8901/30000 (29.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6122s / 199.3740 s
agent0:                 episode reward: -0.5428,                 loss: nan
agent1:                 episode reward: 0.5428,                 loss: 0.3413
Episode: 8921/30000 (29.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6034s / 199.9774 s
agent0:                 episode reward: -0.3692,                 loss: nan
agent1:                 episode reward: 0.3692,                 loss: 0.3418
Episode: 8941/30000 (29.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6103s / 200.5878 s
agent0:                 episode reward: -0.3264,                 loss: nan
agent1:                 episode reward: 0.3264,                 loss: 0.3431
Episode: 8961/30000 (29.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6013s / 201.1891 s
agent0:                 episode reward: -0.8335,                 loss: nan
agent1:                 episode reward: 0.8335,                 loss: 0.3416
Episode: 8981/30000 (29.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6086s / 201.7977 s
agent0:                 episode reward: -0.3691,                 loss: nan
agent1:                 episode reward: 0.3691,                 loss: 0.3402
Episode: 9001/30000 (30.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6109s / 202.4086 s
agent0:                 episode reward: -0.5690,                 loss: nan
agent1:                 episode reward: 0.5690,                 loss: 0.3432
Episode: 9021/30000 (30.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6071s / 203.0157 s
agent0:                 episode reward: -0.2015,                 loss: nan
agent1:                 episode reward: 0.2015,                 loss: 0.3474
Episode: 9041/30000 (30.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6057s / 203.6214 s
agent0:                 episode reward: -0.7922,                 loss: nan
agent1:                 episode reward: 0.7922,                 loss: 0.3480
Episode: 9061/30000 (30.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6105s / 204.2320 s
agent0:                 episode reward: -0.4678,                 loss: nan
agent1:                 episode reward: 0.4678,                 loss: 0.3504
Episode: 9081/30000 (30.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6166s / 204.8485 s
agent0:                 episode reward: -0.9221,                 loss: nan
agent1:                 episode reward: 0.9221,                 loss: 0.3510
Episode: 9101/30000 (30.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6122s / 205.4608 s
agent0:                 episode reward: -0.0221,                 loss: nan
agent1:                 episode reward: 0.0221,                 loss: 0.3491
Episode: 9121/30000 (30.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6103s / 206.0711 s
agent0:                 episode reward: -0.7586,                 loss: nan
agent1:                 episode reward: 0.7586,                 loss: 0.3478
Episode: 9141/30000 (30.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6092s / 206.6803 s
agent0:                 episode reward: -0.7786,                 loss: nan
agent1:                 episode reward: 0.7786,                 loss: 0.3482
Episode: 9161/30000 (30.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6147s / 207.2950 s
agent0:                 episode reward: -0.1833,                 loss: nan
agent1:                 episode reward: 0.1833,                 loss: 0.3461
Episode: 9181/30000 (30.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6145s / 207.9095 s
agent0:                 episode reward: -0.3232,                 loss: nan
agent1:                 episode reward: 0.3232,                 loss: 0.3465
Episode: 9201/30000 (30.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6154s / 208.5249 s
agent0:                 episode reward: -0.8528,                 loss: nan
agent1:                 episode reward: 0.8528,                 loss: 0.3493
Episode: 9221/30000 (30.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6133s / 209.1383 s
agent0:                 episode reward: -0.7387,                 loss: nan
agent1:                 episode reward: 0.7387,                 loss: 0.3470
Episode: 9241/30000 (30.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6203s / 209.7586 s
agent0:                 episode reward: -0.4431,                 loss: nan
agent1:                 episode reward: 0.4431,                 loss: 0.3528
Episode: 9261/30000 (30.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6067s / 210.3653 s
agent0:                 episode reward: -0.2284,                 loss: nan
agent1:                 episode reward: 0.2284,                 loss: 0.3490
Episode: 9281/30000 (30.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6177s / 210.9830 s
agent0:                 episode reward: -0.3206,                 loss: nan
agent1:                 episode reward: 0.3206,                 loss: 0.3480
Episode: 9301/30000 (31.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6196s / 211.6025 s
agent0:                 episode reward: -0.7414,                 loss: nan
agent1:                 episode reward: 0.7414,                 loss: 0.3464
Episode: 9321/30000 (31.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6155s / 212.2181 s
agent0:                 episode reward: -0.3031,                 loss: nan
agent1:                 episode reward: 0.3031,                 loss: 0.3467
Episode: 9341/30000 (31.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6149s / 212.8330 s
agent0:                 episode reward: -0.5726,                 loss: nan
agent1:                 episode reward: 0.5726,                 loss: 0.3434
Episode: 9361/30000 (31.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6179s / 213.4509 s
agent0:                 episode reward: -0.7219,                 loss: nan
agent1:                 episode reward: 0.7219,                 loss: 0.3399
Episode: 9381/30000 (31.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6215s / 214.0724 s
agent0:                 episode reward: -0.0660,                 loss: nan
agent1:                 episode reward: 0.0660,                 loss: 0.3396
Episode: 9401/30000 (31.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6211s / 214.6935 s
agent0:                 episode reward: -0.7198,                 loss: nan
agent1:                 episode reward: 0.7198,                 loss: 0.3406
Episode: 9421/30000 (31.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6195s / 215.3130 s
agent0:                 episode reward: -0.3423,                 loss: nan
agent1:                 episode reward: 0.3423,                 loss: 0.3392
Episode: 9441/30000 (31.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6149s / 215.9278 s
agent0:                 episode reward: -0.1008,                 loss: nan
agent1:                 episode reward: 0.1008,                 loss: 0.3382
Episode: 9461/30000 (31.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6206s / 216.5484 s
agent0:                 episode reward: -0.5389,                 loss: nan
agent1:                 episode reward: 0.5389,                 loss: 0.3377
Episode: 9481/30000 (31.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6099s / 217.1584 s
agent0:                 episode reward: -0.4489,                 loss: nan
agent1:                 episode reward: 0.4489,                 loss: 0.3397
Episode: 9501/30000 (31.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6213s / 217.7797 s
agent0:                 episode reward: -0.5441,                 loss: nan
agent1:                 episode reward: 0.5441,                 loss: 0.3395
Episode: 9521/30000 (31.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6083s / 218.3880 s
agent0:                 episode reward: -0.1309,                 loss: nan
agent1:                 episode reward: 0.1309,                 loss: 0.3386
Episode: 9541/30000 (31.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6091s / 218.9970 s
agent0:                 episode reward: -0.4506,                 loss: nan
agent1:                 episode reward: 0.4506,                 loss: 0.3370
Episode: 9561/30000 (31.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6116s / 219.6086 s
agent0:                 episode reward: -0.6824,                 loss: nan
agent1:                 episode reward: 0.6824,                 loss: 0.3382
Episode: 9581/30000 (31.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6143s / 220.2229 s
agent0:                 episode reward: -0.4575,                 loss: nan
agent1:                 episode reward: 0.4575,                 loss: 0.3411
Episode: 9601/30000 (32.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6184s / 220.8413 s
agent0:                 episode reward: -0.5244,                 loss: nan
agent1:                 episode reward: 0.5244,                 loss: 0.3391
Episode: 9621/30000 (32.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6097s / 221.4510 s
agent0:                 episode reward: -0.5899,                 loss: nan
agent1:                 episode reward: 0.5899,                 loss: 0.3394
Episode: 9641/30000 (32.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6122s / 222.0632 s
agent0:                 episode reward: -0.3453,                 loss: nan
agent1:                 episode reward: 0.3453,                 loss: 0.3399
Episode: 9661/30000 (32.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6241s / 222.6872 s
agent0:                 episode reward: -0.2186,                 loss: nan
agent1:                 episode reward: 0.2186,                 loss: 0.3411
Episode: 9681/30000 (32.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6279s / 223.3151 s
agent0:                 episode reward: -0.3879,                 loss: nan
agent1:                 episode reward: 0.3879,                 loss: 0.3324
Episode: 9701/30000 (32.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6241s / 223.9392 s
agent0:                 episode reward: -0.9451,                 loss: nan
agent1:                 episode reward: 0.9451,                 loss: 0.3314
Episode: 9721/30000 (32.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6224s / 224.5616 s
agent0:                 episode reward: -0.2240,                 loss: nan
agent1:                 episode reward: 0.2240,                 loss: 0.3297
Episode: 9741/30000 (32.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6289s / 225.1906 s
agent0:                 episode reward: -1.0256,                 loss: nan
agent1:                 episode reward: 1.0256,                 loss: 0.3288
Episode: 9761/30000 (32.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6237s / 225.8143 s
agent0:                 episode reward: -0.1326,                 loss: nan
agent1:                 episode reward: 0.1326,                 loss: 0.3344
Episode: 9781/30000 (32.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6240s / 226.4383 s
agent0:                 episode reward: -0.5556,                 loss: nan
agent1:                 episode reward: 0.5556,                 loss: 0.3321
Episode: 9801/30000 (32.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6335s / 227.0717 s
agent0:                 episode reward: -0.7192,                 loss: nan
agent1:                 episode reward: 0.7192,                 loss: 0.3295
Episode: 9821/30000 (32.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6244s / 227.6961 s
agent0:                 episode reward: -0.4340,                 loss: nan
agent1:                 episode reward: 0.4340,                 loss: 0.3365
Episode: 9841/30000 (32.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6302s / 228.3263 s
agent0:                 episode reward: -0.6478,                 loss: nan
agent1:                 episode reward: 0.6478,                 loss: 0.3314
Episode: 9861/30000 (32.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6202s / 228.9465 s
agent0:                 episode reward: -0.4900,                 loss: nan
agent1:                 episode reward: 0.4900,                 loss: 0.3312
Episode: 9881/30000 (32.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6182s / 229.5647 s
agent0:                 episode reward: -0.4690,                 loss: nan
agent1:                 episode reward: 0.4690,                 loss: 0.3297
Episode: 9901/30000 (33.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6142s / 230.1789 s
agent0:                 episode reward: -0.3725,                 loss: nan
agent1:                 episode reward: 0.3725,                 loss: 0.3291
Episode: 9921/30000 (33.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6218s / 230.8008 s
agent0:                 episode reward: -0.5692,                 loss: nan
agent1:                 episode reward: 0.5692,                 loss: 0.3299
Episode: 9941/30000 (33.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6151s / 231.4159 s
agent0:                 episode reward: -0.2341,                 loss: nan
agent1:                 episode reward: 0.2341,                 loss: 0.3302
Episode: 9961/30000 (33.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6263s / 232.0421 s
agent0:                 episode reward: -0.6111,                 loss: nan
agent1:                 episode reward: 0.6111,                 loss: 0.3299
Episode: 9981/30000 (33.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6231s / 232.6652 s
agent0:                 episode reward: -0.2208,                 loss: nan
agent1:                 episode reward: 0.2208,                 loss: 0.3293
Episode: 10001/30000 (33.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6213s / 233.2866 s
agent0:                 episode reward: -0.2923,                 loss: nan
agent1:                 episode reward: 0.2923,                 loss: 0.3320
Episode: 10021/30000 (33.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6239s / 233.9104 s
agent0:                 episode reward: -0.1954,                 loss: nan
agent1:                 episode reward: 0.1954,                 loss: 0.3415
Episode: 10041/30000 (33.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6190s / 234.5295 s
agent0:                 episode reward: -0.5180,                 loss: nan
agent1:                 episode reward: 0.5180,                 loss: 0.3382
Episode: 10061/30000 (33.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6174s / 235.1469 s
agent0:                 episode reward: -0.0780,                 loss: nan
agent1:                 episode reward: 0.0780,                 loss: 0.3392
Episode: 10081/30000 (33.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6239s / 235.7708 s
agent0:                 episode reward: -0.5650,                 loss: nan
agent1:                 episode reward: 0.5650,                 loss: 0.3431
Episode: 10101/30000 (33.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6210s / 236.3918 s
agent0:                 episode reward: -0.7520,                 loss: nan
agent1:                 episode reward: 0.7520,                 loss: 0.3398
Episode: 10121/30000 (33.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6235s / 237.0153 s
agent0:                 episode reward: -0.4044,                 loss: nan
agent1:                 episode reward: 0.4044,                 loss: 0.3440
Episode: 10141/30000 (33.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6253s / 237.6406 s
agent0:                 episode reward: -0.3026,                 loss: nan
agent1:                 episode reward: 0.3026,                 loss: 0.3414
Episode: 10161/30000 (33.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6217s / 238.2623 s
agent0:                 episode reward: -0.4212,                 loss: nan
agent1:                 episode reward: 0.4212,                 loss: 0.3414
Episode: 10181/30000 (33.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6216s / 238.8839 s
agent0:                 episode reward: -0.2410,                 loss: nan
agent1:                 episode reward: 0.2410,                 loss: 0.3413
Episode: 10201/30000 (34.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6164s / 239.5002 s
agent0:                 episode reward: -0.6119,                 loss: nan
agent1:                 episode reward: 0.6119,                 loss: 0.3395
Episode: 10221/30000 (34.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6215s / 240.1217 s
agent0:                 episode reward: -0.4490,                 loss: nan
agent1:                 episode reward: 0.4490,                 loss: 0.3418
Episode: 10241/30000 (34.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6270s / 240.7488 s
agent0:                 episode reward: -0.8658,                 loss: nan
agent1:                 episode reward: 0.8658,                 loss: 0.3417
Episode: 10261/30000 (34.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6222s / 241.3710 s
agent0:                 episode reward: -0.2608,                 loss: nan
agent1:                 episode reward: 0.2608,                 loss: 0.3425
Episode: 10281/30000 (34.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6192s / 241.9903 s
agent0:                 episode reward: -0.5226,                 loss: nan
agent1:                 episode reward: 0.5226,                 loss: 0.3435
Episode: 10301/30000 (34.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6180s / 242.6082 s
agent0:                 episode reward: -0.3037,                 loss: nan
agent1:                 episode reward: 0.3037,                 loss: 0.3408
Episode: 10321/30000 (34.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6134s / 243.2216 s
agent0:                 episode reward: -0.6342,                 loss: nan
agent1:                 episode reward: 0.6342,                 loss: 0.3427
Episode: 10341/30000 (34.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6224s / 243.8441 s
agent0:                 episode reward: -0.5948,                 loss: nan
agent1:                 episode reward: 0.5948,                 loss: 0.3371
Episode: 10361/30000 (34.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6182s / 244.4623 s
agent0:                 episode reward: -0.2684,                 loss: nan
agent1:                 episode reward: 0.2684,                 loss: 0.3324
Episode: 10381/30000 (34.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6155s / 245.0777 s
agent0:                 episode reward: -0.2004,                 loss: nan
agent1:                 episode reward: 0.2004,                 loss: 0.3329
Episode: 10401/30000 (34.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6213s / 245.6990 s
agent0:                 episode reward: -0.3923,                 loss: nan
agent1:                 episode reward: 0.3923,                 loss: 0.3310
Episode: 10421/30000 (34.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6162s / 246.3152 s
agent0:                 episode reward: -0.3961,                 loss: nan
agent1:                 episode reward: 0.3961,                 loss: 0.3328
Episode: 10441/30000 (34.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6288s / 246.9440 s
agent0:                 episode reward: -0.8685,                 loss: nan
agent1:                 episode reward: 0.8685,                 loss: 0.3307
Episode: 10461/30000 (34.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6338s / 247.5777 s
agent0:                 episode reward: -0.5630,                 loss: nan
agent1:                 episode reward: 0.5630,                 loss: 0.3362
Episode: 10481/30000 (34.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6304s / 248.2081 s
agent0:                 episode reward: -0.7868,                 loss: nan
agent1:                 episode reward: 0.7868,                 loss: 0.3367
Episode: 10501/30000 (35.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6182s / 248.8264 s
agent0:                 episode reward: -0.3698,                 loss: nan
agent1:                 episode reward: 0.3698,                 loss: 0.3327
Episode: 10521/30000 (35.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6257s / 249.4521 s
agent0:                 episode reward: -0.4088,                 loss: nan
agent1:                 episode reward: 0.4088,                 loss: 0.3350
Episode: 10541/30000 (35.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6221s / 250.0742 s
agent0:                 episode reward: -0.6356,                 loss: nan
agent1:                 episode reward: 0.6356,                 loss: 0.3317
Episode: 10561/30000 (35.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6151s / 250.6893 s
agent0:                 episode reward: -0.5250,                 loss: nan
agent1:                 episode reward: 0.5250,                 loss: 0.3370
Episode: 10581/30000 (35.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6321s / 251.3214 s
agent0:                 episode reward: -0.7321,                 loss: nan
agent1:                 episode reward: 0.7321,                 loss: 0.3348
Episode: 10601/30000 (35.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6271s / 251.9485 s
agent0:                 episode reward: -0.6626,                 loss: nan
agent1:                 episode reward: 0.6626,                 loss: 0.3354
Episode: 10621/30000 (35.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6233s / 252.5718 s
agent0:                 episode reward: -0.3847,                 loss: nan
agent1:                 episode reward: 0.3847,                 loss: 0.3348
Episode: 10641/30000 (35.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6262s / 253.1980 s
agent0:                 episode reward: -0.6712,                 loss: nan
agent1:                 episode reward: 0.6712,                 loss: 0.3317
Episode: 10661/30000 (35.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6279s / 253.8258 s
agent0:                 episode reward: -0.5408,                 loss: nan
agent1:                 episode reward: 0.5408,                 loss: 0.3320
Episode: 10681/30000 (35.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6279s / 254.4538 s
agent0:                 episode reward: -0.7919,                 loss: nan
agent1:                 episode reward: 0.7919,                 loss: 0.3376
Episode: 10701/30000 (35.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6251s / 255.0789 s
agent0:                 episode reward: -0.7018,                 loss: nan
agent1:                 episode reward: 0.7018,                 loss: 0.3330
Episode: 10721/30000 (35.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6208s / 255.6997 s
agent0:                 episode reward: -0.4785,                 loss: nan
agent1:                 episode reward: 0.4785,                 loss: 0.3368
Episode: 10741/30000 (35.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6239s / 256.3236 s
agent0:                 episode reward: -0.1370,                 loss: nan
agent1:                 episode reward: 0.1370,                 loss: 0.3344
Episode: 10761/30000 (35.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6274s / 256.9510 s
agent0:                 episode reward: -0.3444,                 loss: nan
agent1:                 episode reward: 0.3444,                 loss: 0.3343
Episode: 10781/30000 (35.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6260s / 257.5771 s
agent0:                 episode reward: -0.5348,                 loss: nan
agent1:                 episode reward: 0.5348,                 loss: 0.3349
Episode: 10801/30000 (36.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6329s / 258.2100 s
agent0:                 episode reward: -0.3246,                 loss: nan
agent1:                 episode reward: 0.3246,                 loss: 0.3368
Episode: 10821/30000 (36.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6351s / 258.8451 s
agent0:                 episode reward: -0.1886,                 loss: nan
agent1:                 episode reward: 0.1886,                 loss: 0.3350
Episode: 10841/30000 (36.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6336s / 259.4787 s
agent0:                 episode reward: -0.5734,                 loss: nan
agent1:                 episode reward: 0.5734,                 loss: 0.3367
Episode: 10861/30000 (36.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6172s / 260.0960 s
agent0:                 episode reward: -0.3886,                 loss: nan
agent1:                 episode reward: 0.3886,                 loss: 0.3387
Episode: 10881/30000 (36.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6165s / 260.7125 s
agent0:                 episode reward: -0.3565,                 loss: nan
agent1:                 episode reward: 0.3565,                 loss: 0.3357
Episode: 10901/30000 (36.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6280s / 261.3405 s
agent0:                 episode reward: -0.1132,                 loss: nan
agent1:                 episode reward: 0.1132,                 loss: 0.3342
Episode: 10921/30000 (36.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6286s / 261.9691 s
agent0:                 episode reward: -0.5226,                 loss: nan
agent1:                 episode reward: 0.5226,                 loss: 0.3373
Episode: 10941/30000 (36.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6287s / 262.5978 s
agent0:                 episode reward: -0.3651,                 loss: nan
agent1:                 episode reward: 0.3651,                 loss: 0.3348
Episode: 10961/30000 (36.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6219s / 263.2197 s
agent0:                 episode reward: -0.2707,                 loss: nan
agent1:                 episode reward: 0.2707,                 loss: 0.3355
Episode: 10981/30000 (36.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6308s / 263.8505 s
agent0:                 episode reward: -0.4854,                 loss: nan
agent1:                 episode reward: 0.4854,                 loss: 0.3373
Episode: 11001/30000 (36.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6251s / 264.4756 s
agent0:                 episode reward: -0.6284,                 loss: nan
agent1:                 episode reward: 0.6284,                 loss: 0.3337
Episode: 11021/30000 (36.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6365s / 265.1120 s
agent0:                 episode reward: -0.4981,                 loss: nan
agent1:                 episode reward: 0.4981,                 loss: 0.3466
Episode: 11041/30000 (36.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6335s / 265.7455 s
agent0:                 episode reward: -0.3123,                 loss: nan
agent1:                 episode reward: 0.3123,                 loss: 0.3459
Episode: 11061/30000 (36.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6341s / 266.3796 s
agent0:                 episode reward: -0.7288,                 loss: nan
agent1:                 episode reward: 0.7288,                 loss: 0.3406
Episode: 11081/30000 (36.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6428s / 267.0224 s
agent0:                 episode reward: -0.5887,                 loss: nan
agent1:                 episode reward: 0.5887,                 loss: 0.3439
Episode: 11101/30000 (37.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6339s / 267.6563 s
agent0:                 episode reward: -0.3878,                 loss: nan
agent1:                 episode reward: 0.3878,                 loss: 0.3462
Episode: 11121/30000 (37.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6367s / 268.2931 s
agent0:                 episode reward: -0.8844,                 loss: nan
agent1:                 episode reward: 0.8844,                 loss: 0.3451
Episode: 11141/30000 (37.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6345s / 268.9276 s
agent0:                 episode reward: -0.5591,                 loss: nan
agent1:                 episode reward: 0.5591,                 loss: 0.3418
Episode: 11161/30000 (37.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6495s / 269.5771 s
agent0:                 episode reward: -0.1701,                 loss: nan
agent1:                 episode reward: 0.1701,                 loss: 0.3424
Episode: 11181/30000 (37.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6394s / 270.2165 s
agent0:                 episode reward: -0.5426,                 loss: nan
agent1:                 episode reward: 0.5426,                 loss: 0.3442
Episode: 11201/30000 (37.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6330s / 270.8495 s
agent0:                 episode reward: -0.5452,                 loss: nan
agent1:                 episode reward: 0.5452,                 loss: 0.3444
Episode: 11221/30000 (37.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6424s / 271.4919 s
agent0:                 episode reward: -0.5585,                 loss: nan
agent1:                 episode reward: 0.5585,                 loss: 0.3447
Episode: 11241/30000 (37.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6361s / 272.1280 s
agent0:                 episode reward: -0.4421,                 loss: nan
agent1:                 episode reward: 0.4421,                 loss: 0.3450
Episode: 11261/30000 (37.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6304s / 272.7584 s
agent0:                 episode reward: -0.2464,                 loss: nan
agent1:                 episode reward: 0.2464,                 loss: 0.3448
Episode: 11281/30000 (37.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6436s / 273.4020 s
agent0:                 episode reward: -0.6069,                 loss: nan
agent1:                 episode reward: 0.6069,                 loss: 0.3448
Episode: 11301/30000 (37.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6323s / 274.0343 s
agent0:                 episode reward: -0.5440,                 loss: nan
agent1:                 episode reward: 0.5440,                 loss: 0.3429
Episode: 11321/30000 (37.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6373s / 274.6716 s
agent0:                 episode reward: -0.2950,                 loss: nan
agent1:                 episode reward: 0.2950,                 loss: 0.3433
Episode: 11341/30000 (37.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6405s / 275.3122 s
agent0:                 episode reward: -0.6489,                 loss: nan
agent1:                 episode reward: 0.6489,                 loss: 0.3404
Episode: 11361/30000 (37.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6351s / 275.9473 s
agent0:                 episode reward: -0.7564,                 loss: nan
agent1:                 episode reward: 0.7564,                 loss: 0.3310
Episode: 11381/30000 (37.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6456s / 276.5929 s
agent0:                 episode reward: -0.5953,                 loss: nan
agent1:                 episode reward: 0.5953,                 loss: 0.3296
Episode: 11401/30000 (38.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6316s / 277.2246 s
agent0:                 episode reward: -0.7361,                 loss: nan
agent1:                 episode reward: 0.7361,                 loss: 0.3353
Episode: 11421/30000 (38.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6349s / 277.8594 s
agent0:                 episode reward: -0.6607,                 loss: nan
agent1:                 episode reward: 0.6607,                 loss: 0.3303
Episode: 11441/30000 (38.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6345s / 278.4940 s
agent0:                 episode reward: -0.6514,                 loss: nan
agent1:                 episode reward: 0.6514,                 loss: 0.3325
Episode: 11461/30000 (38.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6417s / 279.1356 s
agent0:                 episode reward: -0.3305,                 loss: nan
agent1:                 episode reward: 0.3305,                 loss: 0.3302
Episode: 11481/30000 (38.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6446s / 279.7802 s
agent0:                 episode reward: -0.3628,                 loss: nan
agent1:                 episode reward: 0.3628,                 loss: 0.3321
Episode: 11501/30000 (38.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6394s / 280.4197 s
agent0:                 episode reward: -0.1775,                 loss: nan
agent1:                 episode reward: 0.1775,                 loss: 0.3323
Episode: 11521/30000 (38.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6401s / 281.0597 s
agent0:                 episode reward: -0.4735,                 loss: nan
agent1:                 episode reward: 0.4735,                 loss: 0.3312
Episode: 11541/30000 (38.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6366s / 281.6963 s
agent0:                 episode reward: -0.7141,                 loss: nan
agent1:                 episode reward: 0.7141,                 loss: 0.3301
Episode: 11561/30000 (38.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6403s / 282.3367 s
agent0:                 episode reward: -0.8129,                 loss: nan
agent1:                 episode reward: 0.8129,                 loss: 0.3340
Episode: 11581/30000 (38.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6478s / 282.9845 s
agent0:                 episode reward: -0.4623,                 loss: nan
agent1:                 episode reward: 0.4623,                 loss: 0.3313
Episode: 11601/30000 (38.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6486s / 283.6331 s
agent0:                 episode reward: -0.5921,                 loss: nan
agent1:                 episode reward: 0.5921,                 loss: 0.3330
Episode: 11621/30000 (38.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6498s / 284.2828 s
agent0:                 episode reward: -0.7252,                 loss: nan
agent1:                 episode reward: 0.7252,                 loss: 0.3293
Episode: 11641/30000 (38.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6518s / 284.9347 s
agent0:                 episode reward: -0.2595,                 loss: nan
agent1:                 episode reward: 0.2595,                 loss: 0.3305
Episode: 11661/30000 (38.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6442s / 285.5789 s
agent0:                 episode reward: -0.8219,                 loss: nan
agent1:                 episode reward: 0.8219,                 loss: 0.3326
Episode: 11681/30000 (38.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6398s / 286.2187 s
agent0:                 episode reward: -1.1509,                 loss: nan
agent1:                 episode reward: 1.1509,                 loss: 0.3432
Episode: 11701/30000 (39.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6552s / 286.8739 s
agent0:                 episode reward: -0.7602,                 loss: nan
agent1:                 episode reward: 0.7602,                 loss: 0.3457
Episode: 11721/30000 (39.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6456s / 287.5194 s
agent0:                 episode reward: -0.6096,                 loss: nan
agent1:                 episode reward: 0.6096,                 loss: 0.3415
Episode: 11741/30000 (39.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6393s / 288.1587 s
agent0:                 episode reward: -0.5313,                 loss: nan
agent1:                 episode reward: 0.5313,                 loss: 0.3458
Episode: 11761/30000 (39.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6437s / 288.8024 s
agent0:                 episode reward: -0.4800,                 loss: nan
agent1:                 episode reward: 0.4800,                 loss: 0.3430
Episode: 11781/30000 (39.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6383s / 289.4407 s
agent0:                 episode reward: -0.4266,                 loss: nan
agent1:                 episode reward: 0.4266,                 loss: 0.3440
Episode: 11801/30000 (39.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6384s / 290.0791 s
agent0:                 episode reward: -0.6695,                 loss: nan
agent1:                 episode reward: 0.6695,                 loss: 0.3481
Episode: 11821/30000 (39.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6434s / 290.7225 s
agent0:                 episode reward: -0.8284,                 loss: nan
agent1:                 episode reward: 0.8284,                 loss: 0.3416
Episode: 11841/30000 (39.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6418s / 291.3643 s
agent0:                 episode reward: -0.4058,                 loss: nan
agent1:                 episode reward: 0.4058,                 loss: 0.3437
Episode: 11861/30000 (39.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6391s / 292.0034 s
agent0:                 episode reward: -0.9284,                 loss: nan
agent1:                 episode reward: 0.9284,                 loss: 0.3461
Episode: 11881/30000 (39.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6336s / 292.6369 s
agent0:                 episode reward: -0.8788,                 loss: nan
agent1:                 episode reward: 0.8788,                 loss: 0.3436
Episode: 11901/30000 (39.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6309s / 293.2679 s
agent0:                 episode reward: -0.4138,                 loss: nan
agent1:                 episode reward: 0.4138,                 loss: 0.3420
Episode: 11921/30000 (39.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6417s / 293.9096 s
agent0:                 episode reward: -0.7027,                 loss: nan
agent1:                 episode reward: 0.7027,                 loss: 0.3451
Episode: 11941/30000 (39.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6319s / 294.5414 s
agent0:                 episode reward: -0.6110,                 loss: nan
agent1:                 episode reward: 0.6110,                 loss: 0.3440
Episode: 11961/30000 (39.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6331s / 295.1745 s
agent0:                 episode reward: -0.2533,                 loss: nan
agent1:                 episode reward: 0.2533,                 loss: 0.3434
Episode: 11981/30000 (39.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6425s / 295.8171 s
agent0:                 episode reward: -0.5380,                 loss: nan
agent1:                 episode reward: 0.5380,                 loss: 0.3439
Episode: 12001/30000 (40.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6445s / 296.4615 s
agent0:                 episode reward: -0.6595,                 loss: nan
agent1:                 episode reward: 0.6595,                 loss: 0.3450
Episode: 12021/30000 (40.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6431s / 297.1047 s
agent0:                 episode reward: -0.4075,                 loss: nan
agent1:                 episode reward: 0.4075,                 loss: 0.3381
Episode: 12041/30000 (40.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6836s / 297.7882 s
agent0:                 episode reward: -0.4445,                 loss: nan
agent1:                 episode reward: 0.4445,                 loss: 0.3390
Episode: 12061/30000 (40.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6357s / 298.4239 s
agent0:                 episode reward: -0.6278,                 loss: nan
agent1:                 episode reward: 0.6278,                 loss: 0.3417
Episode: 12081/30000 (40.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6321s / 299.0560 s
agent0:                 episode reward: -0.6446,                 loss: nan
agent1:                 episode reward: 0.6446,                 loss: 0.3367
Episode: 12101/30000 (40.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6489s / 299.7049 s
agent0:                 episode reward: -0.4679,                 loss: nan
agent1:                 episode reward: 0.4679,                 loss: 0.3388
Episode: 12121/30000 (40.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6362s / 300.3411 s
agent0:                 episode reward: -0.3559,                 loss: nan
agent1:                 episode reward: 0.3559,                 loss: 0.3401
Episode: 12141/30000 (40.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6475s / 300.9886 s
agent0:                 episode reward: -0.6022,                 loss: nan
agent1:                 episode reward: 0.6022,                 loss: 0.3419
Episode: 12161/30000 (40.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6488s / 301.6375 s
agent0:                 episode reward: -0.4289,                 loss: nan
agent1:                 episode reward: 0.4289,                 loss: 0.3387
Episode: 12181/30000 (40.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6513s / 302.2888 s
agent0:                 episode reward: -0.4305,                 loss: nan
agent1:                 episode reward: 0.4305,                 loss: 0.3396
Episode: 12201/30000 (40.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6412s / 302.9300 s
agent0:                 episode reward: -0.2932,                 loss: nan
agent1:                 episode reward: 0.2932,                 loss: 0.3386
Episode: 12221/30000 (40.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6421s / 303.5721 s
agent0:                 episode reward: -0.4649,                 loss: nan
agent1:                 episode reward: 0.4649,                 loss: 0.3389
Episode: 12241/30000 (40.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6438s / 304.2159 s
agent0:                 episode reward: -0.3051,                 loss: nan
agent1:                 episode reward: 0.3051,                 loss: 0.3413
Episode: 12261/30000 (40.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6383s / 304.8542 s
agent0:                 episode reward: -0.4967,                 loss: nan
agent1:                 episode reward: 0.4967,                 loss: 0.3401
Episode: 12281/30000 (40.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6346s / 305.4888 s
agent0:                 episode reward: -0.6518,                 loss: nan
agent1:                 episode reward: 0.6518,                 loss: 0.3384
Episode: 12301/30000 (41.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6609s / 306.1497 s
agent0:                 episode reward: -0.6496,                 loss: nan
agent1:                 episode reward: 0.6496,                 loss: 0.3362
Episode: 12321/30000 (41.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6501s / 306.7998 s
agent0:                 episode reward: -0.7601,                 loss: nan
agent1:                 episode reward: 0.7601,                 loss: 0.3405
Episode: 12341/30000 (41.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6465s / 307.4463 s
agent0:                 episode reward: -0.4767,                 loss: nan
agent1:                 episode reward: 0.4767,                 loss: 0.3474
Episode: 12361/30000 (41.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6431s / 308.0895 s
agent0:                 episode reward: -0.3054,                 loss: nan
agent1:                 episode reward: 0.3054,                 loss: 0.3541
Episode: 12381/30000 (41.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6484s / 308.7379 s
agent0:                 episode reward: -0.6093,                 loss: nan
agent1:                 episode reward: 0.6093,                 loss: 0.3522
Episode: 12401/30000 (41.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6361s / 309.3740 s
agent0:                 episode reward: -0.7336,                 loss: nan
agent1:                 episode reward: 0.7336,                 loss: 0.3552
Episode: 12421/30000 (41.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6385s / 310.0125 s
agent0:                 episode reward: -0.3747,                 loss: nan
agent1:                 episode reward: 0.3747,                 loss: 0.3515
Episode: 12441/30000 (41.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6381s / 310.6506 s
agent0:                 episode reward: -0.6132,                 loss: nan
agent1:                 episode reward: 0.6132,                 loss: 0.3530
Episode: 12461/30000 (41.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6389s / 311.2894 s
agent0:                 episode reward: -0.5135,                 loss: nan
agent1:                 episode reward: 0.5135,                 loss: 0.3522
Episode: 12481/30000 (41.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6448s / 311.9343 s
agent0:                 episode reward: -0.6426,                 loss: nan
agent1:                 episode reward: 0.6426,                 loss: 0.3542
Episode: 12501/30000 (41.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6420s / 312.5763 s
agent0:                 episode reward: -0.6758,                 loss: nan
agent1:                 episode reward: 0.6758,                 loss: 0.3534
Episode: 12521/30000 (41.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6418s / 313.2181 s
agent0:                 episode reward: -0.5347,                 loss: nan
agent1:                 episode reward: 0.5347,                 loss: 0.3532
Episode: 12541/30000 (41.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6434s / 313.8615 s
agent0:                 episode reward: -0.4297,                 loss: nan
agent1:                 episode reward: 0.4297,                 loss: 0.3532
Episode: 12561/30000 (41.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6622s / 314.5237 s
agent0:                 episode reward: -0.5025,                 loss: nan
agent1:                 episode reward: 0.5025,                 loss: 0.3543
Episode: 12581/30000 (41.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6451s / 315.1688 s
agent0:                 episode reward: -0.4622,                 loss: nan
agent1:                 episode reward: 0.4622,                 loss: 0.3565
Episode: 12601/30000 (42.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6526s / 315.8214 s
agent0:                 episode reward: -0.4885,                 loss: nan
agent1:                 episode reward: 0.4885,                 loss: 0.3545
Episode: 12621/30000 (42.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6503s / 316.4717 s
agent0:                 episode reward: -0.4164,                 loss: nan
agent1:                 episode reward: 0.4164,                 loss: 0.3533
Episode: 12641/30000 (42.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6482s / 317.1199 s
agent0:                 episode reward: -0.5380,                 loss: nan
agent1:                 episode reward: 0.5380,                 loss: 0.3545
Episode: 12661/30000 (42.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6415s / 317.7613 s
agent0:                 episode reward: -0.2165,                 loss: nan
agent1:                 episode reward: 0.2165,                 loss: 0.3549
Episode: 12681/30000 (42.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6437s / 318.4051 s
agent0:                 episode reward: -0.7004,                 loss: nan
agent1:                 episode reward: 0.7004,                 loss: 0.3424
Episode: 12701/30000 (42.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6618s / 319.0669 s
agent0:                 episode reward: -0.2916,                 loss: nan
agent1:                 episode reward: 0.2916,                 loss: 0.3380
Episode: 12721/30000 (42.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6485s / 319.7154 s
agent0:                 episode reward: -0.4920,                 loss: nan
agent1:                 episode reward: 0.4920,                 loss: 0.3426
Episode: 12741/30000 (42.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6580s / 320.3735 s
agent0:                 episode reward: -0.7328,                 loss: nan
agent1:                 episode reward: 0.7328,                 loss: 0.3368
Episode: 12761/30000 (42.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6509s / 321.0243 s
agent0:                 episode reward: -0.5353,                 loss: nan
agent1:                 episode reward: 0.5353,                 loss: 0.3393
Episode: 12781/30000 (42.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6525s / 321.6769 s
agent0:                 episode reward: -0.3087,                 loss: nan
agent1:                 episode reward: 0.3087,                 loss: 0.3381
Episode: 12801/30000 (42.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6590s / 322.3358 s
agent0:                 episode reward: -0.4347,                 loss: nan
agent1:                 episode reward: 0.4347,                 loss: 0.3380
Episode: 12821/30000 (42.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6490s / 322.9849 s
agent0:                 episode reward: -0.3832,                 loss: nan
agent1:                 episode reward: 0.3832,                 loss: 0.3399
Episode: 12841/30000 (42.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6497s / 323.6346 s
agent0:                 episode reward: -0.4888,                 loss: nan
agent1:                 episode reward: 0.4888,                 loss: 0.3433
Episode: 12861/30000 (42.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6483s / 324.2829 s
agent0:                 episode reward: -0.3897,                 loss: nan
agent1:                 episode reward: 0.3897,                 loss: 0.3402
Episode: 12881/30000 (42.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6595s / 324.9424 s
agent0:                 episode reward: -0.4546,                 loss: nan
agent1:                 episode reward: 0.4546,                 loss: 0.3370
Episode: 12901/30000 (43.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6571s / 325.5994 s
agent0:                 episode reward: -0.4581,                 loss: nan
agent1:                 episode reward: 0.4581,                 loss: 0.3384
Episode: 12921/30000 (43.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6472s / 326.2466 s
agent0:                 episode reward: -0.3549,                 loss: nan
agent1:                 episode reward: 0.3549,                 loss: 0.3356
Episode: 12941/30000 (43.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6579s / 326.9045 s
agent0:                 episode reward: -0.6728,                 loss: nan
agent1:                 episode reward: 0.6728,                 loss: 0.3411
Episode: 12961/30000 (43.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6415s / 327.5460 s
agent0:                 episode reward: -0.2511,                 loss: nan
agent1:                 episode reward: 0.2511,                 loss: 0.3401
Episode: 12981/30000 (43.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6596s / 328.2056 s
agent0:                 episode reward: -0.5557,                 loss: nan
agent1:                 episode reward: 0.5557,                 loss: 0.3368
Episode: 13001/30000 (43.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6538s / 328.8594 s
agent0:                 episode reward: -0.5745,                 loss: nan
agent1:                 episode reward: 0.5745,                 loss: 0.3401
Episode: 13021/30000 (43.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6485s / 329.5079 s
agent0:                 episode reward: -0.3418,                 loss: nan
agent1:                 episode reward: 0.3418,                 loss: 0.3574
Episode: 13041/30000 (43.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6498s / 330.1577 s
agent0:                 episode reward: -0.7638,                 loss: nan
agent1:                 episode reward: 0.7638,                 loss: 0.3554
Episode: 13061/30000 (43.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6553s / 330.8129 s
agent0:                 episode reward: -0.4009,                 loss: nan
agent1:                 episode reward: 0.4009,                 loss: 0.3585
Episode: 13081/30000 (43.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6453s / 331.4582 s
agent0:                 episode reward: -0.3472,                 loss: nan
agent1:                 episode reward: 0.3472,                 loss: 0.3569
Episode: 13101/30000 (43.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6513s / 332.1095 s
agent0:                 episode reward: -0.3039,                 loss: nan
agent1:                 episode reward: 0.3039,                 loss: 0.3570
Episode: 13121/30000 (43.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6476s / 332.7571 s
agent0:                 episode reward: -0.6566,                 loss: nan
agent1:                 episode reward: 0.6566,                 loss: 0.3586
Episode: 13141/30000 (43.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6553s / 333.4123 s
agent0:                 episode reward: -0.5181,                 loss: nan
agent1:                 episode reward: 0.5181,                 loss: 0.3583
Episode: 13161/30000 (43.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6589s / 334.0713 s
agent0:                 episode reward: -0.7096,                 loss: nan
agent1:                 episode reward: 0.7096,                 loss: 0.3585
Episode: 13181/30000 (43.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6523s / 334.7236 s
agent0:                 episode reward: -0.3846,                 loss: nan
agent1:                 episode reward: 0.3846,                 loss: 0.3592
Episode: 13201/30000 (44.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6590s / 335.3826 s
agent0:                 episode reward: -0.7801,                 loss: nan
agent1:                 episode reward: 0.7801,                 loss: 0.3601
Episode: 13221/30000 (44.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6644s / 336.0470 s
agent0:                 episode reward: -0.7214,                 loss: nan
agent1:                 episode reward: 0.7214,                 loss: 0.3593
Episode: 13241/30000 (44.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6584s / 336.7054 s
agent0:                 episode reward: -0.4505,                 loss: nan
agent1:                 episode reward: 0.4505,                 loss: 0.3589
Episode: 13261/30000 (44.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6568s / 337.3622 s
agent0:                 episode reward: -0.5257,                 loss: nan
agent1:                 episode reward: 0.5257,                 loss: 0.3558
Episode: 13281/30000 (44.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6595s / 338.0217 s
agent0:                 episode reward: -0.6027,                 loss: nan
agent1:                 episode reward: 0.6027,                 loss: 0.3584
Episode: 13301/30000 (44.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6583s / 338.6800 s
agent0:                 episode reward: -0.1507,                 loss: nan
agent1:                 episode reward: 0.1507,                 loss: 0.3589
Episode: 13321/30000 (44.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6648s / 339.3448 s
agent0:                 episode reward: -0.2311,                 loss: nan
agent1:                 episode reward: 0.2311,                 loss: 0.3582
Episode: 13341/30000 (44.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6619s / 340.0067 s
agent0:                 episode reward: -0.3727,                 loss: nan
agent1:                 episode reward: 0.3727,                 loss: 0.3563
Episode: 13361/30000 (44.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6679s / 340.6746 s
agent0:                 episode reward: -0.2626,                 loss: nan
agent1:                 episode reward: 0.2626,                 loss: 0.3484
Episode: 13381/30000 (44.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6581s / 341.3327 s
agent0:                 episode reward: -0.5823,                 loss: nan
agent1:                 episode reward: 0.5823,                 loss: 0.3506
Episode: 13401/30000 (44.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6599s / 341.9926 s
agent0:                 episode reward: -0.2778,                 loss: nan
agent1:                 episode reward: 0.2778,                 loss: 0.3461
Episode: 13421/30000 (44.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6648s / 342.6574 s
agent0:                 episode reward: -0.4824,                 loss: nan
agent1:                 episode reward: 0.4824,                 loss: 0.3485
Episode: 13441/30000 (44.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6651s / 343.3225 s
agent0:                 episode reward: -0.6803,                 loss: nan
agent1:                 episode reward: 0.6803,                 loss: 0.3517
Episode: 13461/30000 (44.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6661s / 343.9886 s
agent0:                 episode reward: -0.2210,                 loss: nan
agent1:                 episode reward: 0.2210,                 loss: 0.3512
Episode: 13481/30000 (44.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6624s / 344.6510 s
agent0:                 episode reward: -0.6827,                 loss: nan
agent1:                 episode reward: 0.6827,                 loss: 0.3507
Episode: 13501/30000 (45.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6682s / 345.3192 s
agent0:                 episode reward: -0.7913,                 loss: nan
agent1:                 episode reward: 0.7913,                 loss: 0.3504
Episode: 13521/30000 (45.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6660s / 345.9852 s
agent0:                 episode reward: -0.4208,                 loss: nan
agent1:                 episode reward: 0.4208,                 loss: 0.3492
Episode: 13541/30000 (45.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6701s / 346.6553 s
agent0:                 episode reward: -0.6718,                 loss: nan
agent1:                 episode reward: 0.6718,                 loss: 0.3510
Episode: 13561/30000 (45.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6767s / 347.3320 s
agent0:                 episode reward: -0.5661,                 loss: nan
agent1:                 episode reward: 0.5661,                 loss: 0.3483
Episode: 13581/30000 (45.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6632s / 347.9953 s
agent0:                 episode reward: -0.4410,                 loss: nan
agent1:                 episode reward: 0.4410,                 loss: 0.3499
Episode: 13601/30000 (45.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6656s / 348.6609 s
agent0:                 episode reward: -0.5590,                 loss: nan
agent1:                 episode reward: 0.5590,                 loss: 0.3514
Episode: 13621/30000 (45.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6598s / 349.3206 s
agent0:                 episode reward: -0.8617,                 loss: nan
agent1:                 episode reward: 0.8617,                 loss: 0.3466
Episode: 13641/30000 (45.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6610s / 349.9817 s
agent0:                 episode reward: -0.7980,                 loss: nan
agent1:                 episode reward: 0.7980,                 loss: 0.3490
Episode: 13661/30000 (45.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6643s / 350.6460 s
agent0:                 episode reward: -0.6367,                 loss: nan
agent1:                 episode reward: 0.6367,                 loss: 0.3515
Episode: 13681/30000 (45.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6570s / 351.3030 s
agent0:                 episode reward: -0.5180,                 loss: nan
agent1:                 episode reward: 0.5180,                 loss: 0.3509
Episode: 13701/30000 (45.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6589s / 351.9620 s
agent0:                 episode reward: -0.2942,                 loss: nan
agent1:                 episode reward: 0.2942,                 loss: 0.3542
Episode: 13721/30000 (45.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6566s / 352.6186 s
agent0:                 episode reward: -0.3244,                 loss: nan
agent1:                 episode reward: 0.3244,                 loss: 0.3554
Episode: 13741/30000 (45.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6657s / 353.2843 s
agent0:                 episode reward: -0.5146,                 loss: nan
agent1:                 episode reward: 0.5146,                 loss: 0.3538
Episode: 13761/30000 (45.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6706s / 353.9549 s
agent0:                 episode reward: -0.3928,                 loss: nan
agent1:                 episode reward: 0.3928,                 loss: 0.3520
Episode: 13781/30000 (45.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6679s / 354.6229 s
agent0:                 episode reward: -0.7691,                 loss: nan
agent1:                 episode reward: 0.7691,                 loss: 0.3508
Episode: 13801/30000 (46.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6634s / 355.2862 s
agent0:                 episode reward: -0.7538,                 loss: nan
agent1:                 episode reward: 0.7538,                 loss: 0.3554
Episode: 13821/30000 (46.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6701s / 355.9563 s
agent0:                 episode reward: -0.3774,                 loss: nan
agent1:                 episode reward: 0.3774,                 loss: 0.3561
Episode: 13841/30000 (46.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6663s / 356.6226 s
agent0:                 episode reward: -0.7059,                 loss: nan
agent1:                 episode reward: 0.7059,                 loss: 0.3556
Episode: 13861/30000 (46.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6754s / 357.2980 s
agent0:                 episode reward: -0.8333,                 loss: nan
agent1:                 episode reward: 0.8333,                 loss: 0.3551
Episode: 13881/30000 (46.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6782s / 357.9762 s
agent0:                 episode reward: -0.3838,                 loss: nan
agent1:                 episode reward: 0.3838,                 loss: 0.3542
Episode: 13901/30000 (46.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6664s / 358.6426 s
agent0:                 episode reward: -0.3648,                 loss: nan
agent1:                 episode reward: 0.3648,                 loss: 0.3555
Episode: 13921/30000 (46.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6759s / 359.3185 s
agent0:                 episode reward: -0.5500,                 loss: nan
agent1:                 episode reward: 0.5500,                 loss: 0.3536
Episode: 13941/30000 (46.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6799s / 359.9984 s
agent0:                 episode reward: -0.6873,                 loss: nan
agent1:                 episode reward: 0.6873,                 loss: 0.3562
Episode: 13961/30000 (46.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6710s / 360.6694 s
agent0:                 episode reward: -0.6281,                 loss: nan
agent1:                 episode reward: 0.6281,                 loss: 0.3546
Episode: 13981/30000 (46.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6678s / 361.3372 s
agent0:                 episode reward: -0.6640,                 loss: nan
agent1:                 episode reward: 0.6640,                 loss: 0.3552
Episode: 14001/30000 (46.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6725s / 362.0097 s
agent0:                 episode reward: -0.2979,                 loss: nan
agent1:                 episode reward: 0.2979,                 loss: 0.3519
Episode: 14021/30000 (46.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6794s / 362.6891 s
agent0:                 episode reward: -0.3726,                 loss: nan
agent1:                 episode reward: 0.3726,                 loss: 0.3489
Episode: 14041/30000 (46.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6674s / 363.3564 s
agent0:                 episode reward: -0.0160,                 loss: nan
agent1:                 episode reward: 0.0160,                 loss: 0.3463
Episode: 14061/30000 (46.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6639s / 364.0203 s
agent0:                 episode reward: -0.7080,                 loss: nan
agent1:                 episode reward: 0.7080,                 loss: 0.3481
Episode: 14081/30000 (46.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6597s / 364.6800 s
agent0:                 episode reward: -0.4009,                 loss: nan
agent1:                 episode reward: 0.4009,                 loss: 0.3512
Episode: 14101/30000 (47.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6690s / 365.3491 s
agent0:                 episode reward: -0.2116,                 loss: nan
agent1:                 episode reward: 0.2116,                 loss: 0.3499
Episode: 14121/30000 (47.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6744s / 366.0235 s
agent0:                 episode reward: -0.4938,                 loss: nan
agent1:                 episode reward: 0.4938,                 loss: 0.3445
Episode: 14141/30000 (47.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6667s / 366.6901 s
agent0:                 episode reward: -0.3250,                 loss: nan
agent1:                 episode reward: 0.3250,                 loss: 0.3493
Episode: 14161/30000 (47.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6681s / 367.3582 s
agent0:                 episode reward: -0.0960,                 loss: nan
agent1:                 episode reward: 0.0960,                 loss: 0.3479
Episode: 14181/30000 (47.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6676s / 368.0258 s
agent0:                 episode reward: -0.1941,                 loss: nan
agent1:                 episode reward: 0.1941,                 loss: 0.3477
Episode: 14201/30000 (47.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6820s / 368.7078 s
agent0:                 episode reward: -0.3960,                 loss: nan
agent1:                 episode reward: 0.3960,                 loss: 0.3513
Episode: 14221/30000 (47.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6750s / 369.3828 s
agent0:                 episode reward: -0.3190,                 loss: nan
agent1:                 episode reward: 0.3190,                 loss: 0.3478
Episode: 14241/30000 (47.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6675s / 370.0503 s
agent0:                 episode reward: -0.4946,                 loss: nan
agent1:                 episode reward: 0.4946,                 loss: 0.3470
Episode: 14261/30000 (47.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6710s / 370.7213 s
agent0:                 episode reward: -0.3764,                 loss: nan
agent1:                 episode reward: 0.3764,                 loss: 0.3506
Episode: 14281/30000 (47.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6721s / 371.3934 s
agent0:                 episode reward: -0.7269,                 loss: nan
agent1:                 episode reward: 0.7269,                 loss: 0.3457
Episode: 14301/30000 (47.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6741s / 372.0675 s
agent0:                 episode reward: -0.4520,                 loss: nan
agent1:                 episode reward: 0.4520,                 loss: 0.3482
Episode: 14321/30000 (47.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6712s / 372.7386 s
agent0:                 episode reward: -0.9667,                 loss: nan
agent1:                 episode reward: 0.9667,                 loss: 0.3478
Episode: 14341/30000 (47.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6704s / 373.4091 s
agent0:                 episode reward: -0.3957,                 loss: nan
agent1:                 episode reward: 0.3957,                 loss: 0.3553
Episode: 14361/30000 (47.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6719s / 374.0810 s
agent0:                 episode reward: -0.3707,                 loss: nan
agent1:                 episode reward: 0.3707,                 loss: 0.3640
Episode: 14381/30000 (47.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6703s / 374.7513 s
agent0:                 episode reward: -0.5733,                 loss: nan
agent1:                 episode reward: 0.5733,                 loss: 0.3655
Episode: 14401/30000 (48.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6652s / 375.4165 s
agent0:                 episode reward: -0.4924,                 loss: nan
agent1:                 episode reward: 0.4924,                 loss: 0.3688
Episode: 14421/30000 (48.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6679s / 376.0844 s
agent0:                 episode reward: -0.7694,                 loss: nan
agent1:                 episode reward: 0.7694,                 loss: 0.3671
Episode: 14441/30000 (48.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6817s / 376.7661 s
agent0:                 episode reward: -0.3510,                 loss: nan
agent1:                 episode reward: 0.3510,                 loss: 0.3675
Episode: 14461/30000 (48.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6781s / 377.4442 s
agent0:                 episode reward: -0.6435,                 loss: nan
agent1:                 episode reward: 0.6435,                 loss: 0.3616
Episode: 14481/30000 (48.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6982s / 378.1424 s
agent0:                 episode reward: -0.4767,                 loss: nan
agent1:                 episode reward: 0.4767,                 loss: 0.3648
Episode: 14501/30000 (48.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6857s / 378.8281 s
agent0:                 episode reward: -0.3412,                 loss: nan
agent1:                 episode reward: 0.3412,                 loss: 0.3650
Episode: 14521/30000 (48.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6760s / 379.5041 s
agent0:                 episode reward: -0.4630,                 loss: nan
agent1:                 episode reward: 0.4630,                 loss: 0.3662
Episode: 14541/30000 (48.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6718s / 380.1758 s
agent0:                 episode reward: -0.8455,                 loss: nan
agent1:                 episode reward: 0.8455,                 loss: 0.3628
Episode: 14561/30000 (48.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6739s / 380.8497 s
agent0:                 episode reward: -0.3760,                 loss: nan
agent1:                 episode reward: 0.3760,                 loss: 0.3664
Episode: 14581/30000 (48.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6739s / 381.5236 s
agent0:                 episode reward: -0.4679,                 loss: nan
agent1:                 episode reward: 0.4679,                 loss: 0.3650
Episode: 14601/30000 (48.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6682s / 382.1919 s
agent0:                 episode reward: -0.2884,                 loss: nan
agent1:                 episode reward: 0.2884,                 loss: 0.3660
Episode: 14621/30000 (48.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6708s / 382.8627 s
agent0:                 episode reward: -0.7459,                 loss: nan
agent1:                 episode reward: 0.7459,                 loss: 0.3652
Episode: 14641/30000 (48.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6826s / 383.5453 s
agent0:                 episode reward: -0.2388,                 loss: nan
agent1:                 episode reward: 0.2388,                 loss: 0.3635
Episode: 14661/30000 (48.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6685s / 384.2138 s
agent0:                 episode reward: -0.6173,                 loss: nan
agent1:                 episode reward: 0.6173,                 loss: 0.3673
Episode: 14681/30000 (48.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6783s / 384.8920 s
agent0:                 episode reward: -0.2581,                 loss: nan
agent1:                 episode reward: 0.2581,                 loss: 0.3541
Episode: 14701/30000 (49.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6732s / 385.5652 s
agent0:                 episode reward: -0.3651,                 loss: nan
agent1:                 episode reward: 0.3651,                 loss: 0.3523
Episode: 14721/30000 (49.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6758s / 386.2410 s
agent0:                 episode reward: -0.3529,                 loss: nan
agent1:                 episode reward: 0.3529,                 loss: 0.3519
Episode: 14741/30000 (49.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6728s / 386.9137 s
agent0:                 episode reward: -0.3179,                 loss: nan
agent1:                 episode reward: 0.3179,                 loss: 0.3525
Episode: 14761/30000 (49.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6766s / 387.5903 s
agent0:                 episode reward: -0.4304,                 loss: nan
agent1:                 episode reward: 0.4304,                 loss: 0.3529
Episode: 14781/30000 (49.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6712s / 388.2616 s
agent0:                 episode reward: -0.5257,                 loss: nan
agent1:                 episode reward: 0.5257,                 loss: 0.3527
Episode: 14801/30000 (49.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6763s / 388.9379 s
agent0:                 episode reward: -0.7084,                 loss: nan
agent1:                 episode reward: 0.7084,                 loss: 0.3511
Episode: 14821/30000 (49.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6673s / 389.6052 s
agent0:                 episode reward: -0.3994,                 loss: nan
agent1:                 episode reward: 0.3994,                 loss: 0.3516
Episode: 14841/30000 (49.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6834s / 390.2886 s
agent0:                 episode reward: -0.1667,                 loss: nan
agent1:                 episode reward: 0.1667,                 loss: 0.3529
Episode: 14861/30000 (49.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6784s / 390.9670 s
agent0:                 episode reward: -0.8039,                 loss: nan
agent1:                 episode reward: 0.8039,                 loss: 0.3529
Episode: 14881/30000 (49.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6810s / 391.6480 s
agent0:                 episode reward: -0.6042,                 loss: nan
agent1:                 episode reward: 0.6042,                 loss: 0.3502
Episode: 14901/30000 (49.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6677s / 392.3157 s
agent0:                 episode reward: -0.3979,                 loss: nan
agent1:                 episode reward: 0.3979,                 loss: 0.3547
Episode: 14921/30000 (49.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6762s / 392.9919 s
agent0:                 episode reward: -0.1545,                 loss: nan
agent1:                 episode reward: 0.1545,                 loss: 0.3534
Episode: 14941/30000 (49.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6578s / 393.6498 s
agent0:                 episode reward: -0.7643,                 loss: nan
agent1:                 episode reward: 0.7643,                 loss: 0.3562
Episode: 14961/30000 (49.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6670s / 394.3168 s
agent0:                 episode reward: -0.1527,                 loss: nan
agent1:                 episode reward: 0.1527,                 loss: 0.3522
Episode: 14981/30000 (49.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6768s / 394.9935 s
agent0:                 episode reward: -0.6055,                 loss: nan
agent1:                 episode reward: 0.6055,                 loss: 0.3549
Episode: 15001/30000 (50.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6739s / 395.6675 s
agent0:                 episode reward: -0.5639,                 loss: nan
agent1:                 episode reward: 0.5639,                 loss: 0.3549
Episode: 15021/30000 (50.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6749s / 396.3424 s
agent0:                 episode reward: -0.5838,                 loss: nan
agent1:                 episode reward: 0.5838,                 loss: 0.3539
Episode: 15041/30000 (50.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6883s / 397.0307 s
agent0:                 episode reward: -0.3967,                 loss: nan
agent1:                 episode reward: 0.3967,                 loss: 0.3507
Episode: 15061/30000 (50.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6973s / 397.7281 s
agent0:                 episode reward: -0.9869,                 loss: nan
agent1:                 episode reward: 0.9869,                 loss: 0.3532
Episode: 15081/30000 (50.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6782s / 398.4062 s
agent0:                 episode reward: -0.5968,                 loss: nan
agent1:                 episode reward: 0.5968,                 loss: 0.3486
Episode: 15101/30000 (50.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6854s / 399.0916 s
agent0:                 episode reward: -0.2986,                 loss: nan
agent1:                 episode reward: 0.2986,                 loss: 0.3509
Episode: 15121/30000 (50.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6943s / 399.7859 s
agent0:                 episode reward: -0.5516,                 loss: nan
agent1:                 episode reward: 0.5516,                 loss: 0.3525
Episode: 15141/30000 (50.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6783s / 400.4643 s
agent0:                 episode reward: -0.6176,                 loss: nan
agent1:                 episode reward: 0.6176,                 loss: 0.3524
Episode: 15161/30000 (50.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6858s / 401.1500 s
agent0:                 episode reward: -0.7414,                 loss: nan
agent1:                 episode reward: 0.7414,                 loss: 0.3528
Episode: 15181/30000 (50.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6980s / 401.8480 s
agent0:                 episode reward: -0.7126,                 loss: nan
agent1:                 episode reward: 0.7126,                 loss: 0.3520
Episode: 15201/30000 (50.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6908s / 402.5388 s
agent0:                 episode reward: -0.7153,                 loss: nan
agent1:                 episode reward: 0.7153,                 loss: 0.3509
Episode: 15221/30000 (50.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6772s / 403.2160 s
agent0:                 episode reward: -0.5238,                 loss: nan
agent1:                 episode reward: 0.5238,                 loss: 0.3550
Episode: 15241/30000 (50.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6789s / 403.8949 s
agent0:                 episode reward: -0.3848,                 loss: nan
agent1:                 episode reward: 0.3848,                 loss: 0.3537
Episode: 15261/30000 (50.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6831s / 404.5780 s
agent0:                 episode reward: -0.1823,                 loss: nan
agent1:                 episode reward: 0.1823,                 loss: 0.3520
Episode: 15281/30000 (50.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6817s / 405.2596 s
agent0:                 episode reward: -0.4830,                 loss: nan
agent1:                 episode reward: 0.4830,                 loss: 0.3522
Episode: 15301/30000 (51.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6917s / 405.9514 s
agent0:                 episode reward: -0.4499,                 loss: nan
agent1:                 episode reward: 0.4499,                 loss: 0.3543
Episode: 15321/30000 (51.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6773s / 406.6287 s
agent0:                 episode reward: -0.3558,                 loss: nan
agent1:                 episode reward: 0.3558,                 loss: 0.3526
Episode: 15341/30000 (51.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6802s / 407.3088 s
agent0:                 episode reward: -0.3932,                 loss: nan
agent1:                 episode reward: 0.3932,                 loss: 0.3529
Episode: 15361/30000 (51.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6800s / 407.9888 s
agent0:                 episode reward: -0.5258,                 loss: nan
agent1:                 episode reward: 0.5258,                 loss: 0.3562
Episode: 15381/30000 (51.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6824s / 408.6712 s
agent0:                 episode reward: -0.5360,                 loss: nan
agent1:                 episode reward: 0.5360,                 loss: 0.3497
Episode: 15401/30000 (51.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6784s / 409.3495 s
agent0:                 episode reward: -0.4060,                 loss: nan
agent1:                 episode reward: 0.4060,                 loss: 0.3518
Episode: 15421/30000 (51.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6775s / 410.0270 s
agent0:                 episode reward: -0.2228,                 loss: nan
agent1:                 episode reward: 0.2228,                 loss: 0.3517
Episode: 15441/30000 (51.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6924s / 410.7194 s
agent0:                 episode reward: -0.5959,                 loss: nan
agent1:                 episode reward: 0.5959,                 loss: 0.3553
Episode: 15461/30000 (51.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6850s / 411.4044 s
agent0:                 episode reward: -0.1420,                 loss: nan
agent1:                 episode reward: 0.1420,                 loss: 0.3555
Episode: 15481/30000 (51.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6827s / 412.0871 s
agent0:                 episode reward: -0.8528,                 loss: nan
agent1:                 episode reward: 0.8528,                 loss: 0.3572
Episode: 15501/30000 (51.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6816s / 412.7687 s
agent0:                 episode reward: -0.5158,                 loss: nan
agent1:                 episode reward: 0.5158,                 loss: 0.3552
Episode: 15521/30000 (51.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6724s / 413.4410 s
agent0:                 episode reward: -0.5718,                 loss: nan
agent1:                 episode reward: 0.5718,                 loss: 0.3540
Episode: 15541/30000 (51.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6871s / 414.1282 s
agent0:                 episode reward: -0.8637,                 loss: nan
agent1:                 episode reward: 0.8637,                 loss: 0.3506
Episode: 15561/30000 (51.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6846s / 414.8128 s
agent0:                 episode reward: -0.0952,                 loss: nan
agent1:                 episode reward: 0.0952,                 loss: 0.3524
Episode: 15581/30000 (51.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6815s / 415.4943 s
agent0:                 episode reward: -0.3117,                 loss: nan
agent1:                 episode reward: 0.3117,                 loss: 0.3502
Episode: 15601/30000 (52.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6780s / 416.1723 s
agent0:                 episode reward: -0.5988,                 loss: nan
agent1:                 episode reward: 0.5988,                 loss: 0.3543
Episode: 15621/30000 (52.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6910s / 416.8633 s
agent0:                 episode reward: -0.2161,                 loss: nan
agent1:                 episode reward: 0.2161,                 loss: 0.3559
Episode: 15641/30000 (52.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6858s / 417.5492 s
agent0:                 episode reward: -0.6375,                 loss: nan
agent1:                 episode reward: 0.6375,                 loss: 0.3519
Episode: 15661/30000 (52.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6696s / 418.2188 s
agent0:                 episode reward: -0.4711,                 loss: nan
agent1:                 episode reward: 0.4711,                 loss: 0.3552
Episode: 15681/30000 (52.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6788s / 418.8976 s
agent0:                 episode reward: -0.6196,                 loss: nan
agent1:                 episode reward: 0.6196,                 loss: 0.3619
Episode: 15701/30000 (52.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6810s / 419.5786 s
agent0:                 episode reward: -0.3758,                 loss: nan
agent1:                 episode reward: 0.3758,                 loss: 0.3620
Episode: 15721/30000 (52.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6974s / 420.2760 s
agent0:                 episode reward: -0.4097,                 loss: nan
agent1:                 episode reward: 0.4097,                 loss: 0.3615
Episode: 15741/30000 (52.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7029s / 420.9789 s
agent0:                 episode reward: -0.3681,                 loss: nan
agent1:                 episode reward: 0.3681,                 loss: 0.3612
Episode: 15761/30000 (52.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6830s / 421.6619 s
agent0:                 episode reward: -0.4865,                 loss: nan
agent1:                 episode reward: 0.4865,                 loss: 0.3623
Episode: 15781/30000 (52.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7046s / 422.3665 s
agent0:                 episode reward: -0.5836,                 loss: nan
agent1:                 episode reward: 0.5836,                 loss: 0.3658
Episode: 15801/30000 (52.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6918s / 423.0583 s
agent0:                 episode reward: -0.2161,                 loss: nan
agent1:                 episode reward: 0.2161,                 loss: 0.3638
Episode: 15821/30000 (52.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6905s / 423.7488 s
agent0:                 episode reward: -0.3826,                 loss: nan
agent1:                 episode reward: 0.3826,                 loss: 0.3620
Episode: 15841/30000 (52.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6873s / 424.4361 s
agent0:                 episode reward: -0.0775,                 loss: nan
agent1:                 episode reward: 0.0775,                 loss: 0.3615
Episode: 15861/30000 (52.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6946s / 425.1307 s
agent0:                 episode reward: -0.6583,                 loss: nan
agent1:                 episode reward: 0.6583,                 loss: 0.3635
Episode: 15881/30000 (52.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6928s / 425.8235 s
agent0:                 episode reward: -0.2402,                 loss: nan
agent1:                 episode reward: 0.2402,                 loss: 0.3606
Episode: 15901/30000 (53.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6862s / 426.5097 s
agent0:                 episode reward: -0.4144,                 loss: nan
agent1:                 episode reward: 0.4144,                 loss: 0.3619
Episode: 15921/30000 (53.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6879s / 427.1976 s
agent0:                 episode reward: -0.7759,                 loss: nan
agent1:                 episode reward: 0.7759,                 loss: 0.3587
Episode: 15941/30000 (53.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6862s / 427.8838 s
agent0:                 episode reward: -0.5560,                 loss: nan
agent1:                 episode reward: 0.5560,                 loss: 0.3623
Episode: 15961/30000 (53.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6848s / 428.5686 s
agent0:                 episode reward: -0.8004,                 loss: nan
agent1:                 episode reward: 0.8004,                 loss: 0.3629
Episode: 15981/30000 (53.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6896s / 429.2581 s
agent0:                 episode reward: -0.5452,                 loss: nan
agent1:                 episode reward: 0.5452,                 loss: 0.3588
Episode: 16001/30000 (53.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6905s / 429.9486 s
agent0:                 episode reward: -0.3977,                 loss: nan
agent1:                 episode reward: 0.3977,                 loss: 0.3616
Episode: 16021/30000 (53.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6962s / 430.6448 s
agent0:                 episode reward: -0.4673,                 loss: nan
agent1:                 episode reward: 0.4673,                 loss: 0.3390
Episode: 16041/30000 (53.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6941s / 431.3389 s
agent0:                 episode reward: -0.7356,                 loss: nan
agent1:                 episode reward: 0.7356,                 loss: 0.3418
Episode: 16061/30000 (53.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6917s / 432.0306 s
agent0:                 episode reward: -0.6098,                 loss: nan
agent1:                 episode reward: 0.6098,                 loss: 0.3427
Episode: 16081/30000 (53.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7024s / 432.7330 s
agent0:                 episode reward: -0.4559,                 loss: nan
agent1:                 episode reward: 0.4559,                 loss: 0.3379
Episode: 16101/30000 (53.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7082s / 433.4412 s
agent0:                 episode reward: -0.2482,                 loss: nan
agent1:                 episode reward: 0.2482,                 loss: 0.3377
Episode: 16121/30000 (53.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7140s / 434.1553 s
agent0:                 episode reward: -0.7080,                 loss: nan
agent1:                 episode reward: 0.7080,                 loss: 0.3391
Episode: 16141/30000 (53.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6978s / 434.8531 s
agent0:                 episode reward: -0.5869,                 loss: nan
agent1:                 episode reward: 0.5869,                 loss: 0.3400
Episode: 16161/30000 (53.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6900s / 435.5430 s
agent0:                 episode reward: -0.4767,                 loss: nan
agent1:                 episode reward: 0.4767,                 loss: 0.3361
Episode: 16181/30000 (53.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6917s / 436.2347 s
agent0:                 episode reward: -0.7462,                 loss: nan
agent1:                 episode reward: 0.7462,                 loss: 0.3373
Episode: 16201/30000 (54.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6925s / 436.9273 s
agent0:                 episode reward: -0.5027,                 loss: nan
agent1:                 episode reward: 0.5027,                 loss: 0.3368
Episode: 16221/30000 (54.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7014s / 437.6286 s
agent0:                 episode reward: -0.4761,                 loss: nan
agent1:                 episode reward: 0.4761,                 loss: 0.3399
Episode: 16241/30000 (54.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6928s / 438.3214 s
agent0:                 episode reward: -0.6865,                 loss: nan
agent1:                 episode reward: 0.6865,                 loss: 0.3416
Episode: 16261/30000 (54.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6969s / 439.0183 s
agent0:                 episode reward: -0.6664,                 loss: nan
agent1:                 episode reward: 0.6664,                 loss: 0.3409
Episode: 16281/30000 (54.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6965s / 439.7149 s
agent0:                 episode reward: -0.5609,                 loss: nan
agent1:                 episode reward: 0.5609,                 loss: 0.3380
Episode: 16301/30000 (54.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6908s / 440.4057 s
agent0:                 episode reward: -0.3277,                 loss: nan
agent1:                 episode reward: 0.3277,                 loss: 0.3412
Episode: 16321/30000 (54.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6909s / 441.0965 s
agent0:                 episode reward: -0.4796,                 loss: nan
agent1:                 episode reward: 0.4796,                 loss: 0.3397
Episode: 16341/30000 (54.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7147s / 441.8113 s
agent0:                 episode reward: -0.4405,                 loss: nan
agent1:                 episode reward: 0.4405,                 loss: 0.3518
Episode: 16361/30000 (54.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7169s / 442.5282 s
agent0:                 episode reward: -0.5601,                 loss: nan
agent1:                 episode reward: 0.5601,                 loss: 0.3666
Episode: 16381/30000 (54.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7009s / 443.2291 s
agent0:                 episode reward: -0.3237,                 loss: nan
agent1:                 episode reward: 0.3237,                 loss: 0.3672
Episode: 16401/30000 (54.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6985s / 443.9276 s
agent0:                 episode reward: -0.3274,                 loss: nan
agent1:                 episode reward: 0.3274,                 loss: 0.3674
Episode: 16421/30000 (54.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6981s / 444.6258 s
agent0:                 episode reward: -0.4525,                 loss: nan
agent1:                 episode reward: 0.4525,                 loss: 0.3724
Episode: 16441/30000 (54.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6935s / 445.3192 s
agent0:                 episode reward: -0.7501,                 loss: nan
agent1:                 episode reward: 0.7501,                 loss: 0.3673
Episode: 16461/30000 (54.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6919s / 446.0111 s
agent0:                 episode reward: -0.5525,                 loss: nan
agent1:                 episode reward: 0.5525,                 loss: 0.3694
Episode: 16481/30000 (54.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6989s / 446.7101 s
agent0:                 episode reward: -0.6491,                 loss: nan
agent1:                 episode reward: 0.6491,                 loss: 0.3685
Episode: 16501/30000 (55.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6993s / 447.4094 s
agent0:                 episode reward: -0.7935,                 loss: nan
agent1:                 episode reward: 0.7935,                 loss: 0.3681
Episode: 16521/30000 (55.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7128s / 448.1221 s
agent0:                 episode reward: -0.3586,                 loss: nan
agent1:                 episode reward: 0.3586,                 loss: 0.3680
Episode: 16541/30000 (55.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6966s / 448.8187 s
agent0:                 episode reward: -0.5917,                 loss: nan
agent1:                 episode reward: 0.5917,                 loss: 0.3670
Episode: 16561/30000 (55.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6890s / 449.5077 s
agent0:                 episode reward: -0.4828,                 loss: nan
agent1:                 episode reward: 0.4828,                 loss: 0.3671
Episode: 16581/30000 (55.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7113s / 450.2190 s
agent0:                 episode reward: -0.4976,                 loss: nan
agent1:                 episode reward: 0.4976,                 loss: 0.3677
Episode: 16601/30000 (55.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6962s / 450.9152 s
agent0:                 episode reward: -0.5318,                 loss: nan
agent1:                 episode reward: 0.5318,                 loss: 0.3685
Episode: 16621/30000 (55.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6941s / 451.6092 s
agent0:                 episode reward: -0.4993,                 loss: nan
agent1:                 episode reward: 0.4993,                 loss: 0.3702
Episode: 16641/30000 (55.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6996s / 452.3089 s
agent0:                 episode reward: -0.5563,                 loss: nan
agent1:                 episode reward: 0.5563,                 loss: 0.3680
Episode: 16661/30000 (55.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6946s / 453.0035 s
agent0:                 episode reward: -0.1337,                 loss: nan
agent1:                 episode reward: 0.1337,                 loss: 0.3694
Episode: 16681/30000 (55.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6926s / 453.6961 s
agent0:                 episode reward: -0.6391,                 loss: nan
agent1:                 episode reward: 0.6391,                 loss: 0.3560
Episode: 16701/30000 (55.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7055s / 454.4016 s
agent0:                 episode reward: -0.7219,                 loss: nan
agent1:                 episode reward: 0.7219,                 loss: 0.3521
Episode: 16721/30000 (55.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7023s / 455.1039 s
agent0:                 episode reward: -0.5828,                 loss: nan
agent1:                 episode reward: 0.5828,                 loss: 0.3533
Episode: 16741/30000 (55.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6962s / 455.8001 s
agent0:                 episode reward: -0.7424,                 loss: nan
agent1:                 episode reward: 0.7424,                 loss: 0.3533
Episode: 16761/30000 (55.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7045s / 456.5046 s
agent0:                 episode reward: -0.4917,                 loss: nan
agent1:                 episode reward: 0.4917,                 loss: 0.3543
Episode: 16781/30000 (55.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7070s / 457.2115 s
agent0:                 episode reward: -0.4582,                 loss: nan
agent1:                 episode reward: 0.4582,                 loss: 0.3486
Episode: 16801/30000 (56.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7034s / 457.9150 s
agent0:                 episode reward: -0.2084,                 loss: nan
agent1:                 episode reward: 0.2084,                 loss: 0.3501
Episode: 16821/30000 (56.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7067s / 458.6217 s
agent0:                 episode reward: -0.5286,                 loss: nan
agent1:                 episode reward: 0.5286,                 loss: 0.3529
Episode: 16841/30000 (56.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7126s / 459.3342 s
agent0:                 episode reward: -0.4979,                 loss: nan
agent1:                 episode reward: 0.4979,                 loss: 0.3532
Episode: 16861/30000 (56.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7141s / 460.0483 s
agent0:                 episode reward: -0.6533,                 loss: nan
agent1:                 episode reward: 0.6533,                 loss: 0.3547
Episode: 16881/30000 (56.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6980s / 460.7464 s
agent0:                 episode reward: -0.3985,                 loss: nan
agent1:                 episode reward: 0.3985,                 loss: 0.3549
Episode: 16901/30000 (56.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7063s / 461.4527 s
agent0:                 episode reward: -0.5898,                 loss: nan
agent1:                 episode reward: 0.5898,                 loss: 0.3537
Episode: 16921/30000 (56.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7047s / 462.1574 s
agent0:                 episode reward: -0.2657,                 loss: nan
agent1:                 episode reward: 0.2657,                 loss: 0.3543
Episode: 16941/30000 (56.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7106s / 462.8680 s
agent0:                 episode reward: -0.5143,                 loss: nan
agent1:                 episode reward: 0.5143,                 loss: 0.3504
Episode: 16961/30000 (56.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7117s / 463.5796 s
agent0:                 episode reward: -0.3638,                 loss: nan
agent1:                 episode reward: 0.3638,                 loss: 0.3479
Episode: 16981/30000 (56.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7124s / 464.2920 s
agent0:                 episode reward: -0.4965,                 loss: nan
agent1:                 episode reward: 0.4965,                 loss: 0.3563
Episode: 17001/30000 (56.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7066s / 464.9987 s
agent0:                 episode reward: -0.1774,                 loss: nan
agent1:                 episode reward: 0.1774,                 loss: 0.3536
Episode: 17021/30000 (56.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7170s / 465.7157 s
agent0:                 episode reward: -0.6321,                 loss: nan
agent1:                 episode reward: 0.6321,                 loss: 0.3508
Episode: 17041/30000 (56.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7141s / 466.4298 s
agent0:                 episode reward: -0.5388,                 loss: nan
agent1:                 episode reward: 0.5388,                 loss: 0.3533
Episode: 17061/30000 (56.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7116s / 467.1413 s
agent0:                 episode reward: -0.4450,                 loss: nan
agent1:                 episode reward: 0.4450,                 loss: 0.3556
Episode: 17081/30000 (56.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7088s / 467.8501 s
agent0:                 episode reward: -0.3160,                 loss: nan
agent1:                 episode reward: 0.3160,                 loss: 0.3509
Episode: 17101/30000 (57.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7171s / 468.5672 s
agent0:                 episode reward: -0.6664,                 loss: nan
agent1:                 episode reward: 0.6664,                 loss: 0.3557
Episode: 17121/30000 (57.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7077s / 469.2749 s
agent0:                 episode reward: -0.0222,                 loss: nan
agent1:                 episode reward: 0.0222,                 loss: 0.3552
Episode: 17141/30000 (57.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7050s / 469.9798 s
agent0:                 episode reward: -0.7377,                 loss: nan
agent1:                 episode reward: 0.7377,                 loss: 0.3524
Episode: 17161/30000 (57.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7119s / 470.6917 s
agent0:                 episode reward: -0.3759,                 loss: nan
agent1:                 episode reward: 0.3759,                 loss: 0.3505
Episode: 17181/30000 (57.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6992s / 471.3909 s
agent0:                 episode reward: -0.5975,                 loss: nan
agent1:                 episode reward: 0.5975,                 loss: 0.3513
Episode: 17201/30000 (57.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7081s / 472.0990 s
agent0:                 episode reward: -0.7637,                 loss: nan
agent1:                 episode reward: 0.7637,                 loss: 0.3515
Episode: 17221/30000 (57.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7172s / 472.8162 s
agent0:                 episode reward: -0.5146,                 loss: nan
agent1:                 episode reward: 0.5146,                 loss: 0.3538
Episode: 17241/30000 (57.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7146s / 473.5309 s
agent0:                 episode reward: -0.6077,                 loss: nan
agent1:                 episode reward: 0.6077,                 loss: 0.3521
Episode: 17261/30000 (57.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7132s / 474.2441 s
agent0:                 episode reward: -0.5904,                 loss: nan
agent1:                 episode reward: 0.5904,                 loss: 0.3526
Episode: 17281/30000 (57.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7021s / 474.9461 s
agent0:                 episode reward: -0.9595,                 loss: nan
agent1:                 episode reward: 0.9595,                 loss: 0.3540
Episode: 17301/30000 (57.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7065s / 475.6526 s
agent0:                 episode reward: -0.5754,                 loss: nan
agent1:                 episode reward: 0.5754,                 loss: 0.3515
Episode: 17321/30000 (57.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7051s / 476.3577 s
agent0:                 episode reward: -0.4381,                 loss: nan
agent1:                 episode reward: 0.4381,                 loss: 0.3536
Episode: 17341/30000 (57.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7038s / 477.0615 s
agent0:                 episode reward: -0.8287,                 loss: nan
agent1:                 episode reward: 0.8287,                 loss: 0.3563
Episode: 17361/30000 (57.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7024s / 477.7639 s
agent0:                 episode reward: -0.6975,                 loss: nan
agent1:                 episode reward: 0.6975,                 loss: 0.3645
Episode: 17381/30000 (57.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7066s / 478.4705 s
agent0:                 episode reward: -0.7416,                 loss: nan
agent1:                 episode reward: 0.7416,                 loss: 0.3594
Episode: 17401/30000 (58.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7115s / 479.1820 s
agent0:                 episode reward: -0.4395,                 loss: nan
agent1:                 episode reward: 0.4395,                 loss: 0.3595
Episode: 17421/30000 (58.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7074s / 479.8894 s
agent0:                 episode reward: -0.5013,                 loss: nan
agent1:                 episode reward: 0.5013,                 loss: 0.3629
Episode: 17441/30000 (58.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7067s / 480.5961 s
agent0:                 episode reward: -0.3633,                 loss: nan
agent1:                 episode reward: 0.3633,                 loss: 0.3603
Episode: 17461/30000 (58.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7098s / 481.3059 s
agent0:                 episode reward: -0.5139,                 loss: nan
agent1:                 episode reward: 0.5139,                 loss: 0.3624
Episode: 17481/30000 (58.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6984s / 482.0043 s
agent0:                 episode reward: -0.6179,                 loss: nan
agent1:                 episode reward: 0.6179,                 loss: 0.3571
Episode: 17501/30000 (58.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7146s / 482.7189 s
agent0:                 episode reward: -0.6155,                 loss: nan
agent1:                 episode reward: 0.6155,                 loss: 0.3639
Episode: 17521/30000 (58.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7020s / 483.4209 s
agent0:                 episode reward: -0.8315,                 loss: nan
agent1:                 episode reward: 0.8315,                 loss: 0.3606
Episode: 17541/30000 (58.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7093s / 484.1303 s
agent0:                 episode reward: -0.8107,                 loss: nan
agent1:                 episode reward: 0.8107,                 loss: 0.3628
Episode: 17561/30000 (58.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7024s / 484.8327 s
agent0:                 episode reward: -0.3390,                 loss: nan
agent1:                 episode reward: 0.3390,                 loss: 0.3621
Episode: 17581/30000 (58.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7057s / 485.5384 s
agent0:                 episode reward: -0.6933,                 loss: nan
agent1:                 episode reward: 0.6933,                 loss: 0.3602
Episode: 17601/30000 (58.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7147s / 486.2531 s
agent0:                 episode reward: -0.0859,                 loss: nan
agent1:                 episode reward: 0.0859,                 loss: 0.3617
Episode: 17621/30000 (58.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7090s / 486.9621 s
agent0:                 episode reward: -0.5272,                 loss: nan
agent1:                 episode reward: 0.5272,                 loss: 0.3591
Episode: 17641/30000 (58.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7134s / 487.6755 s
agent0:                 episode reward: -0.5792,                 loss: nan
agent1:                 episode reward: 0.5792,                 loss: 0.3618
Episode: 17661/30000 (58.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7126s / 488.3882 s
agent0:                 episode reward: -0.4861,                 loss: nan
agent1:                 episode reward: 0.4861,                 loss: 0.3598
Episode: 17681/30000 (58.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7048s / 489.0930 s
agent0:                 episode reward: -0.4953,                 loss: nan
agent1:                 episode reward: 0.4953,                 loss: 0.3615
Episode: 17701/30000 (59.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7151s / 489.8081 s
agent0:                 episode reward: -0.3802,                 loss: nan
agent1:                 episode reward: 0.3802,                 loss: 0.3594
Episode: 17721/30000 (59.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7117s / 490.5198 s
agent0:                 episode reward: -0.1800,                 loss: nan
agent1:                 episode reward: 0.1800,                 loss: 0.3589
Episode: 17741/30000 (59.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7066s / 491.2264 s
agent0:                 episode reward: -0.0506,                 loss: nan
agent1:                 episode reward: 0.0506,                 loss: 0.3645
Episode: 17761/30000 (59.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7046s / 491.9310 s
agent0:                 episode reward: -0.5044,                 loss: nan
agent1:                 episode reward: 0.5044,                 loss: 0.3600
Episode: 17781/30000 (59.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7107s / 492.6418 s
agent0:                 episode reward: -0.7803,                 loss: nan
agent1:                 episode reward: 0.7803,                 loss: 0.3604
Episode: 17801/30000 (59.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7167s / 493.3585 s
agent0:                 episode reward: -0.2250,                 loss: nan
agent1:                 episode reward: 0.2250,                 loss: 0.3602
Episode: 17821/30000 (59.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7053s / 494.0638 s
agent0:                 episode reward: -0.1907,                 loss: nan
agent1:                 episode reward: 0.1907,                 loss: 0.3612
Episode: 17841/30000 (59.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7204s / 494.7842 s
agent0:                 episode reward: -0.3088,                 loss: nan
agent1:                 episode reward: 0.3088,                 loss: 0.3634
Episode: 17861/30000 (59.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7052s / 495.4894 s
agent0:                 episode reward: -0.4027,                 loss: nan
agent1:                 episode reward: 0.4027,                 loss: 0.3642
Episode: 17881/30000 (59.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7202s / 496.2095 s
agent0:                 episode reward: -0.1269,                 loss: nan
agent1:                 episode reward: 0.1269,                 loss: 0.3597
Episode: 17901/30000 (59.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7173s / 496.9268 s
agent0:                 episode reward: -0.5332,                 loss: nan
agent1:                 episode reward: 0.5332,                 loss: 0.3611
Episode: 17921/30000 (59.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7104s / 497.6372 s
agent0:                 episode reward: -0.7540,                 loss: nan
agent1:                 episode reward: 0.7540,                 loss: 0.3602
Episode: 17941/30000 (59.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7074s / 498.3445 s
agent0:                 episode reward: -0.3590,                 loss: nan
agent1:                 episode reward: 0.3590,                 loss: 0.3621
Episode: 17961/30000 (59.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7168s / 499.0613 s
agent0:                 episode reward: -0.7791,                 loss: nan
agent1:                 episode reward: 0.7791,                 loss: 0.3610
Episode: 17981/30000 (59.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7225s / 499.7838 s
agent0:                 episode reward: -0.3894,                 loss: nan
agent1:                 episode reward: 0.3894,                 loss: 0.3624
Episode: 18001/30000 (60.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7170s / 500.5008 s
agent0:                 episode reward: -0.3744,                 loss: nan
agent1:                 episode reward: 0.3744,                 loss: 0.3603
Episode: 18021/30000 (60.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7227s / 501.2235 s
agent0:                 episode reward: -0.2720,                 loss: nan
agent1:                 episode reward: 0.2720,                 loss: 0.3543
Episode: 18041/30000 (60.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7158s / 501.9393 s
agent0:                 episode reward: -0.4333,                 loss: nan
agent1:                 episode reward: 0.4333,                 loss: 0.3502
Episode: 18061/30000 (60.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7177s / 502.6571 s
agent0:                 episode reward: -0.4687,                 loss: nan
agent1:                 episode reward: 0.4687,                 loss: 0.3536
Episode: 18081/30000 (60.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7240s / 503.3811 s
agent0:                 episode reward: -0.4574,                 loss: nan
agent1:                 episode reward: 0.4574,                 loss: 0.3529
Episode: 18101/30000 (60.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7206s / 504.1017 s
agent0:                 episode reward: -0.6102,                 loss: nan
agent1:                 episode reward: 0.6102,                 loss: 0.3511
Episode: 18121/30000 (60.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7220s / 504.8237 s
agent0:                 episode reward: -0.2168,                 loss: nan
agent1:                 episode reward: 0.2168,                 loss: 0.3521
Episode: 18141/30000 (60.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7165s / 505.5402 s
agent0:                 episode reward: -0.2348,                 loss: nan
agent1:                 episode reward: 0.2348,                 loss: 0.3462
Episode: 18161/30000 (60.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7179s / 506.2581 s
agent0:                 episode reward: -0.7739,                 loss: nan
agent1:                 episode reward: 0.7739,                 loss: 0.3499
Episode: 18181/30000 (60.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7187s / 506.9768 s
agent0:                 episode reward: -0.2591,                 loss: nan
agent1:                 episode reward: 0.2591,                 loss: 0.3485
Episode: 18201/30000 (60.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7348s / 507.7116 s
agent0:                 episode reward: -0.1303,                 loss: nan
agent1:                 episode reward: 0.1303,                 loss: 0.3501
Episode: 18221/30000 (60.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7118s / 508.4233 s
agent0:                 episode reward: -0.2075,                 loss: nan
agent1:                 episode reward: 0.2075,                 loss: 0.3504
Episode: 18241/30000 (60.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7166s / 509.1399 s
agent0:                 episode reward: -0.2990,                 loss: nan
agent1:                 episode reward: 0.2990,                 loss: 0.3497
Episode: 18261/30000 (60.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7165s / 509.8565 s
agent0:                 episode reward: -0.4501,                 loss: nan
agent1:                 episode reward: 0.4501,                 loss: 0.3542
Episode: 18281/30000 (60.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7215s / 510.5780 s
agent0:                 episode reward: -0.5944,                 loss: nan
agent1:                 episode reward: 0.5944,                 loss: 0.3481
Episode: 18301/30000 (61.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7166s / 511.2945 s
agent0:                 episode reward: -0.5661,                 loss: nan
agent1:                 episode reward: 0.5661,                 loss: 0.3472
Episode: 18321/30000 (61.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7166s / 512.0111 s
agent0:                 episode reward: -0.7661,                 loss: nan
agent1:                 episode reward: 0.7661,                 loss: 0.3530
Episode: 18341/30000 (61.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7266s / 512.7377 s
agent0:                 episode reward: -1.0591,                 loss: nan
agent1:                 episode reward: 1.0591,                 loss: 0.3576
Episode: 18361/30000 (61.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7229s / 513.4606 s
agent0:                 episode reward: -0.7338,                 loss: nan
agent1:                 episode reward: 0.7338,                 loss: 0.3652
Episode: 18381/30000 (61.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7114s / 514.1721 s
agent0:                 episode reward: -0.4152,                 loss: nan
agent1:                 episode reward: 0.4152,                 loss: 0.3678
Episode: 18401/30000 (61.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7185s / 514.8906 s
agent0:                 episode reward: -0.6607,                 loss: nan
agent1:                 episode reward: 0.6607,                 loss: 0.3642
Episode: 18421/30000 (61.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7254s / 515.6160 s
agent0:                 episode reward: -0.4130,                 loss: nan
agent1:                 episode reward: 0.4130,                 loss: 0.3632
Episode: 18441/30000 (61.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7510s / 516.3670 s
agent0:                 episode reward: -0.6714,                 loss: nan
agent1:                 episode reward: 0.6714,                 loss: 0.3665
Episode: 18461/30000 (61.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7221s / 517.0891 s
agent0:                 episode reward: -0.6232,                 loss: nan
agent1:                 episode reward: 0.6232,                 loss: 0.3659
Episode: 18481/30000 (61.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7203s / 517.8094 s
agent0:                 episode reward: -0.7361,                 loss: nan
agent1:                 episode reward: 0.7361,                 loss: 0.3649
Episode: 18501/30000 (61.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7236s / 518.5330 s
agent0:                 episode reward: -0.7490,                 loss: nan
agent1:                 episode reward: 0.7490,                 loss: 0.3641
Episode: 18521/30000 (61.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7268s / 519.2598 s
agent0:                 episode reward: -0.8751,                 loss: nan
agent1:                 episode reward: 0.8751,                 loss: 0.3655
Episode: 18541/30000 (61.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7379s / 519.9977 s
agent0:                 episode reward: -0.5807,                 loss: nan
agent1:                 episode reward: 0.5807,                 loss: 0.3654
Episode: 18561/30000 (61.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7154s / 520.7131 s
agent0:                 episode reward: -0.5912,                 loss: nan
agent1:                 episode reward: 0.5912,                 loss: 0.3638
Episode: 18581/30000 (61.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7169s / 521.4300 s
agent0:                 episode reward: -0.3441,                 loss: nan
agent1:                 episode reward: 0.3441,                 loss: 0.3671
Episode: 18601/30000 (62.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7137s / 522.1437 s
agent0:                 episode reward: -0.5425,                 loss: nan
agent1:                 episode reward: 0.5425,                 loss: 0.3651
Episode: 18621/30000 (62.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7179s / 522.8616 s
agent0:                 episode reward: -0.6115,                 loss: nan
agent1:                 episode reward: 0.6115,                 loss: 0.3644
Episode: 18641/30000 (62.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7285s / 523.5901 s
agent0:                 episode reward: -0.8246,                 loss: nan
agent1:                 episode reward: 0.8246,                 loss: 0.3636
Episode: 18661/30000 (62.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7285s / 524.3186 s
agent0:                 episode reward: -0.2129,                 loss: nan
agent1:                 episode reward: 0.2129,                 loss: 0.3661
Episode: 18681/30000 (62.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7270s / 525.0456 s
agent0:                 episode reward: -0.3565,                 loss: nan
agent1:                 episode reward: 0.3565,                 loss: 0.3647
Episode: 18701/30000 (62.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7149s / 525.7605 s
agent0:                 episode reward: -0.6204,                 loss: nan
agent1:                 episode reward: 0.6204,                 loss: 0.3592
Episode: 18721/30000 (62.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7361s / 526.4966 s
agent0:                 episode reward: -0.6435,                 loss: nan
agent1:                 episode reward: 0.6435,                 loss: 0.3635
Episode: 18741/30000 (62.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7248s / 527.2214 s
agent0:                 episode reward: -0.9177,                 loss: nan
agent1:                 episode reward: 0.9177,                 loss: 0.3613
Episode: 18761/30000 (62.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7249s / 527.9462 s
agent0:                 episode reward: -0.9395,                 loss: nan
agent1:                 episode reward: 0.9395,                 loss: 0.3582
Episode: 18781/30000 (62.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7276s / 528.6738 s
agent0:                 episode reward: -0.6834,                 loss: nan
agent1:                 episode reward: 0.6834,                 loss: 0.3621
Episode: 18801/30000 (62.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7229s / 529.3967 s
agent0:                 episode reward: -0.2785,                 loss: nan
agent1:                 episode reward: 0.2785,                 loss: 0.3591
Episode: 18821/30000 (62.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7273s / 530.1240 s
agent0:                 episode reward: -0.2572,                 loss: nan
agent1:                 episode reward: 0.2572,                 loss: 0.3604
Episode: 18841/30000 (62.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7286s / 530.8526 s
agent0:                 episode reward: -0.5638,                 loss: nan
agent1:                 episode reward: 0.5638,                 loss: 0.3626
Episode: 18861/30000 (62.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7268s / 531.5794 s
agent0:                 episode reward: -0.5278,                 loss: nan
agent1:                 episode reward: 0.5278,                 loss: 0.3613
Episode: 18881/30000 (62.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7309s / 532.3102 s
agent0:                 episode reward: -0.3126,                 loss: nan
agent1:                 episode reward: 0.3126,                 loss: 0.3640
Episode: 18901/30000 (63.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7233s / 533.0336 s
agent0:                 episode reward: -0.8265,                 loss: nan
agent1:                 episode reward: 0.8265,                 loss: 0.3603
Episode: 18921/30000 (63.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7239s / 533.7574 s
agent0:                 episode reward: -0.5567,                 loss: nan
agent1:                 episode reward: 0.5567,                 loss: 0.3605
Episode: 18941/30000 (63.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7391s / 534.4966 s
agent0:                 episode reward: -0.8441,                 loss: nan
agent1:                 episode reward: 0.8441,                 loss: 0.3577
Episode: 18961/30000 (63.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7319s / 535.2285 s
agent0:                 episode reward: -0.5851,                 loss: nan
agent1:                 episode reward: 0.5851,                 loss: 0.3631
Episode: 18981/30000 (63.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7337s / 535.9622 s
agent0:                 episode reward: -0.7248,                 loss: nan
agent1:                 episode reward: 0.7248,                 loss: 0.3621
Episode: 19001/30000 (63.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7341s / 536.6964 s
agent0:                 episode reward: -0.7054,                 loss: nan
agent1:                 episode reward: 0.7054,                 loss: 0.3646
Episode: 19021/30000 (63.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7282s / 537.4246 s
agent0:                 episode reward: -0.4609,                 loss: nan
agent1:                 episode reward: 0.4609,                 loss: 0.3506
Episode: 19041/30000 (63.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7288s / 538.1534 s
agent0:                 episode reward: -0.4322,                 loss: nan
agent1:                 episode reward: 0.4322,                 loss: 0.3474
Episode: 19061/30000 (63.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7252s / 538.8786 s
agent0:                 episode reward: -0.4145,                 loss: nan
agent1:                 episode reward: 0.4145,                 loss: 0.3462
Episode: 19081/30000 (63.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7521s / 539.6307 s
agent0:                 episode reward: -0.9597,                 loss: nan
agent1:                 episode reward: 0.9597,                 loss: 0.3476
Episode: 19101/30000 (63.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7329s / 540.3636 s
agent0:                 episode reward: -0.6230,                 loss: nan
agent1:                 episode reward: 0.6230,                 loss: 0.3448
Episode: 19121/30000 (63.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7321s / 541.0957 s
agent0:                 episode reward: -0.2884,                 loss: nan
agent1:                 episode reward: 0.2884,                 loss: 0.3492
Episode: 19141/30000 (63.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7355s / 541.8312 s
agent0:                 episode reward: -0.6767,                 loss: nan
agent1:                 episode reward: 0.6767,                 loss: 0.3466
Episode: 19161/30000 (63.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7354s / 542.5666 s
agent0:                 episode reward: -0.2828,                 loss: nan
agent1:                 episode reward: 0.2828,                 loss: 0.3448
Episode: 19181/30000 (63.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7384s / 543.3050 s
agent0:                 episode reward: -0.6340,                 loss: nan
agent1:                 episode reward: 0.6340,                 loss: 0.3464
Episode: 19201/30000 (64.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7257s / 544.0307 s
agent0:                 episode reward: -0.4573,                 loss: nan
agent1:                 episode reward: 0.4573,                 loss: 0.3468
Episode: 19221/30000 (64.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7358s / 544.7665 s
agent0:                 episode reward: 0.0071,                 loss: nan
agent1:                 episode reward: -0.0071,                 loss: 0.3449
Episode: 19241/30000 (64.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7589s / 545.5254 s
agent0:                 episode reward: -0.4971,                 loss: nan
agent1:                 episode reward: 0.4971,                 loss: 0.3469
Episode: 19261/30000 (64.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7477s / 546.2730 s
agent0:                 episode reward: -0.5127,                 loss: nan
agent1:                 episode reward: 0.5127,                 loss: 0.3442
Episode: 19281/30000 (64.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7407s / 547.0137 s
agent0:                 episode reward: -0.6949,                 loss: nan
agent1:                 episode reward: 0.6949,                 loss: 0.3463
Episode: 19301/30000 (64.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7393s / 547.7530 s
agent0:                 episode reward: -0.5957,                 loss: nan
agent1:                 episode reward: 0.5957,                 loss: 0.3457
Episode: 19321/30000 (64.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7447s / 548.4977 s
agent0:                 episode reward: -0.4019,                 loss: nan
agent1:                 episode reward: 0.4019,                 loss: 0.3455
Episode: 19341/30000 (64.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7578s / 549.2554 s
agent0:                 episode reward: -0.6498,                 loss: nan
agent1:                 episode reward: 0.6498,                 loss: 0.3565
Episode: 19361/30000 (64.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7374s / 549.9929 s
agent0:                 episode reward: -0.5477,                 loss: nan
agent1:                 episode reward: 0.5477,                 loss: 0.3689
Episode: 19381/30000 (64.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7437s / 550.7366 s
agent0:                 episode reward: -0.5589,                 loss: nan
agent1:                 episode reward: 0.5589,                 loss: 0.3661
Episode: 19401/30000 (64.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7501s / 551.4867 s
agent0:                 episode reward: -0.7613,                 loss: nan
agent1:                 episode reward: 0.7613,                 loss: 0.3644
Episode: 19421/30000 (64.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7460s / 552.2327 s
agent0:                 episode reward: -0.7857,                 loss: nan
agent1:                 episode reward: 0.7857,                 loss: 0.3680
Episode: 19441/30000 (64.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7518s / 552.9845 s
agent0:                 episode reward: -0.5112,                 loss: nan
agent1:                 episode reward: 0.5112,                 loss: 0.3676
Episode: 19461/30000 (64.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7443s / 553.7288 s
agent0:                 episode reward: -0.5294,                 loss: nan
agent1:                 episode reward: 0.5294,                 loss: 0.3667
Episode: 19481/30000 (64.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7398s / 554.4686 s
agent0:                 episode reward: -0.4377,                 loss: nan
agent1:                 episode reward: 0.4377,                 loss: 0.3672
Episode: 19501/30000 (65.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7467s / 555.2153 s
agent0:                 episode reward: -0.5722,                 loss: nan
agent1:                 episode reward: 0.5722,                 loss: 0.3673
Episode: 19521/30000 (65.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7581s / 555.9734 s
agent0:                 episode reward: -0.7778,                 loss: nan
agent1:                 episode reward: 0.7778,                 loss: 0.3653
Episode: 19541/30000 (65.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7518s / 556.7251 s
agent0:                 episode reward: -0.4562,                 loss: nan
agent1:                 episode reward: 0.4562,                 loss: 0.3649
Episode: 19561/30000 (65.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7500s / 557.4751 s
agent0:                 episode reward: -0.6472,                 loss: nan
agent1:                 episode reward: 0.6472,                 loss: 0.3664
Episode: 19581/30000 (65.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7473s / 558.2225 s
agent0:                 episode reward: -0.5423,                 loss: nan
agent1:                 episode reward: 0.5423,                 loss: 0.3659
Episode: 19601/30000 (65.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7351s / 558.9575 s
agent0:                 episode reward: -0.2057,                 loss: nan
agent1:                 episode reward: 0.2057,                 loss: 0.3628
Episode: 19621/30000 (65.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7515s / 559.7090 s
agent0:                 episode reward: -0.7467,                 loss: nan
agent1:                 episode reward: 0.7467,                 loss: 0.3697
Episode: 19641/30000 (65.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7516s / 560.4605 s
agent0:                 episode reward: -0.1734,                 loss: nan
agent1:                 episode reward: 0.1734,                 loss: 0.3674
Episode: 19661/30000 (65.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7339s / 561.1944 s
agent0:                 episode reward: -0.6877,                 loss: nan
agent1:                 episode reward: 0.6877,                 loss: 0.3692
Episode: 19681/30000 (65.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7468s / 561.9411 s
agent0:                 episode reward: -0.2863,                 loss: nan
agent1:                 episode reward: 0.2863,                 loss: 0.3630
Episode: 19701/30000 (65.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7460s / 562.6872 s
agent0:                 episode reward: -0.1104,                 loss: nan
agent1:                 episode reward: 0.1104,                 loss: 0.3615
Episode: 19721/30000 (65.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7401s / 563.4272 s
agent0:                 episode reward: -0.1526,                 loss: nan
agent1:                 episode reward: 0.1526,                 loss: 0.3616
Episode: 19741/30000 (65.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7667s / 564.1939 s
agent0:                 episode reward: -0.4243,                 loss: nan
agent1:                 episode reward: 0.4243,                 loss: 0.3585
Episode: 19761/30000 (65.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7408s / 564.9347 s
agent0:                 episode reward: -0.6076,                 loss: nan
agent1:                 episode reward: 0.6076,                 loss: 0.3597
Episode: 19781/30000 (65.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7489s / 565.6836 s
agent0:                 episode reward: -0.7798,                 loss: nan
agent1:                 episode reward: 0.7798,                 loss: 0.3606
Episode: 19801/30000 (66.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7450s / 566.4286 s
agent0:                 episode reward: -0.8727,                 loss: nan
agent1:                 episode reward: 0.8727,                 loss: 0.3621
Episode: 19821/30000 (66.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7394s / 567.1680 s
agent0:                 episode reward: -0.8136,                 loss: nan
agent1:                 episode reward: 0.8136,                 loss: 0.3592
Episode: 19841/30000 (66.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7355s / 567.9035 s
agent0:                 episode reward: -0.7933,                 loss: nan
agent1:                 episode reward: 0.7933,                 loss: 0.3601
Episode: 19861/30000 (66.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7527s / 568.6561 s
agent0:                 episode reward: -0.4180,                 loss: nan
agent1:                 episode reward: 0.4180,                 loss: 0.3630
Episode: 19881/30000 (66.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7432s / 569.3994 s
agent0:                 episode reward: -0.5906,                 loss: nan
agent1:                 episode reward: 0.5906,                 loss: 0.3623
Episode: 19901/30000 (66.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7426s / 570.1420 s
agent0:                 episode reward: -0.4054,                 loss: nan
agent1:                 episode reward: 0.4054,                 loss: 0.3619
Episode: 19921/30000 (66.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7488s / 570.8907 s
agent0:                 episode reward: -0.6068,                 loss: nan
agent1:                 episode reward: 0.6068,                 loss: 0.3623
Episode: 19941/30000 (66.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7491s / 571.6398 s
agent0:                 episode reward: -0.7309,                 loss: nan
agent1:                 episode reward: 0.7309,                 loss: 0.3583
Episode: 19961/30000 (66.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7482s / 572.3880 s
agent0:                 episode reward: -0.5378,                 loss: nan
agent1:                 episode reward: 0.5378,                 loss: 0.3630
Episode: 19981/30000 (66.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7505s / 573.1386 s
agent0:                 episode reward: -0.6862,                 loss: nan
agent1:                 episode reward: 0.6862,                 loss: 0.3646
Episode: 20001/30000 (66.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7496s / 573.8882 s
agent0:                 episode reward: -0.4737,                 loss: nan
agent1:                 episode reward: 0.4737,                 loss: 0.3628
Episode: 20021/30000 (66.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7577s / 574.6458 s
agent0:                 episode reward: -0.4194,                 loss: nan
agent1:                 episode reward: 0.4194,                 loss: 0.3473
Episode: 20041/30000 (66.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7455s / 575.3914 s
agent0:                 episode reward: -0.6639,                 loss: nan
agent1:                 episode reward: 0.6639,                 loss: 0.3504
Episode: 20061/30000 (66.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7507s / 576.1421 s
agent0:                 episode reward: -0.6734,                 loss: nan
agent1:                 episode reward: 0.6734,                 loss: 0.3470
Episode: 20081/30000 (66.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7501s / 576.8921 s
agent0:                 episode reward: -0.6143,                 loss: nan
agent1:                 episode reward: 0.6143,                 loss: 0.3482
Episode: 20101/30000 (67.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7473s / 577.6394 s
agent0:                 episode reward: -0.8354,                 loss: nan
agent1:                 episode reward: 0.8354,                 loss: 0.3486
Episode: 20121/30000 (67.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7440s / 578.3835 s
agent0:                 episode reward: -0.4515,                 loss: nan
agent1:                 episode reward: 0.4515,                 loss: 0.3518
Episode: 20141/30000 (67.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7540s / 579.1374 s
agent0:                 episode reward: -0.3501,                 loss: nan
agent1:                 episode reward: 0.3501,                 loss: 0.3523
Episode: 20161/30000 (67.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7485s / 579.8860 s
agent0:                 episode reward: -0.3358,                 loss: nan
agent1:                 episode reward: 0.3358,                 loss: 0.3565
Episode: 20181/30000 (67.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7568s / 580.6428 s
agent0:                 episode reward: -0.7951,                 loss: nan
agent1:                 episode reward: 0.7951,                 loss: 0.3486
Episode: 20201/30000 (67.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7416s / 581.3844 s
agent0:                 episode reward: -0.5258,                 loss: nan
agent1:                 episode reward: 0.5258,                 loss: 0.3499
Episode: 20221/30000 (67.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7648s / 582.1493 s
agent0:                 episode reward: -0.6317,                 loss: nan
agent1:                 episode reward: 0.6317,                 loss: 0.3456
Episode: 20241/30000 (67.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7580s / 582.9073 s
agent0:                 episode reward: -0.3507,                 loss: nan
agent1:                 episode reward: 0.3507,                 loss: 0.3506
Episode: 20261/30000 (67.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7593s / 583.6666 s
agent0:                 episode reward: -0.2758,                 loss: nan
agent1:                 episode reward: 0.2758,                 loss: 0.3507
Episode: 20281/30000 (67.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7516s / 584.4183 s
agent0:                 episode reward: -0.6340,                 loss: nan
agent1:                 episode reward: 0.6340,                 loss: 0.3476
Episode: 20301/30000 (67.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7431s / 585.1614 s
agent0:                 episode reward: -0.6599,                 loss: nan
agent1:                 episode reward: 0.6599,                 loss: 0.3513
Episode: 20321/30000 (67.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7573s / 585.9187 s
agent0:                 episode reward: -0.6441,                 loss: nan
agent1:                 episode reward: 0.6441,                 loss: 0.3479
Episode: 20341/30000 (67.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7549s / 586.6735 s
agent0:                 episode reward: -0.3560,                 loss: nan
agent1:                 episode reward: 0.3560,                 loss: 0.3571
Episode: 20361/30000 (67.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7613s / 587.4348 s
agent0:                 episode reward: -0.3780,                 loss: nan
agent1:                 episode reward: 0.3780,                 loss: 0.3724
Episode: 20381/30000 (67.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7483s / 588.1831 s
agent0:                 episode reward: -0.6260,                 loss: nan
agent1:                 episode reward: 0.6260,                 loss: 0.3686
Episode: 20401/30000 (68.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7510s / 588.9340 s
agent0:                 episode reward: -0.2409,                 loss: nan
agent1:                 episode reward: 0.2409,                 loss: 0.3688
Episode: 20421/30000 (68.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7584s / 589.6925 s
agent0:                 episode reward: -0.6156,                 loss: nan
agent1:                 episode reward: 0.6156,                 loss: 0.3710
Episode: 20441/30000 (68.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7534s / 590.4459 s
agent0:                 episode reward: -0.3772,                 loss: nan
agent1:                 episode reward: 0.3772,                 loss: 0.3702
Episode: 20461/30000 (68.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7518s / 591.1977 s
agent0:                 episode reward: -0.3074,                 loss: nan
agent1:                 episode reward: 0.3074,                 loss: 0.3691
Episode: 20481/30000 (68.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7544s / 591.9521 s
agent0:                 episode reward: -0.5079,                 loss: nan
agent1:                 episode reward: 0.5079,                 loss: 0.3710
Episode: 20501/30000 (68.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7655s / 592.7176 s
agent0:                 episode reward: -0.7867,                 loss: nan
agent1:                 episode reward: 0.7867,                 loss: 0.3689
Episode: 20521/30000 (68.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7508s / 593.4684 s
agent0:                 episode reward: -0.3807,                 loss: nan
agent1:                 episode reward: 0.3807,                 loss: 0.3711
Episode: 20541/30000 (68.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7639s / 594.2323 s
agent0:                 episode reward: -0.6735,                 loss: nan
agent1:                 episode reward: 0.6735,                 loss: 0.3698
Episode: 20561/30000 (68.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7616s / 594.9939 s
agent0:                 episode reward: -0.5904,                 loss: nan
agent1:                 episode reward: 0.5904,                 loss: 0.3687
Episode: 20581/30000 (68.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7518s / 595.7458 s
agent0:                 episode reward: -0.5208,                 loss: nan
agent1:                 episode reward: 0.5208,                 loss: 0.3675
Episode: 20601/30000 (68.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7580s / 596.5038 s
agent0:                 episode reward: -0.7273,                 loss: nan
agent1:                 episode reward: 0.7273,                 loss: 0.3706
Episode: 20621/30000 (68.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7496s / 597.2534 s
agent0:                 episode reward: -0.6409,                 loss: nan
agent1:                 episode reward: 0.6409,                 loss: 0.3680
Episode: 20641/30000 (68.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7595s / 598.0129 s
agent0:                 episode reward: -0.1030,                 loss: nan
agent1:                 episode reward: 0.1030,                 loss: 0.3690
Episode: 20661/30000 (68.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7570s / 598.7699 s
agent0:                 episode reward: -0.7109,                 loss: nan
agent1:                 episode reward: 0.7109,                 loss: 0.3695
Episode: 20681/30000 (68.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7522s / 599.5220 s
agent0:                 episode reward: -0.5621,                 loss: nan
agent1:                 episode reward: 0.5621,                 loss: 0.3617
Episode: 20701/30000 (69.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7774s / 600.2995 s
agent0:                 episode reward: -0.9008,                 loss: nan
agent1:                 episode reward: 0.9008,                 loss: 0.3596
Episode: 20721/30000 (69.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7609s / 601.0604 s
agent0:                 episode reward: -0.7296,                 loss: nan
agent1:                 episode reward: 0.7296,                 loss: 0.3588
Episode: 20741/30000 (69.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7692s / 601.8296 s
agent0:                 episode reward: -0.2627,                 loss: nan
agent1:                 episode reward: 0.2627,                 loss: 0.3571
Episode: 20761/30000 (69.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7573s / 602.5869 s
agent0:                 episode reward: -0.4682,                 loss: nan
agent1:                 episode reward: 0.4682,                 loss: 0.3611
Episode: 20781/30000 (69.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7647s / 603.3516 s
agent0:                 episode reward: -0.3705,                 loss: nan
agent1:                 episode reward: 0.3705,                 loss: 0.3572
Episode: 20801/30000 (69.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7635s / 604.1151 s
agent0:                 episode reward: -0.2055,                 loss: nan
agent1:                 episode reward: 0.2055,                 loss: 0.3597
Episode: 20821/30000 (69.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7535s / 604.8686 s
agent0:                 episode reward: -0.4483,                 loss: nan
agent1:                 episode reward: 0.4483,                 loss: 0.3577
Episode: 20841/30000 (69.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7643s / 605.6328 s
agent0:                 episode reward: -0.6080,                 loss: nan
agent1:                 episode reward: 0.6080,                 loss: 0.3593
Episode: 20861/30000 (69.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7602s / 606.3931 s
agent0:                 episode reward: -0.7293,                 loss: nan
agent1:                 episode reward: 0.7293,                 loss: 0.3590
Episode: 20881/30000 (69.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7709s / 607.1639 s
agent0:                 episode reward: -0.5182,                 loss: nan
agent1:                 episode reward: 0.5182,                 loss: 0.3585
Episode: 20901/30000 (69.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7669s / 607.9308 s
agent0:                 episode reward: -0.4565,                 loss: nan
agent1:                 episode reward: 0.4565,                 loss: 0.3581
Episode: 20921/30000 (69.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7675s / 608.6983 s
agent0:                 episode reward: -0.3805,                 loss: nan
agent1:                 episode reward: 0.3805,                 loss: 0.3565
Episode: 20941/30000 (69.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7674s / 609.4657 s
agent0:                 episode reward: -0.6385,                 loss: nan
agent1:                 episode reward: 0.6385,                 loss: 0.3576
Episode: 20961/30000 (69.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7536s / 610.2193 s
agent0:                 episode reward: -0.5176,                 loss: nan
agent1:                 episode reward: 0.5176,                 loss: 0.3580
Episode: 20981/30000 (69.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7608s / 610.9801 s
agent0:                 episode reward: -0.4692,                 loss: nan
agent1:                 episode reward: 0.4692,                 loss: 0.3576
Episode: 21001/30000 (70.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7546s / 611.7347 s
agent0:                 episode reward: -0.3693,                 loss: nan
agent1:                 episode reward: 0.3693,                 loss: 0.3583
Episode: 21021/30000 (70.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7599s / 612.4946 s
agent0:                 episode reward: -0.3285,                 loss: nan
agent1:                 episode reward: 0.3285,                 loss: 0.3480
Episode: 21041/30000 (70.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7528s / 613.2474 s
agent0:                 episode reward: -0.5037,                 loss: nan
agent1:                 episode reward: 0.5037,                 loss: 0.3477
Episode: 21061/30000 (70.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7592s / 614.0066 s
agent0:                 episode reward: -0.0443,                 loss: nan
agent1:                 episode reward: 0.0443,                 loss: 0.3459
Episode: 21081/30000 (70.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7645s / 614.7712 s
agent0:                 episode reward: -0.3557,                 loss: nan
agent1:                 episode reward: 0.3557,                 loss: 0.3436
Episode: 21101/30000 (70.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7605s / 615.5317 s
agent0:                 episode reward: -0.6227,                 loss: nan
agent1:                 episode reward: 0.6227,                 loss: 0.3473
Episode: 21121/30000 (70.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7647s / 616.2964 s
agent0:                 episode reward: -0.6443,                 loss: nan
agent1:                 episode reward: 0.6443,                 loss: 0.3420
Episode: 21141/30000 (70.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7666s / 617.0630 s
agent0:                 episode reward: -0.6216,                 loss: nan
agent1:                 episode reward: 0.6216,                 loss: 0.3442
Episode: 21161/30000 (70.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7782s / 617.8412 s
agent0:                 episode reward: -0.2150,                 loss: nan
agent1:                 episode reward: 0.2150,                 loss: 0.3463
Episode: 21181/30000 (70.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7641s / 618.6053 s
agent0:                 episode reward: -0.7340,                 loss: nan
agent1:                 episode reward: 0.7340,                 loss: 0.3453
Episode: 21201/30000 (70.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7638s / 619.3692 s
agent0:                 episode reward: -0.1149,                 loss: nan
agent1:                 episode reward: 0.1149,                 loss: 0.3438
Episode: 21221/30000 (70.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7683s / 620.1375 s
agent0:                 episode reward: -0.6672,                 loss: nan
agent1:                 episode reward: 0.6672,                 loss: 0.3475
Episode: 21241/30000 (70.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7595s / 620.8970 s
agent0:                 episode reward: -0.4033,                 loss: nan
agent1:                 episode reward: 0.4033,                 loss: 0.3475
Episode: 21261/30000 (70.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7715s / 621.6685 s
agent0:                 episode reward: -0.5104,                 loss: nan
agent1:                 episode reward: 0.5104,                 loss: 0.3455
Episode: 21281/30000 (70.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7606s / 622.4291 s
agent0:                 episode reward: -0.2331,                 loss: nan
agent1:                 episode reward: 0.2331,                 loss: 0.3445
Episode: 21301/30000 (71.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7656s / 623.1948 s
agent0:                 episode reward: -0.3650,                 loss: nan
agent1:                 episode reward: 0.3650,                 loss: 0.3453
Episode: 21321/30000 (71.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7607s / 623.9554 s
agent0:                 episode reward: -0.5564,                 loss: nan
agent1:                 episode reward: 0.5564,                 loss: 0.3459
Episode: 21341/30000 (71.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8227s / 624.7782 s
agent0:                 episode reward: -0.3666,                 loss: nan
agent1:                 episode reward: 0.3666,                 loss: 0.3578
Episode: 21361/30000 (71.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7751s / 625.5532 s
agent0:                 episode reward: -0.4788,                 loss: nan
agent1:                 episode reward: 0.4788,                 loss: 0.3694
Episode: 21381/30000 (71.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7727s / 626.3259 s
agent0:                 episode reward: -0.3954,                 loss: nan
agent1:                 episode reward: 0.3954,                 loss: 0.3675
Episode: 21401/30000 (71.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7656s / 627.0915 s
agent0:                 episode reward: -0.5264,                 loss: nan
agent1:                 episode reward: 0.5264,                 loss: 0.3693
Episode: 21421/30000 (71.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7689s / 627.8604 s
agent0:                 episode reward: -0.4940,                 loss: nan
agent1:                 episode reward: 0.4940,                 loss: 0.3646
Episode: 21441/30000 (71.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7843s / 628.6447 s
agent0:                 episode reward: -0.4675,                 loss: nan
agent1:                 episode reward: 0.4675,                 loss: 0.3706
Episode: 21461/30000 (71.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7802s / 629.4249 s
agent0:                 episode reward: -0.5435,                 loss: nan
agent1:                 episode reward: 0.5435,                 loss: 0.3675
Episode: 21481/30000 (71.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7736s / 630.1985 s
agent0:                 episode reward: -0.6401,                 loss: nan
agent1:                 episode reward: 0.6401,                 loss: 0.3691
Episode: 21501/30000 (71.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7821s / 630.9806 s
agent0:                 episode reward: -0.3995,                 loss: nan
agent1:                 episode reward: 0.3995,                 loss: 0.3680
Episode: 21521/30000 (71.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7786s / 631.7592 s
agent0:                 episode reward: -0.5033,                 loss: nan
agent1:                 episode reward: 0.5033,                 loss: 0.3687
Episode: 21541/30000 (71.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7685s / 632.5278 s
agent0:                 episode reward: -0.5168,                 loss: nan
agent1:                 episode reward: 0.5168,                 loss: 0.3677
Episode: 21561/30000 (71.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7739s / 633.3017 s
agent0:                 episode reward: -0.5968,                 loss: nan
agent1:                 episode reward: 0.5968,                 loss: 0.3691
Episode: 21581/30000 (71.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7676s / 634.0693 s
agent0:                 episode reward: -0.5315,                 loss: nan
agent1:                 episode reward: 0.5315,                 loss: 0.3664
Episode: 21601/30000 (72.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7774s / 634.8467 s
agent0:                 episode reward: -0.0225,                 loss: nan
agent1:                 episode reward: 0.0225,                 loss: 0.3678
Episode: 21621/30000 (72.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7739s / 635.6206 s
agent0:                 episode reward: -0.4015,                 loss: nan
agent1:                 episode reward: 0.4015,                 loss: 0.3689
Episode: 21641/30000 (72.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7769s / 636.3975 s
agent0:                 episode reward: -0.3097,                 loss: nan
agent1:                 episode reward: 0.3097,                 loss: 0.3663
Episode: 21661/30000 (72.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7835s / 637.1810 s
agent0:                 episode reward: -0.4958,                 loss: nan
agent1:                 episode reward: 0.4958,                 loss: 0.3677
Episode: 21681/30000 (72.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7698s / 637.9508 s
agent0:                 episode reward: -0.4130,                 loss: nan
agent1:                 episode reward: 0.4130,                 loss: 0.3570
Episode: 21701/30000 (72.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7769s / 638.7277 s
agent0:                 episode reward: -0.5869,                 loss: nan
agent1:                 episode reward: 0.5869,                 loss: 0.3471
Episode: 21721/30000 (72.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8088s / 639.5365 s
agent0:                 episode reward: -0.7340,                 loss: nan
agent1:                 episode reward: 0.7340,                 loss: 0.3505
Episode: 21741/30000 (72.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7766s / 640.3131 s
agent0:                 episode reward: -0.3588,                 loss: nan
agent1:                 episode reward: 0.3588,                 loss: 0.3486
Episode: 21761/30000 (72.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7762s / 641.0892 s
agent0:                 episode reward: -0.2907,                 loss: nan
agent1:                 episode reward: 0.2907,                 loss: 0.3454
Episode: 21781/30000 (72.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7759s / 641.8651 s
agent0:                 episode reward: -0.6229,                 loss: nan
agent1:                 episode reward: 0.6229,                 loss: 0.3476
Episode: 21801/30000 (72.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7895s / 642.6546 s
agent0:                 episode reward: -0.3816,                 loss: nan
agent1:                 episode reward: 0.3816,                 loss: 0.3474
Episode: 21821/30000 (72.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7882s / 643.4428 s
agent0:                 episode reward: -0.5646,                 loss: nan
agent1:                 episode reward: 0.5646,                 loss: 0.3453
Episode: 21841/30000 (72.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7806s / 644.2233 s
agent0:                 episode reward: -0.6630,                 loss: nan
agent1:                 episode reward: 0.6630,                 loss: 0.3487
Episode: 21861/30000 (72.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7724s / 644.9958 s
agent0:                 episode reward: -0.6503,                 loss: nan
agent1:                 episode reward: 0.6503,                 loss: 0.3458
Episode: 21881/30000 (72.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7674s / 645.7631 s
agent0:                 episode reward: -0.2998,                 loss: nan
agent1:                 episode reward: 0.2998,                 loss: 0.3498
Episode: 21901/30000 (73.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7819s / 646.5451 s
agent0:                 episode reward: -0.6674,                 loss: nan
agent1:                 episode reward: 0.6674,                 loss: 0.3481
Episode: 21921/30000 (73.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7718s / 647.3169 s
agent0:                 episode reward: -0.5487,                 loss: nan
agent1:                 episode reward: 0.5487,                 loss: 0.3474
Episode: 21941/30000 (73.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7738s / 648.0907 s
agent0:                 episode reward: -0.4683,                 loss: nan
agent1:                 episode reward: 0.4683,                 loss: 0.3493
Episode: 21961/30000 (73.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7826s / 648.8732 s
agent0:                 episode reward: -0.4171,                 loss: nan
agent1:                 episode reward: 0.4171,                 loss: 0.3500
Episode: 21981/30000 (73.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7769s / 649.6502 s
agent0:                 episode reward: -0.7041,                 loss: nan
agent1:                 episode reward: 0.7041,                 loss: 0.3434
Episode: 22001/30000 (73.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7858s / 650.4359 s
agent0:                 episode reward: -0.6957,                 loss: nan
agent1:                 episode reward: 0.6957,                 loss: 0.3488
Episode: 22021/30000 (73.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7934s / 651.2293 s
agent0:                 episode reward: -0.3227,                 loss: nan
agent1:                 episode reward: 0.3227,                 loss: 0.3640
Episode: 22041/30000 (73.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8022s / 652.0315 s
agent0:                 episode reward: -0.6601,                 loss: nan
agent1:                 episode reward: 0.6601,                 loss: 0.3566
Episode: 22061/30000 (73.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7748s / 652.8063 s
agent0:                 episode reward: -0.2868,                 loss: nan
agent1:                 episode reward: 0.2868,                 loss: 0.3573
Episode: 22081/30000 (73.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7830s / 653.5893 s
agent0:                 episode reward: -0.8843,                 loss: nan
agent1:                 episode reward: 0.8843,                 loss: 0.3575
Episode: 22101/30000 (73.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7798s / 654.3692 s
agent0:                 episode reward: -0.5257,                 loss: nan
agent1:                 episode reward: 0.5257,                 loss: 0.3587
Episode: 22121/30000 (73.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7860s / 655.1551 s
agent0:                 episode reward: -0.5072,                 loss: nan
agent1:                 episode reward: 0.5072,                 loss: 0.3589
Episode: 22141/30000 (73.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7889s / 655.9440 s
agent0:                 episode reward: -0.5837,                 loss: nan
agent1:                 episode reward: 0.5837,                 loss: 0.3612
Episode: 22161/30000 (73.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7815s / 656.7255 s
agent0:                 episode reward: -0.7414,                 loss: nan
agent1:                 episode reward: 0.7414,                 loss: 0.3554
Episode: 22181/30000 (73.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7984s / 657.5239 s
agent0:                 episode reward: -0.4270,                 loss: nan
agent1:                 episode reward: 0.4270,                 loss: 0.3574
Episode: 22201/30000 (74.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7912s / 658.3152 s
agent0:                 episode reward: -0.4357,                 loss: nan
agent1:                 episode reward: 0.4357,                 loss: 0.3584
Episode: 22221/30000 (74.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7849s / 659.1001 s
agent0:                 episode reward: -0.4031,                 loss: nan
agent1:                 episode reward: 0.4031,                 loss: 0.3589
Episode: 22241/30000 (74.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8002s / 659.9002 s
agent0:                 episode reward: -0.6164,                 loss: nan
agent1:                 episode reward: 0.6164,                 loss: 0.3606
Episode: 22261/30000 (74.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7913s / 660.6915 s
agent0:                 episode reward: -0.4783,                 loss: nan
agent1:                 episode reward: 0.4783,                 loss: 0.3583
Episode: 22281/30000 (74.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7834s / 661.4749 s
agent0:                 episode reward: -0.2485,                 loss: nan
agent1:                 episode reward: 0.2485,                 loss: 0.3578
Episode: 22301/30000 (74.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7961s / 662.2710 s
agent0:                 episode reward: -0.5624,                 loss: nan
agent1:                 episode reward: 0.5624,                 loss: 0.3588
Episode: 22321/30000 (74.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7880s / 663.0590 s
agent0:                 episode reward: -0.4891,                 loss: nan
agent1:                 episode reward: 0.4891,                 loss: 0.3572
Episode: 22341/30000 (74.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7894s / 663.8484 s
agent0:                 episode reward: -0.4003,                 loss: nan
agent1:                 episode reward: 0.4003,                 loss: 0.3642
Episode: 22361/30000 (74.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8198s / 664.6682 s
agent0:                 episode reward: -0.5119,                 loss: nan
agent1:                 episode reward: 0.5119,                 loss: 0.3682
Episode: 22381/30000 (74.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8118s / 665.4800 s
agent0:                 episode reward: -0.7117,                 loss: nan
agent1:                 episode reward: 0.7117,                 loss: 0.3650
Episode: 22401/30000 (74.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7783s / 666.2583 s
agent0:                 episode reward: -0.4483,                 loss: nan
agent1:                 episode reward: 0.4483,                 loss: 0.3639
Episode: 22421/30000 (74.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7884s / 667.0467 s
agent0:                 episode reward: -0.3288,                 loss: nan
agent1:                 episode reward: 0.3288,                 loss: 0.3648
Episode: 22441/30000 (74.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7971s / 667.8438 s
agent0:                 episode reward: -0.5406,                 loss: nan
agent1:                 episode reward: 0.5406,                 loss: 0.3654
Episode: 22461/30000 (74.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7911s / 668.6349 s
agent0:                 episode reward: -0.7339,                 loss: nan
agent1:                 episode reward: 0.7339,                 loss: 0.3675
Episode: 22481/30000 (74.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7904s / 669.4253 s
agent0:                 episode reward: -0.5421,                 loss: nan
agent1:                 episode reward: 0.5421,                 loss: 0.3654
Episode: 22501/30000 (75.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8263s / 670.2516 s
agent0:                 episode reward: -0.2232,                 loss: nan
agent1:                 episode reward: 0.2232,                 loss: 0.3650
Episode: 22521/30000 (75.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7996s / 671.0512 s
agent0:                 episode reward: -0.4471,                 loss: nan
agent1:                 episode reward: 0.4471,                 loss: 0.3684
Episode: 22541/30000 (75.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7910s / 671.8421 s
agent0:                 episode reward: -0.9192,                 loss: nan
agent1:                 episode reward: 0.9192,                 loss: 0.3665
Episode: 22561/30000 (75.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7815s / 672.6236 s
agent0:                 episode reward: -0.3407,                 loss: nan
agent1:                 episode reward: 0.3407,                 loss: 0.3656
Episode: 22581/30000 (75.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8071s / 673.4306 s
agent0:                 episode reward: -0.5266,                 loss: nan
agent1:                 episode reward: 0.5266,                 loss: 0.3660
Episode: 22601/30000 (75.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8070s / 674.2377 s
agent0:                 episode reward: -0.6902,                 loss: nan
agent1:                 episode reward: 0.6902,                 loss: 0.3667
Episode: 22621/30000 (75.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7824s / 675.0201 s
agent0:                 episode reward: -0.2326,                 loss: nan
agent1:                 episode reward: 0.2326,                 loss: 0.3662
Episode: 22641/30000 (75.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7938s / 675.8138 s
agent0:                 episode reward: -0.4857,                 loss: nan
agent1:                 episode reward: 0.4857,                 loss: 0.3678
Episode: 22661/30000 (75.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8066s / 676.6205 s
agent0:                 episode reward: -0.5849,                 loss: nan
agent1:                 episode reward: 0.5849,                 loss: 0.3666
Episode: 22681/30000 (75.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7999s / 677.4204 s
agent0:                 episode reward: -0.4382,                 loss: nan
agent1:                 episode reward: 0.4382,                 loss: 0.3570
Episode: 22701/30000 (75.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7927s / 678.2130 s
agent0:                 episode reward: -0.2199,                 loss: nan
agent1:                 episode reward: 0.2199,                 loss: 0.3483
Episode: 22721/30000 (75.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8124s / 679.0254 s
agent0:                 episode reward: -0.5911,                 loss: nan
agent1:                 episode reward: 0.5911,                 loss: 0.3456
Episode: 22741/30000 (75.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8073s / 679.8327 s
agent0:                 episode reward: -0.1719,                 loss: nan
agent1:                 episode reward: 0.1719,                 loss: 0.3485
Episode: 22761/30000 (75.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8237s / 680.6565 s
agent0:                 episode reward: -0.7864,                 loss: nan
agent1:                 episode reward: 0.7864,                 loss: 0.3515
Episode: 22781/30000 (75.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8149s / 681.4713 s
agent0:                 episode reward: -0.7084,                 loss: nan
agent1:                 episode reward: 0.7084,                 loss: 0.3462
Episode: 22801/30000 (76.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8330s / 682.3043 s
agent0:                 episode reward: -0.3797,                 loss: nan
agent1:                 episode reward: 0.3797,                 loss: 0.3507
Episode: 22821/30000 (76.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7965s / 683.1008 s
agent0:                 episode reward: -0.6575,                 loss: nan
agent1:                 episode reward: 0.6575,                 loss: 0.3489
Episode: 22841/30000 (76.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7967s / 683.8975 s
agent0:                 episode reward: -0.5707,                 loss: nan
agent1:                 episode reward: 0.5707,                 loss: 0.3478
Episode: 22861/30000 (76.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8176s / 684.7151 s
agent0:                 episode reward: -0.3521,                 loss: nan
agent1:                 episode reward: 0.3521,                 loss: 0.3499
Episode: 22881/30000 (76.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8031s / 685.5182 s
agent0:                 episode reward: -0.6259,                 loss: nan
agent1:                 episode reward: 0.6259,                 loss: 0.3490
Episode: 22901/30000 (76.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8076s / 686.3258 s
agent0:                 episode reward: -0.6993,                 loss: nan
agent1:                 episode reward: 0.6993,                 loss: 0.3517
Episode: 22921/30000 (76.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8054s / 687.1312 s
agent0:                 episode reward: -0.7872,                 loss: nan
agent1:                 episode reward: 0.7872,                 loss: 0.3476
Episode: 22941/30000 (76.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7956s / 687.9268 s
agent0:                 episode reward: -0.2623,                 loss: nan
agent1:                 episode reward: 0.2623,                 loss: 0.3512
Episode: 22961/30000 (76.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8038s / 688.7306 s
agent0:                 episode reward: -0.6334,                 loss: nan
agent1:                 episode reward: 0.6334,                 loss: 0.3472
Episode: 22981/30000 (76.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7962s / 689.5268 s
agent0:                 episode reward: -0.6560,                 loss: nan
agent1:                 episode reward: 0.6560,                 loss: 0.3451
Episode: 23001/30000 (76.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8041s / 690.3309 s
agent0:                 episode reward: -0.2083,                 loss: nan
agent1:                 episode reward: 0.2083,                 loss: 0.3512
Episode: 23021/30000 (76.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8017s / 691.1326 s
agent0:                 episode reward: -0.4593,                 loss: nan
agent1:                 episode reward: 0.4593,                 loss: 0.3637
Episode: 23041/30000 (76.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7994s / 691.9320 s
agent0:                 episode reward: -1.0495,                 loss: nan
agent1:                 episode reward: 1.0495,                 loss: 0.3642
Episode: 23061/30000 (76.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7854s / 692.7174 s
agent0:                 episode reward: -0.7429,                 loss: nan
agent1:                 episode reward: 0.7429,                 loss: 0.3621
Episode: 23081/30000 (76.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7980s / 693.5154 s
agent0:                 episode reward: -0.3575,                 loss: nan
agent1:                 episode reward: 0.3575,                 loss: 0.3641
Episode: 23101/30000 (77.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8043s / 694.3196 s
agent0:                 episode reward: -0.4011,                 loss: nan
agent1:                 episode reward: 0.4011,                 loss: 0.3641
Episode: 23121/30000 (77.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8165s / 695.1362 s
agent0:                 episode reward: -0.5216,                 loss: nan
agent1:                 episode reward: 0.5216,                 loss: 0.3631
Episode: 23141/30000 (77.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8056s / 695.9417 s
agent0:                 episode reward: -0.7404,                 loss: nan
agent1:                 episode reward: 0.7404,                 loss: 0.3615
Episode: 23161/30000 (77.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8096s / 696.7514 s
agent0:                 episode reward: -0.6001,                 loss: nan
agent1:                 episode reward: 0.6001,                 loss: 0.3631
Episode: 23181/30000 (77.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7889s / 697.5403 s
agent0:                 episode reward: -0.7524,                 loss: nan
agent1:                 episode reward: 0.7524,                 loss: 0.3631
Episode: 23201/30000 (77.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8097s / 698.3499 s
agent0:                 episode reward: -0.2284,                 loss: nan
agent1:                 episode reward: 0.2284,                 loss: 0.3610
Episode: 23221/30000 (77.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8247s / 699.1747 s
agent0:                 episode reward: -0.7584,                 loss: nan
agent1:                 episode reward: 0.7584,                 loss: 0.3656
Episode: 23241/30000 (77.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8029s / 699.9776 s
agent0:                 episode reward: -0.7768,                 loss: nan
agent1:                 episode reward: 0.7768,                 loss: 0.3633
Episode: 23261/30000 (77.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8114s / 700.7889 s
agent0:                 episode reward: -0.6295,                 loss: nan
agent1:                 episode reward: 0.6295,                 loss: 0.3600
Episode: 23281/30000 (77.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8131s / 701.6020 s
agent0:                 episode reward: -0.6317,                 loss: nan
agent1:                 episode reward: 0.6317,                 loss: 0.3608
Episode: 23301/30000 (77.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8044s / 702.4064 s
agent0:                 episode reward: -0.5457,                 loss: nan
agent1:                 episode reward: 0.5457,                 loss: 0.3632
Episode: 23321/30000 (77.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8093s / 703.2157 s
agent0:                 episode reward: -0.6458,                 loss: nan
agent1:                 episode reward: 0.6458,                 loss: 0.3642
Episode: 23341/30000 (77.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8077s / 704.0235 s
agent0:                 episode reward: -0.5248,                 loss: nan
agent1:                 episode reward: 0.5248,                 loss: 0.3663
Episode: 23361/30000 (77.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8002s / 704.8237 s
agent0:                 episode reward: -0.5896,                 loss: nan
agent1:                 episode reward: 0.5896,                 loss: 0.3706
Episode: 23381/30000 (77.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8070s / 705.6307 s
agent0:                 episode reward: -0.2896,                 loss: nan
agent1:                 episode reward: 0.2896,                 loss: 0.3692
Episode: 23401/30000 (78.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8060s / 706.4367 s
agent0:                 episode reward: -0.2997,                 loss: nan
agent1:                 episode reward: 0.2997,                 loss: 0.3704
Episode: 23421/30000 (78.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7954s / 707.2321 s
agent0:                 episode reward: -0.1734,                 loss: nan
agent1:                 episode reward: 0.1734,                 loss: 0.3762
Episode: 23441/30000 (78.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8106s / 708.0427 s
agent0:                 episode reward: -0.4946,                 loss: nan
agent1:                 episode reward: 0.4946,                 loss: 0.3716
Episode: 23461/30000 (78.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8101s / 708.8528 s
agent0:                 episode reward: -0.5528,                 loss: nan
agent1:                 episode reward: 0.5528,                 loss: 0.3711
Episode: 23481/30000 (78.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8144s / 709.6672 s
agent0:                 episode reward: -0.7541,                 loss: nan
agent1:                 episode reward: 0.7541,                 loss: 0.3716
Episode: 23501/30000 (78.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8212s / 710.4883 s
agent0:                 episode reward: -0.5042,                 loss: nan
agent1:                 episode reward: 0.5042,                 loss: 0.3741
Episode: 23521/30000 (78.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8146s / 711.3029 s
agent0:                 episode reward: -0.4645,                 loss: nan
agent1:                 episode reward: 0.4645,                 loss: 0.3690
Episode: 23541/30000 (78.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8342s / 712.1371 s
agent0:                 episode reward: -0.6263,                 loss: nan
agent1:                 episode reward: 0.6263,                 loss: 0.3719
Episode: 23561/30000 (78.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8277s / 712.9648 s
agent0:                 episode reward: -0.9628,                 loss: nan
agent1:                 episode reward: 0.9628,                 loss: 0.3729
Episode: 23581/30000 (78.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8113s / 713.7761 s
agent0:                 episode reward: -0.5067,                 loss: nan
agent1:                 episode reward: 0.5067,                 loss: 0.3717
Episode: 23601/30000 (78.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8154s / 714.5915 s
agent0:                 episode reward: -0.3737,                 loss: nan
agent1:                 episode reward: 0.3737,                 loss: 0.3714
Episode: 23621/30000 (78.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8163s / 715.4078 s
agent0:                 episode reward: -0.4574,                 loss: nan
agent1:                 episode reward: 0.4574,                 loss: 0.3736
Episode: 23641/30000 (78.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8148s / 716.2226 s
agent0:                 episode reward: -0.6471,                 loss: nan
agent1:                 episode reward: 0.6471,                 loss: 0.3726
Episode: 23661/30000 (78.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8149s / 717.0375 s
agent0:                 episode reward: -0.8280,                 loss: nan
agent1:                 episode reward: 0.8280,                 loss: 0.3683
Episode: 23681/30000 (78.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8173s / 717.8548 s
agent0:                 episode reward: -0.4287,                 loss: nan
agent1:                 episode reward: 0.4287,                 loss: 0.3645
Episode: 23701/30000 (79.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8257s / 718.6805 s
agent0:                 episode reward: -0.3626,                 loss: nan
agent1:                 episode reward: 0.3626,                 loss: 0.3600
Episode: 23721/30000 (79.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8121s / 719.4926 s
agent0:                 episode reward: -0.6155,                 loss: nan
agent1:                 episode reward: 0.6155,                 loss: 0.3630
Episode: 23741/30000 (79.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8198s / 720.3125 s
agent0:                 episode reward: -0.5636,                 loss: nan
agent1:                 episode reward: 0.5636,                 loss: 0.3596
Episode: 23761/30000 (79.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8332s / 721.1456 s
agent0:                 episode reward: -0.5717,                 loss: nan
agent1:                 episode reward: 0.5717,                 loss: 0.3594
Episode: 23781/30000 (79.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8299s / 721.9756 s
agent0:                 episode reward: -0.6819,                 loss: nan
agent1:                 episode reward: 0.6819,                 loss: 0.3628
Episode: 23801/30000 (79.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8229s / 722.7985 s
agent0:                 episode reward: -0.4784,                 loss: nan
agent1:                 episode reward: 0.4784,                 loss: 0.3598
Episode: 23821/30000 (79.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8249s / 723.6234 s
agent0:                 episode reward: -0.3897,                 loss: nan
agent1:                 episode reward: 0.3897,                 loss: 0.3598
Episode: 23841/30000 (79.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8137s / 724.4371 s
agent0:                 episode reward: -0.7570,                 loss: nan
agent1:                 episode reward: 0.7570,                 loss: 0.3601
Episode: 23861/30000 (79.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8135s / 725.2506 s
agent0:                 episode reward: -0.2623,                 loss: nan
agent1:                 episode reward: 0.2623,                 loss: 0.3610
Episode: 23881/30000 (79.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8303s / 726.0808 s
agent0:                 episode reward: -0.9054,                 loss: nan
agent1:                 episode reward: 0.9054,                 loss: 0.3580
Episode: 23901/30000 (79.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8418s / 726.9227 s
agent0:                 episode reward: -0.4532,                 loss: nan
agent1:                 episode reward: 0.4532,                 loss: 0.3593
Episode: 23921/30000 (79.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8169s / 727.7396 s
agent0:                 episode reward: -0.7383,                 loss: nan
agent1:                 episode reward: 0.7383,                 loss: 0.3591
Episode: 23941/30000 (79.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8176s / 728.5572 s
agent0:                 episode reward: -0.5112,                 loss: nan
agent1:                 episode reward: 0.5112,                 loss: 0.3605
Episode: 23961/30000 (79.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8365s / 729.3937 s
agent0:                 episode reward: -0.4588,                 loss: nan
agent1:                 episode reward: 0.4588,                 loss: 0.3592
Episode: 23981/30000 (79.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8193s / 730.2130 s
agent0:                 episode reward: -0.4492,                 loss: nan
agent1:                 episode reward: 0.4492,                 loss: 0.3579
Episode: 24001/30000 (80.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8362s / 731.0492 s
agent0:                 episode reward: -0.1526,                 loss: nan
agent1:                 episode reward: 0.1526,                 loss: 0.3578
Episode: 24021/30000 (80.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8184s / 731.8676 s
agent0:                 episode reward: -0.5943,                 loss: nan
agent1:                 episode reward: 0.5943,                 loss: 0.3552
Episode: 24041/30000 (80.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8180s / 732.6856 s
agent0:                 episode reward: -0.6199,                 loss: nan
agent1:                 episode reward: 0.6199,                 loss: 0.3538
Episode: 24061/30000 (80.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8230s / 733.5086 s
agent0:                 episode reward: -0.4482,                 loss: nan
agent1:                 episode reward: 0.4482,                 loss: 0.3554
Episode: 24081/30000 (80.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8340s / 734.3426 s
agent0:                 episode reward: -0.2979,                 loss: nan
agent1:                 episode reward: 0.2979,                 loss: 0.3531
Episode: 24101/30000 (80.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8111s / 735.1537 s
agent0:                 episode reward: -0.2207,                 loss: nan
agent1:                 episode reward: 0.2207,                 loss: 0.3536
Episode: 24121/30000 (80.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8273s / 735.9810 s
agent0:                 episode reward: -0.6512,                 loss: nan
agent1:                 episode reward: 0.6512,                 loss: 0.3553
Episode: 24141/30000 (80.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8267s / 736.8077 s
agent0:                 episode reward: -0.4287,                 loss: nan
agent1:                 episode reward: 0.4287,                 loss: 0.3527
Episode: 24161/30000 (80.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8287s / 737.6364 s
agent0:                 episode reward: -0.9116,                 loss: nan
agent1:                 episode reward: 0.9116,                 loss: 0.3537
Episode: 24181/30000 (80.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8426s / 738.4790 s
agent0:                 episode reward: -0.4857,                 loss: nan
agent1:                 episode reward: 0.4857,                 loss: 0.3567
Episode: 24201/30000 (80.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8176s / 739.2966 s
agent0:                 episode reward: -0.3498,                 loss: nan
agent1:                 episode reward: 0.3498,                 loss: 0.3508
Episode: 24221/30000 (80.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8363s / 740.1329 s
agent0:                 episode reward: -0.3066,                 loss: nan
agent1:                 episode reward: 0.3066,                 loss: 0.3510
Episode: 24241/30000 (80.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8447s / 740.9776 s
agent0:                 episode reward: -0.2797,                 loss: nan
agent1:                 episode reward: 0.2797,                 loss: 0.3538
Episode: 24261/30000 (80.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8285s / 741.8061 s
agent0:                 episode reward: -0.4952,                 loss: nan
agent1:                 episode reward: 0.4952,                 loss: 0.3547
Episode: 24281/30000 (80.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8364s / 742.6424 s
agent0:                 episode reward: -0.5371,                 loss: nan
agent1:                 episode reward: 0.5371,                 loss: 0.3539
Episode: 24301/30000 (81.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8555s / 743.4980 s
agent0:                 episode reward: -0.4102,                 loss: nan
agent1:                 episode reward: 0.4102,                 loss: 0.3533
Episode: 24321/30000 (81.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8286s / 744.3266 s
agent0:                 episode reward: -0.4822,                 loss: nan
agent1:                 episode reward: 0.4822,                 loss: 0.3542
Episode: 24341/30000 (81.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8282s / 745.1548 s
agent0:                 episode reward: -0.2191,                 loss: nan
agent1:                 episode reward: 0.2191,                 loss: 0.3634
Episode: 24361/30000 (81.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8512s / 746.0060 s
agent0:                 episode reward: -0.1529,                 loss: nan
agent1:                 episode reward: 0.1529,                 loss: 0.3721
Episode: 24381/30000 (81.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8413s / 746.8473 s
agent0:                 episode reward: -0.4022,                 loss: nan
agent1:                 episode reward: 0.4022,                 loss: 0.3748
Episode: 24401/30000 (81.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8466s / 747.6938 s
agent0:                 episode reward: -0.5301,                 loss: nan
agent1:                 episode reward: 0.5301,                 loss: 0.3752
Episode: 24421/30000 (81.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8223s / 748.5161 s
agent0:                 episode reward: -0.5157,                 loss: nan
agent1:                 episode reward: 0.5157,                 loss: 0.3748
Episode: 24441/30000 (81.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8281s / 749.3442 s
agent0:                 episode reward: -0.2867,                 loss: nan
agent1:                 episode reward: 0.2867,                 loss: 0.3742
Episode: 24461/30000 (81.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8269s / 750.1711 s
agent0:                 episode reward: -0.4757,                 loss: nan
agent1:                 episode reward: 0.4757,                 loss: 0.3763
Episode: 24481/30000 (81.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8326s / 751.0036 s
agent0:                 episode reward: -0.8717,                 loss: nan
agent1:                 episode reward: 0.8717,                 loss: 0.3746
Episode: 24501/30000 (81.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8337s / 751.8374 s
agent0:                 episode reward: -0.6051,                 loss: nan
agent1:                 episode reward: 0.6051,                 loss: 0.3736
Episode: 24521/30000 (81.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8210s / 752.6584 s
agent0:                 episode reward: -0.5420,                 loss: nan
agent1:                 episode reward: 0.5420,                 loss: 0.3749
Episode: 24541/30000 (81.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8272s / 753.4856 s
agent0:                 episode reward: -0.3203,                 loss: nan
agent1:                 episode reward: 0.3203,                 loss: 0.3720
Episode: 24561/30000 (81.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8292s / 754.3148 s
agent0:                 episode reward: -0.3298,                 loss: nan
agent1:                 episode reward: 0.3298,                 loss: 0.3750
Episode: 24581/30000 (81.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8288s / 755.1436 s
agent0:                 episode reward: -0.6966,                 loss: nan
agent1:                 episode reward: 0.6966,                 loss: 0.3754
Episode: 24601/30000 (82.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8310s / 755.9746 s
agent0:                 episode reward: -0.3795,                 loss: nan
agent1:                 episode reward: 0.3795,                 loss: 0.3769
Episode: 24621/30000 (82.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8307s / 756.8053 s
agent0:                 episode reward: -0.3340,                 loss: nan
agent1:                 episode reward: 0.3340,                 loss: 0.3744
Episode: 24641/30000 (82.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8358s / 757.6410 s
agent0:                 episode reward: -0.7217,                 loss: nan
agent1:                 episode reward: 0.7217,                 loss: 0.3729
Episode: 24661/30000 (82.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8275s / 758.4685 s
agent0:                 episode reward: -0.6565,                 loss: nan
agent1:                 episode reward: 0.6565,                 loss: 0.3749
Episode: 24681/30000 (82.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8425s / 759.3110 s
agent0:                 episode reward: -0.5396,                 loss: nan
agent1:                 episode reward: 0.5396,                 loss: 0.3628
Episode: 24701/30000 (82.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8269s / 760.1380 s
agent0:                 episode reward: -0.8114,                 loss: nan
agent1:                 episode reward: 0.8114,                 loss: 0.3581
Episode: 24721/30000 (82.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8316s / 760.9696 s
agent0:                 episode reward: -0.6259,                 loss: nan
agent1:                 episode reward: 0.6259,                 loss: 0.3592
Episode: 24741/30000 (82.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8392s / 761.8088 s
agent0:                 episode reward: -0.5990,                 loss: nan
agent1:                 episode reward: 0.5990,                 loss: 0.3549
Episode: 24761/30000 (82.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8400s / 762.6488 s
agent0:                 episode reward: -0.3510,                 loss: nan
agent1:                 episode reward: 0.3510,                 loss: 0.3560
Episode: 24781/30000 (82.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8387s / 763.4875 s
agent0:                 episode reward: -0.7114,                 loss: nan
agent1:                 episode reward: 0.7114,                 loss: 0.3611
Episode: 24801/30000 (82.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8504s / 764.3379 s
agent0:                 episode reward: -0.7280,                 loss: nan
agent1:                 episode reward: 0.7280,                 loss: 0.3620
Episode: 24821/30000 (82.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8474s / 765.1852 s
agent0:                 episode reward: -0.6385,                 loss: nan
agent1:                 episode reward: 0.6385,                 loss: 0.3571
Episode: 24841/30000 (82.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8395s / 766.0247 s
agent0:                 episode reward: -0.6401,                 loss: nan
agent1:                 episode reward: 0.6401,                 loss: 0.3575
Episode: 24861/30000 (82.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8340s / 766.8588 s
agent0:                 episode reward: -0.3611,                 loss: nan
agent1:                 episode reward: 0.3611,                 loss: 0.3576
Episode: 24881/30000 (82.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8462s / 767.7050 s
agent0:                 episode reward: -0.4184,                 loss: nan
agent1:                 episode reward: 0.4184,                 loss: 0.3577
Episode: 24901/30000 (83.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8373s / 768.5423 s
agent0:                 episode reward: -0.5565,                 loss: nan
agent1:                 episode reward: 0.5565,                 loss: 0.3581
Episode: 24921/30000 (83.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8422s / 769.3845 s
agent0:                 episode reward: -0.2898,                 loss: nan
agent1:                 episode reward: 0.2898,                 loss: 0.3590
Episode: 24941/30000 (83.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8424s / 770.2268 s
agent0:                 episode reward: -0.6489,                 loss: nan
agent1:                 episode reward: 0.6489,                 loss: 0.3618
Episode: 24961/30000 (83.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8351s / 771.0620 s
agent0:                 episode reward: -0.3066,                 loss: nan
agent1:                 episode reward: 0.3066,                 loss: 0.3590
Episode: 24981/30000 (83.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8432s / 771.9052 s
agent0:                 episode reward: -0.5610,                 loss: nan
agent1:                 episode reward: 0.5610,                 loss: 0.3607
Episode: 25001/30000 (83.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8431s / 772.7483 s
agent0:                 episode reward: -0.5437,                 loss: nan
agent1:                 episode reward: 0.5437,                 loss: 0.3575
Episode: 25021/30000 (83.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8384s / 773.5867 s
agent0:                 episode reward: -0.6791,                 loss: nan
agent1:                 episode reward: 0.6791,                 loss: 0.3573
Episode: 25041/30000 (83.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8412s / 774.4280 s
agent0:                 episode reward: -0.6450,                 loss: nan
agent1:                 episode reward: 0.6450,                 loss: 0.3589
Episode: 25061/30000 (83.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8429s / 775.2709 s
agent0:                 episode reward: -0.6944,                 loss: nan
agent1:                 episode reward: 0.6944,                 loss: 0.3606
Episode: 25081/30000 (83.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8567s / 776.1276 s
agent0:                 episode reward: -0.5415,                 loss: nan
agent1:                 episode reward: 0.5415,                 loss: 0.3578
Episode: 25101/30000 (83.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8489s / 776.9764 s
agent0:                 episode reward: -0.3640,                 loss: nan
agent1:                 episode reward: 0.3640,                 loss: 0.3579
Episode: 25121/30000 (83.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8503s / 777.8268 s
agent0:                 episode reward: -0.6172,                 loss: nan
agent1:                 episode reward: 0.6172,                 loss: 0.3611
Episode: 25141/30000 (83.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8554s / 778.6821 s
agent0:                 episode reward: -0.3354,                 loss: nan
agent1:                 episode reward: 0.3354,                 loss: 0.3586
Episode: 25161/30000 (83.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8502s / 779.5323 s
agent0:                 episode reward: -0.5707,                 loss: nan
agent1:                 episode reward: 0.5707,                 loss: 0.3606
Episode: 25181/30000 (83.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8492s / 780.3816 s
agent0:                 episode reward: -0.8121,                 loss: nan
agent1:                 episode reward: 0.8121,                 loss: 0.3556
Episode: 25201/30000 (84.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8563s / 781.2379 s
agent0:                 episode reward: -0.2862,                 loss: nan
agent1:                 episode reward: 0.2862,                 loss: 0.3597
Episode: 25221/30000 (84.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8596s / 782.0975 s
agent0:                 episode reward: -0.0297,                 loss: nan
agent1:                 episode reward: 0.0297,                 loss: 0.3609
Episode: 25241/30000 (84.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8543s / 782.9518 s
agent0:                 episode reward: -0.2956,                 loss: nan
agent1:                 episode reward: 0.2956,                 loss: 0.3582
Episode: 25261/30000 (84.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8734s / 783.8252 s
agent0:                 episode reward: -0.7213,                 loss: nan
agent1:                 episode reward: 0.7213,                 loss: 0.3570
Episode: 25281/30000 (84.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8499s / 784.6750 s
agent0:                 episode reward: -0.7460,                 loss: nan
agent1:                 episode reward: 0.7460,                 loss: 0.3584
Episode: 25301/30000 (84.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8504s / 785.5255 s
agent0:                 episode reward: -0.7614,                 loss: nan
agent1:                 episode reward: 0.7614,                 loss: 0.3596
Episode: 25321/30000 (84.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8529s / 786.3784 s
agent0:                 episode reward: -0.2461,                 loss: nan
agent1:                 episode reward: 0.2461,                 loss: 0.3576
Episode: 25341/30000 (84.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8846s / 787.2630 s
agent0:                 episode reward: -0.4706,                 loss: nan
agent1:                 episode reward: 0.4706,                 loss: 0.3659
Episode: 25361/30000 (84.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8566s / 788.1195 s
agent0:                 episode reward: -0.2843,                 loss: nan
agent1:                 episode reward: 0.2843,                 loss: 0.3703
Episode: 25381/30000 (84.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8493s / 788.9689 s
agent0:                 episode reward: -0.3962,                 loss: nan
agent1:                 episode reward: 0.3962,                 loss: 0.3702
Episode: 25401/30000 (84.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8605s / 789.8294 s
agent0:                 episode reward: -0.7710,                 loss: nan
agent1:                 episode reward: 0.7710,                 loss: 0.3727
Episode: 25421/30000 (84.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8443s / 790.6737 s
agent0:                 episode reward: -0.5241,                 loss: nan
agent1:                 episode reward: 0.5241,                 loss: 0.3713
Episode: 25441/30000 (84.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8569s / 791.5306 s
agent0:                 episode reward: -0.6510,                 loss: nan
agent1:                 episode reward: 0.6510,                 loss: 0.3686
Episode: 25461/30000 (84.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8485s / 792.3792 s
agent0:                 episode reward: -0.3866,                 loss: nan
agent1:                 episode reward: 0.3866,                 loss: 0.3671
Episode: 25481/30000 (84.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8580s / 793.2372 s
agent0:                 episode reward: -0.6676,                 loss: nan
agent1:                 episode reward: 0.6676,                 loss: 0.3702
Episode: 25501/30000 (85.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8539s / 794.0911 s
agent0:                 episode reward: -0.6046,                 loss: nan
agent1:                 episode reward: 0.6046,                 loss: 0.3713
Episode: 25521/30000 (85.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8485s / 794.9396 s
agent0:                 episode reward: -0.5252,                 loss: nan
agent1:                 episode reward: 0.5252,                 loss: 0.3676
Episode: 25541/30000 (85.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8496s / 795.7892 s
agent0:                 episode reward: 0.0336,                 loss: nan
agent1:                 episode reward: -0.0336,                 loss: 0.3697
Episode: 25561/30000 (85.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8590s / 796.6482 s
agent0:                 episode reward: -0.8775,                 loss: nan
agent1:                 episode reward: 0.8775,                 loss: 0.3670
Episode: 25581/30000 (85.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8489s / 797.4970 s
agent0:                 episode reward: -0.8080,                 loss: nan
agent1:                 episode reward: 0.8080,                 loss: 0.3718
Episode: 25601/30000 (85.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8611s / 798.3581 s
agent0:                 episode reward: -0.2569,                 loss: nan
agent1:                 episode reward: 0.2569,                 loss: 0.3693
Episode: 25621/30000 (85.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8557s / 799.2138 s
agent0:                 episode reward: -0.6485,                 loss: nan
agent1:                 episode reward: 0.6485,                 loss: 0.3685
Episode: 25641/30000 (85.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8634s / 800.0772 s
agent0:                 episode reward: -0.3213,                 loss: nan
agent1:                 episode reward: 0.3213,                 loss: 0.3707
Episode: 25661/30000 (85.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8691s / 800.9463 s
agent0:                 episode reward: -0.3599,                 loss: nan
agent1:                 episode reward: 0.3599,                 loss: 0.3693
Episode: 25681/30000 (85.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8633s / 801.8096 s
agent0:                 episode reward: -0.2032,                 loss: nan
agent1:                 episode reward: 0.2032,                 loss: 0.3615
Episode: 25701/30000 (85.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8605s / 802.6701 s
agent0:                 episode reward: -0.7743,                 loss: nan
agent1:                 episode reward: 0.7743,                 loss: 0.3586
Episode: 25721/30000 (85.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8522s / 803.5223 s
agent0:                 episode reward: -0.4003,                 loss: nan
agent1:                 episode reward: 0.4003,                 loss: 0.3528
Episode: 25741/30000 (85.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8511s / 804.3735 s
agent0:                 episode reward: -0.6645,                 loss: nan
agent1:                 episode reward: 0.6645,                 loss: 0.3553
Episode: 25761/30000 (85.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8693s / 805.2428 s
agent0:                 episode reward: -0.1470,                 loss: nan
agent1:                 episode reward: 0.1470,                 loss: 0.3534
Episode: 25781/30000 (85.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8562s / 806.0989 s
agent0:                 episode reward: -0.5726,                 loss: nan
agent1:                 episode reward: 0.5726,                 loss: 0.3544
Episode: 25801/30000 (86.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8576s / 806.9566 s
agent0:                 episode reward: -0.4691,                 loss: nan
agent1:                 episode reward: 0.4691,                 loss: 0.3503
Episode: 25821/30000 (86.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8581s / 807.8147 s
agent0:                 episode reward: -0.6298,                 loss: nan
agent1:                 episode reward: 0.6298,                 loss: 0.3562
Episode: 25841/30000 (86.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8748s / 808.6895 s
agent0:                 episode reward: -0.2865,                 loss: nan
agent1:                 episode reward: 0.2865,                 loss: 0.3533
Episode: 25861/30000 (86.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8551s / 809.5446 s
agent0:                 episode reward: -0.3651,                 loss: nan
agent1:                 episode reward: 0.3651,                 loss: 0.3514
Episode: 25881/30000 (86.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8703s / 810.4149 s
agent0:                 episode reward: -0.7973,                 loss: nan
agent1:                 episode reward: 0.7973,                 loss: 0.3556
Episode: 25901/30000 (86.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8713s / 811.2862 s
agent0:                 episode reward: -0.2930,                 loss: nan
agent1:                 episode reward: 0.2930,                 loss: 0.3533
Episode: 25921/30000 (86.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8616s / 812.1479 s
agent0:                 episode reward: -0.7958,                 loss: nan
agent1:                 episode reward: 0.7958,                 loss: 0.3554
Episode: 25941/30000 (86.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8753s / 813.0232 s
agent0:                 episode reward: -0.7348,                 loss: nan
agent1:                 episode reward: 0.7348,                 loss: 0.3524
Episode: 25961/30000 (86.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8706s / 813.8938 s
agent0:                 episode reward: -0.6664,                 loss: nan
agent1:                 episode reward: 0.6664,                 loss: 0.3557
Episode: 25981/30000 (86.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8665s / 814.7602 s
agent0:                 episode reward: -0.2196,                 loss: nan
agent1:                 episode reward: 0.2196,                 loss: 0.3560
Episode: 26001/30000 (86.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8610s / 815.6212 s
agent0:                 episode reward: 0.2358,                 loss: nan
agent1:                 episode reward: -0.2358,                 loss: 0.3577
Episode: 26021/30000 (86.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8757s / 816.4968 s
agent0:                 episode reward: -0.3719,                 loss: nan
agent1:                 episode reward: 0.3719,                 loss: 0.3737
Episode: 26041/30000 (86.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8572s / 817.3540 s
agent0:                 episode reward: -0.6233,                 loss: nan
agent1:                 episode reward: 0.6233,                 loss: 0.3726
Episode: 26061/30000 (86.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8671s / 818.2212 s
agent0:                 episode reward: -0.6704,                 loss: nan
agent1:                 episode reward: 0.6704,                 loss: 0.3706
Episode: 26081/30000 (86.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8750s / 819.0962 s
agent0:                 episode reward: -0.4802,                 loss: nan
agent1:                 episode reward: 0.4802,                 loss: 0.3682
Episode: 26101/30000 (87.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8593s / 819.9555 s
agent0:                 episode reward: -0.6388,                 loss: nan
agent1:                 episode reward: 0.6388,                 loss: 0.3709
Episode: 26121/30000 (87.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8711s / 820.8266 s
agent0:                 episode reward: -0.3050,                 loss: nan
agent1:                 episode reward: 0.3050,                 loss: 0.3700
Episode: 26141/30000 (87.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8587s / 821.6853 s
agent0:                 episode reward: -0.3808,                 loss: nan
agent1:                 episode reward: 0.3808,                 loss: 0.3683
Episode: 26161/30000 (87.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8650s / 822.5503 s
agent0:                 episode reward: -0.2330,                 loss: nan
agent1:                 episode reward: 0.2330,                 loss: 0.3693
Episode: 26181/30000 (87.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8703s / 823.4206 s
agent0:                 episode reward: -0.3297,                 loss: nan
agent1:                 episode reward: 0.3297,                 loss: 0.3683
Episode: 26201/30000 (87.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8740s / 824.2947 s
agent0:                 episode reward: -0.1843,                 loss: nan
agent1:                 episode reward: 0.1843,                 loss: 0.3723
Episode: 26221/30000 (87.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8656s / 825.1602 s
agent0:                 episode reward: -0.7534,                 loss: nan
agent1:                 episode reward: 0.7534,                 loss: 0.3715
Episode: 26241/30000 (87.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8769s / 826.0371 s
agent0:                 episode reward: -0.4003,                 loss: nan
agent1:                 episode reward: 0.4003,                 loss: 0.3699
Episode: 26261/30000 (87.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8761s / 826.9132 s
agent0:                 episode reward: -0.4591,                 loss: nan
agent1:                 episode reward: 0.4591,                 loss: 0.3714
Episode: 26281/30000 (87.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8911s / 827.8042 s
agent0:                 episode reward: -0.5090,                 loss: nan
agent1:                 episode reward: 0.5090,                 loss: 0.3704
Episode: 26301/30000 (87.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8907s / 828.6949 s
agent0:                 episode reward: -0.9565,                 loss: nan
agent1:                 episode reward: 0.9565,                 loss: 0.3708
Episode: 26321/30000 (87.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9038s / 829.5987 s
agent0:                 episode reward: -0.6196,                 loss: nan
agent1:                 episode reward: 0.6196,                 loss: 0.3724
Episode: 26341/30000 (87.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8839s / 830.4826 s
agent0:                 episode reward: -0.4793,                 loss: nan
agent1:                 episode reward: 0.4793,                 loss: 0.3712
Episode: 26361/30000 (87.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8618s / 831.3444 s
agent0:                 episode reward: -0.7895,                 loss: nan
agent1:                 episode reward: 0.7895,                 loss: 0.3700
Episode: 26381/30000 (87.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8679s / 832.2123 s
agent0:                 episode reward: -0.1543,                 loss: nan
agent1:                 episode reward: 0.1543,                 loss: 0.3739
Episode: 26401/30000 (88.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8672s / 833.0795 s
agent0:                 episode reward: -0.3805,                 loss: nan
agent1:                 episode reward: 0.3805,                 loss: 0.3729
Episode: 26421/30000 (88.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8704s / 833.9499 s
agent0:                 episode reward: -0.5384,                 loss: nan
agent1:                 episode reward: 0.5384,                 loss: 0.3704
Episode: 26441/30000 (88.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8790s / 834.8289 s
agent0:                 episode reward: -0.6522,                 loss: nan
agent1:                 episode reward: 0.6522,                 loss: 0.3731
Episode: 26461/30000 (88.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8893s / 835.7182 s
agent0:                 episode reward: -0.6509,                 loss: nan
agent1:                 episode reward: 0.6509,                 loss: 0.3713
Episode: 26481/30000 (88.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8746s / 836.5928 s
agent0:                 episode reward: -0.3358,                 loss: nan
agent1:                 episode reward: 0.3358,                 loss: 0.3699
Episode: 26501/30000 (88.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8806s / 837.4734 s
agent0:                 episode reward: -0.2630,                 loss: nan
agent1:                 episode reward: 0.2630,                 loss: 0.3713
Episode: 26521/30000 (88.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8876s / 838.3611 s
agent0:                 episode reward: -0.6634,                 loss: nan
agent1:                 episode reward: 0.6634,                 loss: 0.3734
Episode: 26541/30000 (88.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8866s / 839.2477 s
agent0:                 episode reward: -0.4396,                 loss: nan
agent1:                 episode reward: 0.4396,                 loss: 0.3705
Episode: 26561/30000 (88.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8842s / 840.1319 s
agent0:                 episode reward: -0.4665,                 loss: nan
agent1:                 episode reward: 0.4665,                 loss: 0.3707
Episode: 26581/30000 (88.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8822s / 841.0141 s
agent0:                 episode reward: -0.0648,                 loss: nan
agent1:                 episode reward: 0.0648,                 loss: 0.3697
Episode: 26601/30000 (88.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8712s / 841.8853 s
agent0:                 episode reward: -0.3090,                 loss: nan
agent1:                 episode reward: 0.3090,                 loss: 0.3706
Episode: 26621/30000 (88.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8796s / 842.7649 s
agent0:                 episode reward: -0.3204,                 loss: nan
agent1:                 episode reward: 0.3204,                 loss: 0.3723
Episode: 26641/30000 (88.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8750s / 843.6398 s
agent0:                 episode reward: -0.4895,                 loss: nan
agent1:                 episode reward: 0.4895,                 loss: 0.3692
Episode: 26661/30000 (88.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8789s / 844.5187 s
agent0:                 episode reward: -0.6564,                 loss: nan
agent1:                 episode reward: 0.6564,                 loss: 0.3704
Episode: 26681/30000 (88.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9141s / 845.4328 s
agent0:                 episode reward: -0.4528,                 loss: nan
agent1:                 episode reward: 0.4528,                 loss: 0.3610
Episode: 26701/30000 (89.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8782s / 846.3110 s
agent0:                 episode reward: -0.5358,                 loss: nan
agent1:                 episode reward: 0.5358,                 loss: 0.3536
Episode: 26721/30000 (89.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8744s / 847.1854 s
agent0:                 episode reward: -0.5658,                 loss: nan
agent1:                 episode reward: 0.5658,                 loss: 0.3534
Episode: 26741/30000 (89.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8800s / 848.0653 s
agent0:                 episode reward: -0.7564,                 loss: nan
agent1:                 episode reward: 0.7564,                 loss: 0.3531
Episode: 26761/30000 (89.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8851s / 848.9504 s
agent0:                 episode reward: -0.6215,                 loss: nan
agent1:                 episode reward: 0.6215,                 loss: 0.3546
Episode: 26781/30000 (89.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8751s / 849.8255 s
agent0:                 episode reward: -0.7773,                 loss: nan
agent1:                 episode reward: 0.7773,                 loss: 0.3539
Episode: 26801/30000 (89.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8901s / 850.7156 s
agent0:                 episode reward: -0.4357,                 loss: nan
agent1:                 episode reward: 0.4357,                 loss: 0.3518
Episode: 26821/30000 (89.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9102s / 851.6258 s
agent0:                 episode reward: -0.2730,                 loss: nan
agent1:                 episode reward: 0.2730,                 loss: 0.3565
Episode: 26841/30000 (89.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9135s / 852.5393 s
agent0:                 episode reward: -0.5017,                 loss: nan
agent1:                 episode reward: 0.5017,                 loss: 0.3556
Episode: 26861/30000 (89.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8790s / 853.4183 s
agent0:                 episode reward: -0.9651,                 loss: nan
agent1:                 episode reward: 0.9651,                 loss: 0.3536
Episode: 26881/30000 (89.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8946s / 854.3129 s
agent0:                 episode reward: -0.9533,                 loss: nan
agent1:                 episode reward: 0.9533,                 loss: 0.3546
Episode: 26901/30000 (89.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8883s / 855.2012 s
agent0:                 episode reward: -0.0524,                 loss: nan
agent1:                 episode reward: 0.0524,                 loss: 0.3529
Episode: 26921/30000 (89.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8800s / 856.0812 s
agent0:                 episode reward: -0.4866,                 loss: nan
agent1:                 episode reward: 0.4866,                 loss: 0.3553
Episode: 26941/30000 (89.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8720s / 856.9533 s
agent0:                 episode reward: -0.6023,                 loss: nan
agent1:                 episode reward: 0.6023,                 loss: 0.3555
Episode: 26961/30000 (89.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8854s / 857.8386 s
agent0:                 episode reward: -0.5546,                 loss: nan
agent1:                 episode reward: 0.5546,                 loss: 0.3539
Episode: 26981/30000 (89.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8865s / 858.7252 s
agent0:                 episode reward: -0.9239,                 loss: nan
agent1:                 episode reward: 0.9239,                 loss: 0.3550
Episode: 27001/30000 (90.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8761s / 859.6012 s
agent0:                 episode reward: -0.5800,                 loss: nan
agent1:                 episode reward: 0.5800,                 loss: 0.3571
Episode: 27021/30000 (90.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8670s / 860.4683 s
agent0:                 episode reward: -0.6151,                 loss: nan
agent1:                 episode reward: 0.6151,                 loss: 0.3610
Episode: 27041/30000 (90.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8991s / 861.3674 s
agent0:                 episode reward: -0.2667,                 loss: nan
agent1:                 episode reward: 0.2667,                 loss: 0.3621
Episode: 27061/30000 (90.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8792s / 862.2466 s
agent0:                 episode reward: -0.3154,                 loss: nan
agent1:                 episode reward: 0.3154,                 loss: 0.3610
Episode: 27081/30000 (90.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9081s / 863.1548 s
agent0:                 episode reward: -0.5501,                 loss: nan
agent1:                 episode reward: 0.5501,                 loss: 0.3628
Episode: 27101/30000 (90.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8824s / 864.0371 s
agent0:                 episode reward: -0.4378,                 loss: nan
agent1:                 episode reward: 0.4378,                 loss: 0.3648
Episode: 27121/30000 (90.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8725s / 864.9096 s
agent0:                 episode reward: -0.7794,                 loss: nan
agent1:                 episode reward: 0.7794,                 loss: 0.3629
Episode: 27141/30000 (90.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8927s / 865.8022 s
agent0:                 episode reward: -0.4399,                 loss: nan
agent1:                 episode reward: 0.4399,                 loss: 0.3577
Episode: 27161/30000 (90.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8828s / 866.6851 s
agent0:                 episode reward: -0.3788,                 loss: nan
agent1:                 episode reward: 0.3788,                 loss: 0.3626
Episode: 27181/30000 (90.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8854s / 867.5705 s
agent0:                 episode reward: -0.6397,                 loss: nan
agent1:                 episode reward: 0.6397,                 loss: 0.3617
Episode: 27201/30000 (90.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8968s / 868.4673 s
agent0:                 episode reward: -0.7005,                 loss: nan
agent1:                 episode reward: 0.7005,                 loss: 0.3617
Episode: 27221/30000 (90.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9039s / 869.3712 s
agent0:                 episode reward: -0.4504,                 loss: nan
agent1:                 episode reward: 0.4504,                 loss: 0.3622
Episode: 27241/30000 (90.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8948s / 870.2660 s
agent0:                 episode reward: -0.5337,                 loss: nan
agent1:                 episode reward: 0.5337,                 loss: 0.3639
Episode: 27261/30000 (90.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9003s / 871.1663 s
agent0:                 episode reward: -0.9103,                 loss: nan
agent1:                 episode reward: 0.9103,                 loss: 0.3624
Episode: 27281/30000 (90.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9000s / 872.0662 s
agent0:                 episode reward: -0.5593,                 loss: nan
agent1:                 episode reward: 0.5593,                 loss: 0.3605
Episode: 27301/30000 (91.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9075s / 872.9737 s
agent0:                 episode reward: -0.7042,                 loss: nan
agent1:                 episode reward: 0.7042,                 loss: 0.3620
Episode: 27321/30000 (91.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8949s / 873.8687 s
agent0:                 episode reward: -0.7544,                 loss: nan
agent1:                 episode reward: 0.7544,                 loss: 0.3594
Episode: 27341/30000 (91.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8884s / 874.7571 s
agent0:                 episode reward: -0.7976,                 loss: nan
agent1:                 episode reward: 0.7976,                 loss: 0.3665
Episode: 27361/30000 (91.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8973s / 875.6544 s
agent0:                 episode reward: -0.3811,                 loss: nan
agent1:                 episode reward: 0.3811,                 loss: 0.3670
Episode: 27381/30000 (91.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8798s / 876.5342 s
agent0:                 episode reward: -0.4022,                 loss: nan
agent1:                 episode reward: 0.4022,                 loss: 0.3702
Episode: 27401/30000 (91.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8970s / 877.4312 s
agent0:                 episode reward: -0.3684,                 loss: nan
agent1:                 episode reward: 0.3684,                 loss: 0.3649
Episode: 27421/30000 (91.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8823s / 878.3134 s
agent0:                 episode reward: -0.6306,                 loss: nan
agent1:                 episode reward: 0.6306,                 loss: 0.3657
Episode: 27441/30000 (91.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8986s / 879.2120 s
agent0:                 episode reward: -0.4660,                 loss: nan
agent1:                 episode reward: 0.4660,                 loss: 0.3663
Episode: 27461/30000 (91.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8858s / 880.0978 s
agent0:                 episode reward: -0.5034,                 loss: nan
agent1:                 episode reward: 0.5034,                 loss: 0.3658
Episode: 27481/30000 (91.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8865s / 880.9842 s
agent0:                 episode reward: -0.4585,                 loss: nan
agent1:                 episode reward: 0.4585,                 loss: 0.3688
Episode: 27501/30000 (91.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9101s / 881.8943 s
agent0:                 episode reward: -0.2644,                 loss: nan
agent1:                 episode reward: 0.2644,                 loss: 0.3658
Episode: 27521/30000 (91.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8910s / 882.7854 s
agent0:                 episode reward: -0.2647,                 loss: nan
agent1:                 episode reward: 0.2647,                 loss: 0.3657
Episode: 27541/30000 (91.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9049s / 883.6903 s
agent0:                 episode reward: -0.6881,                 loss: nan
agent1:                 episode reward: 0.6881,                 loss: 0.3643
Episode: 27561/30000 (91.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8950s / 884.5853 s
agent0:                 episode reward: -0.3737,                 loss: nan
agent1:                 episode reward: 0.3737,                 loss: 0.3659
Episode: 27581/30000 (91.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9060s / 885.4913 s
agent0:                 episode reward: -0.3623,                 loss: nan
agent1:                 episode reward: 0.3623,                 loss: 0.3700
Episode: 27601/30000 (92.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8997s / 886.3911 s
agent0:                 episode reward: -1.1057,                 loss: nan
agent1:                 episode reward: 1.1057,                 loss: 0.3674
Episode: 27621/30000 (92.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9026s / 887.2936 s
agent0:                 episode reward: -0.3993,                 loss: nan
agent1:                 episode reward: 0.3993,                 loss: 0.3666
Episode: 27641/30000 (92.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9186s / 888.2123 s
agent0:                 episode reward: -0.2258,                 loss: nan
agent1:                 episode reward: 0.2258,                 loss: 0.3682
Episode: 27661/30000 (92.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9051s / 889.1174 s
agent0:                 episode reward: -0.3617,                 loss: nan
agent1:                 episode reward: 0.3617,                 loss: 0.3684
Episode: 27681/30000 (92.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9052s / 890.0226 s
agent0:                 episode reward: -0.4767,                 loss: nan
agent1:                 episode reward: 0.4767,                 loss: 0.3570
Episode: 27701/30000 (92.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9150s / 890.9377 s
agent0:                 episode reward: -0.7299,                 loss: nan
agent1:                 episode reward: 0.7299,                 loss: 0.3498
Episode: 27721/30000 (92.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8920s / 891.8297 s
agent0:                 episode reward: -0.5792,                 loss: nan
agent1:                 episode reward: 0.5792,                 loss: 0.3504
Episode: 27741/30000 (92.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9189s / 892.7486 s
agent0:                 episode reward: -0.4445,                 loss: nan
agent1:                 episode reward: 0.4445,                 loss: 0.3512
Episode: 27761/30000 (92.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9017s / 893.6503 s
agent0:                 episode reward: -0.5175,                 loss: nan
agent1:                 episode reward: 0.5175,                 loss: 0.3469
Episode: 27781/30000 (92.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9343s / 894.5845 s
agent0:                 episode reward: -0.6685,                 loss: nan
agent1:                 episode reward: 0.6685,                 loss: 0.3527
Episode: 27801/30000 (92.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9136s / 895.4981 s
agent0:                 episode reward: -0.7454,                 loss: nan
agent1:                 episode reward: 0.7454,                 loss: 0.3527
Episode: 27821/30000 (92.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8941s / 896.3922 s
agent0:                 episode reward: -0.5407,                 loss: nan
agent1:                 episode reward: 0.5407,                 loss: 0.3488
Episode: 27841/30000 (92.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8989s / 897.2911 s
agent0:                 episode reward: -0.6598,                 loss: nan
agent1:                 episode reward: 0.6598,                 loss: 0.3492
Episode: 27861/30000 (92.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8944s / 898.1854 s
agent0:                 episode reward: -0.5260,                 loss: nan
agent1:                 episode reward: 0.5260,                 loss: 0.3482
Episode: 27881/30000 (92.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9040s / 899.0894 s
agent0:                 episode reward: -0.9649,                 loss: nan
agent1:                 episode reward: 0.9649,                 loss: 0.3489
Episode: 27901/30000 (93.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9002s / 899.9896 s
agent0:                 episode reward: -0.8290,                 loss: nan
agent1:                 episode reward: 0.8290,                 loss: 0.3521
Episode: 27921/30000 (93.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9138s / 900.9035 s
agent0:                 episode reward: -0.8299,                 loss: nan
agent1:                 episode reward: 0.8299,                 loss: 0.3539
Episode: 27941/30000 (93.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9036s / 901.8071 s
agent0:                 episode reward: -0.1643,                 loss: nan
agent1:                 episode reward: 0.1643,                 loss: 0.3495
Episode: 27961/30000 (93.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9214s / 902.7285 s
agent0:                 episode reward: -0.2040,                 loss: nan
agent1:                 episode reward: 0.2040,                 loss: 0.3465
Episode: 27981/30000 (93.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9001s / 903.6286 s
agent0:                 episode reward: -0.6009,                 loss: nan
agent1:                 episode reward: 0.6009,                 loss: 0.3517
Episode: 28001/30000 (93.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9044s / 904.5330 s
agent0:                 episode reward: -0.8869,                 loss: nan
agent1:                 episode reward: 0.8869,                 loss: 0.3540
Episode: 28021/30000 (93.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9110s / 905.4440 s
agent0:                 episode reward: -0.7138,                 loss: nan
agent1:                 episode reward: 0.7138,                 loss: 0.3694
Episode: 28041/30000 (93.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8989s / 906.3430 s
agent0:                 episode reward: -0.3202,                 loss: nan
agent1:                 episode reward: 0.3202,                 loss: 0.3673
Episode: 28061/30000 (93.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9025s / 907.2454 s
agent0:                 episode reward: -0.4974,                 loss: nan
agent1:                 episode reward: 0.4974,                 loss: 0.3657
Episode: 28081/30000 (93.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9062s / 908.1516 s
agent0:                 episode reward: -0.3513,                 loss: nan
agent1:                 episode reward: 0.3513,                 loss: 0.3675
Episode: 28101/30000 (93.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9084s / 909.0600 s
agent0:                 episode reward: -0.6263,                 loss: nan
agent1:                 episode reward: 0.6263,                 loss: 0.3707
Episode: 28121/30000 (93.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8920s / 909.9520 s
agent0:                 episode reward: -0.3932,                 loss: nan
agent1:                 episode reward: 0.3932,                 loss: 0.3675
Episode: 28141/30000 (93.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9118s / 910.8638 s
agent0:                 episode reward: -0.7813,                 loss: nan
agent1:                 episode reward: 0.7813,                 loss: 0.3665
Episode: 28161/30000 (93.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8966s / 911.7604 s
agent0:                 episode reward: -0.5601,                 loss: nan
agent1:                 episode reward: 0.5601,                 loss: 0.3674
Episode: 28181/30000 (93.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9072s / 912.6676 s
agent0:                 episode reward: -0.3498,                 loss: nan
agent1:                 episode reward: 0.3498,                 loss: 0.3672
Episode: 28201/30000 (94.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9170s / 913.5846 s
agent0:                 episode reward: -0.5678,                 loss: nan
agent1:                 episode reward: 0.5678,                 loss: 0.3691
Episode: 28221/30000 (94.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9254s / 914.5100 s
agent0:                 episode reward: -0.5055,                 loss: nan
agent1:                 episode reward: 0.5055,                 loss: 0.3671
Episode: 28241/30000 (94.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9145s / 915.4245 s
agent0:                 episode reward: -0.3112,                 loss: nan
agent1:                 episode reward: 0.3112,                 loss: 0.3695
Episode: 28261/30000 (94.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9114s / 916.3359 s
agent0:                 episode reward: -0.6175,                 loss: nan
agent1:                 episode reward: 0.6175,                 loss: 0.3692
Episode: 28281/30000 (94.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9212s / 917.2571 s
agent0:                 episode reward: -0.2991,                 loss: nan
agent1:                 episode reward: 0.2991,                 loss: 0.3669
Episode: 28301/30000 (94.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9383s / 918.1955 s
agent0:                 episode reward: -0.8091,                 loss: nan
agent1:                 episode reward: 0.8091,                 loss: 0.3714
Episode: 28321/30000 (94.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9025s / 919.0980 s
agent0:                 episode reward: -0.2580,                 loss: nan
agent1:                 episode reward: 0.2580,                 loss: 0.3675
Episode: 28341/30000 (94.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9193s / 920.0173 s
agent0:                 episode reward: -0.5768,                 loss: nan
agent1:                 episode reward: 0.5768,                 loss: 0.3697
Episode: 28361/30000 (94.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9192s / 920.9365 s
agent0:                 episode reward: -0.5545,                 loss: nan
agent1:                 episode reward: 0.5545,                 loss: 0.3651
Episode: 28381/30000 (94.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9172s / 921.8536 s
agent0:                 episode reward: -0.2621,                 loss: nan
agent1:                 episode reward: 0.2621,                 loss: 0.3615
Episode: 28401/30000 (94.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9172s / 922.7709 s
agent0:                 episode reward: -0.7079,                 loss: nan
agent1:                 episode reward: 0.7079,                 loss: 0.3658
Episode: 28421/30000 (94.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9221s / 923.6929 s
agent0:                 episode reward: -0.5952,                 loss: nan
agent1:                 episode reward: 0.5952,                 loss: 0.3641
Episode: 28441/30000 (94.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9020s / 924.5949 s
agent0:                 episode reward: -0.5070,                 loss: nan
agent1:                 episode reward: 0.5070,                 loss: 0.3652
Episode: 28461/30000 (94.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9072s / 925.5021 s
agent0:                 episode reward: -0.5797,                 loss: nan
agent1:                 episode reward: 0.5797,                 loss: 0.3653
Episode: 28481/30000 (94.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9166s / 926.4187 s
agent0:                 episode reward: -0.5198,                 loss: nan
agent1:                 episode reward: 0.5198,                 loss: 0.3636
Episode: 28501/30000 (95.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9440s / 927.3627 s
agent0:                 episode reward: -0.5594,                 loss: nan
agent1:                 episode reward: 0.5594,                 loss: 0.3656
Episode: 28521/30000 (95.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9067s / 928.2694 s
agent0:                 episode reward: -0.8236,                 loss: nan
agent1:                 episode reward: 0.8236,                 loss: 0.3641
Episode: 28541/30000 (95.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9181s / 929.1875 s
agent0:                 episode reward: -0.5009,                 loss: nan
agent1:                 episode reward: 0.5009,                 loss: 0.3648
Episode: 28561/30000 (95.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9262s / 930.1137 s
agent0:                 episode reward: -0.8431,                 loss: nan
agent1:                 episode reward: 0.8431,                 loss: 0.3677
Episode: 28581/30000 (95.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9260s / 931.0397 s
agent0:                 episode reward: -0.8697,                 loss: nan
agent1:                 episode reward: 0.8697,                 loss: 0.3676
Episode: 28601/30000 (95.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9241s / 931.9639 s
agent0:                 episode reward: -0.8804,                 loss: nan
agent1:                 episode reward: 0.8804,                 loss: 0.3641
Episode: 28621/30000 (95.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9398s / 932.9037 s
agent0:                 episode reward: -0.1968,                 loss: nan
agent1:                 episode reward: 0.1968,                 loss: 0.3650
Episode: 28641/30000 (95.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9288s / 933.8325 s
agent0:                 episode reward: -0.5957,                 loss: nan
agent1:                 episode reward: 0.5957,                 loss: 0.3643
Episode: 28661/30000 (95.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9337s / 934.7662 s
agent0:                 episode reward: -0.7102,                 loss: nan
agent1:                 episode reward: 0.7102,                 loss: 0.3651
Episode: 28681/30000 (95.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9172s / 935.6834 s
agent0:                 episode reward: -0.6891,                 loss: nan
agent1:                 episode reward: 0.6891,                 loss: 0.3566
Episode: 28701/30000 (95.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9166s / 936.6000 s
agent0:                 episode reward: -0.7194,                 loss: nan
agent1:                 episode reward: 0.7194,                 loss: 0.3466
Episode: 28721/30000 (95.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9516s / 937.5515 s
agent0:                 episode reward: -0.5940,                 loss: nan
agent1:                 episode reward: 0.5940,                 loss: 0.3435
Episode: 28741/30000 (95.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9299s / 938.4815 s
agent0:                 episode reward: -0.5113,                 loss: nan
agent1:                 episode reward: 0.5113,                 loss: 0.3438
Episode: 28761/30000 (95.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9254s / 939.4069 s
agent0:                 episode reward: -0.3971,                 loss: nan
agent1:                 episode reward: 0.3971,                 loss: 0.3411
Episode: 28781/30000 (95.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9170s / 940.3238 s
agent0:                 episode reward: -0.7925,                 loss: nan
agent1:                 episode reward: 0.7925,                 loss: 0.3433
Episode: 28801/30000 (96.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9211s / 941.2450 s
agent0:                 episode reward: -0.2415,                 loss: nan
agent1:                 episode reward: 0.2415,                 loss: 0.3397
Episode: 28821/30000 (96.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9236s / 942.1686 s
agent0:                 episode reward: -0.3473,                 loss: nan
agent1:                 episode reward: 0.3473,                 loss: 0.3399
Episode: 28841/30000 (96.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9245s / 943.0931 s
agent0:                 episode reward: -0.3442,                 loss: nan
agent1:                 episode reward: 0.3442,                 loss: 0.3418
Episode: 28861/30000 (96.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9162s / 944.0093 s
agent0:                 episode reward: -0.3377,                 loss: nan
agent1:                 episode reward: 0.3377,                 loss: 0.3428
Episode: 28881/30000 (96.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9093s / 944.9186 s
agent0:                 episode reward: -0.7333,                 loss: nan
agent1:                 episode reward: 0.7333,                 loss: 0.3437
Episode: 28901/30000 (96.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9151s / 945.8337 s
agent0:                 episode reward: -0.5964,                 loss: nan
agent1:                 episode reward: 0.5964,                 loss: 0.3419
Episode: 28921/30000 (96.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9212s / 946.7549 s
agent0:                 episode reward: -0.5374,                 loss: nan
agent1:                 episode reward: 0.5374,                 loss: 0.3424
Episode: 28941/30000 (96.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9362s / 947.6911 s
agent0:                 episode reward: -0.4677,                 loss: nan
agent1:                 episode reward: 0.4677,                 loss: 0.3401
Episode: 28961/30000 (96.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9275s / 948.6186 s
agent0:                 episode reward: -0.4564,                 loss: nan
agent1:                 episode reward: 0.4564,                 loss: 0.3426
Episode: 28981/30000 (96.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9223s / 949.5408 s
agent0:                 episode reward: -0.6643,                 loss: nan
agent1:                 episode reward: 0.6643,                 loss: 0.3426
Episode: 29001/30000 (96.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9365s / 950.4773 s
agent0:                 episode reward: -0.6238,                 loss: nan
agent1:                 episode reward: 0.6238,                 loss: 0.3449
Episode: 29021/30000 (96.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9370s / 951.4143 s
agent0:                 episode reward: -0.8973,                 loss: nan
agent1:                 episode reward: 0.8973,                 loss: 0.3790
Episode: 29041/30000 (96.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9320s / 952.3463 s
agent0:                 episode reward: -0.3719,                 loss: nan
agent1:                 episode reward: 0.3719,                 loss: 0.3744
Episode: 29061/30000 (96.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9295s / 953.2758 s
agent0:                 episode reward: -0.8003,                 loss: nan
agent1:                 episode reward: 0.8003,                 loss: 0.3751
Episode: 29081/30000 (96.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9306s / 954.2064 s
agent0:                 episode reward: -0.4105,                 loss: nan
agent1:                 episode reward: 0.4105,                 loss: 0.3752
Episode: 29101/30000 (97.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9264s / 955.1328 s
agent0:                 episode reward: -0.2099,                 loss: nan
agent1:                 episode reward: 0.2099,                 loss: 0.3764
Episode: 29121/30000 (97.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9310s / 956.0638 s
agent0:                 episode reward: -0.7414,                 loss: nan
agent1:                 episode reward: 0.7414,                 loss: 0.3781
Episode: 29141/30000 (97.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9320s / 956.9958 s
agent0:                 episode reward: -0.5108,                 loss: nan
agent1:                 episode reward: 0.5108,                 loss: 0.3760
Episode: 29161/30000 (97.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9309s / 957.9267 s
agent0:                 episode reward: -0.3473,                 loss: nan
agent1:                 episode reward: 0.3473,                 loss: 0.3767
Episode: 29181/30000 (97.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9417s / 958.8685 s
agent0:                 episode reward: -0.4252,                 loss: nan
agent1:                 episode reward: 0.4252,                 loss: 0.3767
Episode: 29201/30000 (97.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9493s / 959.8177 s
agent0:                 episode reward: -0.3343,                 loss: nan
agent1:                 episode reward: 0.3343,                 loss: 0.3750
Episode: 29221/30000 (97.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9493s / 960.7671 s
agent0:                 episode reward: -0.5796,                 loss: nan
agent1:                 episode reward: 0.5796,                 loss: 0.3777
Episode: 29241/30000 (97.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9224s / 961.6895 s
agent0:                 episode reward: -0.5834,                 loss: nan
agent1:                 episode reward: 0.5834,                 loss: 0.3761
Episode: 29261/30000 (97.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9589s / 962.6484 s
agent0:                 episode reward: -0.3875,                 loss: nan
agent1:                 episode reward: 0.3875,                 loss: 0.3746
Episode: 29281/30000 (97.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9415s / 963.5898 s
agent0:                 episode reward: -0.4927,                 loss: nan
agent1:                 episode reward: 0.4927,                 loss: 0.3757
Episode: 29301/30000 (97.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9286s / 964.5184 s
agent0:                 episode reward: -0.1104,                 loss: nan
agent1:                 episode reward: 0.1104,                 loss: 0.3728
Episode: 29321/30000 (97.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9398s / 965.4582 s
agent0:                 episode reward: -0.6172,                 loss: nan
agent1:                 episode reward: 0.6172,                 loss: 0.3748
Episode: 29341/30000 (97.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9369s / 966.3950 s
agent0:                 episode reward: -0.2508,                 loss: nan
agent1:                 episode reward: 0.2508,                 loss: 0.3714
Episode: 29361/30000 (97.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9364s / 967.3314 s
agent0:                 episode reward: -0.6964,                 loss: nan
agent1:                 episode reward: 0.6964,                 loss: 0.3608
Episode: 29381/30000 (97.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9340s / 968.2654 s
agent0:                 episode reward: -0.6065,                 loss: nan
agent1:                 episode reward: 0.6065,                 loss: 0.3593
Episode: 29401/30000 (98.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9423s / 969.2077 s
agent0:                 episode reward: -0.5942,                 loss: nan
agent1:                 episode reward: 0.5942,                 loss: 0.3590
Episode: 29421/30000 (98.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9390s / 970.1467 s
agent0:                 episode reward: -0.6721,                 loss: nan
agent1:                 episode reward: 0.6721,                 loss: 0.3624
Episode: 29441/30000 (98.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9412s / 971.0879 s
agent0:                 episode reward: -0.4290,                 loss: nan
agent1:                 episode reward: 0.4290,                 loss: 0.3624
Episode: 29461/30000 (98.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9550s / 972.0429 s
agent0:                 episode reward: -0.7902,                 loss: nan
agent1:                 episode reward: 0.7902,                 loss: 0.3603
Episode: 29481/30000 (98.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9459s / 972.9888 s
agent0:                 episode reward: -0.2355,                 loss: nan
agent1:                 episode reward: 0.2355,                 loss: 0.3617
Episode: 29501/30000 (98.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9424s / 973.9311 s
agent0:                 episode reward: -0.6765,                 loss: nan
agent1:                 episode reward: 0.6765,                 loss: 0.3630
Episode: 29521/30000 (98.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9508s / 974.8820 s
agent0:                 episode reward: -0.2038,                 loss: nan
agent1:                 episode reward: 0.2038,                 loss: 0.3602
Episode: 29541/30000 (98.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9505s / 975.8325 s
agent0:                 episode reward: -0.4856,                 loss: nan
agent1:                 episode reward: 0.4856,                 loss: 0.3573
Episode: 29561/30000 (98.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9360s / 976.7686 s
agent0:                 episode reward: -0.0144,                 loss: nan
agent1:                 episode reward: 0.0144,                 loss: 0.3609
Episode: 29581/30000 (98.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9441s / 977.7127 s
agent0:                 episode reward: -0.4515,                 loss: nan
agent1:                 episode reward: 0.4515,                 loss: 0.3609
Episode: 29601/30000 (98.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9524s / 978.6650 s
agent0:                 episode reward: -0.2610,                 loss: nan
agent1:                 episode reward: 0.2610,                 loss: 0.3599
Episode: 29621/30000 (98.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9474s / 979.6125 s
agent0:                 episode reward: -0.6269,                 loss: nan
agent1:                 episode reward: 0.6269,                 loss: 0.3582/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

Episode: 29641/30000 (98.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9477s / 980.5602 s
agent0:                 episode reward: -0.5916,                 loss: nan
agent1:                 episode reward: 0.5916,                 loss: 0.3620
Episode: 29661/30000 (98.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9447s / 981.5050 s
agent0:                 episode reward: -0.5482,                 loss: nan
agent1:                 episode reward: 0.5482,                 loss: 0.3589
Episode: 29681/30000 (98.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9819s / 982.4868 s
agent0:                 episode reward: -0.3770,                 loss: nan
agent1:                 episode reward: 0.3770,                 loss: 0.3583
Episode: 29701/30000 (99.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9738s / 983.4606 s
agent0:                 episode reward: -0.6048,                 loss: nan
agent1:                 episode reward: 0.6048,                 loss: 0.3527
Episode: 29721/30000 (99.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9354s / 984.3960 s
agent0:                 episode reward: -0.4164,                 loss: nan
agent1:                 episode reward: 0.4164,                 loss: 0.3541
Episode: 29741/30000 (99.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9465s / 985.3425 s
agent0:                 episode reward: -0.4296,                 loss: nan
agent1:                 episode reward: 0.4296,                 loss: 0.3521
Episode: 29761/30000 (99.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9430s / 986.2855 s
agent0:                 episode reward: -0.6483,                 loss: nan
agent1:                 episode reward: 0.6483,                 loss: 0.3532
Episode: 29781/30000 (99.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9592s / 987.2447 s
agent0:                 episode reward: -0.3631,                 loss: nan
agent1:                 episode reward: 0.3631,                 loss: 0.3514
Episode: 29801/30000 (99.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9604s / 988.2051 s
agent0:                 episode reward: -0.5069,                 loss: nan
agent1:                 episode reward: 0.5069,                 loss: 0.3510
Episode: 29821/30000 (99.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9499s / 989.1549 s
agent0:                 episode reward: -0.4577,                 loss: nan
agent1:                 episode reward: 0.4577,                 loss: 0.3511
Episode: 29841/30000 (99.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9538s / 990.1088 s
agent0:                 episode reward: -0.3643,                 loss: nan
agent1:                 episode reward: 0.3643,                 loss: 0.3512
Episode: 29861/30000 (99.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9558s / 991.0645 s
agent0:                 episode reward: -0.3685,                 loss: nan
agent1:                 episode reward: 0.3685,                 loss: 0.3525
Episode: 29881/30000 (99.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9473s / 992.0118 s
agent0:                 episode reward: -0.6876,                 loss: nan
agent1:                 episode reward: 0.6876,                 loss: 0.3514
Episode: 29901/30000 (99.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9602s / 992.9721 s
agent0:                 episode reward: -0.6319,                 loss: nan
agent1:                 episode reward: 0.6319,                 loss: 0.3521
Episode: 29921/30000 (99.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9447s / 993.9168 s
agent0:                 episode reward: -0.3585,                 loss: nan
agent1:                 episode reward: 0.3585,                 loss: 0.3525
Episode: 29941/30000 (99.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9606s / 994.8774 s
agent0:                 episode reward: -0.5633,                 loss: nan
agent1:                 episode reward: 0.5633,                 loss: 0.3561
Episode: 29961/30000 (99.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9595s / 995.8369 s
agent0:                 episode reward: -1.1171,                 loss: nan
agent1:                 episode reward: 1.1171,                 loss: 0.3519
Episode: 29981/30000 (99.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9239s / 996.7608 s
agent0:                 episode reward: -0.5584,                 loss: nan
agent1:                 episode reward: 0.5584,                 loss: 0.3505
