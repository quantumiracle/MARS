pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
tennis_v2 pettingzoo
Load tennis_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
random seed: 91
<mars.env.wrappers.mars_wrappers.Dict2TupleWrapper object at 0x7f5b1dac33c8>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
Agents No. [0] (index starting from 0) are not learnable.
Load meta strategy:  [[0.028 0.028 0.028 ... 0.028 0.028 0.028]
 [0.028 0.028 0.028 ... 0.028 0.028 0.028]]
Load checkpoints (policy family):  [['182' '281' '369' ... '3816' '3926' '3972']
 ['260' '341' '670' ... '3905' '3950' '3993']]
Arguments:  {'env_name': 'tennis_v2', 'env_type': 'pettingzoo', 'num_envs': 1, 'ram': True, 'seed': 'random', 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000, 'update_itr': 1}, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': './data/model/20220115_0159/pettingzoo_tennis_v2_fictitious_selfplay2/', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'fictitious_selfplay2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'selfplay_score_delta': 50, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'against_baseline': False}
Save models to : /home/zihan/research/MARS/data/model/20220115_0159_exploit/pettingzoo_tennis_v2_fictitious_selfplay2. 
 Save logs to: /home/zihan/research/MARS/data/log/20220115_0159_exploit/pettingzoo_tennis_v2_fictitious_selfplay2.
Episode: 1/10000 (0.0100%),                 avg. length: 1935.0,                last time consumption/overall running time: 19.7215s / 19.7215 s
first_0:                 episode reward: 22.0000,                 loss: nan
second_0:                 episode reward: -22.0000,                 loss: 0.0057
Episode: 21/10000 (0.2100%),                 avg. length: 1797.35,                last time consumption/overall running time: 363.3121s / 383.0336 s
first_0:                 episode reward: 22.2000,                 loss: nan
second_0:                 episode reward: -22.2000,                 loss: 0.0059
Episode: 41/10000 (0.4100%),                 avg. length: 2848.2,                last time consumption/overall running time: 600.1259s / 983.1596 s
first_0:                 episode reward: -0.8500,                 loss: nan
second_0:                 episode reward: 0.8500,                 loss: 0.0057
Episode: 61/10000 (0.6100%),                 avg. length: 3288.4,                last time consumption/overall running time: 707.3499s / 1690.5094 s
first_0:                 episode reward: 17.9500,                 loss: nan
second_0:                 episode reward: -17.9500,                 loss: 0.0066
Episode: 81/10000 (0.8100%),                 avg. length: 7634.7,                last time consumption/overall running time: 1637.3481s / 3327.8575 s
first_0:                 episode reward: 16.3500,                 loss: nan
second_0:                 episode reward: -16.3500,                 loss: 0.0075
Episode: 101/10000 (1.0100%),                 avg. length: 6996.8,                last time consumption/overall running time: 1503.1104s / 4830.9679 s
first_0:                 episode reward: -23.2500,                 loss: nan
second_0:                 episode reward: 23.2500,                 loss: 0.0073
Episode: 121/10000 (1.2100%),                 avg. length: 8744.7,                last time consumption/overall running time: 1874.5879s / 6705.5558 s
first_0:                 episode reward: 4.2000,                 loss: nan
second_0:                 episode reward: -4.2000,                 loss: 0.0066
Episode: 141/10000 (1.4100%),                 avg. length: 7226.95,                last time consumption/overall running time: 1548.4603s / 8254.0161 s
first_0:                 episode reward: 12.5500,                 loss: nan
second_0:                 episode reward: -12.5500,                 loss: 0.0082
Episode: 161/10000 (1.6100%),                 avg. length: 8266.5,                last time consumption/overall running time: 1770.0900s / 10024.1060 s
first_0:                 episode reward: 19.7000,                 loss: nan
second_0:                 episode reward: -19.7000,                 loss: 0.0089
Episode: 181/10000 (1.8100%),                 avg. length: 9233.3,                last time consumption/overall running time: 2035.6682s / 12059.7742 s
first_0:                 episode reward: 16.7000,                 loss: nan
second_0:                 episode reward: -16.7000,                 loss: 0.0127
Episode: 201/10000 (2.0100%),                 avg. length: 5564.8,                last time consumption/overall running time: 1253.2948s / 13313.0690 s
first_0:                 episode reward: 21.3500,                 loss: nan
second_0:                 episode reward: -21.3500,                 loss: 0.0104
Episode: 221/10000 (2.2100%),                 avg. length: 7423.45,                last time consumption/overall running time: 1677.3629s / 14990.4319 s
first_0:                 episode reward: 5.9000,                 loss: nan
second_0:                 episode reward: -5.9000,                 loss: 0.0077
Episode: 241/10000 (2.4100%),                 avg. length: 7762.85,                last time consumption/overall running time: 1755.9247s / 16746.3566 s
first_0:                 episode reward: 32.2000,                 loss: nan
second_0:                 episode reward: -32.2000,                 loss: 0.0098
Episode: 261/10000 (2.6100%),                 avg. length: 8303.6,                last time consumption/overall running time: 1884.4416s / 18630.7982 s
first_0:                 episode reward: 72.6000,                 loss: nan
second_0:                 episode reward: -72.6000,                 loss: 0.0097
Episode: 281/10000 (2.8100%),                 avg. length: 8476.4,                last time consumption/overall running time: 1922.2750s / 20553.0732 s
first_0:                 episode reward: 26.2000,                 loss: nan
second_0:                 episode reward: -26.2000,                 loss: 0.0129
Episode: 301/10000 (3.0100%),                 avg. length: 6916.05,                last time consumption/overall running time: 1572.5317s / 22125.6049 s
first_0:                 episode reward: 17.5500,                 loss: nan
second_0:                 episode reward: -17.5500,                 loss: 0.0128
Episode: 321/10000 (3.2100%),                 avg. length: 6115.7,                last time consumption/overall running time: 1381.7517s / 23507.3566 s
first_0:                 episode reward: 43.2000,                 loss: nan
second_0:                 episode reward: -43.2000,                 loss: 0.0113
Episode: 341/10000 (3.4100%),                 avg. length: 7337.3,                last time consumption/overall running time: 1651.3407s / 25158.6972 s
first_0:                 episode reward: 23.3000,                 loss: nan
second_0:                 episode reward: -23.3000,                 loss: 0.0096
Episode: 361/10000 (3.6100%),                 avg. length: 7182.0,                last time consumption/overall running time: 1615.5204s / 26774.2176 s
first_0:                 episode reward: 26.0500,                 loss: nan
second_0:                 episode reward: -26.0500,                 loss: 0.0122
Episode: 381/10000 (3.8100%),                 avg. length: 7811.85,                last time consumption/overall running time: 1759.9582s / 28534.1758 s
first_0:                 episode reward: 15.7500,                 loss: nan
second_0:                 episode reward: -15.7500,                 loss: 0.0150
Episode: 401/10000 (4.0100%),                 avg. length: 6718.0,                last time consumption/overall running time: 1510.7635s / 30044.9393 s
first_0:                 episode reward: 1.2500,                 loss: nan
second_0:                 episode reward: -1.2500,                 loss: 0.0146
Episode: 421/10000 (4.2100%),                 avg. length: 6456.0,                last time consumption/overall running time: 1448.3439s / 31493.2833 s
first_0:                 episode reward: 30.6000,                 loss: nan
second_0:                 episode reward: -30.6000,                 loss: 0.0155
Episode: 441/10000 (4.4100%),                 avg. length: 7101.35,                last time consumption/overall running time: 1595.4299s / 33088.7132 s
first_0:                 episode reward: -13.7000,                 loss: nan
second_0:                 episode reward: 13.7000,                 loss: 0.0161
Episode: 461/10000 (4.6100%),                 avg. length: 7991.8,                last time consumption/overall running time: 1794.6353s / 34883.3485 s
first_0:                 episode reward: -2.0500,                 loss: nan
second_0:                 episode reward: 2.0500,                 loss: 0.0185
Episode: 481/10000 (4.8100%),                 avg. length: 5381.5,                last time consumption/overall running time: 1206.4221s / 36089.7706 s
first_0:                 episode reward: 23.7000,                 loss: nan
second_0:                 episode reward: -23.7000,                 loss: 0.0136
Episode: 501/10000 (5.0100%),                 avg. length: 5934.0,                last time consumption/overall running time: 1328.2627s / 37418.0333 s
first_0:                 episode reward: -20.8000,                 loss: nan
second_0:                 episode reward: 20.8000,                 loss: 0.0145
Episode: 521/10000 (5.2100%),                 avg. length: 5797.15,                last time consumption/overall running time: 1300.7232s / 38718.7565 s
first_0:                 episode reward: -8.8000,                 loss: nan
second_0:                 episode reward: 8.8000,                 loss: 0.0178
Episode: 541/10000 (5.4100%),                 avg. length: 7017.05,                last time consumption/overall running time: 1572.1276s / 40290.8840 s
first_0:                 episode reward: -12.5500,                 loss: nan
second_0:                 episode reward: 12.5500,                 loss: 0.0142
Episode: 561/10000 (5.6100%),                 avg. length: 6983.95,                last time consumption/overall running time: 1566.4897s / 41857.3738 s
first_0:                 episode reward: 39.8500,                 loss: nan
second_0:                 episode reward: -39.8500,                 loss: 0.0116
Episode: 581/10000 (5.8100%),                 avg. length: 6144.35,                last time consumption/overall running time: 1381.4668s / 43238.8406 s
first_0:                 episode reward: -15.9000,                 loss: nan
second_0:                 episode reward: 15.9000,                 loss: 0.0117
Episode: 601/10000 (6.0100%),                 avg. length: 7051.3,                last time consumption/overall running time: 1584.3825s / 44823.2230 s
first_0:                 episode reward: 2.1500,                 loss: nan
second_0:                 episode reward: -2.1500,                 loss: 0.0127
Episode: 621/10000 (6.2100%),                 avg. length: 6122.1,                last time consumption/overall running time: 1375.8203s / 46199.0434 s
first_0:                 episode reward: -41.7500,                 loss: nan
second_0:                 episode reward: 41.7500,                 loss: 0.0147
Episode: 641/10000 (6.4100%),                 avg. length: 6089.85,                last time consumption/overall running time: 1369.8523s / 47568.8957 s
first_0:                 episode reward: 3.1500,                 loss: nan
second_0:                 episode reward: -3.1500,                 loss: 0.0186
Episode: 661/10000 (6.6100%),                 avg. length: 5792.65,                last time consumption/overall running time: 1247.4227s / 48816.3184 s
first_0:                 episode reward: -7.4500,                 loss: nan
second_0:                 episode reward: 7.4500,                 loss: 0.0125
Episode: 681/10000 (6.8100%),                 avg. length: 5884.75,                last time consumption/overall running time: 1203.8052s / 50020.1236 s
first_0:                 episode reward: 23.2500,                 loss: nan
second_0:                 episode reward: -23.2500,                 loss: 0.0144
Episode: 701/10000 (7.0100%),                 avg. length: 6926.05,                last time consumption/overall running time: 1414.3676s / 51434.4912 s
first_0:                 episode reward: 3.9000,                 loss: nan
second_0:                 episode reward: -3.9000,                 loss: 0.0140
Episode: 721/10000 (7.2100%),                 avg. length: 6728.85,                last time consumption/overall running time: 1371.6021s / 52806.0933 s
first_0:                 episode reward: 43.8500,                 loss: nan
second_0:                 episode reward: -43.8500,                 loss: 0.0157
Episode: 741/10000 (7.4100%),                 avg. length: 6705.0,                last time consumption/overall running time: 1364.5162s / 54170.6095 s
first_0:                 episode reward: 1.7000,                 loss: nan
second_0:                 episode reward: -1.7000,                 loss: 0.0129
Episode: 761/10000 (7.6100%),                 avg. length: 7262.15,                last time consumption/overall running time: 1483.0584s / 55653.6680 s
first_0:                 episode reward: 32.3000,                 loss: nan
second_0:                 episode reward: -32.3000,                 loss: 0.0094
Episode: 781/10000 (7.8100%),                 avg. length: 6864.85,                last time consumption/overall running time: 1400.5345s / 57054.2025 s
first_0:                 episode reward: -7.6000,                 loss: nan
second_0:                 episode reward: 7.6000,                 loss: 0.0234
Episode: 801/10000 (8.0100%),                 avg. length: 5259.0,                last time consumption/overall running time: 1074.0959s / 58128.2984 s
first_0:                 episode reward: 25.0000,                 loss: nan
second_0:                 episode reward: -25.0000,                 loss: 0.0216
Episode: 821/10000 (8.2100%),                 avg. length: 7619.75,                last time consumption/overall running time: 1554.3077s / 59682.6061 s
first_0:                 episode reward: 48.5000,                 loss: nan
second_0:                 episode reward: -48.5000,                 loss: 0.0219
Episode: 841/10000 (8.4100%),                 avg. length: 4176.75,                last time consumption/overall running time: 852.1108s / 60534.7169 s
first_0:                 episode reward: 32.4500,                 loss: nan
second_0:                 episode reward: -32.4500,                 loss: 0.0221
Episode: 861/10000 (8.6100%),                 avg. length: 4233.6,                last time consumption/overall running time: 867.3497s / 61402.0665 s
first_0:                 episode reward: 9.6000,                 loss: nan
second_0:                 episode reward: -9.6000,                 loss: 0.0146
Episode: 881/10000 (8.8100%),                 avg. length: 5044.15,                last time consumption/overall running time: 1029.8821s / 62431.9487 s
first_0:                 episode reward: -15.1500,                 loss: nan
second_0:                 episode reward: 15.1500,                 loss: 0.0154
Episode: 901/10000 (9.0100%),                 avg. length: 4979.05,                last time consumption/overall running time: 1018.8670s / 63450.8157 s
first_0:                 episode reward: 36.3500,                 loss: nan
second_0:                 episode reward: -36.3500,                 loss: 0.0129
Episode: 921/10000 (9.2100%),                 avg. length: 7007.35,                last time consumption/overall running time: 1429.6453s / 64880.4610 s
first_0:                 episode reward: -34.4500,                 loss: nan
second_0:                 episode reward: 34.4500,                 loss: 0.0118
Episode: 941/10000 (9.4100%),                 avg. length: 6282.8,                last time consumption/overall running time: 1285.1654s / 66165.6264 s
first_0:                 episode reward: -42.7500,                 loss: nan
second_0:                 episode reward: 42.7500,                 loss: 0.0129
Episode: 961/10000 (9.6100%),                 avg. length: 5729.1,                last time consumption/overall running time: 1173.2444s / 67338.8708 s
first_0:                 episode reward: -9.1500,                 loss: nan
second_0:                 episode reward: 9.1500,                 loss: 0.0130
Episode: 981/10000 (9.8100%),                 avg. length: 4861.15,                last time consumption/overall running time: 997.3642s / 68336.2350 s
first_0:                 episode reward: -11.3500,                 loss: nan
second_0:                 episode reward: 11.3500,                 loss: 0.0204
Episode: 1001/10000 (10.0100%),                 avg. length: 6066.7,                last time consumption/overall running time: 1246.6360s / 69582.8710 s
first_0:                 episode reward: -15.3500,                 loss: nan
second_0:                 episode reward: 15.3500,                 loss: 0.0190
Episode: 1021/10000 (10.2100%),                 avg. length: 5282.8,                last time consumption/overall running time: 1081.9425s / 70664.8135 s
first_0:                 episode reward: -4.2000,                 loss: nan
second_0:                 episode reward: 4.2000,                 loss: 0.0169
Episode: 1041/10000 (10.4100%),                 avg. length: 5122.9,                last time consumption/overall running time: 1051.0462s / 71715.8597 s
first_0:                 episode reward: 17.5000,                 loss: nan
second_0:                 episode reward: -17.5000,                 loss: 0.0124
Episode: 1061/10000 (10.6100%),                 avg. length: 6446.8,                last time consumption/overall running time: 1324.7484s / 73040.6080 s
first_0:                 episode reward: 23.3000,                 loss: nan
second_0:                 episode reward: -23.3000,                 loss: 0.0138
Episode: 1081/10000 (10.8100%),                 avg. length: 5025.35,                last time consumption/overall running time: 1026.4758s / 74067.0838 s
first_0:                 episode reward: 6.7000,                 loss: nan
second_0:                 episode reward: -6.7000,                 loss: 0.0124
Episode: 1101/10000 (11.0100%),                 avg. length: 6453.35,                last time consumption/overall running time: 1323.2428s / 75390.3267 s
first_0:                 episode reward: 16.3500,                 loss: nan
second_0:                 episode reward: -16.3500,                 loss: 0.0120
Episode: 1121/10000 (11.2100%),                 avg. length: 6577.8,                last time consumption/overall running time: 1350.7989s / 76741.1255 s
first_0:                 episode reward: -37.0000,                 loss: nan
second_0:                 episode reward: 37.0000,                 loss: 0.0128
Episode: 1141/10000 (11.4100%),                 avg. length: 7103.55,                last time consumption/overall running time: 1455.2040s / 78196.3295 s
first_0:                 episode reward: -48.2500,                 loss: nan
second_0:                 episode reward: 48.2500,                 loss: 0.0108
Episode: 1161/10000 (11.6100%),                 avg. length: 8100.45,                last time consumption/overall running time: 1658.9740s / 79855.3036 s
first_0:                 episode reward: 4.6500,                 loss: nan
second_0:                 episode reward: -4.6500,                 loss: 0.0095
Episode: 1181/10000 (11.8100%),                 avg. length: 6853.2,                last time consumption/overall running time: 1400.2158s / 81255.5193 s
first_0:                 episode reward: -3.3500,                 loss: nan
second_0:                 episode reward: 3.3500,                 loss: 0.0089
Episode: 1201/10000 (12.0100%),                 avg. length: 6605.5,                last time consumption/overall running time: 1352.2451s / 82607.7645 s
first_0:                 episode reward: -11.9000,                 loss: nan
second_0:                 episode reward: 11.9000,                 loss: 0.0090
Episode: 1221/10000 (12.2100%),                 avg. length: 7882.25,                last time consumption/overall running time: 1611.0850s / 84218.8494 s
first_0:                 episode reward: -18.6000,                 loss: nan
second_0:                 episode reward: 18.6000,                 loss: 0.0094
Episode: 1241/10000 (12.4100%),                 avg. length: 7805.1,                last time consumption/overall running time: 1596.5469s / 85815.3963 s
first_0:                 episode reward: -9.5500,                 loss: nan
second_0:                 episode reward: 9.5500,                 loss: 0.0075
Episode: 1261/10000 (12.6100%),                 avg. length: 7349.45,                last time consumption/overall running time: 1501.7281s / 87317.1245 s
first_0:                 episode reward: -25.3000,                 loss: nan
second_0:                 episode reward: 25.3000,                 loss: 0.0081
Episode: 1281/10000 (12.8100%),                 avg. length: 7585.95,                last time consumption/overall running time: 1552.8465s / 88869.9710 s
first_0:                 episode reward: 6.3000,                 loss: nan
second_0:                 episode reward: -6.3000,                 loss: 0.0132
Episode: 1301/10000 (13.0100%),                 avg. length: 5190.6,                last time consumption/overall running time: 1061.7165s / 89931.6875 s
first_0:                 episode reward: 17.6500,                 loss: nan
second_0:                 episode reward: -17.6500,                 loss: 0.0321
Episode: 1321/10000 (13.2100%),                 avg. length: 5972.5,                last time consumption/overall running time: 1217.3559s / 91149.0434 s
first_0:                 episode reward: 17.6500,                 loss: nan
second_0:                 episode reward: -17.6500,                 loss: 0.0274
Episode: 1341/10000 (13.4100%),                 avg. length: 5497.6,                last time consumption/overall running time: 1121.3764s / 92270.4198 s
first_0:                 episode reward: 57.5000,                 loss: nan
second_0:                 episode reward: -57.5000,                 loss: 0.0283
Episode: 1361/10000 (13.6100%),                 avg. length: 6543.85,                last time consumption/overall running time: 1334.6217s / 93605.0415 s
first_0:                 episode reward: 2.2000,                 loss: nan
second_0:                 episode reward: -2.2000,                 loss: 0.0220
Episode: 1381/10000 (13.8100%),                 avg. length: 4990.4,                last time consumption/overall running time: 994.9647s / 94600.0062 s
first_0:                 episode reward: 22.6500,                 loss: nan
second_0:                 episode reward: -22.6500,                 loss: 0.0179
Episode: 1401/10000 (14.0100%),                 avg. length: 6339.85,                last time consumption/overall running time: 1254.2964s / 95854.3026 s