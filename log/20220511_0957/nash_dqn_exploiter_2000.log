2022-05-11 09:57:28.812206: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia:/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia
2022-05-11 09:57:28.812270: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia:/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia
2022-05-11 09:57:28.812275: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
pygame 2.0.1 (SDL 2.0.14, Python 3.6.13)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 33.0, (1,), float32) action space: Discrete(3)
random seed: 267
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7f9c865668d0>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=32, bias=True)
      (3): ReLU()
      (4): Linear(in_features=32, out_features=32, bias=True)
      (5): ReLU()
      (6): Linear(in_features=32, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=32, bias=True)
      (3): ReLU()
      (4): Linear(in_features=32, out_features=32, bias=True)
      (5): ReLU()
      (6): Linear(in_features=32, out_features=3, bias=True)
    )
  )
)
Error: no exploited model index given!
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  data/model/20220510143601/mdp_arbitrary_mdp_nash_dqn_exploiter/2000_0
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': 'random', 'algorithm': 'NashDQNExploiter', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 1.0, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.0, 'eps_decay': 8000, 'exploiter_update_itr': 1}, 'num_process': 1, 'batch_size': 640, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 10, 'log_interval': 10, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220510143601/mdp_arbitrary_mdp_nash_dqn_exploiter/2000_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 1000, 'net_architecture': {'hidden_dim_list': [32, 32, 32], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn_exploiter', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True}, 'against_baseline': False}
Save models to : /home/quantumiracle/research/MARS/data/model/20220510143601_exploit_2000/mdp_arbitrary_mdp_nash_dqn_exploiter. 
 Save logs to: /home/quantumiracle/research/MARS/data/log/20220510143601_exploit_2000/mdp_arbitrary_mdp_nash_dqn_exploiter.
Episode: 1/10000 (0.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8305s / 0.8305 s
agent0:                 episode reward: 0.2565,                 loss: nan
agent1:                 episode reward: -0.2565,                 loss: nan
Episode: 11/10000 (0.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.1401s / 0.9706 s
agent0:                 episode reward: -0.3683,                 loss: nan
agent1:                 episode reward: 0.3683,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.1009s / 1.0714 s
agent0:                 episode reward: 0.5802,                 loss: nan
agent1:                 episode reward: -0.5802,                 loss: nan
Episode: 31/10000 (0.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.1114s / 1.1828 s
agent0:                 episode reward: -0.3642,                 loss: nan
agent1:                 episode reward: 0.3642,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.1414s / 1.3242 s
agent0:                 episode reward: 0.6289,                 loss: nan
agent1:                 episode reward: -0.6289,                 loss: nan
Episode: 51/10000 (0.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.0971s / 1.4214 s
agent0:                 episode reward: 1.2595,                 loss: nan
agent1:                 episode reward: -1.2595,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.0989s / 1.5203 s
agent0:                 episode reward: 1.1313,                 loss: nan
agent1:                 episode reward: -1.1313,                 loss: nan
Episode: 71/10000 (0.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.3435s / 1.8638 s
agent0:                 episode reward: 0.8240,                 loss: nan
agent1:                 episode reward: -0.8240,                 loss: 0.4424
Episode: 81/10000 (0.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4096s / 2.2735 s
agent0:                 episode reward: 1.1830,                 loss: nan
agent1:                 episode reward: -1.1830,                 loss: 0.4322
Episode: 91/10000 (0.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4777s / 2.7512 s
agent0:                 episode reward: 0.5154,                 loss: nan
agent1:                 episode reward: -0.5154,                 loss: 0.4268
Episode: 101/10000 (1.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4291s / 3.1802 s
agent0:                 episode reward: 1.5744,                 loss: nan
agent1:                 episode reward: -1.5744,                 loss: 0.4220
Episode: 111/10000 (1.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4021s / 3.5823 s
agent0:                 episode reward: 0.6023,                 loss: nan
agent1:                 episode reward: -0.6023,                 loss: 0.4194
Episode: 121/10000 (1.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4513s / 4.0336 s
agent0:                 episode reward: 1.1671,                 loss: nan
agent1:                 episode reward: -1.1671,                 loss: 0.4154
Episode: 131/10000 (1.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4278s / 4.4614 s
agent0:                 episode reward: 1.6735,                 loss: nan
agent1:                 episode reward: -1.6735,                 loss: 0.4138
Episode: 141/10000 (1.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4638s / 4.9252 s
agent0:                 episode reward: 1.1007,                 loss: nan
agent1:                 episode reward: -1.1007,                 loss: 0.4114
Episode: 151/10000 (1.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4359s / 5.3611 s
agent0:                 episode reward: 0.7637,                 loss: nan
agent1:                 episode reward: -0.7637,                 loss: 0.4101
Episode: 161/10000 (1.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5047s / 5.8659 s
agent0:                 episode reward: 0.7422,                 loss: nan
agent1:                 episode reward: -0.7422,                 loss: 0.4124
Episode: 171/10000 (1.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5569s / 6.4227 s
agent0:                 episode reward: 0.7314,                 loss: nan
agent1:                 episode reward: -0.7314,                 loss: 0.4218
Episode: 181/10000 (1.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5131s / 6.9358 s
agent0:                 episode reward: 0.4706,                 loss: nan
agent1:                 episode reward: -0.4706,                 loss: 0.4264
Episode: 191/10000 (1.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4895s / 7.4253 s
agent0:                 episode reward: 1.5813,                 loss: nan
agent1:                 episode reward: -1.5813,                 loss: 0.4281
Episode: 201/10000 (2.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5598s / 7.9851 s
agent0:                 episode reward: 0.3852,                 loss: nan
agent1:                 episode reward: -0.3852,                 loss: 0.4301
Episode: 211/10000 (2.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4754s / 8.4605 s
agent0:                 episode reward: 0.7371,                 loss: nan
agent1:                 episode reward: -0.7371,                 loss: 0.4300
Episode: 221/10000 (2.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4414s / 8.9018 s
agent0:                 episode reward: 0.3931,                 loss: nan
agent1:                 episode reward: -0.3931,                 loss: 0.4300
Episode: 231/10000 (2.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4323s / 9.3341 s
agent0:                 episode reward: 0.3852,                 loss: nan
agent1:                 episode reward: -0.3852,                 loss: 0.4306
Episode: 241/10000 (2.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4354s / 9.7695 s
agent0:                 episode reward: 0.8513,                 loss: nan
agent1:                 episode reward: -0.8513,                 loss: 0.4306
Episode: 251/10000 (2.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4772s / 10.2467 s
agent0:                 episode reward: 0.7025,                 loss: nan
agent1:                 episode reward: -0.7025,                 loss: 0.4294
Episode: 261/10000 (2.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5006s / 10.7473 s
agent0:                 episode reward: 0.4188,                 loss: nan
agent1:                 episode reward: -0.4188,                 loss: 0.4294
Episode: 271/10000 (2.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5817s / 11.3290 s
agent0:                 episode reward: 1.6983,                 loss: nan
agent1:                 episode reward: -1.6983,                 loss: 0.4359
Episode: 281/10000 (2.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4550s / 11.7840 s
agent0:                 episode reward: 1.0397,                 loss: nan
agent1:                 episode reward: -1.0397,                 loss: 0.4376
Episode: 291/10000 (2.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4866s / 12.2706 s
agent0:                 episode reward: 0.9467,                 loss: nan
agent1:                 episode reward: -0.9467,                 loss: 0.4387
Episode: 301/10000 (3.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4786s / 12.7491 s
agent0:                 episode reward: 0.5103,                 loss: nan
agent1:                 episode reward: -0.5103,                 loss: 0.4375
Episode: 311/10000 (3.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4642s / 13.2133 s
agent0:                 episode reward: 1.1641,                 loss: nan
agent1:                 episode reward: -1.1641,                 loss: 0.4365
Episode: 321/10000 (3.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4974s / 13.7107 s
agent0:                 episode reward: 0.6117,                 loss: nan
agent1:                 episode reward: -0.6117,                 loss: 0.4359
Episode: 331/10000 (3.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5343s / 14.2450 s
agent0:                 episode reward: 0.0889,                 loss: nan
agent1:                 episode reward: -0.0889,                 loss: 0.4371
Episode: 341/10000 (3.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4711s / 14.7161 s
agent0:                 episode reward: 1.4134,                 loss: nan
agent1:                 episode reward: -1.4134,                 loss: 0.4380
Episode: 351/10000 (3.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4591s / 15.1753 s
agent0:                 episode reward: 1.2322,                 loss: nan
agent1:                 episode reward: -1.2322,                 loss: 0.4380
Episode: 361/10000 (3.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5501s / 15.7254 s
agent0:                 episode reward: 1.7266,                 loss: nan
agent1:                 episode reward: -1.7266,                 loss: 0.4374
Episode: 371/10000 (3.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5468s / 16.2722 s
agent0:                 episode reward: 0.6767,                 loss: nan
agent1:                 episode reward: -0.6767,                 loss: 0.4410
Episode: 381/10000 (3.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4398s / 16.7120 s
agent0:                 episode reward: 0.5851,                 loss: nan
agent1:                 episode reward: -0.5851,                 loss: 0.4433
Episode: 391/10000 (3.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4398s / 17.1518 s
agent0:                 episode reward: 0.7666,                 loss: nan
agent1:                 episode reward: -0.7666,                 loss: 0.4429
Episode: 401/10000 (4.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4361s / 17.5879 s
agent0:                 episode reward: 0.7058,                 loss: nan
agent1:                 episode reward: -0.7058,                 loss: 0.4419
Episode: 411/10000 (4.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4768s / 18.0648 s
agent0:                 episode reward: 0.6046,                 loss: nan
agent1:                 episode reward: -0.6046,                 loss: 0.4415
Episode: 421/10000 (4.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4372s / 18.5020 s
agent0:                 episode reward: 0.1951,                 loss: nan
agent1:                 episode reward: -0.1951,                 loss: 0.4414
Episode: 431/10000 (4.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4149s / 18.9169 s
agent0:                 episode reward: 0.9729,                 loss: nan
agent1:                 episode reward: -0.9729,                 loss: 0.4395
Episode: 441/10000 (4.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4141s / 19.3310 s
agent0:                 episode reward: 0.3211,                 loss: nan
agent1:                 episode reward: -0.3211,                 loss: 0.4412
Episode: 451/10000 (4.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4138s / 19.7448 s
agent0:                 episode reward: 0.2639,                 loss: nan
agent1:                 episode reward: -0.2639,                 loss: 0.4404
Episode: 461/10000 (4.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4158s / 20.1606 s
agent0:                 episode reward: -0.1021,                 loss: nan
agent1:                 episode reward: 0.1021,                 loss: 0.4403
Episode: 471/10000 (4.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4141s / 20.5747 s
agent0:                 episode reward: 0.2132,                 loss: nan
agent1:                 episode reward: -0.2132,                 loss: 0.4412
Episode: 481/10000 (4.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4282s / 21.0029 s
agent0:                 episode reward: 0.7904,                 loss: nan
agent1:                 episode reward: -0.7904,                 loss: 0.4403
Episode: 491/10000 (4.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4295s / 21.4324 s
agent0:                 episode reward: 0.7604,                 loss: nan
agent1:                 episode reward: -0.7604,                 loss: 0.4406
Episode: 501/10000 (5.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4181s / 21.8504 s
agent0:                 episode reward: 1.4649,                 loss: nan
agent1:                 episode reward: -1.4649,                 loss: 0.4402
Episode: 511/10000 (5.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4220s / 22.2725 s
agent0:                 episode reward: 0.9534,                 loss: nan
agent1:                 episode reward: -0.9534,                 loss: 0.4407
Episode: 521/10000 (5.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4235s / 22.6959 s
agent0:                 episode reward: 0.2412,                 loss: nan
agent1:                 episode reward: -0.2412,                 loss: 0.4411
Episode: 531/10000 (5.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4190s / 23.1150 s
agent0:                 episode reward: 0.8906,                 loss: nan
agent1:                 episode reward: -0.8906,                 loss: 0.4398
Episode: 541/10000 (5.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4215s / 23.5365 s
agent0:                 episode reward: 0.0611,                 loss: nan
agent1:                 episode reward: -0.0611,                 loss: 0.4394
Episode: 551/10000 (5.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4148s / 23.9513 s
agent0:                 episode reward: -0.0999,                 loss: nan
agent1:                 episode reward: 0.0999,                 loss: 0.4402
Episode: 561/10000 (5.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4454s / 24.3967 s
agent0:                 episode reward: 1.1308,                 loss: nan
agent1:                 episode reward: -1.1308,                 loss: 0.4412
Episode: 571/10000 (5.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4359s / 24.8325 s
agent0:                 episode reward: 1.0582,                 loss: nan
agent1:                 episode reward: -1.0582,                 loss: 0.4433
Episode: 581/10000 (5.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4444s / 25.2770 s
agent0:                 episode reward: 0.6612,                 loss: nan
agent1:                 episode reward: -0.6612,                 loss: 0.4443
Episode: 591/10000 (5.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4497s / 25.7267 s
agent0:                 episode reward: 0.8688,                 loss: nan
agent1:                 episode reward: -0.8688,                 loss: 0.4432
Episode: 601/10000 (6.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4232s / 26.1499 s
agent0:                 episode reward: 0.5644,                 loss: nan
agent1:                 episode reward: -0.5644,                 loss: 0.4430
Episode: 611/10000 (6.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4185s / 26.5683 s
agent0:                 episode reward: 0.9052,                 loss: nan
agent1:                 episode reward: -0.9052,                 loss: 0.4428
Episode: 621/10000 (6.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4192s / 26.9875 s
agent0:                 episode reward: 0.2076,                 loss: nan
agent1:                 episode reward: -0.2076,                 loss: 0.4443
Episode: 631/10000 (6.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4233s / 27.4109 s
agent0:                 episode reward: 1.4734,                 loss: nan
agent1:                 episode reward: -1.4734,                 loss: 0.4439
Episode: 641/10000 (6.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4289s / 27.8398 s
agent0:                 episode reward: 0.7548,                 loss: nan
agent1:                 episode reward: -0.7548,                 loss: 0.4423
Episode: 651/10000 (6.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4866s / 28.3264 s
agent0:                 episode reward: 0.2899,                 loss: nan
agent1:                 episode reward: -0.2899,                 loss: 0.4436
Episode: 661/10000 (6.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4502s / 28.7766 s
agent0:                 episode reward: 0.8272,                 loss: nan
agent1:                 episode reward: -0.8272,                 loss: 0.4427
Episode: 671/10000 (6.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4346s / 29.2112 s
agent0:                 episode reward: 0.1163,                 loss: nan
agent1:                 episode reward: -0.1163,                 loss: 0.4444
Episode: 681/10000 (6.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4280s / 29.6392 s
agent0:                 episode reward: 0.4481,                 loss: nan
agent1:                 episode reward: -0.4481,                 loss: 0.4441
Episode: 691/10000 (6.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4594s / 30.0986 s
agent0:                 episode reward: 1.2482,                 loss: nan
agent1:                 episode reward: -1.2482,                 loss: 0.4437
Episode: 701/10000 (7.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5055s / 30.6041 s
agent0:                 episode reward: 0.1332,                 loss: nan
agent1:                 episode reward: -0.1332,                 loss: 0.4430
Episode: 711/10000 (7.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5187s / 31.1228 s
agent0:                 episode reward: 1.5095,                 loss: nan
agent1:                 episode reward: -1.5095,                 loss: 0.4431
Episode: 721/10000 (7.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5422s / 31.6649 s
agent0:                 episode reward: 1.8011,                 loss: nan
agent1:                 episode reward: -1.8011,                 loss: 0.4413
Episode: 731/10000 (7.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5404s / 32.2054 s
agent0:                 episode reward: -0.9334,                 loss: nan
agent1:                 episode reward: 0.9334,                 loss: 0.4427
Episode: 741/10000 (7.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5344s / 32.7397 s
agent0:                 episode reward: 0.4253,                 loss: nan
agent1:                 episode reward: -0.4253,                 loss: 0.4421
Episode: 751/10000 (7.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5001s / 33.2398 s
agent0:                 episode reward: 1.0464,                 loss: nan
agent1:                 episode reward: -1.0464,                 loss: 0.4409
Episode: 761/10000 (7.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4964s / 33.7362 s
agent0:                 episode reward: 0.5760,                 loss: nan
agent1:                 episode reward: -0.5760,                 loss: 0.4392
Episode: 771/10000 (7.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5548s / 34.2910 s
agent0:                 episode reward: 1.2368,                 loss: nan
agent1:                 episode reward: -1.2368,                 loss: 0.4325
Episode: 781/10000 (7.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5479s / 34.8389 s
agent0:                 episode reward: 1.5533,                 loss: nan
agent1:                 episode reward: -1.5533,                 loss: 0.4252
Episode: 791/10000 (7.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5347s / 35.3736 s
agent0:                 episode reward: 1.0399,                 loss: nan
agent1:                 episode reward: -1.0399,                 loss: 0.4242
Episode: 801/10000 (8.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5294s / 35.9030 s
agent0:                 episode reward: 1.3434,                 loss: nan
agent1:                 episode reward: -1.3434,                 loss: 0.4236
Episode: 811/10000 (8.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5271s / 36.4301 s
agent0:                 episode reward: -0.3568,                 loss: nan
agent1:                 episode reward: 0.3568,                 loss: 0.4239
Episode: 821/10000 (8.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5327s / 36.9628 s
agent0:                 episode reward: 0.9568,                 loss: nan
agent1:                 episode reward: -0.9568,                 loss: 0.4231
Episode: 831/10000 (8.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5298s / 37.4926 s
agent0:                 episode reward: 0.4433,                 loss: nan
agent1:                 episode reward: -0.4433,                 loss: 0.4209
Episode: 841/10000 (8.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5443s / 38.0369 s
agent0:                 episode reward: 0.0979,                 loss: nan
agent1:                 episode reward: -0.0979,                 loss: 0.4198
Episode: 851/10000 (8.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6049s / 38.6418 s
agent0:                 episode reward: 0.1821,                 loss: nan
agent1:                 episode reward: -0.1821,                 loss: 0.4195
Episode: 861/10000 (8.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5448s / 39.1866 s
agent0:                 episode reward: 0.0701,                 loss: nan
agent1:                 episode reward: -0.0701,                 loss: 0.4221
Episode: 871/10000 (8.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5466s / 39.7332 s
agent0:                 episode reward: 0.9104,                 loss: nan
agent1:                 episode reward: -0.9104,                 loss: 0.3957
Episode: 881/10000 (8.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5347s / 40.2680 s
agent0:                 episode reward: -0.3112,                 loss: nan
agent1:                 episode reward: 0.3112,                 loss: 0.3803
Episode: 891/10000 (8.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5483s / 40.8163 s
agent0:                 episode reward: 0.6608,                 loss: nan
agent1:                 episode reward: -0.6608,                 loss: 0.3795
Episode: 901/10000 (9.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5384s / 41.3547 s
agent0:                 episode reward: 0.6613,                 loss: nan
agent1:                 episode reward: -0.6613,                 loss: 0.3774
Episode: 911/10000 (9.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5585s / 41.9132 s
agent0:                 episode reward: 0.2050,                 loss: nan
agent1:                 episode reward: -0.2050,                 loss: 0.3759
Episode: 921/10000 (9.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5473s / 42.4606 s
agent0:                 episode reward: 0.9069,                 loss: nan
agent1:                 episode reward: -0.9069,                 loss: 0.3768
Episode: 931/10000 (9.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5404s / 43.0010 s
agent0:                 episode reward: 0.7667,                 loss: nan
agent1:                 episode reward: -0.7667,                 loss: 0.3741
Episode: 941/10000 (9.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5407s / 43.5417 s
agent0:                 episode reward: 0.2889,                 loss: nan
agent1:                 episode reward: -0.2889,                 loss: 0.3752
Episode: 951/10000 (9.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5606s / 44.1023 s
agent0:                 episode reward: 1.1879,                 loss: nan
agent1:                 episode reward: -1.1879,                 loss: 0.3722
Episode: 961/10000 (9.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5424s / 44.6447 s
agent0:                 episode reward: -0.2398,                 loss: nan
agent1:                 episode reward: 0.2398,                 loss: 0.3710
Episode: 971/10000 (9.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5430s / 45.1877 s
agent0:                 episode reward: 0.2941,                 loss: nan
agent1:                 episode reward: -0.2941,                 loss: 0.3418
Episode: 981/10000 (9.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5514s / 45.7390 s
agent0:                 episode reward: 0.6307,                 loss: nan
agent1:                 episode reward: -0.6307,                 loss: 0.3225
Episode: 991/10000 (9.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5406s / 46.2796 s
agent0:                 episode reward: 0.8443,                 loss: nan
agent1:                 episode reward: -0.8443,                 loss: 0.3209
Episode: 1001/10000 (10.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5499s / 46.8296 s
agent0:                 episode reward: -0.0462,                 loss: nan
agent1:                 episode reward: 0.0462,                 loss: 0.3182
Episode: 1011/10000 (10.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5559s / 47.3855 s
agent0:                 episode reward: 1.2918,                 loss: nan
agent1:                 episode reward: -1.2918,                 loss: 0.3145
Episode: 1021/10000 (10.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5445s / 47.9300 s
agent0:                 episode reward: 0.0790,                 loss: nan
agent1:                 episode reward: -0.0790,                 loss: 0.3157
Episode: 1031/10000 (10.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5471s / 48.4772 s
agent0:                 episode reward: 0.5904,                 loss: nan
agent1:                 episode reward: -0.5904,                 loss: 0.3122
Episode: 1041/10000 (10.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6015s / 49.0786 s
agent0:                 episode reward: -0.0118,                 loss: nan
agent1:                 episode reward: 0.0118,                 loss: 0.3126
Episode: 1051/10000 (10.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5529s / 49.6316 s
agent0:                 episode reward: 0.7109,                 loss: nan
agent1:                 episode reward: -0.7109,                 loss: 0.3111
Episode: 1061/10000 (10.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5731s / 50.2047 s
agent0:                 episode reward: 0.7736,                 loss: nan
agent1:                 episode reward: -0.7736,                 loss: 0.3093
Episode: 1071/10000 (10.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5521s / 50.7567 s
agent0:                 episode reward: 1.6567,                 loss: nan
agent1:                 episode reward: -1.6567,                 loss: 0.2837
Episode: 1081/10000 (10.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5496s / 51.3063 s
agent0:                 episode reward: 1.3111,                 loss: nan
agent1:                 episode reward: -1.3111,                 loss: 0.2692
Episode: 1091/10000 (10.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5509s / 51.8572 s
agent0:                 episode reward: -0.2368,                 loss: nan
agent1:                 episode reward: 0.2368,                 loss: 0.2664
Episode: 1101/10000 (11.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5531s / 52.4104 s
agent0:                 episode reward: 0.8751,                 loss: nan
agent1:                 episode reward: -0.8751,                 loss: 0.2658
Episode: 1111/10000 (11.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5790s / 52.9893 s
agent0:                 episode reward: 0.4780,                 loss: nan
agent1:                 episode reward: -0.4780,                 loss: 0.2602
Episode: 1121/10000 (11.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5544s / 53.5438 s
agent0:                 episode reward: 0.6412,                 loss: nan
agent1:                 episode reward: -0.6412,                 loss: 0.2616
Episode: 1131/10000 (11.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5575s / 54.1013 s
agent0:                 episode reward: 1.3699,                 loss: nan
agent1:                 episode reward: -1.3699,                 loss: 0.2575
Episode: 1141/10000 (11.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5604s / 54.6617 s
agent0:                 episode reward: 0.8410,                 loss: nan
agent1:                 episode reward: -0.8410,                 loss: 0.2564
Episode: 1151/10000 (11.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5537s / 55.2154 s
agent0:                 episode reward: 0.8582,                 loss: nan
agent1:                 episode reward: -0.8582,                 loss: 0.2542
Episode: 1161/10000 (11.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5647s / 55.7801 s
agent0:                 episode reward: 1.5259,                 loss: nan
agent1:                 episode reward: -1.5259,                 loss: 0.2513
Episode: 1171/10000 (11.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5626s / 56.3427 s
agent0:                 episode reward: -0.0055,                 loss: nan
agent1:                 episode reward: 0.0055,                 loss: 0.2460
Episode: 1181/10000 (11.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5676s / 56.9103 s
agent0:                 episode reward: 1.0847,                 loss: nan
agent1:                 episode reward: -1.0847,                 loss: 0.2393
Episode: 1191/10000 (11.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5654s / 57.4757 s
agent0:                 episode reward: 0.8643,                 loss: nan
agent1:                 episode reward: -0.8643,                 loss: 0.2334
Episode: 1201/10000 (12.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5606s / 58.0363 s
agent0:                 episode reward: 0.4028,                 loss: nan
agent1:                 episode reward: -0.4028,                 loss: 0.2325
Episode: 1211/10000 (12.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5815s / 58.6179 s
agent0:                 episode reward: 0.9099,                 loss: nan
agent1:                 episode reward: -0.9099,                 loss: 0.2315
Episode: 1221/10000 (12.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6229s / 59.2407 s
agent0:                 episode reward: 0.8484,                 loss: nan
agent1:                 episode reward: -0.8484,                 loss: 0.2282
Episode: 1231/10000 (12.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5680s / 59.8087 s
agent0:                 episode reward: -0.0346,                 loss: nan
agent1:                 episode reward: 0.0346,                 loss: 0.2256
Episode: 1241/10000 (12.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5612s / 60.3699 s
agent0:                 episode reward: 1.2148,                 loss: nan
agent1:                 episode reward: -1.2148,                 loss: 0.2259
Episode: 1251/10000 (12.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5609s / 60.9308 s
agent0:                 episode reward: -0.3195,                 loss: nan
agent1:                 episode reward: 0.3195,                 loss: 0.2271
Episode: 1261/10000 (12.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5592s / 61.4900 s
agent0:                 episode reward: 0.2794,                 loss: nan
agent1:                 episode reward: -0.2794,                 loss: 0.2236
Episode: 1271/10000 (12.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5768s / 62.0668 s
agent0:                 episode reward: -0.4790,                 loss: nan
agent1:                 episode reward: 0.4790,                 loss: 0.2341
Episode: 1281/10000 (12.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5593s / 62.6261 s
agent0:                 episode reward: 0.1376,                 loss: nan
agent1:                 episode reward: -0.1376,                 loss: 0.2371
Episode: 1291/10000 (12.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5616s / 63.1878 s
agent0:                 episode reward: 0.6311,                 loss: nan
agent1:                 episode reward: -0.6311,                 loss: 0.2363
Episode: 1301/10000 (13.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5662s / 63.7540 s
agent0:                 episode reward: 0.4259,                 loss: nan
agent1:                 episode reward: -0.4259,                 loss: 0.2372
Episode: 1311/10000 (13.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5658s / 64.3198 s
agent0:                 episode reward: -0.2590,                 loss: nan
agent1:                 episode reward: 0.2590,                 loss: 0.2334
Episode: 1321/10000 (13.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5902s / 64.9099 s
agent0:                 episode reward: 0.0663,                 loss: nan
agent1:                 episode reward: -0.0663,                 loss: 0.2353
Episode: 1331/10000 (13.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5753s / 65.4853 s
agent0:                 episode reward: 0.5298,                 loss: nan
agent1:                 episode reward: -0.5298,                 loss: 0.2358
Episode: 1341/10000 (13.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5651s / 66.0503 s
agent0:                 episode reward: -0.8888,                 loss: nan
agent1:                 episode reward: 0.8888,                 loss: 0.2331
Episode: 1351/10000 (13.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5754s / 66.6257 s
agent0:                 episode reward: 1.0991,                 loss: nan
agent1:                 episode reward: -1.0991,                 loss: 0.2326
Episode: 1361/10000 (13.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5824s / 67.2081 s
agent0:                 episode reward: -0.4238,                 loss: nan
agent1:                 episode reward: 0.4238,                 loss: 0.2348
Episode: 1371/10000 (13.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5745s / 67.7826 s
agent0:                 episode reward: 0.1361,                 loss: nan
agent1:                 episode reward: -0.1361,                 loss: 0.2604
Episode: 1381/10000 (13.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5866s / 68.3692 s
agent0:                 episode reward: 1.0561,                 loss: nan
agent1:                 episode reward: -1.0561,                 loss: 0.2677
Episode: 1391/10000 (13.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5768s / 68.9460 s
agent0:                 episode reward: -0.0987,                 loss: nan
agent1:                 episode reward: 0.0987,                 loss: 0.2656
Episode: 1401/10000 (14.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6518s / 69.5978 s
agent0:                 episode reward: 0.2580,                 loss: nan
agent1:                 episode reward: -0.2580,                 loss: 0.2651
Episode: 1411/10000 (14.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5757s / 70.1735 s
agent0:                 episode reward: 1.9051,                 loss: nan
agent1:                 episode reward: -1.9051,                 loss: 0.2663
Episode: 1421/10000 (14.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5683s / 70.7418 s
agent0:                 episode reward: 0.2946,                 loss: nan
agent1:                 episode reward: -0.2946,                 loss: 0.2653
Episode: 1431/10000 (14.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5812s / 71.3230 s
agent0:                 episode reward: 1.0853,                 loss: nan
agent1:                 episode reward: -1.0853,                 loss: 0.2630
Episode: 1441/10000 (14.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5967s / 71.9197 s
agent0:                 episode reward: 1.1398,                 loss: nan
agent1:                 episode reward: -1.1398,                 loss: 0.2603
Episode: 1451/10000 (14.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5720s / 72.4916 s
agent0:                 episode reward: 0.7971,                 loss: nan
agent1:                 episode reward: -0.7971,                 loss: 0.2612
Episode: 1461/10000 (14.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5720s / 73.0636 s
agent0:                 episode reward: 0.3156,                 loss: nan
agent1:                 episode reward: -0.3156,                 loss: 0.2643
Episode: 1471/10000 (14.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5780s / 73.6416 s
agent0:                 episode reward: 0.8007,                 loss: nan
agent1:                 episode reward: -0.8007,                 loss: 0.2997
Episode: 1481/10000 (14.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5867s / 74.2283 s
agent0:                 episode reward: 0.4244,                 loss: nan
agent1:                 episode reward: -0.4244,                 loss: 0.3066
Episode: 1491/10000 (14.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5807s / 74.8090 s
agent0:                 episode reward: 0.2526,                 loss: nan
agent1:                 episode reward: -0.2526,                 loss: 0.3053
Episode: 1501/10000 (15.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6028s / 75.4119 s
agent0:                 episode reward: 0.6033,                 loss: nan
agent1:                 episode reward: -0.6033,                 loss: 0.3048
Episode: 1511/10000 (15.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5735s / 75.9853 s
agent0:                 episode reward: 0.6200,                 loss: nan
agent1:                 episode reward: -0.6200,                 loss: 0.3055
Episode: 1521/10000 (15.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5705s / 76.5558 s
agent0:                 episode reward: 1.1477,                 loss: nan
agent1:                 episode reward: -1.1477,                 loss: 0.3027
Episode: 1531/10000 (15.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5869s / 77.1427 s
agent0:                 episode reward: 0.4638,                 loss: nan
agent1:                 episode reward: -0.4638,                 loss: 0.3020
Episode: 1541/10000 (15.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5755s / 77.7182 s
agent0:                 episode reward: 1.7128,                 loss: nan
agent1:                 episode reward: -1.7128,                 loss: 0.3029
Episode: 1551/10000 (15.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5754s / 78.2936 s
agent0:                 episode reward: 0.4569,                 loss: nan
agent1:                 episode reward: -0.4569,                 loss: 0.3009
Episode: 1561/10000 (15.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5770s / 78.8706 s
agent0:                 episode reward: 0.5758,                 loss: nan
agent1:                 episode reward: -0.5758,                 loss: 0.2991
Episode: 1571/10000 (15.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6529s / 79.5235 s
agent0:                 episode reward: 1.2751,                 loss: nan
agent1:                 episode reward: -1.2751,                 loss: 0.3263
Episode: 1581/10000 (15.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5960s / 80.1195 s
agent0:                 episode reward: 1.1183,                 loss: nan
agent1:                 episode reward: -1.1183,                 loss: 0.3309
Episode: 1591/10000 (15.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5904s / 80.7099 s
agent0:                 episode reward: -0.1560,                 loss: nan
agent1:                 episode reward: 0.1560,                 loss: 0.3271
Episode: 1601/10000 (16.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5836s / 81.2936 s
agent0:                 episode reward: 0.9612,                 loss: nan
agent1:                 episode reward: -0.9612,                 loss: 0.3289
Episode: 1611/10000 (16.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5761s / 81.8696 s
agent0:                 episode reward: 1.6632,                 loss: nan
agent1:                 episode reward: -1.6632,                 loss: 0.3267
Episode: 1621/10000 (16.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6035s / 82.4731 s
agent0:                 episode reward: 0.3943,                 loss: nan
agent1:                 episode reward: -0.3943,                 loss: 0.3245
Episode: 1631/10000 (16.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5900s / 83.0631 s
agent0:                 episode reward: 0.5668,                 loss: nan
agent1:                 episode reward: -0.5668,                 loss: 0.3255
Episode: 1641/10000 (16.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6102s / 83.6732 s
agent0:                 episode reward: 0.4925,                 loss: nan
agent1:                 episode reward: -0.4925,                 loss: 0.3271
Episode: 1651/10000 (16.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5817s / 84.2549 s
agent0:                 episode reward: 0.0740,                 loss: nan
agent1:                 episode reward: -0.0740,                 loss: 0.3263
Episode: 1661/10000 (16.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5842s / 84.8391 s
agent0:                 episode reward: 0.1974,                 loss: nan
agent1:                 episode reward: -0.1974,                 loss: 0.3246
Episode: 1671/10000 (16.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5795s / 85.4186 s
agent0:                 episode reward: 1.1918,                 loss: nan
agent1:                 episode reward: -1.1918,                 loss: 0.3343
Episode: 1681/10000 (16.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6099s / 86.0285 s
agent0:                 episode reward: 1.0960,                 loss: nan
agent1:                 episode reward: -1.0960,                 loss: 0.3287
Episode: 1691/10000 (16.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5870s / 86.6155 s
agent0:                 episode reward: -0.1861,                 loss: nan
agent1:                 episode reward: 0.1861,                 loss: 0.3277
Episode: 1701/10000 (17.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5871s / 87.2026 s
agent0:                 episode reward: 0.2177,                 loss: nan
agent1:                 episode reward: -0.2177,                 loss: 0.3282
Episode: 1711/10000 (17.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6079s / 87.8105 s
agent0:                 episode reward: 0.9228,                 loss: nan
agent1:                 episode reward: -0.9228,                 loss: 0.3283
Episode: 1721/10000 (17.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5879s / 88.3984 s
agent0:                 episode reward: 0.7374,                 loss: nan
agent1:                 episode reward: -0.7374,                 loss: 0.3236
Episode: 1731/10000 (17.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5881s / 88.9866 s
agent0:                 episode reward: 1.3687,                 loss: nan
agent1:                 episode reward: -1.3687,                 loss: 0.3264
Episode: 1741/10000 (17.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6119s / 89.5984 s
agent0:                 episode reward: -0.4982,                 loss: nan
agent1:                 episode reward: 0.4982,                 loss: 0.3275
Episode: 1751/10000 (17.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6324s / 90.2308 s
agent0:                 episode reward: 0.4389,                 loss: nan
agent1:                 episode reward: -0.4389,                 loss: 0.3266
Episode: 1761/10000 (17.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5917s / 90.8225 s
agent0:                 episode reward: 0.4294,                 loss: nan
agent1:                 episode reward: -0.4294,                 loss: 0.3237
Episode: 1771/10000 (17.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6042s / 91.4267 s
agent0:                 episode reward: 1.4256,                 loss: nan
agent1:                 episode reward: -1.4256,                 loss: 0.3316
Episode: 1781/10000 (17.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6274s / 92.0541 s
agent0:                 episode reward: 0.8569,                 loss: nan
agent1:                 episode reward: -0.8569,                 loss: 0.3280
Episode: 1791/10000 (17.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6504s / 92.7045 s
agent0:                 episode reward: -0.0460,                 loss: nan
agent1:                 episode reward: 0.0460,                 loss: 0.3277
Episode: 1801/10000 (18.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5902s / 93.2946 s
agent0:                 episode reward: 0.1131,                 loss: nan
agent1:                 episode reward: -0.1131,                 loss: 0.3257
Episode: 1811/10000 (18.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5906s / 93.8853 s
agent0:                 episode reward: -0.0471,                 loss: nan
agent1:                 episode reward: 0.0471,                 loss: 0.3259
Episode: 1821/10000 (18.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5919s / 94.4771 s
agent0:                 episode reward: 0.1061,                 loss: nan
agent1:                 episode reward: -0.1061,                 loss: 0.3245
Episode: 1831/10000 (18.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5977s / 95.0749 s
agent0:                 episode reward: 0.9831,                 loss: nan
agent1:                 episode reward: -0.9831,                 loss: 0.3254
Episode: 1841/10000 (18.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6012s / 95.6760 s
agent0:                 episode reward: 0.8783,                 loss: nan
agent1:                 episode reward: -0.8783,                 loss: 0.3234
Episode: 1851/10000 (18.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5948s / 96.2708 s
agent0:                 episode reward: 1.4621,                 loss: nan
agent1:                 episode reward: -1.4621,                 loss: 0.3241
Episode: 1861/10000 (18.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5954s / 96.8663 s
agent0:                 episode reward: -0.2411,                 loss: nan
agent1:                 episode reward: 0.2411,                 loss: 0.3213
Episode: 1871/10000 (18.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5950s / 97.4612 s
agent0:                 episode reward: 0.9812,                 loss: nan
agent1:                 episode reward: -0.9812,                 loss: 0.3387
Episode: 1881/10000 (18.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6048s / 98.0661 s
agent0:                 episode reward: 0.8508,                 loss: nan
agent1:                 episode reward: -0.8508,                 loss: 0.3426
Episode: 1891/10000 (18.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6240s / 98.6901 s
agent0:                 episode reward: 0.1435,                 loss: nan
agent1:                 episode reward: -0.1435,                 loss: 0.3422
Episode: 1901/10000 (19.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5950s / 99.2851 s
agent0:                 episode reward: 1.6581,                 loss: nan
agent1:                 episode reward: -1.6581,                 loss: 0.3410
Episode: 1911/10000 (19.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6704s / 99.9554 s
agent0:                 episode reward: 0.9210,                 loss: nan
agent1:                 episode reward: -0.9210,                 loss: 0.3398
Episode: 1921/10000 (19.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6120s / 100.5674 s
agent0:                 episode reward: 0.2061,                 loss: nan
agent1:                 episode reward: -0.2061,                 loss: 0.3401
Episode: 1931/10000 (19.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6030s / 101.1704 s
agent0:                 episode reward: -0.2536,                 loss: nan
agent1:                 episode reward: 0.2536,                 loss: 0.3374
Episode: 1941/10000 (19.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6145s / 101.7849 s
agent0:                 episode reward: 0.9480,                 loss: nan
agent1:                 episode reward: -0.9480,                 loss: 0.3334
Episode: 1951/10000 (19.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5972s / 102.3821 s
agent0:                 episode reward: 1.7310,                 loss: nan
agent1:                 episode reward: -1.7310,                 loss: 0.3346
Episode: 1961/10000 (19.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6030s / 102.9851 s
agent0:                 episode reward: 0.4347,                 loss: nan
agent1:                 episode reward: -0.4347,                 loss: 0.3339
Episode: 1971/10000 (19.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6011s / 103.5863 s
agent0:                 episode reward: -0.1540,                 loss: nan
agent1:                 episode reward: 0.1540,                 loss: 0.3570
Episode: 1981/10000 (19.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5987s / 104.1850 s
agent0:                 episode reward: 0.7747,                 loss: nan
agent1:                 episode reward: -0.7747,                 loss: 0.3641
Episode: 1991/10000 (19.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6131s / 104.7981 s
agent0:                 episode reward: 0.4400,                 loss: nan
agent1:                 episode reward: -0.4400,                 loss: 0.3648
Episode: 2001/10000 (20.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5988s / 105.3969 s
agent0:                 episode reward: -0.0935,                 loss: nan
agent1:                 episode reward: 0.0935,                 loss: 0.3639
Episode: 2011/10000 (20.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6174s / 106.0143 s
agent0:                 episode reward: 0.1023,                 loss: nan
agent1:                 episode reward: -0.1023,                 loss: 0.3639
Episode: 2021/10000 (20.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6161s / 106.6304 s
agent0:                 episode reward: 0.0525,                 loss: nan
agent1:                 episode reward: -0.0525,                 loss: 0.3623
Episode: 2031/10000 (20.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6037s / 107.2341 s
agent0:                 episode reward: 1.2142,                 loss: nan
agent1:                 episode reward: -1.2142,                 loss: 0.3607
Episode: 2041/10000 (20.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6155s / 107.8496 s
agent0:                 episode reward: 0.2999,                 loss: nan
agent1:                 episode reward: -0.2999,                 loss: 0.3617
Episode: 2051/10000 (20.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6200s / 108.4696 s
agent0:                 episode reward: 1.5244,                 loss: nan
agent1:                 episode reward: -1.5244,                 loss: 0.3617
Episode: 2061/10000 (20.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6046s / 109.0742 s
agent0:                 episode reward: 0.0502,                 loss: nan
agent1:                 episode reward: -0.0502,                 loss: 0.3608
Episode: 2071/10000 (20.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6062s / 109.6804 s
agent0:                 episode reward: -0.2303,                 loss: nan
agent1:                 episode reward: 0.2303,                 loss: 0.3837
Episode: 2081/10000 (20.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6946s / 110.3750 s
agent0:                 episode reward: 0.7705,                 loss: nan
agent1:                 episode reward: -0.7705,                 loss: 0.3903
Episode: 2091/10000 (20.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6070s / 110.9821 s
agent0:                 episode reward: 0.1923,                 loss: nan
agent1:                 episode reward: -0.1923,                 loss: 0.3910
Episode: 2101/10000 (21.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6051s / 111.5872 s
agent0:                 episode reward: -0.4964,                 loss: nan
agent1:                 episode reward: 0.4964,                 loss: 0.3904
Episode: 2111/10000 (21.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6027s / 112.1899 s
agent0:                 episode reward: 0.6438,                 loss: nan
agent1:                 episode reward: -0.6438,                 loss: 0.3893
Episode: 2121/10000 (21.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6079s / 112.7978 s
agent0:                 episode reward: -0.2051,                 loss: nan
agent1:                 episode reward: 0.2051,                 loss: 0.3882
Episode: 2131/10000 (21.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6134s / 113.4112 s
agent0:                 episode reward: 0.4274,                 loss: nan
agent1:                 episode reward: -0.4274,                 loss: 0.3870
Episode: 2141/10000 (21.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6596s / 114.0708 s
agent0:                 episode reward: -0.3948,                 loss: nan
agent1:                 episode reward: 0.3948,                 loss: 0.3873
Episode: 2151/10000 (21.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6078s / 114.6786 s
agent0:                 episode reward: 0.1131,                 loss: nan
agent1:                 episode reward: -0.1131,                 loss: 0.3857
Episode: 2161/10000 (21.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6087s / 115.2873 s
agent0:                 episode reward: -0.8592,                 loss: nan
agent1:                 episode reward: 0.8592,                 loss: 0.3841
Episode: 2171/10000 (21.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6078s / 115.8951 s
agent0:                 episode reward: -0.4734,                 loss: nan
agent1:                 episode reward: 0.4734,                 loss: 0.4014
Episode: 2181/10000 (21.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6364s / 116.5315 s
agent0:                 episode reward: 0.2410,                 loss: nan
agent1:                 episode reward: -0.2410,                 loss: 0.4051
Episode: 2191/10000 (21.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6439s / 117.1754 s
agent0:                 episode reward: -0.1678,                 loss: nan
agent1:                 episode reward: 0.1678,                 loss: 0.4045
Episode: 2201/10000 (22.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6140s / 117.7894 s
agent0:                 episode reward: -0.1960,                 loss: nan
agent1:                 episode reward: 0.1960,                 loss: 0.4031
Episode: 2211/10000 (22.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6170s / 118.4064 s
agent0:                 episode reward: 0.3402,                 loss: nan
agent1:                 episode reward: -0.3402,                 loss: 0.4026
Episode: 2221/10000 (22.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6771s / 119.0835 s
agent0:                 episode reward: 1.3139,                 loss: nan
agent1:                 episode reward: -1.3139,                 loss: 0.4016
Episode: 2231/10000 (22.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6345s / 119.7180 s
agent0:                 episode reward: -0.5060,                 loss: nan
agent1:                 episode reward: 0.5060,                 loss: 0.4004
Episode: 2241/10000 (22.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6247s / 120.3427 s
agent0:                 episode reward: 0.2959,                 loss: nan
agent1:                 episode reward: -0.2959,                 loss: 0.4016
Episode: 2251/10000 (22.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6894s / 121.0321 s
agent0:                 episode reward: 0.0888,                 loss: nan
agent1:                 episode reward: -0.0888,                 loss: 0.4020
Episode: 2261/10000 (22.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6139s / 121.6459 s
agent0:                 episode reward: 0.2581,                 loss: nan
agent1:                 episode reward: -0.2581,                 loss: 0.3988
Episode: 2271/10000 (22.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6180s / 122.2639 s
agent0:                 episode reward: 0.2434,                 loss: nan
agent1:                 episode reward: -0.2434,                 loss: 0.3939
Episode: 2281/10000 (22.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6227s / 122.8866 s
agent0:                 episode reward: -0.0134,                 loss: nan
agent1:                 episode reward: 0.0134,                 loss: 0.3865
Episode: 2291/10000 (22.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6189s / 123.5055 s
agent0:                 episode reward: 0.6563,                 loss: nan
agent1:                 episode reward: -0.6563,                 loss: 0.3819
Episode: 2301/10000 (23.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6187s / 124.1242 s
agent0:                 episode reward: 0.4561,                 loss: nan
agent1:                 episode reward: -0.4561,                 loss: 0.3811
Episode: 2311/10000 (23.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6351s / 124.7592 s
agent0:                 episode reward: -0.4184,                 loss: nan
agent1:                 episode reward: 0.4184,                 loss: 0.3825
Episode: 2321/10000 (23.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6166s / 125.3758 s
agent0:                 episode reward: -0.2453,                 loss: nan
agent1:                 episode reward: 0.2453,                 loss: 0.3824
Episode: 2331/10000 (23.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6278s / 126.0036 s
agent0:                 episode reward: -0.1238,                 loss: nan
agent1:                 episode reward: 0.1238,                 loss: 0.3809
Episode: 2341/10000 (23.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6165s / 126.6201 s
agent0:                 episode reward: 0.4976,                 loss: nan
agent1:                 episode reward: -0.4976,                 loss: 0.3794
Episode: 2351/10000 (23.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6162s / 127.2363 s
agent0:                 episode reward: 0.2790,                 loss: nan
agent1:                 episode reward: -0.2790,                 loss: 0.3792
Episode: 2361/10000 (23.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6197s / 127.8560 s
agent0:                 episode reward: 0.2367,                 loss: nan
agent1:                 episode reward: -0.2367,                 loss: 0.3778
Episode: 2371/10000 (23.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6263s / 128.4823 s
agent0:                 episode reward: -0.8575,                 loss: nan
agent1:                 episode reward: 0.8575,                 loss: 0.3561
Episode: 2381/10000 (23.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6207s / 129.1030 s
agent0:                 episode reward: -0.1523,                 loss: nan
agent1:                 episode reward: 0.1523,                 loss: 0.3375
Episode: 2391/10000 (23.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6185s / 129.7216 s
agent0:                 episode reward: 0.6103,                 loss: nan
agent1:                 episode reward: -0.6103,                 loss: 0.3373
Episode: 2401/10000 (24.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6385s / 130.3601 s
agent0:                 episode reward: 0.1338,                 loss: nan
agent1:                 episode reward: -0.1338,                 loss: 0.3321
Episode: 2411/10000 (24.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6885s / 131.0486 s
agent0:                 episode reward: 1.0134,                 loss: nan
agent1:                 episode reward: -1.0134,                 loss: 0.3345
Episode: 2421/10000 (24.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6700s / 131.7187 s
agent0:                 episode reward: 0.4251,                 loss: nan
agent1:                 episode reward: -0.4251,                 loss: 0.3378
Episode: 2431/10000 (24.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6307s / 132.3494 s
agent0:                 episode reward: 0.3778,                 loss: nan
agent1:                 episode reward: -0.3778,                 loss: 0.3355
Episode: 2441/10000 (24.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6342s / 132.9836 s
agent0:                 episode reward: -0.5152,                 loss: nan
agent1:                 episode reward: 0.5152,                 loss: 0.3335
Episode: 2451/10000 (24.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6910s / 133.6745 s
agent0:                 episode reward: 0.2220,                 loss: nan
agent1:                 episode reward: -0.2220,                 loss: 0.3332
Episode: 2461/10000 (24.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6201s / 134.2946 s
agent0:                 episode reward: -0.7818,                 loss: nan
agent1:                 episode reward: 0.7818,                 loss: 0.3330
Episode: 2471/10000 (24.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6321s / 134.9267 s
agent0:                 episode reward: -1.4713,                 loss: nan
agent1:                 episode reward: 1.4713,                 loss: 0.3253
Episode: 2481/10000 (24.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6283s / 135.5551 s
agent0:                 episode reward: 0.5810,                 loss: nan
agent1:                 episode reward: -0.5810,                 loss: 0.3160
Episode: 2491/10000 (24.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6242s / 136.1793 s
agent0:                 episode reward: 0.6501,                 loss: nan
agent1:                 episode reward: -0.6501,                 loss: 0.3186
Episode: 2501/10000 (25.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6299s / 136.8091 s
agent0:                 episode reward: -0.5130,                 loss: nan
agent1:                 episode reward: 0.5130,                 loss: 0.3154
Episode: 2511/10000 (25.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6278s / 137.4369 s
agent0:                 episode reward: 0.4861,                 loss: nan
agent1:                 episode reward: -0.4861,                 loss: 0.3167
Episode: 2521/10000 (25.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6572s / 138.0941 s
agent0:                 episode reward: -0.0686,                 loss: nan
agent1:                 episode reward: 0.0686,                 loss: 0.3172
Episode: 2531/10000 (25.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6608s / 138.7549 s
agent0:                 episode reward: 0.5121,                 loss: nan
agent1:                 episode reward: -0.5121,                 loss: 0.3150
Episode: 2541/10000 (25.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6317s / 139.3867 s
agent0:                 episode reward: -0.8420,                 loss: nan
agent1:                 episode reward: 0.8420,                 loss: 0.3149
Episode: 2551/10000 (25.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6287s / 140.0154 s
agent0:                 episode reward: 0.1572,                 loss: nan
agent1:                 episode reward: -0.1572,                 loss: 0.3130
Episode: 2561/10000 (25.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6350s / 140.6504 s
agent0:                 episode reward: -0.3047,                 loss: nan
agent1:                 episode reward: 0.3047,                 loss: 0.3112
Episode: 2571/10000 (25.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6980s / 141.3484 s
agent0:                 episode reward: 1.0169,                 loss: nan
agent1:                 episode reward: -1.0169,                 loss: 0.3135
Episode: 2581/10000 (25.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6553s / 142.0037 s
agent0:                 episode reward: -0.5045,                 loss: nan
agent1:                 episode reward: 0.5045,                 loss: 0.3071
Episode: 2591/10000 (25.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6366s / 142.6402 s
agent0:                 episode reward: 0.3885,                 loss: nan
agent1:                 episode reward: -0.3885,                 loss: 0.3067
Episode: 2601/10000 (26.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6283s / 143.2685 s
agent0:                 episode reward: -0.7326,                 loss: nan
agent1:                 episode reward: 0.7326,                 loss: 0.3027
Episode: 2611/10000 (26.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6403s / 143.9089 s
agent0:                 episode reward: -1.0530,                 loss: nan
agent1:                 episode reward: 1.0530,                 loss: 0.3048
Episode: 2621/10000 (26.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6452s / 144.5541 s
agent0:                 episode reward: 0.2742,                 loss: nan
agent1:                 episode reward: -0.2742,                 loss: 0.3065
Episode: 2631/10000 (26.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6394s / 145.1935 s
agent0:                 episode reward: -1.0415,                 loss: nan
agent1:                 episode reward: 1.0415,                 loss: 0.3010
Episode: 2641/10000 (26.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6399s / 145.8334 s
agent0:                 episode reward: -1.4191,                 loss: nan
agent1:                 episode reward: 1.4191,                 loss: 0.3033
Episode: 2651/10000 (26.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6434s / 146.4768 s
agent0:                 episode reward: -1.0986,                 loss: nan
agent1:                 episode reward: 1.0986,                 loss: 0.3022
Episode: 2661/10000 (26.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6379s / 147.1147 s
agent0:                 episode reward: -0.0795,                 loss: nan
agent1:                 episode reward: 0.0795,                 loss: 0.3002
Episode: 2671/10000 (26.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6325s / 147.7472 s
agent0:                 episode reward: -0.0649,                 loss: nan
agent1:                 episode reward: 0.0649,                 loss: 0.3199
Episode: 2681/10000 (26.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6318s / 148.3790 s
agent0:                 episode reward: -0.3157,                 loss: nan
agent1:                 episode reward: 0.3157,                 loss: 0.3201
Episode: 2691/10000 (26.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6373s / 149.0163 s
agent0:                 episode reward: -0.2755,                 loss: nan
agent1:                 episode reward: 0.2755,                 loss: 0.3200
Episode: 2701/10000 (27.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6666s / 149.6829 s
agent0:                 episode reward: -0.1112,                 loss: nan
agent1:                 episode reward: 0.1112,                 loss: 0.3169
Episode: 2711/10000 (27.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6769s / 150.3598 s
agent0:                 episode reward: -0.6792,                 loss: nan
agent1:                 episode reward: 0.6792,                 loss: 0.3139
Episode: 2721/10000 (27.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6291s / 150.9890 s
agent0:                 episode reward: -0.6109,                 loss: nan
agent1:                 episode reward: 0.6109,                 loss: 0.3168
Episode: 2731/10000 (27.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6820s / 151.6709 s
agent0:                 episode reward: 0.3570,                 loss: nan
agent1:                 episode reward: -0.3570,                 loss: 0.3161
Episode: 2741/10000 (27.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6427s / 152.3136 s
agent0:                 episode reward: -0.2228,                 loss: nan
agent1:                 episode reward: 0.2228,                 loss: 0.3127
Episode: 2751/10000 (27.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6496s / 152.9632 s
agent0:                 episode reward: -1.2243,                 loss: nan
agent1:                 episode reward: 1.2243,                 loss: 0.3149
Episode: 2761/10000 (27.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6527s / 153.6159 s
agent0:                 episode reward: 0.2963,                 loss: nan
agent1:                 episode reward: -0.2963,                 loss: 0.3132
Episode: 2771/10000 (27.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6400s / 154.2559 s
agent0:                 episode reward: 0.3153,                 loss: nan
agent1:                 episode reward: -0.3153,                 loss: 0.3259
Episode: 2781/10000 (27.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6342s / 154.8901 s
agent0:                 episode reward: 0.0572,                 loss: nan
agent1:                 episode reward: -0.0572,                 loss: 0.3210
Episode: 2791/10000 (27.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6403s / 155.5304 s
agent0:                 episode reward: 0.5312,                 loss: nan
agent1:                 episode reward: -0.5312,                 loss: 0.3195
Episode: 2801/10000 (28.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6593s / 156.1897 s
agent0:                 episode reward: -0.0731,                 loss: nan
agent1:                 episode reward: 0.0731,                 loss: 0.3192
Episode: 2811/10000 (28.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6393s / 156.8290 s
agent0:                 episode reward: -0.7285,                 loss: nan
agent1:                 episode reward: 0.7285,                 loss: 0.3160
Episode: 2821/10000 (28.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6406s / 157.4696 s
agent0:                 episode reward: -1.2478,                 loss: nan
agent1:                 episode reward: 1.2478,                 loss: 0.3167
Episode: 2831/10000 (28.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6593s / 158.1289 s
agent0:                 episode reward: 0.4778,                 loss: nan
agent1:                 episode reward: -0.4778,                 loss: 0.3156
Episode: 2841/10000 (28.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6368s / 158.7657 s
agent0:                 episode reward: -0.8831,                 loss: nan
agent1:                 episode reward: 0.8831,                 loss: 0.3136
Episode: 2851/10000 (28.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6385s / 159.4042 s
agent0:                 episode reward: -0.5702,                 loss: nan
agent1:                 episode reward: 0.5702,                 loss: 0.3140
Episode: 2861/10000 (28.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6415s / 160.0457 s
agent0:                 episode reward: -0.1806,                 loss: nan
agent1:                 episode reward: 0.1806,                 loss: 0.3159
Episode: 2871/10000 (28.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6524s / 160.6981 s
agent0:                 episode reward: 0.0932,                 loss: nan
agent1:                 episode reward: -0.0932,                 loss: 0.3149
Episode: 2881/10000 (28.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6840s / 161.3822 s
agent0:                 episode reward: 0.5859,                 loss: nan
agent1:                 episode reward: -0.5859,                 loss: 0.3059
Episode: 2891/10000 (28.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7074s / 162.0896 s
agent0:                 episode reward: 0.7322,                 loss: nan
agent1:                 episode reward: -0.7322,                 loss: 0.3064
Episode: 2901/10000 (29.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6566s / 162.7462 s
agent0:                 episode reward: 0.4912,                 loss: nan
agent1:                 episode reward: -0.4912,                 loss: 0.3040
Episode: 2911/10000 (29.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6885s / 163.4347 s
agent0:                 episode reward: 0.3440,                 loss: nan
agent1:                 episode reward: -0.3440,                 loss: 0.3035
Episode: 2921/10000 (29.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6534s / 164.0882 s
agent0:                 episode reward: -1.0699,                 loss: nan
agent1:                 episode reward: 1.0699,                 loss: 0.3024
Episode: 2931/10000 (29.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6704s / 164.7586 s
agent0:                 episode reward: 0.6084,                 loss: nan
agent1:                 episode reward: -0.6084,                 loss: 0.3039
Episode: 2941/10000 (29.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6552s / 165.4138 s
agent0:                 episode reward: -0.4772,                 loss: nan
agent1:                 episode reward: 0.4772,                 loss: 0.3017
Episode: 2951/10000 (29.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6520s / 166.0658 s
agent0:                 episode reward: -0.6386,                 loss: nan
agent1:                 episode reward: 0.6386,                 loss: 0.3015
Episode: 2961/10000 (29.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6724s / 166.7382 s
agent0:                 episode reward: 0.1749,                 loss: nan
agent1:                 episode reward: -0.1749,                 loss: 0.3025
Episode: 2971/10000 (29.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6825s / 167.4207 s
agent0:                 episode reward: -0.2657,                 loss: nan
agent1:                 episode reward: 0.2657,                 loss: 0.3129
Episode: 2981/10000 (29.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6704s / 168.0911 s
agent0:                 episode reward: -0.7574,                 loss: nan
agent1:                 episode reward: 0.7574,                 loss: 0.3134
Episode: 2991/10000 (29.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6577s / 168.7488 s
agent0:                 episode reward: 0.1999,                 loss: nan
agent1:                 episode reward: -0.1999,                 loss: 0.3096
Episode: 3001/10000 (30.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6530s / 169.4017 s
agent0:                 episode reward: -0.4860,                 loss: nan
agent1:                 episode reward: 0.4860,                 loss: 0.3098
Episode: 3011/10000 (30.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6603s / 170.0620 s
agent0:                 episode reward: -0.9159,                 loss: nan
agent1:                 episode reward: 0.9159,                 loss: 0.3113
Episode: 3021/10000 (30.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6669s / 170.7289 s
agent0:                 episode reward: 0.1929,                 loss: nan
agent1:                 episode reward: -0.1929,                 loss: 0.3097
Episode: 3031/10000 (30.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6783s / 171.4072 s
agent0:                 episode reward: 0.3037,                 loss: nan
agent1:                 episode reward: -0.3037,                 loss: 0.3118
Episode: 3041/10000 (30.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7096s / 172.1168 s
agent0:                 episode reward: 0.8398,                 loss: nan
agent1:                 episode reward: -0.8398,                 loss: 0.3061
Episode: 3051/10000 (30.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6600s / 172.7768 s
agent0:                 episode reward: -0.7074,                 loss: nan
agent1:                 episode reward: 0.7074,                 loss: 0.3110
Episode: 3061/10000 (30.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6949s / 173.4717 s
agent0:                 episode reward: 0.7616,                 loss: nan
agent1:                 episode reward: -0.7616,                 loss: 0.3093
Episode: 3071/10000 (30.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6752s / 174.1469 s
agent0:                 episode reward: -0.6703,                 loss: nan
agent1:                 episode reward: 0.6703,                 loss: 0.3294
Episode: 3081/10000 (30.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6940s / 174.8409 s
agent0:                 episode reward: -0.6154,                 loss: nan
agent1:                 episode reward: 0.6154,                 loss: 0.3285
Episode: 3091/10000 (30.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6591s / 175.5000 s
agent0:                 episode reward: -0.3002,                 loss: nan
agent1:                 episode reward: 0.3002,                 loss: 0.3304
Episode: 3101/10000 (31.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6632s / 176.1632 s
agent0:                 episode reward: 0.1797,                 loss: nan
agent1:                 episode reward: -0.1797,                 loss: 0.3306
Episode: 3111/10000 (31.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6636s / 176.8268 s
agent0:                 episode reward: 0.0904,                 loss: nan
agent1:                 episode reward: -0.0904,                 loss: 0.3292
Episode: 3121/10000 (31.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6761s / 177.5029 s
agent0:                 episode reward: -0.1760,                 loss: nan
agent1:                 episode reward: 0.1760,                 loss: 0.3280
Episode: 3131/10000 (31.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6602s / 178.1630 s
agent0:                 episode reward: -0.8042,                 loss: nan
agent1:                 episode reward: 0.8042,                 loss: 0.3277
Episode: 3141/10000 (31.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6642s / 178.8272 s
agent0:                 episode reward: -0.9249,                 loss: nan
agent1:                 episode reward: 0.9249,                 loss: 0.3280
Episode: 3151/10000 (31.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6574s / 179.4846 s
agent0:                 episode reward: -0.8810,                 loss: nan
agent1:                 episode reward: 0.8810,                 loss: 0.3272
Episode: 3161/10000 (31.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6615s / 180.1461 s
agent0:                 episode reward: 0.5782,                 loss: nan
agent1:                 episode reward: -0.5782,                 loss: 0.3264
Episode: 3171/10000 (31.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6660s / 180.8121 s
agent0:                 episode reward: -0.0334,                 loss: nan
agent1:                 episode reward: 0.0334,                 loss: 0.3387
Episode: 3181/10000 (31.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6563s / 181.4684 s
agent0:                 episode reward: -0.7998,                 loss: nan
agent1:                 episode reward: 0.7998,                 loss: 0.3353
Episode: 3191/10000 (31.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7066s / 182.1750 s
agent0:                 episode reward: -0.2175,                 loss: nan
agent1:                 episode reward: 0.2175,                 loss: 0.3359
Episode: 3201/10000 (32.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6730s / 182.8479 s
agent0:                 episode reward: -0.9313,                 loss: nan
agent1:                 episode reward: 0.9313,                 loss: 0.3337
Episode: 3211/10000 (32.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6767s / 183.5246 s
agent0:                 episode reward: -1.0919,                 loss: nan
agent1:                 episode reward: 1.0919,                 loss: 0.3292
Episode: 3221/10000 (32.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6638s / 184.1884 s
agent0:                 episode reward: -0.1979,                 loss: nan
agent1:                 episode reward: 0.1979,                 loss: 0.3309
Episode: 3231/10000 (32.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6664s / 184.8548 s
agent0:                 episode reward: -0.5298,                 loss: nan
agent1:                 episode reward: 0.5298,                 loss: 0.3308
Episode: 3241/10000 (32.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6636s / 185.5184 s
agent0:                 episode reward: -1.1308,                 loss: nan
agent1:                 episode reward: 1.1308,                 loss: 0.3315
Episode: 3251/10000 (32.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6741s / 186.1925 s
agent0:                 episode reward: 0.7928,                 loss: nan
agent1:                 episode reward: -0.7928,                 loss: 0.3300
Episode: 3261/10000 (32.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6618s / 186.8543 s
agent0:                 episode reward: -0.9951,                 loss: nan
agent1:                 episode reward: 0.9951,                 loss: 0.3284
Episode: 3271/10000 (32.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6630s / 187.5173 s
agent0:                 episode reward: 0.5278,                 loss: nan
agent1:                 episode reward: -0.5278,                 loss: 0.3131
Episode: 3281/10000 (32.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6618s / 188.1791 s
agent0:                 episode reward: -0.4515,                 loss: nan
agent1:                 episode reward: 0.4515,                 loss: 0.2915
Episode: 3291/10000 (32.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6696s / 188.8487 s
agent0:                 episode reward: -0.3220,                 loss: nan
agent1:                 episode reward: 0.3220,                 loss: 0.2854
Episode: 3301/10000 (33.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6756s / 189.5244 s
agent0:                 episode reward: -0.2603,                 loss: nan
agent1:                 episode reward: 0.2603,                 loss: 0.2843
Episode: 3311/10000 (33.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6624s / 190.1868 s
agent0:                 episode reward: -0.9803,                 loss: nan
agent1:                 episode reward: 0.9803,                 loss: 0.2850
Episode: 3321/10000 (33.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6706s / 190.8574 s
agent0:                 episode reward: -0.5466,                 loss: nan
agent1:                 episode reward: 0.5466,                 loss: 0.2818
Episode: 3331/10000 (33.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6893s / 191.5468 s
agent0:                 episode reward: -0.6071,                 loss: nan
agent1:                 episode reward: 0.6071,                 loss: 0.2796
Episode: 3341/10000 (33.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7339s / 192.2806 s
agent0:                 episode reward: -0.0591,                 loss: nan
agent1:                 episode reward: 0.0591,                 loss: 0.2833
Episode: 3351/10000 (33.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6668s / 192.9474 s
agent0:                 episode reward: 0.3490,                 loss: nan
agent1:                 episode reward: -0.3490,                 loss: 0.2805
Episode: 3361/10000 (33.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6787s / 193.6261 s
agent0:                 episode reward: -0.2492,                 loss: nan
agent1:                 episode reward: 0.2492,                 loss: 0.2785
Episode: 3371/10000 (33.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6890s / 194.3152 s
agent0:                 episode reward: 0.4725,                 loss: nan
agent1:                 episode reward: -0.4725,                 loss: 0.2523
Episode: 3381/10000 (33.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6767s / 194.9919 s
agent0:                 episode reward: -0.0594,                 loss: nan
agent1:                 episode reward: 0.0594,                 loss: 0.2296
Episode: 3391/10000 (33.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6926s / 195.6845 s
agent0:                 episode reward: -0.4938,                 loss: nan
agent1:                 episode reward: 0.4938,                 loss: 0.2238
Episode: 3401/10000 (34.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6674s / 196.3518 s
agent0:                 episode reward: -1.1438,                 loss: nan
agent1:                 episode reward: 1.1438,                 loss: 0.2240
Episode: 3411/10000 (34.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6738s / 197.0256 s
agent0:                 episode reward: 0.4285,                 loss: nan
agent1:                 episode reward: -0.4285,                 loss: 0.2223
Episode: 3421/10000 (34.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6858s / 197.7114 s
agent0:                 episode reward: 0.4917,                 loss: nan
agent1:                 episode reward: -0.4917,                 loss: 0.2219
Episode: 3431/10000 (34.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6844s / 198.3958 s
agent0:                 episode reward: -0.2699,                 loss: nan
agent1:                 episode reward: 0.2699,                 loss: 0.2211
Episode: 3441/10000 (34.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6740s / 199.0698 s
agent0:                 episode reward: 0.3355,                 loss: nan
agent1:                 episode reward: -0.3355,                 loss: 0.2196
Episode: 3451/10000 (34.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7055s / 199.7753 s
agent0:                 episode reward: -0.4401,                 loss: nan
agent1:                 episode reward: 0.4401,                 loss: 0.2210
Episode: 3461/10000 (34.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6826s / 200.4579 s
agent0:                 episode reward: -1.2049,                 loss: nan
agent1:                 episode reward: 1.2049,                 loss: 0.2188
Episode: 3471/10000 (34.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6928s / 201.1506 s
agent0:                 episode reward: -0.5689,                 loss: nan
agent1:                 episode reward: 0.5689,                 loss: 0.2149
Episode: 3481/10000 (34.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6805s / 201.8311 s
agent0:                 episode reward: 0.2045,                 loss: nan
agent1:                 episode reward: -0.2045,                 loss: 0.2083
Episode: 3491/10000 (34.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7188s / 202.5499 s
agent0:                 episode reward: -0.4972,                 loss: nan
agent1:                 episode reward: 0.4972,                 loss: 0.2051
Episode: 3501/10000 (35.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6817s / 203.2316 s
agent0:                 episode reward: -1.0308,                 loss: nan
agent1:                 episode reward: 1.0308,                 loss: 0.2064
Episode: 3511/10000 (35.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6806s / 203.9123 s
agent0:                 episode reward: -0.9344,                 loss: nan
agent1:                 episode reward: 0.9344,                 loss: 0.2044
Episode: 3521/10000 (35.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6880s / 204.6002 s
agent0:                 episode reward: -0.3441,                 loss: nan
agent1:                 episode reward: 0.3441,                 loss: 0.2040
Episode: 3531/10000 (35.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6776s / 205.2779 s
agent0:                 episode reward: -0.4003,                 loss: nan
agent1:                 episode reward: 0.4003,                 loss: 0.2021
Episode: 3541/10000 (35.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6979s / 205.9757 s
agent0:                 episode reward: -1.3992,                 loss: nan
agent1:                 episode reward: 1.3992,                 loss: 0.2042
Episode: 3551/10000 (35.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6712s / 206.6470 s
agent0:                 episode reward: -0.0809,                 loss: nan
agent1:                 episode reward: 0.0809,                 loss: 0.2017
Episode: 3561/10000 (35.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6858s / 207.3327 s
agent0:                 episode reward: 0.2332,                 loss: nan
agent1:                 episode reward: -0.2332,                 loss: 0.2039
Episode: 3571/10000 (35.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7127s / 208.0455 s
agent0:                 episode reward: -0.0159,                 loss: nan
agent1:                 episode reward: 0.0159,                 loss: 0.2260
Episode: 3581/10000 (35.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6804s / 208.7259 s
agent0:                 episode reward: -0.4062,                 loss: nan
agent1:                 episode reward: 0.4062,                 loss: 0.2320
Episode: 3591/10000 (35.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6795s / 209.4054 s
agent0:                 episode reward: -0.0196,                 loss: nan
agent1:                 episode reward: 0.0196,                 loss: 0.2283
Episode: 3601/10000 (36.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6793s / 210.0847 s
agent0:                 episode reward: 0.1765,                 loss: nan
agent1:                 episode reward: -0.1765,                 loss: 0.2294
Episode: 3611/10000 (36.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7141s / 210.7988 s
agent0:                 episode reward: -0.9266,                 loss: nan
agent1:                 episode reward: 0.9266,                 loss: 0.2284
Episode: 3621/10000 (36.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6810s / 211.4798 s
agent0:                 episode reward: 0.1503,                 loss: nan
agent1:                 episode reward: -0.1503,                 loss: 0.2295
Episode: 3631/10000 (36.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6909s / 212.1708 s
agent0:                 episode reward: -1.0437,                 loss: nan
agent1:                 episode reward: 1.0437,                 loss: 0.2277
Episode: 3641/10000 (36.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7493s / 212.9201 s
agent0:                 episode reward: -1.4522,                 loss: nan
agent1:                 episode reward: 1.4522,                 loss: 0.2291
Episode: 3651/10000 (36.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7141s / 213.6341 s
agent0:                 episode reward: -0.8059,                 loss: nan
agent1:                 episode reward: 0.8059,                 loss: 0.2268
Episode: 3661/10000 (36.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6979s / 214.3320 s
agent0:                 episode reward: -0.2090,                 loss: nan
agent1:                 episode reward: 0.2090,                 loss: 0.2273
Episode: 3671/10000 (36.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6868s / 215.0188 s
agent0:                 episode reward: -0.4987,                 loss: nan
agent1:                 episode reward: 0.4987,                 loss: 0.2555
Episode: 3681/10000 (36.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6903s / 215.7091 s
agent0:                 episode reward: -0.4125,                 loss: nan
agent1:                 episode reward: 0.4125,                 loss: 0.2649
Episode: 3691/10000 (36.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7178s / 216.4269 s
agent0:                 episode reward: 0.0705,                 loss: nan
agent1:                 episode reward: -0.0705,                 loss: 0.2631
Episode: 3701/10000 (37.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7026s / 217.1295 s
agent0:                 episode reward: 0.4321,                 loss: nan
agent1:                 episode reward: -0.4321,                 loss: 0.2607
Episode: 3711/10000 (37.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7073s / 217.8368 s
agent0:                 episode reward: -0.4779,                 loss: nan
agent1:                 episode reward: 0.4779,                 loss: 0.2630
Episode: 3721/10000 (37.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6929s / 218.5297 s
agent0:                 episode reward: -0.8008,                 loss: nan
agent1:                 episode reward: 0.8008,                 loss: 0.2613
Episode: 3731/10000 (37.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6926s / 219.2223 s
agent0:                 episode reward: 0.3719,                 loss: nan
agent1:                 episode reward: -0.3719,                 loss: 0.2609
Episode: 3741/10000 (37.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6953s / 219.9176 s
agent0:                 episode reward: -0.4859,                 loss: nan
agent1:                 episode reward: 0.4859,                 loss: 0.2600
Episode: 3751/10000 (37.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6870s / 220.6047 s
agent0:                 episode reward: -0.7140,                 loss: nan
agent1:                 episode reward: 0.7140,                 loss: 0.2620
Episode: 3761/10000 (37.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6956s / 221.3002 s
agent0:                 episode reward: -0.3915,                 loss: nan
agent1:                 episode reward: 0.3915,                 loss: 0.2581
Episode: 3771/10000 (37.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7027s / 222.0029 s
agent0:                 episode reward: 0.3693,                 loss: nan
agent1:                 episode reward: -0.3693,                 loss: 0.2884
Episode: 3781/10000 (37.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7116s / 222.7145 s
agent0:                 episode reward: -0.3040,                 loss: nan
agent1:                 episode reward: 0.3040,                 loss: 0.2970
Episode: 3791/10000 (37.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7427s / 223.4573 s
agent0:                 episode reward: 0.9380,                 loss: nan
agent1:                 episode reward: -0.9380,                 loss: 0.2947
Episode: 3801/10000 (38.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7127s / 224.1700 s
agent0:                 episode reward: -0.1929,                 loss: nan
agent1:                 episode reward: 0.1929,                 loss: 0.2974
Episode: 3811/10000 (38.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6849s / 224.8549 s
agent0:                 episode reward: -0.2355,                 loss: nan
agent1:                 episode reward: 0.2355,                 loss: 0.2910
Episode: 3821/10000 (38.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6970s / 225.5519 s
agent0:                 episode reward: 0.9725,                 loss: nan
agent1:                 episode reward: -0.9725,                 loss: 0.2951
Episode: 3831/10000 (38.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7019s / 226.2538 s
agent0:                 episode reward: -0.9466,                 loss: nan
agent1:                 episode reward: 0.9466,                 loss: 0.2931
Episode: 3841/10000 (38.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6984s / 226.9521 s
agent0:                 episode reward: -0.9077,                 loss: nan
agent1:                 episode reward: 0.9077,                 loss: 0.2914
Episode: 3851/10000 (38.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6927s / 227.6449 s
agent0:                 episode reward: 0.2776,                 loss: nan
agent1:                 episode reward: -0.2776,                 loss: 0.2901
Episode: 3861/10000 (38.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7272s / 228.3721 s
agent0:                 episode reward: -0.4239,                 loss: nan
agent1:                 episode reward: 0.4239,                 loss: 0.2930
Episode: 3871/10000 (38.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6996s / 229.0716 s
agent0:                 episode reward: -0.5504,                 loss: nan
agent1:                 episode reward: 0.5504,                 loss: 0.3080
Episode: 3881/10000 (38.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6953s / 229.7669 s
agent0:                 episode reward: -0.3584,                 loss: nan
agent1:                 episode reward: 0.3584,                 loss: 0.3048
Episode: 3891/10000 (38.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7021s / 230.4690 s
agent0:                 episode reward: -0.3382,                 loss: nan
agent1:                 episode reward: 0.3382,                 loss: 0.3035
Episode: 3901/10000 (39.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7019s / 231.1709 s
agent0:                 episode reward: -1.1656,                 loss: nan
agent1:                 episode reward: 1.1656,                 loss: 0.3053
Episode: 3911/10000 (39.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7228s / 231.8937 s
agent0:                 episode reward: 0.0145,                 loss: nan
agent1:                 episode reward: -0.0145,                 loss: 0.3024
Episode: 3921/10000 (39.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7157s / 232.6094 s
agent0:                 episode reward: 0.2506,                 loss: nan
agent1:                 episode reward: -0.2506,                 loss: 0.3049
Episode: 3931/10000 (39.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7488s / 233.3581 s
agent0:                 episode reward: -0.5598,                 loss: nan
agent1:                 episode reward: 0.5598,                 loss: 0.3018
Episode: 3941/10000 (39.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7069s / 234.0650 s
agent0:                 episode reward: -1.3461,                 loss: nan
agent1:                 episode reward: 1.3461,                 loss: 0.3038
Episode: 3951/10000 (39.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7350s / 234.8000 s
agent0:                 episode reward: -0.2467,                 loss: nan
agent1:                 episode reward: 0.2467,                 loss: 0.3033
Episode: 3961/10000 (39.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7099s / 235.5099 s
agent0:                 episode reward: 0.1539,                 loss: nan
agent1:                 episode reward: -0.1539,                 loss: 0.3038
Episode: 3971/10000 (39.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7093s / 236.2192 s
agent0:                 episode reward: -0.0032,                 loss: nan
agent1:                 episode reward: 0.0032,                 loss: 0.3023
Episode: 3981/10000 (39.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7044s / 236.9236 s
agent0:                 episode reward: -0.8515,                 loss: nan
agent1:                 episode reward: 0.8515,                 loss: 0.2939
Episode: 3991/10000 (39.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7195s / 237.6431 s
agent0:                 episode reward: -1.0977,                 loss: nan
agent1:                 episode reward: 1.0977,                 loss: 0.2932
Episode: 4001/10000 (40.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7091s / 238.3522 s
agent0:                 episode reward: 0.0140,                 loss: nan
agent1:                 episode reward: -0.0140,                 loss: 0.2925
Episode: 4011/10000 (40.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7130s / 239.0652 s
agent0:                 episode reward: -0.5945,                 loss: nan
agent1:                 episode reward: 0.5945,                 loss: 0.2938
Episode: 4021/10000 (40.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7138s / 239.7790 s
agent0:                 episode reward: 0.3726,                 loss: nan
agent1:                 episode reward: -0.3726,                 loss: 0.2935
Episode: 4031/10000 (40.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7078s / 240.4868 s
agent0:                 episode reward: -1.3389,                 loss: nan
agent1:                 episode reward: 1.3389,                 loss: 0.2908
Episode: 4041/10000 (40.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7323s / 241.2190 s
agent0:                 episode reward: -0.7199,                 loss: nan
agent1:                 episode reward: 0.7199,                 loss: 0.2929
Episode: 4051/10000 (40.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7090s / 241.9280 s
agent0:                 episode reward: -1.0830,                 loss: nan
agent1:                 episode reward: 1.0830,                 loss: 0.2935
Episode: 4061/10000 (40.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6977s / 242.6258 s
agent0:                 episode reward: -1.1500,                 loss: nan
agent1:                 episode reward: 1.1500,                 loss: 0.2911
Episode: 4071/10000 (40.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7437s / 243.3694 s
agent0:                 episode reward: 0.4950,                 loss: nan
agent1:                 episode reward: -0.4950,                 loss: 0.2989
Episode: 4081/10000 (40.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7430s / 244.1124 s
agent0:                 episode reward: -1.4899,                 loss: nan
agent1:                 episode reward: 1.4899,                 loss: 0.2929
Episode: 4091/10000 (40.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7073s / 244.8197 s
agent0:                 episode reward: -0.9244,                 loss: nan
agent1:                 episode reward: 0.9244,                 loss: 0.2928
Episode: 4101/10000 (41.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7043s / 245.5240 s
agent0:                 episode reward: -1.4476,                 loss: nan
agent1:                 episode reward: 1.4476,                 loss: 0.2925
Episode: 4111/10000 (41.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7107s / 246.2347 s
agent0:                 episode reward: -0.6530,                 loss: nan
agent1:                 episode reward: 0.6530,                 loss: 0.2935
Episode: 4121/10000 (41.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7162s / 246.9509 s
agent0:                 episode reward: -0.7712,                 loss: nan
agent1:                 episode reward: 0.7712,                 loss: 0.2907
Episode: 4131/10000 (41.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7231s / 247.6740 s
agent0:                 episode reward: -1.3963,                 loss: nan
agent1:                 episode reward: 1.3963,                 loss: 0.2913
Episode: 4141/10000 (41.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7129s / 248.3869 s
agent0:                 episode reward: 0.2756,                 loss: nan
agent1:                 episode reward: -0.2756,                 loss: 0.2889
Episode: 4151/10000 (41.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7245s / 249.1115 s
agent0:                 episode reward: -0.5373,                 loss: nan
agent1:                 episode reward: 0.5373,                 loss: 0.2923
Episode: 4161/10000 (41.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7324s / 249.8439 s
agent0:                 episode reward: 0.2034,                 loss: nan
agent1:                 episode reward: -0.2034,                 loss: 0.2894
Episode: 4171/10000 (41.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7227s / 250.5666 s
agent0:                 episode reward: -0.5470,                 loss: nan
agent1:                 episode reward: 0.5470,                 loss: 0.3084
Episode: 4181/10000 (41.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7195s / 251.2861 s
agent0:                 episode reward: -1.1680,                 loss: nan
agent1:                 episode reward: 1.1680,                 loss: 0.3071
Episode: 4191/10000 (41.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7280s / 252.0141 s
agent0:                 episode reward: -0.5829,                 loss: nan
agent1:                 episode reward: 0.5829,                 loss: 0.3054
Episode: 4201/10000 (42.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7345s / 252.7485 s
agent0:                 episode reward: -1.1610,                 loss: nan
agent1:                 episode reward: 1.1610,                 loss: 0.3061
Episode: 4211/10000 (42.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7186s / 253.4671 s
agent0:                 episode reward: 0.1248,                 loss: nan
agent1:                 episode reward: -0.1248,                 loss: 0.3046
Episode: 4221/10000 (42.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7783s / 254.2455 s
agent0:                 episode reward: -0.9340,                 loss: nan
agent1:                 episode reward: 0.9340,                 loss: 0.3059
Episode: 4231/10000 (42.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7198s / 254.9652 s
agent0:                 episode reward: -1.1942,                 loss: nan
agent1:                 episode reward: 1.1942,                 loss: 0.3049
Episode: 4241/10000 (42.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7513s / 255.7166 s
agent0:                 episode reward: 0.0136,                 loss: nan
agent1:                 episode reward: -0.0136,                 loss: 0.3035
Episode: 4251/10000 (42.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7170s / 256.4336 s
agent0:                 episode reward: -1.3834,                 loss: nan
agent1:                 episode reward: 1.3834,                 loss: 0.3019
Episode: 4261/10000 (42.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7117s / 257.1453 s
agent0:                 episode reward: -0.9587,                 loss: nan
agent1:                 episode reward: 0.9587,                 loss: 0.3027
Episode: 4271/10000 (42.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7322s / 257.8775 s
agent0:                 episode reward: 0.2876,                 loss: nan
agent1:                 episode reward: -0.2876,                 loss: 0.3056
Episode: 4281/10000 (42.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7270s / 258.6045 s
agent0:                 episode reward: -0.2464,                 loss: nan
agent1:                 episode reward: 0.2464,                 loss: 0.2920
Episode: 4291/10000 (42.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7688s / 259.3733 s
agent0:                 episode reward: -0.2395,                 loss: nan
agent1:                 episode reward: 0.2395,                 loss: 0.2903
Episode: 4301/10000 (43.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7244s / 260.0977 s
agent0:                 episode reward: -0.1916,                 loss: nan
agent1:                 episode reward: 0.1916,                 loss: 0.2903
Episode: 4311/10000 (43.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7241s / 260.8218 s
agent0:                 episode reward: -0.4945,                 loss: nan
agent1:                 episode reward: 0.4945,                 loss: 0.2891
Episode: 4321/10000 (43.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7370s / 261.5588 s
agent0:                 episode reward: -0.7555,                 loss: nan
agent1:                 episode reward: 0.7555,                 loss: 0.2898
Episode: 4331/10000 (43.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7390s / 262.2978 s
agent0:                 episode reward: -1.4190,                 loss: nan
agent1:                 episode reward: 1.4190,                 loss: 0.2897
Episode: 4341/10000 (43.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7191s / 263.0169 s
agent0:                 episode reward: -0.7461,                 loss: nan
agent1:                 episode reward: 0.7461,                 loss: 0.2877
Episode: 4351/10000 (43.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7226s / 263.7395 s
agent0:                 episode reward: -0.9377,                 loss: nan
agent1:                 episode reward: 0.9377,                 loss: 0.2902
Episode: 4361/10000 (43.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7981s / 264.5376 s
agent0:                 episode reward: -0.2728,                 loss: nan
agent1:                 episode reward: 0.2728,                 loss: 0.2877
Episode: 4371/10000 (43.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7347s / 265.2723 s
agent0:                 episode reward: -1.1213,                 loss: nan
agent1:                 episode reward: 1.1213,                 loss: 0.2617
Episode: 4381/10000 (43.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7440s / 266.0163 s
agent0:                 episode reward: 0.1182,                 loss: nan
agent1:                 episode reward: -0.1182,                 loss: 0.2338
Episode: 4391/10000 (43.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7355s / 266.7518 s
agent0:                 episode reward: -0.0169,                 loss: nan
agent1:                 episode reward: 0.0169,                 loss: 0.2313
Episode: 4401/10000 (44.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7460s / 267.4979 s
agent0:                 episode reward: -0.7880,                 loss: nan
agent1:                 episode reward: 0.7880,                 loss: 0.2302
Episode: 4411/10000 (44.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7681s / 268.2660 s
agent0:                 episode reward: 0.2243,                 loss: nan
agent1:                 episode reward: -0.2243,                 loss: 0.2264
Episode: 4421/10000 (44.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7632s / 269.0292 s
agent0:                 episode reward: -0.0278,                 loss: nan
agent1:                 episode reward: 0.0278,                 loss: 0.2250
Episode: 4431/10000 (44.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7223s / 269.7516 s
agent0:                 episode reward: -0.0385,                 loss: nan
agent1:                 episode reward: 0.0385,                 loss: 0.2270
Episode: 4441/10000 (44.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7282s / 270.4797 s
agent0:                 episode reward: -0.9255,                 loss: nan
agent1:                 episode reward: 0.9255,                 loss: 0.2242
Episode: 4451/10000 (44.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7364s / 271.2161 s
agent0:                 episode reward: -0.9474,                 loss: nan
agent1:                 episode reward: 0.9474,                 loss: 0.2254
Episode: 4461/10000 (44.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7501s / 271.9662 s
agent0:                 episode reward: -0.3766,                 loss: nan
agent1:                 episode reward: 0.3766,                 loss: 0.2243
Episode: 4471/10000 (44.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7445s / 272.7108 s
agent0:                 episode reward: -0.8372,                 loss: nan
agent1:                 episode reward: 0.8372,                 loss: 0.2022
Episode: 4481/10000 (44.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7369s / 273.4477 s
agent0:                 episode reward: -0.5947,                 loss: nan
agent1:                 episode reward: 0.5947,                 loss: 0.1810
Episode: 4491/10000 (44.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8032s / 274.2508 s
agent0:                 episode reward: 0.1862,                 loss: nan
agent1:                 episode reward: -0.1862,                 loss: 0.1773
Episode: 4501/10000 (45.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7426s / 274.9935 s
agent0:                 episode reward: -0.4594,                 loss: nan
agent1:                 episode reward: 0.4594,                 loss: 0.1769
Episode: 4511/10000 (45.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7383s / 275.7318 s
agent0:                 episode reward: 0.3549,                 loss: nan
agent1:                 episode reward: -0.3549,                 loss: 0.1792
Episode: 4521/10000 (45.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7295s / 276.4612 s
agent0:                 episode reward: 0.2822,                 loss: nan
agent1:                 episode reward: -0.2822,                 loss: 0.1788
Episode: 4531/10000 (45.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7507s / 277.2119 s
agent0:                 episode reward: -0.3846,                 loss: nan
agent1:                 episode reward: 0.3846,                 loss: 0.1769
Episode: 4541/10000 (45.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7362s / 277.9481 s
agent0:                 episode reward: -0.2951,                 loss: nan
agent1:                 episode reward: 0.2951,                 loss: 0.1793
Episode: 4551/10000 (45.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7319s / 278.6800 s
agent0:                 episode reward: 0.6485,                 loss: nan
agent1:                 episode reward: -0.6485,                 loss: 0.1761
Episode: 4561/10000 (45.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7422s / 279.4223 s
agent0:                 episode reward: 0.8738,                 loss: nan
agent1:                 episode reward: -0.8738,                 loss: 0.1791
Episode: 4571/10000 (45.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7460s / 280.1683 s
agent0:                 episode reward: -0.4906,                 loss: nan
agent1:                 episode reward: 0.4906,                 loss: 0.1920
Episode: 4581/10000 (45.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7447s / 280.9130 s
agent0:                 episode reward: -1.5304,                 loss: nan
agent1:                 episode reward: 1.5304,                 loss: 0.1974
Episode: 4591/10000 (45.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7328s / 281.6458 s
agent0:                 episode reward: -0.5348,                 loss: nan
agent1:                 episode reward: 0.5348,                 loss: 0.1988
Episode: 4601/10000 (46.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7630s / 282.4088 s
agent0:                 episode reward: 0.8026,                 loss: nan
agent1:                 episode reward: -0.8026,                 loss: 0.1971
Episode: 4611/10000 (46.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7362s / 283.1451 s
agent0:                 episode reward: 0.1083,                 loss: nan
agent1:                 episode reward: -0.1083,                 loss: 0.1973
Episode: 4621/10000 (46.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7419s / 283.8870 s
agent0:                 episode reward: -1.3364,                 loss: nan
agent1:                 episode reward: 1.3364,                 loss: 0.1968
Episode: 4631/10000 (46.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7841s / 284.6711 s
agent0:                 episode reward: 0.6531,                 loss: nan
agent1:                 episode reward: -0.6531,                 loss: 0.1967
Episode: 4641/10000 (46.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7522s / 285.4233 s
agent0:                 episode reward: 0.3004,                 loss: nan
agent1:                 episode reward: -0.3004,                 loss: 0.1938
Episode: 4651/10000 (46.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7475s / 286.1708 s
agent0:                 episode reward: -0.7530,                 loss: nan
agent1:                 episode reward: 0.7530,                 loss: 0.1960
Episode: 4661/10000 (46.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7459s / 286.9167 s
agent0:                 episode reward: -0.9516,                 loss: nan
agent1:                 episode reward: 0.9516,                 loss: 0.1949
Episode: 4671/10000 (46.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7533s / 287.6700 s
agent0:                 episode reward: -1.2368,                 loss: nan
agent1:                 episode reward: 1.2368,                 loss: 0.2260
Episode: 4681/10000 (46.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7461s / 288.4160 s
agent0:                 episode reward: -0.7570,                 loss: nan
agent1:                 episode reward: 0.7570,                 loss: 0.2352
Episode: 4691/10000 (46.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7538s / 289.1699 s
agent0:                 episode reward: -1.5851,                 loss: nan
agent1:                 episode reward: 1.5851,                 loss: 0.2375
Episode: 4701/10000 (47.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7441s / 289.9139 s
agent0:                 episode reward: -0.9695,                 loss: nan
agent1:                 episode reward: 0.9695,                 loss: 0.2373
Episode: 4711/10000 (47.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7589s / 290.6728 s
agent0:                 episode reward: -0.0173,                 loss: nan
agent1:                 episode reward: 0.0173,                 loss: 0.2372
Episode: 4721/10000 (47.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7424s / 291.4152 s
agent0:                 episode reward: 0.0822,                 loss: nan
agent1:                 episode reward: -0.0822,                 loss: 0.2379
Episode: 4731/10000 (47.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7559s / 292.1711 s
agent0:                 episode reward: -0.6939,                 loss: nan
agent1:                 episode reward: 0.6939,                 loss: 0.2354
Episode: 4741/10000 (47.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7461s / 292.9172 s
agent0:                 episode reward: 0.4893,                 loss: nan
agent1:                 episode reward: -0.4893,                 loss: 0.2328
Episode: 4751/10000 (47.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7530s / 293.6701 s
agent0:                 episode reward: -0.4125,                 loss: nan
agent1:                 episode reward: 0.4125,                 loss: 0.2348
Episode: 4761/10000 (47.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7456s / 294.4157 s
agent0:                 episode reward: -0.5598,                 loss: nan
agent1:                 episode reward: 0.5598,                 loss: 0.2366
Episode: 4771/10000 (47.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8093s / 295.2251 s
agent0:                 episode reward: -0.1509,                 loss: nan
agent1:                 episode reward: 0.1509,                 loss: 0.2673
Episode: 4781/10000 (47.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7426s / 295.9677 s
agent0:                 episode reward: -0.2434,                 loss: nan
agent1:                 episode reward: 0.2434,                 loss: 0.2735
Episode: 4791/10000 (47.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7489s / 296.7166 s
agent0:                 episode reward: -0.6462,                 loss: nan
agent1:                 episode reward: 0.6462,                 loss: 0.2725
Episode: 4801/10000 (48.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7533s / 297.4699 s
agent0:                 episode reward: 0.2020,                 loss: nan
agent1:                 episode reward: -0.2020,                 loss: 0.2726
Episode: 4811/10000 (48.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7693s / 298.2392 s
agent0:                 episode reward: -0.4544,                 loss: nan
agent1:                 episode reward: 0.4544,                 loss: 0.2725
Episode: 4821/10000 (48.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7708s / 299.0101 s
agent0:                 episode reward: -0.3648,                 loss: nan
agent1:                 episode reward: 0.3648,                 loss: 0.2718
Episode: 4831/10000 (48.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7612s / 299.7713 s
agent0:                 episode reward: -0.4278,                 loss: nan
agent1:                 episode reward: 0.4278,                 loss: 0.2716
Episode: 4841/10000 (48.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7460s / 300.5172 s
agent0:                 episode reward: 0.3465,                 loss: nan
agent1:                 episode reward: -0.3465,                 loss: 0.2727
Episode: 4851/10000 (48.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7466s / 301.2638 s
agent0:                 episode reward: -0.4541,                 loss: nan
agent1:                 episode reward: 0.4541,                 loss: 0.2713
Episode: 4861/10000 (48.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7555s / 302.0194 s
agent0:                 episode reward: -0.5892,                 loss: nan
agent1:                 episode reward: 0.5892,                 loss: 0.2710
Episode: 4871/10000 (48.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7685s / 302.7879 s
agent0:                 episode reward: -0.0696,                 loss: nan
agent1:                 episode reward: 0.0696,                 loss: 0.3028
Episode: 4881/10000 (48.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7531s / 303.5410 s
agent0:                 episode reward: -1.4452,                 loss: nan
agent1:                 episode reward: 1.4452,                 loss: 0.3083
Episode: 4891/10000 (48.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7623s / 304.3033 s
agent0:                 episode reward: -0.6596,                 loss: nan
agent1:                 episode reward: 0.6596,                 loss: 0.3059
Episode: 4901/10000 (49.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8023s / 305.1056 s
agent0:                 episode reward: -1.1410,                 loss: nan
agent1:                 episode reward: 1.1410,                 loss: 0.3070
Episode: 4911/10000 (49.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7583s / 305.8639 s
agent0:                 episode reward: -0.7392,                 loss: nan
agent1:                 episode reward: 0.7392,                 loss: 0.3055
Episode: 4921/10000 (49.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7605s / 306.6245 s
agent0:                 episode reward: -0.0765,                 loss: nan
agent1:                 episode reward: 0.0765,                 loss: 0.3057
Episode: 4931/10000 (49.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7704s / 307.3949 s
agent0:                 episode reward: -0.5021,                 loss: nan
agent1:                 episode reward: 0.5021,                 loss: 0.3084
Episode: 4941/10000 (49.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7580s / 308.1529 s
agent0:                 episode reward: -0.4813,                 loss: nan
agent1:                 episode reward: 0.4813,                 loss: 0.3083
Episode: 4951/10000 (49.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7596s / 308.9126 s
agent0:                 episode reward: -0.4520,                 loss: nan
agent1:                 episode reward: 0.4520,                 loss: 0.3079
Episode: 4961/10000 (49.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7566s / 309.6692 s
agent0:                 episode reward: -0.5038,                 loss: nan
agent1:                 episode reward: 0.5038,                 loss: 0.3051
Episode: 4971/10000 (49.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7499s / 310.4190 s
agent0:                 episode reward: -1.2496,                 loss: nan
agent1:                 episode reward: 1.2496,                 loss: 0.3158
Episode: 4981/10000 (49.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7495s / 311.1685 s
agent0:                 episode reward: -0.6416,                 loss: nan
agent1:                 episode reward: 0.6416,                 loss: 0.3137
Episode: 4991/10000 (49.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7612s / 311.9297 s
agent0:                 episode reward: -0.4810,                 loss: nan
agent1:                 episode reward: 0.4810,                 loss: 0.3105
Episode: 5001/10000 (50.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7616s / 312.6914 s
agent0:                 episode reward: -0.6733,                 loss: nan
agent1:                 episode reward: 0.6733,                 loss: 0.3101
Episode: 5011/10000 (50.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7569s / 313.4482 s
agent0:                 episode reward: -0.5835,                 loss: nan
agent1:                 episode reward: 0.5835,                 loss: 0.3088
Episode: 5021/10000 (50.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7621s / 314.2103 s
agent0:                 episode reward: -0.6210,                 loss: nan
agent1:                 episode reward: 0.6210,                 loss: 0.3092
Episode: 5031/10000 (50.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7669s / 314.9772 s
agent0:                 episode reward: -0.0750,                 loss: nan
agent1:                 episode reward: 0.0750,                 loss: 0.3085
Episode: 5041/10000 (50.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8394s / 315.8166 s
agent0:                 episode reward: 0.5522,                 loss: nan
agent1:                 episode reward: -0.5522,                 loss: 0.3077
Episode: 5051/10000 (50.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7663s / 316.5829 s
agent0:                 episode reward: -0.9051,                 loss: nan
agent1:                 episode reward: 0.9051,                 loss: 0.3070
Episode: 5061/10000 (50.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7518s / 317.3347 s
agent0:                 episode reward: -0.5806,                 loss: nan
agent1:                 episode reward: 0.5806,                 loss: 0.3063
Episode: 5071/10000 (50.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7557s / 318.0904 s
agent0:                 episode reward: 0.0932,                 loss: nan
agent1:                 episode reward: -0.0932,                 loss: 0.3163
Episode: 5081/10000 (50.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7762s / 318.8666 s
agent0:                 episode reward: 0.6033,                 loss: nan
agent1:                 episode reward: -0.6033,                 loss: 0.3116
Episode: 5091/10000 (50.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7687s / 319.6354 s
agent0:                 episode reward: -0.2696,                 loss: nan
agent1:                 episode reward: 0.2696,                 loss: 0.3140
Episode: 5101/10000 (51.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7629s / 320.3983 s
agent0:                 episode reward: -1.2262,                 loss: nan
agent1:                 episode reward: 1.2262,                 loss: 0.3111
Episode: 5111/10000 (51.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7622s / 321.1604 s
agent0:                 episode reward: -0.0204,                 loss: nan
agent1:                 episode reward: 0.0204,                 loss: 0.3110
Episode: 5121/10000 (51.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7780s / 321.9385 s
agent0:                 episode reward: -1.8813,                 loss: nan
agent1:                 episode reward: 1.8813,                 loss: 0.3125
Episode: 5131/10000 (51.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7782s / 322.7167 s
agent0:                 episode reward: -1.0268,                 loss: nan
agent1:                 episode reward: 1.0268,                 loss: 0.3114
Episode: 5141/10000 (51.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7810s / 323.4977 s
agent0:                 episode reward: 0.2489,                 loss: nan
agent1:                 episode reward: -0.2489,                 loss: 0.3110
Episode: 5151/10000 (51.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7681s / 324.2659 s
agent0:                 episode reward: -0.1391,                 loss: nan
agent1:                 episode reward: 0.1391,                 loss: 0.3106
Episode: 5161/10000 (51.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7743s / 325.0402 s
agent0:                 episode reward: -0.0102,                 loss: nan
agent1:                 episode reward: 0.0102,                 loss: 0.3110
Episode: 5171/10000 (51.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8170s / 325.8571 s
agent0:                 episode reward: -0.6485,                 loss: nan
agent1:                 episode reward: 0.6485,                 loss: 0.3209
Episode: 5181/10000 (51.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7707s / 326.6279 s
agent0:                 episode reward: -0.0811,                 loss: nan
agent1:                 episode reward: 0.0811,                 loss: 0.3176
Episode: 5191/10000 (51.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7731s / 327.4010 s
agent0:                 episode reward: -0.4089,                 loss: nan
agent1:                 episode reward: 0.4089,                 loss: 0.3161
Episode: 5201/10000 (52.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7684s / 328.1694 s
agent0:                 episode reward: -0.6333,                 loss: nan
agent1:                 episode reward: 0.6333,                 loss: 0.3149
Episode: 5211/10000 (52.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7647s / 328.9341 s
agent0:                 episode reward: -0.6203,                 loss: nan
agent1:                 episode reward: 0.6203,                 loss: 0.3173
Episode: 5221/10000 (52.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7654s / 329.6995 s
agent0:                 episode reward: -0.3277,                 loss: nan
agent1:                 episode reward: 0.3277,                 loss: 0.3143
Episode: 5231/10000 (52.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7707s / 330.4702 s
agent0:                 episode reward: -0.1747,                 loss: nan
agent1:                 episode reward: 0.1747,                 loss: 0.3165
Episode: 5241/10000 (52.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7805s / 331.2507 s
agent0:                 episode reward: -0.5635,                 loss: nan
agent1:                 episode reward: 0.5635,                 loss: 0.3173
Episode: 5251/10000 (52.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7864s / 332.0371 s
agent0:                 episode reward: -0.4605,                 loss: nan
agent1:                 episode reward: 0.4605,                 loss: 0.3158
Episode: 5261/10000 (52.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7760s / 332.8131 s
agent0:                 episode reward: -1.3428,                 loss: nan
agent1:                 episode reward: 1.3428,                 loss: 0.3126
Episode: 5271/10000 (52.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7713s / 333.5844 s
agent0:                 episode reward: -1.1910,                 loss: nan
agent1:                 episode reward: 1.1910,                 loss: 0.3209
Episode: 5281/10000 (52.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7895s / 334.3738 s
agent0:                 episode reward: -0.6538,                 loss: nan
agent1:                 episode reward: 0.6538,                 loss: 0.3107
Episode: 5291/10000 (52.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7789s / 335.1527 s
agent0:                 episode reward: -0.1132,                 loss: nan
agent1:                 episode reward: 0.1132,                 loss: 0.3076
Episode: 5301/10000 (53.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8082s / 335.9609 s
agent0:                 episode reward: -0.6950,                 loss: nan
agent1:                 episode reward: 0.6950,                 loss: 0.3065
Episode: 5311/10000 (53.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7837s / 336.7446 s
agent0:                 episode reward: -1.0032,                 loss: nan
agent1:                 episode reward: 1.0032,                 loss: 0.3071
Episode: 5321/10000 (53.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8002s / 337.5448 s
agent0:                 episode reward: 0.2931,                 loss: nan
agent1:                 episode reward: -0.2931,                 loss: 0.3054
Episode: 5331/10000 (53.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7697s / 338.3145 s
agent0:                 episode reward: 0.0779,                 loss: nan
agent1:                 episode reward: -0.0779,                 loss: 0.3073
Episode: 5341/10000 (53.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7813s / 339.0958 s
agent0:                 episode reward: 0.0499,                 loss: nan
agent1:                 episode reward: -0.0499,                 loss: 0.3072
Episode: 5351/10000 (53.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7733s / 339.8691 s
agent0:                 episode reward: -0.5708,                 loss: nan
agent1:                 episode reward: 0.5708,                 loss: 0.3068
Episode: 5361/10000 (53.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7916s / 340.6607 s
agent0:                 episode reward: -0.6727,                 loss: nan
agent1:                 episode reward: 0.6727,                 loss: 0.3043
Episode: 5371/10000 (53.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7738s / 341.4345 s
agent0:                 episode reward: -2.1307,                 loss: nan
agent1:                 episode reward: 2.1307,                 loss: 0.2864
Episode: 5381/10000 (53.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7683s / 342.2027 s
agent0:                 episode reward: -0.5913,                 loss: nan
agent1:                 episode reward: 0.5913,                 loss: 0.2634
Episode: 5391/10000 (53.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7896s / 342.9923 s
agent0:                 episode reward: 0.7000,                 loss: nan
agent1:                 episode reward: -0.7000,                 loss: 0.2617
Episode: 5401/10000 (54.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8451s / 343.8374 s
agent0:                 episode reward: 0.2853,                 loss: nan
agent1:                 episode reward: -0.2853,                 loss: 0.2623
Episode: 5411/10000 (54.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7834s / 344.6208 s
agent0:                 episode reward: -0.4521,                 loss: nan
agent1:                 episode reward: 0.4521,                 loss: 0.2594
Episode: 5421/10000 (54.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7781s / 345.3989 s
agent0:                 episode reward: 0.2220,                 loss: nan
agent1:                 episode reward: -0.2220,                 loss: 0.2594
Episode: 5431/10000 (54.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8484s / 346.2472 s
agent0:                 episode reward: -0.9345,                 loss: nan
agent1:                 episode reward: 0.9345,                 loss: 0.2595
Episode: 5441/10000 (54.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7774s / 347.0247 s
agent0:                 episode reward: -0.9329,                 loss: nan
agent1:                 episode reward: 0.9329,                 loss: 0.2588
Episode: 5451/10000 (54.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8214s / 347.8461 s
agent0:                 episode reward: -0.7560,                 loss: nan
agent1:                 episode reward: 0.7560,                 loss: 0.2565
Episode: 5461/10000 (54.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7974s / 348.6434 s
agent0:                 episode reward: -0.0046,                 loss: nan
agent1:                 episode reward: 0.0046,                 loss: 0.2580
Episode: 5471/10000 (54.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7981s / 349.4415 s
agent0:                 episode reward: 0.4017,                 loss: nan
agent1:                 episode reward: -0.4017,                 loss: 0.2284
Episode: 5481/10000 (54.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7852s / 350.2268 s
agent0:                 episode reward: -0.2078,                 loss: nan
agent1:                 episode reward: 0.2078,                 loss: 0.2021
Episode: 5491/10000 (54.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7885s / 351.0152 s
agent0:                 episode reward: -0.7671,                 loss: nan
agent1:                 episode reward: 0.7671,                 loss: 0.1996
Episode: 5501/10000 (55.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7964s / 351.8116 s
agent0:                 episode reward: 0.0635,                 loss: nan
agent1:                 episode reward: -0.0635,                 loss: 0.1990
Episode: 5511/10000 (55.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7947s / 352.6063 s
agent0:                 episode reward: -0.9097,                 loss: nan
agent1:                 episode reward: 0.9097,                 loss: 0.1981
Episode: 5521/10000 (55.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8005s / 353.4067 s
agent0:                 episode reward: -0.3543,                 loss: nan
agent1:                 episode reward: 0.3543,                 loss: 0.1964
Episode: 5531/10000 (55.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7886s / 354.1953 s
agent0:                 episode reward: -0.7399,                 loss: nan
agent1:                 episode reward: 0.7399,                 loss: 0.1954
Episode: 5541/10000 (55.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7850s / 354.9804 s
agent0:                 episode reward: -0.8667,                 loss: nan
agent1:                 episode reward: 0.8667,                 loss: 0.1957
Episode: 5551/10000 (55.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8001s / 355.7805 s
agent0:                 episode reward: -0.6726,                 loss: nan
agent1:                 episode reward: 0.6726,                 loss: 0.1947
Episode: 5561/10000 (55.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8265s / 356.6070 s
agent0:                 episode reward: -1.0925,                 loss: nan
agent1:                 episode reward: 1.0925,                 loss: 0.1946
Episode: 5571/10000 (55.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8320s / 357.4391 s
agent0:                 episode reward: -1.2083,                 loss: nan
agent1:                 episode reward: 1.2083,                 loss: 0.1898
Episode: 5581/10000 (55.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7895s / 358.2286 s
agent0:                 episode reward: -0.5536,                 loss: nan
agent1:                 episode reward: 0.5536,                 loss: 0.1746
Episode: 5591/10000 (55.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8192s / 359.0477 s
agent0:                 episode reward: -0.5742,                 loss: nan
agent1:                 episode reward: 0.5742,                 loss: 0.1733
Episode: 5601/10000 (56.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7852s / 359.8330 s
agent0:                 episode reward: -1.1827,                 loss: nan
agent1:                 episode reward: 1.1827,                 loss: 0.1744
Episode: 5611/10000 (56.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7889s / 360.6218 s
agent0:                 episode reward: -0.2351,                 loss: nan
agent1:                 episode reward: 0.2351,                 loss: 0.1743
Episode: 5621/10000 (56.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8420s / 361.4639 s
agent0:                 episode reward: -0.5981,                 loss: nan
agent1:                 episode reward: 0.5981,                 loss: 0.1720
Episode: 5631/10000 (56.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8038s / 362.2677 s
agent0:                 episode reward: -0.3984,                 loss: nan
agent1:                 episode reward: 0.3984,                 loss: 0.1730
Episode: 5641/10000 (56.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7888s / 363.0565 s
agent0:                 episode reward: -0.2841,                 loss: nan
agent1:                 episode reward: 0.2841,                 loss: 0.1745
Episode: 5651/10000 (56.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8014s / 363.8579 s
agent0:                 episode reward: -0.2682,                 loss: nan
agent1:                 episode reward: 0.2682,                 loss: 0.1716
Episode: 5661/10000 (56.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8016s / 364.6595 s
agent0:                 episode reward: -0.3688,                 loss: nan
agent1:                 episode reward: 0.3688,                 loss: 0.1723
Episode: 5671/10000 (56.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8124s / 365.4719 s
agent0:                 episode reward: 0.0173,                 loss: nan
agent1:                 episode reward: -0.0173,                 loss: 0.1987
Episode: 5681/10000 (56.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8112s / 366.2831 s
agent0:                 episode reward: -0.0268,                 loss: nan
agent1:                 episode reward: 0.0268,                 loss: 0.2024
Episode: 5691/10000 (56.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8699s / 367.1529 s
agent0:                 episode reward: -0.0722,                 loss: nan
agent1:                 episode reward: 0.0722,                 loss: 0.2007
Episode: 5701/10000 (57.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7945s / 367.9475 s
agent0:                 episode reward: 0.2694,                 loss: nan
agent1:                 episode reward: -0.2694,                 loss: 0.2007
Episode: 5711/10000 (57.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7934s / 368.7409 s
agent0:                 episode reward: -0.2625,                 loss: nan
agent1:                 episode reward: 0.2625,                 loss: 0.1998
Episode: 5721/10000 (57.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7910s / 369.5318 s
agent0:                 episode reward: -0.5752,                 loss: nan
agent1:                 episode reward: 0.5752,                 loss: 0.2007
Episode: 5731/10000 (57.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8283s / 370.3601 s
agent0:                 episode reward: -1.1866,                 loss: nan
agent1:                 episode reward: 1.1866,                 loss: 0.1995
Episode: 5741/10000 (57.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8015s / 371.1616 s
agent0:                 episode reward: -0.5273,                 loss: nan
agent1:                 episode reward: 0.5273,                 loss: 0.1990
Episode: 5751/10000 (57.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8089s / 371.9705 s
agent0:                 episode reward: -0.0899,                 loss: nan
agent1:                 episode reward: 0.0899,                 loss: 0.2014
Episode: 5761/10000 (57.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8072s / 372.7777 s
agent0:                 episode reward: -0.7418,                 loss: nan
agent1:                 episode reward: 0.7418,                 loss: 0.1993
Episode: 5771/10000 (57.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8141s / 373.5918 s
agent0:                 episode reward: -0.6193,                 loss: nan
agent1:                 episode reward: 0.6193,                 loss: 0.2305
Episode: 5781/10000 (57.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8075s / 374.3993 s
agent0:                 episode reward: -0.4124,                 loss: nan
agent1:                 episode reward: 0.4124,                 loss: 0.2420
Episode: 5791/10000 (57.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8001s / 375.1994 s
agent0:                 episode reward: -0.5876,                 loss: nan
agent1:                 episode reward: 0.5876,                 loss: 0.2404
Episode: 5801/10000 (58.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8072s / 376.0065 s
agent0:                 episode reward: -0.7400,                 loss: nan
agent1:                 episode reward: 0.7400,                 loss: 0.2387
Episode: 5811/10000 (58.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8603s / 376.8668 s
agent0:                 episode reward: -0.5963,                 loss: nan
agent1:                 episode reward: 0.5963,                 loss: 0.2393
Episode: 5821/10000 (58.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8100s / 377.6768 s
agent0:                 episode reward: -0.5312,                 loss: nan
agent1:                 episode reward: 0.5312,                 loss: 0.2362
Episode: 5831/10000 (58.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8437s / 378.5205 s
agent0:                 episode reward: -0.2278,                 loss: nan
agent1:                 episode reward: 0.2278,                 loss: 0.2378
Episode: 5841/10000 (58.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8138s / 379.3343 s
agent0:                 episode reward: -1.0746,                 loss: nan
agent1:                 episode reward: 1.0746,                 loss: 0.2411
Episode: 5851/10000 (58.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7974s / 380.1317 s
agent0:                 episode reward: -0.1687,                 loss: nan
agent1:                 episode reward: 0.1687,                 loss: 0.2402
Episode: 5861/10000 (58.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8110s / 380.9427 s
agent0:                 episode reward: -0.5825,                 loss: nan
agent1:                 episode reward: 0.5825,                 loss: 0.2402
Episode: 5871/10000 (58.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8147s / 381.7575 s
agent0:                 episode reward: 0.5324,                 loss: nan
agent1:                 episode reward: -0.5324,                 loss: 0.2780
Episode: 5881/10000 (58.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8190s / 382.5765 s
agent0:                 episode reward: -0.6182,                 loss: nan
agent1:                 episode reward: 0.6182,                 loss: 0.2904
Episode: 5891/10000 (58.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8061s / 383.3826 s
agent0:                 episode reward: -0.7515,                 loss: nan
agent1:                 episode reward: 0.7515,                 loss: 0.2891
Episode: 5901/10000 (59.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8125s / 384.1951 s
agent0:                 episode reward: -1.0033,                 loss: nan
agent1:                 episode reward: 1.0033,                 loss: 0.2894
Episode: 5911/10000 (59.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8089s / 385.0040 s
agent0:                 episode reward: -0.6665,                 loss: nan
agent1:                 episode reward: 0.6665,                 loss: 0.2876
Episode: 5921/10000 (59.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8180s / 385.8220 s
agent0:                 episode reward: 0.3010,                 loss: nan
agent1:                 episode reward: -0.3010,                 loss: 0.2887
Episode: 5931/10000 (59.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8094s / 386.6314 s
agent0:                 episode reward: 0.2157,                 loss: nan
agent1:                 episode reward: -0.2157,                 loss: 0.2884
Episode: 5941/10000 (59.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8505s / 387.4818 s
agent0:                 episode reward: -0.7596,                 loss: nan
agent1:                 episode reward: 0.7596,                 loss: 0.2863
Episode: 5951/10000 (59.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8234s / 388.3053 s
agent0:                 episode reward: 0.1566,                 loss: nan
agent1:                 episode reward: -0.1566,                 loss: 0.2895
Episode: 5961/10000 (59.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8179s / 389.1231 s
agent0:                 episode reward: -0.4987,                 loss: nan
agent1:                 episode reward: 0.4987,                 loss: 0.2859
Episode: 5971/10000 (59.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8491s / 389.9722 s
agent0:                 episode reward: -0.3765,                 loss: nan
agent1:                 episode reward: 0.3765,                 loss: 0.3105
Episode: 5981/10000 (59.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8151s / 390.7874 s
agent0:                 episode reward: -0.6411,                 loss: nan
agent1:                 episode reward: 0.6411,                 loss: 0.3140
Episode: 5991/10000 (59.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8212s / 391.6085 s
agent0:                 episode reward: -0.2279,                 loss: nan
agent1:                 episode reward: 0.2279,                 loss: 0.3136
Episode: 6001/10000 (60.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8152s / 392.4237 s
agent0:                 episode reward: -0.7099,                 loss: nan
agent1:                 episode reward: 0.7099,                 loss: 0.3145
Episode: 6011/10000 (60.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8232s / 393.2470 s
agent0:                 episode reward: -0.0976,                 loss: nan
agent1:                 episode reward: 0.0976,                 loss: 0.3148
Episode: 6021/10000 (60.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8272s / 394.0741 s
agent0:                 episode reward: -0.6712,                 loss: nan
agent1:                 episode reward: 0.6712,                 loss: 0.3150
Episode: 6031/10000 (60.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8387s / 394.9129 s
agent0:                 episode reward: -0.3585,                 loss: nan
agent1:                 episode reward: 0.3585,                 loss: 0.3123
Episode: 6041/10000 (60.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8190s / 395.7318 s
agent0:                 episode reward: -0.1840,                 loss: nan
agent1:                 episode reward: 0.1840,                 loss: 0.3146
Episode: 6051/10000 (60.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8307s / 396.5625 s
agent0:                 episode reward: -1.1454,                 loss: nan
agent1:                 episode reward: 1.1454,                 loss: 0.3120
Episode: 6061/10000 (60.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8733s / 397.4359 s
agent0:                 episode reward: -0.2244,                 loss: nan
agent1:                 episode reward: 0.2244,                 loss: 0.3122
Episode: 6071/10000 (60.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8450s / 398.2808 s
agent0:                 episode reward: -0.3986,                 loss: nan
agent1:                 episode reward: 0.3986,                 loss: 0.3234
Episode: 6081/10000 (60.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8197s / 399.1005 s
agent0:                 episode reward: -0.2978,                 loss: nan
agent1:                 episode reward: 0.2978,                 loss: 0.3242
Episode: 6091/10000 (60.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8258s / 399.9264 s
agent0:                 episode reward: -0.5396,                 loss: nan
agent1:                 episode reward: 0.5396,                 loss: 0.3227
Episode: 6101/10000 (61.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8310s / 400.7573 s
agent0:                 episode reward: -1.2798,                 loss: nan
agent1:                 episode reward: 1.2798,                 loss: 0.3226
Episode: 6111/10000 (61.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8680s / 401.6254 s
agent0:                 episode reward: -0.8396,                 loss: nan
agent1:                 episode reward: 0.8396,                 loss: 0.3214
Episode: 6121/10000 (61.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8235s / 402.4489 s
agent0:                 episode reward: 0.0536,                 loss: nan
agent1:                 episode reward: -0.0536,                 loss: 0.3216
Episode: 6131/10000 (61.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8221s / 403.2710 s
agent0:                 episode reward: -1.2439,                 loss: nan
agent1:                 episode reward: 1.2439,                 loss: 0.3196
Episode: 6141/10000 (61.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8312s / 404.1022 s
agent0:                 episode reward: -0.4716,                 loss: nan
agent1:                 episode reward: 0.4716,                 loss: 0.3228
Episode: 6151/10000 (61.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8179s / 404.9201 s
agent0:                 episode reward: -1.7063,                 loss: nan
agent1:                 episode reward: 1.7063,                 loss: 0.3195
Episode: 6161/10000 (61.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8463s / 405.7664 s
agent0:                 episode reward: -1.3950,                 loss: nan
agent1:                 episode reward: 1.3950,                 loss: 0.3237
Episode: 6171/10000 (61.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8343s / 406.6007 s
agent0:                 episode reward: 0.0882,                 loss: nan
agent1:                 episode reward: -0.0882,                 loss: 0.3206
Episode: 6181/10000 (61.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8631s / 407.4638 s
agent0:                 episode reward: -0.9325,                 loss: nan
agent1:                 episode reward: 0.9325,                 loss: 0.3139
Episode: 6191/10000 (61.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8344s / 408.2982 s
agent0:                 episode reward: -0.3810,                 loss: nan
agent1:                 episode reward: 0.3810,                 loss: 0.3115
Episode: 6201/10000 (62.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8254s / 409.1236 s
agent0:                 episode reward: -0.8645,                 loss: nan
agent1:                 episode reward: 0.8645,                 loss: 0.3110
Episode: 6211/10000 (62.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8326s / 409.9562 s
agent0:                 episode reward: -0.9950,                 loss: nan
agent1:                 episode reward: 0.9950,                 loss: 0.3093
Episode: 6221/10000 (62.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8260s / 410.7821 s
agent0:                 episode reward: -0.6508,                 loss: nan
agent1:                 episode reward: 0.6508,                 loss: 0.3097
Episode: 6231/10000 (62.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8305s / 411.6127 s
agent0:                 episode reward: -1.1611,                 loss: nan
agent1:                 episode reward: 1.1611,                 loss: 0.3102
Episode: 6241/10000 (62.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8362s / 412.4488 s
agent0:                 episode reward: -0.4338,                 loss: nan
agent1:                 episode reward: 0.4338,                 loss: 0.3108
Episode: 6251/10000 (62.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8478s / 413.2967 s
agent0:                 episode reward: -0.2972,                 loss: nan
agent1:                 episode reward: 0.2972,                 loss: 0.3088
Episode: 6261/10000 (62.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8315s / 414.1282 s
agent0:                 episode reward: -1.1301,                 loss: nan
agent1:                 episode reward: 1.1301,                 loss: 0.3096
Episode: 6271/10000 (62.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8561s / 414.9843 s
agent0:                 episode reward: -0.8763,                 loss: nan
agent1:                 episode reward: 0.8763,                 loss: 0.3155
Episode: 6281/10000 (62.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8452s / 415.8296 s
agent0:                 episode reward: 0.1495,                 loss: nan
agent1:                 episode reward: -0.1495,                 loss: 0.3103
Episode: 6291/10000 (62.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8358s / 416.6654 s
agent0:                 episode reward: -1.0515,                 loss: nan
agent1:                 episode reward: 1.0515,                 loss: 0.3085
Episode: 6301/10000 (63.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8234s / 417.4888 s
agent0:                 episode reward: 0.1711,                 loss: nan
agent1:                 episode reward: -0.1711,                 loss: 0.3084
Episode: 6311/10000 (63.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8734s / 418.3622 s
agent0:                 episode reward: -1.6502,                 loss: nan
agent1:                 episode reward: 1.6502,                 loss: 0.3077
Episode: 6321/10000 (63.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8321s / 419.1943 s
agent0:                 episode reward: 0.0532,                 loss: nan
agent1:                 episode reward: -0.0532,                 loss: 0.3064
Episode: 6331/10000 (63.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8384s / 420.0328 s
agent0:                 episode reward: -1.0422,                 loss: nan
agent1:                 episode reward: 1.0422,                 loss: 0.3056
Episode: 6341/10000 (63.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8352s / 420.8679 s
agent0:                 episode reward: 0.1727,                 loss: nan
agent1:                 episode reward: -0.1727,                 loss: 0.3049
Episode: 6351/10000 (63.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8426s / 421.7105 s
agent0:                 episode reward: -0.9571,                 loss: nan
agent1:                 episode reward: 0.9571,                 loss: 0.3080
Episode: 6361/10000 (63.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8477s / 422.5582 s
agent0:                 episode reward: -0.6808,                 loss: nan
agent1:                 episode reward: 0.6808,                 loss: 0.3047
Episode: 6371/10000 (63.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9091s / 423.4673 s
agent0:                 episode reward: -0.3867,                 loss: nan
agent1:                 episode reward: 0.3867,                 loss: 0.2990
Episode: 6381/10000 (63.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8522s / 424.3195 s
agent0:                 episode reward: 0.2981,                 loss: nan
agent1:                 episode reward: -0.2981,                 loss: 0.2809
Episode: 6391/10000 (63.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8381s / 425.1575 s
agent0:                 episode reward: -0.3646,                 loss: nan
agent1:                 episode reward: 0.3646,                 loss: 0.2790
Episode: 6401/10000 (64.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8384s / 425.9959 s
agent0:                 episode reward: -0.6740,                 loss: nan
agent1:                 episode reward: 0.6740,                 loss: 0.2786
Episode: 6411/10000 (64.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8386s / 426.8346 s
agent0:                 episode reward: -0.4612,                 loss: nan
agent1:                 episode reward: 0.4612,                 loss: 0.2784
Episode: 6421/10000 (64.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8523s / 427.6869 s
agent0:                 episode reward: -1.6609,                 loss: nan
agent1:                 episode reward: 1.6609,                 loss: 0.2777
Episode: 6431/10000 (64.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8813s / 428.5682 s
agent0:                 episode reward: -0.5799,                 loss: nan
agent1:                 episode reward: 0.5799,                 loss: 0.2797
Episode: 6441/10000 (64.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8336s / 429.4018 s
agent0:                 episode reward: 0.0650,                 loss: nan
agent1:                 episode reward: -0.0650,                 loss: 0.2768
Episode: 6451/10000 (64.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8363s / 430.2381 s
agent0:                 episode reward: 0.4229,                 loss: nan
agent1:                 episode reward: -0.4229,                 loss: 0.2781
Episode: 6461/10000 (64.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8494s / 431.0876 s
agent0:                 episode reward: -0.7839,                 loss: nan
agent1:                 episode reward: 0.7839,                 loss: 0.2763
Episode: 6471/10000 (64.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8553s / 431.9428 s
agent0:                 episode reward: 0.0818,                 loss: nan
agent1:                 episode reward: -0.0818,                 loss: 0.2424
Episode: 6481/10000 (64.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8403s / 432.7831 s
agent0:                 episode reward: 0.3777,                 loss: nan
agent1:                 episode reward: -0.3777,                 loss: 0.2087
Episode: 6491/10000 (64.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8655s / 433.6486 s
agent0:                 episode reward: -0.5973,                 loss: nan
agent1:                 episode reward: 0.5973,                 loss: 0.2075
Episode: 6501/10000 (65.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8449s / 434.4936 s
agent0:                 episode reward: -0.8952,                 loss: nan
agent1:                 episode reward: 0.8952,                 loss: 0.2020
Episode: 6511/10000 (65.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8387s / 435.3322 s
agent0:                 episode reward: -0.0511,                 loss: nan
agent1:                 episode reward: 0.0511,                 loss: 0.2014
Episode: 6521/10000 (65.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8489s / 436.1811 s
agent0:                 episode reward: -0.8118,                 loss: nan
agent1:                 episode reward: 0.8118,                 loss: 0.2012
Episode: 6531/10000 (65.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8574s / 437.0385 s
agent0:                 episode reward: -0.3173,                 loss: nan
agent1:                 episode reward: 0.3173,                 loss: 0.2014
Episode: 6541/10000 (65.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8346s / 437.8731 s
agent0:                 episode reward: 0.1094,                 loss: nan
agent1:                 episode reward: -0.1094,                 loss: 0.2017
Episode: 6551/10000 (65.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9069s / 438.7800 s
agent0:                 episode reward: -0.2914,                 loss: nan
agent1:                 episode reward: 0.2914,                 loss: 0.2006
Episode: 6561/10000 (65.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9092s / 439.6892 s
agent0:                 episode reward: -0.7501,                 loss: nan
agent1:                 episode reward: 0.7501,                 loss: 0.2000
Episode: 6571/10000 (65.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8522s / 440.5413 s
agent0:                 episode reward: 0.1055,                 loss: nan
agent1:                 episode reward: -0.1055,                 loss: 0.1878
Episode: 6581/10000 (65.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8475s / 441.3888 s
agent0:                 episode reward: 0.2131,                 loss: nan
agent1:                 episode reward: -0.2131,                 loss: 0.1690
Episode: 6591/10000 (65.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8520s / 442.2408 s
agent0:                 episode reward: -0.3295,                 loss: nan
agent1:                 episode reward: 0.3295,                 loss: 0.1688
Episode: 6601/10000 (66.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8668s / 443.1076 s
agent0:                 episode reward: -0.2060,                 loss: nan
agent1:                 episode reward: 0.2060,                 loss: 0.1687
Episode: 6611/10000 (66.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8463s / 443.9539 s
agent0:                 episode reward: -0.9835,                 loss: nan
agent1:                 episode reward: 0.9835,                 loss: 0.1682
Episode: 6621/10000 (66.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8639s / 444.8179 s
agent0:                 episode reward: -0.1859,                 loss: nan
agent1:                 episode reward: 0.1859,                 loss: 0.1668
Episode: 6631/10000 (66.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8779s / 445.6958 s
agent0:                 episode reward: -1.2458,                 loss: nan
agent1:                 episode reward: 1.2458,                 loss: 0.1671
Episode: 6641/10000 (66.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8886s / 446.5844 s
agent0:                 episode reward: -0.6089,                 loss: nan
agent1:                 episode reward: 0.6089,                 loss: 0.1650
Episode: 6651/10000 (66.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8718s / 447.4562 s
agent0:                 episode reward: 0.4040,                 loss: nan
agent1:                 episode reward: -0.4040,                 loss: 0.1644
Episode: 6661/10000 (66.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8722s / 448.3284 s
agent0:                 episode reward: -0.4293,                 loss: nan
agent1:                 episode reward: 0.4293,                 loss: 0.1655
Episode: 6671/10000 (66.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9017s / 449.2300 s
agent0:                 episode reward: -0.5573,                 loss: nan
agent1:                 episode reward: 0.5573,                 loss: 0.1854
Episode: 6681/10000 (66.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8548s / 450.0848 s
agent0:                 episode reward: -1.1327,                 loss: nan
agent1:                 episode reward: 1.1327,                 loss: 0.1898
Episode: 6691/10000 (66.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8530s / 450.9378 s
agent0:                 episode reward: -0.5095,                 loss: nan
agent1:                 episode reward: 0.5095,                 loss: 0.1895
Episode: 6701/10000 (67.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8990s / 451.8368 s
agent0:                 episode reward: -1.2458,                 loss: nan
agent1:                 episode reward: 1.2458,                 loss: 0.1858
Episode: 6711/10000 (67.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8651s / 452.7019 s
agent0:                 episode reward: 0.4252,                 loss: nan
agent1:                 episode reward: -0.4252,                 loss: 0.1883
Episode: 6721/10000 (67.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8596s / 453.5615 s
agent0:                 episode reward: -0.2899,                 loss: nan
agent1:                 episode reward: 0.2899,                 loss: 0.1888
Episode: 6731/10000 (67.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8574s / 454.4189 s
agent0:                 episode reward: -0.5261,                 loss: nan
agent1:                 episode reward: 0.5261,                 loss: 0.1864
Episode: 6741/10000 (67.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8870s / 455.3059 s
agent0:                 episode reward: -1.0310,                 loss: nan
agent1:                 episode reward: 1.0310,                 loss: 0.1878
Episode: 6751/10000 (67.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8558s / 456.1616 s
agent0:                 episode reward: -0.8318,                 loss: nan
agent1:                 episode reward: 0.8318,                 loss: 0.1858
Episode: 6761/10000 (67.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8778s / 457.0394 s
agent0:                 episode reward: 0.1304,                 loss: nan
agent1:                 episode reward: -0.1304,                 loss: 0.1876
Episode: 6771/10000 (67.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8707s / 457.9101 s
agent0:                 episode reward: -0.2392,                 loss: nan
agent1:                 episode reward: 0.2392,                 loss: 0.2207
Episode: 6781/10000 (67.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9178s / 458.8279 s
agent0:                 episode reward: -0.3022,                 loss: nan
agent1:                 episode reward: 0.3022,                 loss: 0.2307
Episode: 6791/10000 (67.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8709s / 459.6987 s
agent0:                 episode reward: -0.0557,                 loss: nan
agent1:                 episode reward: 0.0557,                 loss: 0.2298
Episode: 6801/10000 (68.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8652s / 460.5639 s
agent0:                 episode reward: -0.2629,                 loss: nan
agent1:                 episode reward: 0.2629,                 loss: 0.2322
Episode: 6811/10000 (68.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8749s / 461.4388 s
agent0:                 episode reward: -0.3362,                 loss: nan
agent1:                 episode reward: 0.3362,                 loss: 0.2305
Episode: 6821/10000 (68.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8806s / 462.3194 s
agent0:                 episode reward: 0.0843,                 loss: nan
agent1:                 episode reward: -0.0843,                 loss: 0.2317
Episode: 6831/10000 (68.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8777s / 463.1971 s
agent0:                 episode reward: -0.3605,                 loss: nan
agent1:                 episode reward: 0.3605,                 loss: 0.2286
Episode: 6841/10000 (68.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8726s / 464.0696 s
agent0:                 episode reward: -0.9145,                 loss: nan
agent1:                 episode reward: 0.9145,                 loss: 0.2309
Episode: 6851/10000 (68.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8944s / 464.9640 s
agent0:                 episode reward: -0.1573,                 loss: nan
agent1:                 episode reward: 0.1573,                 loss: 0.2276
Episode: 6861/10000 (68.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8690s / 465.8330 s
agent0:                 episode reward: -0.0531,                 loss: nan
agent1:                 episode reward: 0.0531,                 loss: 0.2286
Episode: 6871/10000 (68.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8692s / 466.7022 s
agent0:                 episode reward: -0.1451,                 loss: nan
agent1:                 episode reward: 0.1451,                 loss: 0.2645
Episode: 6881/10000 (68.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8643s / 467.5665 s
agent0:                 episode reward: -0.4362,                 loss: nan
agent1:                 episode reward: 0.4362,                 loss: 0.2763
Episode: 6891/10000 (68.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8714s / 468.4379 s
agent0:                 episode reward: -0.6283,                 loss: nan
agent1:                 episode reward: 0.6283,                 loss: 0.2736
Episode: 6901/10000 (69.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8887s / 469.3266 s
agent0:                 episode reward: -1.1370,                 loss: nan
agent1:                 episode reward: 1.1370,                 loss: 0.2774
Episode: 6911/10000 (69.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8984s / 470.2250 s
agent0:                 episode reward: -0.1960,                 loss: nan
agent1:                 episode reward: 0.1960,                 loss: 0.2739
Episode: 6921/10000 (69.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8676s / 471.0925 s
agent0:                 episode reward: -0.7088,                 loss: nan
agent1:                 episode reward: 0.7088,                 loss: 0.2767
Episode: 6931/10000 (69.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8685s / 471.9610 s
agent0:                 episode reward: -0.5704,                 loss: nan
agent1:                 episode reward: 0.5704,                 loss: 0.2756
Episode: 6941/10000 (69.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8788s / 472.8397 s
agent0:                 episode reward: -0.0303,                 loss: nan
agent1:                 episode reward: 0.0303,                 loss: 0.2728
Episode: 6951/10000 (69.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8933s / 473.7330 s
agent0:                 episode reward: -0.7644,                 loss: nan
agent1:                 episode reward: 0.7644,                 loss: 0.2778
Episode: 6961/10000 (69.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8862s / 474.6192 s
agent0:                 episode reward: -0.0583,                 loss: nan
agent1:                 episode reward: 0.0583,                 loss: 0.2742
Episode: 6971/10000 (69.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8835s / 475.5027 s
agent0:                 episode reward: -0.3552,                 loss: nan
agent1:                 episode reward: 0.3552,                 loss: 0.3081
Episode: 6981/10000 (69.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8887s / 476.3914 s
agent0:                 episode reward: 0.8033,                 loss: nan
agent1:                 episode reward: -0.8033,                 loss: 0.3169
Episode: 6991/10000 (69.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8691s / 477.2605 s
agent0:                 episode reward: 0.2659,                 loss: nan
agent1:                 episode reward: -0.2659,                 loss: 0.3158
Episode: 7001/10000 (70.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8706s / 478.1311 s
agent0:                 episode reward: -0.0284,                 loss: nan
agent1:                 episode reward: 0.0284,                 loss: 0.3148
Episode: 7011/10000 (70.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9074s / 479.0384 s
agent0:                 episode reward: 0.0831,                 loss: nan
agent1:                 episode reward: -0.0831,                 loss: 0.3158
Episode: 7021/10000 (70.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9244s / 479.9628 s
agent0:                 episode reward: -1.1774,                 loss: nan
agent1:                 episode reward: 1.1774,                 loss: 0.3113
Episode: 7031/10000 (70.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8830s / 480.8458 s
agent0:                 episode reward: 0.1895,                 loss: nan
agent1:                 episode reward: -0.1895,                 loss: 0.3154
Episode: 7041/10000 (70.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8938s / 481.7396 s
agent0:                 episode reward: 0.0529,                 loss: nan
agent1:                 episode reward: -0.0529,                 loss: 0.3115
Episode: 7051/10000 (70.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8877s / 482.6273 s
agent0:                 episode reward: -0.9256,                 loss: nan
agent1:                 episode reward: 0.9256,                 loss: 0.3124
Episode: 7061/10000 (70.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8868s / 483.5141 s
agent0:                 episode reward: 0.9959,                 loss: nan
agent1:                 episode reward: -0.9959,                 loss: 0.3158
Episode: 7071/10000 (70.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8926s / 484.4067 s
agent0:                 episode reward: -0.1591,                 loss: nan
agent1:                 episode reward: 0.1591,                 loss: 0.3228
Episode: 7081/10000 (70.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9016s / 485.3083 s
agent0:                 episode reward: 0.3843,                 loss: nan
agent1:                 episode reward: -0.3843,                 loss: 0.3145
Episode: 7091/10000 (70.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9015s / 486.2098 s
agent0:                 episode reward: 0.6405,                 loss: nan
agent1:                 episode reward: -0.6405,                 loss: 0.3158
Episode: 7101/10000 (71.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8974s / 487.1072 s
agent0:                 episode reward: -1.3833,                 loss: nan
agent1:                 episode reward: 1.3833,                 loss: 0.3153
Episode: 7111/10000 (71.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9024s / 488.0096 s
agent0:                 episode reward: -0.7092,                 loss: nan
agent1:                 episode reward: 0.7092,                 loss: 0.3139
Episode: 7121/10000 (71.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9048s / 488.9144 s
agent0:                 episode reward: -0.2101,                 loss: nan
agent1:                 episode reward: 0.2101,                 loss: 0.3157
Episode: 7131/10000 (71.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9382s / 489.8526 s
agent0:                 episode reward: 0.1299,                 loss: nan
agent1:                 episode reward: -0.1299,                 loss: 0.3155
Episode: 7141/10000 (71.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8954s / 490.7480 s
agent0:                 episode reward: -0.8262,                 loss: nan
agent1:                 episode reward: 0.8262,                 loss: 0.3129
Episode: 7151/10000 (71.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9073s / 491.6553 s
agent0:                 episode reward: -0.6207,                 loss: nan
agent1:                 episode reward: 0.6207,                 loss: 0.3131
Episode: 7161/10000 (71.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8951s / 492.5504 s
agent0:                 episode reward: -0.2798,                 loss: nan
agent1:                 episode reward: 0.2798,                 loss: 0.3128
Episode: 7171/10000 (71.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8930s / 493.4434 s
agent0:                 episode reward: -0.0351,                 loss: nan
agent1:                 episode reward: 0.0351,                 loss: 0.3207
Episode: 7181/10000 (71.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8998s / 494.3433 s
agent0:                 episode reward: 0.1304,                 loss: nan
agent1:                 episode reward: -0.1304,                 loss: 0.3140
Episode: 7191/10000 (71.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9084s / 495.2517 s
agent0:                 episode reward: 0.1828,                 loss: nan
agent1:                 episode reward: -0.1828,                 loss: 0.3143
Episode: 7201/10000 (72.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9007s / 496.1523 s
agent0:                 episode reward: 0.0813,                 loss: nan
agent1:                 episode reward: -0.0813,                 loss: 0.3121
Episode: 7211/10000 (72.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9033s / 497.0556 s
agent0:                 episode reward: -0.4569,                 loss: nan
agent1:                 episode reward: 0.4569,                 loss: 0.3089
Episode: 7221/10000 (72.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9183s / 497.9739 s
agent0:                 episode reward: -0.0375,                 loss: nan
agent1:                 episode reward: 0.0375,                 loss: 0.3113
Episode: 7231/10000 (72.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9202s / 498.8941 s
agent0:                 episode reward: -0.9532,                 loss: nan
agent1:                 episode reward: 0.9532,                 loss: 0.3092
Episode: 7241/10000 (72.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9431s / 499.8372 s
agent0:                 episode reward: -0.2797,                 loss: nan
agent1:                 episode reward: 0.2797,                 loss: 0.3122
Episode: 7251/10000 (72.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9069s / 500.7441 s
agent0:                 episode reward: -0.9323,                 loss: nan
agent1:                 episode reward: 0.9323,                 loss: 0.3127
Episode: 7261/10000 (72.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9184s / 501.6625 s
agent0:                 episode reward: -0.8317,                 loss: nan
agent1:                 episode reward: 0.8317,                 loss: 0.3093
Episode: 7271/10000 (72.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9245s / 502.5870 s
agent0:                 episode reward: 0.0560,                 loss: nan
agent1:                 episode reward: -0.0560,                 loss: 0.3196
Episode: 7281/10000 (72.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9011s / 503.4882 s
agent0:                 episode reward: 0.3667,                 loss: nan
agent1:                 episode reward: -0.3667,                 loss: 0.3120
Episode: 7291/10000 (72.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9152s / 504.4034 s
agent0:                 episode reward: -0.2528,                 loss: nan
agent1:                 episode reward: 0.2528,                 loss: 0.3112
Episode: 7301/10000 (73.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9131s / 505.3166 s
agent0:                 episode reward: -0.5410,                 loss: nan
agent1:                 episode reward: 0.5410,                 loss: 0.3099
Episode: 7311/10000 (73.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9181s / 506.2347 s
agent0:                 episode reward: 0.9765,                 loss: nan
agent1:                 episode reward: -0.9765,                 loss: 0.3094
Episode: 7321/10000 (73.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9108s / 507.1455 s
agent0:                 episode reward: -1.3090,                 loss: nan
agent1:                 episode reward: 1.3090,                 loss: 0.3088
Episode: 7331/10000 (73.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8989s / 508.0444 s
agent0:                 episode reward: -0.1324,                 loss: nan
agent1:                 episode reward: 0.1324,                 loss: 0.3075
Episode: 7341/10000 (73.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9016s / 508.9460 s
agent0:                 episode reward: -0.7191,                 loss: nan
agent1:                 episode reward: 0.7191,                 loss: 0.3072
Episode: 7351/10000 (73.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9873s / 509.9332 s
agent0:                 episode reward: -0.3902,                 loss: nan
agent1:                 episode reward: 0.3902,                 loss: 0.3075
Episode: 7361/10000 (73.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9132s / 510.8464 s
agent0:                 episode reward: -0.5055,                 loss: nan
agent1:                 episode reward: 0.5055,                 loss: 0.3083
Episode: 7371/10000 (73.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9093s / 511.7557 s
agent0:                 episode reward: -1.6215,                 loss: nan
agent1:                 episode reward: 1.6215,                 loss: 0.2836
Episode: 7381/10000 (73.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9219s / 512.6776 s
agent0:                 episode reward: -0.4039,                 loss: nan
agent1:                 episode reward: 0.4039,                 loss: 0.2623
Episode: 7391/10000 (73.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9006s / 513.5782 s
agent0:                 episode reward: -0.5949,                 loss: nan
agent1:                 episode reward: 0.5949,                 loss: 0.2606
Episode: 7401/10000 (74.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9224s / 514.5007 s
agent0:                 episode reward: -1.3528,                 loss: nan
agent1:                 episode reward: 1.3528,                 loss: 0.2617
Episode: 7411/10000 (74.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9151s / 515.4158 s
agent0:                 episode reward: -0.5816,                 loss: nan
agent1:                 episode reward: 0.5816,                 loss: 0.2613
Episode: 7421/10000 (74.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9373s / 516.3532 s
agent0:                 episode reward: -0.7992,                 loss: nan
agent1:                 episode reward: 0.7992,                 loss: 0.2577
Episode: 7431/10000 (74.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9082s / 517.2614 s
agent0:                 episode reward: -0.7758,                 loss: nan
agent1:                 episode reward: 0.7758,                 loss: 0.2611
Episode: 7441/10000 (74.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9140s / 518.1754 s
agent0:                 episode reward: -0.9888,                 loss: nan
agent1:                 episode reward: 0.9888,                 loss: 0.2621
Episode: 7451/10000 (74.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9128s / 519.0882 s
agent0:                 episode reward: -0.8815,                 loss: nan
agent1:                 episode reward: 0.8815,                 loss: 0.2573
Episode: 7461/10000 (74.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9029s / 519.9911 s
agent0:                 episode reward: -0.7176,                 loss: nan
agent1:                 episode reward: 0.7176,                 loss: 0.2570
Episode: 7471/10000 (74.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9596s / 520.9507 s
agent0:                 episode reward: 0.4125,                 loss: nan
agent1:                 episode reward: -0.4125,                 loss: 0.2216
Episode: 7481/10000 (74.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9104s / 521.8611 s
agent0:                 episode reward: 0.1174,                 loss: nan
agent1:                 episode reward: -0.1174,                 loss: 0.1903
Episode: 7491/10000 (74.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9357s / 522.7968 s
agent0:                 episode reward: -0.6120,                 loss: nan
agent1:                 episode reward: 0.6120,                 loss: 0.1900
Episode: 7501/10000 (75.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9144s / 523.7112 s
agent0:                 episode reward: -0.8876,                 loss: nan
agent1:                 episode reward: 0.8876,                 loss: 0.1891
Episode: 7511/10000 (75.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9269s / 524.6381 s
agent0:                 episode reward: -0.3356,                 loss: nan
agent1:                 episode reward: 0.3356,                 loss: 0.1877
Episode: 7521/10000 (75.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9211s / 525.5591 s
agent0:                 episode reward: -0.1899,                 loss: nan
agent1:                 episode reward: 0.1899,                 loss: 0.1898
Episode: 7531/10000 (75.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9299s / 526.4891 s
agent0:                 episode reward: -0.8984,                 loss: nan
agent1:                 episode reward: 0.8984,                 loss: 0.1868
Episode: 7541/10000 (75.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9251s / 527.4141 s
agent0:                 episode reward: -0.3481,                 loss: nan
agent1:                 episode reward: 0.3481,                 loss: 0.1873
Episode: 7551/10000 (75.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9341s / 528.3483 s
agent0:                 episode reward: -0.1457,                 loss: nan
agent1:                 episode reward: 0.1457,                 loss: 0.1858
Episode: 7561/10000 (75.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9256s / 529.2738 s
agent0:                 episode reward: -0.8936,                 loss: nan
agent1:                 episode reward: 0.8936,                 loss: 0.1867
Episode: 7571/10000 (75.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9291s / 530.2029 s
agent0:                 episode reward: -1.0888,                 loss: nan
agent1:                 episode reward: 1.0888,                 loss: 0.1785
Episode: 7581/10000 (75.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0045s / 531.2075 s
agent0:                 episode reward: -0.9846,                 loss: nan
agent1:                 episode reward: 0.9846,                 loss: 0.1685
Episode: 7591/10000 (75.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9216s / 532.1291 s
agent0:                 episode reward: -0.0217,                 loss: nan
agent1:                 episode reward: 0.0217,                 loss: 0.1675
Episode: 7601/10000 (76.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9299s / 533.0590 s
agent0:                 episode reward: -0.2107,                 loss: nan
agent1:                 episode reward: 0.2107,                 loss: 0.1667
Episode: 7611/10000 (76.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9263s / 533.9853 s
agent0:                 episode reward: -0.7359,                 loss: nan
agent1:                 episode reward: 0.7359,                 loss: 0.1666
Episode: 7621/10000 (76.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9310s / 534.9163 s
agent0:                 episode reward: -0.1435,                 loss: nan
agent1:                 episode reward: 0.1435,                 loss: 0.1668
Episode: 7631/10000 (76.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9235s / 535.8398 s
agent0:                 episode reward: -0.8186,                 loss: nan
agent1:                 episode reward: 0.8186,                 loss: 0.1664
Episode: 7641/10000 (76.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9314s / 536.7712 s
agent0:                 episode reward: 0.0739,                 loss: nan
agent1:                 episode reward: -0.0739,                 loss: 0.1649
Episode: 7651/10000 (76.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9238s / 537.6950 s
agent0:                 episode reward: -0.5781,                 loss: nan
agent1:                 episode reward: 0.5781,                 loss: 0.1645
Episode: 7661/10000 (76.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9221s / 538.6171 s
agent0:                 episode reward: 0.0752,                 loss: nan
agent1:                 episode reward: -0.0752,                 loss: 0.1650
Episode: 7671/10000 (76.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9495s / 539.5666 s
agent0:                 episode reward: -0.9855,                 loss: nan
agent1:                 episode reward: 0.9855,                 loss: 0.1873
Episode: 7681/10000 (76.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9345s / 540.5011 s
agent0:                 episode reward: -0.0924,                 loss: nan
agent1:                 episode reward: 0.0924,                 loss: 0.1939
Episode: 7691/10000 (76.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9674s / 541.4684 s
agent0:                 episode reward: -0.3808,                 loss: nan
agent1:                 episode reward: 0.3808,                 loss: 0.1909
Episode: 7701/10000 (77.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9256s / 542.3940 s
agent0:                 episode reward: -0.6292,                 loss: nan
agent1:                 episode reward: 0.6292,                 loss: 0.1912
Episode: 7711/10000 (77.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9405s / 543.3346 s
agent0:                 episode reward: -1.1818,                 loss: nan
agent1:                 episode reward: 1.1818,                 loss: 0.1907
Episode: 7721/10000 (77.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9374s / 544.2719 s
agent0:                 episode reward: 0.3205,                 loss: nan
agent1:                 episode reward: -0.3205,                 loss: 0.1906
Episode: 7731/10000 (77.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9369s / 545.2088 s
agent0:                 episode reward: -1.0219,                 loss: nan
agent1:                 episode reward: 1.0219,                 loss: 0.1907
Episode: 7741/10000 (77.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9344s / 546.1432 s
agent0:                 episode reward: -1.3195,                 loss: nan
agent1:                 episode reward: 1.3195,                 loss: 0.1900
Episode: 7751/10000 (77.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9311s / 547.0743 s
agent0:                 episode reward: 0.4587,                 loss: nan
agent1:                 episode reward: -0.4587,                 loss: 0.1896
Episode: 7761/10000 (77.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9528s / 548.0271 s
agent0:                 episode reward: -0.1353,                 loss: nan
agent1:                 episode reward: 0.1353,                 loss: 0.1911
Episode: 7771/10000 (77.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9471s / 548.9742 s
agent0:                 episode reward: -0.1804,                 loss: nan
agent1:                 episode reward: 0.1804,                 loss: 0.2309
Episode: 7781/10000 (77.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9231s / 549.8972 s
agent0:                 episode reward: 0.1313,                 loss: nan
agent1:                 episode reward: -0.1313,                 loss: 0.2437
Episode: 7791/10000 (77.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9600s / 550.8572 s
agent0:                 episode reward: -0.9841,                 loss: nan
agent1:                 episode reward: 0.9841,                 loss: 0.2382
Episode: 7801/10000 (78.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9381s / 551.7953 s
agent0:                 episode reward: -0.5906,                 loss: nan
agent1:                 episode reward: 0.5906,                 loss: 0.2383
Episode: 7811/10000 (78.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9411s / 552.7364 s
agent0:                 episode reward: -2.0066,                 loss: nan
agent1:                 episode reward: 2.0066,                 loss: 0.2374
Episode: 7821/10000 (78.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9355s / 553.6719 s
agent0:                 episode reward: -0.3396,                 loss: nan
agent1:                 episode reward: 0.3396,                 loss: 0.2368
Episode: 7831/10000 (78.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9591s / 554.6310 s
agent0:                 episode reward: -0.7164,                 loss: nan
agent1:                 episode reward: 0.7164,                 loss: 0.2367
Episode: 7841/10000 (78.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9771s / 555.6081 s
agent0:                 episode reward: -0.8209,                 loss: nan
agent1:                 episode reward: 0.8209,                 loss: 0.2355
Episode: 7851/10000 (78.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9589s / 556.5670 s
agent0:                 episode reward: -0.4917,                 loss: nan
agent1:                 episode reward: 0.4917,                 loss: 0.2364
Episode: 7861/10000 (78.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9425s / 557.5095 s
agent0:                 episode reward: -0.4315,                 loss: nan
agent1:                 episode reward: 0.4315,                 loss: 0.2377
Episode: 7871/10000 (78.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9442s / 558.4537 s
agent0:                 episode reward: -0.9825,                 loss: nan
agent1:                 episode reward: 0.9825,                 loss: 0.2821
Episode: 7881/10000 (78.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9519s / 559.4056 s
agent0:                 episode reward: -0.9775,                 loss: nan
agent1:                 episode reward: 0.9775,                 loss: 0.2959
Episode: 7891/10000 (78.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9487s / 560.3543 s
agent0:                 episode reward: -1.4206,                 loss: nan
agent1:                 episode reward: 1.4206,                 loss: 0.2940
Episode: 7901/10000 (79.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9965s / 561.3508 s
agent0:                 episode reward: 0.1581,                 loss: nan
agent1:                 episode reward: -0.1581,                 loss: 0.2965
Episode: 7911/10000 (79.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9433s / 562.2941 s
agent0:                 episode reward: -0.5162,                 loss: nan
agent1:                 episode reward: 0.5162,                 loss: 0.2921
Episode: 7921/10000 (79.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9675s / 563.2616 s
agent0:                 episode reward: -1.8037,                 loss: nan
agent1:                 episode reward: 1.8037,                 loss: 0.2965
Episode: 7931/10000 (79.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9619s / 564.2235 s
agent0:                 episode reward: -0.0792,                 loss: nan
agent1:                 episode reward: 0.0792,                 loss: 0.2931
Episode: 7941/10000 (79.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9523s / 565.1758 s
agent0:                 episode reward: -0.3175,                 loss: nan
agent1:                 episode reward: 0.3175,                 loss: 0.2927
Episode: 7951/10000 (79.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9621s / 566.1378 s
agent0:                 episode reward: -0.2476,                 loss: nan
agent1:                 episode reward: 0.2476,                 loss: 0.2926
Episode: 7961/10000 (79.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9781s / 567.1159 s
agent0:                 episode reward: -0.6288,                 loss: nan
agent1:                 episode reward: 0.6288,                 loss: 0.2908
Episode: 7971/10000 (79.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9415s / 568.0574 s
agent0:                 episode reward: 1.0221,                 loss: nan
agent1:                 episode reward: -1.0221,                 loss: 0.3107
Episode: 7981/10000 (79.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9643s / 569.0218 s
agent0:                 episode reward: -0.8558,                 loss: nan
agent1:                 episode reward: 0.8558,                 loss: 0.3051
Episode: 7991/10000 (79.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9805s / 570.0023 s
agent0:                 episode reward: -0.5155,                 loss: nan
agent1:                 episode reward: 0.5155,                 loss: 0.3067
Episode: 8001/10000 (80.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9463s / 570.9486 s
agent0:                 episode reward: -0.4229,                 loss: nan
agent1:                 episode reward: 0.4229,                 loss: 0.3081
Episode: 8011/10000 (80.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0310s / 571.9797 s
agent0:                 episode reward: -0.2097,                 loss: nan
agent1:                 episode reward: 0.2097,                 loss: 0.3057
Episode: 8021/10000 (80.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9879s / 572.9676 s
agent0:                 episode reward: -0.3659,                 loss: nan
agent1:                 episode reward: 0.3659,                 loss: 0.3073
Episode: 8031/10000 (80.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9590s / 573.9266 s
agent0:                 episode reward: -0.5598,                 loss: nan
agent1:                 episode reward: 0.5598,                 loss: 0.3053
Episode: 8041/10000 (80.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9528s / 574.8793 s
agent0:                 episode reward: -0.4685,                 loss: nan
agent1:                 episode reward: 0.4685,                 loss: 0.3046
Episode: 8051/10000 (80.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9610s / 575.8404 s
agent0:                 episode reward: -0.0986,                 loss: nan
agent1:                 episode reward: 0.0986,                 loss: 0.3035
Episode: 8061/10000 (80.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9737s / 576.8140 s
agent0:                 episode reward: 0.3235,                 loss: nan
agent1:                 episode reward: -0.3235,                 loss: 0.3043
Episode: 8071/10000 (80.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9671s / 577.7812 s
agent0:                 episode reward: -0.7805,                 loss: nan
agent1:                 episode reward: 0.7805,                 loss: 0.2978
Episode: 8081/10000 (80.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9703s / 578.7514 s
agent0:                 episode reward: -0.1914,                 loss: nan
agent1:                 episode reward: 0.1914,                 loss: 0.2857
Episode: 8091/10000 (80.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9753s / 579.7267 s
agent0:                 episode reward: 0.1838,                 loss: nan
agent1:                 episode reward: -0.1838,                 loss: 0.2887
Episode: 8101/10000 (81.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9567s / 580.6834 s
agent0:                 episode reward: -0.4515,                 loss: nan
agent1:                 episode reward: 0.4515,                 loss: 0.2850
Episode: 8111/10000 (81.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0124s / 581.6958 s
agent0:                 episode reward: -0.2935,                 loss: nan
agent1:                 episode reward: 0.2935,                 loss: 0.2862
Episode: 8121/10000 (81.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9719s / 582.6677 s
agent0:                 episode reward: -0.4359,                 loss: nan
agent1:                 episode reward: 0.4359,                 loss: 0.2868
Episode: 8131/10000 (81.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9558s / 583.6235 s
agent0:                 episode reward: -0.6994,                 loss: nan
agent1:                 episode reward: 0.6994,                 loss: 0.2854
Episode: 8141/10000 (81.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9672s / 584.5907 s
agent0:                 episode reward: -0.5001,                 loss: nan
agent1:                 episode reward: 0.5001,                 loss: 0.2878
Episode: 8151/10000 (81.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9583s / 585.5490 s
agent0:                 episode reward: 0.5698,                 loss: nan
agent1:                 episode reward: -0.5698,                 loss: 0.2827
Episode: 8161/10000 (81.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9749s / 586.5239 s
agent0:                 episode reward: 0.2466,                 loss: nan
agent1:                 episode reward: -0.2466,                 loss: 0.2851
Episode: 8171/10000 (81.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9549s / 587.4788 s
agent0:                 episode reward: 0.0910,                 loss: nan
agent1:                 episode reward: -0.0910,                 loss: 0.2958
Episode: 8181/10000 (81.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9651s / 588.4438 s
agent0:                 episode reward: -0.7644,                 loss: nan
agent1:                 episode reward: 0.7644,                 loss: 0.2891
Episode: 8191/10000 (81.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9789s / 589.4227 s
agent0:                 episode reward: -0.2065,                 loss: nan
agent1:                 episode reward: 0.2065,                 loss: 0.2822
Episode: 8201/10000 (82.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9617s / 590.3844 s
agent0:                 episode reward: -0.6971,                 loss: nan
agent1:                 episode reward: 0.6971,                 loss: 0.2808
Episode: 8211/10000 (82.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9901s / 591.3745 s
agent0:                 episode reward: 0.0284,                 loss: nan
agent1:                 episode reward: -0.0284,                 loss: 0.2840
Episode: 8221/10000 (82.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0057s / 592.3802 s
agent0:                 episode reward: -0.7209,                 loss: nan
agent1:                 episode reward: 0.7209,                 loss: 0.2846
Episode: 8231/10000 (82.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9837s / 593.3639 s
agent0:                 episode reward: -1.1045,                 loss: nan
agent1:                 episode reward: 1.1045,                 loss: 0.2830
Episode: 8241/10000 (82.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9837s / 594.3476 s
agent0:                 episode reward: -0.6687,                 loss: nan
agent1:                 episode reward: 0.6687,                 loss: 0.2827
Episode: 8251/10000 (82.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9559s / 595.3035 s
agent0:                 episode reward: -0.2753,                 loss: nan
agent1:                 episode reward: 0.2753,                 loss: 0.2830
Episode: 8261/10000 (82.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9816s / 596.2851 s
agent0:                 episode reward: -0.3914,                 loss: nan
agent1:                 episode reward: 0.3914,                 loss: 0.2818
Episode: 8271/10000 (82.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9929s / 597.2780 s
agent0:                 episode reward: -0.0350,                 loss: nan
agent1:                 episode reward: 0.0350,                 loss: 0.2939
Episode: 8281/10000 (82.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9730s / 598.2510 s
agent0:                 episode reward: -0.6622,                 loss: nan
agent1:                 episode reward: 0.6622,                 loss: 0.2847
Episode: 8291/10000 (82.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9771s / 599.2281 s
agent0:                 episode reward: 0.3230,                 loss: nan
agent1:                 episode reward: -0.3230,                 loss: 0.2826
Episode: 8301/10000 (83.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9806s / 600.2087 s
agent0:                 episode reward: -1.6395,                 loss: nan
agent1:                 episode reward: 1.6395,                 loss: 0.2816
Episode: 8311/10000 (83.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9741s / 601.1828 s
agent0:                 episode reward: -0.6580,                 loss: nan
agent1:                 episode reward: 0.6580,                 loss: 0.2801
Episode: 8321/10000 (83.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0283s / 602.2111 s
agent0:                 episode reward: -0.9001,                 loss: nan
agent1:                 episode reward: 0.9001,                 loss: 0.2810
Episode: 8331/10000 (83.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0085s / 603.2196 s
agent0:                 episode reward: 0.4923,                 loss: nan
agent1:                 episode reward: -0.4923,                 loss: 0.2768
Episode: 8341/10000 (83.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9679s / 604.1875 s
agent0:                 episode reward: -0.3803,                 loss: nan
agent1:                 episode reward: 0.3803,                 loss: 0.2785
Episode: 8351/10000 (83.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9517s / 605.1392 s
agent0:                 episode reward: -1.1267,                 loss: nan
agent1:                 episode reward: 1.1267,                 loss: 0.2805
Episode: 8361/10000 (83.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0048s / 606.1440 s
agent0:                 episode reward: -0.0386,                 loss: nan
agent1:                 episode reward: 0.0386,                 loss: 0.2803
Episode: 8371/10000 (83.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9859s / 607.1300 s
agent0:                 episode reward: 0.1426,                 loss: nan
agent1:                 episode reward: -0.1426,                 loss: 0.2423
Episode: 8381/10000 (83.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9737s / 608.1037 s
agent0:                 episode reward: -1.8377,                 loss: nan
agent1:                 episode reward: 1.8377,                 loss: 0.2126
Episode: 8391/10000 (83.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0042s / 609.1079 s
agent0:                 episode reward: -0.3006,                 loss: nan
agent1:                 episode reward: 0.3006,                 loss: 0.2105
Episode: 8401/10000 (84.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9863s / 610.0942 s
agent0:                 episode reward: -0.9509,                 loss: nan
agent1:                 episode reward: 0.9509,                 loss: 0.2101
Episode: 8411/10000 (84.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9820s / 611.0762 s
agent0:                 episode reward: -1.0991,                 loss: nan
agent1:                 episode reward: 1.0991,                 loss: 0.2084
Episode: 8421/10000 (84.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9825s / 612.0587 s
agent0:                 episode reward: -0.3533,                 loss: nan
agent1:                 episode reward: 0.3533,                 loss: 0.2100
Episode: 8431/10000 (84.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0312s / 613.0899 s
agent0:                 episode reward: -1.0432,                 loss: nan
agent1:                 episode reward: 1.0432,                 loss: 0.2071
Episode: 8441/10000 (84.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9983s / 614.0883 s
agent0:                 episode reward: -0.7110,                 loss: nan
agent1:                 episode reward: 0.7110,                 loss: 0.2093
Episode: 8451/10000 (84.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9881s / 615.0764 s
agent0:                 episode reward: -1.0806,                 loss: nan
agent1:                 episode reward: 1.0806,                 loss: 0.2073
Episode: 8461/10000 (84.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9838s / 616.0602 s
agent0:                 episode reward: -1.0096,                 loss: nan
agent1:                 episode reward: 1.0096,                 loss: 0.2050
Episode: 8471/10000 (84.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9856s / 617.0458 s
agent0:                 episode reward: -0.3382,                 loss: nan
agent1:                 episode reward: 0.3382,                 loss: 0.1809
Episode: 8481/10000 (84.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9804s / 618.0262 s
agent0:                 episode reward: -0.6819,                 loss: nan
agent1:                 episode reward: 0.6819,                 loss: 0.1578
Episode: 8491/10000 (84.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9944s / 619.0206 s
agent0:                 episode reward: 0.5464,                 loss: nan
agent1:                 episode reward: -0.5464,                 loss: 0.1565
Episode: 8501/10000 (85.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9864s / 620.0070 s
agent0:                 episode reward: -0.5759,                 loss: nan
agent1:                 episode reward: 0.5759,                 loss: 0.1591
Episode: 8511/10000 (85.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9923s / 620.9993 s
agent0:                 episode reward: -0.9153,                 loss: nan
agent1:                 episode reward: 0.9153,                 loss: 0.1585
Episode: 8521/10000 (85.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9898s / 621.9891 s
agent0:                 episode reward: -0.7177,                 loss: nan
agent1:                 episode reward: 0.7177,                 loss: 0.1611
Episode: 8531/10000 (85.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0360s / 623.0250 s
agent0:                 episode reward: -1.0294,                 loss: nan
agent1:                 episode reward: 1.0294,                 loss: 0.1586
Episode: 8541/10000 (85.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0035s / 624.0285 s
agent0:                 episode reward: -1.1728,                 loss: nan
agent1:                 episode reward: 1.1728,                 loss: 0.1580
Episode: 8551/10000 (85.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9851s / 625.0137 s
agent0:                 episode reward: -0.1045,                 loss: nan
agent1:                 episode reward: 0.1045,                 loss: 0.1570
Episode: 8561/10000 (85.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9889s / 626.0025 s
agent0:                 episode reward: -1.1994,                 loss: nan
agent1:                 episode reward: 1.1994,                 loss: 0.1593
Episode: 8571/10000 (85.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9954s / 626.9979 s
agent0:                 episode reward: -0.6958,                 loss: nan
agent1:                 episode reward: 0.6958,                 loss: 0.1658
Episode: 8581/10000 (85.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0029s / 628.0008 s
agent0:                 episode reward: 0.0317,                 loss: nan
agent1:                 episode reward: -0.0317,                 loss: 0.1592
Episode: 8591/10000 (85.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0042s / 629.0050 s
agent0:                 episode reward: -0.0617,                 loss: nan
agent1:                 episode reward: 0.0617,                 loss: 0.1580
Episode: 8601/10000 (86.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9817s / 629.9867 s
agent0:                 episode reward: -0.8903,                 loss: nan
agent1:                 episode reward: 0.8903,                 loss: 0.1590
Episode: 8611/10000 (86.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0022s / 630.9889 s
agent0:                 episode reward: -1.3292,                 loss: nan
agent1:                 episode reward: 1.3292,                 loss: 0.1561
Episode: 8621/10000 (86.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9882s / 631.9771 s
agent0:                 episode reward: -0.2158,                 loss: nan
agent1:                 episode reward: 0.2158,                 loss: 0.1572
Episode: 8631/10000 (86.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0480s / 633.0251 s
agent0:                 episode reward: 0.3347,                 loss: nan
agent1:                 episode reward: -0.3347,                 loss: 0.1570
Episode: 8641/10000 (86.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9963s / 634.0214 s
agent0:                 episode reward: -0.3320,                 loss: nan
agent1:                 episode reward: 0.3320,                 loss: 0.1560
Episode: 8651/10000 (86.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9848s / 635.0062 s
agent0:                 episode reward: -0.1418,                 loss: nan
agent1:                 episode reward: 0.1418,                 loss: 0.1555
Episode: 8661/10000 (86.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0055s / 636.0116 s
agent0:                 episode reward: -0.8582,                 loss: nan
agent1:                 episode reward: 0.8582,                 loss: 0.1558
Episode: 8671/10000 (86.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0135s / 637.0251 s
agent0:                 episode reward: 0.0460,                 loss: nan
agent1:                 episode reward: -0.0460,                 loss: 0.1950
Episode: 8681/10000 (86.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0032s / 638.0283 s
agent0:                 episode reward: -0.6092,                 loss: nan
agent1:                 episode reward: 0.6092,                 loss: 0.2020
Episode: 8691/10000 (86.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0273s / 639.0557 s
agent0:                 episode reward: -0.3515,                 loss: nan
agent1:                 episode reward: 0.3515,                 loss: 0.2025
Episode: 8701/10000 (87.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0012s / 640.0569 s
agent0:                 episode reward: -0.5593,                 loss: nan
agent1:                 episode reward: 0.5593,                 loss: 0.2004
Episode: 8711/10000 (87.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0182s / 641.0751 s
agent0:                 episode reward: 0.3280,                 loss: nan
agent1:                 episode reward: -0.3280,                 loss: 0.2012
Episode: 8721/10000 (87.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0107s / 642.0858 s
agent0:                 episode reward: -0.2106,                 loss: nan
agent1:                 episode reward: 0.2106,                 loss: 0.1998
Episode: 8731/10000 (87.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0828s / 643.1685 s
agent0:                 episode reward: -0.5370,                 loss: nan
agent1:                 episode reward: 0.5370,                 loss: 0.2000
Episode: 8741/10000 (87.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0224s / 644.1909 s
agent0:                 episode reward: -0.1271,                 loss: nan
agent1:                 episode reward: 0.1271,                 loss: 0.1999
Episode: 8751/10000 (87.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0160s / 645.2069 s
agent0:                 episode reward: -0.6573,                 loss: nan
agent1:                 episode reward: 0.6573,                 loss: 0.1991
Episode: 8761/10000 (87.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0182s / 646.2251 s
agent0:                 episode reward: 0.2123,                 loss: nan
agent1:                 episode reward: -0.2123,                 loss: 0.1998
Episode: 8771/10000 (87.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0388s / 647.2639 s
agent0:                 episode reward: -0.4527,                 loss: nan
agent1:                 episode reward: 0.4527,                 loss: 0.2451
Episode: 8781/10000 (87.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9952s / 648.2591 s
agent0:                 episode reward: -0.8496,                 loss: nan
agent1:                 episode reward: 0.8496,                 loss: 0.2596
Episode: 8791/10000 (87.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0003s / 649.2595 s
agent0:                 episode reward: -0.3619,                 loss: nan
agent1:                 episode reward: 0.3619,                 loss: 0.2577
Episode: 8801/10000 (88.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0374s / 650.2968 s
agent0:                 episode reward: -0.3066,                 loss: nan
agent1:                 episode reward: 0.3066,                 loss: 0.2561
Episode: 8811/10000 (88.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0140s / 651.3109 s
agent0:                 episode reward: -0.5185,                 loss: nan
agent1:                 episode reward: 0.5185,                 loss: 0.2589
Episode: 8821/10000 (88.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0228s / 652.3336 s
agent0:                 episode reward: 0.0257,                 loss: nan
agent1:                 episode reward: -0.0257,                 loss: 0.2568
Episode: 8831/10000 (88.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0778s / 653.4114 s
agent0:                 episode reward: -1.2320,                 loss: nan
agent1:                 episode reward: 1.2320,                 loss: 0.2586
Episode: 8841/10000 (88.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0427s / 654.4542 s
agent0:                 episode reward: -0.1621,                 loss: nan
agent1:                 episode reward: 0.1621,                 loss: 0.2556
Episode: 8851/10000 (88.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0783s / 655.5325 s
agent0:                 episode reward: -0.9811,                 loss: nan
agent1:                 episode reward: 0.9811,                 loss: 0.2571
Episode: 8861/10000 (88.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0244s / 656.5569 s
agent0:                 episode reward: 0.2908,                 loss: nan
agent1:                 episode reward: -0.2908,                 loss: 0.2577
Episode: 8871/10000 (88.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0351s / 657.5920 s
agent0:                 episode reward: -0.7071,                 loss: nan
agent1:                 episode reward: 0.7071,                 loss: 0.2882
Episode: 8881/10000 (88.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0303s / 658.6223 s
agent0:                 episode reward: -0.2822,                 loss: nan
agent1:                 episode reward: 0.2822,                 loss: 0.2919
Episode: 8891/10000 (88.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0307s / 659.6530 s
agent0:                 episode reward: -0.7456,                 loss: nan
agent1:                 episode reward: 0.7456,                 loss: 0.2886
Episode: 8901/10000 (89.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0033s / 660.6563 s
agent0:                 episode reward: 0.5819,                 loss: nan
agent1:                 episode reward: -0.5819,                 loss: 0.2890
Episode: 8911/10000 (89.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0308s / 661.6871 s
agent0:                 episode reward: -0.9188,                 loss: nan
agent1:                 episode reward: 0.9188,                 loss: 0.2868
Episode: 8921/10000 (89.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0396s / 662.7267 s
agent0:                 episode reward: -0.2380,                 loss: nan
agent1:                 episode reward: 0.2380,                 loss: 0.2889
Episode: 8931/10000 (89.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1176s / 663.8443 s
agent0:                 episode reward: -0.5495,                 loss: nan
agent1:                 episode reward: 0.5495,                 loss: 0.2854
Episode: 8941/10000 (89.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0311s / 664.8754 s
agent0:                 episode reward: -1.0270,                 loss: nan
agent1:                 episode reward: 1.0270,                 loss: 0.2896
Episode: 8951/10000 (89.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0160s / 665.8914 s
agent0:                 episode reward: -0.8078,                 loss: nan
agent1:                 episode reward: 0.8078,                 loss: 0.2872
Episode: 8961/10000 (89.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0248s / 666.9162 s
agent0:                 episode reward: -0.4186,                 loss: nan
agent1:                 episode reward: 0.4186,                 loss: 0.2883
Episode: 8971/10000 (89.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0363s / 667.9525 s
agent0:                 episode reward: -0.5270,                 loss: nan
agent1:                 episode reward: 0.5270,                 loss: 0.2833
Episode: 8981/10000 (89.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0212s / 668.9737 s
agent0:                 episode reward: -0.3182,                 loss: nan
agent1:                 episode reward: 0.3182,                 loss: 0.2672
Episode: 8991/10000 (89.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0711s / 670.0448 s
agent0:                 episode reward: -0.7992,                 loss: nan
agent1:                 episode reward: 0.7992,                 loss: 0.2676
Episode: 9001/10000 (90.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0138s / 671.0587 s
agent0:                 episode reward: -1.3108,                 loss: nan
agent1:                 episode reward: 1.3108,                 loss: 0.2684
Episode: 9011/10000 (90.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0403s / 672.0990 s
agent0:                 episode reward: -0.3220,                 loss: nan
agent1:                 episode reward: 0.3220,                 loss: 0.2648
Episode: 9021/10000 (90.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0250s / 673.1240 s
agent0:                 episode reward: -0.4337,                 loss: nan
agent1:                 episode reward: 0.4337,                 loss: 0.2655
Episode: 9031/10000 (90.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0668s / 674.1908 s
agent0:                 episode reward: 0.2270,                 loss: nan
agent1:                 episode reward: -0.2270,                 loss: 0.2658
Episode: 9041/10000 (90.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0208s / 675.2116 s
agent0:                 episode reward: -1.0109,                 loss: nan
agent1:                 episode reward: 1.0109,                 loss: 0.2667
Episode: 9051/10000 (90.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0220s / 676.2336 s
agent0:                 episode reward: -1.0973,                 loss: nan
agent1:                 episode reward: 1.0973,                 loss: 0.2662
Episode: 9061/10000 (90.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0141s / 677.2478 s
agent0:                 episode reward: -0.9469,                 loss: nan
agent1:                 episode reward: 0.9469,                 loss: 0.2649
Episode: 9071/10000 (90.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0459s / 678.2937 s
agent0:                 episode reward: -0.3361,                 loss: nan
agent1:                 episode reward: 0.3361,                 loss: 0.2685
Episode: 9081/10000 (90.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0141s / 679.3078 s
agent0:                 episode reward: -0.2941,                 loss: nan
agent1:                 episode reward: 0.2941,                 loss: 0.2590
Episode: 9091/10000 (90.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0728s / 680.3806 s
agent0:                 episode reward: -0.1051,                 loss: nan
agent1:                 episode reward: 0.1051,                 loss: 0.2573
Episode: 9101/10000 (91.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0366s / 681.4172 s
agent0:                 episode reward: -0.1349,                 loss: nan
agent1:                 episode reward: 0.1349,                 loss: 0.2591
Episode: 9111/10000 (91.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0544s / 682.4716 s
agent0:                 episode reward: -0.0631,                 loss: nan
agent1:                 episode reward: 0.0631,                 loss: 0.2550
Episode: 9121/10000 (91.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0267s / 683.4984 s
agent0:                 episode reward: -0.8214,                 loss: nan
agent1:                 episode reward: 0.8214,                 loss: 0.2572
Episode: 9131/10000 (91.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0771s / 684.5754 s
agent0:                 episode reward: -0.4859,                 loss: nan
agent1:                 episode reward: 0.4859,                 loss: 0.2554
Episode: 9141/10000 (91.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0279s / 685.6033 s
agent0:                 episode reward: -0.0120,                 loss: nan
agent1:                 episode reward: 0.0120,                 loss: 0.2558
Episode: 9151/10000 (91.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0442s / 686.6475 s
agent0:                 episode reward: -0.4723,                 loss: nan
agent1:                 episode reward: 0.4723,                 loss: 0.2539
Episode: 9161/10000 (91.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0469s / 687.6944 s
agent0:                 episode reward: -0.8956,                 loss: nan
agent1:                 episode reward: 0.8956,                 loss: 0.2559
Episode: 9171/10000 (91.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0388s / 688.7332 s
agent0:                 episode reward: 0.7038,                 loss: nan
agent1:                 episode reward: -0.7038,                 loss: 0.2761
Episode: 9181/10000 (91.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0372s / 689.7704 s
agent0:                 episode reward: -0.4010,                 loss: nan
agent1:                 episode reward: 0.4010,                 loss: 0.2705
Episode: 9191/10000 (91.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0533s / 690.8238 s
agent0:                 episode reward: -0.8743,                 loss: nan
agent1:                 episode reward: 0.8743,                 loss: 0.2697
Episode: 9201/10000 (92.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0479s / 691.8717 s
agent0:                 episode reward: -1.0209,                 loss: nan
agent1:                 episode reward: 1.0209,                 loss: 0.2664
Episode: 9211/10000 (92.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0445s / 692.9162 s
agent0:                 episode reward: 0.2150,                 loss: nan
agent1:                 episode reward: -0.2150,                 loss: 0.2639
Episode: 9221/10000 (92.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0581s / 693.9743 s
agent0:                 episode reward: -0.7483,                 loss: nan
agent1:                 episode reward: 0.7483,                 loss: 0.2659
Episode: 9231/10000 (92.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0975s / 695.0718 s
agent0:                 episode reward: -0.2736,                 loss: nan
agent1:                 episode reward: 0.2736,                 loss: 0.2661
Episode: 9241/10000 (92.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0602s / 696.1320 s
agent0:                 episode reward: -0.3442,                 loss: nan
agent1:                 episode reward: 0.3442,                 loss: 0.2659
Episode: 9251/10000 (92.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0418s / 697.1738 s
agent0:                 episode reward: -0.5048,                 loss: nan
agent1:                 episode reward: 0.5048,                 loss: 0.2653
Episode: 9261/10000 (92.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0774s / 698.2512 s
agent0:                 episode reward: -0.4324,                 loss: nan
agent1:                 episode reward: 0.4324,                 loss: 0.2653
Episode: 9271/10000 (92.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0458s / 699.2970 s
agent0:                 episode reward: -0.0882,                 loss: nan
agent1:                 episode reward: 0.0882,                 loss: 0.2491
Episode: 9281/10000 (92.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0683s / 700.3654 s
agent0:                 episode reward: -0.0623,                 loss: nan
agent1:                 episode reward: 0.0623,                 loss: 0.2231
Episode: 9291/10000 (92.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0549s / 701.4203 s
agent0:                 episode reward: -0.7581,                 loss: nan
agent1:                 episode reward: 0.7581,                 loss: 0.2224
Episode: 9301/10000 (93.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0543s / 702.4746 s
agent0:                 episode reward: -0.4903,                 loss: nan
agent1:                 episode reward: 0.4903,                 loss: 0.2199
Episode: 9311/10000 (93.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1056s / 703.5802 s
agent0:                 episode reward: -0.6518,                 loss: nan
agent1:                 episode reward: 0.6518,                 loss: 0.2201
Episode: 9321/10000 (93.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0877s / 704.6679 s
agent0:                 episode reward: -0.8616,                 loss: nan
agent1:                 episode reward: 0.8616,                 loss: 0.2206
Episode: 9331/10000 (93.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0729s / 705.7408 s
agent0:                 episode reward: -0.9777,                 loss: nan
agent1:                 episode reward: 0.9777,                 loss: 0.2191
Episode: 9341/10000 (93.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0445s / 706.7853 s
agent0:                 episode reward: -0.3045,                 loss: nan
agent1:                 episode reward: 0.3045,                 loss: 0.2183
Episode: 9351/10000 (93.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0731s / 707.8584 s
agent0:                 episode reward: 0.1693,                 loss: nan
agent1:                 episode reward: -0.1693,                 loss: 0.2176
Episode: 9361/10000 (93.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0631s / 708.9215 s
agent0:                 episode reward: 0.1029,                 loss: nan
agent1:                 episode reward: -0.1029,                 loss: 0.2185
Episode: 9371/10000 (93.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0543s / 709.9758 s
agent0:                 episode reward: 0.1592,                 loss: nan
agent1:                 episode reward: -0.1592,                 loss: 0.1931
Episode: 9381/10000 (93.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0537s / 711.0295 s
agent0:                 episode reward: 0.7666,                 loss: nan
agent1:                 episode reward: -0.7666,                 loss: 0.1655
Episode: 9391/10000 (93.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0687s / 712.0982 s
agent0:                 episode reward: -0.5935,                 loss: nan
agent1:                 episode reward: 0.5935,                 loss: 0.1629
Episode: 9401/10000 (94.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0532s / 713.1514 s
agent0:                 episode reward: 0.2665,                 loss: nan
agent1:                 episode reward: -0.2665,                 loss: 0.1616
Episode: 9411/10000 (94.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0606s / 714.2120 s
agent0:                 episode reward: -0.5883,                 loss: nan
agent1:                 episode reward: 0.5883,                 loss: 0.1634
Episode: 9421/10000 (94.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0807s / 715.2927 s
agent0:                 episode reward: -0.6721,                 loss: nan
agent1:                 episode reward: 0.6721,                 loss: 0.1628
Episode: 9431/10000 (94.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0572s / 716.3499 s
agent0:                 episode reward: -1.0272,                 loss: nan
agent1:                 episode reward: 1.0272,                 loss: 0.1609
Episode: 9441/10000 (94.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0561s / 717.4060 s
agent0:                 episode reward: 1.2583,                 loss: nan
agent1:                 episode reward: -1.2583,                 loss: 0.1599
Episode: 9451/10000 (94.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0790s / 718.4850 s
agent0:                 episode reward: -0.9617,                 loss: nan
agent1:                 episode reward: 0.9617,                 loss: 0.1609
Episode: 9461/10000 (94.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0543s / 719.5393 s
agent0:                 episode reward: 0.4321,                 loss: nan
agent1:                 episode reward: -0.4321,                 loss: 0.1621
Episode: 9471/10000 (94.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0724s / 720.6117 s
agent0:                 episode reward: -0.4805,                 loss: nan
agent1:                 episode reward: 0.4805,                 loss: 0.1606
Episode: 9481/10000 (94.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0878s / 721.6995 s
agent0:                 episode reward: -0.7076,                 loss: nan
agent1:                 episode reward: 0.7076,                 loss: 0.1510
Episode: 9491/10000 (94.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0808s / 722.7803 s
agent0:                 episode reward: -1.0310,                 loss: nan
agent1:                 episode reward: 1.0310,                 loss: 0.1503
Episode: 9501/10000 (95.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0540s / 723.8343 s
agent0:                 episode reward: -1.3957,                 loss: nan
agent1:                 episode reward: 1.3957,                 loss: 0.1515
Episode: 9511/10000 (95.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0496s / 724.8839 s
agent0:                 episode reward: -0.2300,                 loss: nan
agent1:                 episode reward: 0.2300,                 loss: 0.1506
Episode: 9521/10000 (95.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1080s / 725.9919 s
agent0:                 episode reward: -0.3751,                 loss: nan
agent1:                 episode reward: 0.3751,                 loss: 0.1489
Episode: 9531/10000 (95.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0691s / 727.0609 s
agent0:                 episode reward: -0.5203,                 loss: nan
agent1:                 episode reward: 0.5203,                 loss: 0.1516
Episode: 9541/10000 (95.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0808s / 728.1418 s
agent0:                 episode reward: -0.9333,                 loss: nan
agent1:                 episode reward: 0.9333,                 loss: 0.1491
Episode: 9551/10000 (95.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0689s / 729.2107 s
agent0:                 episode reward: -0.2091,                 loss: nan
agent1:                 episode reward: 0.2091,                 loss: 0.1501
Episode: 9561/10000 (95.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1079s / 730.3186 s
agent0:                 episode reward: -0.3978,                 loss: nan
agent1:                 episode reward: 0.3978,                 loss: 0.1507
Episode: 9571/10000 (95.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0778s / 731.3965 s
agent0:                 episode reward: -0.8940,                 loss: nan
agent1:                 episode reward: 0.8940,                 loss: 0.1809
Episode: 9581/10000 (95.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0645s / 732.4610 s
agent0:                 episode reward: -0.9775,                 loss: nan
agent1:                 episode reward: 0.9775,                 loss: 0.1860
Episode: 9591/10000 (95.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0694s / 733.5304 s
agent0:                 episode reward: -0.8257,                 loss: nan
agent1:                 episode reward: 0.8257,                 loss: 0.1867
Episode: 9601/10000 (96.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0978s / 734.6282 s
agent0:                 episode reward: -0.2321,                 loss: nan
agent1:                 episode reward: 0.2321,                 loss: 0.1855
Episode: 9611/10000 (96.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1052s / 735.7334 s
agent0:                 episode reward: -0.1162,                 loss: nan
agent1:                 episode reward: 0.1162,                 loss: 0.1860
Episode: 9621/10000 (96.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0768s / 736.8102 s
agent0:                 episode reward: -0.5103,                 loss: nan
agent1:                 episode reward: 0.5103,                 loss: 0.1850
Episode: 9631/10000 (96.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0648s / 737.8750 s
agent0:                 episode reward: -1.2781,                 loss: nan
agent1:                 episode reward: 1.2781,                 loss: 0.1830
Episode: 9641/10000 (96.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1232s / 738.9983 s
agent0:                 episode reward: -0.8530,                 loss: nan
agent1:                 episode reward: 0.8530,                 loss: 0.1852
Episode: 9651/10000 (96.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0776s / 740.0758 s
agent0:                 episode reward: -1.1598,                 loss: nan
agent1:                 episode reward: 1.1598,                 loss: 0.1852
Episode: 9661/10000 (96.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0792s / 741.1551 s
agent0:                 episode reward: -0.2083,                 loss: nan
agent1:                 episode reward: 0.2083,                 loss: 0.1835
Episode: 9671/10000 (96.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1272s / 742.2822 s
agent0:                 episode reward: -1.1155,                 loss: nan
agent1:                 episode reward: 1.1155,                 loss: 0.2222
Episode: 9681/10000 (96.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0776s / 743.3598 s
agent0:                 episode reward: 0.0784,                 loss: nan
agent1:                 episode reward: -0.0784,                 loss: 0.2334
Episode: 9691/10000 (96.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0758s / 744.4357 s
agent0:                 episode reward: -0.3595,                 loss: nan
agent1:                 episode reward: 0.3595,                 loss: 0.2295
Episode: 9701/10000 (97.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1315s / 745.5672 s
agent0:                 episode reward: -1.0850,                 loss: nan
agent1:                 episode reward: 1.0850,                 loss: 0.2306
Episode: 9711/10000 (97.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0814s / 746.6486 s
agent0:                 episode reward: -0.6999,                 loss: nan
agent1:                 episode reward: 0.6999,                 loss: 0.2291
Episode: 9721/10000 (97.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0950s / 747.7436 s
agent0:                 episode reward: -0.4557,                 loss: nan
agent1:                 episode reward: 0.4557,                 loss: 0.2294
Episode: 9731/10000 (97.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1032s / 748.8468 s
agent0:                 episode reward: -0.3285,                 loss: nan
agent1:                 episode reward: 0.3285,                 loss: 0.2291
Episode: 9741/10000 (97.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0819s / 749.9287 s
agent0:                 episode reward: 0.4672,                 loss: nan
agent1:                 episode reward: -0.4672,                 loss: 0.2289
Episode: 9751/10000 (97.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0851s / 751.0138 s
agent0:                 episode reward: -0.9003,                 loss: nan
agent1:                 episode reward: 0.9003,                 loss: 0.2286
Episode: 9761/10000 (97.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0710s / 752.0848 s
agent0:                 episode reward: -0.3454,                 loss: nan
agent1:                 episode reward: 0.3454,                 loss: 0.2295
Episode: 9771/10000 (97.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0834s / 753.1682 s
agent0:                 episode reward: -0.0418,                 loss: nan
agent1:                 episode reward: 0.0418,                 loss: 0.2732
Episode: 9781/10000 (97.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0871s / 754.2553 s
agent0:                 episode reward: -0.2477,                 loss: nan
agent1:                 episode reward: 0.2477,                 loss: 0.2838
Episode: 9791/10000 (97.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0813s / 755.3366 s
agent0:                 episode reward: -0.5818,                 loss: nan
agent1:                 episode reward: 0.5818,                 loss: 0.2839
Episode: 9801/10000 (98.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1266s / 756.4632 s
agent0:                 episode reward: -0.4985,                 loss: nan
agent1:                 episode reward: 0.4985,                 loss: 0.2842
Episode: 9811/10000 (98.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0918s / 757.5550 s
agent0:                 episode reward: -0.4084,                 loss: nan
agent1:                 episode reward: 0.4084,                 loss: 0.2826
Episode: 9821/10000 (98.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0919s / 758.6469 s
agent0:                 episode reward: -0.6864,                 loss: nan
agent1:                 episode reward: 0.6864,                 loss: 0.2788
Episode: 9831/10000 (98.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0943s / 759.7412 s
agent0:                 episode reward: 0.1416,                 loss: nan
agent1:                 episode reward: -0.1416,                 loss: 0.2813/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

Episode: 9841/10000 (98.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1140s / 760.8552 s
agent0:                 episode reward: -0.4181,                 loss: nan
agent1:                 episode reward: 0.4181,                 loss: 0.2803
Episode: 9851/10000 (98.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0754s / 761.9306 s
agent0:                 episode reward: -0.6357,                 loss: nan
agent1:                 episode reward: 0.6357,                 loss: 0.2804
Episode: 9861/10000 (98.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0844s / 763.0150 s
agent0:                 episode reward: -0.0725,                 loss: nan
agent1:                 episode reward: 0.0725,                 loss: 0.2795
Episode: 9871/10000 (98.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0979s / 764.1129 s
agent0:                 episode reward: -0.3415,                 loss: nan
agent1:                 episode reward: 0.3415,                 loss: 0.2947
Episode: 9881/10000 (98.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0844s / 765.1973 s
agent0:                 episode reward: 0.1020,                 loss: nan
agent1:                 episode reward: -0.1020,                 loss: 0.2860
Episode: 9891/10000 (98.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1347s / 766.3320 s
agent0:                 episode reward: -0.8142,                 loss: nan
agent1:                 episode reward: 0.8142,                 loss: 0.2878
Episode: 9901/10000 (99.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0870s / 767.4191 s
agent0:                 episode reward: 0.1325,                 loss: nan
agent1:                 episode reward: -0.1325,                 loss: 0.2839
Episode: 9911/10000 (99.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0913s / 768.5104 s
agent0:                 episode reward: -0.3140,                 loss: nan
agent1:                 episode reward: 0.3140,                 loss: 0.2849
Episode: 9921/10000 (99.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1023s / 769.6127 s
agent0:                 episode reward: -0.2527,                 loss: nan
agent1:                 episode reward: 0.2527,                 loss: 0.2840
Episode: 9931/10000 (99.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0820s / 770.6947 s
agent0:                 episode reward: -0.6496,                 loss: nan
agent1:                 episode reward: 0.6496,                 loss: 0.2834
Episode: 9941/10000 (99.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1101s / 771.8048 s
agent0:                 episode reward: 0.0066,                 loss: nan
agent1:                 episode reward: -0.0066,                 loss: 0.2872
Episode: 9951/10000 (99.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1065s / 772.9113 s
agent0:                 episode reward: 0.0449,                 loss: nan
agent1:                 episode reward: -0.0449,                 loss: 0.2841
Episode: 9961/10000 (99.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0898s / 774.0011 s
agent0:                 episode reward: -0.8830,                 loss: nan
agent1:                 episode reward: 0.8830,                 loss: 0.2817
Episode: 9971/10000 (99.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0956s / 775.0966 s
agent0:                 episode reward: -0.5628,                 loss: nan
agent1:                 episode reward: 0.5628,                 loss: 0.2800
Episode: 9981/10000 (99.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0954s / 776.1921 s
agent0:                 episode reward: -0.2960,                 loss: nan
agent1:                 episode reward: 0.2960,                 loss: 0.2692
Episode: 9991/10000 (99.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1538s / 777.3459 s
agent0:                 episode reward: -0.6845,                 loss: nan
agent1:                 episode reward: 0.6845,                 loss: 0.2675
