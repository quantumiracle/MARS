pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 42.0, (1,), float32) action space: Discrete(6)
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7fc0fde04e48>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
Error: no exploited model index given!
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  data/model/20220518032943/mdp_arbitrary_mdp_nfsp/40000_0
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': '1i', 'algorithm': 'NFSP', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.0, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 640, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 10000, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220518032943/mdp_arbitrary_mdp_nfsp/40000_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False, 'policy': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': 'Softmax'}}, 'marl_method': 'nfsp', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'eta': 0.1}, 'against_baseline': False}
Save models to : /home/zihan/research/MARS/data/model/20220518032943_exploit_40000/mdp_arbitrary_mdp_nfsp. 
 Save logs to: /home/zihan/research/MARS/data/log/20220518032943_exploit_40000/mdp_arbitrary_mdp_nfsp.
Episode: 1/30000 (0.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 7.4179s / 7.4179 s
agent0:                 episode reward: 0.4149,                 loss: nan
agent1:                 episode reward: -0.4149,                 loss: nan
Episode: 21/30000 (0.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3928s / 7.8106 s
agent0:                 episode reward: -0.2541,                 loss: nan
agent1:                 episode reward: 0.2541,                 loss: nan
Episode: 41/30000 (0.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3939s / 8.2046 s
agent0:                 episode reward: 0.0956,                 loss: nan
agent1:                 episode reward: -0.0956,                 loss: nan
Episode: 61/30000 (0.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3959s / 8.6004 s
agent0:                 episode reward: -0.0679,                 loss: nan
agent1:                 episode reward: 0.0679,                 loss: nan
Episode: 81/30000 (0.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3965s / 8.9969 s
agent0:                 episode reward: -0.0665,                 loss: nan
agent1:                 episode reward: 0.0665,                 loss: nan
Episode: 101/30000 (0.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3941s / 9.3910 s
agent0:                 episode reward: -0.2965,                 loss: nan
agent1:                 episode reward: 0.2965,                 loss: nan
Episode: 121/30000 (0.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3962s / 9.7872 s
agent0:                 episode reward: 0.1383,                 loss: nan
agent1:                 episode reward: -0.1383,                 loss: nan
Episode: 141/30000 (0.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.4027s / 10.1899 s
agent0:                 episode reward: 0.3301,                 loss: nan
agent1:                 episode reward: -0.3301,                 loss: nan
Episode: 161/30000 (0.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3976s / 10.5875 s
agent0:                 episode reward: -0.1425,                 loss: nan
agent1:                 episode reward: 0.1425,                 loss: nan
Episode: 181/30000 (0.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3961s / 10.9836 s
agent0:                 episode reward: 0.1801,                 loss: nan
agent1:                 episode reward: -0.1801,                 loss: nan
Episode: 201/30000 (0.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.4024s / 11.3859 s
agent0:                 episode reward: -0.1821,                 loss: nan
agent1:                 episode reward: 0.1821,                 loss: nan
Episode: 221/30000 (0.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.4036s / 11.7896 s
agent0:                 episode reward: 0.5437,                 loss: nan
agent1:                 episode reward: -0.5437,                 loss: nan
Episode: 241/30000 (0.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.4004s / 12.1900 s
agent0:                 episode reward: -0.0727,                 loss: nan
agent1:                 episode reward: 0.0727,                 loss: nan
Episode: 261/30000 (0.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3949s / 12.5849 s
agent0:                 episode reward: 0.1236,                 loss: nan
agent1:                 episode reward: -0.1236,                 loss: nan
Episode: 281/30000 (0.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3930s / 12.9780 s
agent0:                 episode reward: 0.0609,                 loss: nan
agent1:                 episode reward: -0.0609,                 loss: nan
Episode: 301/30000 (1.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3887s / 13.3666 s
agent0:                 episode reward: -0.1777,                 loss: nan
agent1:                 episode reward: 0.1777,                 loss: nan
Episode: 321/30000 (1.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3985s / 13.7652 s
agent0:                 episode reward: 0.0804,                 loss: nan
agent1:                 episode reward: -0.0804,                 loss: nan
Episode: 341/30000 (1.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3914s / 14.1566 s
agent0:                 episode reward: -0.5437,                 loss: nan
agent1:                 episode reward: 0.5437,                 loss: nan
Episode: 361/30000 (1.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3951s / 14.5517 s
agent0:                 episode reward: -0.1585,                 loss: nan
agent1:                 episode reward: 0.1585,                 loss: nan
Episode: 381/30000 (1.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3918s / 14.9435 s
agent0:                 episode reward: 0.5062,                 loss: nan
agent1:                 episode reward: -0.5062,                 loss: nan
Episode: 401/30000 (1.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3940s / 15.3375 s
agent0:                 episode reward: -0.3591,                 loss: nan
agent1:                 episode reward: 0.3591,                 loss: nan
Episode: 421/30000 (1.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3956s / 15.7331 s
agent0:                 episode reward: -0.2155,                 loss: nan
agent1:                 episode reward: 0.2155,                 loss: nan
Episode: 441/30000 (1.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3943s / 16.1274 s
agent0:                 episode reward: -0.6361,                 loss: nan
agent1:                 episode reward: 0.6361,                 loss: nan
Episode: 461/30000 (1.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3882s / 16.5156 s
agent0:                 episode reward: -0.1229,                 loss: nan
agent1:                 episode reward: 0.1229,                 loss: nan
Episode: 481/30000 (1.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3885s / 16.9041 s
agent0:                 episode reward: -0.5132,                 loss: nan
agent1:                 episode reward: 0.5132,                 loss: nan
Episode: 501/30000 (1.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3969s / 17.3010 s
agent0:                 episode reward: 0.5492,                 loss: nan
agent1:                 episode reward: -0.5492,                 loss: nan
Episode: 521/30000 (1.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3897s / 17.6908 s
agent0:                 episode reward: 0.2688,                 loss: nan
agent1:                 episode reward: -0.2688,                 loss: nan
Episode: 541/30000 (1.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3883s / 18.0790 s
agent0:                 episode reward: 0.1918,                 loss: nan
agent1:                 episode reward: -0.1918,                 loss: nan
Episode: 561/30000 (1.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3915s / 18.4705 s
agent0:                 episode reward: -0.0126,                 loss: nan
agent1:                 episode reward: 0.0126,                 loss: nan
Episode: 581/30000 (1.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3927s / 18.8632 s
agent0:                 episode reward: -0.1433,                 loss: nan
agent1:                 episode reward: 0.1433,                 loss: nan
Episode: 601/30000 (2.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3942s / 19.2574 s
agent0:                 episode reward: -0.1538,                 loss: nan
agent1:                 episode reward: 0.1538,                 loss: nan
Episode: 621/30000 (2.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3926s / 19.6500 s
agent0:                 episode reward: 0.1256,                 loss: nan
agent1:                 episode reward: -0.1256,                 loss: nan
Episode: 641/30000 (2.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3955s / 20.0455 s
agent0:                 episode reward: 0.1303,                 loss: nan
agent1:                 episode reward: -0.1303,                 loss: nan
Episode: 661/30000 (2.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3975s / 20.4430 s
agent0:                 episode reward: -0.0935,                 loss: nan
agent1:                 episode reward: 0.0935,                 loss: nan
Episode: 681/30000 (2.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3947s / 20.8377 s
agent0:                 episode reward: -0.0321,                 loss: nan
agent1:                 episode reward: 0.0321,                 loss: nan
Episode: 701/30000 (2.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3978s / 21.2355 s
agent0:                 episode reward: 0.2089,                 loss: nan
agent1:                 episode reward: -0.2089,                 loss: nan
Episode: 721/30000 (2.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3947s / 21.6302 s
agent0:                 episode reward: -0.1081,                 loss: nan
agent1:                 episode reward: 0.1081,                 loss: nan
Episode: 741/30000 (2.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.4005s / 22.0307 s
agent0:                 episode reward: -0.0969,                 loss: nan
agent1:                 episode reward: 0.0969,                 loss: nan
Episode: 761/30000 (2.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3936s / 22.4243 s
agent0:                 episode reward: -0.0064,                 loss: nan
agent1:                 episode reward: 0.0064,                 loss: nan
Episode: 781/30000 (2.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3907s / 22.8150 s
agent0:                 episode reward: -0.2621,                 loss: nan
agent1:                 episode reward: 0.2621,                 loss: nan
Episode: 801/30000 (2.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3936s / 23.2086 s
agent0:                 episode reward: -0.1923,                 loss: nan
agent1:                 episode reward: 0.1923,                 loss: nan
Episode: 821/30000 (2.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3944s / 23.6030 s
agent0:                 episode reward: 0.1860,                 loss: nan
agent1:                 episode reward: -0.1860,                 loss: nan
Episode: 841/30000 (2.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3845s / 23.9876 s
agent0:                 episode reward: 0.1900,                 loss: nan
agent1:                 episode reward: -0.1900,                 loss: nan
Episode: 861/30000 (2.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3923s / 24.3799 s
agent0:                 episode reward: 0.0380,                 loss: nan
agent1:                 episode reward: -0.0380,                 loss: nan
Episode: 881/30000 (2.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3888s / 24.7687 s
agent0:                 episode reward: -0.0774,                 loss: nan
agent1:                 episode reward: 0.0774,                 loss: nan
Episode: 901/30000 (3.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3853s / 25.1540 s
agent0:                 episode reward: -0.2736,                 loss: nan
agent1:                 episode reward: 0.2736,                 loss: nan
Episode: 921/30000 (3.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3889s / 25.5429 s
agent0:                 episode reward: -0.2268,                 loss: nan
agent1:                 episode reward: 0.2268,                 loss: nan
Episode: 941/30000 (3.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3942s / 25.9371 s
agent0:                 episode reward: -0.2013,                 loss: nan
agent1:                 episode reward: 0.2013,                 loss: nan
Episode: 961/30000 (3.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3938s / 26.3309 s
agent0:                 episode reward: 0.4172,                 loss: nan
agent1:                 episode reward: -0.4172,                 loss: nan
Episode: 981/30000 (3.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3888s / 26.7197 s
agent0:                 episode reward: 0.7249,                 loss: nan
agent1:                 episode reward: -0.7249,                 loss: nan
Episode: 1001/30000 (3.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3949s / 27.1146 s
agent0:                 episode reward: -0.4895,                 loss: nan
agent1:                 episode reward: 0.4895,                 loss: nan
Episode: 1021/30000 (3.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3849s / 27.4995 s
agent0:                 episode reward: -0.4783,                 loss: nan
agent1:                 episode reward: 0.4783,                 loss: nan
Episode: 1041/30000 (3.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3962s / 27.8957 s
agent0:                 episode reward: -0.0927,                 loss: nan
agent1:                 episode reward: 0.0927,                 loss: nan
Episode: 1061/30000 (3.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3955s / 28.2912 s
agent0:                 episode reward: 0.3380,                 loss: nan
agent1:                 episode reward: -0.3380,                 loss: nan
Episode: 1081/30000 (3.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3927s / 28.6839 s
agent0:                 episode reward: -0.3393,                 loss: nan
agent1:                 episode reward: 0.3393,                 loss: nan
Episode: 1101/30000 (3.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3921s / 29.0760 s
agent0:                 episode reward: 0.0730,                 loss: nan
agent1:                 episode reward: -0.0730,                 loss: nan
Episode: 1121/30000 (3.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3884s / 29.4644 s
agent0:                 episode reward: 0.3295,                 loss: nan
agent1:                 episode reward: -0.3295,                 loss: nan
Episode: 1141/30000 (3.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3870s / 29.8514 s
agent0:                 episode reward: 0.3760,                 loss: nan
agent1:                 episode reward: -0.3760,                 loss: nan
Episode: 1161/30000 (3.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3998s / 30.2513 s
agent0:                 episode reward: -0.0672,                 loss: nan
agent1:                 episode reward: 0.0672,                 loss: nan
Episode: 1181/30000 (3.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3939s / 30.6452 s
agent0:                 episode reward: -0.0230,                 loss: nan
agent1:                 episode reward: 0.0230,                 loss: nan
Episode: 1201/30000 (4.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3991s / 31.0443 s
agent0:                 episode reward: 0.2921,                 loss: nan
agent1:                 episode reward: -0.2921,                 loss: nan
Episode: 1221/30000 (4.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3997s / 31.4440 s
agent0:                 episode reward: -0.2940,                 loss: nan
agent1:                 episode reward: 0.2940,                 loss: nan
Episode: 1241/30000 (4.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3865s / 31.8305 s
agent0:                 episode reward: -0.3569,                 loss: nan
agent1:                 episode reward: 0.3569,                 loss: nan
Episode: 1261/30000 (4.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3973s / 32.2277 s
agent0:                 episode reward: -0.0574,                 loss: nan
agent1:                 episode reward: 0.0574,                 loss: nan
Episode: 1281/30000 (4.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3907s / 32.6184 s
agent0:                 episode reward: 0.1104,                 loss: nan
agent1:                 episode reward: -0.1104,                 loss: nan
Episode: 1301/30000 (4.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3923s / 33.0107 s
agent0:                 episode reward: -0.1598,                 loss: nan
agent1:                 episode reward: 0.1598,                 loss: nan
Episode: 1321/30000 (4.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3934s / 33.4041 s
agent0:                 episode reward: 0.1844,                 loss: nan
agent1:                 episode reward: -0.1844,                 loss: nan
Episode: 1341/30000 (4.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3948s / 33.7990 s
agent0:                 episode reward: 0.0960,                 loss: nan
agent1:                 episode reward: -0.0960,                 loss: nan
Episode: 1361/30000 (4.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3984s / 34.1974 s
agent0:                 episode reward: 0.5446,                 loss: nan
agent1:                 episode reward: -0.5446,                 loss: nan
Episode: 1381/30000 (4.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3901s / 34.5874 s
agent0:                 episode reward: -0.0678,                 loss: nan
agent1:                 episode reward: 0.0678,                 loss: nan
Episode: 1401/30000 (4.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3882s / 34.9756 s
agent0:                 episode reward: 0.0318,                 loss: nan
agent1:                 episode reward: -0.0318,                 loss: nan
Episode: 1421/30000 (4.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3928s / 35.3684 s
agent0:                 episode reward: -0.0490,                 loss: nan
agent1:                 episode reward: 0.0490,                 loss: nan
Episode: 1441/30000 (4.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3958s / 35.7642 s
agent0:                 episode reward: -0.0788,                 loss: nan
agent1:                 episode reward: 0.0788,                 loss: nan
Episode: 1461/30000 (4.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3965s / 36.1607 s
agent0:                 episode reward: 0.0486,                 loss: nan
agent1:                 episode reward: -0.0486,                 loss: nan
Episode: 1481/30000 (4.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3979s / 36.5586 s
agent0:                 episode reward: 0.2167,                 loss: nan
agent1:                 episode reward: -0.2167,                 loss: nan
Episode: 1501/30000 (5.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3955s / 36.9541 s
agent0:                 episode reward: -0.0695,                 loss: nan
agent1:                 episode reward: 0.0695,                 loss: nan
Episode: 1521/30000 (5.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.4045s / 37.3587 s
agent0:                 episode reward: -0.6170,                 loss: nan
agent1:                 episode reward: 0.6170,                 loss: nan
Episode: 1541/30000 (5.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3738s / 37.7324 s
agent0:                 episode reward: -0.4572,                 loss: nan
agent1:                 episode reward: 0.4572,                 loss: nan
Episode: 1561/30000 (5.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3916s / 38.1240 s
agent0:                 episode reward: -0.5868,                 loss: nan
agent1:                 episode reward: 0.5868,                 loss: nan
Episode: 1581/30000 (5.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3951s / 38.5191 s
agent0:                 episode reward: 0.1519,                 loss: nan
agent1:                 episode reward: -0.1519,                 loss: nan
Episode: 1601/30000 (5.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3949s / 38.9141 s
agent0:                 episode reward: 0.1588,                 loss: nan
agent1:                 episode reward: -0.1588,                 loss: nan
Episode: 1621/30000 (5.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3851s / 39.2992 s
agent0:                 episode reward: -0.3752,                 loss: nan
agent1:                 episode reward: 0.3752,                 loss: nan
Episode: 1641/30000 (5.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3935s / 39.6927 s
agent0:                 episode reward: 0.1393,                 loss: nan
agent1:                 episode reward: -0.1393,                 loss: nan
Episode: 1661/30000 (5.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3640s / 40.0567 s
agent0:                 episode reward: -0.5926,                 loss: nan
agent1:                 episode reward: 0.5926,                 loss: nan
Episode: 1681/30000 (5.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 2.0804s / 42.1370 s
agent0:                 episode reward: 0.3547,                 loss: nan
agent1:                 episode reward: -0.3547,                 loss: 0.4513
Episode: 1701/30000 (5.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1524s / 43.2894 s
agent0:                 episode reward: -0.3909,                 loss: nan
agent1:                 episode reward: 0.3909,                 loss: 0.4151
Episode: 1721/30000 (5.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1610s / 44.4504 s
agent0:                 episode reward: 0.0416,                 loss: nan
agent1:                 episode reward: -0.0416,                 loss: 0.4047
Episode: 1741/30000 (5.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1378s / 45.5882 s
agent0:                 episode reward: 0.0975,                 loss: nan
agent1:                 episode reward: -0.0975,                 loss: 0.3954
Episode: 1761/30000 (5.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1421s / 46.7303 s
agent0:                 episode reward: -0.7120,                 loss: nan
agent1:                 episode reward: 0.7120,                 loss: 0.3813
Episode: 1781/30000 (5.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1419s / 47.8722 s
agent0:                 episode reward: -0.4491,                 loss: nan
agent1:                 episode reward: 0.4491,                 loss: 0.3605
Episode: 1801/30000 (6.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1414s / 49.0136 s
agent0:                 episode reward: -0.0166,                 loss: nan
agent1:                 episode reward: 0.0166,                 loss: 0.3415
Episode: 1821/30000 (6.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1456s / 50.1593 s
agent0:                 episode reward: -0.0323,                 loss: nan
agent1:                 episode reward: 0.0323,                 loss: 0.3238
Episode: 1841/30000 (6.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1462s / 51.3055 s
agent0:                 episode reward: -0.6755,                 loss: nan
agent1:                 episode reward: 0.6755,                 loss: 0.3610
Episode: 1861/30000 (6.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1544s / 52.4599 s
agent0:                 episode reward: -0.0890,                 loss: nan
agent1:                 episode reward: 0.0890,                 loss: 0.4167
Episode: 1881/30000 (6.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1425s / 53.6024 s
agent0:                 episode reward: 0.1594,                 loss: nan
agent1:                 episode reward: -0.1594,                 loss: 0.4143
Episode: 1901/30000 (6.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1361s / 54.7386 s
agent0:                 episode reward: 0.2238,                 loss: nan
agent1:                 episode reward: -0.2238,                 loss: 0.4117
Episode: 1921/30000 (6.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1476s / 55.8862 s
agent0:                 episode reward: 0.7814,                 loss: nan
agent1:                 episode reward: -0.7814,                 loss: 0.4102
Episode: 1941/30000 (6.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1461s / 57.0322 s
agent0:                 episode reward: 0.0037,                 loss: nan
agent1:                 episode reward: -0.0037,                 loss: 0.4096
Episode: 1961/30000 (6.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1360s / 58.1682 s
agent0:                 episode reward: -0.2218,                 loss: nan
agent1:                 episode reward: 0.2218,                 loss: 0.4098
Episode: 1981/30000 (6.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1444s / 59.3126 s
agent0:                 episode reward: 0.0846,                 loss: nan
agent1:                 episode reward: -0.0846,                 loss: 0.4084
Episode: 2001/30000 (6.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1566s / 60.4693 s
agent0:                 episode reward: -0.0670,                 loss: nan
agent1:                 episode reward: 0.0670,                 loss: 0.4102
Episode: 2021/30000 (6.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1608s / 61.6300 s
agent0:                 episode reward: -0.0068,                 loss: nan
agent1:                 episode reward: 0.0068,                 loss: 0.4392
Episode: 2041/30000 (6.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1517s / 62.7817 s
agent0:                 episode reward: 0.4765,                 loss: nan
agent1:                 episode reward: -0.4765,                 loss: 0.4278
Episode: 2061/30000 (6.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1464s / 63.9281 s
agent0:                 episode reward: 0.3321,                 loss: nan
agent1:                 episode reward: -0.3321,                 loss: 0.4236
Episode: 2081/30000 (6.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1468s / 65.0749 s
agent0:                 episode reward: 0.0676,                 loss: nan
agent1:                 episode reward: -0.0676,                 loss: 0.4225
Episode: 2101/30000 (7.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1611s / 66.2359 s
agent0:                 episode reward: 0.3543,                 loss: nan
agent1:                 episode reward: -0.3543,                 loss: 0.4221
Episode: 2121/30000 (7.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1644s / 67.4004 s
agent0:                 episode reward: 0.1959,                 loss: nan
agent1:                 episode reward: -0.1959,                 loss: 0.4201
Episode: 2141/30000 (7.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1502s / 68.5505 s
agent0:                 episode reward: -0.2881,                 loss: nan
agent1:                 episode reward: 0.2881,                 loss: 0.4180
Episode: 2161/30000 (7.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1510s / 69.7015 s
agent0:                 episode reward: -0.0458,                 loss: nan
agent1:                 episode reward: 0.0458,                 loss: 0.4179
Episode: 2181/30000 (7.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1527s / 70.8542 s
agent0:                 episode reward: 0.0122,                 loss: nan
agent1:                 episode reward: -0.0122,                 loss: 0.4199
Episode: 2201/30000 (7.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1641s / 72.0183 s
agent0:                 episode reward: -0.3469,                 loss: nan
agent1:                 episode reward: 0.3469,                 loss: 0.4161
Episode: 2221/30000 (7.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1386s / 73.1569 s
agent0:                 episode reward: 0.0857,                 loss: nan
agent1:                 episode reward: -0.0857,                 loss: 0.4154
Episode: 2241/30000 (7.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1543s / 74.3112 s
agent0:                 episode reward: 0.1049,                 loss: nan
agent1:                 episode reward: -0.1049,                 loss: 0.4158
Episode: 2261/30000 (7.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1597s / 75.4708 s
agent0:                 episode reward: -0.4081,                 loss: nan
agent1:                 episode reward: 0.4081,                 loss: 0.4175
Episode: 2281/30000 (7.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1447s / 76.6155 s
agent0:                 episode reward: -0.0528,                 loss: nan
agent1:                 episode reward: 0.0528,                 loss: 0.4164
Episode: 2301/30000 (7.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1465s / 77.7621 s
agent0:                 episode reward: 0.0971,                 loss: nan
agent1:                 episode reward: -0.0971,                 loss: 0.4143
Episode: 2321/30000 (7.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1575s / 78.9195 s
agent0:                 episode reward: 0.0673,                 loss: nan
agent1:                 episode reward: -0.0673,                 loss: 0.4141
Episode: 2341/30000 (7.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1601s / 80.0796 s
agent0:                 episode reward: 0.0461,                 loss: nan
agent1:                 episode reward: -0.0461,                 loss: 0.4212
Episode: 2361/30000 (7.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1523s / 81.2319 s
agent0:                 episode reward: -0.4123,                 loss: nan
agent1:                 episode reward: 0.4123,                 loss: 0.4289
Episode: 2381/30000 (7.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1629s / 82.3948 s
agent0:                 episode reward: 0.4545,                 loss: nan
agent1:                 episode reward: -0.4545,                 loss: 0.4269
Episode: 2401/30000 (8.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1562s / 83.5510 s
agent0:                 episode reward: 0.1034,                 loss: nan
agent1:                 episode reward: -0.1034,                 loss: 0.4292
Episode: 2421/30000 (8.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1592s / 84.7102 s
agent0:                 episode reward: -0.1547,                 loss: nan
agent1:                 episode reward: 0.1547,                 loss: 0.4267
Episode: 2441/30000 (8.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1540s / 85.8642 s
agent0:                 episode reward: -0.4608,                 loss: nan
agent1:                 episode reward: 0.4608,                 loss: 0.4251
Episode: 2461/30000 (8.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1602s / 87.0244 s
agent0:                 episode reward: -0.1133,                 loss: nan
agent1:                 episode reward: 0.1133,                 loss: 0.4265
Episode: 2481/30000 (8.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1516s / 88.1760 s
agent0:                 episode reward: -0.1964,                 loss: nan
agent1:                 episode reward: 0.1964,                 loss: 0.4261
Episode: 2501/30000 (8.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1615s / 89.3374 s
agent0:                 episode reward: -0.5837,                 loss: nan
agent1:                 episode reward: 0.5837,                 loss: 0.4266
Episode: 2521/30000 (8.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1571s / 90.4945 s
agent0:                 episode reward: -0.1415,                 loss: nan
agent1:                 episode reward: 0.1415,                 loss: 0.4244
Episode: 2541/30000 (8.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1484s / 91.6430 s
agent0:                 episode reward: 0.3530,                 loss: nan
agent1:                 episode reward: -0.3530,                 loss: 0.4219
Episode: 2561/30000 (8.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1660s / 92.8090 s
agent0:                 episode reward: -0.0388,                 loss: nan
agent1:                 episode reward: 0.0388,                 loss: 0.4220
Episode: 2581/30000 (8.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1676s / 93.9766 s
agent0:                 episode reward: 0.0797,                 loss: nan
agent1:                 episode reward: -0.0797,                 loss: 0.4209
Episode: 2601/30000 (8.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1524s / 95.1290 s
agent0:                 episode reward: -0.1860,                 loss: nan
agent1:                 episode reward: 0.1860,                 loss: 0.4223
Episode: 2621/30000 (8.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1562s / 96.2853 s
agent0:                 episode reward: -0.1092,                 loss: nan
agent1:                 episode reward: 0.1092,                 loss: 0.4208
Episode: 2641/30000 (8.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1655s / 97.4507 s
agent0:                 episode reward: 0.7560,                 loss: nan
agent1:                 episode reward: -0.7560,                 loss: 0.4201
Episode: 2661/30000 (8.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1648s / 98.6155 s
agent0:                 episode reward: -0.0677,                 loss: nan
agent1:                 episode reward: 0.0677,                 loss: 0.4206
Episode: 2681/30000 (8.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1538s / 99.7693 s
agent0:                 episode reward: 0.1136,                 loss: nan
agent1:                 episode reward: -0.1136,                 loss: 0.4141
Episode: 2701/30000 (9.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1547s / 100.9240 s
agent0:                 episode reward: -0.1372,                 loss: nan
agent1:                 episode reward: 0.1372,                 loss: 0.4080
Episode: 2721/30000 (9.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1592s / 102.0832 s
agent0:                 episode reward: 0.0008,                 loss: nan
agent1:                 episode reward: -0.0008,                 loss: 0.4073
Episode: 2741/30000 (9.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1521s / 103.2354 s
agent0:                 episode reward: -0.0681,                 loss: nan
agent1:                 episode reward: 0.0681,                 loss: 0.4046
Episode: 2761/30000 (9.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1609s / 104.3962 s
agent0:                 episode reward: 0.2685,                 loss: nan
agent1:                 episode reward: -0.2685,                 loss: 0.4066
Episode: 2781/30000 (9.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1655s / 105.5618 s
agent0:                 episode reward: 0.5358,                 loss: nan
agent1:                 episode reward: -0.5358,                 loss: 0.4036
Episode: 2801/30000 (9.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1627s / 106.7245 s
agent0:                 episode reward: -0.3162,                 loss: nan
agent1:                 episode reward: 0.3162,                 loss: 0.4037
Episode: 2821/30000 (9.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1567s / 107.8811 s
agent0:                 episode reward: 0.1606,                 loss: nan
agent1:                 episode reward: -0.1606,                 loss: 0.4045
Episode: 2841/30000 (9.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1477s / 109.0288 s
agent0:                 episode reward: 0.0274,                 loss: nan
agent1:                 episode reward: -0.0274,                 loss: 0.4093
Episode: 2861/30000 (9.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1621s / 110.1909 s
agent0:                 episode reward: -0.4939,                 loss: nan
agent1:                 episode reward: 0.4939,                 loss: 0.4156
Episode: 2881/30000 (9.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1648s / 111.3558 s
agent0:                 episode reward: -0.0825,                 loss: nan
agent1:                 episode reward: 0.0825,                 loss: 0.4159
Episode: 2901/30000 (9.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1642s / 112.5200 s
agent0:                 episode reward: -0.2406,                 loss: nan
agent1:                 episode reward: 0.2406,                 loss: 0.4170
Episode: 2921/30000 (9.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1713s / 113.6913 s
agent0:                 episode reward: -0.1311,                 loss: nan
agent1:                 episode reward: 0.1311,                 loss: 0.4155
Episode: 2941/30000 (9.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1671s / 114.8584 s
agent0:                 episode reward: -0.4250,                 loss: nan
agent1:                 episode reward: 0.4250,                 loss: 0.4150
Episode: 2961/30000 (9.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1681s / 116.0265 s
agent0:                 episode reward: -0.0378,                 loss: nan
agent1:                 episode reward: 0.0378,                 loss: 0.4151
Episode: 2981/30000 (9.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1720s / 117.1985 s
agent0:                 episode reward: 0.2200,                 loss: nan
agent1:                 episode reward: -0.2200,                 loss: 0.4152
Episode: 3001/30000 (10.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1614s / 118.3599 s
agent0:                 episode reward: -0.2326,                 loss: nan
agent1:                 episode reward: 0.2326,                 loss: 0.4172
Episode: 3021/30000 (10.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1675s / 119.5274 s
agent0:                 episode reward: 0.0580,                 loss: nan
agent1:                 episode reward: -0.0580,                 loss: 0.4460
Episode: 3041/30000 (10.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1690s / 120.6964 s
agent0:                 episode reward: 0.0463,                 loss: nan
agent1:                 episode reward: -0.0463,                 loss: 0.4444
Episode: 3061/30000 (10.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1619s / 121.8584 s
agent0:                 episode reward: -0.2624,                 loss: nan
agent1:                 episode reward: 0.2624,                 loss: 0.4453
Episode: 3081/30000 (10.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1538s / 123.0122 s
agent0:                 episode reward: -0.4069,                 loss: nan
agent1:                 episode reward: 0.4069,                 loss: 0.4442
Episode: 3101/30000 (10.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1631s / 124.1753 s
agent0:                 episode reward: -0.2169,                 loss: nan
agent1:                 episode reward: 0.2169,                 loss: 0.4443
Episode: 3121/30000 (10.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1596s / 125.3349 s
agent0:                 episode reward: -0.4975,                 loss: nan
agent1:                 episode reward: 0.4975,                 loss: 0.4430
Episode: 3141/30000 (10.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1681s / 126.5030 s
agent0:                 episode reward: 0.2273,                 loss: nan
agent1:                 episode reward: -0.2273,                 loss: 0.4446
Episode: 3161/30000 (10.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1678s / 127.6708 s
agent0:                 episode reward: 0.0324,                 loss: nan
agent1:                 episode reward: -0.0324,                 loss: 0.4437
Episode: 3181/30000 (10.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1661s / 128.8369 s
agent0:                 episode reward: -0.4702,                 loss: nan
agent1:                 episode reward: 0.4702,                 loss: 0.4371
Episode: 3201/30000 (10.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1586s / 129.9955 s
agent0:                 episode reward: -0.1198,                 loss: nan
agent1:                 episode reward: 0.1198,                 loss: 0.4307
Episode: 3221/30000 (10.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1678s / 131.1633 s
agent0:                 episode reward: -0.3792,                 loss: nan
agent1:                 episode reward: 0.3792,                 loss: 0.4305
Episode: 3241/30000 (10.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1653s / 132.3286 s
agent0:                 episode reward: 0.0248,                 loss: nan
agent1:                 episode reward: -0.0248,                 loss: 0.4304
Episode: 3261/30000 (10.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1705s / 133.4991 s
agent0:                 episode reward: 0.0240,                 loss: nan
agent1:                 episode reward: -0.0240,                 loss: 0.4297
Episode: 3281/30000 (10.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1577s / 134.6569 s
agent0:                 episode reward: -0.3577,                 loss: nan
agent1:                 episode reward: 0.3577,                 loss: 0.4291
Episode: 3301/30000 (11.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1635s / 135.8204 s
agent0:                 episode reward: -0.0628,                 loss: nan
agent1:                 episode reward: 0.0628,                 loss: 0.4280
Episode: 3321/30000 (11.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1694s / 136.9898 s
agent0:                 episode reward: -0.5017,                 loss: nan
agent1:                 episode reward: 0.5017,                 loss: 0.4286
Episode: 3341/30000 (11.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1787s / 138.1685 s
agent0:                 episode reward: 0.3396,                 loss: nan
agent1:                 episode reward: -0.3396,                 loss: 0.4302
Episode: 3361/30000 (11.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1694s / 139.3378 s
agent0:                 episode reward: 0.0609,                 loss: nan
agent1:                 episode reward: -0.0609,                 loss: 0.4293
Episode: 3381/30000 (11.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1689s / 140.5067 s
agent0:                 episode reward: 0.4495,                 loss: nan
agent1:                 episode reward: -0.4495,                 loss: 0.4284
Episode: 3401/30000 (11.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1720s / 141.6787 s
agent0:                 episode reward: -0.1270,                 loss: nan
agent1:                 episode reward: 0.1270,                 loss: 0.4285
Episode: 3421/30000 (11.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1626s / 142.8412 s
agent0:                 episode reward: -0.3832,                 loss: nan
agent1:                 episode reward: 0.3832,                 loss: 0.4282
Episode: 3441/30000 (11.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1659s / 144.0071 s
agent0:                 episode reward: -0.2109,                 loss: nan
agent1:                 episode reward: 0.2109,                 loss: 0.4285
Episode: 3461/30000 (11.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1572s / 145.1643 s
agent0:                 episode reward: 0.1975,                 loss: nan
agent1:                 episode reward: -0.1975,                 loss: 0.4270
Episode: 3481/30000 (11.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1762s / 146.3405 s
agent0:                 episode reward: -0.1513,                 loss: nan
agent1:                 episode reward: 0.1513,                 loss: 0.4269
Episode: 3501/30000 (11.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1744s / 147.5150 s
agent0:                 episode reward: -0.2120,                 loss: nan
agent1:                 episode reward: 0.2120,                 loss: 0.4292
Episode: 3521/30000 (11.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1651s / 148.6800 s
agent0:                 episode reward: -0.1014,                 loss: nan
agent1:                 episode reward: 0.1014,                 loss: 0.4256
Episode: 3541/30000 (11.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1637s / 149.8437 s
agent0:                 episode reward: 0.1055,                 loss: nan
agent1:                 episode reward: -0.1055,                 loss: 0.4245
Episode: 3561/30000 (11.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1659s / 151.0096 s
agent0:                 episode reward: -0.2966,                 loss: nan
agent1:                 episode reward: 0.2966,                 loss: 0.4245
Episode: 3581/30000 (11.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1579s / 152.1675 s
agent0:                 episode reward: -0.2797,                 loss: nan
agent1:                 episode reward: 0.2797,                 loss: 0.4232
Episode: 3601/30000 (12.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1752s / 153.3427 s
agent0:                 episode reward: -0.0726,                 loss: nan
agent1:                 episode reward: 0.0726,                 loss: 0.4240
Episode: 3621/30000 (12.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1690s / 154.5117 s
agent0:                 episode reward: 0.1406,                 loss: nan
agent1:                 episode reward: -0.1406,                 loss: 0.4234
Episode: 3641/30000 (12.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1738s / 155.6855 s
agent0:                 episode reward: -0.5640,                 loss: nan
agent1:                 episode reward: 0.5640,                 loss: 0.4230
Episode: 3661/30000 (12.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1801s / 156.8655 s
agent0:                 episode reward: -0.2996,                 loss: nan
agent1:                 episode reward: 0.2996,                 loss: 0.4230
Episode: 3681/30000 (12.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1771s / 158.0426 s
agent0:                 episode reward: -0.4901,                 loss: nan
agent1:                 episode reward: 0.4901,                 loss: 0.4243
Episode: 3701/30000 (12.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1852s / 159.2279 s
agent0:                 episode reward: -0.6625,                 loss: nan
agent1:                 episode reward: 0.6625,                 loss: 0.4219
Episode: 3721/30000 (12.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1708s / 160.3986 s
agent0:                 episode reward: -0.0049,                 loss: nan
agent1:                 episode reward: 0.0049,                 loss: 0.4209
Episode: 3741/30000 (12.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1711s / 161.5698 s
agent0:                 episode reward: -0.3491,                 loss: nan
agent1:                 episode reward: 0.3491,                 loss: 0.4216
Episode: 3761/30000 (12.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1664s / 162.7362 s
agent0:                 episode reward: -0.0786,                 loss: nan
agent1:                 episode reward: 0.0786,                 loss: 0.4205
Episode: 3781/30000 (12.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1688s / 163.9050 s
agent0:                 episode reward: -0.4735,                 loss: nan
agent1:                 episode reward: 0.4735,                 loss: 0.4211
Episode: 3801/30000 (12.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1743s / 165.0793 s
agent0:                 episode reward: -0.8755,                 loss: nan
agent1:                 episode reward: 0.8755,                 loss: 0.4194
Episode: 3821/30000 (12.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1794s / 166.2587 s
agent0:                 episode reward: 0.3371,                 loss: nan
agent1:                 episode reward: -0.3371,                 loss: 0.4199
Episode: 3841/30000 (12.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1653s / 167.4240 s
agent0:                 episode reward: -0.2173,                 loss: nan
agent1:                 episode reward: 0.2173,                 loss: 0.4302
Episode: 3861/30000 (12.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1681s / 168.5921 s
agent0:                 episode reward: -0.1828,                 loss: nan
agent1:                 episode reward: 0.1828,                 loss: 0.4430
Episode: 3881/30000 (12.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1744s / 169.7664 s
agent0:                 episode reward: -0.5727,                 loss: nan
agent1:                 episode reward: 0.5727,                 loss: 0.4424
Episode: 3901/30000 (13.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1840s / 170.9505 s
agent0:                 episode reward: -0.3123,                 loss: nan
agent1:                 episode reward: 0.3123,                 loss: 0.4414
Episode: 3921/30000 (13.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1800s / 172.1304 s
agent0:                 episode reward: -0.5753,                 loss: nan
agent1:                 episode reward: 0.5753,                 loss: 0.4420
Episode: 3941/30000 (13.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1947s / 173.3251 s
agent0:                 episode reward: -0.2079,                 loss: nan
agent1:                 episode reward: 0.2079,                 loss: 0.4403
Episode: 3961/30000 (13.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1727s / 174.4978 s
agent0:                 episode reward: 0.4686,                 loss: nan
agent1:                 episode reward: -0.4686,                 loss: 0.4416
Episode: 3981/30000 (13.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1838s / 175.6815 s
agent0:                 episode reward: -0.6745,                 loss: nan
agent1:                 episode reward: 0.6745,                 loss: 0.4396
Episode: 4001/30000 (13.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1800s / 176.8615 s
agent0:                 episode reward: -0.6272,                 loss: nan
agent1:                 episode reward: 0.6272,                 loss: 0.4409
Episode: 4021/30000 (13.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1765s / 178.0380 s
agent0:                 episode reward: -0.4776,                 loss: nan
agent1:                 episode reward: 0.4776,                 loss: 0.4474
Episode: 4041/30000 (13.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1648s / 179.2028 s
agent0:                 episode reward: -0.3294,                 loss: nan
agent1:                 episode reward: 0.3294,                 loss: 0.4450
Episode: 4061/30000 (13.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1729s / 180.3758 s
agent0:                 episode reward: -0.2549,                 loss: nan
agent1:                 episode reward: 0.2549,                 loss: 0.4461
Episode: 4081/30000 (13.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1887s / 181.5645 s
agent0:                 episode reward: -0.1061,                 loss: nan
agent1:                 episode reward: 0.1061,                 loss: 0.4449
Episode: 4101/30000 (13.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1818s / 182.7463 s
agent0:                 episode reward: -0.3972,                 loss: nan
agent1:                 episode reward: 0.3972,                 loss: 0.4455
Episode: 4121/30000 (13.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1795s / 183.9258 s
agent0:                 episode reward: -0.0067,                 loss: nan
agent1:                 episode reward: 0.0067,                 loss: 0.4448
Episode: 4141/30000 (13.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1836s / 185.1094 s
agent0:                 episode reward: -0.0331,                 loss: nan
agent1:                 episode reward: 0.0331,                 loss: 0.4443
Episode: 4161/30000 (13.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1812s / 186.2906 s
agent0:                 episode reward: 0.0336,                 loss: nan
agent1:                 episode reward: -0.0336,                 loss: 0.4451
Episode: 4181/30000 (13.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1912s / 187.4818 s
agent0:                 episode reward: -0.1293,                 loss: nan
agent1:                 episode reward: 0.1293,                 loss: 0.4424
Episode: 4201/30000 (14.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1804s / 188.6622 s
agent0:                 episode reward: -0.6199,                 loss: nan
agent1:                 episode reward: 0.6199,                 loss: 0.4391
Episode: 4221/30000 (14.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1826s / 189.8448 s
agent0:                 episode reward: -0.2251,                 loss: nan
agent1:                 episode reward: 0.2251,                 loss: 0.4410
Episode: 4241/30000 (14.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1786s / 191.0234 s
agent0:                 episode reward: -0.0917,                 loss: nan
agent1:                 episode reward: 0.0917,                 loss: 0.4393
Episode: 4261/30000 (14.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1833s / 192.2067 s
agent0:                 episode reward: 0.3956,                 loss: nan
agent1:                 episode reward: -0.3956,                 loss: 0.4399
Episode: 4281/30000 (14.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1892s / 193.3959 s
agent0:                 episode reward: -1.0409,                 loss: nan
agent1:                 episode reward: 1.0409,                 loss: 0.4400
Episode: 4301/30000 (14.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1926s / 194.5885 s
agent0:                 episode reward: -0.3470,                 loss: nan
agent1:                 episode reward: 0.3470,                 loss: 0.4397
Episode: 4321/30000 (14.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1920s / 195.7805 s
agent0:                 episode reward: -0.2088,                 loss: nan
agent1:                 episode reward: 0.2088,                 loss: 0.4387
Episode: 4341/30000 (14.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1757s / 196.9562 s
agent0:                 episode reward: -0.0701,                 loss: nan
agent1:                 episode reward: 0.0701,                 loss: 0.4407
Episode: 4361/30000 (14.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1868s / 198.1431 s
agent0:                 episode reward: -0.0150,                 loss: nan
agent1:                 episode reward: 0.0150,                 loss: 0.4418
Episode: 4381/30000 (14.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1840s / 199.3271 s
agent0:                 episode reward: -0.1830,                 loss: nan
agent1:                 episode reward: 0.1830,                 loss: 0.4401
Episode: 4401/30000 (14.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1764s / 200.5035 s
agent0:                 episode reward: -0.2159,                 loss: nan
agent1:                 episode reward: 0.2159,                 loss: 0.4400
Episode: 4421/30000 (14.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1825s / 201.6859 s
agent0:                 episode reward: 0.3072,                 loss: nan
agent1:                 episode reward: -0.3072,                 loss: 0.4404
Episode: 4441/30000 (14.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1827s / 202.8687 s
agent0:                 episode reward: 0.0763,                 loss: nan
agent1:                 episode reward: -0.0763,                 loss: 0.4389
Episode: 4461/30000 (14.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1848s / 204.0535 s
agent0:                 episode reward: -0.2629,                 loss: nan
agent1:                 episode reward: 0.2629,                 loss: 0.4403
Episode: 4481/30000 (14.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1936s / 205.2471 s
agent0:                 episode reward: -0.1856,                 loss: nan
agent1:                 episode reward: 0.1856,                 loss: 0.4408
Episode: 4501/30000 (15.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3434s / 206.5904 s
agent0:                 episode reward: 0.2504,                 loss: nan
agent1:                 episode reward: -0.2504,                 loss: 0.4405
Episode: 4521/30000 (15.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1855s / 207.7759 s
agent0:                 episode reward: -0.5324,                 loss: nan
agent1:                 episode reward: 0.5324,                 loss: 0.4372
Episode: 4541/30000 (15.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1770s / 208.9529 s
agent0:                 episode reward: 0.3044,                 loss: nan
agent1:                 episode reward: -0.3044,                 loss: 0.4377
Episode: 4561/30000 (15.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1858s / 210.1388 s
agent0:                 episode reward: -0.5665,                 loss: nan
agent1:                 episode reward: 0.5665,                 loss: 0.4364
Episode: 4581/30000 (15.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1787s / 211.3174 s
agent0:                 episode reward: 0.0372,                 loss: nan
agent1:                 episode reward: -0.0372,                 loss: 0.4355
Episode: 4601/30000 (15.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1759s / 212.4933 s
agent0:                 episode reward: -0.1046,                 loss: nan
agent1:                 episode reward: 0.1046,                 loss: 0.4364
Episode: 4621/30000 (15.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1769s / 213.6701 s
agent0:                 episode reward: 0.0354,                 loss: nan
agent1:                 episode reward: -0.0354,                 loss: 0.4383
Episode: 4641/30000 (15.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1707s / 214.8408 s
agent0:                 episode reward: -0.4187,                 loss: nan
agent1:                 episode reward: 0.4187,                 loss: 0.4377
Episode: 4661/30000 (15.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1879s / 216.0287 s
agent0:                 episode reward: -0.2926,                 loss: nan
agent1:                 episode reward: 0.2926,                 loss: 0.4364
Episode: 4681/30000 (15.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1758s / 217.2045 s
agent0:                 episode reward: -0.3037,                 loss: nan
agent1:                 episode reward: 0.3037,                 loss: 0.4400
Episode: 4701/30000 (15.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1948s / 218.3994 s
agent0:                 episode reward: -0.1353,                 loss: nan
agent1:                 episode reward: 0.1353,                 loss: 0.4419
Episode: 4721/30000 (15.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1862s / 219.5856 s
agent0:                 episode reward: -0.5788,                 loss: nan
agent1:                 episode reward: 0.5788,                 loss: 0.4422
Episode: 4741/30000 (15.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1998s / 220.7854 s
agent0:                 episode reward: -0.1504,                 loss: nan
agent1:                 episode reward: 0.1504,                 loss: 0.4423
Episode: 4761/30000 (15.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1845s / 221.9699 s
agent0:                 episode reward: -0.7286,                 loss: nan
agent1:                 episode reward: 0.7286,                 loss: 0.4436
Episode: 4781/30000 (15.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1931s / 223.1630 s
agent0:                 episode reward: -0.0232,                 loss: nan
agent1:                 episode reward: 0.0232,                 loss: 0.4421
Episode: 4801/30000 (16.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1830s / 224.3459 s
agent0:                 episode reward: -0.4599,                 loss: nan
agent1:                 episode reward: 0.4599,                 loss: 0.4425
Episode: 4821/30000 (16.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1866s / 225.5325 s
agent0:                 episode reward: -0.6946,                 loss: nan
agent1:                 episode reward: 0.6946,                 loss: 0.4415
Episode: 4841/30000 (16.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2016s / 226.7341 s
agent0:                 episode reward: -0.6962,                 loss: nan
agent1:                 episode reward: 0.6962,                 loss: 0.4429
Episode: 4861/30000 (16.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1864s / 227.9205 s
agent0:                 episode reward: -0.2745,                 loss: nan
agent1:                 episode reward: 0.2745,                 loss: 0.4426
Episode: 4881/30000 (16.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1940s / 229.1145 s
agent0:                 episode reward: -0.0529,                 loss: nan
agent1:                 episode reward: 0.0529,                 loss: 0.4429
Episode: 4901/30000 (16.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1973s / 230.3118 s
agent0:                 episode reward: 0.0151,                 loss: nan
agent1:                 episode reward: -0.0151,                 loss: 0.4417
Episode: 4921/30000 (16.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1958s / 231.5076 s
agent0:                 episode reward: -0.2128,                 loss: nan
agent1:                 episode reward: 0.2128,                 loss: 0.4429
Episode: 4941/30000 (16.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1969s / 232.7045 s
agent0:                 episode reward: -0.1624,                 loss: nan
agent1:                 episode reward: 0.1624,                 loss: 0.4436
Episode: 4961/30000 (16.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1866s / 233.8911 s
agent0:                 episode reward: -0.0081,                 loss: nan
agent1:                 episode reward: 0.0081,                 loss: 0.4423
Episode: 4981/30000 (16.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1966s / 235.0877 s
agent0:                 episode reward: -0.3847,                 loss: nan
agent1:                 episode reward: 0.3847,                 loss: 0.4428
Episode: 5001/30000 (16.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1917s / 236.2794 s
agent0:                 episode reward: 0.0283,                 loss: nan
agent1:                 episode reward: -0.0283,                 loss: 0.4431
Episode: 5021/30000 (16.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2039s / 237.4834 s
agent0:                 episode reward: -0.0110,                 loss: nan
agent1:                 episode reward: 0.0110,                 loss: 0.4427
Episode: 5041/30000 (16.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1899s / 238.6733 s
agent0:                 episode reward: -0.5307,                 loss: nan
agent1:                 episode reward: 0.5307,                 loss: 0.4415
Episode: 5061/30000 (16.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2019s / 239.8752 s
agent0:                 episode reward: -0.2923,                 loss: nan
agent1:                 episode reward: 0.2923,                 loss: 0.4425
Episode: 5081/30000 (16.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2014s / 241.0766 s
agent0:                 episode reward: 0.0205,                 loss: nan
agent1:                 episode reward: -0.0205,                 loss: 0.4427
Episode: 5101/30000 (17.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2124s / 242.2889 s
agent0:                 episode reward: -0.8236,                 loss: nan
agent1:                 episode reward: 0.8236,                 loss: 0.4435
Episode: 5121/30000 (17.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2126s / 243.5015 s
agent0:                 episode reward: -0.7061,                 loss: nan
agent1:                 episode reward: 0.7061,                 loss: 0.4425
Episode: 5141/30000 (17.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1927s / 244.6942 s
agent0:                 episode reward: -0.5268,                 loss: nan
agent1:                 episode reward: 0.5268,                 loss: 0.4424
Episode: 5161/30000 (17.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1936s / 245.8878 s
agent0:                 episode reward: -0.4979,                 loss: nan
agent1:                 episode reward: 0.4979,                 loss: 0.4425
Episode: 5181/30000 (17.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2151s / 247.1030 s
agent0:                 episode reward: -0.2405,                 loss: nan
agent1:                 episode reward: 0.2405,                 loss: 0.4429
Episode: 5201/30000 (17.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2054s / 248.3084 s
agent0:                 episode reward: -0.8634,                 loss: nan
agent1:                 episode reward: 0.8634,                 loss: 0.4435
Episode: 5221/30000 (17.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2096s / 249.5180 s
agent0:                 episode reward: 0.1499,                 loss: nan
agent1:                 episode reward: -0.1499,                 loss: 0.4432
Episode: 5241/30000 (17.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2227s / 250.7408 s
agent0:                 episode reward: -0.1065,                 loss: nan
agent1:                 episode reward: 0.1065,                 loss: 0.4427
Episode: 5261/30000 (17.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2309s / 251.9717 s
agent0:                 episode reward: 0.0797,                 loss: nan
agent1:                 episode reward: -0.0797,                 loss: 0.4429
Episode: 5281/30000 (17.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2252s / 253.1969 s
agent0:                 episode reward: -0.3133,                 loss: nan
agent1:                 episode reward: 0.3133,                 loss: 0.4437
Episode: 5301/30000 (17.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2108s / 254.4076 s
agent0:                 episode reward: -0.4528,                 loss: nan
agent1:                 episode reward: 0.4528,                 loss: 0.4429
Episode: 5321/30000 (17.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2163s / 255.6239 s
agent0:                 episode reward: -0.4449,                 loss: nan
agent1:                 episode reward: 0.4449,                 loss: 0.4434
Episode: 5341/30000 (17.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2039s / 256.8278 s
agent0:                 episode reward: 0.0853,                 loss: nan
agent1:                 episode reward: -0.0853,                 loss: 0.4433
Episode: 5361/30000 (17.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2098s / 258.0377 s
agent0:                 episode reward: -0.1743,                 loss: nan
agent1:                 episode reward: 0.1743,                 loss: 0.4424
Episode: 5381/30000 (17.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2102s / 259.2479 s
agent0:                 episode reward: -1.2112,                 loss: nan
agent1:                 episode reward: 1.2112,                 loss: 0.4417
Episode: 5401/30000 (18.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2062s / 260.4541 s
agent0:                 episode reward: -0.6974,                 loss: nan
agent1:                 episode reward: 0.6974,                 loss: 0.4418
Episode: 5421/30000 (18.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1997s / 261.6538 s
agent0:                 episode reward: 0.3405,                 loss: nan
agent1:                 episode reward: -0.3405,                 loss: 0.4418
Episode: 5441/30000 (18.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2100s / 262.8638 s
agent0:                 episode reward: -0.3974,                 loss: nan
agent1:                 episode reward: 0.3974,                 loss: 0.4412
Episode: 5461/30000 (18.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2130s / 264.0767 s
agent0:                 episode reward: -0.1367,                 loss: nan
agent1:                 episode reward: 0.1367,                 loss: 0.4418
Episode: 5481/30000 (18.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2133s / 265.2900 s
agent0:                 episode reward: 0.1978,                 loss: nan
agent1:                 episode reward: -0.1978,                 loss: 0.4410
Episode: 5501/30000 (18.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2051s / 266.4952 s
agent0:                 episode reward: -0.0482,                 loss: nan
agent1:                 episode reward: 0.0482,                 loss: 0.4415
Episode: 5521/30000 (18.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1986s / 267.6938 s
agent0:                 episode reward: -0.4405,                 loss: nan
agent1:                 episode reward: 0.4405,                 loss: 0.4436
Episode: 5541/30000 (18.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2102s / 268.9039 s
agent0:                 episode reward: -0.6208,                 loss: nan
agent1:                 episode reward: 0.6208,                 loss: 0.4429
Episode: 5561/30000 (18.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2077s / 270.1117 s
agent0:                 episode reward: -0.8367,                 loss: nan
agent1:                 episode reward: 0.8367,                 loss: 0.4423
Episode: 5581/30000 (18.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2128s / 271.3245 s
agent0:                 episode reward: -0.6230,                 loss: nan
agent1:                 episode reward: 0.6230,                 loss: 0.4442
Episode: 5601/30000 (18.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2082s / 272.5326 s
agent0:                 episode reward: -0.1397,                 loss: nan
agent1:                 episode reward: 0.1397,                 loss: 0.4432
Episode: 5621/30000 (18.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2297s / 273.7624 s
agent0:                 episode reward: -0.9061,                 loss: nan
agent1:                 episode reward: 0.9061,                 loss: 0.4430
Episode: 5641/30000 (18.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2084s / 274.9708 s
agent0:                 episode reward: -0.5254,                 loss: nan
agent1:                 episode reward: 0.5254,                 loss: 0.4433
Episode: 5661/30000 (18.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2218s / 276.1926 s
agent0:                 episode reward: -0.1630,                 loss: nan
agent1:                 episode reward: 0.1630,                 loss: 0.4428
Episode: 5681/30000 (18.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2024s / 277.3950 s
agent0:                 episode reward: -0.4981,                 loss: nan
agent1:                 episode reward: 0.4981,                 loss: 0.4388
Episode: 5701/30000 (19.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2062s / 278.6012 s
agent0:                 episode reward: -0.4480,                 loss: nan
agent1:                 episode reward: 0.4480,                 loss: 0.4364
Episode: 5721/30000 (19.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2110s / 279.8123 s
agent0:                 episode reward: -0.2081,                 loss: nan
agent1:                 episode reward: 0.2081,                 loss: 0.4339
Episode: 5741/30000 (19.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2070s / 281.0193 s
agent0:                 episode reward: -0.1673,                 loss: nan
agent1:                 episode reward: 0.1673,                 loss: 0.4353
Episode: 5761/30000 (19.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2171s / 282.2363 s
agent0:                 episode reward: -0.2559,                 loss: nan
agent1:                 episode reward: 0.2559,                 loss: 0.4362
Episode: 5781/30000 (19.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2229s / 283.4592 s
agent0:                 episode reward: -0.5704,                 loss: nan
agent1:                 episode reward: 0.5704,                 loss: 0.4359
Episode: 5801/30000 (19.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2077s / 284.6669 s
agent0:                 episode reward: -0.4833,                 loss: nan
agent1:                 episode reward: 0.4833,                 loss: 0.4344
Episode: 5821/30000 (19.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2057s / 285.8726 s
agent0:                 episode reward: -0.2482,                 loss: nan
agent1:                 episode reward: 0.2482,                 loss: 0.4341
Episode: 5841/30000 (19.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2178s / 287.0905 s
agent0:                 episode reward: -0.5208,                 loss: nan
agent1:                 episode reward: 0.5208,                 loss: 0.4337
Episode: 5861/30000 (19.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2057s / 288.2962 s
agent0:                 episode reward: -0.3042,                 loss: nan
agent1:                 episode reward: 0.3042,                 loss: 0.4322
Episode: 5881/30000 (19.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2205s / 289.5167 s
agent0:                 episode reward: -0.3234,                 loss: nan
agent1:                 episode reward: 0.3234,                 loss: 0.4302
Episode: 5901/30000 (19.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2192s / 290.7360 s
agent0:                 episode reward: -0.4662,                 loss: nan
agent1:                 episode reward: 0.4662,                 loss: 0.4297
Episode: 5921/30000 (19.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2110s / 291.9469 s
agent0:                 episode reward: -0.4516,                 loss: nan
agent1:                 episode reward: 0.4516,                 loss: 0.4310
Episode: 5941/30000 (19.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2206s / 293.1675 s
agent0:                 episode reward: -0.0318,                 loss: nan
agent1:                 episode reward: 0.0318,                 loss: 0.4313
Episode: 5961/30000 (19.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2275s / 294.3950 s
agent0:                 episode reward: -0.4577,                 loss: nan
agent1:                 episode reward: 0.4577,                 loss: 0.4303
Episode: 5981/30000 (19.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2196s / 295.6146 s
agent0:                 episode reward: -0.1253,                 loss: nan
agent1:                 episode reward: 0.1253,                 loss: 0.4287
Episode: 6001/30000 (20.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2243s / 296.8389 s
agent0:                 episode reward: 0.0585,                 loss: nan
agent1:                 episode reward: -0.0585,                 loss: 0.4292
Episode: 6021/30000 (20.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2291s / 298.0680 s
agent0:                 episode reward: -0.3673,                 loss: nan
agent1:                 episode reward: 0.3673,                 loss: 0.4155
Episode: 6041/30000 (20.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2218s / 299.2899 s
agent0:                 episode reward: -0.7066,                 loss: nan
agent1:                 episode reward: 0.7066,                 loss: 0.4152
Episode: 6061/30000 (20.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2144s / 300.5042 s
agent0:                 episode reward: 0.1074,                 loss: nan
agent1:                 episode reward: -0.1074,                 loss: 0.4149
Episode: 6081/30000 (20.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2191s / 301.7234 s
agent0:                 episode reward: -0.7478,                 loss: nan
agent1:                 episode reward: 0.7478,                 loss: 0.4151
Episode: 6101/30000 (20.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2224s / 302.9458 s
agent0:                 episode reward: -1.0620,                 loss: nan
agent1:                 episode reward: 1.0620,                 loss: 0.4139
Episode: 6121/30000 (20.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2200s / 304.1658 s
agent0:                 episode reward: 0.3352,                 loss: nan
agent1:                 episode reward: -0.3352,                 loss: 0.4136
Episode: 6141/30000 (20.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2232s / 305.3890 s
agent0:                 episode reward: -0.2958,                 loss: nan
agent1:                 episode reward: 0.2958,                 loss: 0.4156
Episode: 6161/30000 (20.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2346s / 306.6236 s
agent0:                 episode reward: -0.6602,                 loss: nan
agent1:                 episode reward: 0.6602,                 loss: 0.4130
Episode: 6181/30000 (20.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2112s / 307.8348 s
agent0:                 episode reward: 0.0990,                 loss: nan
agent1:                 episode reward: -0.0990,                 loss: 0.4198
Episode: 6201/30000 (20.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2225s / 309.0574 s
agent0:                 episode reward: -0.4110,                 loss: nan
agent1:                 episode reward: 0.4110,                 loss: 0.4213
Episode: 6221/30000 (20.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2505s / 310.3078 s
agent0:                 episode reward: -0.1603,                 loss: nan
agent1:                 episode reward: 0.1603,                 loss: 0.4214
Episode: 6241/30000 (20.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2529s / 311.5607 s
agent0:                 episode reward: 0.0445,                 loss: nan
agent1:                 episode reward: -0.0445,                 loss: 0.4195
Episode: 6261/30000 (20.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2380s / 312.7987 s
agent0:                 episode reward: -0.4886,                 loss: nan
agent1:                 episode reward: 0.4886,                 loss: 0.4188
Episode: 6281/30000 (20.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2284s / 314.0271 s
agent0:                 episode reward: -0.3136,                 loss: nan
agent1:                 episode reward: 0.3136,                 loss: 0.4194
Episode: 6301/30000 (21.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2293s / 315.2563 s
agent0:                 episode reward: -0.3258,                 loss: nan
agent1:                 episode reward: 0.3258,                 loss: 0.4201
Episode: 6321/30000 (21.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2219s / 316.4782 s
agent0:                 episode reward: -0.1614,                 loss: nan
agent1:                 episode reward: 0.1614,                 loss: 0.4200
Episode: 6341/30000 (21.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2259s / 317.7041 s
agent0:                 episode reward: -0.5293,                 loss: nan
agent1:                 episode reward: 0.5293,                 loss: 0.4187
Episode: 6361/30000 (21.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2265s / 318.9306 s
agent0:                 episode reward: -0.5577,                 loss: nan
agent1:                 episode reward: 0.5577,                 loss: 0.4114
Episode: 6381/30000 (21.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2276s / 320.1582 s
agent0:                 episode reward: -0.3105,                 loss: nan
agent1:                 episode reward: 0.3105,                 loss: 0.4103
Episode: 6401/30000 (21.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2240s / 321.3822 s
agent0:                 episode reward: -0.5069,                 loss: nan
agent1:                 episode reward: 0.5069,                 loss: 0.4097
Episode: 6421/30000 (21.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2313s / 322.6136 s
agent0:                 episode reward: -0.2275,                 loss: nan
agent1:                 episode reward: 0.2275,                 loss: 0.4098
Episode: 6441/30000 (21.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2289s / 323.8425 s
agent0:                 episode reward: -0.0580,                 loss: nan
agent1:                 episode reward: 0.0580,                 loss: 0.4090
Episode: 6461/30000 (21.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2241s / 325.0666 s
agent0:                 episode reward: -0.9260,                 loss: nan
agent1:                 episode reward: 0.9260,                 loss: 0.4092
Episode: 6481/30000 (21.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2170s / 326.2836 s
agent0:                 episode reward: -0.5809,                 loss: nan
agent1:                 episode reward: 0.5809,                 loss: 0.4089
Episode: 6501/30000 (21.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2462s / 327.5298 s
agent0:                 episode reward: -0.4697,                 loss: nan
agent1:                 episode reward: 0.4697,                 loss: 0.4119
Episode: 6521/30000 (21.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2182s / 328.7480 s
agent0:                 episode reward: -0.7622,                 loss: nan
agent1:                 episode reward: 0.7622,                 loss: 0.4279
Episode: 6541/30000 (21.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2466s / 329.9946 s
agent0:                 episode reward: -0.6268,                 loss: nan
agent1:                 episode reward: 0.6268,                 loss: 0.4293
Episode: 6561/30000 (21.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2300s / 331.2246 s
agent0:                 episode reward: -0.4927,                 loss: nan
agent1:                 episode reward: 0.4927,                 loss: 0.4273
Episode: 6581/30000 (21.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2381s / 332.4627 s
agent0:                 episode reward: -0.2132,                 loss: nan
agent1:                 episode reward: 0.2132,                 loss: 0.4282
Episode: 6601/30000 (22.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2310s / 333.6937 s
agent0:                 episode reward: 0.2573,                 loss: nan
agent1:                 episode reward: -0.2573,                 loss: 0.4286
Episode: 6621/30000 (22.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2403s / 334.9339 s
agent0:                 episode reward: -0.2795,                 loss: nan
agent1:                 episode reward: 0.2795,                 loss: 0.4280
Episode: 6641/30000 (22.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2267s / 336.1606 s
agent0:                 episode reward: -0.4716,                 loss: nan
agent1:                 episode reward: 0.4716,                 loss: 0.4270
Episode: 6661/30000 (22.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2367s / 337.3973 s
agent0:                 episode reward: 0.0928,                 loss: nan
agent1:                 episode reward: -0.0928,                 loss: 0.4268
Episode: 6681/30000 (22.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2391s / 338.6364 s
agent0:                 episode reward: -0.2954,                 loss: nan
agent1:                 episode reward: 0.2954,                 loss: 0.4232
Episode: 6701/30000 (22.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2335s / 339.8700 s
agent0:                 episode reward: -0.7574,                 loss: nan
agent1:                 episode reward: 0.7574,                 loss: 0.4174
Episode: 6721/30000 (22.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2454s / 341.1153 s
agent0:                 episode reward: -0.0272,                 loss: nan
agent1:                 episode reward: 0.0272,                 loss: 0.4152
Episode: 6741/30000 (22.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2372s / 342.3526 s
agent0:                 episode reward: -0.2983,                 loss: nan
agent1:                 episode reward: 0.2983,                 loss: 0.4150
Episode: 6761/30000 (22.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2433s / 343.5959 s
agent0:                 episode reward: -0.0074,                 loss: nan
agent1:                 episode reward: 0.0074,                 loss: 0.4144
Episode: 6781/30000 (22.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2352s / 344.8310 s
agent0:                 episode reward: 0.0192,                 loss: nan
agent1:                 episode reward: -0.0192,                 loss: 0.4153
Episode: 6801/30000 (22.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2321s / 346.0631 s
agent0:                 episode reward: -0.5985,                 loss: nan
agent1:                 episode reward: 0.5985,                 loss: 0.4161
Episode: 6821/30000 (22.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2357s / 347.2988 s
agent0:                 episode reward: -0.0504,                 loss: nan
agent1:                 episode reward: 0.0504,                 loss: 0.4143
Episode: 6841/30000 (22.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2419s / 348.5407 s
agent0:                 episode reward: -0.2321,                 loss: nan
agent1:                 episode reward: 0.2321,                 loss: 0.4114
Episode: 6861/30000 (22.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2446s / 349.7853 s
agent0:                 episode reward: -0.5994,                 loss: nan
agent1:                 episode reward: 0.5994,                 loss: 0.4030
Episode: 6881/30000 (22.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2484s / 351.0338 s
agent0:                 episode reward: -0.0033,                 loss: nan
agent1:                 episode reward: 0.0033,                 loss: 0.4038
Episode: 6901/30000 (23.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2514s / 352.2852 s
agent0:                 episode reward: -0.5445,                 loss: nan
agent1:                 episode reward: 0.5445,                 loss: 0.4041
Episode: 6921/30000 (23.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2712s / 353.5564 s
agent0:                 episode reward: -0.7582,                 loss: nan
agent1:                 episode reward: 0.7582,                 loss: 0.4026
Episode: 6941/30000 (23.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2537s / 354.8101 s
agent0:                 episode reward: -0.1433,                 loss: nan
agent1:                 episode reward: 0.1433,                 loss: 0.4046
Episode: 6961/30000 (23.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2566s / 356.0668 s
agent0:                 episode reward: -0.4737,                 loss: nan
agent1:                 episode reward: 0.4737,                 loss: 0.4024
Episode: 6981/30000 (23.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2489s / 357.3157 s
agent0:                 episode reward: -0.3984,                 loss: nan
agent1:                 episode reward: 0.3984,                 loss: 0.4032
Episode: 7001/30000 (23.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2563s / 358.5720 s
agent0:                 episode reward: -0.0246,                 loss: nan
agent1:                 episode reward: 0.0246,                 loss: 0.4048
Episode: 7021/30000 (23.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2581s / 359.8301 s
agent0:                 episode reward: -0.0635,                 loss: nan
agent1:                 episode reward: 0.0635,                 loss: 0.4250
Episode: 7041/30000 (23.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2617s / 361.0918 s
agent0:                 episode reward: -0.1239,                 loss: nan
agent1:                 episode reward: 0.1239,                 loss: 0.4243
Episode: 7061/30000 (23.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2584s / 362.3503 s
agent0:                 episode reward: -0.2952,                 loss: nan
agent1:                 episode reward: 0.2952,                 loss: 0.4245
Episode: 7081/30000 (23.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2647s / 363.6149 s
agent0:                 episode reward: -0.0787,                 loss: nan
agent1:                 episode reward: 0.0787,                 loss: 0.4251
Episode: 7101/30000 (23.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2634s / 364.8784 s
agent0:                 episode reward: -0.2645,                 loss: nan
agent1:                 episode reward: 0.2645,                 loss: 0.4231
Episode: 7121/30000 (23.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2763s / 366.1547 s
agent0:                 episode reward: -0.2103,                 loss: nan
agent1:                 episode reward: 0.2103,                 loss: 0.4233
Episode: 7141/30000 (23.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2677s / 367.4223 s
agent0:                 episode reward: -0.1989,                 loss: nan
agent1:                 episode reward: 0.1989,                 loss: 0.4246
Episode: 7161/30000 (23.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2624s / 368.6847 s
agent0:                 episode reward: -0.5575,                 loss: nan
agent1:                 episode reward: 0.5575,                 loss: 0.4249
Episode: 7181/30000 (23.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2592s / 369.9439 s
agent0:                 episode reward: -0.3028,                 loss: nan
agent1:                 episode reward: 0.3028,                 loss: 0.4244
Episode: 7201/30000 (24.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2587s / 371.2026 s
agent0:                 episode reward: -0.2655,                 loss: nan
agent1:                 episode reward: 0.2655,                 loss: 0.4206
Episode: 7221/30000 (24.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3113s / 372.5139 s
agent0:                 episode reward: -0.8621,                 loss: nan
agent1:                 episode reward: 0.8621,                 loss: 0.4207
Episode: 7241/30000 (24.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2530s / 373.7669 s
agent0:                 episode reward: 0.0513,                 loss: nan
agent1:                 episode reward: -0.0513,                 loss: 0.4214
Episode: 7261/30000 (24.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2531s / 375.0199 s
agent0:                 episode reward: -0.3949,                 loss: nan
agent1:                 episode reward: 0.3949,                 loss: 0.4204
Episode: 7281/30000 (24.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2560s / 376.2760 s
agent0:                 episode reward: -0.2698,                 loss: nan
agent1:                 episode reward: 0.2698,                 loss: 0.4200
Episode: 7301/30000 (24.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2560s / 377.5319 s
agent0:                 episode reward: -0.5268,                 loss: nan
agent1:                 episode reward: 0.5268,                 loss: 0.4207
Episode: 7321/30000 (24.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2584s / 378.7904 s
agent0:                 episode reward: -0.4979,                 loss: nan
agent1:                 episode reward: 0.4979,                 loss: 0.4203
Episode: 7341/30000 (24.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2657s / 380.0561 s
agent0:                 episode reward: -0.3076,                 loss: nan
agent1:                 episode reward: 0.3076,                 loss: 0.4274
Episode: 7361/30000 (24.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2622s / 381.3183 s
agent0:                 episode reward: -0.2194,                 loss: nan
agent1:                 episode reward: 0.2194,                 loss: 0.4317
Episode: 7381/30000 (24.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2677s / 382.5860 s
agent0:                 episode reward: -0.3839,                 loss: nan
agent1:                 episode reward: 0.3839,                 loss: 0.4307
Episode: 7401/30000 (24.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2648s / 383.8508 s
agent0:                 episode reward: -0.6980,                 loss: nan
agent1:                 episode reward: 0.6980,                 loss: 0.4299
Episode: 7421/30000 (24.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2642s / 385.1150 s
agent0:                 episode reward: -0.3476,                 loss: nan
agent1:                 episode reward: 0.3476,                 loss: 0.4301
Episode: 7441/30000 (24.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2616s / 386.3766 s
agent0:                 episode reward: -0.9671,                 loss: nan
agent1:                 episode reward: 0.9671,                 loss: 0.4297
Episode: 7461/30000 (24.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2862s / 387.6628 s
agent0:                 episode reward: -0.8323,                 loss: nan
agent1:                 episode reward: 0.8323,                 loss: 0.4296
Episode: 7481/30000 (24.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2692s / 388.9320 s
agent0:                 episode reward: -0.3690,                 loss: nan
agent1:                 episode reward: 0.3690,                 loss: 0.4297
Episode: 7501/30000 (25.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2653s / 390.1973 s
agent0:                 episode reward: -0.4765,                 loss: nan
agent1:                 episode reward: 0.4765,                 loss: 0.4303
Episode: 7521/30000 (25.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2680s / 391.4653 s
agent0:                 episode reward: -0.3977,                 loss: nan
agent1:                 episode reward: 0.3977,                 loss: 0.4256
Episode: 7541/30000 (25.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2701s / 392.7355 s
agent0:                 episode reward: -0.3090,                 loss: nan
agent1:                 episode reward: 0.3090,                 loss: 0.4237
Episode: 7561/30000 (25.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2770s / 394.0124 s
agent0:                 episode reward: 0.0095,                 loss: nan
agent1:                 episode reward: -0.0095,                 loss: 0.4238
Episode: 7581/30000 (25.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2670s / 395.2795 s
agent0:                 episode reward: 0.0827,                 loss: nan
agent1:                 episode reward: -0.0827,                 loss: 0.4236
Episode: 7601/30000 (25.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2710s / 396.5505 s
agent0:                 episode reward: -0.0597,                 loss: nan
agent1:                 episode reward: 0.0597,                 loss: 0.4253
Episode: 7621/30000 (25.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2636s / 397.8141 s
agent0:                 episode reward: -0.4488,                 loss: nan
agent1:                 episode reward: 0.4488,                 loss: 0.4259
Episode: 7641/30000 (25.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2766s / 399.0907 s
agent0:                 episode reward: -0.1355,                 loss: nan
agent1:                 episode reward: 0.1355,                 loss: 0.4239
Episode: 7661/30000 (25.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2813s / 400.3720 s
agent0:                 episode reward: -0.4487,                 loss: nan
agent1:                 episode reward: 0.4487,                 loss: 0.4229
Episode: 7681/30000 (25.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2767s / 401.6488 s
agent0:                 episode reward: -0.1754,                 loss: nan
agent1:                 episode reward: 0.1754,                 loss: 0.4106
Episode: 7701/30000 (25.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2896s / 402.9384 s
agent0:                 episode reward: -0.3151,                 loss: nan
agent1:                 episode reward: 0.3151,                 loss: 0.4034
Episode: 7721/30000 (25.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2789s / 404.2173 s
agent0:                 episode reward: -0.4331,                 loss: nan
agent1:                 episode reward: 0.4331,                 loss: 0.4032
Episode: 7741/30000 (25.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2718s / 405.4891 s
agent0:                 episode reward: 0.0906,                 loss: nan
agent1:                 episode reward: -0.0906,                 loss: 0.4043
Episode: 7761/30000 (25.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2780s / 406.7670 s
agent0:                 episode reward: -0.1046,                 loss: nan
agent1:                 episode reward: 0.1046,                 loss: 0.4045
Episode: 7781/30000 (25.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2905s / 408.0575 s
agent0:                 episode reward: -0.4415,                 loss: nan
agent1:                 episode reward: 0.4415,                 loss: 0.4010
Episode: 7801/30000 (26.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2975s / 409.3550 s
agent0:                 episode reward: -0.2369,                 loss: nan
agent1:                 episode reward: 0.2369,                 loss: 0.4023
Episode: 7821/30000 (26.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3269s / 410.6819 s
agent0:                 episode reward: -0.0390,                 loss: nan
agent1:                 episode reward: 0.0390,                 loss: 0.4022
Episode: 7841/30000 (26.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3163s / 411.9982 s
agent0:                 episode reward: -0.7032,                 loss: nan
agent1:                 episode reward: 0.7032,                 loss: 0.4104
Episode: 7861/30000 (26.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2862s / 413.2844 s
agent0:                 episode reward: -0.1630,                 loss: nan
agent1:                 episode reward: 0.1630,                 loss: 0.4188
Episode: 7881/30000 (26.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2786s / 414.5630 s
agent0:                 episode reward: -0.0721,                 loss: nan
agent1:                 episode reward: 0.0721,                 loss: 0.4187
Episode: 7901/30000 (26.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2984s / 415.8614 s
agent0:                 episode reward: -0.0010,                 loss: nan
agent1:                 episode reward: 0.0010,                 loss: 0.4182
Episode: 7921/30000 (26.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2980s / 417.1594 s
agent0:                 episode reward: -0.2347,                 loss: nan
agent1:                 episode reward: 0.2347,                 loss: 0.4190
Episode: 7941/30000 (26.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3002s / 418.4595 s
agent0:                 episode reward: -0.3819,                 loss: nan
agent1:                 episode reward: 0.3819,                 loss: 0.4188
Episode: 7961/30000 (26.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2756s / 419.7351 s
agent0:                 episode reward: -0.1984,                 loss: nan
agent1:                 episode reward: 0.1984,                 loss: 0.4175
Episode: 7981/30000 (26.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2816s / 421.0167 s
agent0:                 episode reward: -1.0156,                 loss: nan
agent1:                 episode reward: 1.0156,                 loss: 0.4187
Episode: 8001/30000 (26.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2923s / 422.3090 s
agent0:                 episode reward: -0.8033,                 loss: nan
agent1:                 episode reward: 0.8033,                 loss: 0.4210
Episode: 8021/30000 (26.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2832s / 423.5922 s
agent0:                 episode reward: 0.3345,                 loss: nan
agent1:                 episode reward: -0.3345,                 loss: 0.4282
Episode: 8041/30000 (26.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2820s / 424.8742 s
agent0:                 episode reward: -0.5467,                 loss: nan
agent1:                 episode reward: 0.5467,                 loss: 0.4251
Episode: 8061/30000 (26.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2798s / 426.1540 s
agent0:                 episode reward: -0.2897,                 loss: nan
agent1:                 episode reward: 0.2897,                 loss: 0.4261
Episode: 8081/30000 (26.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2749s / 427.4289 s
agent0:                 episode reward: -0.6808,                 loss: nan
agent1:                 episode reward: 0.6808,                 loss: 0.4256
Episode: 8101/30000 (27.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2830s / 428.7119 s
agent0:                 episode reward: 0.0463,                 loss: nan
agent1:                 episode reward: -0.0463,                 loss: 0.4251
Episode: 8121/30000 (27.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2866s / 429.9985 s
agent0:                 episode reward: 0.0580,                 loss: nan
agent1:                 episode reward: -0.0580,                 loss: 0.4261
Episode: 8141/30000 (27.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2671s / 431.2656 s
agent0:                 episode reward: -0.2540,                 loss: nan
agent1:                 episode reward: 0.2540,                 loss: 0.4250
Episode: 8161/30000 (27.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2741s / 432.5397 s
agent0:                 episode reward: 0.0736,                 loss: nan
agent1:                 episode reward: -0.0736,                 loss: 0.4251
Episode: 8181/30000 (27.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3544s / 433.8941 s
agent0:                 episode reward: -0.0604,                 loss: nan
agent1:                 episode reward: 0.0604,                 loss: 0.4353
Episode: 8201/30000 (27.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2871s / 435.1812 s
agent0:                 episode reward: -0.3264,                 loss: nan
agent1:                 episode reward: 0.3264,                 loss: 0.4381
Episode: 8221/30000 (27.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2789s / 436.4601 s
agent0:                 episode reward: 0.2043,                 loss: nan
agent1:                 episode reward: -0.2043,                 loss: 0.4384
Episode: 8241/30000 (27.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2856s / 437.7457 s
agent0:                 episode reward: -0.4187,                 loss: nan
agent1:                 episode reward: 0.4187,                 loss: 0.4389
Episode: 8261/30000 (27.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2876s / 439.0333 s
agent0:                 episode reward: -0.8191,                 loss: nan
agent1:                 episode reward: 0.8191,                 loss: 0.4374
Episode: 8281/30000 (27.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2874s / 440.3208 s
agent0:                 episode reward: -0.2190,                 loss: nan
agent1:                 episode reward: 0.2190,                 loss: 0.4382
Episode: 8301/30000 (27.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3183s / 441.6391 s
agent0:                 episode reward: -0.5933,                 loss: nan
agent1:                 episode reward: 0.5933,                 loss: 0.4393
Episode: 8321/30000 (27.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3144s / 442.9535 s
agent0:                 episode reward: -0.4815,                 loss: nan
agent1:                 episode reward: 0.4815,                 loss: 0.4390
Episode: 8341/30000 (27.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3041s / 444.2576 s
agent0:                 episode reward: -0.1579,                 loss: nan
agent1:                 episode reward: 0.1579,                 loss: 0.4371
Episode: 8361/30000 (27.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3000s / 445.5575 s
agent0:                 episode reward: -0.6730,                 loss: nan
agent1:                 episode reward: 0.6730,                 loss: 0.4365
Episode: 8381/30000 (27.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3050s / 446.8625 s
agent0:                 episode reward: -0.2544,                 loss: nan
agent1:                 episode reward: 0.2544,                 loss: 0.4380
Episode: 8401/30000 (28.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3011s / 448.1636 s
agent0:                 episode reward: -1.0191,                 loss: nan
agent1:                 episode reward: 1.0191,                 loss: 0.4359
Episode: 8421/30000 (28.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2995s / 449.4631 s
agent0:                 episode reward: -0.5008,                 loss: nan
agent1:                 episode reward: 0.5008,                 loss: 0.4355
Episode: 8441/30000 (28.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3041s / 450.7672 s
agent0:                 episode reward: 0.0062,                 loss: nan
agent1:                 episode reward: -0.0062,                 loss: 0.4378
Episode: 8461/30000 (28.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3067s / 452.0738 s
agent0:                 episode reward: -0.0982,                 loss: nan
agent1:                 episode reward: 0.0982,                 loss: 0.4373
Episode: 8481/30000 (28.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3164s / 453.3902 s
agent0:                 episode reward: -0.0909,                 loss: nan
agent1:                 episode reward: 0.0909,                 loss: 0.4366
Episode: 8501/30000 (28.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3129s / 454.7031 s
agent0:                 episode reward: -0.1120,                 loss: nan
agent1:                 episode reward: 0.1120,                 loss: 0.4364
Episode: 8521/30000 (28.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3164s / 456.0195 s
agent0:                 episode reward: -0.7782,                 loss: nan
agent1:                 episode reward: 0.7782,                 loss: 0.4242
Episode: 8541/30000 (28.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3140s / 457.3335 s
agent0:                 episode reward: -0.0667,                 loss: nan
agent1:                 episode reward: 0.0667,                 loss: 0.4240
Episode: 8561/30000 (28.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3206s / 458.6541 s
agent0:                 episode reward: -0.3451,                 loss: nan
agent1:                 episode reward: 0.3451,                 loss: 0.4237
Episode: 8581/30000 (28.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3057s / 459.9598 s
agent0:                 episode reward: -0.1582,                 loss: nan
agent1:                 episode reward: 0.1582,                 loss: 0.4218
Episode: 8601/30000 (28.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3122s / 461.2720 s
agent0:                 episode reward: 0.3964,                 loss: nan
agent1:                 episode reward: -0.3964,                 loss: 0.4221
Episode: 8621/30000 (28.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3214s / 462.5934 s
agent0:                 episode reward: -0.2529,                 loss: nan
agent1:                 episode reward: 0.2529,                 loss: 0.4238
Episode: 8641/30000 (28.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3243s / 463.9177 s
agent0:                 episode reward: -0.5235,                 loss: nan
agent1:                 episode reward: 0.5235,                 loss: 0.4226
Episode: 8661/30000 (28.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3212s / 465.2389 s
agent0:                 episode reward: -0.2376,                 loss: nan
agent1:                 episode reward: 0.2376,                 loss: 0.4227
Episode: 8681/30000 (28.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3146s / 466.5535 s
agent0:                 episode reward: -0.6883,                 loss: nan
agent1:                 episode reward: 0.6883,                 loss: 0.4196
Episode: 8701/30000 (29.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3165s / 467.8700 s
agent0:                 episode reward: 0.2609,                 loss: nan
agent1:                 episode reward: -0.2609,                 loss: 0.4157
Episode: 8721/30000 (29.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3212s / 469.1911 s
agent0:                 episode reward: -0.2279,                 loss: nan
agent1:                 episode reward: 0.2279,                 loss: 0.4159
Episode: 8741/30000 (29.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3412s / 470.5323 s
agent0:                 episode reward: -0.5690,                 loss: nan
agent1:                 episode reward: 0.5690,                 loss: 0.4164
Episode: 8761/30000 (29.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3227s / 471.8551 s
agent0:                 episode reward: 0.5547,                 loss: nan
agent1:                 episode reward: -0.5547,                 loss: 0.4177
Episode: 8781/30000 (29.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3229s / 473.1780 s
agent0:                 episode reward: -0.1552,                 loss: nan
agent1:                 episode reward: 0.1552,                 loss: 0.4160
Episode: 8801/30000 (29.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3202s / 474.4981 s
agent0:                 episode reward: -0.0452,                 loss: nan
agent1:                 episode reward: 0.0452,                 loss: 0.4163
Episode: 8821/30000 (29.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3299s / 475.8280 s
agent0:                 episode reward: -0.3567,                 loss: nan
agent1:                 episode reward: 0.3567,                 loss: 0.4164
Episode: 8841/30000 (29.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3103s / 477.1384 s
agent0:                 episode reward: -0.2195,                 loss: nan
agent1:                 episode reward: 0.2195,                 loss: 0.4159
Episode: 8861/30000 (29.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3144s / 478.4528 s
agent0:                 episode reward: -0.6726,                 loss: nan
agent1:                 episode reward: 0.6726,                 loss: 0.4137
Episode: 8881/30000 (29.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3358s / 479.7885 s
agent0:                 episode reward: -0.7409,                 loss: nan
agent1:                 episode reward: 0.7409,                 loss: 0.4142
Episode: 8901/30000 (29.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3173s / 481.1058 s
agent0:                 episode reward: -0.2739,                 loss: nan
agent1:                 episode reward: 0.2739,                 loss: 0.4143
Episode: 8921/30000 (29.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3335s / 482.4394 s
agent0:                 episode reward: -0.7706,                 loss: nan
agent1:                 episode reward: 0.7706,                 loss: 0.4152
Episode: 8941/30000 (29.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3297s / 483.7691 s
agent0:                 episode reward: -0.3433,                 loss: nan
agent1:                 episode reward: 0.3433,                 loss: 0.4134
Episode: 8961/30000 (29.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3319s / 485.1010 s
agent0:                 episode reward: 0.2616,                 loss: nan
agent1:                 episode reward: -0.2616,                 loss: 0.4145
Episode: 8981/30000 (29.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3354s / 486.4364 s
agent0:                 episode reward: 0.0984,                 loss: nan
agent1:                 episode reward: -0.0984,                 loss: 0.4150
Episode: 9001/30000 (30.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3255s / 487.7618 s
agent0:                 episode reward: -0.7742,                 loss: nan
agent1:                 episode reward: 0.7742,                 loss: 0.4141
Episode: 9021/30000 (30.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3190s / 489.0809 s
agent0:                 episode reward: 0.0928,                 loss: nan
agent1:                 episode reward: -0.0928,                 loss: 0.4131
Episode: 9041/30000 (30.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3287s / 490.4095 s
agent0:                 episode reward: 0.1552,                 loss: nan
agent1:                 episode reward: -0.1552,                 loss: 0.4115
Episode: 9061/30000 (30.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3308s / 491.7403 s
agent0:                 episode reward: -0.4312,                 loss: nan
agent1:                 episode reward: 0.4312,                 loss: 0.4106
Episode: 9081/30000 (30.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3369s / 493.0773 s
agent0:                 episode reward: -0.3937,                 loss: nan
agent1:                 episode reward: 0.3937,                 loss: 0.4132
Episode: 9101/30000 (30.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3535s / 494.4308 s
agent0:                 episode reward: -0.1333,                 loss: nan
agent1:                 episode reward: 0.1333,                 loss: 0.4121
Episode: 9121/30000 (30.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3245s / 495.7553 s
agent0:                 episode reward: -0.5791,                 loss: nan
agent1:                 episode reward: 0.5791,                 loss: 0.4118
Episode: 9141/30000 (30.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3350s / 497.0903 s
agent0:                 episode reward: 0.0211,                 loss: nan
agent1:                 episode reward: -0.0211,                 loss: 0.4115
Episode: 9161/30000 (30.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3367s / 498.4270 s
agent0:                 episode reward: -1.0562,                 loss: nan
agent1:                 episode reward: 1.0562,                 loss: 0.4108
Episode: 9181/30000 (30.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3441s / 499.7711 s
agent0:                 episode reward: -0.3275,                 loss: nan
agent1:                 episode reward: 0.3275,                 loss: 0.4293
Episode: 9201/30000 (30.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3503s / 501.1214 s
agent0:                 episode reward: -0.2645,                 loss: nan
agent1:                 episode reward: 0.2645,                 loss: 0.4313
Episode: 9221/30000 (30.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3527s / 502.4741 s
agent0:                 episode reward: -0.0117,                 loss: nan
agent1:                 episode reward: 0.0117,                 loss: 0.4316
Episode: 9241/30000 (30.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3487s / 503.8228 s
agent0:                 episode reward: -0.3509,                 loss: nan
agent1:                 episode reward: 0.3509,                 loss: 0.4299
Episode: 9261/30000 (30.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3635s / 505.1863 s
agent0:                 episode reward: -0.3906,                 loss: nan
agent1:                 episode reward: 0.3906,                 loss: 0.4309
Episode: 9281/30000 (30.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3632s / 506.5495 s
agent0:                 episode reward: -0.2249,                 loss: nan
agent1:                 episode reward: 0.2249,                 loss: 0.4311
Episode: 9301/30000 (31.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3439s / 507.8935 s
agent0:                 episode reward: 0.0441,                 loss: nan
agent1:                 episode reward: -0.0441,                 loss: 0.4327
Episode: 9321/30000 (31.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3466s / 509.2401 s
agent0:                 episode reward: -0.4830,                 loss: nan
agent1:                 episode reward: 0.4830,                 loss: 0.4318
Episode: 9341/30000 (31.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3580s / 510.5981 s
agent0:                 episode reward: -0.1978,                 loss: nan
agent1:                 episode reward: 0.1978,                 loss: 0.4323
Episode: 9361/30000 (31.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3577s / 511.9558 s
agent0:                 episode reward: -0.5606,                 loss: nan
agent1:                 episode reward: 0.5606,                 loss: 0.4299
Episode: 9381/30000 (31.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3637s / 513.3194 s
agent0:                 episode reward: -0.1707,                 loss: nan
agent1:                 episode reward: 0.1707,                 loss: 0.4282
Episode: 9401/30000 (31.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3640s / 514.6834 s
agent0:                 episode reward: -0.6168,                 loss: nan
agent1:                 episode reward: 0.6168,                 loss: 0.4290
Episode: 9421/30000 (31.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3739s / 516.0572 s
agent0:                 episode reward: 0.0044,                 loss: nan
agent1:                 episode reward: -0.0044,                 loss: 0.4287
Episode: 9441/30000 (31.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3667s / 517.4239 s
agent0:                 episode reward: -0.4350,                 loss: nan
agent1:                 episode reward: 0.4350,                 loss: 0.4277
Episode: 9461/30000 (31.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3553s / 518.7792 s
agent0:                 episode reward: -0.7413,                 loss: nan
agent1:                 episode reward: 0.7413,                 loss: 0.4278
Episode: 9481/30000 (31.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3685s / 520.1477 s
agent0:                 episode reward: -0.8329,                 loss: nan
agent1:                 episode reward: 0.8329,                 loss: 0.4281
Episode: 9501/30000 (31.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3589s / 521.5066 s
agent0:                 episode reward: -0.4911,                 loss: nan
agent1:                 episode reward: 0.4911,                 loss: 0.4286
Episode: 9521/30000 (31.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3604s / 522.8670 s
agent0:                 episode reward: -0.2734,                 loss: nan
agent1:                 episode reward: 0.2734,                 loss: 0.4333
Episode: 9541/30000 (31.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3471s / 524.2141 s
agent0:                 episode reward: 0.0147,                 loss: nan
agent1:                 episode reward: -0.0147,                 loss: 0.4317
Episode: 9561/30000 (31.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3508s / 525.5649 s
agent0:                 episode reward: -0.3990,                 loss: nan
agent1:                 episode reward: 0.3990,                 loss: 0.4308
Episode: 9581/30000 (31.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3677s / 526.9327 s
agent0:                 episode reward: -0.3532,                 loss: nan
agent1:                 episode reward: 0.3532,                 loss: 0.4310
Episode: 9601/30000 (32.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3512s / 528.2839 s
agent0:                 episode reward: -0.2846,                 loss: nan
agent1:                 episode reward: 0.2846,                 loss: 0.4320
Episode: 9621/30000 (32.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3541s / 529.6380 s
agent0:                 episode reward: -0.0419,                 loss: nan
agent1:                 episode reward: 0.0419,                 loss: 0.4313
Episode: 9641/30000 (32.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3602s / 530.9982 s
agent0:                 episode reward: -0.3658,                 loss: nan
agent1:                 episode reward: 0.3658,                 loss: 0.4321
Episode: 9661/30000 (32.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3607s / 532.3589 s
agent0:                 episode reward: -0.5275,                 loss: nan
agent1:                 episode reward: 0.5275,                 loss: 0.4316
Episode: 9681/30000 (32.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3531s / 533.7120 s
agent0:                 episode reward: -0.5922,                 loss: nan
agent1:                 episode reward: 0.5922,                 loss: 0.4225
Episode: 9701/30000 (32.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3499s / 535.0620 s
agent0:                 episode reward: -0.4906,                 loss: nan
agent1:                 episode reward: 0.4906,                 loss: 0.4145
Episode: 9721/30000 (32.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3597s / 536.4217 s
agent0:                 episode reward: -0.3388,                 loss: nan
agent1:                 episode reward: 0.3388,                 loss: 0.4135
Episode: 9741/30000 (32.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3679s / 537.7895 s
agent0:                 episode reward: -0.5201,                 loss: nan
agent1:                 episode reward: 0.5201,                 loss: 0.4133
Episode: 9761/30000 (32.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3574s / 539.1469 s
agent0:                 episode reward: -0.6651,                 loss: nan
agent1:                 episode reward: 0.6651,                 loss: 0.4131
Episode: 9781/30000 (32.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3616s / 540.5085 s
agent0:                 episode reward: -0.2186,                 loss: nan
agent1:                 episode reward: 0.2186,                 loss: 0.4132
Episode: 9801/30000 (32.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3599s / 541.8684 s
agent0:                 episode reward: -0.4046,                 loss: nan
agent1:                 episode reward: 0.4046,                 loss: 0.4122
Episode: 9821/30000 (32.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3598s / 543.2282 s
agent0:                 episode reward: -0.7276,                 loss: nan
agent1:                 episode reward: 0.7276,                 loss: 0.4135
Episode: 9841/30000 (32.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3804s / 544.6087 s
agent0:                 episode reward: -0.3987,                 loss: nan
agent1:                 episode reward: 0.3987,                 loss: 0.3997
Episode: 9861/30000 (32.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3621s / 545.9708 s
agent0:                 episode reward: -0.1819,                 loss: nan
agent1:                 episode reward: 0.1819,                 loss: 0.3718
Episode: 9881/30000 (32.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3671s / 547.3379 s
agent0:                 episode reward: -0.7887,                 loss: nan
agent1:                 episode reward: 0.7887,                 loss: 0.3710
Episode: 9901/30000 (33.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3641s / 548.7020 s
agent0:                 episode reward: -0.2136,                 loss: nan
agent1:                 episode reward: 0.2136,                 loss: 0.3722
Episode: 9921/30000 (33.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3725s / 550.0745 s
agent0:                 episode reward: -0.7696,                 loss: nan
agent1:                 episode reward: 0.7696,                 loss: 0.3696
Episode: 9941/30000 (33.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3776s / 551.4520 s
agent0:                 episode reward: -0.5372,                 loss: nan
agent1:                 episode reward: 0.5372,                 loss: 0.3711
Episode: 9961/30000 (33.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3650s / 552.8171 s
agent0:                 episode reward: -0.4308,                 loss: nan
agent1:                 episode reward: 0.4308,                 loss: 0.3707
Episode: 9981/30000 (33.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3639s / 554.1810 s
agent0:                 episode reward: -0.5822,                 loss: nan
agent1:                 episode reward: 0.5822,                 loss: 0.3706
Episode: 10001/30000 (33.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3770s / 555.5579 s
agent0:                 episode reward: -0.5418,                 loss: nan
agent1:                 episode reward: 0.5418,                 loss: 0.3697
Episode: 10021/30000 (33.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3786s / 556.9365 s
agent0:                 episode reward: -0.2553,                 loss: nan
agent1:                 episode reward: 0.2553,                 loss: 0.4044
Episode: 10041/30000 (33.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3788s / 558.3153 s
agent0:                 episode reward: 0.2204,                 loss: nan
agent1:                 episode reward: -0.2204,                 loss: 0.4050
Episode: 10061/30000 (33.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3872s / 559.7025 s
agent0:                 episode reward: -0.8221,                 loss: nan
agent1:                 episode reward: 0.8221,                 loss: 0.4024
Episode: 10081/30000 (33.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3908s / 561.0933 s
agent0:                 episode reward: -0.3807,                 loss: nan
agent1:                 episode reward: 0.3807,                 loss: 0.4041
Episode: 10101/30000 (33.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3757s / 562.4690 s
agent0:                 episode reward: -0.1337,                 loss: nan
agent1:                 episode reward: 0.1337,                 loss: 0.4035
Episode: 10121/30000 (33.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3777s / 563.8467 s
agent0:                 episode reward: -0.5464,                 loss: nan
agent1:                 episode reward: 0.5464,                 loss: 0.4028
Episode: 10141/30000 (33.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3698s / 565.2165 s
agent0:                 episode reward: -0.3200,                 loss: nan
agent1:                 episode reward: 0.3200,                 loss: 0.4027
Episode: 10161/30000 (33.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3900s / 566.6065 s
agent0:                 episode reward: -0.5201,                 loss: nan
agent1:                 episode reward: 0.5201,                 loss: 0.4026
Episode: 10181/30000 (33.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3899s / 567.9964 s
agent0:                 episode reward: -0.4274,                 loss: nan
agent1:                 episode reward: 0.4274,                 loss: 0.4147
Episode: 10201/30000 (34.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3874s / 569.3838 s
agent0:                 episode reward: -0.7894,                 loss: nan
agent1:                 episode reward: 0.7894,                 loss: 0.4159
Episode: 10221/30000 (34.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3869s / 570.7707 s
agent0:                 episode reward: -0.0535,                 loss: nan
agent1:                 episode reward: 0.0535,                 loss: 0.4164
Episode: 10241/30000 (34.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3886s / 572.1593 s
agent0:                 episode reward: -0.9775,                 loss: nan
agent1:                 episode reward: 0.9775,                 loss: 0.4160
Episode: 10261/30000 (34.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3899s / 573.5492 s
agent0:                 episode reward: -0.6251,                 loss: nan
agent1:                 episode reward: 0.6251,                 loss: 0.4172
Episode: 10281/30000 (34.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3873s / 574.9365 s
agent0:                 episode reward: 0.3293,                 loss: nan
agent1:                 episode reward: -0.3293,                 loss: 0.4141
Episode: 10301/30000 (34.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.4045s / 576.3410 s
agent0:                 episode reward: -0.9108,                 loss: nan
agent1:                 episode reward: 0.9108,                 loss: 0.4172
Episode: 10321/30000 (34.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3971s / 577.7382 s
agent0:                 episode reward: -0.4718,                 loss: nan
agent1:                 episode reward: 0.4718,                 loss: 0.4157