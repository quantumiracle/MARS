pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
boxing_v1 pettingzoo
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
random seed: [740, 694, 31, 588, 704]
<SubprocVectorEnv instance>
Agents No. [1] (index starting from 0) are not learnable.
Arguments:  {'env_name': 'boxing_v1', 'env_type': 'pettingzoo', 'num_envs': 5, 'ram': True, 'seed': 'random', 'algorithm': 'NashPPO', 'algorithm_spec': {'episodic_update': True, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 30000, 'lambda': 0.95, 'eps_clip': 0.2, 'K_epoch': 4, 'GAE': True}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False, 'feature': {'hidden_dim_list': [128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'policy': {'hidden_dim_list': [128, 128], 'hidden_activation': False, 'output_activation': 'Softmax'}, 'value': {'hidden_dim_list': [128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}}, 'marl_method': 'nash_ppo', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True}}
Save models to : /home/zihan/research/MARS/data/model/20220427_1507/pettingzoo_boxing_v1_nash_ppo. 
 Save logs to: /home/zihan/research/MARS/data/log/20220427_1507/pettingzoo_boxing_v1_nash_ppo.
Episode: 1/10000 (0.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 10.1922s / 10.1922 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.8476
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
env2_first_0:                 episode reward: 1.0000,                 loss: nan
env2_second_0:                 episode reward: -1.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: -1.0000,                 loss: nan
env4_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 64.3784s / 74.5706 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.5153
env0_second_0:                 episode reward: -0.0500,                 loss: nan
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
env2_first_0:                 episode reward: 0.1500,                 loss: nan
env2_second_0:                 episode reward: -0.1500,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: -0.4500,                 loss: nan
env4_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 74.9508s / 149.5214 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.9422
env0_second_0:                 episode reward: 0.2000,                 loss: nan
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
env3_first_0:                 episode reward: 0.1500,                 loss: nan
env3_second_0:                 episode reward: -0.1500,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.6794s / 227.2008 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.9881
env0_second_0:                 episode reward: -0.1000,                 loss: nan
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
env2_first_0:                 episode reward: -0.1500,                 loss: nan
env2_second_0:                 episode reward: 0.1500,                 loss: nan
env3_first_0:                 episode reward: -0.3000,                 loss: nan
env3_second_0:                 episode reward: 0.3000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 81/10000 (0.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.7071s / 302.9079 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.8981
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
env2_first_0:                 episode reward: -0.1500,                 loss: nan
env2_second_0:                 episode reward: 0.1500,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: -0.0500,                 loss: nan
env4_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 101/10000 (1.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 74.1098s / 377.0176 s
env0_first_0:                 episode reward: 0.1500,                 loss: -0.9777
env0_second_0:                 episode reward: -0.1500,                 loss: nan
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
env2_first_0:                 episode reward: 0.3000,                 loss: nan
env2_second_0:                 episode reward: -0.3000,                 loss: nan
env3_first_0:                 episode reward: -0.1500,                 loss: nan
env3_second_0:                 episode reward: 0.1500,                 loss: nan
env4_first_0:                 episode reward: -0.3500,                 loss: nan
env4_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 121/10000 (1.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 73.9118s / 450.9295 s
env0_first_0:                 episode reward: -0.3500,                 loss: -0.9771
env0_second_0:                 episode reward: 0.3500,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
env3_first_0:                 episode reward: -0.3000,                 loss: nan
env3_second_0:                 episode reward: 0.3000,                 loss: nan
env4_first_0:                 episode reward: -0.0500,                 loss: nan
env4_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 141/10000 (1.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 74.4049s / 525.3344 s
env0_first_0:                 episode reward: 0.0500,                 loss: -1.0107
env0_second_0:                 episode reward: -0.0500,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.2000,                 loss: nan
env2_second_0:                 episode reward: -0.2000,                 loss: nan
env3_first_0:                 episode reward: 0.0500,                 loss: nan
env3_second_0:                 episode reward: -0.0500,                 loss: nan
env4_first_0:                 episode reward: -0.1000,                 loss: nan
env4_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 161/10000 (1.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 73.6925s / 599.0269 s
env0_first_0:                 episode reward: -0.0500,                 loss: -1.1283
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0500,                 loss: nan
env4_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 181/10000 (1.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.2131s / 675.2400 s
env0_first_0:                 episode reward: 0.0000,                 loss: -1.0994
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.0500,                 loss: nan
env2_second_0:                 episode reward: -0.0500,                 loss: nan
env3_first_0:                 episode reward: -0.3000,                 loss: nan
env3_second_0:                 episode reward: 0.3000,                 loss: nan
env4_first_0:                 episode reward: 0.1000,                 loss: nan
env4_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 201/10000 (2.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.4689s / 755.7089 s
env0_first_0:                 episode reward: 0.0000,                 loss: -1.1146
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
env3_first_0:                 episode reward: -0.1500,                 loss: nan
env3_second_0:                 episode reward: 0.1500,                 loss: nan
env4_first_0:                 episode reward: 0.0500,                 loss: nan
env4_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 221/10000 (2.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.9361s / 835.6449 s
env0_first_0:                 episode reward: 0.1000,                 loss: -1.0852
env0_second_0:                 episode reward: -0.1000,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0500,                 loss: nan
env4_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 241/10000 (2.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.7891s / 915.4340 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.9893
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.1000,                 loss: nan
env2_second_0:                 episode reward: -0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.0500,                 loss: nan
env3_second_0:                 episode reward: -0.0500,                 loss: nan
env4_first_0:                 episode reward: -0.1500,                 loss: nan
env4_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 261/10000 (2.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.6124s / 995.0464 s
env0_first_0:                 episode reward: 0.0000,                 loss: -1.0548
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 281/10000 (2.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.2690s / 1075.3154 s
env0_first_0:                 episode reward: 0.0000,                 loss: -1.0694
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 301/10000 (3.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.1904s / 1154.5059 s
env0_first_0:                 episode reward: 0.0000,                 loss: -1.0121
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 321/10000 (3.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.0162s / 1234.5220 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.9334
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 341/10000 (3.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.1713s / 1314.6933 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.9022
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 361/10000 (3.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.1792s / 1394.8725 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.9067
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: -0.2000,                 loss: nan
env2_second_0:                 episode reward: 0.2000,                 loss: nan
env3_first_0:                 episode reward: 0.3000,                 loss: nan
env3_second_0:                 episode reward: -0.3000,                 loss: nan
env4_first_0:                 episode reward: 0.1500,                 loss: nan
env4_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 381/10000 (3.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.6064s / 1474.4789 s
env0_first_0:                 episode reward: 0.0000,                 loss: -1.0967
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.1000,                 loss: nan
env2_second_0:                 episode reward: -0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.1000,                 loss: nan
env3_second_0:                 episode reward: -0.1000,                 loss: nan
env4_first_0:                 episode reward: 0.1500,                 loss: nan
env4_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 401/10000 (4.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.1674s / 1554.6463 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.9581
env0_second_0:                 episode reward: 0.1000,                 loss: nan
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: -0.1500,                 loss: nan
env2_second_0:                 episode reward: 0.1500,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: -0.1000,                 loss: nan
env4_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 421/10000 (4.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.1720s / 1634.8183 s
env0_first_0:                 episode reward: 0.1000,                 loss: -1.0659
env0_second_0:                 episode reward: -0.1000,                 loss: nan
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.1000,                 loss: nan
env2_second_0:                 episode reward: -0.1000,                 loss: nan
env3_first_0:                 episode reward: -0.5500,                 loss: nan
env3_second_0:                 episode reward: 0.5500,                 loss: nan
env4_first_0:                 episode reward: 0.3000,                 loss: nan
env4_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 441/10000 (4.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.7961s / 1713.6143 s
env0_first_0:                 episode reward: 0.4000,                 loss: -1.0911
env0_second_0:                 episode reward: -0.4000,                 loss: nan
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: -0.1000,                 loss: nan
env4_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 461/10000 (4.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.7105s / 1793.3248 s
env0_first_0:                 episode reward: -1.2000,                 loss: -0.0920
env0_second_0:                 episode reward: 1.2000,                 loss: nan
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
env2_first_0:                 episode reward: -1.0500,                 loss: nan
env2_second_0:                 episode reward: 1.0500,                 loss: nan
env3_first_0:                 episode reward: 0.2000,                 loss: nan
env3_second_0:                 episode reward: -0.2000,                 loss: nan
env4_first_0:                 episode reward: -0.3000,                 loss: nan
env4_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 481/10000 (4.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.4925s / 1871.8173 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.1715
env0_second_0:                 episode reward: 0.7500,                 loss: nan
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
env2_first_0:                 episode reward: -0.9000,                 loss: nan
env2_second_0:                 episode reward: 0.9000,                 loss: nan
env3_first_0:                 episode reward: 0.0500,                 loss: nan
env3_second_0:                 episode reward: -0.0500,                 loss: nan
env4_first_0:                 episode reward: -1.1000,                 loss: nan
env4_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 501/10000 (5.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.7308s / 1951.5481 s
env0_first_0:                 episode reward: 0.3000,                 loss: -0.0156
env0_second_0:                 episode reward: -0.3000,                 loss: nan
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
env2_first_0:                 episode reward: -2.0000,                 loss: nan
env2_second_0:                 episode reward: 2.0000,                 loss: nan
env3_first_0:                 episode reward: -0.5500,                 loss: nan
env3_second_0:                 episode reward: 0.5500,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 521/10000 (5.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.0483s / 2031.5963 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.6274
env0_second_0:                 episode reward: -0.0500,                 loss: nan
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
env2_first_0:                 episode reward: 0.1500,                 loss: nan
env2_second_0:                 episode reward: -0.1500,                 loss: nan
env3_first_0:                 episode reward: -0.2000,                 loss: nan
env3_second_0:                 episode reward: 0.2000,                 loss: nan
env4_first_0:                 episode reward: -0.3000,                 loss: nan
env4_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 541/10000 (5.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.4288s / 2112.0252 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.8946
env0_second_0:                 episode reward: -0.1000,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: -0.4000,                 loss: nan
env2_second_0:                 episode reward: 0.4000,                 loss: nan
env3_first_0:                 episode reward: 0.1500,                 loss: nan
env3_second_0:                 episode reward: -0.1500,                 loss: nan
env4_first_0:                 episode reward: -0.3500,                 loss: nan
env4_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 561/10000 (5.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.4594s / 2191.4845 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2404
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: -0.6000,                 loss: nan
env2_second_0:                 episode reward: 0.6000,                 loss: nan
env3_first_0:                 episode reward: -0.8000,                 loss: nan
env3_second_0:                 episode reward: 0.8000,                 loss: nan
env4_first_0:                 episode reward: -0.5500,                 loss: nan
env4_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 581/10000 (5.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.8708s / 2269.3553 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.7387
env0_second_0:                 episode reward: 0.4000,                 loss: nan
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
env2_first_0:                 episode reward: 0.6500,                 loss: nan
env2_second_0:                 episode reward: -0.6500,                 loss: nan
env3_first_0:                 episode reward: -2.3000,                 loss: nan
env3_second_0:                 episode reward: 2.3000,                 loss: nan
env4_first_0:                 episode reward: -1.5000,                 loss: nan
env4_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 601/10000 (6.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.8848s / 2348.2401 s
env0_first_0:                 episode reward: -0.2500,                 loss: -0.4497
env0_second_0:                 episode reward: 0.2500,                 loss: nan
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
env2_first_0:                 episode reward: -0.1500,                 loss: nan
env2_second_0:                 episode reward: 0.1500,                 loss: nan
env3_first_0:                 episode reward: -0.1000,                 loss: nan
env3_second_0:                 episode reward: 0.1000,                 loss: nan
env4_first_0:                 episode reward: -0.7000,                 loss: nan
env4_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 621/10000 (6.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.6550s / 2427.8952 s
env0_first_0:                 episode reward: -0.8500,                 loss: -0.5464
env0_second_0:                 episode reward: 0.8500,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: -0.4000,                 loss: nan
env2_second_0:                 episode reward: 0.4000,                 loss: nan
env3_first_0:                 episode reward: -0.2000,                 loss: nan
env3_second_0:                 episode reward: 0.2000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 641/10000 (6.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.7312s / 2507.6263 s
env0_first_0:                 episode reward: -0.4000,                 loss: -0.7217
env0_second_0:                 episode reward: 0.4000,                 loss: nan
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
env3_first_0:                 episode reward: -0.5000,                 loss: nan
env3_second_0:                 episode reward: 0.5000,                 loss: nan
env4_first_0:                 episode reward: -0.7500,                 loss: nan
env4_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 661/10000 (6.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.0374s / 2586.6638 s
env0_first_0:                 episode reward: 0.1000,                 loss: 1.6658
env0_second_0:                 episode reward: -0.1000,                 loss: nan
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
env2_first_0:                 episode reward: -1.8000,                 loss: nan
env2_second_0:                 episode reward: 1.8000,                 loss: nan
env3_first_0:                 episode reward: -0.8000,                 loss: nan
env3_second_0:                 episode reward: 0.8000,                 loss: nan
env4_first_0:                 episode reward: -0.8000,                 loss: nan
env4_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 681/10000 (6.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.1489s / 2666.8127 s
env0_first_0:                 episode reward: -1.1500,                 loss: -0.0198
env0_second_0:                 episode reward: 1.1500,                 loss: nan
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
env2_first_0:                 episode reward: -0.7000,                 loss: nan
env2_second_0:                 episode reward: 0.7000,                 loss: nan
env3_first_0:                 episode reward: -0.8500,                 loss: nan
env3_second_0:                 episode reward: 0.8500,                 loss: nan
env4_first_0:                 episode reward: 0.2000,                 loss: nan
env4_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 701/10000 (7.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.9254s / 2746.7380 s
env0_first_0:                 episode reward: -2.0500,                 loss: 2.0305
env0_second_0:                 episode reward: 2.0500,                 loss: nan
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
env2_first_0:                 episode reward: -2.7500,                 loss: nan
env2_second_0:                 episode reward: 2.7500,                 loss: nan
env3_first_0:                 episode reward: -1.5500,                 loss: nan
env3_second_0:                 episode reward: 1.5500,                 loss: nan
env4_first_0:                 episode reward: -1.4000,                 loss: nan
env4_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 721/10000 (7.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.0690s / 2825.8070 s
env0_first_0:                 episode reward: -2.8000,                 loss: 2.3882
env0_second_0:                 episode reward: 2.8000,                 loss: nan
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
env2_first_0:                 episode reward: -1.7000,                 loss: nan
env2_second_0:                 episode reward: 1.7000,                 loss: nan
env3_first_0:                 episode reward: -1.7500,                 loss: nan
env3_second_0:                 episode reward: 1.7500,                 loss: nan
env4_first_0:                 episode reward: -1.5000,                 loss: nan
env4_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 741/10000 (7.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.5202s / 2905.3273 s
env0_first_0:                 episode reward: 0.5500,                 loss: 1.9893
env0_second_0:                 episode reward: -0.5500,                 loss: nan
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
env2_first_0:                 episode reward: -1.9500,                 loss: nan
env2_second_0:                 episode reward: 1.9500,                 loss: nan
env3_first_0:                 episode reward: -2.6000,                 loss: nan
env3_second_0:                 episode reward: 2.6000,                 loss: nan
env4_first_0:                 episode reward: -1.9500,                 loss: nan
env4_second_0:                 episode reward: 1.9500,                 loss: nan
Episode: 761/10000 (7.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.8843s / 2984.2116 s
env0_first_0:                 episode reward: -2.1500,                 loss: 3.3055
env0_second_0:                 episode reward: 2.1500,                 loss: nan
env1_first_0:                 episode reward: -1.8500,                 loss: nan
env1_second_0:                 episode reward: 1.8500,                 loss: nan
env2_first_0:                 episode reward: -3.8500,                 loss: nan
env2_second_0:                 episode reward: 3.8500,                 loss: nan
env3_first_0:                 episode reward: -3.2000,                 loss: nan
env3_second_0:                 episode reward: 3.2000,                 loss: nan
env4_first_0:                 episode reward: -0.4500,                 loss: nan
env4_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 781/10000 (7.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.0044s / 3063.2160 s
env0_first_0:                 episode reward: -1.1500,                 loss: 2.7131
env0_second_0:                 episode reward: 1.1500,                 loss: nan
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
env2_first_0:                 episode reward: -2.7500,                 loss: nan
env2_second_0:                 episode reward: 2.7500,                 loss: nan
env3_first_0:                 episode reward: -1.4500,                 loss: nan
env3_second_0:                 episode reward: 1.4500,                 loss: nan
env4_first_0:                 episode reward: -0.5000,                 loss: nan
env4_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 801/10000 (8.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.3218s / 3142.5378 s
env0_first_0:                 episode reward: -1.2500,                 loss: 3.2959
env0_second_0:                 episode reward: 1.2500,                 loss: nan
env1_first_0:                 episode reward: -3.0000,                 loss: nan
env1_second_0:                 episode reward: 3.0000,                 loss: nan
env2_first_0:                 episode reward: -1.4500,                 loss: nan
env2_second_0:                 episode reward: 1.4500,                 loss: nan
env3_first_0:                 episode reward: -3.2500,                 loss: nan
env3_second_0:                 episode reward: 3.2500,                 loss: nan
env4_first_0:                 episode reward: -1.4500,                 loss: nan
env4_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 821/10000 (8.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.8345s / 3221.3723 s
env0_first_0:                 episode reward: -0.8500,                 loss: 3.3490
env0_second_0:                 episode reward: 0.8500,                 loss: nan
env1_first_0:                 episode reward: -2.2500,                 loss: nan
env1_second_0:                 episode reward: 2.2500,                 loss: nan
env2_first_0:                 episode reward: -4.5000,                 loss: nan
env2_second_0:                 episode reward: 4.5000,                 loss: nan
env3_first_0:                 episode reward: -0.6000,                 loss: nan
env3_second_0:                 episode reward: 0.6000,                 loss: nan
env4_first_0:                 episode reward: -0.7000,                 loss: nan
env4_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 841/10000 (8.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.9028s / 3300.2751 s
env0_first_0:                 episode reward: -2.5000,                 loss: 4.5804
env0_second_0:                 episode reward: 2.5000,                 loss: nan
env1_first_0:                 episode reward: -2.5500,                 loss: nan
env1_second_0:                 episode reward: 2.5500,                 loss: nan
env2_first_0:                 episode reward: -3.6000,                 loss: nan
env2_second_0:                 episode reward: 3.6000,                 loss: nan
env3_first_0:                 episode reward: -3.4000,                 loss: nan
env3_second_0:                 episode reward: 3.4000,                 loss: nan
env4_first_0:                 episode reward: -2.3000,                 loss: nan
env4_second_0:                 episode reward: 2.3000,                 loss: nan
Episode: 861/10000 (8.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.5052s / 3378.7803 s
env0_first_0:                 episode reward: -3.2000,                 loss: 3.3527
env0_second_0:                 episode reward: 3.2000,                 loss: nan
env1_first_0:                 episode reward: -1.9000,                 loss: nan
env1_second_0:                 episode reward: 1.9000,                 loss: nan
env2_first_0:                 episode reward: -4.1500,                 loss: nan
env2_second_0:                 episode reward: 4.1500,                 loss: nan
env3_first_0:                 episode reward: -6.5000,                 loss: nan
env3_second_0:                 episode reward: 6.5000,                 loss: nan
env4_first_0:                 episode reward: -1.2500,                 loss: nan
env4_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 881/10000 (8.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.8843s / 3457.6646 s
env0_first_0:                 episode reward: -0.1000,                 loss: 4.1194
env0_second_0:                 episode reward: 0.1000,                 loss: nan
env1_first_0:                 episode reward: -2.4500,                 loss: nan
env1_second_0:                 episode reward: 2.4500,                 loss: nan
env2_first_0:                 episode reward: -3.4500,                 loss: nan
env2_second_0:                 episode reward: 3.4500,                 loss: nan
env3_first_0:                 episode reward: -1.1000,                 loss: nan
env3_second_0:                 episode reward: 1.1000,                 loss: nan
env4_first_0:                 episode reward: -5.5000,                 loss: nan
env4_second_0:                 episode reward: 5.5000,                 loss: nan
Episode: 901/10000 (9.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.2613s / 3536.9260 s
env0_first_0:                 episode reward: -0.3500,                 loss: 3.6957
env0_second_0:                 episode reward: 0.3500,                 loss: nan
env1_first_0:                 episode reward: -2.7500,                 loss: nan
env1_second_0:                 episode reward: 2.7500,                 loss: nan
env2_first_0:                 episode reward: -2.6500,                 loss: nan
env2_second_0:                 episode reward: 2.6500,                 loss: nan
env3_first_0:                 episode reward: -4.1500,                 loss: nan
env3_second_0:                 episode reward: 4.1500,                 loss: nan
env4_first_0:                 episode reward: -2.5000,                 loss: nan
env4_second_0:                 episode reward: 2.5000,                 loss: nan
Episode: 921/10000 (9.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.8232s / 3616.7491 s
env0_first_0:                 episode reward: -2.3000,                 loss: 2.7700
env0_second_0:                 episode reward: 2.3000,                 loss: nan
env1_first_0:                 episode reward: -2.8500,                 loss: nan
env1_second_0:                 episode reward: 2.8500,                 loss: nan
env2_first_0:                 episode reward: -0.8000,                 loss: nan
env2_second_0:                 episode reward: 0.8000,                 loss: nan
env3_first_0:                 episode reward: 0.3500,                 loss: nan
env3_second_0:                 episode reward: -0.3500,                 loss: nan
env4_first_0:                 episode reward: -0.9000,                 loss: nan
env4_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 941/10000 (9.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.6775s / 3695.4266 s
env0_first_0:                 episode reward: -6.4500,                 loss: 6.0625
env0_second_0:                 episode reward: 6.4500,                 loss: nan
env1_first_0:                 episode reward: -2.2000,                 loss: nan
env1_second_0:                 episode reward: 2.2000,                 loss: nan
env2_first_0:                 episode reward: -3.2000,                 loss: nan
env2_second_0:                 episode reward: 3.2000,                 loss: nan
env3_first_0:                 episode reward: -5.7500,                 loss: nan
env3_second_0:                 episode reward: 5.7500,                 loss: nan
env4_first_0:                 episode reward: -4.2000,                 loss: nan
env4_second_0:                 episode reward: 4.2000,                 loss: nan
Episode: 961/10000 (9.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.2425s / 3774.6691 s
env0_first_0:                 episode reward: -2.9500,                 loss: 6.3585
env0_second_0:                 episode reward: 2.9500,                 loss: nan
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
env2_first_0:                 episode reward: -2.4000,                 loss: nan
env2_second_0:                 episode reward: 2.4000,                 loss: nan
env3_first_0:                 episode reward: -3.9000,                 loss: nan
env3_second_0:                 episode reward: 3.9000,                 loss: nan
env4_first_0:                 episode reward: -2.1000,                 loss: nan
env4_second_0:                 episode reward: 2.1000,                 loss: nan
Episode: 981/10000 (9.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.4388s / 3853.1079 s
env0_first_0:                 episode reward: -2.6000,                 loss: 5.5752
env0_second_0:                 episode reward: 2.6000,                 loss: nan
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
env2_first_0:                 episode reward: -2.3500,                 loss: nan
env2_second_0:                 episode reward: 2.3500,                 loss: nan
env3_first_0:                 episode reward: -4.9500,                 loss: nan
env3_second_0:                 episode reward: 4.9500,                 loss: nan
env4_first_0:                 episode reward: -2.1000,                 loss: nan
env4_second_0:                 episode reward: 2.1000,                 loss: nan
Episode: 1001/10000 (10.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.4349s / 3931.5429 s
env0_first_0:                 episode reward: 1.3000,                 loss: 5.7902
env0_second_0:                 episode reward: -1.3000,                 loss: nan
env1_first_0:                 episode reward: -4.7500,                 loss: nan
env1_second_0:                 episode reward: 4.7500,                 loss: nan
env2_first_0:                 episode reward: -1.9000,                 loss: nan
env2_second_0:                 episode reward: 1.9000,                 loss: nan
env3_first_0:                 episode reward: -2.7500,                 loss: nan
env3_second_0:                 episode reward: 2.7500,                 loss: nan
env4_first_0:                 episode reward: -2.1000,                 loss: nan
env4_second_0:                 episode reward: 2.1000,                 loss: nan
Episode: 1021/10000 (10.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.5573s / 4011.1002 s
env0_first_0:                 episode reward: -4.8500,                 loss: 7.1936
env0_second_0:                 episode reward: 4.8500,                 loss: nan
env1_first_0:                 episode reward: -4.1000,                 loss: nan
env1_second_0:                 episode reward: 4.1000,                 loss: nan
env2_first_0:                 episode reward: -1.4500,                 loss: nan
env2_second_0:                 episode reward: 1.4500,                 loss: nan
env3_first_0:                 episode reward: -5.6500,                 loss: nan
env3_second_0:                 episode reward: 5.6500,                 loss: nan
env4_first_0:                 episode reward: -4.0000,                 loss: nan
env4_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 1041/10000 (10.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.9224s / 4090.0226 s
env0_first_0:                 episode reward: -1.0500,                 loss: 4.8734
env0_second_0:                 episode reward: 1.0500,                 loss: nan
env1_first_0:                 episode reward: -2.3000,                 loss: nan
env1_second_0:                 episode reward: 2.3000,                 loss: nan
env2_first_0:                 episode reward: -0.9500,                 loss: nan
env2_second_0:                 episode reward: 0.9500,                 loss: nan
env3_first_0:                 episode reward: -1.5000,                 loss: nan
env3_second_0:                 episode reward: 1.5000,                 loss: nan
env4_first_0:                 episode reward: -1.7000,                 loss: nan
env4_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 1061/10000 (10.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.0398s / 4168.0623 s
env0_first_0:                 episode reward: -5.0000,                 loss: 7.1444
env0_second_0:                 episode reward: 5.0000,                 loss: nan
env1_first_0:                 episode reward: -4.1000,                 loss: nan
env1_second_0:                 episode reward: 4.1000,                 loss: nan
env2_first_0:                 episode reward: -3.8500,                 loss: nan
env2_second_0:                 episode reward: 3.8500,                 loss: nan
env3_first_0:                 episode reward: -5.6000,                 loss: nan
env3_second_0:                 episode reward: 5.6000,                 loss: nan
env4_first_0:                 episode reward: -2.6500,                 loss: nan
env4_second_0:                 episode reward: 2.6500,                 loss: nan
Episode: 1081/10000 (10.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.1904s / 4247.2527 s
env0_first_0:                 episode reward: -4.8000,                 loss: 7.4136
env0_second_0:                 episode reward: 4.8000,                 loss: nan
env1_first_0:                 episode reward: -4.7500,                 loss: nan
env1_second_0:                 episode reward: 4.7500,                 loss: nan
env2_first_0:                 episode reward: -7.3000,                 loss: nan
env2_second_0:                 episode reward: 7.3000,                 loss: nan
env3_first_0:                 episode reward: -5.2500,                 loss: nan
env3_second_0:                 episode reward: 5.2500,                 loss: nan
env4_first_0:                 episode reward: -7.7000,                 loss: nan
env4_second_0:                 episode reward: 7.7000,                 loss: nan
Episode: 1101/10000 (11.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.7116s / 4324.9643 s
env0_first_0:                 episode reward: -5.9500,                 loss: 5.4960
env0_second_0:                 episode reward: 5.9500,                 loss: nan
env1_first_0:                 episode reward: -5.0000,                 loss: nan
env1_second_0:                 episode reward: 5.0000,                 loss: nan
env2_first_0:                 episode reward: -3.4000,                 loss: nan
env2_second_0:                 episode reward: 3.4000,                 loss: nan
env3_first_0:                 episode reward: -4.1500,                 loss: nan
env3_second_0:                 episode reward: 4.1500,                 loss: nan
env4_first_0:                 episode reward: -4.4500,                 loss: nan
env4_second_0:                 episode reward: 4.4500,                 loss: nan
Episode: 1121/10000 (11.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.5394s / 4403.5037 s
env0_first_0:                 episode reward: -4.0000,                 loss: 5.5263
env0_second_0:                 episode reward: 4.0000,                 loss: nan
env1_first_0:                 episode reward: -5.7500,                 loss: nan
env1_second_0:                 episode reward: 5.7500,                 loss: nan
env2_first_0:                 episode reward: -5.5000,                 loss: nan
env2_second_0:                 episode reward: 5.5000,                 loss: nan
env3_first_0:                 episode reward: -4.9500,                 loss: nan
env3_second_0:                 episode reward: 4.9500,                 loss: nan
env4_first_0:                 episode reward: -5.0000,                 loss: nan
env4_second_0:                 episode reward: 5.0000,                 loss: nan
Episode: 1141/10000 (11.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.6344s / 4482.1381 s
env0_first_0:                 episode reward: -7.8000,                 loss: 8.1928
env0_second_0:                 episode reward: 7.8000,                 loss: nan
env1_first_0:                 episode reward: -8.6000,                 loss: nan
env1_second_0:                 episode reward: 8.6000,                 loss: nan
env2_first_0:                 episode reward: -4.8000,                 loss: nan
env2_second_0:                 episode reward: 4.8000,                 loss: nan
env3_first_0:                 episode reward: -6.5500,                 loss: nan
env3_second_0:                 episode reward: 6.5500,                 loss: nan
env4_first_0:                 episode reward: -6.0000,                 loss: nan
env4_second_0:                 episode reward: 6.0000,                 loss: nan
Episode: 1161/10000 (11.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.4523s / 4560.5904 s
env0_first_0:                 episode reward: -5.2500,                 loss: 8.9853
env0_second_0:                 episode reward: 5.2500,                 loss: nan
env1_first_0:                 episode reward: -9.9000,                 loss: nan
env1_second_0:                 episode reward: 9.9000,                 loss: nan
env2_first_0:                 episode reward: -9.3500,                 loss: nan
env2_second_0:                 episode reward: 9.3500,                 loss: nan
env3_first_0:                 episode reward: -7.3000,                 loss: nan
env3_second_0:                 episode reward: 7.3000,                 loss: nan
env4_first_0:                 episode reward: -8.3000,                 loss: nan
env4_second_0:                 episode reward: 8.3000,                 loss: nan
Episode: 1181/10000 (11.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.9331s / 4639.5236 s
env0_first_0:                 episode reward: -9.7000,                 loss: 10.6510
env0_second_0:                 episode reward: 9.7000,                 loss: nan
env1_first_0:                 episode reward: -8.6500,                 loss: nan
env1_second_0:                 episode reward: 8.6500,                 loss: nan
env2_first_0:                 episode reward: -9.5000,                 loss: nan
env2_second_0:                 episode reward: 9.5000,                 loss: nan
env3_first_0:                 episode reward: -12.4500,                 loss: nan
env3_second_0:                 episode reward: 12.4500,                 loss: nan
env4_first_0:                 episode reward: -10.8500,                 loss: nan
env4_second_0:                 episode reward: 10.8500,                 loss: nan
Episode: 1201/10000 (12.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.1131s / 4718.6367 s
env0_first_0:                 episode reward: -7.9000,                 loss: 11.9267
env0_second_0:                 episode reward: 7.9000,                 loss: nan
env1_first_0:                 episode reward: -9.1500,                 loss: nan
env1_second_0:                 episode reward: 9.1500,                 loss: nan
env2_first_0:                 episode reward: -9.2500,                 loss: nan
env2_second_0:                 episode reward: 9.2500,                 loss: nan
env3_first_0:                 episode reward: -7.4000,                 loss: nan
env3_second_0:                 episode reward: 7.4000,                 loss: nan
env4_first_0:                 episode reward: -8.6000,                 loss: nan
env4_second_0:                 episode reward: 8.6000,                 loss: nan
Episode: 1221/10000 (12.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.9798s / 4797.6165 s
env0_first_0:                 episode reward: -12.9000,                 loss: 10.7513
env0_second_0:                 episode reward: 12.9000,                 loss: nan
env1_first_0:                 episode reward: -11.8000,                 loss: nan
env1_second_0:                 episode reward: 11.8000,                 loss: nan
env2_first_0:                 episode reward: -10.4500,                 loss: nan
env2_second_0:                 episode reward: 10.4500,                 loss: nan
env3_first_0:                 episode reward: -8.4500,                 loss: nan
env3_second_0:                 episode reward: 8.4500,                 loss: nan
env4_first_0:                 episode reward: -10.7000,                 loss: nan
env4_second_0:                 episode reward: 10.7000,                 loss: nan
Episode: 1241/10000 (12.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.8410s / 4876.4575 s
env0_first_0:                 episode reward: -16.8500,                 loss: 16.5512
env0_second_0:                 episode reward: 16.8500,                 loss: nan
env1_first_0:                 episode reward: -14.2000,                 loss: nan
env1_second_0:                 episode reward: 14.2000,                 loss: nan
env2_first_0:                 episode reward: -16.8000,                 loss: nan
env2_second_0:                 episode reward: 16.8000,                 loss: nan
env3_first_0:                 episode reward: -14.3500,                 loss: nan
env3_second_0:                 episode reward: 14.3500,                 loss: nan
env4_first_0:                 episode reward: -13.9500,                 loss: nan
env4_second_0:                 episode reward: 13.9500,                 loss: nan
Episode: 1261/10000 (12.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.7176s / 4954.1752 s
env0_first_0:                 episode reward: -17.4000,                 loss: 11.6357
env0_second_0:                 episode reward: 17.4000,                 loss: nan
env1_first_0:                 episode reward: -11.8000,                 loss: nan
env1_second_0:                 episode reward: 11.8000,                 loss: nan
env2_first_0:                 episode reward: -10.5000,                 loss: nan
env2_second_0:                 episode reward: 10.5000,                 loss: nan
env3_first_0:                 episode reward: -12.5000,                 loss: nan
env3_second_0:                 episode reward: 12.5000,                 loss: nan
env4_first_0:                 episode reward: -10.5500,                 loss: nan
env4_second_0:                 episode reward: 10.5500,                 loss: nan
Episode: 1281/10000 (12.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.9621s / 5031.1373 s
env0_first_0:                 episode reward: -15.0000,                 loss: 15.3035
env0_second_0:                 episode reward: 15.0000,                 loss: nan
env1_first_0:                 episode reward: -19.6000,                 loss: nan
env1_second_0:                 episode reward: 19.6000,                 loss: nan
env2_first_0:                 episode reward: -13.0500,                 loss: nan
env2_second_0:                 episode reward: 13.0500,                 loss: nan
env3_first_0:                 episode reward: -12.8000,                 loss: nan
env3_second_0:                 episode reward: 12.8000,                 loss: nan
env4_first_0:                 episode reward: -14.8000,                 loss: nan
env4_second_0:                 episode reward: 14.8000,                 loss: nan
Episode: 1301/10000 (13.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.2893s / 5109.4266 s
env0_first_0:                 episode reward: -9.6000,                 loss: 14.8635
env0_second_0:                 episode reward: 9.6000,                 loss: nan
env1_first_0:                 episode reward: -12.1500,                 loss: nan
env1_second_0:                 episode reward: 12.1500,                 loss: nan
env2_first_0:                 episode reward: -12.0000,                 loss: nan
env2_second_0:                 episode reward: 12.0000,                 loss: nan
env3_first_0:                 episode reward: -12.2000,                 loss: nan
env3_second_0:                 episode reward: 12.2000,                 loss: nan
env4_first_0:                 episode reward: -10.4000,                 loss: nan
env4_second_0:                 episode reward: 10.4000,                 loss: nan
Episode: 1321/10000 (13.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.7695s / 5188.1961 s
env0_first_0:                 episode reward: -15.0000,                 loss: 18.2765
env0_second_0:                 episode reward: 15.0000,                 loss: nan
env1_first_0:                 episode reward: -18.2000,                 loss: nan
env1_second_0:                 episode reward: 18.2000,                 loss: nan
env2_first_0:                 episode reward: -15.5500,                 loss: nan
env2_second_0:                 episode reward: 15.5500,                 loss: nan
env3_first_0:                 episode reward: -11.7000,                 loss: nan
env3_second_0:                 episode reward: 11.7000,                 loss: nan
env4_first_0:                 episode reward: -12.3000,                 loss: nan
env4_second_0:                 episode reward: 12.3000,                 loss: nan
Episode: 1341/10000 (13.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.6324s / 5266.8285 s
env0_first_0:                 episode reward: -15.5000,                 loss: 17.5304
env0_second_0:                 episode reward: 15.5000,                 loss: nan
env1_first_0:                 episode reward: -11.6500,                 loss: nan
env1_second_0:                 episode reward: 11.6500,                 loss: nan
env2_first_0:                 episode reward: -14.9500,                 loss: nan
env2_second_0:                 episode reward: 14.9500,                 loss: nan
env3_first_0:                 episode reward: -16.4500,                 loss: nan
env3_second_0:                 episode reward: 16.4500,                 loss: nan
env4_first_0:                 episode reward: -19.2000,                 loss: nan
env4_second_0:                 episode reward: 19.2000,                 loss: nan
Episode: 1361/10000 (13.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.9051s / 5345.7336 s
env0_first_0:                 episode reward: -11.8500,                 loss: 17.9988
env0_second_0:                 episode reward: 11.8500,                 loss: nan
env1_first_0:                 episode reward: -15.2000,                 loss: nan
env1_second_0:                 episode reward: 15.2000,                 loss: nan
env2_first_0:                 episode reward: -9.1000,                 loss: nan
env2_second_0:                 episode reward: 9.1000,                 loss: nan
env3_first_0:                 episode reward: -17.1000,                 loss: nan
env3_second_0:                 episode reward: 17.1000,                 loss: nan
env4_first_0:                 episode reward: -14.1000,                 loss: nan
env4_second_0:                 episode reward: 14.1000,                 loss: nan
Episode: 1381/10000 (13.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.9095s / 5424.6431 s
env0_first_0:                 episode reward: -9.6500,                 loss: 21.6388
env0_second_0:                 episode reward: 9.6500,                 loss: nan
env1_first_0:                 episode reward: -13.3000,                 loss: nan
env1_second_0:                 episode reward: 13.3000,                 loss: nan
env2_first_0:                 episode reward: -12.5500,                 loss: nan
env2_second_0:                 episode reward: 12.5500,                 loss: nan
env3_first_0:                 episode reward: -14.3000,                 loss: nan
env3_second_0:                 episode reward: 14.3000,                 loss: nan
env4_first_0:                 episode reward: -11.8000,                 loss: nan
env4_second_0:                 episode reward: 11.8000,                 loss: nan
Episode: 1401/10000 (14.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.8935s / 5502.5366 s
env0_first_0:                 episode reward: -14.3500,                 loss: 33.2324
env0_second_0:                 episode reward: 14.3500,                 loss: nan
env1_first_0:                 episode reward: -18.9000,                 loss: nan
env1_second_0:                 episode reward: 18.9000,                 loss: nan
env2_first_0:                 episode reward: -16.6000,                 loss: nan
env2_second_0:                 episode reward: 16.6000,                 loss: nan
env3_first_0:                 episode reward: -17.5500,                 loss: nan
env3_second_0:                 episode reward: 17.5500,                 loss: nan
env4_first_0:                 episode reward: -18.2000,                 loss: nan
env4_second_0:                 episode reward: 18.2000,                 loss: nan
Episode: 1421/10000 (14.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.4651s / 5581.0016 s
env0_first_0:                 episode reward: -15.7000,                 loss: 28.4797
env0_second_0:                 episode reward: 15.7000,                 loss: nan
env1_first_0:                 episode reward: -12.9500,                 loss: nan
env1_second_0:                 episode reward: 12.9500,                 loss: nan
env2_first_0:                 episode reward: -13.4000,                 loss: nan
env2_second_0:                 episode reward: 13.4000,                 loss: nan
env3_first_0:                 episode reward: -8.1000,                 loss: nan
env3_second_0:                 episode reward: 8.1000,                 loss: nan
env4_first_0:                 episode reward: -14.7000,                 loss: nan
env4_second_0:                 episode reward: 14.7000,                 loss: nan
Episode: 1441/10000 (14.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.2158s / 5659.2174 s
env0_first_0:                 episode reward: -20.2500,                 loss: 29.3286
env0_second_0:                 episode reward: 20.2500,                 loss: nan
env1_first_0:                 episode reward: -14.8500,                 loss: nan
env1_second_0:                 episode reward: 14.8500,                 loss: nan
env2_first_0:                 episode reward: -18.2500,                 loss: nan
env2_second_0:                 episode reward: 18.2500,                 loss: nan
env3_first_0:                 episode reward: -16.7500,                 loss: nan
env3_second_0:                 episode reward: 16.7500,                 loss: nan
env4_first_0:                 episode reward: -17.0500,                 loss: nan
env4_second_0:                 episode reward: 17.0500,                 loss: nan
Episode: 1461/10000 (14.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.8486s / 5739.0660 s
env0_first_0:                 episode reward: -16.4000,                 loss: 27.5605
env0_second_0:                 episode reward: 16.4000,                 loss: nan
env1_first_0:                 episode reward: -20.8500,                 loss: nan
env1_second_0:                 episode reward: 20.8500,                 loss: nan
env2_first_0:                 episode reward: -16.7000,                 loss: nan
env2_second_0:                 episode reward: 16.7000,                 loss: nan
env3_first_0:                 episode reward: -10.4500,                 loss: nan
env3_second_0:                 episode reward: 10.4500,                 loss: nan
env4_first_0:                 episode reward: -9.7000,                 loss: nan
env4_second_0:                 episode reward: 9.7000,                 loss: nan
Episode: 1481/10000 (14.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.9888s / 5820.0549 s
env0_first_0:                 episode reward: -17.3500,                 loss: 24.2349
env0_second_0:                 episode reward: 17.3500,                 loss: nan
env1_first_0:                 episode reward: -8.5500,                 loss: nan
env1_second_0:                 episode reward: 8.5500,                 loss: nan
env2_first_0:                 episode reward: -14.9000,                 loss: nan
env2_second_0:                 episode reward: 14.9000,                 loss: nan
env3_first_0:                 episode reward: -10.6000,                 loss: nan
env3_second_0:                 episode reward: 10.6000,                 loss: nan
env4_first_0:                 episode reward: -4.4500,                 loss: nan
env4_second_0:                 episode reward: 4.4500,                 loss: nan
Episode: 1501/10000 (15.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.0061s / 5900.0609 s
env0_first_0:                 episode reward: -4.1500,                 loss: 21.3534
env0_second_0:                 episode reward: 4.1500,                 loss: nan
env1_first_0:                 episode reward: -7.0500,                 loss: nan
env1_second_0:                 episode reward: 7.0500,                 loss: nan
env2_first_0:                 episode reward: -11.8000,                 loss: nan
env2_second_0:                 episode reward: 11.8000,                 loss: nan
env3_first_0:                 episode reward: -3.2000,                 loss: nan
env3_second_0:                 episode reward: 3.2000,                 loss: nan
env4_first_0:                 episode reward: -9.7000,                 loss: nan
env4_second_0:                 episode reward: 9.7000,                 loss: nan
Episode: 1521/10000 (15.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.5314s / 5980.5923 s
env0_first_0:                 episode reward: -6.8500,                 loss: 24.4300
env0_second_0:                 episode reward: 6.8500,                 loss: nan
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
env2_first_0:                 episode reward: -9.6000,                 loss: nan
env2_second_0:                 episode reward: 9.6000,                 loss: nan
env3_first_0:                 episode reward: -5.1000,                 loss: nan
env3_second_0:                 episode reward: 5.1000,                 loss: nan
env4_first_0:                 episode reward: -5.8000,                 loss: nan
env4_second_0:                 episode reward: 5.8000,                 loss: nan
Episode: 1541/10000 (15.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.7368s / 6059.3291 s
env0_first_0:                 episode reward: -13.4000,                 loss: 30.6713
env0_second_0:                 episode reward: 13.4000,                 loss: nan
env1_first_0:                 episode reward: -5.7500,                 loss: nan
env1_second_0:                 episode reward: 5.7500,                 loss: nan
env2_first_0:                 episode reward: -12.8000,                 loss: nan
env2_second_0:                 episode reward: 12.8000,                 loss: nan
env3_first_0:                 episode reward: -11.3000,                 loss: nan
env3_second_0:                 episode reward: 11.3000,                 loss: nan
env4_first_0:                 episode reward: -16.7000,                 loss: nan
env4_second_0:                 episode reward: 16.7000,                 loss: nan
Episode: 1561/10000 (15.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.7539s / 6139.0830 s
env0_first_0:                 episode reward: -9.8000,                 loss: 26.4338
env0_second_0:                 episode reward: 9.8000,                 loss: nan
env1_first_0:                 episode reward: -10.7500,                 loss: nan
env1_second_0:                 episode reward: 10.7500,                 loss: nan
env2_first_0:                 episode reward: -9.2000,                 loss: nan
env2_second_0:                 episode reward: 9.2000,                 loss: nan
env3_first_0:                 episode reward: -11.7500,                 loss: nan
env3_second_0:                 episode reward: 11.7500,                 loss: nan
env4_first_0:                 episode reward: -13.5500,                 loss: nan
env4_second_0:                 episode reward: 13.5500,                 loss: nan
Episode: 1581/10000 (15.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.7419s / 6217.8248 s
env0_first_0:                 episode reward: -25.0500,                 loss: 33.8800
env0_second_0:                 episode reward: 25.0500,                 loss: nan
env1_first_0:                 episode reward: -19.5500,                 loss: nan
env1_second_0:                 episode reward: 19.5500,                 loss: nan
env2_first_0:                 episode reward: -27.6000,                 loss: nan
env2_second_0:                 episode reward: 27.6000,                 loss: nan
env3_first_0:                 episode reward: -21.2500,                 loss: nan
env3_second_0:                 episode reward: 21.2500,                 loss: nan
env4_first_0:                 episode reward: -19.4000,                 loss: nan
env4_second_0:                 episode reward: 19.4000,                 loss: nan
Episode: 1601/10000 (16.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.4661s / 6297.2910 s
env0_first_0:                 episode reward: -27.5500,                 loss: 43.8071
env0_second_0:                 episode reward: 27.5500,                 loss: nan
env1_first_0:                 episode reward: -26.0000,                 loss: nan
env1_second_0:                 episode reward: 26.0000,                 loss: nan
env2_first_0:                 episode reward: -29.8000,                 loss: nan
env2_second_0:                 episode reward: 29.8000,                 loss: nan
env3_first_0:                 episode reward: -22.9500,                 loss: nan
env3_second_0:                 episode reward: 22.9500,                 loss: nan
env4_first_0:                 episode reward: -25.0000,                 loss: nan
env4_second_0:                 episode reward: 25.0000,                 loss: nan
Episode: 1621/10000 (16.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.9534s / 6377.2443 s
env0_first_0:                 episode reward: -26.9500,                 loss: 50.7787
env0_second_0:                 episode reward: 26.9500,                 loss: nan
env1_first_0:                 episode reward: -29.6000,                 loss: nan
env1_second_0:                 episode reward: 29.6000,                 loss: nan
env2_first_0:                 episode reward: -32.1000,                 loss: nan
env2_second_0:                 episode reward: 32.1000,                 loss: nan
env3_first_0:                 episode reward: -29.9000,                 loss: nan
env3_second_0:                 episode reward: 29.9000,                 loss: nan
env4_first_0:                 episode reward: -35.1500,                 loss: nan
env4_second_0:                 episode reward: 35.1500,                 loss: nan
Episode: 1641/10000 (16.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.7966s / 6457.0410 s
env0_first_0:                 episode reward: -32.2000,                 loss: 45.5723
env0_second_0:                 episode reward: 32.2000,                 loss: nan
env1_first_0:                 episode reward: -33.6500,                 loss: nan
env1_second_0:                 episode reward: 33.6500,                 loss: nan
env2_first_0:                 episode reward: -29.7500,                 loss: nan
env2_second_0:                 episode reward: 29.7500,                 loss: nan
env3_first_0:                 episode reward: -33.1500,                 loss: nan
env3_second_0:                 episode reward: 33.1500,                 loss: nan
env4_first_0:                 episode reward: -31.9500,                 loss: nan
env4_second_0:                 episode reward: 31.9500,                 loss: nan
Episode: 1661/10000 (16.6100%),                 avg. length: 297.15,                last time consumption/overall running time: 79.4885s / 6536.5295 s
env0_first_0:                 episode reward: -36.1500,                 loss: 62.6501
env0_second_0:                 episode reward: 36.1500,                 loss: nan
env1_first_0:                 episode reward: -37.6500,                 loss: nan
env1_second_0:                 episode reward: 37.6500,                 loss: nan
env2_first_0:                 episode reward: -23.3500,                 loss: nan
env2_second_0:                 episode reward: 23.3500,                 loss: nan
env3_first_0:                 episode reward: -34.3500,                 loss: nan
env3_second_0:                 episode reward: 34.3500,                 loss: nan
env4_first_0:                 episode reward: -35.9000,                 loss: nan
env4_second_0:                 episode reward: 35.9000,                 loss: nan
Episode: 1681/10000 (16.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.4334s / 6615.9629 s
env0_first_0:                 episode reward: -21.7000,                 loss: 49.5628
env0_second_0:                 episode reward: 21.7000,                 loss: nan
env1_first_0:                 episode reward: -28.7000,                 loss: nan
env1_second_0:                 episode reward: 28.7000,                 loss: nan
env2_first_0:                 episode reward: -12.5000,                 loss: nan
env2_second_0:                 episode reward: 12.5000,                 loss: nan
env3_first_0:                 episode reward: -20.7000,                 loss: nan
env3_second_0:                 episode reward: 20.7000,                 loss: nan
env4_first_0:                 episode reward: -19.5500,                 loss: nan
env4_second_0:                 episode reward: 19.5500,                 loss: nan
Episode: 1701/10000 (17.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.4708s / 6695.4337 s
env0_first_0:                 episode reward: -14.6500,                 loss: 45.3883
env0_second_0:                 episode reward: 14.6500,                 loss: nan
env1_first_0:                 episode reward: -11.8000,                 loss: nan
env1_second_0:                 episode reward: 11.8000,                 loss: nan
env2_first_0:                 episode reward: -8.9000,                 loss: nan
env2_second_0:                 episode reward: 8.9000,                 loss: nan
env3_first_0:                 episode reward: -11.2000,                 loss: nan
env3_second_0:                 episode reward: 11.2000,                 loss: nan
env4_first_0:                 episode reward: -16.1000,                 loss: nan
env4_second_0:                 episode reward: 16.1000,                 loss: nan
Episode: 1721/10000 (17.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.9380s / 6774.3718 s
env0_first_0:                 episode reward: -24.8500,                 loss: 52.2962
env0_second_0:                 episode reward: 24.8500,                 loss: nan
env1_first_0:                 episode reward: -17.7500,                 loss: nan
env1_second_0:                 episode reward: 17.7500,                 loss: nan
env2_first_0:                 episode reward: -19.4000,                 loss: nan
env2_second_0:                 episode reward: 19.4000,                 loss: nan
env3_first_0:                 episode reward: -24.1000,                 loss: nan
env3_second_0:                 episode reward: 24.1000,                 loss: nan
env4_first_0:                 episode reward: -13.9500,                 loss: nan
env4_second_0:                 episode reward: 13.9500,                 loss: nan
Episode: 1741/10000 (17.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.0366s / 6852.4083 s
env0_first_0:                 episode reward: -25.6500,                 loss: 60.2858
env0_second_0:                 episode reward: 25.6500,                 loss: nan
env1_first_0:                 episode reward: -29.2000,                 loss: nan
env1_second_0:                 episode reward: 29.2000,                 loss: nan
env2_first_0:                 episode reward: -26.5500,                 loss: nan
env2_second_0:                 episode reward: 26.5500,                 loss: nan
env3_first_0:                 episode reward: -16.1500,                 loss: nan
env3_second_0:                 episode reward: 16.1500,                 loss: nan
env4_first_0:                 episode reward: -13.7000,                 loss: nan
env4_second_0:                 episode reward: 13.7000,                 loss: nan
Episode: 1761/10000 (17.6100%),                 avg. length: 298.1,                last time consumption/overall running time: 77.8330s / 6930.2413 s
env0_first_0:                 episode reward: -21.5500,                 loss: 64.4828
env0_second_0:                 episode reward: 21.5500,                 loss: nan
env1_first_0:                 episode reward: -23.6500,                 loss: nan
env1_second_0:                 episode reward: 23.6500,                 loss: nan
env2_first_0:                 episode reward: -24.6000,                 loss: nan
env2_second_0:                 episode reward: 24.6000,                 loss: nan
env3_first_0:                 episode reward: -34.8000,                 loss: nan
env3_second_0:                 episode reward: 34.8000,                 loss: nan
env4_first_0:                 episode reward: -29.0500,                 loss: nan
env4_second_0:                 episode reward: 29.0500,                 loss: nan
Episode: 1781/10000 (17.8100%),                 avg. length: 295.9,                last time consumption/overall running time: 78.8573s / 7009.0987 s
env0_first_0:                 episode reward: -22.4000,                 loss: 89.9261
env0_second_0:                 episode reward: 22.4000,                 loss: nan
env1_first_0:                 episode reward: -33.4500,                 loss: nan
env1_second_0:                 episode reward: 33.4500,                 loss: nan
env2_first_0:                 episode reward: -44.6500,                 loss: nan
env2_second_0:                 episode reward: 44.6500,                 loss: nan
env3_first_0:                 episode reward: -39.0500,                 loss: nan
env3_second_0:                 episode reward: 39.0500,                 loss: nan
env4_first_0:                 episode reward: -34.4500,                 loss: nan
env4_second_0:                 episode reward: 34.4500,                 loss: nan
Episode: 1801/10000 (18.0100%),                 avg. length: 298.0,                last time consumption/overall running time: 78.8896s / 7087.9883 s
env0_first_0:                 episode reward: -16.2000,                 loss: 46.1548
env0_second_0:                 episode reward: 16.2000,                 loss: nan
env1_first_0:                 episode reward: -15.7500,                 loss: nan
env1_second_0:                 episode reward: 15.7500,                 loss: nan
env2_first_0:                 episode reward: -12.6000,                 loss: nan
env2_second_0:                 episode reward: 12.6000,                 loss: nan
env3_first_0:                 episode reward: -15.4500,                 loss: nan
env3_second_0:                 episode reward: 15.4500,                 loss: nan
env4_first_0:                 episode reward: -27.2000,                 loss: nan
env4_second_0:                 episode reward: 27.2000,                 loss: nan
Episode: 1821/10000 (18.2100%),                 avg. length: 298.95,                last time consumption/overall running time: 79.0129s / 7167.0012 s
env0_first_0:                 episode reward: -27.4000,                 loss: 55.5002
env0_second_0:                 episode reward: 27.4000,                 loss: nan
env1_first_0:                 episode reward: -30.0000,                 loss: nan
env1_second_0:                 episode reward: 30.0000,                 loss: nan
env2_first_0:                 episode reward: -19.4500,                 loss: nan
env2_second_0:                 episode reward: 19.4500,                 loss: nan
env3_first_0:                 episode reward: -24.0000,                 loss: nan
env3_second_0:                 episode reward: 24.0000,                 loss: nan
env4_first_0:                 episode reward: -30.7000,                 loss: nan
env4_second_0:                 episode reward: 30.7000,                 loss: nan
Episode: 1841/10000 (18.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.4046s / 7246.4058 s
env0_first_0:                 episode reward: -24.5500,                 loss: 45.4348
env0_second_0:                 episode reward: 24.5500,                 loss: nan
env1_first_0:                 episode reward: -26.5000,                 loss: nan
env1_second_0:                 episode reward: 26.5000,                 loss: nan
env2_first_0:                 episode reward: -16.9500,                 loss: nan
env2_second_0:                 episode reward: 16.9500,                 loss: nan
env3_first_0:                 episode reward: -20.9000,                 loss: nan
env3_second_0:                 episode reward: 20.9000,                 loss: nan
env4_first_0:                 episode reward: -23.2000,                 loss: nan
env4_second_0:                 episode reward: 23.2000,                 loss: nan
Episode: 1861/10000 (18.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.3918s / 7325.7976 s
env0_first_0:                 episode reward: -11.8500,                 loss: 38.8329
env0_second_0:                 episode reward: 11.8500,                 loss: nan
env1_first_0:                 episode reward: -15.9500,                 loss: nan
env1_second_0:                 episode reward: 15.9500,                 loss: nan
env2_first_0:                 episode reward: -17.5000,                 loss: nan
env2_second_0:                 episode reward: 17.5000,                 loss: nan
env3_first_0:                 episode reward: -18.6000,                 loss: nan
env3_second_0:                 episode reward: 18.6000,                 loss: nan
env4_first_0:                 episode reward: -15.7000,                 loss: nan
env4_second_0:                 episode reward: 15.7000,                 loss: nan
Episode: 1881/10000 (18.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.5874s / 7404.3849 s
env0_first_0:                 episode reward: -1.5500,                 loss: 0.4380
env0_second_0:                 episode reward: 1.5500,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: -0.2000,                 loss: nan
env2_second_0:                 episode reward: 0.2000,                 loss: nan
env3_first_0:                 episode reward: -0.2000,                 loss: nan
env3_second_0:                 episode reward: 0.2000,                 loss: nan
env4_first_0:                 episode reward: -1.4500,                 loss: nan
env4_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 1901/10000 (19.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.3958s / 7483.7807 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.8656
env0_second_0:                 episode reward: -0.0500,                 loss: nan
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
env3_first_0:                 episode reward: -0.2000,                 loss: nan
env3_second_0:                 episode reward: 0.2000,                 loss: nan
env4_first_0:                 episode reward: -0.0500,                 loss: nan
env4_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1921/10000 (19.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.9752s / 7562.7559 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.6012
env0_second_0:                 episode reward: 0.1500,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.0500,                 loss: nan
env2_second_0:                 episode reward: -0.0500,                 loss: nan
env3_first_0:                 episode reward: 0.1500,                 loss: nan
env3_second_0:                 episode reward: -0.1500,                 loss: nan
env4_first_0:                 episode reward: -0.3000,                 loss: nan
env4_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 1941/10000 (19.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.8362s / 7641.5922 s
env0_first_0:                 episode reward: -1.3500,                 loss: -0.2579
env0_second_0:                 episode reward: 1.3500,                 loss: nan
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
env2_first_0:                 episode reward: -0.6000,                 loss: nan
env2_second_0:                 episode reward: 0.6000,                 loss: nan
env3_first_0:                 episode reward: -0.3500,                 loss: nan
env3_second_0:                 episode reward: 0.3500,                 loss: nan
env4_first_0:                 episode reward: -0.4000,                 loss: nan
env4_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 1961/10000 (19.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.4064s / 7719.9986 s
env0_first_0:                 episode reward: -3.3500,                 loss: 1.4613
env0_second_0:                 episode reward: 3.3500,                 loss: nan
env1_first_0:                 episode reward: -1.9500,                 loss: nan
env1_second_0:                 episode reward: 1.9500,                 loss: nan
env2_first_0:                 episode reward: -0.4500,                 loss: nan
env2_second_0:                 episode reward: 0.4500,                 loss: nan
env3_first_0:                 episode reward: -1.1000,                 loss: nan
env3_second_0:                 episode reward: 1.1000,                 loss: nan
env4_first_0:                 episode reward: -2.7500,                 loss: nan
env4_second_0:                 episode reward: 2.7500,                 loss: nan
Episode: 1981/10000 (19.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.3905s / 7798.3891 s
env0_first_0:                 episode reward: -1.3000,                 loss: 1.5271
env0_second_0:                 episode reward: 1.3000,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: -0.7500,                 loss: nan
env2_second_0:                 episode reward: 0.7500,                 loss: nan
env3_first_0:                 episode reward: -2.1000,                 loss: nan
env3_second_0:                 episode reward: 2.1000,                 loss: nan
env4_first_0:                 episode reward: -0.3500,                 loss: nan
env4_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 2001/10000 (20.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.4878s / 7876.8769 s
env0_first_0:                 episode reward: -2.9500,                 loss: 5.5736
env0_second_0:                 episode reward: 2.9500,                 loss: nan
env1_first_0:                 episode reward: -4.1000,                 loss: nan
env1_second_0:                 episode reward: 4.1000,                 loss: nan
env2_first_0:                 episode reward: -4.7500,                 loss: nan
env2_second_0:                 episode reward: 4.7500,                 loss: nan
env3_first_0:                 episode reward: -3.0500,                 loss: nan
env3_second_0:                 episode reward: 3.0500,                 loss: nan
env4_first_0:                 episode reward: -4.6000,                 loss: nan
env4_second_0:                 episode reward: 4.6000,                 loss: nan
Episode: 2021/10000 (20.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.8413s / 7954.7182 s
env0_first_0:                 episode reward: -7.4000,                 loss: 12.6049
env0_second_0:                 episode reward: 7.4000,                 loss: nan
env1_first_0:                 episode reward: -5.0500,                 loss: nan
env1_second_0:                 episode reward: 5.0500,                 loss: nan
env2_first_0:                 episode reward: -8.6000,                 loss: nan
env2_second_0:                 episode reward: 8.6000,                 loss: nan
env3_first_0:                 episode reward: -7.8000,                 loss: nan
env3_second_0:                 episode reward: 7.8000,                 loss: nan
env4_first_0:                 episode reward: -6.8000,                 loss: nan
env4_second_0:                 episode reward: 6.8000,                 loss: nan
Episode: 2041/10000 (20.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.2989s / 8034.0171 s
env0_first_0:                 episode reward: -8.4000,                 loss: 15.0243
env0_second_0:                 episode reward: 8.4000,                 loss: nan
env1_first_0:                 episode reward: -4.9000,                 loss: nan
env1_second_0:                 episode reward: 4.9000,                 loss: nan
env2_first_0:                 episode reward: -8.9000,                 loss: nan
env2_second_0:                 episode reward: 8.9000,                 loss: nan
env3_first_0:                 episode reward: -4.9000,                 loss: nan
env3_second_0:                 episode reward: 4.9000,                 loss: nan
env4_first_0:                 episode reward: -8.1000,                 loss: nan
env4_second_0:                 episode reward: 8.1000,                 loss: nan
Episode: 2061/10000 (20.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.2808s / 8113.2979 s
env0_first_0:                 episode reward: -13.1500,                 loss: 24.1321
env0_second_0:                 episode reward: 13.1500,                 loss: nan
env1_first_0:                 episode reward: -8.7000,                 loss: nan
env1_second_0:                 episode reward: 8.7000,                 loss: nan
env2_first_0:                 episode reward: -6.2500,                 loss: nan
env2_second_0:                 episode reward: 6.2500,                 loss: nan
env3_first_0:                 episode reward: -18.4500,                 loss: nan
env3_second_0:                 episode reward: 18.4500,                 loss: nan
env4_first_0:                 episode reward: -10.2000,                 loss: nan
env4_second_0:                 episode reward: 10.2000,                 loss: nan
Episode: 2081/10000 (20.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.4980s / 8191.7959 s
env0_first_0:                 episode reward: -13.2000,                 loss: 34.4170
env0_second_0:                 episode reward: 13.2000,                 loss: nan
env1_first_0:                 episode reward: -21.7000,                 loss: nan
env1_second_0:                 episode reward: 21.7000,                 loss: nan
env2_first_0:                 episode reward: -17.8500,                 loss: nan
env2_second_0:                 episode reward: 17.8500,                 loss: nan
env3_first_0:                 episode reward: -16.7500,                 loss: nan
env3_second_0:                 episode reward: 16.7500,                 loss: nan
env4_first_0:                 episode reward: -19.7000,                 loss: nan
env4_second_0:                 episode reward: 19.7000,                 loss: nan
Episode: 2101/10000 (21.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.9234s / 8271.7193 s
env0_first_0:                 episode reward: -13.8000,                 loss: 28.6403
env0_second_0:                 episode reward: 13.8000,                 loss: nan
env1_first_0:                 episode reward: -15.0000,                 loss: nan
env1_second_0:                 episode reward: 15.0000,                 loss: nan
env2_first_0:                 episode reward: -12.1000,                 loss: nan
env2_second_0:                 episode reward: 12.1000,                 loss: nan
env3_first_0:                 episode reward: -9.7000,                 loss: nan
env3_second_0:                 episode reward: 9.7000,                 loss: nan
env4_first_0:                 episode reward: -21.0500,                 loss: nan
env4_second_0:                 episode reward: 21.0500,                 loss: nan
Episode: 2121/10000 (21.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.1309s / 8350.8501 s
env0_first_0:                 episode reward: -2.2000,                 loss: 3.0409
env0_second_0:                 episode reward: 2.2000,                 loss: nan
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
env2_first_0:                 episode reward: -1.5500,                 loss: nan
env2_second_0:                 episode reward: 1.5500,                 loss: nan
env3_first_0:                 episode reward: -2.7500,                 loss: nan
env3_second_0:                 episode reward: 2.7500,                 loss: nan
env4_first_0:                 episode reward: -0.5000,                 loss: nan
env4_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 2141/10000 (21.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.8241s / 8429.6742 s
env0_first_0:                 episode reward: -7.3500,                 loss: 19.4806
env0_second_0:                 episode reward: 7.3500,                 loss: nan
env1_first_0:                 episode reward: -11.3000,                 loss: nan
env1_second_0:                 episode reward: 11.3000,                 loss: nan
env2_first_0:                 episode reward: -6.0500,                 loss: nan
env2_second_0:                 episode reward: 6.0500,                 loss: nan
env3_first_0:                 episode reward: -9.4000,                 loss: nan
env3_second_0:                 episode reward: 9.4000,                 loss: nan
env4_first_0:                 episode reward: -7.6500,                 loss: nan
env4_second_0:                 episode reward: 7.6500,                 loss: nan
Episode: 2161/10000 (21.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.9135s / 8508.5877 s
env0_first_0:                 episode reward: -20.5000,                 loss: 44.6643
env0_second_0:                 episode reward: 20.5000,                 loss: nan
env1_first_0:                 episode reward: -26.6500,                 loss: nan
env1_second_0:                 episode reward: 26.6500,                 loss: nan
env2_first_0:                 episode reward: -24.1000,                 loss: nan
env2_second_0:                 episode reward: 24.1000,                 loss: nan
env3_first_0:                 episode reward: -20.4000,                 loss: nan
env3_second_0:                 episode reward: 20.4000,                 loss: nan
env4_first_0:                 episode reward: -20.5000,                 loss: nan
env4_second_0:                 episode reward: 20.5000,                 loss: nan
Episode: 2181/10000 (21.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.3418s / 8585.9295 s
env0_first_0:                 episode reward: -33.2000,                 loss: 49.1017
env0_second_0:                 episode reward: 33.2000,                 loss: nan
env1_first_0:                 episode reward: -29.3500,                 loss: nan
env1_second_0:                 episode reward: 29.3500,                 loss: nan
env2_first_0:                 episode reward: -24.9000,                 loss: nan
env2_second_0:                 episode reward: 24.9000,                 loss: nan
env3_first_0:                 episode reward: -17.7000,                 loss: nan
env3_second_0:                 episode reward: 17.7000,                 loss: nan
env4_first_0:                 episode reward: -30.3000,                 loss: nan
env4_second_0:                 episode reward: 30.3000,                 loss: nan
Episode: 2201/10000 (22.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.2975s / 8664.2269 s
env0_first_0:                 episode reward: -25.0500,                 loss: 46.0573
env0_second_0:                 episode reward: 25.0500,                 loss: nan
env1_first_0:                 episode reward: -21.8500,                 loss: nan
env1_second_0:                 episode reward: 21.8500,                 loss: nan
env2_first_0:                 episode reward: -24.0000,                 loss: nan
env2_second_0:                 episode reward: 24.0000,                 loss: nan
env3_first_0:                 episode reward: -25.1000,                 loss: nan
env3_second_0:                 episode reward: 25.1000,                 loss: nan
env4_first_0:                 episode reward: -25.4000,                 loss: nan
env4_second_0:                 episode reward: 25.4000,                 loss: nan
Episode: 2221/10000 (22.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.7161s / 8742.9431 s
env0_first_0:                 episode reward: -35.9000,                 loss: 59.4332
env0_second_0:                 episode reward: 35.9000,                 loss: nan
env1_first_0:                 episode reward: -33.7500,                 loss: nan
env1_second_0:                 episode reward: 33.7500,                 loss: nan
env2_first_0:                 episode reward: -29.2000,                 loss: nan
env2_second_0:                 episode reward: 29.2000,                 loss: nan
env3_first_0:                 episode reward: -35.9000,                 loss: nan
env3_second_0:                 episode reward: 35.9000,                 loss: nan
env4_first_0:                 episode reward: -26.3500,                 loss: nan
env4_second_0:                 episode reward: 26.3500,                 loss: nan
Episode: 2241/10000 (22.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.6203s / 8822.5634 s
env0_first_0:                 episode reward: -46.1000,                 loss: 69.6529
env0_second_0:                 episode reward: 46.1000,                 loss: nan
env1_first_0:                 episode reward: -48.9000,                 loss: nan
env1_second_0:                 episode reward: 48.9000,                 loss: nan
env2_first_0:                 episode reward: -34.3000,                 loss: nan
env2_second_0:                 episode reward: 34.3000,                 loss: nan
env3_first_0:                 episode reward: -49.7500,                 loss: nan
env3_second_0:                 episode reward: 49.7500,                 loss: nan
env4_first_0:                 episode reward: -43.6500,                 loss: nan
env4_second_0:                 episode reward: 43.6500,                 loss: nan
Episode: 2261/10000 (22.6100%),                 avg. length: 294.15,                last time consumption/overall running time: 77.6794s / 8900.2429 s
env0_first_0:                 episode reward: -47.9500,                 loss: 85.3226
env0_second_0:                 episode reward: 47.9500,                 loss: nan
env1_first_0:                 episode reward: -42.9000,                 loss: nan
env1_second_0:                 episode reward: 42.9000,                 loss: nan
env2_first_0:                 episode reward: -33.7500,                 loss: nan
env2_second_0:                 episode reward: 33.7500,                 loss: nan
env3_first_0:                 episode reward: -42.6500,                 loss: nan
env3_second_0:                 episode reward: 42.6500,                 loss: nan
env4_first_0:                 episode reward: -43.6500,                 loss: nan
env4_second_0:                 episode reward: 43.6500,                 loss: nan
Episode: 2281/10000 (22.8100%),                 avg. length: 272.6,                last time consumption/overall running time: 74.1566s / 8974.3995 s
env0_first_0:                 episode reward: -51.4000,                 loss: 114.9455
env0_second_0:                 episode reward: 51.4000,                 loss: nan
env1_first_0:                 episode reward: -45.5500,                 loss: nan
env1_second_0:                 episode reward: 45.5500,                 loss: nan
env2_first_0:                 episode reward: -54.4000,                 loss: nan
env2_second_0:                 episode reward: 54.4000,                 loss: nan
env3_first_0:                 episode reward: -52.7000,                 loss: nan
env3_second_0:                 episode reward: 52.7000,                 loss: nan
env4_first_0:                 episode reward: -48.8000,                 loss: nan
env4_second_0:                 episode reward: 48.8000,                 loss: nan
Episode: 2301/10000 (23.0100%),                 avg. length: 287.25,                last time consumption/overall running time: 77.4575s / 9051.8570 s
env0_first_0:                 episode reward: -46.1500,                 loss: 99.5894
env0_second_0:                 episode reward: 46.1500,                 loss: nan
env1_first_0:                 episode reward: -56.3000,                 loss: nan
env1_second_0:                 episode reward: 56.3000,                 loss: nan
env2_first_0:                 episode reward: -54.0500,                 loss: nan
env2_second_0:                 episode reward: 54.0500,                 loss: nan
env3_first_0:                 episode reward: -54.4500,                 loss: nan
env3_second_0:                 episode reward: 54.4500,                 loss: nan
env4_first_0:                 episode reward: -44.6500,                 loss: nan
env4_second_0:                 episode reward: 44.6500,                 loss: nan
Episode: 2321/10000 (23.2100%),                 avg. length: 285.55,                last time consumption/overall running time: 76.2014s / 9128.0584 s
env0_first_0:                 episode reward: -43.0000,                 loss: 96.9639
env0_second_0:                 episode reward: 43.0000,                 loss: nan
env1_first_0:                 episode reward: -47.2500,                 loss: nan
env1_second_0:                 episode reward: 47.2500,                 loss: nan
env2_first_0:                 episode reward: -42.3500,                 loss: nan
env2_second_0:                 episode reward: 42.3500,                 loss: nan
env3_first_0:                 episode reward: -57.8000,                 loss: nan
env3_second_0:                 episode reward: 57.8000,                 loss: nan
env4_first_0:                 episode reward: -53.6000,                 loss: nan
env4_second_0:                 episode reward: 53.6000,                 loss: nan
Episode: 2341/10000 (23.4100%),                 avg. length: 257.9,                last time consumption/overall running time: 70.4140s / 9198.4724 s
env0_first_0:                 episode reward: -58.7500,                 loss: 104.4435
env0_second_0:                 episode reward: 58.7500,                 loss: nan
env1_first_0:                 episode reward: -71.3000,                 loss: nan
env1_second_0:                 episode reward: 71.3000,                 loss: nan
env2_first_0:                 episode reward: -68.9000,                 loss: nan
env2_second_0:                 episode reward: 68.9000,                 loss: nan
env3_first_0:                 episode reward: -64.0500,                 loss: nan
env3_second_0:                 episode reward: 64.0500,                 loss: nan
env4_first_0:                 episode reward: -74.0000,                 loss: nan
env4_second_0:                 episode reward: 74.0000,                 loss: nan
Episode: 2361/10000 (23.6100%),                 avg. length: 277.05,                last time consumption/overall running time: 75.3993s / 9273.8717 s
env0_first_0:                 episode reward: -43.0500,                 loss: 77.7348
env0_second_0:                 episode reward: 43.0500,                 loss: nan
env1_first_0:                 episode reward: -43.0000,                 loss: nan
env1_second_0:                 episode reward: 43.0000,                 loss: nan
env2_first_0:                 episode reward: -36.8500,                 loss: nan
env2_second_0:                 episode reward: 36.8500,                 loss: nan
env3_first_0:                 episode reward: -44.6500,                 loss: nan
env3_second_0:                 episode reward: 44.6500,                 loss: nan
env4_first_0:                 episode reward: -25.7000,                 loss: nan
env4_second_0:                 episode reward: 25.7000,                 loss: nan
Episode: 2381/10000 (23.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.7205s / 9352.5922 s
env0_first_0:                 episode reward: -0.9500,                 loss: 2.6968
env0_second_0:                 episode reward: 0.9500,                 loss: nan
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
env2_first_0:                 episode reward: -0.2500,                 loss: nan
env2_second_0:                 episode reward: 0.2500,                 loss: nan
env3_first_0:                 episode reward: 0.4000,                 loss: nan
env3_second_0:                 episode reward: -0.4000,                 loss: nan
env4_first_0:                 episode reward: -2.1000,                 loss: nan
env4_second_0:                 episode reward: 2.1000,                 loss: nan
Episode: 2401/10000 (24.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.7324s / 9431.3246 s
env0_first_0:                 episode reward: -1.1500,                 loss: 5.8157
env0_second_0:                 episode reward: 1.1500,                 loss: nan
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
env2_first_0:                 episode reward: -4.5000,                 loss: nan
env2_second_0:                 episode reward: 4.5000,                 loss: nan
env3_first_0:                 episode reward: -6.1500,                 loss: nan
env3_second_0:                 episode reward: 6.1500,                 loss: nan
env4_first_0:                 episode reward: -1.8000,                 loss: nan
env4_second_0:                 episode reward: 1.8000,                 loss: nan
Episode: 2421/10000 (24.2100%),                 avg. length: 294.85,                last time consumption/overall running time: 77.9658s / 9509.2905 s
env0_first_0:                 episode reward: -25.5000,                 loss: 68.4543
env0_second_0:                 episode reward: 25.5000,                 loss: nan
env1_first_0:                 episode reward: -29.6000,                 loss: nan
env1_second_0:                 episode reward: 29.6000,                 loss: nan
env2_first_0:                 episode reward: -27.7500,                 loss: nan
env2_second_0:                 episode reward: 27.7500,                 loss: nan
env3_first_0:                 episode reward: -23.7500,                 loss: nan
env3_second_0:                 episode reward: 23.7500,                 loss: nan
env4_first_0:                 episode reward: -23.5000,                 loss: nan
env4_second_0:                 episode reward: 23.5000,                 loss: nan
Episode: 2441/10000 (24.4100%),                 avg. length: 288.35,                last time consumption/overall running time: 77.7670s / 9587.0575 s
env0_first_0:                 episode reward: -21.2500,                 loss: 61.9110
env0_second_0:                 episode reward: 21.2500,                 loss: nan
env1_first_0:                 episode reward: -26.5500,                 loss: nan
env1_second_0:                 episode reward: 26.5500,                 loss: nan
env2_first_0:                 episode reward: -29.4000,                 loss: nan
env2_second_0:                 episode reward: 29.4000,                 loss: nan
env3_first_0:                 episode reward: -30.3000,                 loss: nan
env3_second_0:                 episode reward: 30.3000,                 loss: nan
env4_first_0:                 episode reward: -15.2500,                 loss: nan
env4_second_0:                 episode reward: 15.2500,                 loss: nan
Episode: 2461/10000 (24.6100%),                 avg. length: 295.15,                last time consumption/overall running time: 78.5038s / 9665.5613 s
env0_first_0:                 episode reward: -0.8500,                 loss: 25.2021
env0_second_0:                 episode reward: 0.8500,                 loss: nan
env1_first_0:                 episode reward: -17.3000,                 loss: nan
env1_second_0:                 episode reward: 17.3000,                 loss: nan
env2_first_0:                 episode reward: -7.5500,                 loss: nan
env2_second_0:                 episode reward: 7.5500,                 loss: nan
env3_first_0:                 episode reward: -8.1500,                 loss: nan
env3_second_0:                 episode reward: 8.1500,                 loss: nan
env4_first_0:                 episode reward: -1.8000,                 loss: nan
env4_second_0:                 episode reward: 1.8000,                 loss: nan
Episode: 2481/10000 (24.8100%),                 avg. length: 297.95,                last time consumption/overall running time: 79.0171s / 9744.5785 s
env0_first_0:                 episode reward: -28.5500,                 loss: 72.5319
env0_second_0:                 episode reward: 28.5500,                 loss: nan
env1_first_0:                 episode reward: -48.3500,                 loss: nan
env1_second_0:                 episode reward: 48.3500,                 loss: nan
env2_first_0:                 episode reward: -30.5500,                 loss: nan
env2_second_0:                 episode reward: 30.5500,                 loss: nan
env3_first_0:                 episode reward: -30.4500,                 loss: nan
env3_second_0:                 episode reward: 30.4500,                 loss: nan
env4_first_0:                 episode reward: -28.4000,                 loss: nan
env4_second_0:                 episode reward: 28.4000,                 loss: nan
Episode: 2501/10000 (25.0100%),                 avg. length: 273.25,                last time consumption/overall running time: 74.5267s / 9819.1051 s
env0_first_0:                 episode reward: -58.6500,                 loss: 108.9637
env0_second_0:                 episode reward: 58.6500,                 loss: nan
env1_first_0:                 episode reward: -48.9000,                 loss: nan
env1_second_0:                 episode reward: 48.9000,                 loss: nan
env2_first_0:                 episode reward: -58.7000,                 loss: nan
env2_second_0:                 episode reward: 58.7000,                 loss: nan
env3_first_0:                 episode reward: -53.0000,                 loss: nan
env3_second_0:                 episode reward: 53.0000,                 loss: nan
env4_first_0:                 episode reward: -61.0000,                 loss: nan
env4_second_0:                 episode reward: 61.0000,                 loss: nan
Episode: 2521/10000 (25.2100%),                 avg. length: 258.85,                last time consumption/overall running time: 69.9286s / 9889.0337 s
env0_first_0:                 episode reward: -75.4000,                 loss: 122.1862
env0_second_0:                 episode reward: 75.4000,                 loss: nan
env1_first_0:                 episode reward: -78.7000,                 loss: nan
env1_second_0:                 episode reward: 78.7000,                 loss: nan
env2_first_0:                 episode reward: -75.5500,                 loss: nan
env2_second_0:                 episode reward: 75.5500,                 loss: nan
env3_first_0:                 episode reward: -66.2000,                 loss: nan
env3_second_0:                 episode reward: 66.2000,                 loss: nan
env4_first_0:                 episode reward: -66.2000,                 loss: nan
env4_second_0:                 episode reward: 66.2000,                 loss: nan
Episode: 2541/10000 (25.4100%),                 avg. length: 255.1,                last time consumption/overall running time: 71.4952s / 9960.5289 s
env0_first_0:                 episode reward: -75.4000,                 loss: 128.5374
env0_second_0:                 episode reward: 75.4000,                 loss: nan
env1_first_0:                 episode reward: -72.8000,                 loss: nan
env1_second_0:                 episode reward: 72.8000,                 loss: nan
env2_first_0:                 episode reward: -74.2500,                 loss: nan
env2_second_0:                 episode reward: 74.2500,                 loss: nan
env3_first_0:                 episode reward: -76.1500,                 loss: nan
env3_second_0:                 episode reward: 76.1500,                 loss: nan
env4_first_0:                 episode reward: -68.0000,                 loss: nan
env4_second_0:                 episode reward: 68.0000,                 loss: nan
Episode: 2561/10000 (25.6100%),                 avg. length: 281.45,                last time consumption/overall running time: 75.2022s / 10035.7311 s
env0_first_0:                 episode reward: -27.1000,                 loss: 88.0607
env0_second_0:                 episode reward: 27.1000,                 loss: nan
env1_first_0:                 episode reward: -27.6000,                 loss: nan
env1_second_0:                 episode reward: 27.6000,                 loss: nan
env2_first_0:                 episode reward: -26.2000,                 loss: nan
env2_second_0:                 episode reward: 26.2000,                 loss: nan
env3_first_0:                 episode reward: -29.3500,                 loss: nan
env3_second_0:                 episode reward: 29.3500,                 loss: nan
env4_first_0:                 episode reward: -48.1000,                 loss: nan
env4_second_0:                 episode reward: 48.1000,                 loss: nan
Episode: 2581/10000 (25.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.9070s / 10115.6382 s
env0_first_0:                 episode reward: -3.2500,                 loss: 17.2074
env0_second_0:                 episode reward: 3.2500,                 loss: nan
env1_first_0:                 episode reward: -5.7500,                 loss: nan
env1_second_0:                 episode reward: 5.7500,                 loss: nan
env2_first_0:                 episode reward: -3.7000,                 loss: nan
env2_second_0:                 episode reward: 3.7000,                 loss: nan
env3_first_0:                 episode reward: -2.9500,                 loss: nan
env3_second_0:                 episode reward: 2.9500,                 loss: nan
env4_first_0:                 episode reward: -8.6500,                 loss: nan
env4_second_0:                 episode reward: 8.6500,                 loss: nan
Episode: 2601/10000 (26.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.7791s / 10195.4172 s
env0_first_0:                 episode reward: -1.3000,                 loss: 4.5383
env0_second_0:                 episode reward: 1.3000,                 loss: nan
env1_first_0:                 episode reward: -4.5500,                 loss: nan
env1_second_0:                 episode reward: 4.5500,                 loss: nan
env2_first_0:                 episode reward: -0.5000,                 loss: nan
env2_second_0:                 episode reward: 0.5000,                 loss: nan
env3_first_0:                 episode reward: -0.5000,                 loss: nan
env3_second_0:                 episode reward: 0.5000,                 loss: nan
env4_first_0:                 episode reward: -1.3000,                 loss: nan
env4_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 2621/10000 (26.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.0172s / 10275.4345 s
env0_first_0:                 episode reward: -2.8500,                 loss: 5.7452
env0_second_0:                 episode reward: 2.8500,                 loss: nan
env1_first_0:                 episode reward: -3.1500,                 loss: nan
env1_second_0:                 episode reward: 3.1500,                 loss: nan
env2_first_0:                 episode reward: -1.7500,                 loss: nan
env2_second_0:                 episode reward: 1.7500,                 loss: nan
env3_first_0:                 episode reward: -1.0000,                 loss: nan
env3_second_0:                 episode reward: 1.0000,                 loss: nan
env4_first_0:                 episode reward: -2.8000,                 loss: nan
env4_second_0:                 episode reward: 2.8000,                 loss: nan
Episode: 2641/10000 (26.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.6257s / 10355.0601 s
env0_first_0:                 episode reward: -3.3000,                 loss: 4.3560
env0_second_0:                 episode reward: 3.3000,                 loss: nan
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
env2_first_0:                 episode reward: -3.8000,                 loss: nan
env2_second_0:                 episode reward: 3.8000,                 loss: nan
env3_first_0:                 episode reward: -7.0500,                 loss: nan
env3_second_0:                 episode reward: 7.0500,                 loss: nan
env4_first_0:                 episode reward: -1.3500,                 loss: nan
env4_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 2661/10000 (26.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.5799s / 10433.6400 s
env0_first_0:                 episode reward: -4.5000,                 loss: 5.3579
env0_second_0:                 episode reward: 4.5000,                 loss: nan
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
env2_first_0:                 episode reward: -2.5000,                 loss: nan
env2_second_0:                 episode reward: 2.5000,                 loss: nan
env3_first_0:                 episode reward: -2.6500,                 loss: nan
env3_second_0:                 episode reward: 2.6500,                 loss: nan
env4_first_0:                 episode reward: -1.1500,                 loss: nan
env4_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 2681/10000 (26.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.5991s / 10514.2392 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0738
env0_second_0:                 episode reward: -0.1000,                 loss: nan
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: -0.5000,                 loss: nan
env2_second_0:                 episode reward: 0.5000,                 loss: nan
env3_first_0:                 episode reward: -1.8500,                 loss: nan
env3_second_0:                 episode reward: 1.8500,                 loss: nan
env4_first_0:                 episode reward: -0.3500,                 loss: nan
env4_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 2701/10000 (27.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.4986s / 10593.7378 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0413
env0_second_0:                 episode reward: 0.2000,                 loss: nan
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
env2_first_0:                 episode reward: -1.0500,                 loss: nan
env2_second_0:                 episode reward: 1.0500,                 loss: nan
env3_first_0:                 episode reward: -1.5000,                 loss: nan
env3_second_0:                 episode reward: 1.5000,                 loss: nan
env4_first_0:                 episode reward: 0.4500,                 loss: nan
env4_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 2721/10000 (27.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.4155s / 10673.1533 s
env0_first_0:                 episode reward: -5.0500,                 loss: 8.6169
env0_second_0:                 episode reward: 5.0500,                 loss: nan
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
env2_first_0:                 episode reward: -5.5500,                 loss: nan
env2_second_0:                 episode reward: 5.5500,                 loss: nan
env3_first_0:                 episode reward: -5.3000,                 loss: nan
env3_second_0:                 episode reward: 5.3000,                 loss: nan
env4_first_0:                 episode reward: -4.5000,                 loss: nan
env4_second_0:                 episode reward: 4.5000,                 loss: nan
Episode: 2741/10000 (27.4100%),                 avg. length: 298.1,                last time consumption/overall running time: 78.7531s / 10751.9063 s
env0_first_0:                 episode reward: -27.2000,                 loss: 65.2417
env0_second_0:                 episode reward: 27.2000,                 loss: nan
env1_first_0:                 episode reward: -25.5500,                 loss: nan
env1_second_0:                 episode reward: 25.5500,                 loss: nan
env2_first_0:                 episode reward: -34.2000,                 loss: nan
env2_second_0:                 episode reward: 34.2000,                 loss: nan
env3_first_0:                 episode reward: -32.4000,                 loss: nan
env3_second_0:                 episode reward: 32.4000,                 loss: nan
env4_first_0:                 episode reward: -24.7500,                 loss: nan
env4_second_0:                 episode reward: 24.7500,                 loss: nan
Episode: 2761/10000 (27.6100%),                 avg. length: 296.6,                last time consumption/overall running time: 79.1581s / 10831.0644 s
env0_first_0:                 episode reward: -43.8500,                 loss: 77.8996
env0_second_0:                 episode reward: 43.8500,                 loss: nan
env1_first_0:                 episode reward: -38.4000,                 loss: nan
env1_second_0:                 episode reward: 38.4000,                 loss: nan
env2_first_0:                 episode reward: -51.8000,                 loss: nan
env2_second_0:                 episode reward: 51.8000,                 loss: nan
env3_first_0:                 episode reward: -39.9500,                 loss: nan
env3_second_0:                 episode reward: 39.9500,                 loss: nan
env4_first_0:                 episode reward: -41.7000,                 loss: nan
env4_second_0:                 episode reward: 41.7000,                 loss: nan
Episode: 2781/10000 (27.8100%),                 avg. length: 297.6,                last time consumption/overall running time: 79.9110s / 10910.9755 s
env0_first_0:                 episode reward: -54.1500,                 loss: 88.4941
env0_second_0:                 episode reward: 54.1500,                 loss: nan
env1_first_0:                 episode reward: -46.5500,                 loss: nan
env1_second_0:                 episode reward: 46.5500,                 loss: nan
env2_first_0:                 episode reward: -45.1500,                 loss: nan
env2_second_0:                 episode reward: 45.1500,                 loss: nan
env3_first_0:                 episode reward: -47.9500,                 loss: nan
env3_second_0:                 episode reward: 47.9500,                 loss: nan
env4_first_0:                 episode reward: -42.9500,                 loss: nan
env4_second_0:                 episode reward: 42.9500,                 loss: nan
Episode: 2801/10000 (28.0100%),                 avg. length: 291.45,                last time consumption/overall running time: 77.6408s / 10988.6163 s
env0_first_0:                 episode reward: -54.6000,                 loss: 99.9900
env0_second_0:                 episode reward: 54.6000,                 loss: nan
env1_first_0:                 episode reward: -59.5500,                 loss: nan
env1_second_0:                 episode reward: 59.5500,                 loss: nan
env2_first_0:                 episode reward: -38.8000,                 loss: nan
env2_second_0:                 episode reward: 38.8000,                 loss: nan
env3_first_0:                 episode reward: -47.7000,                 loss: nan
env3_second_0:                 episode reward: 47.7000,                 loss: nan
env4_first_0:                 episode reward: -52.1000,                 loss: nan
env4_second_0:                 episode reward: 52.1000,                 loss: nan
Episode: 2821/10000 (28.2100%),                 avg. length: 277.65,                last time consumption/overall running time: 74.5396s / 11063.1559 s
env0_first_0:                 episode reward: -48.0000,                 loss: 104.9916
env0_second_0:                 episode reward: 48.0000,                 loss: nan
env1_first_0:                 episode reward: -50.8000,                 loss: nan
env1_second_0:                 episode reward: 50.8000,                 loss: nan
env2_first_0:                 episode reward: -35.1500,                 loss: nan
env2_second_0:                 episode reward: 35.1500,                 loss: nan
env3_first_0:                 episode reward: -43.9000,                 loss: nan
env3_second_0:                 episode reward: 43.9000,                 loss: nan
env4_first_0:                 episode reward: -43.1500,                 loss: nan
env4_second_0:                 episode reward: 43.1500,                 loss: nan
Episode: 2841/10000 (28.4100%),                 avg. length: 297.55,                last time consumption/overall running time: 79.0421s / 11142.1980 s
env0_first_0:                 episode reward: -2.1000,                 loss: 45.5773
env0_second_0:                 episode reward: 2.1000,                 loss: nan
env1_first_0:                 episode reward: -10.2000,                 loss: nan
env1_second_0:                 episode reward: 10.2000,                 loss: nan
env2_first_0:                 episode reward: -18.5500,                 loss: nan
env2_second_0:                 episode reward: 18.5500,                 loss: nan
env3_first_0:                 episode reward: -10.2500,                 loss: nan
env3_second_0:                 episode reward: 10.2500,                 loss: nan
env4_first_0:                 episode reward: -12.9500,                 loss: nan
env4_second_0:                 episode reward: 12.9500,                 loss: nan
Episode: 2861/10000 (28.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.8188s / 11223.0168 s
env0_first_0:                 episode reward: -1.9500,                 loss: 3.4803
env0_second_0:                 episode reward: 1.9500,                 loss: nan
env1_first_0:                 episode reward: -2.1000,                 loss: nan
env1_second_0:                 episode reward: 2.1000,                 loss: nan
env2_first_0:                 episode reward: -0.3000,                 loss: nan
env2_second_0:                 episode reward: 0.3000,                 loss: nan
env3_first_0:                 episode reward: -2.1500,                 loss: nan
env3_second_0:                 episode reward: 2.1500,                 loss: nan
env4_first_0:                 episode reward: -0.5500,                 loss: nan
env4_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 2881/10000 (28.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.0696s / 11302.0864 s
env0_first_0:                 episode reward: -1.3500,                 loss: 1.3295
env0_second_0:                 episode reward: 1.3500,                 loss: nan
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
env2_first_0:                 episode reward: -0.6000,                 loss: nan
env2_second_0:                 episode reward: 0.6000,                 loss: nan
env3_first_0:                 episode reward: -1.5500,                 loss: nan
env3_second_0:                 episode reward: 1.5500,                 loss: nan
env4_first_0:                 episode reward: -0.9000,                 loss: nan
env4_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 2901/10000 (29.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.1023s / 11381.1887 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.1863
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
env2_first_0:                 episode reward: -0.8000,                 loss: nan
env2_second_0:                 episode reward: 0.8000,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: -0.5500,                 loss: nan
env4_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 2921/10000 (29.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.5799s / 11461.7686 s
env0_first_0:                 episode reward: -2.9000,                 loss: 4.4097
env0_second_0:                 episode reward: 2.9000,                 loss: nan
env1_first_0:                 episode reward: -1.6500,                 loss: nan
env1_second_0:                 episode reward: 1.6500,                 loss: nan
env2_first_0:                 episode reward: -5.3500,                 loss: nan
env2_second_0:                 episode reward: 5.3500,                 loss: nan
env3_first_0:                 episode reward: -2.8500,                 loss: nan
env3_second_0:                 episode reward: 2.8500,                 loss: nan
env4_first_0:                 episode reward: -2.0000,                 loss: nan
env4_second_0:                 episode reward: 2.0000,                 loss: nan
Episode: 2941/10000 (29.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.5748s / 11542.3434 s
env0_first_0:                 episode reward: -6.9000,                 loss: 11.1455
env0_second_0:                 episode reward: 6.9000,                 loss: nan
env1_first_0:                 episode reward: -6.6500,                 loss: nan
env1_second_0:                 episode reward: 6.6500,                 loss: nan
env2_first_0:                 episode reward: -4.7000,                 loss: nan
env2_second_0:                 episode reward: 4.7000,                 loss: nan
env3_first_0:                 episode reward: -7.1500,                 loss: nan
env3_second_0:                 episode reward: 7.1500,                 loss: nan
env4_first_0:                 episode reward: -3.5500,                 loss: nan
env4_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 2961/10000 (29.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.5586s / 11622.9020 s
env0_first_0:                 episode reward: -8.8500,                 loss: 23.1611
env0_second_0:                 episode reward: 8.8500,                 loss: nan
env1_first_0:                 episode reward: -7.8000,                 loss: nan
env1_second_0:                 episode reward: 7.8000,                 loss: nan
env2_first_0:                 episode reward: -10.2500,                 loss: nan
env2_second_0:                 episode reward: 10.2500,                 loss: nan
env3_first_0:                 episode reward: -5.9500,                 loss: nan
env3_second_0:                 episode reward: 5.9500,                 loss: nan
env4_first_0:                 episode reward: -12.5500,                 loss: nan
env4_second_0:                 episode reward: 12.5500,                 loss: nan
Episode: 2981/10000 (29.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.3711s / 11702.2731 s
env0_first_0:                 episode reward: -16.3000,                 loss: 30.2896
env0_second_0:                 episode reward: 16.3000,                 loss: nan
env1_first_0:                 episode reward: -17.0500,                 loss: nan
env1_second_0:                 episode reward: 17.0500,                 loss: nan
env2_first_0:                 episode reward: -10.6500,                 loss: nan
env2_second_0:                 episode reward: 10.6500,                 loss: nan
env3_first_0:                 episode reward: -8.9000,                 loss: nan
env3_second_0:                 episode reward: 8.9000,                 loss: nan
env4_first_0:                 episode reward: -15.8500,                 loss: nan
env4_second_0:                 episode reward: 15.8500,                 loss: nan
Episode: 3001/10000 (30.0100%),                 avg. length: 295.9,                last time consumption/overall running time: 79.1445s / 11781.4176 s
env0_first_0:                 episode reward: -34.6500,                 loss: 73.9932
env0_second_0:                 episode reward: 34.6500,                 loss: nan
env1_first_0:                 episode reward: -40.8000,                 loss: nan
env1_second_0:                 episode reward: 40.8000,                 loss: nan
env2_first_0:                 episode reward: -40.0000,                 loss: nan
env2_second_0:                 episode reward: 40.0000,                 loss: nan
env3_first_0:                 episode reward: -41.1000,                 loss: nan
env3_second_0:                 episode reward: 41.1000,                 loss: nan
env4_first_0:                 episode reward: -39.2000,                 loss: nan
env4_second_0:                 episode reward: 39.2000,                 loss: nan
Episode: 3021/10000 (30.2100%),                 avg. length: 293.4,                last time consumption/overall running time: 79.6179s / 11861.0354 s
env0_first_0:                 episode reward: -55.1500,                 loss: 96.2432
env0_second_0:                 episode reward: 55.1500,                 loss: nan
env1_first_0:                 episode reward: -43.6500,                 loss: nan
env1_second_0:                 episode reward: 43.6500,                 loss: nan
env2_first_0:                 episode reward: -46.5500,                 loss: nan
env2_second_0:                 episode reward: 46.5500,                 loss: nan
env3_first_0:                 episode reward: -45.5500,                 loss: nan
env3_second_0:                 episode reward: 45.5500,                 loss: nan
env4_first_0:                 episode reward: -41.4500,                 loss: nan
env4_second_0:                 episode reward: 41.4500,                 loss: nan
Episode: 3041/10000 (30.4100%),                 avg. length: 281.65,                last time consumption/overall running time: 76.1140s / 11937.1495 s
env0_first_0:                 episode reward: -38.8000,                 loss: 124.0103
env0_second_0:                 episode reward: 38.8000,                 loss: nan
env1_first_0:                 episode reward: -67.6500,                 loss: nan
env1_second_0:                 episode reward: 67.6500,                 loss: nan
env2_first_0:                 episode reward: -57.4000,                 loss: nan
env2_second_0:                 episode reward: 57.4000,                 loss: nan
env3_first_0:                 episode reward: -43.5500,                 loss: nan
env3_second_0:                 episode reward: 43.5500,                 loss: nan
env4_first_0:                 episode reward: -46.3000,                 loss: nan
env4_second_0:                 episode reward: 46.3000,                 loss: nan
Episode: 3061/10000 (30.6100%),                 avg. length: 283.65,                last time consumption/overall running time: 76.9953s / 12014.1448 s
env0_first_0:                 episode reward: -42.7000,                 loss: 102.6875
env0_second_0:                 episode reward: 42.7000,                 loss: nan
env1_first_0:                 episode reward: -48.5000,                 loss: nan
env1_second_0:                 episode reward: 48.5000,                 loss: nan
env2_first_0:                 episode reward: -46.8500,                 loss: nan
env2_second_0:                 episode reward: 46.8500,                 loss: nan
env3_first_0:                 episode reward: -66.0000,                 loss: nan
env3_second_0:                 episode reward: 66.0000,                 loss: nan
env4_first_0:                 episode reward: -56.6000,                 loss: nan
env4_second_0:                 episode reward: 56.6000,                 loss: nan
Episode: 3081/10000 (30.8100%),                 avg. length: 282.2,                last time consumption/overall running time: 77.1975s / 12091.3423 s
env0_first_0:                 episode reward: -61.5500,                 loss: 105.1957
env0_second_0:                 episode reward: 61.5500,                 loss: nan
env1_first_0:                 episode reward: -57.0000,                 loss: nan
env1_second_0:                 episode reward: 57.0000,                 loss: nan
env2_first_0:                 episode reward: -59.0500,                 loss: nan
env2_second_0:                 episode reward: 59.0500,                 loss: nan
env3_first_0:                 episode reward: -52.1500,                 loss: nan
env3_second_0:                 episode reward: 52.1500,                 loss: nan
env4_first_0:                 episode reward: -54.4500,                 loss: nan
env4_second_0:                 episode reward: 54.4500,                 loss: nan
Episode: 3101/10000 (31.0100%),                 avg. length: 265.45,                last time consumption/overall running time: 73.6343s / 12164.9765 s
env0_first_0:                 episode reward: -50.3000,                 loss: 130.0373
env0_second_0:                 episode reward: 50.3000,                 loss: nan
env1_first_0:                 episode reward: -55.0500,                 loss: nan
env1_second_0:                 episode reward: 55.0500,                 loss: nan
env2_first_0:                 episode reward: -67.5500,                 loss: nan
env2_second_0:                 episode reward: 67.5500,                 loss: nan
env3_first_0:                 episode reward: -60.7500,                 loss: nan
env3_second_0:                 episode reward: 60.7500,                 loss: nan
env4_first_0:                 episode reward: -36.8500,                 loss: nan
env4_second_0:                 episode reward: 36.8500,                 loss: nan
Episode: 3121/10000 (31.2100%),                 avg. length: 289.35,                last time consumption/overall running time: 76.3061s / 12241.2826 s
env0_first_0:                 episode reward: -40.0500,                 loss: 84.1623
env0_second_0:                 episode reward: 40.0500,                 loss: nan
env1_first_0:                 episode reward: -22.3000,                 loss: nan
env1_second_0:                 episode reward: 22.3000,                 loss: nan
env2_first_0:                 episode reward: -37.1000,                 loss: nan
env2_second_0:                 episode reward: 37.1000,                 loss: nan
env3_first_0:                 episode reward: -23.2500,                 loss: nan
env3_second_0:                 episode reward: 23.2500,                 loss: nan
env4_first_0:                 episode reward: -30.5500,                 loss: nan
env4_second_0:                 episode reward: 30.5500,                 loss: nan
Episode: 3141/10000 (31.4100%),                 avg. length: 277.65,                last time consumption/overall running time: 74.5573s / 12315.8399 s
env0_first_0:                 episode reward: -25.7500,                 loss: 69.8638
env0_second_0:                 episode reward: 25.7500,                 loss: nan
env1_first_0:                 episode reward: -16.1500,                 loss: nan
env1_second_0:                 episode reward: 16.1500,                 loss: nan
env2_first_0:                 episode reward: -13.1000,                 loss: nan
env2_second_0:                 episode reward: 13.1000,                 loss: nan
env3_first_0:                 episode reward: -11.2000,                 loss: nan
env3_second_0:                 episode reward: 11.2000,                 loss: nan
env4_first_0:                 episode reward: -15.8000,                 loss: nan
env4_second_0:                 episode reward: 15.8000,                 loss: nan
Episode: 3161/10000 (31.6100%),                 avg. length: 288.15,                last time consumption/overall running time: 78.1372s / 12393.9772 s
env0_first_0:                 episode reward: -59.2000,                 loss: 96.2097
env0_second_0:                 episode reward: 59.2000,                 loss: nan
env1_first_0:                 episode reward: -50.4500,                 loss: nan
env1_second_0:                 episode reward: 50.4500,                 loss: nan
env2_first_0:                 episode reward: -46.3500,                 loss: nan
env2_second_0:                 episode reward: 46.3500,                 loss: nan
env3_first_0:                 episode reward: -44.7500,                 loss: nan
env3_second_0:                 episode reward: 44.7500,                 loss: nan
env4_first_0:                 episode reward: -49.6000,                 loss: nan
env4_second_0:                 episode reward: 49.6000,                 loss: nan
Episode: 3181/10000 (31.8100%),                 avg. length: 271.1,                last time consumption/overall running time: 72.9367s / 12466.9138 s
env0_first_0:                 episode reward: -56.3500,                 loss: 134.2608
env0_second_0:                 episode reward: 56.3500,                 loss: nan
env1_first_0:                 episode reward: -65.1000,                 loss: nan
env1_second_0:                 episode reward: 65.1000,                 loss: nan
env2_first_0:                 episode reward: -57.7000,                 loss: nan
env2_second_0:                 episode reward: 57.7000,                 loss: nan
env3_first_0:                 episode reward: -51.8500,                 loss: nan
env3_second_0:                 episode reward: 51.8500,                 loss: nan
env4_first_0:                 episode reward: -54.8000,                 loss: nan
env4_second_0:                 episode reward: 54.8000,                 loss: nan
Episode: 3201/10000 (32.0100%),                 avg. length: 273.3,                last time consumption/overall running time: 74.4550s / 12541.3688 s
env0_first_0:                 episode reward: -46.8000,                 loss: 137.7791
env0_second_0:                 episode reward: 46.8000,                 loss: nan
env1_first_0:                 episode reward: -51.9500,                 loss: nan
env1_second_0:                 episode reward: 51.9500,                 loss: nan
env2_first_0:                 episode reward: -57.6000,                 loss: nan
env2_second_0:                 episode reward: 57.6000,                 loss: nan
env3_first_0:                 episode reward: -73.6500,                 loss: nan
env3_second_0:                 episode reward: 73.6500,                 loss: nan
env4_first_0:                 episode reward: -48.9500,                 loss: nan
env4_second_0:                 episode reward: 48.9500,                 loss: nan
Episode: 3221/10000 (32.2100%),                 avg. length: 276.15,                last time consumption/overall running time: 75.1923s / 12616.5611 s
env0_first_0:                 episode reward: -49.6000,                 loss: 120.0234
env0_second_0:                 episode reward: 49.6000,                 loss: nan
env1_first_0:                 episode reward: -40.4500,                 loss: nan
env1_second_0:                 episode reward: 40.4500,                 loss: nan
env2_first_0:                 episode reward: -46.3000,                 loss: nan
env2_second_0:                 episode reward: 46.3000,                 loss: nan
env3_first_0:                 episode reward: -57.4000,                 loss: nan
env3_second_0:                 episode reward: 57.4000,                 loss: nan
env4_first_0:                 episode reward: -52.6500,                 loss: nan
env4_second_0:                 episode reward: 52.6500,                 loss: nan
Episode: 3241/10000 (32.4100%),                 avg. length: 272.65,                last time consumption/overall running time: 74.3854s / 12690.9466 s
env0_first_0:                 episode reward: -39.2500,                 loss: 123.5962
env0_second_0:                 episode reward: 39.2500,                 loss: nan
env1_first_0:                 episode reward: -48.3500,                 loss: nan
env1_second_0:                 episode reward: 48.3500,                 loss: nan
env2_first_0:                 episode reward: -31.9000,                 loss: nan
env2_second_0:                 episode reward: 31.9000,                 loss: nan
env3_first_0:                 episode reward: -40.4000,                 loss: nan
env3_second_0:                 episode reward: 40.4000,                 loss: nan
env4_first_0:                 episode reward: -38.6000,                 loss: nan
env4_second_0:                 episode reward: 38.6000,                 loss: nan
Episode: 3261/10000 (32.6100%),                 avg. length: 294.0,                last time consumption/overall running time: 78.7318s / 12769.6783 s
env0_first_0:                 episode reward: -28.4000,                 loss: 81.2428
env0_second_0:                 episode reward: 28.4000,                 loss: nan
env1_first_0:                 episode reward: -24.4000,                 loss: nan
env1_second_0:                 episode reward: 24.4000,                 loss: nan
env2_first_0:                 episode reward: -13.9000,                 loss: nan
env2_second_0:                 episode reward: 13.9000,                 loss: nan
env3_first_0:                 episode reward: -19.2000,                 loss: nan
env3_second_0:                 episode reward: 19.2000,                 loss: nan
env4_first_0:                 episode reward: -10.5000,                 loss: nan
env4_second_0:                 episode reward: 10.5000,                 loss: nan
Episode: 3281/10000 (32.8100%),                 avg. length: 293.7,                last time consumption/overall running time: 80.5842s / 12850.2625 s
env0_first_0:                 episode reward: -25.2500,                 loss: 110.7580
env0_second_0:                 episode reward: 25.2500,                 loss: nan
env1_first_0:                 episode reward: -16.1500,                 loss: nan
env1_second_0:                 episode reward: 16.1500,                 loss: nan
env2_first_0:                 episode reward: -27.0500,                 loss: nan
env2_second_0:                 episode reward: 27.0500,                 loss: nan
env3_first_0:                 episode reward: -27.2500,                 loss: nan
env3_second_0:                 episode reward: 27.2500,                 loss: nan
env4_first_0:                 episode reward: -35.4000,                 loss: nan
env4_second_0:                 episode reward: 35.4000,                 loss: nan
Episode: 3301/10000 (33.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.2119s / 12930.4745 s
env0_first_0:                 episode reward: -1.9500,                 loss: 13.8729
env0_second_0:                 episode reward: 1.9500,                 loss: nan
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
env2_first_0:                 episode reward: 2.7000,                 loss: nan
env2_second_0:                 episode reward: -2.7000,                 loss: nan
env3_first_0:                 episode reward: 1.6500,                 loss: nan
env3_second_0:                 episode reward: -1.6500,                 loss: nan
env4_first_0:                 episode reward: -0.5500,                 loss: nan
env4_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 3321/10000 (33.2100%),                 avg. length: 297.3,                last time consumption/overall running time: 78.6500s / 13009.1244 s
env0_first_0:                 episode reward: -29.6500,                 loss: 109.8390
env0_second_0:                 episode reward: 29.6500,                 loss: nan
env1_first_0:                 episode reward: -37.2000,                 loss: nan
env1_second_0:                 episode reward: 37.2000,                 loss: nan
env2_first_0:                 episode reward: -30.9500,                 loss: nan
env2_second_0:                 episode reward: 30.9500,                 loss: nan
env3_first_0:                 episode reward: -40.9000,                 loss: nan
env3_second_0:                 episode reward: 40.9000,                 loss: nan
env4_first_0:                 episode reward: -43.5000,                 loss: nan
env4_second_0:                 episode reward: 43.5000,                 loss: nan
Episode: 3341/10000 (33.4100%),                 avg. length: 291.0,                last time consumption/overall running time: 77.7667s / 13086.8911 s
env0_first_0:                 episode reward: -48.1500,                 loss: 122.6913
env0_second_0:                 episode reward: 48.1500,                 loss: nan
env1_first_0:                 episode reward: -39.8500,                 loss: nan
env1_second_0:                 episode reward: 39.8500,                 loss: nan
env2_first_0:                 episode reward: -38.6000,                 loss: nan
env2_second_0:                 episode reward: 38.6000,                 loss: nan
env3_first_0:                 episode reward: -38.2500,                 loss: nan
env3_second_0:                 episode reward: 38.2500,                 loss: nan
env4_first_0:                 episode reward: -42.8500,                 loss: nan
env4_second_0:                 episode reward: 42.8500,                 loss: nan
Episode: 3361/10000 (33.6100%),                 avg. length: 292.35,                last time consumption/overall running time: 78.2575s / 13165.1486 s
env0_first_0:                 episode reward: -7.1000,                 loss: 110.2089
env0_second_0:                 episode reward: 7.1000,                 loss: nan
env1_first_0:                 episode reward: -24.9000,                 loss: nan
env1_second_0:                 episode reward: 24.9000,                 loss: nan
env2_first_0:                 episode reward: -31.8500,                 loss: nan
env2_second_0:                 episode reward: 31.8500,                 loss: nan
env3_first_0:                 episode reward: -29.1500,                 loss: nan
env3_second_0:                 episode reward: 29.1500,                 loss: nan
env4_first_0:                 episode reward: -12.0000,                 loss: nan
env4_second_0:                 episode reward: 12.0000,                 loss: nan
Episode: 3381/10000 (33.8100%),                 avg. length: 292.0,                last time consumption/overall running time: 78.0886s / 13243.2373 s
env0_first_0:                 episode reward: -32.6500,                 loss: 117.7126
env0_second_0:                 episode reward: 32.6500,                 loss: nan
env1_first_0:                 episode reward: -39.1000,                 loss: nan
env1_second_0:                 episode reward: 39.1000,                 loss: nan
env2_first_0:                 episode reward: -36.4500,                 loss: nan
env2_second_0:                 episode reward: 36.4500,                 loss: nan
env3_first_0:                 episode reward: -16.8500,                 loss: nan
env3_second_0:                 episode reward: 16.8500,                 loss: nan
env4_first_0:                 episode reward: -25.5500,                 loss: nan
env4_second_0:                 episode reward: 25.5500,                 loss: nan
Episode: 3401/10000 (34.0100%),                 avg. length: 286.5,                last time consumption/overall running time: 76.3165s / 13319.5538 s
env0_first_0:                 episode reward: -23.1000,                 loss: 131.6527
env0_second_0:                 episode reward: 23.1000,                 loss: nan
env1_first_0:                 episode reward: -18.7000,                 loss: nan
env1_second_0:                 episode reward: 18.7000,                 loss: nan
env2_first_0:                 episode reward: -18.1000,                 loss: nan
env2_second_0:                 episode reward: 18.1000,                 loss: nan
env3_first_0:                 episode reward: -33.4500,                 loss: nan
env3_second_0:                 episode reward: 33.4500,                 loss: nan
env4_first_0:                 episode reward: -25.6000,                 loss: nan
env4_second_0:                 episode reward: 25.6000,                 loss: nan
Episode: 3421/10000 (34.2100%),                 avg. length: 286.75,                last time consumption/overall running time: 76.8281s / 13396.3818 s
env0_first_0:                 episode reward: -31.3000,                 loss: 128.7787
env0_second_0:                 episode reward: 31.3000,                 loss: nan
env1_first_0:                 episode reward: -36.0000,                 loss: nan
env1_second_0:                 episode reward: 36.0000,                 loss: nan
env2_first_0:                 episode reward: -28.1500,                 loss: nan
env2_second_0:                 episode reward: 28.1500,                 loss: nan
env3_first_0:                 episode reward: -37.6500,                 loss: nan
env3_second_0:                 episode reward: 37.6500,                 loss: nan
env4_first_0:                 episode reward: -33.2000,                 loss: nan
env4_second_0:                 episode reward: 33.2000,                 loss: nan
Episode: 3441/10000 (34.4100%),                 avg. length: 289.35,                last time consumption/overall running time: 78.7236s / 13475.1054 s
env0_first_0:                 episode reward: -33.0500,                 loss: 133.3310
env0_second_0:                 episode reward: 33.0500,                 loss: nan
env1_first_0:                 episode reward: -43.9500,                 loss: nan
env1_second_0:                 episode reward: 43.9500,                 loss: nan
env2_first_0:                 episode reward: -41.0500,                 loss: nan
env2_second_0:                 episode reward: 41.0500,                 loss: nan
env3_first_0:                 episode reward: -43.6000,                 loss: nan
env3_second_0:                 episode reward: 43.6000,                 loss: nan
env4_first_0:                 episode reward: -32.6500,                 loss: nan
env4_second_0:                 episode reward: 32.6500,                 loss: nan
Episode: 3461/10000 (34.6100%),                 avg. length: 264.4,                last time consumption/overall running time: 73.2925s / 13548.3980 s
env0_first_0:                 episode reward: -50.0500,                 loss: 152.3841
env0_second_0:                 episode reward: 50.0500,                 loss: nan
env1_first_0:                 episode reward: -67.2000,                 loss: nan
env1_second_0:                 episode reward: 67.2000,                 loss: nan
env2_first_0:                 episode reward: -49.9000,                 loss: nan
env2_second_0:                 episode reward: 49.9000,                 loss: nan
env3_first_0:                 episode reward: -49.1500,                 loss: nan
env3_second_0:                 episode reward: 49.1500,                 loss: nan
env4_first_0:                 episode reward: -49.3500,                 loss: nan
env4_second_0:                 episode reward: 49.3500,                 loss: nan
Episode: 3481/10000 (34.8100%),                 avg. length: 280.8,                last time consumption/overall running time: 75.7687s / 13624.1666 s
env0_first_0:                 episode reward: -42.3500,                 loss: 135.9503
env0_second_0:                 episode reward: 42.3500,                 loss: nan
env1_first_0:                 episode reward: -26.1500,                 loss: nan
env1_second_0:                 episode reward: 26.1500,                 loss: nan
env2_first_0:                 episode reward: -33.6500,                 loss: nan
env2_second_0:                 episode reward: 33.6500,                 loss: nan
env3_first_0:                 episode reward: -49.3000,                 loss: nan
env3_second_0:                 episode reward: 49.3000,                 loss: nan
env4_first_0:                 episode reward: -54.7500,                 loss: nan
env4_second_0:                 episode reward: 54.7500,                 loss: nan
Episode: 3501/10000 (35.0100%),                 avg. length: 285.15,                last time consumption/overall running time: 76.0315s / 13700.1981 s
env0_first_0:                 episode reward: -22.5500,                 loss: 108.7266
env0_second_0:                 episode reward: 22.5500,                 loss: nan
env1_first_0:                 episode reward: -26.6000,                 loss: nan
env1_second_0:                 episode reward: 26.6000,                 loss: nan
env2_first_0:                 episode reward: -45.1500,                 loss: nan
env2_second_0:                 episode reward: 45.1500,                 loss: nan
env3_first_0:                 episode reward: -30.8500,                 loss: nan
env3_second_0:                 episode reward: 30.8500,                 loss: nan
env4_first_0:                 episode reward: -51.6000,                 loss: nan
env4_second_0:                 episode reward: 51.6000,                 loss: nan
Episode: 3521/10000 (35.2100%),                 avg. length: 266.3,                last time consumption/overall running time: 71.8886s / 13772.0867 s
env0_first_0:                 episode reward: -56.1000,                 loss: 130.4720
env0_second_0:                 episode reward: 56.1000,                 loss: nan
env1_first_0:                 episode reward: -63.4500,                 loss: nan
env1_second_0:                 episode reward: 63.4500,                 loss: nan
env2_first_0:                 episode reward: -70.9500,                 loss: nan
env2_second_0:                 episode reward: 70.9500,                 loss: nan
env3_first_0:                 episode reward: -62.1000,                 loss: nan
env3_second_0:                 episode reward: 62.1000,                 loss: nan
env4_first_0:                 episode reward: -60.6000,                 loss: nan
env4_second_0:                 episode reward: 60.6000,                 loss: nan
Episode: 3541/10000 (35.4100%),                 avg. length: 267.1,                last time consumption/overall running time: 73.9754s / 13846.0621 s
env0_first_0:                 episode reward: -53.1000,                 loss: 149.8980
env0_second_0:                 episode reward: 53.1000,                 loss: nan
env1_first_0:                 episode reward: -58.1000,                 loss: nan
env1_second_0:                 episode reward: 58.1000,                 loss: nan
env2_first_0:                 episode reward: -40.5000,                 loss: nan
env2_second_0:                 episode reward: 40.5000,                 loss: nan
env3_first_0:                 episode reward: -63.5500,                 loss: nan
env3_second_0:                 episode reward: 63.5500,                 loss: nan
env4_first_0:                 episode reward: -60.9000,                 loss: nan
env4_second_0:                 episode reward: 60.9000,                 loss: nan
Episode: 3561/10000 (35.6100%),                 avg. length: 274.85,                last time consumption/overall running time: 73.4318s / 13919.4939 s
env0_first_0:                 episode reward: -44.9500,                 loss: 128.8284
env0_second_0:                 episode reward: 44.9500,                 loss: nan
env1_first_0:                 episode reward: -55.7000,                 loss: nan
env1_second_0:                 episode reward: 55.7000,                 loss: nan
env2_first_0:                 episode reward: -48.8500,                 loss: nan
env2_second_0:                 episode reward: 48.8500,                 loss: nan
env3_first_0:                 episode reward: -55.0500,                 loss: nan
env3_second_0:                 episode reward: 55.0500,                 loss: nan
env4_first_0:                 episode reward: -50.2500,                 loss: nan
env4_second_0:                 episode reward: 50.2500,                 loss: nan
Episode: 3581/10000 (35.8100%),                 avg. length: 288.65,                last time consumption/overall running time: 77.9236s / 13997.4175 s
env0_first_0:                 episode reward: -44.4000,                 loss: 117.9239
env0_second_0:                 episode reward: 44.4000,                 loss: nan
env1_first_0:                 episode reward: -49.7000,                 loss: nan
env1_second_0:                 episode reward: 49.7000,                 loss: nan
env2_first_0:                 episode reward: -50.9500,                 loss: nan
env2_second_0:                 episode reward: 50.9500,                 loss: nan
env3_first_0:                 episode reward: -44.4500,                 loss: nan
env3_second_0:                 episode reward: 44.4500,                 loss: nan
env4_first_0:                 episode reward: -38.4000,                 loss: nan
env4_second_0:                 episode reward: 38.4000,                 loss: nan
Episode: 3601/10000 (36.0100%),                 avg. length: 247.9,                last time consumption/overall running time: 69.6304s / 14067.0479 s
env0_first_0:                 episode reward: -65.6500,                 loss: 136.4422
env0_second_0:                 episode reward: 65.6500,                 loss: nan
env1_first_0:                 episode reward: -80.3000,                 loss: nan
env1_second_0:                 episode reward: 80.3000,                 loss: nan
env2_first_0:                 episode reward: -69.2500,                 loss: nan
env2_second_0:                 episode reward: 69.2500,                 loss: nan
env3_first_0:                 episode reward: -73.6500,                 loss: nan
env3_second_0:                 episode reward: 73.6500,                 loss: nan
env4_first_0:                 episode reward: -69.2000,                 loss: nan
env4_second_0:                 episode reward: 69.2000,                 loss: nan
Episode: 3621/10000 (36.2100%),                 avg. length: 249.8,                last time consumption/overall running time: 68.5990s / 14135.6468 s
env0_first_0:                 episode reward: -80.2000,                 loss: 117.4922
env0_second_0:                 episode reward: 80.2000,                 loss: nan
env1_first_0:                 episode reward: -74.0000,                 loss: nan
env1_second_0:                 episode reward: 74.0000,                 loss: nan
env2_first_0:                 episode reward: -69.9000,                 loss: nan
env2_second_0:                 episode reward: 69.9000,                 loss: nan
env3_first_0:                 episode reward: -77.8500,                 loss: nan
env3_second_0:                 episode reward: 77.8500,                 loss: nan
env4_first_0:                 episode reward: -71.2500,                 loss: nan
env4_second_0:                 episode reward: 71.2500,                 loss: nan
Episode: 3641/10000 (36.4100%),                 avg. length: 236.4,                last time consumption/overall running time: 67.0733s / 14202.7202 s
env0_first_0:                 episode reward: -63.8000,                 loss: 136.9752
env0_second_0:                 episode reward: 63.8000,                 loss: nan
env1_first_0:                 episode reward: -68.0000,                 loss: nan
env1_second_0:                 episode reward: 68.0000,                 loss: nan
env2_first_0:                 episode reward: -74.9000,                 loss: nan
env2_second_0:                 episode reward: 74.9000,                 loss: nan
env3_first_0:                 episode reward: -68.0500,                 loss: nan
env3_second_0:                 episode reward: 68.0500,                 loss: nan
env4_first_0:                 episode reward: -65.9500,                 loss: nan
env4_second_0:                 episode reward: 65.9500,                 loss: nan
Episode: 3661/10000 (36.6100%),                 avg. length: 292.05,                last time consumption/overall running time: 78.6835s / 14281.4036 s
env0_first_0:                 episode reward: -9.2500,                 loss: 58.2652
env0_second_0:                 episode reward: 9.2500,                 loss: nan
env1_first_0:                 episode reward: -10.5500,                 loss: nan
env1_second_0:                 episode reward: 10.5500,                 loss: nan
env2_first_0:                 episode reward: -19.1500,                 loss: nan
env2_second_0:                 episode reward: 19.1500,                 loss: nan
env3_first_0:                 episode reward: -3.9500,                 loss: nan
env3_second_0:                 episode reward: 3.9500,                 loss: nan
env4_first_0:                 episode reward: -3.3000,                 loss: nan
env4_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 3681/10000 (36.8100%),                 avg. length: 276.5,                last time consumption/overall running time: 74.8289s / 14356.2325 s
env0_first_0:                 episode reward: -17.8000,                 loss: 98.9226
env0_second_0:                 episode reward: 17.8000,                 loss: nan
env1_first_0:                 episode reward: -25.8000,                 loss: nan
env1_second_0:                 episode reward: 25.8000,                 loss: nan
env2_first_0:                 episode reward: -9.4000,                 loss: nan
env2_second_0:                 episode reward: 9.4000,                 loss: nan
env3_first_0:                 episode reward: -27.2000,                 loss: nan
env3_second_0:                 episode reward: 27.2000,                 loss: nan
env4_first_0:                 episode reward: -21.4000,                 loss: nan
env4_second_0:                 episode reward: 21.4000,                 loss: nan
Episode: 3701/10000 (37.0100%),                 avg. length: 288.5,                last time consumption/overall running time: 78.3564s / 14434.5889 s
env0_first_0:                 episode reward: -11.3500,                 loss: 52.9735
env0_second_0:                 episode reward: 11.3500,                 loss: nan
env1_first_0:                 episode reward: -10.7000,                 loss: nan
env1_second_0:                 episode reward: 10.7000,                 loss: nan
env2_first_0:                 episode reward: -12.5500,                 loss: nan
env2_second_0:                 episode reward: 12.5500,                 loss: nan
env3_first_0:                 episode reward: -9.5000,                 loss: nan
env3_second_0:                 episode reward: 9.5000,                 loss: nan
env4_first_0:                 episode reward: -10.6500,                 loss: nan
env4_second_0:                 episode reward: 10.6500,                 loss: nan
Episode: 3721/10000 (37.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.8121s / 14514.4010 s
env0_first_0:                 episode reward: -3.9000,                 loss: 8.5981
env0_second_0:                 episode reward: 3.9000,                 loss: nan
env1_first_0:                 episode reward: -5.4500,                 loss: nan
env1_second_0:                 episode reward: 5.4500,                 loss: nan
env2_first_0:                 episode reward: -3.1000,                 loss: nan
env2_second_0:                 episode reward: 3.1000,                 loss: nan
env3_first_0:                 episode reward: -2.1500,                 loss: nan
env3_second_0:                 episode reward: 2.1500,                 loss: nan
env4_first_0:                 episode reward: -1.0000,                 loss: nan
env4_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 3741/10000 (37.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.1903s / 14594.5913 s
env0_first_0:                 episode reward: -1.5500,                 loss: 33.1411
env0_second_0:                 episode reward: 1.5500,                 loss: nan
env1_first_0:                 episode reward: -2.0000,                 loss: nan
env1_second_0:                 episode reward: 2.0000,                 loss: nan
env2_first_0:                 episode reward: -4.8000,                 loss: nan
env2_second_0:                 episode reward: 4.8000,                 loss: nan
env3_first_0:                 episode reward: -8.6500,                 loss: nan
env3_second_0:                 episode reward: 8.6500,                 loss: nan
env4_first_0:                 episode reward: -3.3500,                 loss: nan
env4_second_0:                 episode reward: 3.3500,                 loss: nan
Episode: 3761/10000 (37.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.8887s / 14674.4800 s
env0_first_0:                 episode reward: 4.3500,                 loss: 10.2078
env0_second_0:                 episode reward: -4.3500,                 loss: nan
env1_first_0:                 episode reward: 7.3500,                 loss: nan
env1_second_0:                 episode reward: -7.3500,                 loss: nan
env2_first_0:                 episode reward: 2.5000,                 loss: nan
env2_second_0:                 episode reward: -2.5000,                 loss: nan
env3_first_0:                 episode reward: 4.6000,                 loss: nan
env3_second_0:                 episode reward: -4.6000,                 loss: nan
env4_first_0:                 episode reward: 3.9000,                 loss: nan
env4_second_0:                 episode reward: -3.9000,                 loss: nan
Episode: 3781/10000 (37.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.7881s / 14755.2681 s
env0_first_0:                 episode reward: -1.1500,                 loss: 7.3758
env0_second_0:                 episode reward: 1.1500,                 loss: nan
env1_first_0:                 episode reward: -2.8500,                 loss: nan
env1_second_0:                 episode reward: 2.8500,                 loss: nan
env2_first_0:                 episode reward: -4.2500,                 loss: nan
env2_second_0:                 episode reward: 4.2500,                 loss: nan
env3_first_0:                 episode reward: -2.4500,                 loss: nan
env3_second_0:                 episode reward: 2.4500,                 loss: nan
env4_first_0:                 episode reward: -1.5000,                 loss: nan
env4_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 3801/10000 (38.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.7129s / 14834.9810 s
env0_first_0:                 episode reward: -12.0000,                 loss: 27.6579
env0_second_0:                 episode reward: 12.0000,                 loss: nan
env1_first_0:                 episode reward: -12.6000,                 loss: nan
env1_second_0:                 episode reward: 12.6000,                 loss: nan
env2_first_0:                 episode reward: -14.3000,                 loss: nan
env2_second_0:                 episode reward: 14.3000,                 loss: nan
env3_first_0:                 episode reward: -12.9000,                 loss: nan
env3_second_0:                 episode reward: 12.9000,                 loss: nan
env4_first_0:                 episode reward: -7.5500,                 loss: nan
env4_second_0:                 episode reward: 7.5500,                 loss: nan
Episode: 3821/10000 (38.2100%),                 avg. length: 296.85,                last time consumption/overall running time: 79.4871s / 14914.4681 s
env0_first_0:                 episode reward: -30.2000,                 loss: 61.0061
env0_second_0:                 episode reward: 30.2000,                 loss: nan
env1_first_0:                 episode reward: -31.8000,                 loss: nan
env1_second_0:                 episode reward: 31.8000,                 loss: nan
env2_first_0:                 episode reward: -28.0500,                 loss: nan
env2_second_0:                 episode reward: 28.0500,                 loss: nan
env3_first_0:                 episode reward: -16.1000,                 loss: nan
env3_second_0:                 episode reward: 16.1000,                 loss: nan
env4_first_0:                 episode reward: -18.7000,                 loss: nan
env4_second_0:                 episode reward: 18.7000,                 loss: nan
Episode: 3841/10000 (38.4100%),                 avg. length: 298.8,                last time consumption/overall running time: 79.0940s / 14993.5620 s
env0_first_0:                 episode reward: -29.1000,                 loss: 65.0875
env0_second_0:                 episode reward: 29.1000,                 loss: nan
env1_first_0:                 episode reward: -21.3000,                 loss: nan
env1_second_0:                 episode reward: 21.3000,                 loss: nan
env2_first_0:                 episode reward: -22.0000,                 loss: nan
env2_second_0:                 episode reward: 22.0000,                 loss: nan
env3_first_0:                 episode reward: -27.5500,                 loss: nan
env3_second_0:                 episode reward: 27.5500,                 loss: nan
env4_first_0:                 episode reward: -18.5500,                 loss: nan
env4_second_0:                 episode reward: 18.5500,                 loss: nan
Episode: 3861/10000 (38.6100%),                 avg. length: 296.2,                last time consumption/overall running time: 79.1336s / 15072.6957 s
env0_first_0:                 episode reward: -47.2500,                 loss: 98.1912
env0_second_0:                 episode reward: 47.2500,                 loss: nan
env1_first_0:                 episode reward: -52.7000,                 loss: nan
env1_second_0:                 episode reward: 52.7000,                 loss: nan
env2_first_0:                 episode reward: -51.0500,                 loss: nan
env2_second_0:                 episode reward: 51.0500,                 loss: nan
env3_first_0:                 episode reward: -48.6000,                 loss: nan
env3_second_0:                 episode reward: 48.6000,                 loss: nan
env4_first_0:                 episode reward: -56.9000,                 loss: nan
env4_second_0:                 episode reward: 56.9000,                 loss: nan
Episode: 3881/10000 (38.8100%),                 avg. length: 281.95,                last time consumption/overall running time: 74.2870s / 15146.9827 s
env0_first_0:                 episode reward: -36.8000,                 loss: 123.6665
env0_second_0:                 episode reward: 36.8000,                 loss: nan
env1_first_0:                 episode reward: -40.4500,                 loss: nan
env1_second_0:                 episode reward: 40.4500,                 loss: nan
env2_first_0:                 episode reward: -48.1000,                 loss: nan
env2_second_0:                 episode reward: 48.1000,                 loss: nan
env3_first_0:                 episode reward: -53.9500,                 loss: nan
env3_second_0:                 episode reward: 53.9500,                 loss: nan
env4_first_0:                 episode reward: -46.7000,                 loss: nan
env4_second_0:                 episode reward: 46.7000,                 loss: nan
Episode: 3901/10000 (39.0100%),                 avg. length: 261.3,                last time consumption/overall running time: 72.4895s / 15219.4722 s
env0_first_0:                 episode reward: -69.9000,                 loss: 133.7655
env0_second_0:                 episode reward: 69.9000,                 loss: nan
env1_first_0:                 episode reward: -58.7000,                 loss: nan
env1_second_0:                 episode reward: 58.7000,                 loss: nan
env2_first_0:                 episode reward: -48.3000,                 loss: nan
env2_second_0:                 episode reward: 48.3000,                 loss: nan
env3_first_0:                 episode reward: -55.8500,                 loss: nan
env3_second_0:                 episode reward: 55.8500,                 loss: nan
env4_first_0:                 episode reward: -55.6000,                 loss: nan
env4_second_0:                 episode reward: 55.6000,                 loss: nan
Episode: 3921/10000 (39.2100%),                 avg. length: 251.3,                last time consumption/overall running time: 70.0927s / 15289.5650 s
env0_first_0:                 episode reward: -65.7000,                 loss: 142.1336
env0_second_0:                 episode reward: 65.7000,                 loss: nan
env1_first_0:                 episode reward: -70.6500,                 loss: nan
env1_second_0:                 episode reward: 70.6500,                 loss: nan
env2_first_0:                 episode reward: -71.1000,                 loss: nan
env2_second_0:                 episode reward: 71.1000,                 loss: nan
env3_first_0:                 episode reward: -62.9500,                 loss: nan
env3_second_0:                 episode reward: 62.9500,                 loss: nan
env4_first_0:                 episode reward: -64.3000,                 loss: nan
env4_second_0:                 episode reward: 64.3000,                 loss: nan
Episode: 3941/10000 (39.4100%),                 avg. length: 246.75,                last time consumption/overall running time: 68.1418s / 15357.7068 s
env0_first_0:                 episode reward: -64.9000,                 loss: 120.7068
env0_second_0:                 episode reward: 64.9000,                 loss: nan
env1_first_0:                 episode reward: -62.2500,                 loss: nan
env1_second_0:                 episode reward: 62.2500,                 loss: nan
env2_first_0:                 episode reward: -80.3000,                 loss: nan
env2_second_0:                 episode reward: 80.3000,                 loss: nan
env3_first_0:                 episode reward: -72.5000,                 loss: nan
env3_second_0:                 episode reward: 72.5000,                 loss: nan
env4_first_0:                 episode reward: -77.0500,                 loss: nan
env4_second_0:                 episode reward: 77.0500,                 loss: nan
Episode: 3961/10000 (39.6100%),                 avg. length: 229.3,                last time consumption/overall running time: 65.6919s / 15423.3987 s
env0_first_0:                 episode reward: -68.7500,                 loss: 138.0065
env0_second_0:                 episode reward: 68.7500,                 loss: nan
env1_first_0:                 episode reward: -66.2500,                 loss: nan
env1_second_0:                 episode reward: 66.2500,                 loss: nan
env2_first_0:                 episode reward: -70.6500,                 loss: nan
env2_second_0:                 episode reward: 70.6500,                 loss: nan
env3_first_0:                 episode reward: -68.5500,                 loss: nan
env3_second_0:                 episode reward: 68.5500,                 loss: nan
env4_first_0:                 episode reward: -72.8500,                 loss: nan
env4_second_0:                 episode reward: 72.8500,                 loss: nan
Episode: 3981/10000 (39.8100%),                 avg. length: 233.1,                last time consumption/overall running time: 65.2675s / 15488.6662 s
env0_first_0:                 episode reward: -81.5000,                 loss: 145.4929
env0_second_0:                 episode reward: 81.5000,                 loss: nan
env1_first_0:                 episode reward: -69.4500,                 loss: nan
env1_second_0:                 episode reward: 69.4500,                 loss: nan
env2_first_0:                 episode reward: -63.6500,                 loss: nan
env2_second_0:                 episode reward: 63.6500,                 loss: nan
env3_first_0:                 episode reward: -70.1000,                 loss: nan
env3_second_0:                 episode reward: 70.1000,                 loss: nan
env4_first_0:                 episode reward: -62.2500,                 loss: nan
env4_second_0:                 episode reward: 62.2500,                 loss: nan
Episode: 4001/10000 (40.0100%),                 avg. length: 250.6,                last time consumption/overall running time: 69.3834s / 15558.0496 s
env0_first_0:                 episode reward: -66.7500,                 loss: 129.6143
env0_second_0:                 episode reward: 66.7500,                 loss: nan
env1_first_0:                 episode reward: -62.6000,                 loss: nan
env1_second_0:                 episode reward: 62.6000,                 loss: nan
env2_first_0:                 episode reward: -73.5000,                 loss: nan
env2_second_0:                 episode reward: 73.5000,                 loss: nan
env3_first_0:                 episode reward: -58.1000,                 loss: nan
env3_second_0:                 episode reward: 58.1000,                 loss: nan
env4_first_0:                 episode reward: -65.7000,                 loss: nan
env4_second_0:                 episode reward: 65.7000,                 loss: nan
Episode: 4021/10000 (40.2100%),                 avg. length: 238.4,                last time consumption/overall running time: 67.7097s / 15625.7593 s
env0_first_0:                 episode reward: -57.7500,                 loss: 139.8124
env0_second_0:                 episode reward: 57.7500,                 loss: nan
env1_first_0:                 episode reward: -78.8500,                 loss: nan
env1_second_0:                 episode reward: 78.8500,                 loss: nan
env2_first_0:                 episode reward: -74.3000,                 loss: nan
env2_second_0:                 episode reward: 74.3000,                 loss: nan
env3_first_0:                 episode reward: -64.2500,                 loss: nan
env3_second_0:                 episode reward: 64.2500,                 loss: nan
env4_first_0:                 episode reward: -59.8000,                 loss: nan
env4_second_0:                 episode reward: 59.8000,                 loss: nan
Episode: 4041/10000 (40.4100%),                 avg. length: 224.8,                last time consumption/overall running time: 64.6525s / 15690.4118 s
env0_first_0:                 episode reward: -66.6500,                 loss: 133.5036
env0_second_0:                 episode reward: 66.6500,                 loss: nan
env1_first_0:                 episode reward: -66.5000,                 loss: nan
env1_second_0:                 episode reward: 66.5000,                 loss: nan
env2_first_0:                 episode reward: -69.2500,                 loss: nan
env2_second_0:                 episode reward: 69.2500,                 loss: nan
env3_first_0:                 episode reward: -74.9000,                 loss: nan
env3_second_0:                 episode reward: 74.9000,                 loss: nan
env4_first_0:                 episode reward: -70.2000,                 loss: nan
env4_second_0:                 episode reward: 70.2000,                 loss: nan
Episode: 4061/10000 (40.6100%),                 avg. length: 236.05,                last time consumption/overall running time: 66.6433s / 15757.0552 s
env0_first_0:                 episode reward: -67.0000,                 loss: 129.6187
env0_second_0:                 episode reward: 67.0000,                 loss: nan
env1_first_0:                 episode reward: -64.7500,                 loss: nan
env1_second_0:                 episode reward: 64.7500,                 loss: nan
env2_first_0:                 episode reward: -75.9500,                 loss: nan
env2_second_0:                 episode reward: 75.9500,                 loss: nan
env3_first_0:                 episode reward: -63.5500,                 loss: nan
env3_second_0:                 episode reward: 63.5500,                 loss: nan
env4_first_0:                 episode reward: -67.3500,                 loss: nan
env4_second_0:                 episode reward: 67.3500,                 loss: nan
Episode: 4081/10000 (40.8100%),                 avg. length: 243.8,                last time consumption/overall running time: 68.4813s / 15825.5365 s
env0_first_0:                 episode reward: -56.5000,                 loss: 119.6538
env0_second_0:                 episode reward: 56.5000,                 loss: nan
env1_first_0:                 episode reward: -68.2000,                 loss: nan
env1_second_0:                 episode reward: 68.2000,                 loss: nan
env2_first_0:                 episode reward: -67.0500,                 loss: nan
env2_second_0:                 episode reward: 67.0500,                 loss: nan
env3_first_0:                 episode reward: -68.1500,                 loss: nan
env3_second_0:                 episode reward: 68.1500,                 loss: nan
env4_first_0:                 episode reward: -64.7500,                 loss: nan
env4_second_0:                 episode reward: 64.7500,                 loss: nan
Episode: 4101/10000 (41.0100%),                 avg. length: 248.4,                last time consumption/overall running time: 69.4892s / 15895.0257 s
env0_first_0:                 episode reward: -48.7500,                 loss: 150.9794
env0_second_0:                 episode reward: 48.7500,                 loss: nan
env1_first_0:                 episode reward: -53.4500,                 loss: nan
env1_second_0:                 episode reward: 53.4500,                 loss: nan
env2_first_0:                 episode reward: -56.8000,                 loss: nan
env2_second_0:                 episode reward: 56.8000,                 loss: nan
env3_first_0:                 episode reward: -57.5000,                 loss: nan
env3_second_0:                 episode reward: 57.5000,                 loss: nan
env4_first_0:                 episode reward: -58.0500,                 loss: nan
env4_second_0:                 episode reward: 58.0500,                 loss: nan
Episode: 4121/10000 (41.2100%),                 avg. length: 250.05,                last time consumption/overall running time: 69.4527s / 15964.4785 s
env0_first_0:                 episode reward: -33.5500,                 loss: 167.9213
env0_second_0:                 episode reward: 33.5500,                 loss: nan
env1_first_0:                 episode reward: -52.3500,                 loss: nan
env1_second_0:                 episode reward: 52.3500,                 loss: nan
env2_first_0:                 episode reward: -34.9500,                 loss: nan
env2_second_0:                 episode reward: 34.9500,                 loss: nan
env3_first_0:                 episode reward: -55.5000,                 loss: nan
env3_second_0:                 episode reward: 55.5000,                 loss: nan
env4_first_0:                 episode reward: -34.6500,                 loss: nan
env4_second_0:                 episode reward: 34.6500,                 loss: nan
Episode: 4141/10000 (41.4100%),                 avg. length: 250.85,                last time consumption/overall running time: 69.9704s / 16034.4489 s
env0_first_0:                 episode reward: -49.5000,                 loss: 173.8575
env0_second_0:                 episode reward: 49.5000,                 loss: nan
env1_first_0:                 episode reward: -32.8000,                 loss: nan
env1_second_0:                 episode reward: 32.8000,                 loss: nan
env2_first_0:                 episode reward: -46.4000,                 loss: nan
env2_second_0:                 episode reward: 46.4000,                 loss: nan
env3_first_0:                 episode reward: -73.0500,                 loss: nan
env3_second_0:                 episode reward: 73.0500,                 loss: nan
env4_first_0:                 episode reward: -57.8500,                 loss: nan
env4_second_0:                 episode reward: 57.8500,                 loss: nan
Episode: 4161/10000 (41.6100%),                 avg. length: 286.15,                last time consumption/overall running time: 76.2161s / 16110.6650 s
env0_first_0:                 episode reward: -24.2000,                 loss: 121.4129
env0_second_0:                 episode reward: 24.2000,                 loss: nan
env1_first_0:                 episode reward: -21.9500,                 loss: nan
env1_second_0:                 episode reward: 21.9500,                 loss: nan
env2_first_0:                 episode reward: -23.9500,                 loss: nan
env2_second_0:                 episode reward: 23.9500,                 loss: nan
env3_first_0:                 episode reward: -40.2500,                 loss: nan
env3_second_0:                 episode reward: 40.2500,                 loss: nan
env4_first_0:                 episode reward: -36.7000,                 loss: nan
env4_second_0:                 episode reward: 36.7000,                 loss: nan
Episode: 4181/10000 (41.8100%),                 avg. length: 271.8,                last time consumption/overall running time: 74.7374s / 16185.4024 s
env0_first_0:                 episode reward: -24.5000,                 loss: 109.1410
env0_second_0:                 episode reward: 24.5000,                 loss: nan
env1_first_0:                 episode reward: -42.0500,                 loss: nan
env1_second_0:                 episode reward: 42.0500,                 loss: nan
env2_first_0:                 episode reward: -31.1500,                 loss: nan
env2_second_0:                 episode reward: 31.1500,                 loss: nan
env3_first_0:                 episode reward: -31.8000,                 loss: nan
env3_second_0:                 episode reward: 31.8000,                 loss: nan
env4_first_0:                 episode reward: -22.1500,                 loss: nan
env4_second_0:                 episode reward: 22.1500,                 loss: nan
Episode: 4201/10000 (42.0100%),                 avg. length: 285.95,                last time consumption/overall running time: 76.8332s / 16262.2355 s
env0_first_0:                 episode reward: -19.6500,                 loss: 86.4936
env0_second_0:                 episode reward: 19.6500,                 loss: nan
env1_first_0:                 episode reward: -29.6500,                 loss: nan
env1_second_0:                 episode reward: 29.6500,                 loss: nan
env2_first_0:                 episode reward: -20.3500,                 loss: nan
env2_second_0:                 episode reward: 20.3500,                 loss: nan
env3_first_0:                 episode reward: -18.1500,                 loss: nan
env3_second_0:                 episode reward: 18.1500,                 loss: nan
env4_first_0:                 episode reward: -19.3500,                 loss: nan
env4_second_0:                 episode reward: 19.3500,                 loss: nan
Episode: 4221/10000 (42.2100%),                 avg. length: 297.85,                last time consumption/overall running time: 78.5187s / 16340.7543 s
env0_first_0:                 episode reward: -2.6000,                 loss: 32.4740
env0_second_0:                 episode reward: 2.6000,                 loss: nan
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
env2_first_0:                 episode reward: -13.2500,                 loss: nan
env2_second_0:                 episode reward: 13.2500,                 loss: nan
env3_first_0:                 episode reward: -11.0000,                 loss: nan
env3_second_0:                 episode reward: 11.0000,                 loss: nan
env4_first_0:                 episode reward: -2.7000,                 loss: nan
env4_second_0:                 episode reward: 2.7000,                 loss: nan
Episode: 4241/10000 (42.4100%),                 avg. length: 288.7,                last time consumption/overall running time: 77.5407s / 16418.2949 s
env0_first_0:                 episode reward: -19.9000,                 loss: 75.8419
env0_second_0:                 episode reward: 19.9000,                 loss: nan
env1_first_0:                 episode reward: -30.1000,                 loss: nan
env1_second_0:                 episode reward: 30.1000,                 loss: nan
env2_first_0:                 episode reward: -16.5500,                 loss: nan
env2_second_0:                 episode reward: 16.5500,                 loss: nan
env3_first_0:                 episode reward: -11.1500,                 loss: nan
env3_second_0:                 episode reward: 11.1500,                 loss: nan
env4_first_0:                 episode reward: -21.4500,                 loss: nan
env4_second_0:                 episode reward: 21.4500,                 loss: nan
Episode: 4261/10000 (42.6100%),                 avg. length: 287.95,                last time consumption/overall running time: 77.5904s / 16495.8853 s
env0_first_0:                 episode reward: -34.2000,                 loss: 98.5738
env0_second_0:                 episode reward: 34.2000,                 loss: nan
env1_first_0:                 episode reward: -28.5000,                 loss: nan
env1_second_0:                 episode reward: 28.5000,                 loss: nan
env2_first_0:                 episode reward: -28.2500,                 loss: nan
env2_second_0:                 episode reward: 28.2500,                 loss: nan
env3_first_0:                 episode reward: -25.2000,                 loss: nan
env3_second_0:                 episode reward: 25.2000,                 loss: nan
env4_first_0:                 episode reward: -30.7500,                 loss: nan
env4_second_0:                 episode reward: 30.7500,                 loss: nan
Episode: 4281/10000 (42.8100%),                 avg. length: 286.15,                last time consumption/overall running time: 77.5930s / 16573.4783 s
env0_first_0:                 episode reward: -37.3000,                 loss: 118.4909
env0_second_0:                 episode reward: 37.3000,                 loss: nan
env1_first_0:                 episode reward: -42.1500,                 loss: nan
env1_second_0:                 episode reward: 42.1500,                 loss: nan
env2_first_0:                 episode reward: -52.7500,                 loss: nan
env2_second_0:                 episode reward: 52.7500,                 loss: nan
env3_first_0:                 episode reward: -49.9500,                 loss: nan
env3_second_0:                 episode reward: 49.9500,                 loss: nan
env4_first_0:                 episode reward: -40.5500,                 loss: nan
env4_second_0:                 episode reward: 40.5500,                 loss: nan
Episode: 4301/10000 (43.0100%),                 avg. length: 273.7,                last time consumption/overall running time: 75.1760s / 16648.6543 s
env0_first_0:                 episode reward: -47.6000,                 loss: 125.6207
env0_second_0:                 episode reward: 47.6000,                 loss: nan
env1_first_0:                 episode reward: -55.4000,                 loss: nan
env1_second_0:                 episode reward: 55.4000,                 loss: nan
env2_first_0:                 episode reward: -67.2000,                 loss: nan
env2_second_0:                 episode reward: 67.2000,                 loss: nan
env3_first_0:                 episode reward: -53.4500,                 loss: nan
env3_second_0:                 episode reward: 53.4500,                 loss: nan
env4_first_0:                 episode reward: -46.1500,                 loss: nan
env4_second_0:                 episode reward: 46.1500,                 loss: nan
Episode: 4321/10000 (43.2100%),                 avg. length: 274.0,                last time consumption/overall running time: 75.5784s / 16724.2327 s
env0_first_0:                 episode reward: -34.6500,                 loss: 120.9496
env0_second_0:                 episode reward: 34.6500,                 loss: nan
env1_first_0:                 episode reward: -56.2000,                 loss: nan
env1_second_0:                 episode reward: 56.2000,                 loss: nan
env2_first_0:                 episode reward: -49.2000,                 loss: nan
env2_second_0:                 episode reward: 49.2000,                 loss: nan
env3_first_0:                 episode reward: -42.1500,                 loss: nan
env3_second_0:                 episode reward: 42.1500,                 loss: nan
env4_first_0:                 episode reward: -50.9500,                 loss: nan
env4_second_0:                 episode reward: 50.9500,                 loss: nan
Episode: 4341/10000 (43.4100%),                 avg. length: 261.0,                last time consumption/overall running time: 71.6635s / 16795.8962 s
env0_first_0:                 episode reward: -38.0000,                 loss: 128.9745
env0_second_0:                 episode reward: 38.0000,                 loss: nan
env1_first_0:                 episode reward: -49.0000,                 loss: nan
env1_second_0:                 episode reward: 49.0000,                 loss: nan
env2_first_0:                 episode reward: -56.8000,                 loss: nan
env2_second_0:                 episode reward: 56.8000,                 loss: nan
env3_first_0:                 episode reward: -36.5500,                 loss: nan
env3_second_0:                 episode reward: 36.5500,                 loss: nan
env4_first_0:                 episode reward: -51.4000,                 loss: nan
env4_second_0:                 episode reward: 51.4000,                 loss: nan
Episode: 4361/10000 (43.6100%),                 avg. length: 275.65,                last time consumption/overall running time: 74.9938s / 16870.8900 s
env0_first_0:                 episode reward: -43.6000,                 loss: 118.3761
env0_second_0:                 episode reward: 43.6000,                 loss: nan
env1_first_0:                 episode reward: -37.7500,                 loss: nan
env1_second_0:                 episode reward: 37.7500,                 loss: nan
env2_first_0:                 episode reward: -38.5000,                 loss: nan
env2_second_0:                 episode reward: 38.5000,                 loss: nan
env3_first_0:                 episode reward: -23.0000,                 loss: nan
env3_second_0:                 episode reward: 23.0000,                 loss: nan
env4_first_0:                 episode reward: -34.4000,                 loss: nan
env4_second_0:                 episode reward: 34.4000,                 loss: nan
Episode: 4381/10000 (43.8100%),                 avg. length: 259.9,                last time consumption/overall running time: 72.0239s / 16942.9139 s
env0_first_0:                 episode reward: -48.7000,                 loss: 132.9083
env0_second_0:                 episode reward: 48.7000,                 loss: nan
env1_first_0:                 episode reward: -45.0000,                 loss: nan
env1_second_0:                 episode reward: 45.0000,                 loss: nan
env2_first_0:                 episode reward: -55.4000,                 loss: nan
env2_second_0:                 episode reward: 55.4000,                 loss: nan
env3_first_0:                 episode reward: -60.8500,                 loss: nan
env3_second_0:                 episode reward: 60.8500,                 loss: nan
env4_first_0:                 episode reward: -47.4500,                 loss: nan
env4_second_0:                 episode reward: 47.4500,                 loss: nan
Episode: 4401/10000 (44.0100%),                 avg. length: 286.05,                last time consumption/overall running time: 77.1689s / 17020.0828 s
env0_first_0:                 episode reward: -20.3500,                 loss: 68.0399
env0_second_0:                 episode reward: 20.3500,                 loss: nan
env1_first_0:                 episode reward: -21.6000,                 loss: nan
env1_second_0:                 episode reward: 21.6000,                 loss: nan
env2_first_0:                 episode reward: -24.8500,                 loss: nan
env2_second_0:                 episode reward: 24.8500,                 loss: nan
env3_first_0:                 episode reward: -24.2500,                 loss: nan
env3_second_0:                 episode reward: 24.2500,                 loss: nan
env4_first_0:                 episode reward: -15.5000,                 loss: nan
env4_second_0:                 episode reward: 15.5000,                 loss: nan
Episode: 4421/10000 (44.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.6402s / 17100.7230 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5074
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4441/10000 (44.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.7501s / 17180.4731 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.4961
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.2000,                 loss: nan
env4_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 4461/10000 (44.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 81.7551s / 17262.2282 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.4486
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4481/10000 (44.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.9824s / 17342.2106 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.4659
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4501/10000 (45.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.0990s / 17422.3096 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5530
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4521/10000 (45.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.3858s / 17502.6954 s
env0_first_0:                 episode reward: -0.4500,                 loss: 2.0499
env0_second_0:                 episode reward: 0.4500,                 loss: nan
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
env2_first_0:                 episode reward: -1.4500,                 loss: nan
env2_second_0:                 episode reward: 1.4500,                 loss: nan
env3_first_0:                 episode reward: -0.3000,                 loss: nan
env3_second_0:                 episode reward: 0.3000,                 loss: nan
env4_first_0:                 episode reward: -0.4000,                 loss: nan
env4_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 4541/10000 (45.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.6912s / 17583.3866 s
env0_first_0:                 episode reward: -1.3000,                 loss: 3.5689
env0_second_0:                 episode reward: 1.3000,                 loss: nan
env1_first_0:                 episode reward: -2.1000,                 loss: nan
env1_second_0:                 episode reward: 2.1000,                 loss: nan
env2_first_0:                 episode reward: -1.0000,                 loss: nan
env2_second_0:                 episode reward: 1.0000,                 loss: nan
env3_first_0:                 episode reward: -0.3000,                 loss: nan
env3_second_0:                 episode reward: 0.3000,                 loss: nan
env4_first_0:                 episode reward: -2.2500,                 loss: nan
env4_second_0:                 episode reward: 2.2500,                 loss: nan
Episode: 4561/10000 (45.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.4797s / 17663.8663 s
env0_first_0:                 episode reward: 6.0000,                 loss: 9.9502
env0_second_0:                 episode reward: -6.0000,                 loss: nan
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
env2_first_0:                 episode reward: 2.3000,                 loss: nan
env2_second_0:                 episode reward: -2.3000,                 loss: nan
env3_first_0:                 episode reward: 3.9000,                 loss: nan
env3_second_0:                 episode reward: -3.9000,                 loss: nan
env4_first_0:                 episode reward: 6.4500,                 loss: nan
env4_second_0:                 episode reward: -6.4500,                 loss: nan
Episode: 4581/10000 (45.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.5290s / 17743.3952 s
env0_first_0:                 episode reward: -3.2500,                 loss: 14.3045
env0_second_0:                 episode reward: 3.2500,                 loss: nan
env1_first_0:                 episode reward: -5.6000,                 loss: nan
env1_second_0:                 episode reward: 5.6000,                 loss: nan
env2_first_0:                 episode reward: -7.7500,                 loss: nan
env2_second_0:                 episode reward: 7.7500,                 loss: nan
env3_first_0:                 episode reward: -7.7500,                 loss: nan
env3_second_0:                 episode reward: 7.7500,                 loss: nan
env4_first_0:                 episode reward: -10.1500,                 loss: nan
env4_second_0:                 episode reward: 10.1500,                 loss: nan
Episode: 4601/10000 (46.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.9664s / 17823.3616 s
env0_first_0:                 episode reward: -2.0000,                 loss: 11.7453
env0_second_0:                 episode reward: 2.0000,                 loss: nan
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
env2_first_0:                 episode reward: -4.4000,                 loss: nan
env2_second_0:                 episode reward: 4.4000,                 loss: nan
env3_first_0:                 episode reward: -5.3000,                 loss: nan
env3_second_0:                 episode reward: 5.3000,                 loss: nan
env4_first_0:                 episode reward: -3.2500,                 loss: nan
env4_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 4621/10000 (46.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.8843s / 17903.2460 s
env0_first_0:                 episode reward: -5.8000,                 loss: 9.3891
env0_second_0:                 episode reward: 5.8000,                 loss: nan
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
env2_first_0:                 episode reward: -5.0500,                 loss: nan
env2_second_0:                 episode reward: 5.0500,                 loss: nan
env3_first_0:                 episode reward: -1.9000,                 loss: nan
env3_second_0:                 episode reward: 1.9000,                 loss: nan
env4_first_0:                 episode reward: -1.8000,                 loss: nan
env4_second_0:                 episode reward: 1.8000,                 loss: nan
Episode: 4641/10000 (46.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.1847s / 17983.4307 s
env0_first_0:                 episode reward: -2.7000,                 loss: 5.9674
env0_second_0:                 episode reward: 2.7000,                 loss: nan
env1_first_0:                 episode reward: -1.9000,                 loss: nan
env1_second_0:                 episode reward: 1.9000,                 loss: nan
env2_first_0:                 episode reward: 0.0500,                 loss: nan
env2_second_0:                 episode reward: -0.0500,                 loss: nan
env3_first_0:                 episode reward: -6.1500,                 loss: nan
env3_second_0:                 episode reward: 6.1500,                 loss: nan
env4_first_0:                 episode reward: -3.5500,                 loss: nan
env4_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 4661/10000 (46.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.2188s / 18063.6495 s
env0_first_0:                 episode reward: -3.4500,                 loss: 15.1046
env0_second_0:                 episode reward: 3.4500,                 loss: nan
env1_first_0:                 episode reward: -6.6500,                 loss: nan
env1_second_0:                 episode reward: 6.6500,                 loss: nan
env2_first_0:                 episode reward: -3.8000,                 loss: nan
env2_second_0:                 episode reward: 3.8000,                 loss: nan
env3_first_0:                 episode reward: -4.2500,                 loss: nan
env3_second_0:                 episode reward: 4.2500,                 loss: nan
env4_first_0:                 episode reward: -2.1500,                 loss: nan
env4_second_0:                 episode reward: 2.1500,                 loss: nan
Episode: 4681/10000 (46.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.6102s / 18142.2597 s
env0_first_0:                 episode reward: -2.0500,                 loss: 17.0732
env0_second_0:                 episode reward: 2.0500,                 loss: nan
env1_first_0:                 episode reward: -2.3500,                 loss: nan
env1_second_0:                 episode reward: 2.3500,                 loss: nan
env2_first_0:                 episode reward: -6.2500,                 loss: nan
env2_second_0:                 episode reward: 6.2500,                 loss: nan
env3_first_0:                 episode reward: -7.7500,                 loss: nan
env3_second_0:                 episode reward: 7.7500,                 loss: nan
env4_first_0:                 episode reward: -7.8500,                 loss: nan
env4_second_0:                 episode reward: 7.8500,                 loss: nan
Episode: 4701/10000 (47.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.7530s / 18223.0127 s
env0_first_0:                 episode reward: -2.1500,                 loss: 7.7808
env0_second_0:                 episode reward: 2.1500,                 loss: nan
env1_first_0:                 episode reward: -2.6500,                 loss: nan
env1_second_0:                 episode reward: 2.6500,                 loss: nan
env2_first_0:                 episode reward: -4.2000,                 loss: nan
env2_second_0:                 episode reward: 4.2000,                 loss: nan
env3_first_0:                 episode reward: -0.8000,                 loss: nan
env3_second_0:                 episode reward: 0.8000,                 loss: nan
env4_first_0:                 episode reward: -4.0500,                 loss: nan
env4_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 4721/10000 (47.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 81.4275s / 18304.4401 s
env0_first_0:                 episode reward: -2.5000,                 loss: 11.0937
env0_second_0:                 episode reward: 2.5000,                 loss: nan
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
env2_first_0:                 episode reward: -2.3500,                 loss: nan
env2_second_0:                 episode reward: 2.3500,                 loss: nan
env3_first_0:                 episode reward: -3.5000,                 loss: nan
env3_second_0:                 episode reward: 3.5000,                 loss: nan
env4_first_0:                 episode reward: -0.8500,                 loss: nan
env4_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 4741/10000 (47.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.4901s / 18384.9302 s
env0_first_0:                 episode reward: -1.8500,                 loss: 6.6297
env0_second_0:                 episode reward: 1.8500,                 loss: nan
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
env2_first_0:                 episode reward: 0.5000,                 loss: nan
env2_second_0:                 episode reward: -0.5000,                 loss: nan
env3_first_0:                 episode reward: -2.6000,                 loss: nan
env3_second_0:                 episode reward: 2.6000,                 loss: nan
env4_first_0:                 episode reward: -2.8500,                 loss: nan
env4_second_0:                 episode reward: 2.8500,                 loss: nan
Episode: 4761/10000 (47.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.7752s / 18464.7054 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2215
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4781/10000 (47.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.9835s / 18545.6889 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.6369
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4801/10000 (48.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.8263s / 18625.5152 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.5676
env0_second_0:                 episode reward: 0.1000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: -0.1500,                 loss: nan
env4_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 4821/10000 (48.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 81.3796s / 18706.8947 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.6632
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4841/10000 (48.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 81.5148s / 18788.4096 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.7031
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4861/10000 (48.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.3468s / 18868.7564 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5485
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4881/10000 (48.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 81.3100s / 18950.0664 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5983
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4901/10000 (49.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.9947s / 19030.0612 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5573
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4921/10000 (49.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.4422s / 19110.5034 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5637
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4941/10000 (49.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.9015s / 19190.4048 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.1173
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4961/10000 (49.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.1667s / 19270.5715 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0912
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4981/10000 (49.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 81.1804s / 19351.7519 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.1342
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5001/10000 (50.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 81.3340s / 19433.0859 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2428
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5021/10000 (50.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.1382s / 19513.2241 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.4023
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5041/10000 (50.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 81.6381s / 19594.8621 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.4889
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5061/10000 (50.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.6287s / 19674.4909 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5429
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5081/10000 (50.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.7017s / 19754.1925 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5166
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5101/10000 (51.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.7613s / 19834.9538 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.4304
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5121/10000 (51.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.6117s / 19914.5655 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.4939
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5141/10000 (51.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.2101s / 19993.7757 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.4443
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5161/10000 (51.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.7376s / 20073.5133 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5215
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5181/10000 (51.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.6922s / 20153.2055 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.4765
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5201/10000 (52.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.7776s / 20232.9831 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.6122
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5221/10000 (52.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.5799s / 20312.5629 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5804
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5241/10000 (52.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 81.7352s / 20394.2981 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.5780
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5261/10000 (52.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.0514s / 20474.3495 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5485
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5281/10000 (52.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.5586s / 20554.9081 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5513
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5301/10000 (53.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 81.3528s / 20636.2610 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5474
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5321/10000 (53.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.5991s / 20715.8600 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5309
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5341/10000 (53.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.4885s / 20796.3485 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.6144
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5361/10000 (53.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 81.5865s / 20877.9350 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5899
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5381/10000 (53.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.5462s / 20958.4813 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5710
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5401/10000 (54.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.4213s / 21037.9026 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5527
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5421/10000 (54.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.8465s / 21118.7491 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5281
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5441/10000 (54.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.9040s / 21199.6531 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.4768
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5461/10000 (54.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.5276s / 21279.1807 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5445
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5481/10000 (54.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.6363s / 21358.8170 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.4723
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5501/10000 (55.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.9941s / 21439.8111 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.4613
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5521/10000 (55.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.7497s / 21520.5608 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5215
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5541/10000 (55.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.3573s / 21599.9181 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5663
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5561/10000 (55.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.0592s / 21679.9774 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5622
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5581/10000 (55.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 81.2182s / 21761.1956 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5807
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5601/10000 (56.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.9381s / 21842.1337 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5950
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5621/10000 (56.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.5014s / 21921.6352 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5585
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5641/10000 (56.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.8832s / 22002.5184 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5515
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5661/10000 (56.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.7282s / 22083.2465 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5782
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5681/10000 (56.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.8944s / 22163.1409 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5839
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5701/10000 (57.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.8187s / 22243.9596 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5805
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5721/10000 (57.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.1536s / 22323.1132 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.4801
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5741/10000 (57.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.9221s / 22404.0353 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.4447
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5761/10000 (57.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.5410s / 22484.5763 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.4201
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5781/10000 (57.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 81.3143s / 22565.8906 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.4941
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5801/10000 (58.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.7749s / 22646.6655 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5104
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5821/10000 (58.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.5796s / 22726.2451 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5871
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5841/10000 (58.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.7334s / 22806.9785 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.6928
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5861/10000 (58.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.4786s / 22887.4571 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.8427
env0_second_0:                 episode reward: -0.0500,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5881/10000 (58.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.2754s / 22967.7325 s
env0_first_0:                 episode reward: 0.0000,                 loss: -1.0277
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.2000,                 loss: nan
env2_second_0:                 episode reward: -0.2000,                 loss: nan
env3_first_0:                 episode reward: 0.2000,                 loss: nan
env3_second_0:                 episode reward: -0.2000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5901/10000 (59.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.5742s / 23047.3067 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.4256
env0_second_0:                 episode reward: 0.4500,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.3500,                 loss: nan
env2_second_0:                 episode reward: -0.3500,                 loss: nan
env3_first_0:                 episode reward: 0.5500,                 loss: nan
env3_second_0:                 episode reward: -0.5500,                 loss: nan
env4_first_0:                 episode reward: -0.3000,                 loss: nan
env4_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 5921/10000 (59.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.0690s / 23127.3757 s
env0_first_0:                 episode reward: -0.7500,                 loss: -0.1896
env0_second_0:                 episode reward: 0.7500,                 loss: nan
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
env2_first_0:                 episode reward: 0.4500,                 loss: nan
env2_second_0:                 episode reward: -0.4500,                 loss: nan
env3_first_0:                 episode reward: -0.1000,                 loss: nan
env3_second_0:                 episode reward: 0.1000,                 loss: nan
env4_first_0:                 episode reward: 0.4500,                 loss: nan
env4_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 5941/10000 (59.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.9664s / 23208.3420 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.7003
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
env2_first_0:                 episode reward: -0.7000,                 loss: nan
env2_second_0:                 episode reward: 0.7000,                 loss: nan
env3_first_0:                 episode reward: -0.2500,                 loss: nan
env3_second_0:                 episode reward: 0.2500,                 loss: nan
env4_first_0:                 episode reward: 0.1000,                 loss: nan
env4_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 5961/10000 (59.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.6667s / 23288.0088 s
env0_first_0:                 episode reward: -0.6000,                 loss: 1.2761
env0_second_0:                 episode reward: 0.6000,                 loss: nan
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
env2_first_0:                 episode reward: -1.3000,                 loss: nan
env2_second_0:                 episode reward: 1.3000,                 loss: nan
env3_first_0:                 episode reward: -1.7500,                 loss: nan
env3_second_0:                 episode reward: 1.7500,                 loss: nan
env4_first_0:                 episode reward: -0.5500,                 loss: nan
env4_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 5981/10000 (59.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.9504s / 23367.9592 s
env0_first_0:                 episode reward: -5.1500,                 loss: 5.4136
env0_second_0:                 episode reward: 5.1500,                 loss: nan
env1_first_0:                 episode reward: -5.4000,                 loss: nan
env1_second_0:                 episode reward: 5.4000,                 loss: nan
env2_first_0:                 episode reward: -4.4000,                 loss: nan
env2_second_0:                 episode reward: 4.4000,                 loss: nan
env3_first_0:                 episode reward: -3.4000,                 loss: nan
env3_second_0:                 episode reward: 3.4000,                 loss: nan
env4_first_0:                 episode reward: -6.8000,                 loss: nan
env4_second_0:                 episode reward: 6.8000,                 loss: nan
Episode: 6001/10000 (60.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.8775s / 23447.8367 s
env0_first_0:                 episode reward: -7.3500,                 loss: 12.2424
env0_second_0:                 episode reward: 7.3500,                 loss: nan
env1_first_0:                 episode reward: -12.5500,                 loss: nan
env1_second_0:                 episode reward: 12.5500,                 loss: nan
env2_first_0:                 episode reward: -7.2500,                 loss: nan
env2_second_0:                 episode reward: 7.2500,                 loss: nan
env3_first_0:                 episode reward: -11.9000,                 loss: nan
env3_second_0:                 episode reward: 11.9000,                 loss: nan
env4_first_0:                 episode reward: -10.4500,                 loss: nan
env4_second_0:                 episode reward: 10.4500,                 loss: nan
Episode: 6021/10000 (60.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.1944s / 23526.0311 s
env0_first_0:                 episode reward: -8.2000,                 loss: 15.3209
env0_second_0:                 episode reward: 8.2000,                 loss: nan
env1_first_0:                 episode reward: -6.8000,                 loss: nan
env1_second_0:                 episode reward: 6.8000,                 loss: nan
env2_first_0:                 episode reward: -12.7000,                 loss: nan
env2_second_0:                 episode reward: 12.7000,                 loss: nan
env3_first_0:                 episode reward: -9.5000,                 loss: nan
env3_second_0:                 episode reward: 9.5000,                 loss: nan
env4_first_0:                 episode reward: -12.4500,                 loss: nan
env4_second_0:                 episode reward: 12.4500,                 loss: nan
Episode: 6041/10000 (60.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.7312s / 23606.7623 s
env0_first_0:                 episode reward: -2.0000,                 loss: 4.8844
env0_second_0:                 episode reward: 2.0000,                 loss: nan
env1_first_0:                 episode reward: -2.3500,                 loss: nan
env1_second_0:                 episode reward: 2.3500,                 loss: nan
env2_first_0:                 episode reward: -2.0500,                 loss: nan
env2_second_0:                 episode reward: 2.0500,                 loss: nan
env3_first_0:                 episode reward: -1.3500,                 loss: nan
env3_second_0:                 episode reward: 1.3500,                 loss: nan
env4_first_0:                 episode reward: -1.3500,                 loss: nan
env4_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 6061/10000 (60.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.4277s / 23687.1900 s
env0_first_0:                 episode reward: -5.3000,                 loss: 13.3279
env0_second_0:                 episode reward: 5.3000,                 loss: nan
env1_first_0:                 episode reward: -7.1500,                 loss: nan
env1_second_0:                 episode reward: 7.1500,                 loss: nan
env2_first_0:                 episode reward: -5.8500,                 loss: nan
env2_second_0:                 episode reward: 5.8500,                 loss: nan
env3_first_0:                 episode reward: -3.9500,                 loss: nan
env3_second_0:                 episode reward: 3.9500,                 loss: nan
env4_first_0:                 episode reward: -9.4500,                 loss: nan
env4_second_0:                 episode reward: 9.4500,                 loss: nan
Episode: 6081/10000 (60.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.1687s / 23766.3587 s
env0_first_0:                 episode reward: -5.6500,                 loss: 13.5464
env0_second_0:                 episode reward: 5.6500,                 loss: nan
env1_first_0:                 episode reward: -5.4500,                 loss: nan
env1_second_0:                 episode reward: 5.4500,                 loss: nan
env2_first_0:                 episode reward: -4.6000,                 loss: nan
env2_second_0:                 episode reward: 4.6000,                 loss: nan
env3_first_0:                 episode reward: -5.3500,                 loss: nan
env3_second_0:                 episode reward: 5.3500,                 loss: nan
env4_first_0:                 episode reward: -5.4000,                 loss: nan
env4_second_0:                 episode reward: 5.4000,                 loss: nan
Episode: 6101/10000 (61.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.9192s / 23845.2779 s
env0_first_0:                 episode reward: -6.5000,                 loss: 14.1056
env0_second_0:                 episode reward: 6.5000,                 loss: nan
env1_first_0:                 episode reward: -2.5500,                 loss: nan
env1_second_0:                 episode reward: 2.5500,                 loss: nan
env2_first_0:                 episode reward: -5.7500,                 loss: nan
env2_second_0:                 episode reward: 5.7500,                 loss: nan
env3_first_0:                 episode reward: -5.7500,                 loss: nan
env3_second_0:                 episode reward: 5.7500,                 loss: nan
env4_first_0:                 episode reward: -5.5500,                 loss: nan
env4_second_0:                 episode reward: 5.5500,                 loss: nan
Episode: 6121/10000 (61.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.5965s / 23925.8744 s
env0_first_0:                 episode reward: -4.6500,                 loss: 12.9874
env0_second_0:                 episode reward: 4.6500,                 loss: nan
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
env2_first_0:                 episode reward: -7.1500,                 loss: nan
env2_second_0:                 episode reward: 7.1500,                 loss: nan
env3_first_0:                 episode reward: -1.2000,                 loss: nan
env3_second_0:                 episode reward: 1.2000,                 loss: nan
env4_first_0:                 episode reward: -5.2500,                 loss: nan
env4_second_0:                 episode reward: 5.2500,                 loss: nan
Episode: 6141/10000 (61.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.8533s / 24005.7277 s
env0_first_0:                 episode reward: -6.4000,                 loss: 13.7114
env0_second_0:                 episode reward: 6.4000,                 loss: nan
env1_first_0:                 episode reward: -5.0500,                 loss: nan
env1_second_0:                 episode reward: 5.0500,                 loss: nan
env2_first_0:                 episode reward: -4.4000,                 loss: nan
env2_second_0:                 episode reward: 4.4000,                 loss: nan
env3_first_0:                 episode reward: -6.3500,                 loss: nan
env3_second_0:                 episode reward: 6.3500,                 loss: nan
env4_first_0:                 episode reward: -6.8000,                 loss: nan
env4_second_0:                 episode reward: 6.8000,                 loss: nan
Episode: 6161/10000 (61.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.0379s / 24084.7656 s
env0_first_0:                 episode reward: -8.6500,                 loss: 18.6218
env0_second_0:                 episode reward: 8.6500,                 loss: nan
env1_first_0:                 episode reward: -11.7000,                 loss: nan
env1_second_0:                 episode reward: 11.7000,                 loss: nan
env2_first_0:                 episode reward: -9.0000,                 loss: nan
env2_second_0:                 episode reward: 9.0000,                 loss: nan
env3_first_0:                 episode reward: -10.5500,                 loss: nan
env3_second_0:                 episode reward: 10.5500,                 loss: nan
env4_first_0:                 episode reward: -12.0000,                 loss: nan
env4_second_0:                 episode reward: 12.0000,                 loss: nan
Episode: 6181/10000 (61.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.5123s / 24164.2779 s
env0_first_0:                 episode reward: -11.4000,                 loss: 21.8852
env0_second_0:                 episode reward: 11.4000,                 loss: nan
env1_first_0:                 episode reward: -8.9000,                 loss: nan
env1_second_0:                 episode reward: 8.9000,                 loss: nan
env2_first_0:                 episode reward: -9.6000,                 loss: nan
env2_second_0:                 episode reward: 9.6000,                 loss: nan
env3_first_0:                 episode reward: -9.8000,                 loss: nan
env3_second_0:                 episode reward: 9.8000,                 loss: nan
env4_first_0:                 episode reward: -9.7500,                 loss: nan
env4_second_0:                 episode reward: 9.7500,                 loss: nan
Episode: 6201/10000 (62.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.5638s / 24243.8417 s
env0_first_0:                 episode reward: -7.2000,                 loss: 22.1721
env0_second_0:                 episode reward: 7.2000,                 loss: nan
env1_first_0:                 episode reward: -7.2000,                 loss: nan
env1_second_0:                 episode reward: 7.2000,                 loss: nan
env2_first_0:                 episode reward: -6.0000,                 loss: nan
env2_second_0:                 episode reward: 6.0000,                 loss: nan
env3_first_0:                 episode reward: -6.7500,                 loss: nan
env3_second_0:                 episode reward: 6.7500,                 loss: nan
env4_first_0:                 episode reward: -6.0000,                 loss: nan
env4_second_0:                 episode reward: 6.0000,                 loss: nan
Episode: 6221/10000 (62.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.1228s / 24323.9644 s
env0_first_0:                 episode reward: -11.7000,                 loss: 23.7481
env0_second_0:                 episode reward: 11.7000,                 loss: nan
env1_first_0:                 episode reward: -4.4500,                 loss: nan
env1_second_0:                 episode reward: 4.4500,                 loss: nan
env2_first_0:                 episode reward: -7.1000,                 loss: nan
env2_second_0:                 episode reward: 7.1000,                 loss: nan
env3_first_0:                 episode reward: -13.4500,                 loss: nan
env3_second_0:                 episode reward: 13.4500,                 loss: nan
env4_first_0:                 episode reward: -8.2500,                 loss: nan
env4_second_0:                 episode reward: 8.2500,                 loss: nan
Episode: 6241/10000 (62.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.1796s / 24404.1440 s
env0_first_0:                 episode reward: -6.5000,                 loss: 26.6819
env0_second_0:                 episode reward: 6.5000,                 loss: nan
env1_first_0:                 episode reward: -5.9000,                 loss: nan
env1_second_0:                 episode reward: 5.9000,                 loss: nan
env2_first_0:                 episode reward: -6.6500,                 loss: nan
env2_second_0:                 episode reward: 6.6500,                 loss: nan
env3_first_0:                 episode reward: -10.7500,                 loss: nan
env3_second_0:                 episode reward: 10.7500,                 loss: nan
env4_first_0:                 episode reward: -11.6000,                 loss: nan
env4_second_0:                 episode reward: 11.6000,                 loss: nan
Episode: 6261/10000 (62.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.0676s / 24483.2116 s
env0_first_0:                 episode reward: -10.1000,                 loss: 33.3704
env0_second_0:                 episode reward: 10.1000,                 loss: nan
env1_first_0:                 episode reward: -15.7500,                 loss: nan
env1_second_0:                 episode reward: 15.7500,                 loss: nan
env2_first_0:                 episode reward: -13.0500,                 loss: nan
env2_second_0:                 episode reward: 13.0500,                 loss: nan
env3_first_0:                 episode reward: -13.0000,                 loss: nan
env3_second_0:                 episode reward: 13.0000,                 loss: nan
env4_first_0:                 episode reward: -10.5000,                 loss: nan
env4_second_0:                 episode reward: 10.5000,                 loss: nan
Episode: 6281/10000 (62.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.2923s / 24563.5039 s
env0_first_0:                 episode reward: -14.5500,                 loss: 37.1520
env0_second_0:                 episode reward: 14.5500,                 loss: nan
env1_first_0:                 episode reward: -15.5500,                 loss: nan
env1_second_0:                 episode reward: 15.5500,                 loss: nan
env2_first_0:                 episode reward: -10.2500,                 loss: nan
env2_second_0:                 episode reward: 10.2500,                 loss: nan
env3_first_0:                 episode reward: -9.5000,                 loss: nan
env3_second_0:                 episode reward: 9.5000,                 loss: nan
env4_first_0:                 episode reward: -17.8500,                 loss: nan
env4_second_0:                 episode reward: 17.8500,                 loss: nan
Episode: 6301/10000 (63.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.4836s / 24643.9875 s
env0_first_0:                 episode reward: -22.7000,                 loss: 49.5027
env0_second_0:                 episode reward: 22.7000,                 loss: nan
env1_first_0:                 episode reward: -17.8500,                 loss: nan
env1_second_0:                 episode reward: 17.8500,                 loss: nan
env2_first_0:                 episode reward: -24.1000,                 loss: nan
env2_second_0:                 episode reward: 24.1000,                 loss: nan
env3_first_0:                 episode reward: -16.6500,                 loss: nan
env3_second_0:                 episode reward: 16.6500,                 loss: nan
env4_first_0:                 episode reward: -21.2000,                 loss: nan
env4_second_0:                 episode reward: 21.2000,                 loss: nan
Episode: 6321/10000 (63.2100%),                 avg. length: 298.1,                last time consumption/overall running time: 78.7812s / 24722.7687 s
env0_first_0:                 episode reward: -41.5500,                 loss: 66.5773
env0_second_0:                 episode reward: 41.5500,                 loss: nan
env1_first_0:                 episode reward: -43.2000,                 loss: nan
env1_second_0:                 episode reward: 43.2000,                 loss: nan
env2_first_0:                 episode reward: -35.5500,                 loss: nan
env2_second_0:                 episode reward: 35.5500,                 loss: nan
env3_first_0:                 episode reward: -39.0000,                 loss: nan
env3_second_0:                 episode reward: 39.0000,                 loss: nan
env4_first_0:                 episode reward: -34.3000,                 loss: nan
env4_second_0:                 episode reward: 34.3000,                 loss: nan
Episode: 6341/10000 (63.4100%),                 avg. length: 297.1,                last time consumption/overall running time: 79.7686s / 24802.5373 s
env0_first_0:                 episode reward: -46.0500,                 loss: 76.2067
env0_second_0:                 episode reward: 46.0500,                 loss: nan
env1_first_0:                 episode reward: -44.8500,                 loss: nan
env1_second_0:                 episode reward: 44.8500,                 loss: nan
env2_first_0:                 episode reward: -43.9500,                 loss: nan
env2_second_0:                 episode reward: 43.9500,                 loss: nan
env3_first_0:                 episode reward: -50.5500,                 loss: nan
env3_second_0:                 episode reward: 50.5500,                 loss: nan
env4_first_0:                 episode reward: -49.9000,                 loss: nan
env4_second_0:                 episode reward: 49.9000,                 loss: nan
Episode: 6361/10000 (63.6100%),                 avg. length: 291.95,                last time consumption/overall running time: 76.6598s / 24879.1972 s
env0_first_0:                 episode reward: -50.8500,                 loss: 87.5162
env0_second_0:                 episode reward: 50.8500,                 loss: nan
env1_first_0:                 episode reward: -43.2500,                 loss: nan
env1_second_0:                 episode reward: 43.2500,                 loss: nan
env2_first_0:                 episode reward: -55.5500,                 loss: nan
env2_second_0:                 episode reward: 55.5500,                 loss: nan
env3_first_0:                 episode reward: -56.3000,                 loss: nan
env3_second_0:                 episode reward: 56.3000,                 loss: nan
env4_first_0:                 episode reward: -59.5000,                 loss: nan
env4_second_0:                 episode reward: 59.5000,                 loss: nan
Episode: 6381/10000 (63.8100%),                 avg. length: 296.0,                last time consumption/overall running time: 77.4657s / 24956.6629 s
env0_first_0:                 episode reward: -48.8000,                 loss: 92.0220
env0_second_0:                 episode reward: 48.8000,                 loss: nan
env1_first_0:                 episode reward: -54.8500,                 loss: nan
env1_second_0:                 episode reward: 54.8500,                 loss: nan
env2_first_0:                 episode reward: -47.0500,                 loss: nan
env2_second_0:                 episode reward: 47.0500,                 loss: nan
env3_first_0:                 episode reward: -50.5000,                 loss: nan
env3_second_0:                 episode reward: 50.5000,                 loss: nan
env4_first_0:                 episode reward: -40.9500,                 loss: nan
env4_second_0:                 episode reward: 40.9500,                 loss: nan
Episode: 6401/10000 (64.0100%),                 avg. length: 296.2,                last time consumption/overall running time: 78.9159s / 25035.5788 s
env0_first_0:                 episode reward: -16.6000,                 loss: 59.8240
env0_second_0:                 episode reward: 16.6000,                 loss: nan
env1_first_0:                 episode reward: -17.7500,                 loss: nan
env1_second_0:                 episode reward: 17.7500,                 loss: nan
env2_first_0:                 episode reward: -23.4000,                 loss: nan
env2_second_0:                 episode reward: 23.4000,                 loss: nan
env3_first_0:                 episode reward: -16.1000,                 loss: nan
env3_second_0:                 episode reward: 16.1000,                 loss: nan
env4_first_0:                 episode reward: -27.2000,                 loss: nan
env4_second_0:                 episode reward: 27.2000,                 loss: nan
Episode: 6421/10000 (64.2100%),                 avg. length: 286.95,                last time consumption/overall running time: 78.0884s / 25113.6672 s
env0_first_0:                 episode reward: -46.7000,                 loss: 120.8582
env0_second_0:                 episode reward: 46.7000,                 loss: nan
env1_first_0:                 episode reward: -52.6500,                 loss: nan
env1_second_0:                 episode reward: 52.6500,                 loss: nan
env2_first_0:                 episode reward: -49.4000,                 loss: nan
env2_second_0:                 episode reward: 49.4000,                 loss: nan
env3_first_0:                 episode reward: -45.9000,                 loss: nan
env3_second_0:                 episode reward: 45.9000,                 loss: nan
env4_first_0:                 episode reward: -58.5000,                 loss: nan
env4_second_0:                 episode reward: 58.5000,                 loss: nan
Episode: 6441/10000 (64.4100%),                 avg. length: 285.7,                last time consumption/overall running time: 76.5487s / 25190.2159 s
env0_first_0:                 episode reward: -53.7000,                 loss: 104.3299
env0_second_0:                 episode reward: 53.7000,                 loss: nan
env1_first_0:                 episode reward: -53.7000,                 loss: nan
env1_second_0:                 episode reward: 53.7000,                 loss: nan
env2_first_0:                 episode reward: -48.7500,                 loss: nan
env2_second_0:                 episode reward: 48.7500,                 loss: nan
env3_first_0:                 episode reward: -59.6000,                 loss: nan
env3_second_0:                 episode reward: 59.6000,                 loss: nan
env4_first_0:                 episode reward: -55.4000,                 loss: nan
env4_second_0:                 episode reward: 55.4000,                 loss: nan
Episode: 6461/10000 (64.6100%),                 avg. length: 270.45,                last time consumption/overall running time: 73.9831s / 25264.1990 s
env0_first_0:                 episode reward: -57.8000,                 loss: 142.0884
env0_second_0:                 episode reward: 57.8000,                 loss: nan
env1_first_0:                 episode reward: -68.3500,                 loss: nan
env1_second_0:                 episode reward: 68.3500,                 loss: nan
env2_first_0:                 episode reward: -59.0000,                 loss: nan
env2_second_0:                 episode reward: 59.0000,                 loss: nan
env3_first_0:                 episode reward: -65.0000,                 loss: nan
env3_second_0:                 episode reward: 65.0000,                 loss: nan
env4_first_0:                 episode reward: -57.3500,                 loss: nan
env4_second_0:                 episode reward: 57.3500,                 loss: nan
Episode: 6481/10000 (64.8100%),                 avg. length: 267.6,                last time consumption/overall running time: 73.6487s / 25337.8477 s
env0_first_0:                 episode reward: -58.0000,                 loss: 141.9536
env0_second_0:                 episode reward: 58.0000,                 loss: nan
env1_first_0:                 episode reward: -63.4500,                 loss: nan
env1_second_0:                 episode reward: 63.4500,                 loss: nan
env2_first_0:                 episode reward: -65.7000,                 loss: nan
env2_second_0:                 episode reward: 65.7000,                 loss: nan
env3_first_0:                 episode reward: -70.1500,                 loss: nan
env3_second_0:                 episode reward: 70.1500,                 loss: nan
env4_first_0:                 episode reward: -57.1000,                 loss: nan
env4_second_0:                 episode reward: 57.1000,                 loss: nan
Episode: 6501/10000 (65.0100%),                 avg. length: 294.6,                last time consumption/overall running time: 78.4385s / 25416.2862 s
env0_first_0:                 episode reward: -34.9000,                 loss: 55.5305
env0_second_0:                 episode reward: 34.9000,                 loss: nan
env1_first_0:                 episode reward: -17.5000,                 loss: nan
env1_second_0:                 episode reward: 17.5000,                 loss: nan
env2_first_0:                 episode reward: -13.8500,                 loss: nan
env2_second_0:                 episode reward: 13.8500,                 loss: nan
env3_first_0:                 episode reward: -26.7000,                 loss: nan
env3_second_0:                 episode reward: 26.7000,                 loss: nan
env4_first_0:                 episode reward: -22.2500,                 loss: nan
env4_second_0:                 episode reward: 22.2500,                 loss: nan
Episode: 6521/10000 (65.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.9146s / 25494.2008 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.0334
env0_second_0:                 episode reward: -0.0500,                 loss: nan
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
env3_first_0:                 episode reward: -0.1000,                 loss: nan
env3_second_0:                 episode reward: 0.1000,                 loss: nan
env4_first_0:                 episode reward: 0.2000,                 loss: nan
env4_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 6541/10000 (65.4100%),                 avg. length: 297.95,                last time consumption/overall running time: 79.3393s / 25573.5401 s
env0_first_0:                 episode reward: -3.5000,                 loss: 5.9622
env0_second_0:                 episode reward: 3.5000,                 loss: nan
env1_first_0:                 episode reward: -5.2500,                 loss: nan
env1_second_0:                 episode reward: 5.2500,                 loss: nan
env2_first_0:                 episode reward: -1.5500,                 loss: nan
env2_second_0:                 episode reward: 1.5500,                 loss: nan
env3_first_0:                 episode reward: -1.1000,                 loss: nan
env3_second_0:                 episode reward: 1.1000,                 loss: nan
env4_first_0:                 episode reward: 0.1000,                 loss: nan
env4_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 6561/10000 (65.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.9877s / 25653.5278 s
env0_first_0:                 episode reward: -3.4000,                 loss: 22.4366
env0_second_0:                 episode reward: 3.4000,                 loss: nan
env1_first_0:                 episode reward: -7.8500,                 loss: nan
env1_second_0:                 episode reward: 7.8500,                 loss: nan
env2_first_0:                 episode reward: -7.2000,                 loss: nan
env2_second_0:                 episode reward: 7.2000,                 loss: nan
env3_first_0:                 episode reward: -5.6500,                 loss: nan
env3_second_0:                 episode reward: 5.6500,                 loss: nan
env4_first_0:                 episode reward: -6.3500,                 loss: nan
env4_second_0:                 episode reward: 6.3500,                 loss: nan
Episode: 6581/10000 (65.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 81.0040s / 25734.5317 s
env0_first_0:                 episode reward: -0.2000,                 loss: 1.7800
env0_second_0:                 episode reward: 0.2000,                 loss: nan
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
env2_first_0:                 episode reward: -0.3500,                 loss: nan
env2_second_0:                 episode reward: 0.3500,                 loss: nan
env3_first_0:                 episode reward: -0.5000,                 loss: nan
env3_second_0:                 episode reward: 0.5000,                 loss: nan
env4_first_0:                 episode reward: -0.7000,                 loss: nan
env4_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 6601/10000 (66.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 81.4651s / 25815.9969 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.6927
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.5500,                 loss: nan
env2_second_0:                 episode reward: -0.5500,                 loss: nan
env3_first_0:                 episode reward: -1.1000,                 loss: nan
env3_second_0:                 episode reward: 1.1000,                 loss: nan
env4_first_0:                 episode reward: -0.4000,                 loss: nan
env4_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 6621/10000 (66.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 81.5491s / 25897.5460 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.6554
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.1000,                 loss: nan
env2_second_0:                 episode reward: -0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0500,                 loss: nan
env4_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 6641/10000 (66.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.3843s / 25977.9302 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.5937
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: -0.1000,                 loss: nan
env4_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 6661/10000 (66.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.8720s / 26058.8023 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.6734
env0_second_0:                 episode reward: 0.1000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0500,                 loss: nan
env2_second_0:                 episode reward: -0.0500,                 loss: nan
env3_first_0:                 episode reward: -0.1000,                 loss: nan
env3_second_0:                 episode reward: 0.1000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 6681/10000 (66.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.8587s / 26139.6610 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.6098
env0_second_0:                 episode reward: 0.2000,                 loss: nan
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
env2_first_0:                 episode reward: 0.2000,                 loss: nan
env2_second_0:                 episode reward: -0.2000,                 loss: nan
env3_first_0:                 episode reward: 0.4000,                 loss: nan
env3_second_0:                 episode reward: -0.4000,                 loss: nan
env4_first_0:                 episode reward: -0.2500,                 loss: nan
env4_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 6701/10000 (67.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.9947s / 26220.6557 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.2035
env0_second_0:                 episode reward: 1.3500,                 loss: nan
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
env2_first_0:                 episode reward: 0.2500,                 loss: nan
env2_second_0:                 episode reward: -0.2500,                 loss: nan
env3_first_0:                 episode reward: -0.7500,                 loss: nan
env3_second_0:                 episode reward: 0.7500,                 loss: nan
env4_first_0:                 episode reward: -0.9000,                 loss: nan
env4_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 6721/10000 (67.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.3125s / 26299.9683 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.9939
env0_second_0:                 episode reward: 1.2500,                 loss: nan
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
env2_first_0:                 episode reward: 0.1500,                 loss: nan
env2_second_0:                 episode reward: -0.1500,                 loss: nan
env3_first_0:                 episode reward: -0.9500,                 loss: nan
env3_second_0:                 episode reward: 0.9500,                 loss: nan
env4_first_0:                 episode reward: -0.2500,                 loss: nan
env4_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 6741/10000 (67.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.8514s / 26379.8197 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.4199
env0_second_0:                 episode reward: 0.9000,                 loss: nan
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
env2_first_0:                 episode reward: -0.7000,                 loss: nan
env2_second_0:                 episode reward: 0.7000,                 loss: nan
env3_first_0:                 episode reward: -0.3000,                 loss: nan
env3_second_0:                 episode reward: 0.3000,                 loss: nan
env4_first_0:                 episode reward: -0.1500,                 loss: nan
env4_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 6761/10000 (67.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.9053s / 26460.7250 s
env0_first_0:                 episode reward: -12.8500,                 loss: 22.0303
env0_second_0:                 episode reward: 12.8500,                 loss: nan
env1_first_0:                 episode reward: -14.7000,                 loss: nan
env1_second_0:                 episode reward: 14.7000,                 loss: nan
env2_first_0:                 episode reward: -17.2000,                 loss: nan
env2_second_0:                 episode reward: 17.2000,                 loss: nan
env3_first_0:                 episode reward: -17.8500,                 loss: nan
env3_second_0:                 episode reward: 17.8500,                 loss: nan
env4_first_0:                 episode reward: -12.3500,                 loss: nan
env4_second_0:                 episode reward: 12.3500,                 loss: nan
Episode: 6781/10000 (67.8100%),                 avg. length: 296.8,                last time consumption/overall running time: 79.6871s / 26540.4122 s
env0_first_0:                 episode reward: -27.6500,                 loss: 51.5292
env0_second_0:                 episode reward: 27.6500,                 loss: nan
env1_first_0:                 episode reward: -40.2500,                 loss: nan
env1_second_0:                 episode reward: 40.2500,                 loss: nan
env2_first_0:                 episode reward: -33.5500,                 loss: nan
env2_second_0:                 episode reward: 33.5500,                 loss: nan
env3_first_0:                 episode reward: -35.6000,                 loss: nan
env3_second_0:                 episode reward: 35.6000,                 loss: nan
env4_first_0:                 episode reward: -40.1000,                 loss: nan
env4_second_0:                 episode reward: 40.1000,                 loss: nan
Episode: 6801/10000 (68.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.8748s / 26620.2870 s
env0_first_0:                 episode reward: -44.3500,                 loss: 77.2100
env0_second_0:                 episode reward: 44.3500,                 loss: nan
env1_first_0:                 episode reward: -35.1000,                 loss: nan
env1_second_0:                 episode reward: 35.1000,                 loss: nan
env2_first_0:                 episode reward: -45.6000,                 loss: nan
env2_second_0:                 episode reward: 45.6000,                 loss: nan
env3_first_0:                 episode reward: -43.5500,                 loss: nan
env3_second_0:                 episode reward: 43.5500,                 loss: nan
env4_first_0:                 episode reward: -53.6000,                 loss: nan
env4_second_0:                 episode reward: 53.6000,                 loss: nan
Episode: 6821/10000 (68.2100%),                 avg. length: 297.95,                last time consumption/overall running time: 80.6016s / 26700.8886 s
env0_first_0:                 episode reward: -19.1500,                 loss: 45.5387
env0_second_0:                 episode reward: 19.1500,                 loss: nan
env1_first_0:                 episode reward: -16.3000,                 loss: nan
env1_second_0:                 episode reward: 16.3000,                 loss: nan
env2_first_0:                 episode reward: -15.3000,                 loss: nan
env2_second_0:                 episode reward: 15.3000,                 loss: nan
env3_first_0:                 episode reward: -21.1500,                 loss: nan
env3_second_0:                 episode reward: 21.1500,                 loss: nan
env4_first_0:                 episode reward: -14.6000,                 loss: nan
env4_second_0:                 episode reward: 14.6000,                 loss: nan
Episode: 6841/10000 (68.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.2445s / 26780.1331 s
env0_first_0:                 episode reward: -5.5000,                 loss: 17.4498
env0_second_0:                 episode reward: 5.5000,                 loss: nan
env1_first_0:                 episode reward: -5.8500,                 loss: nan
env1_second_0:                 episode reward: 5.8500,                 loss: nan
env2_first_0:                 episode reward: -4.7000,                 loss: nan
env2_second_0:                 episode reward: 4.7000,                 loss: nan
env3_first_0:                 episode reward: -3.4500,                 loss: nan
env3_second_0:                 episode reward: 3.4500,                 loss: nan
env4_first_0:                 episode reward: -7.1000,                 loss: nan
env4_second_0:                 episode reward: 7.1000,                 loss: nan
Episode: 6861/10000 (68.6100%),                 avg. length: 270.1,                last time consumption/overall running time: 73.8220s / 26853.9552 s
env0_first_0:                 episode reward: -53.4000,                 loss: 126.2263
env0_second_0:                 episode reward: 53.4000,                 loss: nan
env1_first_0:                 episode reward: -62.2500,                 loss: nan
env1_second_0:                 episode reward: 62.2500,                 loss: nan
env2_first_0:                 episode reward: -65.5500,                 loss: nan
env2_second_0:                 episode reward: 65.5500,                 loss: nan
env3_first_0:                 episode reward: -54.8500,                 loss: nan
env3_second_0:                 episode reward: 54.8500,                 loss: nan
env4_first_0:                 episode reward: -51.7500,                 loss: nan
env4_second_0:                 episode reward: 51.7500,                 loss: nan
Episode: 6881/10000 (68.8100%),                 avg. length: 249.1,                last time consumption/overall running time: 69.2867s / 26923.2419 s
env0_first_0:                 episode reward: -66.9500,                 loss: 142.2309
env0_second_0:                 episode reward: 66.9500,                 loss: nan
env1_first_0:                 episode reward: -67.6000,                 loss: nan
env1_second_0:                 episode reward: 67.6000,                 loss: nan
env2_first_0:                 episode reward: -73.6500,                 loss: nan
env2_second_0:                 episode reward: 73.6500,                 loss: nan
env3_first_0:                 episode reward: -67.9000,                 loss: nan
env3_second_0:                 episode reward: 67.9000,                 loss: nan
env4_first_0:                 episode reward: -76.6000,                 loss: nan
env4_second_0:                 episode reward: 76.6000,                 loss: nan
Episode: 6901/10000 (69.0100%),                 avg. length: 249.2,                last time consumption/overall running time: 70.7648s / 26994.0066 s
env0_first_0:                 episode reward: -69.4000,                 loss: 123.9360
env0_second_0:                 episode reward: 69.4000,                 loss: nan
env1_first_0:                 episode reward: -75.4500,                 loss: nan
env1_second_0:                 episode reward: 75.4500,                 loss: nan
env2_first_0:                 episode reward: -77.8500,                 loss: nan
env2_second_0:                 episode reward: 77.8500,                 loss: nan
env3_first_0:                 episode reward: -77.2000,                 loss: nan
env3_second_0:                 episode reward: 77.2000,                 loss: nan
env4_first_0:                 episode reward: -68.8500,                 loss: nan
env4_second_0:                 episode reward: 68.8500,                 loss: nan
Episode: 6921/10000 (69.2100%),                 avg. length: 238.15,                last time consumption/overall running time: 69.0348s / 27063.0414 s
env0_first_0:                 episode reward: -79.0000,                 loss: 126.8303
env0_second_0:                 episode reward: 79.0000,                 loss: nan
env1_first_0:                 episode reward: -73.7500,                 loss: nan
env1_second_0:                 episode reward: 73.7500,                 loss: nan
env2_first_0:                 episode reward: -78.3500,                 loss: nan
env2_second_0:                 episode reward: 78.3500,                 loss: nan
env3_first_0:                 episode reward: -75.4500,                 loss: nan
env3_second_0:                 episode reward: 75.4500,                 loss: nan
env4_first_0:                 episode reward: -77.4500,                 loss: nan
env4_second_0:                 episode reward: 77.4500,                 loss: nan
Episode: 6941/10000 (69.4100%),                 avg. length: 234.25,                last time consumption/overall running time: 65.7932s / 27128.8347 s
env0_first_0:                 episode reward: -78.0000,                 loss: 116.3070
env0_second_0:                 episode reward: 78.0000,                 loss: nan
env1_first_0:                 episode reward: -84.0500,                 loss: nan
env1_second_0:                 episode reward: 84.0500,                 loss: nan
env2_first_0:                 episode reward: -87.2500,                 loss: nan
env2_second_0:                 episode reward: 87.2500,                 loss: nan
env3_first_0:                 episode reward: -87.7500,                 loss: nan
env3_second_0:                 episode reward: 87.7500,                 loss: nan
env4_first_0:                 episode reward: -82.3500,                 loss: nan
env4_second_0:                 episode reward: 82.3500,                 loss: nan
Episode: 6961/10000 (69.6100%),                 avg. length: 234.9,                last time consumption/overall running time: 66.3800s / 27195.2147 s
env0_first_0:                 episode reward: -74.3500,                 loss: 113.2962
env0_second_0:                 episode reward: 74.3500,                 loss: nan
env1_first_0:                 episode reward: -81.1500,                 loss: nan
env1_second_0:                 episode reward: 81.1500,                 loss: nan
env2_first_0:                 episode reward: -72.6000,                 loss: nan
env2_second_0:                 episode reward: 72.6000,                 loss: nan
env3_first_0:                 episode reward: -81.7500,                 loss: nan
env3_second_0:                 episode reward: 81.7500,                 loss: nan
env4_first_0:                 episode reward: -67.2500,                 loss: nan
env4_second_0:                 episode reward: 67.2500,                 loss: nan
Episode: 6981/10000 (69.8100%),                 avg. length: 227.5,                last time consumption/overall running time: 66.4317s / 27261.6464 s
env0_first_0:                 episode reward: -80.8500,                 loss: 114.4874
env0_second_0:                 episode reward: 80.8500,                 loss: nan
env1_first_0:                 episode reward: -84.5000,                 loss: nan
env1_second_0:                 episode reward: 84.5000,                 loss: nan
env2_first_0:                 episode reward: -86.4500,                 loss: nan
env2_second_0:                 episode reward: 86.4500,                 loss: nan
env3_first_0:                 episode reward: -74.0000,                 loss: nan
env3_second_0:                 episode reward: 74.0000,                 loss: nan
env4_first_0:                 episode reward: -74.5000,                 loss: nan
env4_second_0:                 episode reward: 74.5000,                 loss: nan
Episode: 7001/10000 (70.0100%),                 avg. length: 242.55,                last time consumption/overall running time: 69.3593s / 27331.0057 s
env0_first_0:                 episode reward: -64.6000,                 loss: 122.4000
env0_second_0:                 episode reward: 64.6000,                 loss: nan
env1_first_0:                 episode reward: -83.9500,                 loss: nan
env1_second_0:                 episode reward: 83.9500,                 loss: nan
env2_first_0:                 episode reward: -70.7500,                 loss: nan
env2_second_0:                 episode reward: 70.7500,                 loss: nan
env3_first_0:                 episode reward: -60.4000,                 loss: nan
env3_second_0:                 episode reward: 60.4000,                 loss: nan
env4_first_0:                 episode reward: -66.6500,                 loss: nan
env4_second_0:                 episode reward: 66.6500,                 loss: nan
Episode: 7021/10000 (70.2100%),                 avg. length: 255.0,                last time consumption/overall running time: 69.6990s / 27400.7048 s
env0_first_0:                 episode reward: -60.4500,                 loss: 136.7121
env0_second_0:                 episode reward: 60.4500,                 loss: nan
env1_first_0:                 episode reward: -60.1500,                 loss: nan
env1_second_0:                 episode reward: 60.1500,                 loss: nan
env2_first_0:                 episode reward: -72.8500,                 loss: nan
env2_second_0:                 episode reward: 72.8500,                 loss: nan
env3_first_0:                 episode reward: -55.2000,                 loss: nan
env3_second_0:                 episode reward: 55.2000,                 loss: nan
env4_first_0:                 episode reward: -60.7000,                 loss: nan
env4_second_0:                 episode reward: 60.7000,                 loss: nan
Episode: 7041/10000 (70.4100%),                 avg. length: 239.55,                last time consumption/overall running time: 67.1915s / 27467.8963 s
env0_first_0:                 episode reward: -80.4500,                 loss: 119.4650
env0_second_0:                 episode reward: 80.4500,                 loss: nan
env1_first_0:                 episode reward: -74.9000,                 loss: nan
env1_second_0:                 episode reward: 74.9000,                 loss: nan
env2_first_0:                 episode reward: -76.7500,                 loss: nan
env2_second_0:                 episode reward: 76.7500,                 loss: nan
env3_first_0:                 episode reward: -81.9000,                 loss: nan
env3_second_0:                 episode reward: 81.9000,                 loss: nan
env4_first_0:                 episode reward: -83.8000,                 loss: nan
env4_second_0:                 episode reward: 83.8000,                 loss: nan
Episode: 7061/10000 (70.6100%),                 avg. length: 248.3,                last time consumption/overall running time: 68.7892s / 27536.6855 s
env0_first_0:                 episode reward: -80.7500,                 loss: 101.0150
env0_second_0:                 episode reward: 80.7500,                 loss: nan
env1_first_0:                 episode reward: -79.2500,                 loss: nan
env1_second_0:                 episode reward: 79.2500,                 loss: nan
env2_first_0:                 episode reward: -79.2000,                 loss: nan
env2_second_0:                 episode reward: 79.2000,                 loss: nan
env3_first_0:                 episode reward: -75.9500,                 loss: nan
env3_second_0:                 episode reward: 75.9500,                 loss: nan
env4_first_0:                 episode reward: -73.4500,                 loss: nan
env4_second_0:                 episode reward: 73.4500,                 loss: nan
Episode: 7081/10000 (70.8100%),                 avg. length: 253.7,                last time consumption/overall running time: 69.3156s / 27606.0011 s
env0_first_0:                 episode reward: -72.4500,                 loss: 95.1002
env0_second_0:                 episode reward: 72.4500,                 loss: nan
env1_first_0:                 episode reward: -77.4000,                 loss: nan
env1_second_0:                 episode reward: 77.4000,                 loss: nan
env2_first_0:                 episode reward: -80.5500,                 loss: nan
env2_second_0:                 episode reward: 80.5500,                 loss: nan
env3_first_0:                 episode reward: -85.2500,                 loss: nan
env3_second_0:                 episode reward: 85.2500,                 loss: nan
env4_first_0:                 episode reward: -80.5000,                 loss: nan
env4_second_0:                 episode reward: 80.5000,                 loss: nan
Episode: 7101/10000 (71.0100%),                 avg. length: 227.3,                last time consumption/overall running time: 64.4098s / 27670.4109 s
env0_first_0:                 episode reward: -84.1500,                 loss: 87.0141
env0_second_0:                 episode reward: 84.1500,                 loss: nan
env1_first_0:                 episode reward: -79.3000,                 loss: nan
env1_second_0:                 episode reward: 79.3000,                 loss: nan
env2_first_0:                 episode reward: -88.7500,                 loss: nan
env2_second_0:                 episode reward: 88.7500,                 loss: nan
env3_first_0:                 episode reward: -82.6000,                 loss: nan
env3_second_0:                 episode reward: 82.6000,                 loss: nan
env4_first_0:                 episode reward: -78.1500,                 loss: nan
env4_second_0:                 episode reward: 78.1500,                 loss: nan
Episode: 7121/10000 (71.2100%),                 avg. length: 221.9,                last time consumption/overall running time: 61.8790s / 27732.2899 s
env0_first_0:                 episode reward: -84.0500,                 loss: 82.2466
env0_second_0:                 episode reward: 84.0500,                 loss: nan
env1_first_0:                 episode reward: -87.5500,                 loss: nan
env1_second_0:                 episode reward: 87.5500,                 loss: nan
env2_first_0:                 episode reward: -83.1000,                 loss: nan
env2_second_0:                 episode reward: 83.1000,                 loss: nan
env3_first_0:                 episode reward: -85.2500,                 loss: nan
env3_second_0:                 episode reward: 85.2500,                 loss: nan
env4_first_0:                 episode reward: -86.8500,                 loss: nan
env4_second_0:                 episode reward: 86.8500,                 loss: nan
Episode: 7141/10000 (71.4100%),                 avg. length: 242.35,                last time consumption/overall running time: 66.6341s / 27798.9240 s
env0_first_0:                 episode reward: -70.7500,                 loss: 85.0031
env0_second_0:                 episode reward: 70.7500,                 loss: nan
env1_first_0:                 episode reward: -84.9000,                 loss: nan
env1_second_0:                 episode reward: 84.9000,                 loss: nan
env2_first_0:                 episode reward: -79.5500,                 loss: nan
env2_second_0:                 episode reward: 79.5500,                 loss: nan
env3_first_0:                 episode reward: -77.5000,                 loss: nan
env3_second_0:                 episode reward: 77.5000,                 loss: nan
env4_first_0:                 episode reward: -75.0000,                 loss: nan
env4_second_0:                 episode reward: 75.0000,                 loss: nan
Episode: 7161/10000 (71.6100%),                 avg. length: 230.6,                last time consumption/overall running time: 65.0270s / 27863.9511 s
env0_first_0:                 episode reward: -83.1000,                 loss: 83.4457
env0_second_0:                 episode reward: 83.1000,                 loss: nan
env1_first_0:                 episode reward: -87.7000,                 loss: nan
env1_second_0:                 episode reward: 87.7000,                 loss: nan
env2_first_0:                 episode reward: -81.2500,                 loss: nan
env2_second_0:                 episode reward: 81.2500,                 loss: nan
env3_first_0:                 episode reward: -83.1500,                 loss: nan
env3_second_0:                 episode reward: 83.1500,                 loss: nan
env4_first_0:                 episode reward: -80.7000,                 loss: nan
env4_second_0:                 episode reward: 80.7000,                 loss: nan
Episode: 7181/10000 (71.8100%),                 avg. length: 265.2,                last time consumption/overall running time: 71.8754s / 27935.8264 s
env0_first_0:                 episode reward: -57.8500,                 loss: 97.9827
env0_second_0:                 episode reward: 57.8500,                 loss: nan
env1_first_0:                 episode reward: -50.2000,                 loss: nan
env1_second_0:                 episode reward: 50.2000,                 loss: nan
env2_first_0:                 episode reward: -48.2500,                 loss: nan
env2_second_0:                 episode reward: 48.2500,                 loss: nan
env3_first_0:                 episode reward: -62.1500,                 loss: nan
env3_second_0:                 episode reward: 62.1500,                 loss: nan
env4_first_0:                 episode reward: -66.8500,                 loss: nan
env4_second_0:                 episode reward: 66.8500,                 loss: nan
Episode: 7201/10000 (72.0100%),                 avg. length: 252.45,                last time consumption/overall running time: 70.4119s / 28006.2383 s
env0_first_0:                 episode reward: -80.2500,                 loss: 85.9872
env0_second_0:                 episode reward: 80.2500,                 loss: nan
env1_first_0:                 episode reward: -82.1500,                 loss: nan
env1_second_0:                 episode reward: 82.1500,                 loss: nan
env2_first_0:                 episode reward: -77.9000,                 loss: nan
env2_second_0:                 episode reward: 77.9000,                 loss: nan
env3_first_0:                 episode reward: -77.2500,                 loss: nan
env3_second_0:                 episode reward: 77.2500,                 loss: nan
env4_first_0:                 episode reward: -80.8000,                 loss: nan
env4_second_0:                 episode reward: 80.8000,                 loss: nan
Episode: 7221/10000 (72.2100%),                 avg. length: 292.8,                last time consumption/overall running time: 76.2326s / 28082.4710 s
env0_first_0:                 episode reward: -51.8000,                 loss: 85.3328
env0_second_0:                 episode reward: 51.8000,                 loss: nan
env1_first_0:                 episode reward: -49.0000,                 loss: nan
env1_second_0:                 episode reward: 49.0000,                 loss: nan
env2_first_0:                 episode reward: -39.2000,                 loss: nan
env2_second_0:                 episode reward: 39.2000,                 loss: nan
env3_first_0:                 episode reward: -54.8000,                 loss: nan
env3_second_0:                 episode reward: 54.8000,                 loss: nan
env4_first_0:                 episode reward: -55.7500,                 loss: nan
env4_second_0:                 episode reward: 55.7500,                 loss: nan
Episode: 7241/10000 (72.4100%),                 avg. length: 285.5,                last time consumption/overall running time: 75.7074s / 28158.1784 s
env0_first_0:                 episode reward: -55.8000,                 loss: 136.6664
env0_second_0:                 episode reward: 55.8000,                 loss: nan
env1_first_0:                 episode reward: -34.1500,                 loss: nan
env1_second_0:                 episode reward: 34.1500,                 loss: nan
env2_first_0:                 episode reward: -49.9000,                 loss: nan
env2_second_0:                 episode reward: 49.9000,                 loss: nan
env3_first_0:                 episode reward: -39.3500,                 loss: nan
env3_second_0:                 episode reward: 39.3500,                 loss: nan
env4_first_0:                 episode reward: -40.9500,                 loss: nan
env4_second_0:                 episode reward: 40.9500,                 loss: nan
Episode: 7261/10000 (72.6100%),                 avg. length: 277.85,                last time consumption/overall running time: 73.6117s / 28231.7901 s
env0_first_0:                 episode reward: -64.3500,                 loss: 124.1558
env0_second_0:                 episode reward: 64.3500,                 loss: nan
env1_first_0:                 episode reward: -60.8000,                 loss: nan
env1_second_0:                 episode reward: 60.8000,                 loss: nan
env2_first_0:                 episode reward: -50.3500,                 loss: nan
env2_second_0:                 episode reward: 50.3500,                 loss: nan
env3_first_0:                 episode reward: -55.6000,                 loss: nan
env3_second_0:                 episode reward: 55.6000,                 loss: nan
env4_first_0:                 episode reward: -61.0000,                 loss: nan
env4_second_0:                 episode reward: 61.0000,                 loss: nan
Episode: 7281/10000 (72.8100%),                 avg. length: 273.9,                last time consumption/overall running time: 75.0484s / 28306.8385 s
env0_first_0:                 episode reward: -78.2000,                 loss: 120.5257
env0_second_0:                 episode reward: 78.2000,                 loss: nan
env1_first_0:                 episode reward: -63.8500,                 loss: nan
env1_second_0:                 episode reward: 63.8500,                 loss: nan
env2_first_0:                 episode reward: -69.1500,                 loss: nan
env2_second_0:                 episode reward: 69.1500,                 loss: nan
env3_first_0:                 episode reward: -64.5000,                 loss: nan
env3_second_0:                 episode reward: 64.5000,                 loss: nan
env4_first_0:                 episode reward: -57.7000,                 loss: nan
env4_second_0:                 episode reward: 57.7000,                 loss: nan
Episode: 7301/10000 (73.0100%),                 avg. length: 268.85,                last time consumption/overall running time: 73.6679s / 28380.5064 s
env0_first_0:                 episode reward: -78.6500,                 loss: 106.8666
env0_second_0:                 episode reward: 78.6500,                 loss: nan
env1_first_0:                 episode reward: -68.5500,                 loss: nan
env1_second_0:                 episode reward: 68.5500,                 loss: nan
env2_first_0:                 episode reward: -69.3000,                 loss: nan
env2_second_0:                 episode reward: 69.3000,                 loss: nan
env3_first_0:                 episode reward: -69.6500,                 loss: nan
env3_second_0:                 episode reward: 69.6500,                 loss: nan
env4_first_0:                 episode reward: -67.2000,                 loss: nan
env4_second_0:                 episode reward: 67.2000,                 loss: nan
Episode: 7321/10000 (73.2100%),                 avg. length: 246.8,                last time consumption/overall running time: 67.7626s / 28448.2690 s
env0_first_0:                 episode reward: -74.2500,                 loss: 107.9376
env0_second_0:                 episode reward: 74.2500,                 loss: nan
env1_first_0:                 episode reward: -78.5500,                 loss: nan
env1_second_0:                 episode reward: 78.5500,                 loss: nan
env2_first_0:                 episode reward: -78.8500,                 loss: nan
env2_second_0:                 episode reward: 78.8500,                 loss: nan
env3_first_0:                 episode reward: -70.4000,                 loss: nan
env3_second_0:                 episode reward: 70.4000,                 loss: nan
env4_first_0:                 episode reward: -69.8000,                 loss: nan
env4_second_0:                 episode reward: 69.8000,                 loss: nan
Episode: 7341/10000 (73.4100%),                 avg. length: 249.9,                last time consumption/overall running time: 68.3051s / 28516.5741 s
env0_first_0:                 episode reward: -67.0500,                 loss: 116.4171
env0_second_0:                 episode reward: 67.0500,                 loss: nan
env1_first_0:                 episode reward: -75.4000,                 loss: nan
env1_second_0:                 episode reward: 75.4000,                 loss: nan
env2_first_0:                 episode reward: -65.4500,                 loss: nan
env2_second_0:                 episode reward: 65.4500,                 loss: nan
env3_first_0:                 episode reward: -71.7500,                 loss: nan
env3_second_0:                 episode reward: 71.7500,                 loss: nan
env4_first_0:                 episode reward: -75.1000,                 loss: nan
env4_second_0:                 episode reward: 75.1000,                 loss: nan
Episode: 7361/10000 (73.6100%),                 avg. length: 273.05,                last time consumption/overall running time: 74.0564s / 28590.6304 s
env0_first_0:                 episode reward: -48.4000,                 loss: 106.6437
env0_second_0:                 episode reward: 48.4000,                 loss: nan
env1_first_0:                 episode reward: -52.1500,                 loss: nan
env1_second_0:                 episode reward: 52.1500,                 loss: nan
env2_first_0:                 episode reward: -53.5500,                 loss: nan
env2_second_0:                 episode reward: 53.5500,                 loss: nan
env3_first_0:                 episode reward: -48.7000,                 loss: nan
env3_second_0:                 episode reward: 48.7000,                 loss: nan
env4_first_0:                 episode reward: -45.8000,                 loss: nan
env4_second_0:                 episode reward: 45.8000,                 loss: nan
Episode: 7381/10000 (73.8100%),                 avg. length: 274.4,                last time consumption/overall running time: 73.2727s / 28663.9031 s
env0_first_0:                 episode reward: -36.0500,                 loss: 115.6166
env0_second_0:                 episode reward: 36.0500,                 loss: nan
env1_first_0:                 episode reward: -38.8500,                 loss: nan
env1_second_0:                 episode reward: 38.8500,                 loss: nan
env2_first_0:                 episode reward: -46.2000,                 loss: nan
env2_second_0:                 episode reward: 46.2000,                 loss: nan
env3_first_0:                 episode reward: -28.6500,                 loss: nan
env3_second_0:                 episode reward: 28.6500,                 loss: nan
env4_first_0:                 episode reward: -49.5500,                 loss: nan
env4_second_0:                 episode reward: 49.5500,                 loss: nan
Episode: 7401/10000 (74.0100%),                 avg. length: 285.4,                last time consumption/overall running time: 76.1327s / 28740.0358 s
env0_first_0:                 episode reward: -35.6000,                 loss: 99.0565
env0_second_0:                 episode reward: 35.6000,                 loss: nan
env1_first_0:                 episode reward: -42.1500,                 loss: nan
env1_second_0:                 episode reward: 42.1500,                 loss: nan
env2_first_0:                 episode reward: -23.7000,                 loss: nan
env2_second_0:                 episode reward: 23.7000,                 loss: nan
env3_first_0:                 episode reward: -34.8500,                 loss: nan
env3_second_0:                 episode reward: 34.8500,                 loss: nan
env4_first_0:                 episode reward: -40.8500,                 loss: nan
env4_second_0:                 episode reward: 40.8500,                 loss: nan
Episode: 7421/10000 (74.2100%),                 avg. length: 245.6,                last time consumption/overall running time: 67.7966s / 28807.8324 s
env0_first_0:                 episode reward: -65.3500,                 loss: 103.0421
env0_second_0:                 episode reward: 65.3500,                 loss: nan
env1_first_0:                 episode reward: -63.1000,                 loss: nan
env1_second_0:                 episode reward: 63.1000,                 loss: nan
env2_first_0:                 episode reward: -67.8000,                 loss: nan
env2_second_0:                 episode reward: 67.8000,                 loss: nan
env3_first_0:                 episode reward: -60.5500,                 loss: nan
env3_second_0:                 episode reward: 60.5500,                 loss: nan
env4_first_0:                 episode reward: -83.3500,                 loss: nan
env4_second_0:                 episode reward: 83.3500,                 loss: nan
Episode: 7441/10000 (74.4100%),                 avg. length: 267.0,                last time consumption/overall running time: 72.6180s / 28880.4503 s
env0_first_0:                 episode reward: -47.9500,                 loss: 128.8043
env0_second_0:                 episode reward: 47.9500,                 loss: nan
env1_first_0:                 episode reward: -39.3500,                 loss: nan
env1_second_0:                 episode reward: 39.3500,                 loss: nan
env2_first_0:                 episode reward: -53.8500,                 loss: nan
env2_second_0:                 episode reward: 53.8500,                 loss: nan
env3_first_0:                 episode reward: -32.9500,                 loss: nan
env3_second_0:                 episode reward: 32.9500,                 loss: nan
env4_first_0:                 episode reward: -42.4000,                 loss: nan
env4_second_0:                 episode reward: 42.4000,                 loss: nan
Episode: 7461/10000 (74.6100%),                 avg. length: 269.1,                last time consumption/overall running time: 74.1184s / 28954.5687 s
env0_first_0:                 episode reward: -55.7500,                 loss: 142.7332
env0_second_0:                 episode reward: 55.7500,                 loss: nan
env1_first_0:                 episode reward: -36.5000,                 loss: nan
env1_second_0:                 episode reward: 36.5000,                 loss: nan
env2_first_0:                 episode reward: -54.9000,                 loss: nan
env2_second_0:                 episode reward: 54.9000,                 loss: nan
env3_first_0:                 episode reward: -62.9000,                 loss: nan
env3_second_0:                 episode reward: 62.9000,                 loss: nan
env4_first_0:                 episode reward: -71.9000,                 loss: nan
env4_second_0:                 episode reward: 71.9000,                 loss: nan
Episode: 7481/10000 (74.8100%),                 avg. length: 266.5,                last time consumption/overall running time: 72.4801s / 29027.0488 s
env0_first_0:                 episode reward: -55.1000,                 loss: 140.8901
env0_second_0:                 episode reward: 55.1000,                 loss: nan
env1_first_0:                 episode reward: -48.0500,                 loss: nan
env1_second_0:                 episode reward: 48.0500,                 loss: nan
env2_first_0:                 episode reward: -63.0500,                 loss: nan
env2_second_0:                 episode reward: 63.0500,                 loss: nan
env3_first_0:                 episode reward: -41.1500,                 loss: nan
env3_second_0:                 episode reward: 41.1500,                 loss: nan
env4_first_0:                 episode reward: -59.7500,                 loss: nan
env4_second_0:                 episode reward: 59.7500,                 loss: nan
Episode: 7501/10000 (75.0100%),                 avg. length: 267.75,                last time consumption/overall running time: 73.0023s / 29100.0511 s
env0_first_0:                 episode reward: -48.2000,                 loss: 147.2351
env0_second_0:                 episode reward: 48.2000,                 loss: nan
env1_first_0:                 episode reward: -40.7000,                 loss: nan
env1_second_0:                 episode reward: 40.7000,                 loss: nan
env2_first_0:                 episode reward: -61.6000,                 loss: nan
env2_second_0:                 episode reward: 61.6000,                 loss: nan
env3_first_0:                 episode reward: -58.2000,                 loss: nan
env3_second_0:                 episode reward: 58.2000,                 loss: nan
env4_first_0:                 episode reward: -62.2000,                 loss: nan
env4_second_0:                 episode reward: 62.2000,                 loss: nan
Episode: 7521/10000 (75.2100%),                 avg. length: 275.65,                last time consumption/overall running time: 73.9721s / 29174.0232 s
env0_first_0:                 episode reward: -63.2000,                 loss: 125.0724
env0_second_0:                 episode reward: 63.2000,                 loss: nan
env1_first_0:                 episode reward: -64.5000,                 loss: nan
env1_second_0:                 episode reward: 64.5000,                 loss: nan
env2_first_0:                 episode reward: -47.5500,                 loss: nan
env2_second_0:                 episode reward: 47.5500,                 loss: nan
env3_first_0:                 episode reward: -43.1000,                 loss: nan
env3_second_0:                 episode reward: 43.1000,                 loss: nan
env4_first_0:                 episode reward: -81.8000,                 loss: nan
env4_second_0:                 episode reward: 81.8000,                 loss: nan
Episode: 7541/10000 (75.4100%),                 avg. length: 278.0,                last time consumption/overall running time: 75.4460s / 29249.4692 s
env0_first_0:                 episode reward: -59.0000,                 loss: 129.1567
env0_second_0:                 episode reward: 59.0000,                 loss: nan
env1_first_0:                 episode reward: -50.5000,                 loss: nan
env1_second_0:                 episode reward: 50.5000,                 loss: nan
env2_first_0:                 episode reward: -46.0500,                 loss: nan
env2_second_0:                 episode reward: 46.0500,                 loss: nan
env3_first_0:                 episode reward: -34.2500,                 loss: nan
env3_second_0:                 episode reward: 34.2500,                 loss: nan
env4_first_0:                 episode reward: -52.0500,                 loss: nan
env4_second_0:                 episode reward: 52.0500,                 loss: nan
Episode: 7561/10000 (75.6100%),                 avg. length: 281.75,                last time consumption/overall running time: 74.7381s / 29324.2073 s
env0_first_0:                 episode reward: -35.1500,                 loss: 80.9985
env0_second_0:                 episode reward: 35.1500,                 loss: nan
env1_first_0:                 episode reward: -40.9500,                 loss: nan
env1_second_0:                 episode reward: 40.9500,                 loss: nan
env2_first_0:                 episode reward: -37.8000,                 loss: nan
env2_second_0:                 episode reward: 37.8000,                 loss: nan
env3_first_0:                 episode reward: -47.8000,                 loss: nan
env3_second_0:                 episode reward: 47.8000,                 loss: nan
env4_first_0:                 episode reward: -44.4000,                 loss: nan
env4_second_0:                 episode reward: 44.4000,                 loss: nan
Episode: 7581/10000 (75.8100%),                 avg. length: 277.35,                last time consumption/overall running time: 75.0746s / 29399.2819 s
env0_first_0:                 episode reward: -57.9500,                 loss: 115.4557
env0_second_0:                 episode reward: 57.9500,                 loss: nan
env1_first_0:                 episode reward: -54.7500,                 loss: nan
env1_second_0:                 episode reward: 54.7500,                 loss: nan
env2_first_0:                 episode reward: -67.6000,                 loss: nan
env2_second_0:                 episode reward: 67.6000,                 loss: nan
env3_first_0:                 episode reward: -62.2500,                 loss: nan
env3_second_0:                 episode reward: 62.2500,                 loss: nan
env4_first_0:                 episode reward: -73.4000,                 loss: nan
env4_second_0:                 episode reward: 73.4000,                 loss: nan
Episode: 7601/10000 (76.0100%),                 avg. length: 265.55,                last time consumption/overall running time: 71.4592s / 29470.7411 s
env0_first_0:                 episode reward: -64.8000,                 loss: 124.3933
env0_second_0:                 episode reward: 64.8000,                 loss: nan
env1_first_0:                 episode reward: -49.5000,                 loss: nan
env1_second_0:                 episode reward: 49.5000,                 loss: nan
env2_first_0:                 episode reward: -45.1000,                 loss: nan
env2_second_0:                 episode reward: 45.1000,                 loss: nan
env3_first_0:                 episode reward: -56.6000,                 loss: nan
env3_second_0:                 episode reward: 56.6000,                 loss: nan
env4_first_0:                 episode reward: -67.0500,                 loss: nan
env4_second_0:                 episode reward: 67.0500,                 loss: nan
Episode: 7621/10000 (76.2100%),                 avg. length: 286.2,                last time consumption/overall running time: 75.4737s / 29546.2148 s
env0_first_0:                 episode reward: -43.4500,                 loss: 94.8108
env0_second_0:                 episode reward: 43.4500,                 loss: nan
env1_first_0:                 episode reward: -35.3000,                 loss: nan
env1_second_0:                 episode reward: 35.3000,                 loss: nan
env2_first_0:                 episode reward: -46.0000,                 loss: nan
env2_second_0:                 episode reward: 46.0000,                 loss: nan
env3_first_0:                 episode reward: -31.3000,                 loss: nan
env3_second_0:                 episode reward: 31.3000,                 loss: nan
env4_first_0:                 episode reward: -41.4000,                 loss: nan
env4_second_0:                 episode reward: 41.4000,                 loss: nan
Episode: 7641/10000 (76.4100%),                 avg. length: 289.9,                last time consumption/overall running time: 76.9104s / 29623.1251 s
env0_first_0:                 episode reward: -39.1500,                 loss: 122.7110
env0_second_0:                 episode reward: 39.1500,                 loss: nan
env1_first_0:                 episode reward: -52.0000,                 loss: nan
env1_second_0:                 episode reward: 52.0000,                 loss: nan
env2_first_0:                 episode reward: -39.8000,                 loss: nan
env2_second_0:                 episode reward: 39.8000,                 loss: nan
env3_first_0:                 episode reward: -43.2000,                 loss: nan
env3_second_0:                 episode reward: 43.2000,                 loss: nan
env4_first_0:                 episode reward: -49.5000,                 loss: nan
env4_second_0:                 episode reward: 49.5000,                 loss: nan
Episode: 7661/10000 (76.6100%),                 avg. length: 269.95,                last time consumption/overall running time: 73.0804s / 29696.2055 s
env0_first_0:                 episode reward: -50.9000,                 loss: 130.0296
env0_second_0:                 episode reward: 50.9000,                 loss: nan
env1_first_0:                 episode reward: -58.0000,                 loss: nan
env1_second_0:                 episode reward: 58.0000,                 loss: nan
env2_first_0:                 episode reward: -59.8500,                 loss: nan
env2_second_0:                 episode reward: 59.8500,                 loss: nan
env3_first_0:                 episode reward: -65.3500,                 loss: nan
env3_second_0:                 episode reward: 65.3500,                 loss: nan
env4_first_0:                 episode reward: -50.7000,                 loss: nan
env4_second_0:                 episode reward: 50.7000,                 loss: nan
Episode: 7681/10000 (76.8100%),                 avg. length: 259.3,                last time consumption/overall running time: 71.2036s / 29767.4092 s
env0_first_0:                 episode reward: -74.3500,                 loss: 115.8161
env0_second_0:                 episode reward: 74.3500,                 loss: nan
env1_first_0:                 episode reward: -72.7500,                 loss: nan
env1_second_0:                 episode reward: 72.7500,                 loss: nan
env2_first_0:                 episode reward: -63.8000,                 loss: nan
env2_second_0:                 episode reward: 63.8000,                 loss: nan
env3_first_0:                 episode reward: -62.5000,                 loss: nan
env3_second_0:                 episode reward: 62.5000,                 loss: nan
env4_first_0:                 episode reward: -57.2500,                 loss: nan
env4_second_0:                 episode reward: 57.2500,                 loss: nan
Episode: 7701/10000 (77.0100%),                 avg. length: 256.65,                last time consumption/overall running time: 70.0246s / 29837.4337 s
env0_first_0:                 episode reward: -67.5500,                 loss: 106.9169
env0_second_0:                 episode reward: 67.5500,                 loss: nan
env1_first_0:                 episode reward: -62.0500,                 loss: nan
env1_second_0:                 episode reward: 62.0500,                 loss: nan
env2_first_0:                 episode reward: -66.5500,                 loss: nan
env2_second_0:                 episode reward: 66.5500,                 loss: nan
env3_first_0:                 episode reward: -70.7500,                 loss: nan
env3_second_0:                 episode reward: 70.7500,                 loss: nan
env4_first_0:                 episode reward: -59.6500,                 loss: nan
env4_second_0:                 episode reward: 59.6500,                 loss: nan
Episode: 7721/10000 (77.2100%),                 avg. length: 266.35,                last time consumption/overall running time: 71.6891s / 29909.1228 s
env0_first_0:                 episode reward: -46.1500,                 loss: 128.4788
env0_second_0:                 episode reward: 46.1500,                 loss: nan
env1_first_0:                 episode reward: -56.1000,                 loss: nan
env1_second_0:                 episode reward: 56.1000,                 loss: nan
env2_first_0:                 episode reward: -54.2500,                 loss: nan
env2_second_0:                 episode reward: 54.2500,                 loss: nan
env3_first_0:                 episode reward: -55.5500,                 loss: nan
env3_second_0:                 episode reward: 55.5500,                 loss: nan
env4_first_0:                 episode reward: -61.9000,                 loss: nan
env4_second_0:                 episode reward: 61.9000,                 loss: nan
Episode: 7741/10000 (77.4100%),                 avg. length: 265.35,                last time consumption/overall running time: 72.1854s / 29981.3083 s
env0_first_0:                 episode reward: -55.3500,                 loss: 123.3550
env0_second_0:                 episode reward: 55.3500,                 loss: nan
env1_first_0:                 episode reward: -60.6500,                 loss: nan
env1_second_0:                 episode reward: 60.6500,                 loss: nan
env2_first_0:                 episode reward: -55.7000,                 loss: nan
env2_second_0:                 episode reward: 55.7000,                 loss: nan
env3_first_0:                 episode reward: -35.7500,                 loss: nan
env3_second_0:                 episode reward: 35.7500,                 loss: nan
env4_first_0:                 episode reward: -45.7000,                 loss: nan
env4_second_0:                 episode reward: 45.7000,                 loss: nan
Episode: 7761/10000 (77.6100%),                 avg. length: 271.9,                last time consumption/overall running time: 72.3720s / 30053.6803 s
env0_first_0:                 episode reward: -36.2000,                 loss: 124.6296
env0_second_0:                 episode reward: 36.2000,                 loss: nan
env1_first_0:                 episode reward: -41.5000,                 loss: nan
env1_second_0:                 episode reward: 41.5000,                 loss: nan
env2_first_0:                 episode reward: -32.8000,                 loss: nan
env2_second_0:                 episode reward: 32.8000,                 loss: nan
env3_first_0:                 episode reward: -38.3500,                 loss: nan
env3_second_0:                 episode reward: 38.3500,                 loss: nan
env4_first_0:                 episode reward: -49.3000,                 loss: nan
env4_second_0:                 episode reward: 49.3000,                 loss: nan
Episode: 7781/10000 (77.8100%),                 avg. length: 261.2,                last time consumption/overall running time: 71.1119s / 30124.7922 s
env0_first_0:                 episode reward: -63.1000,                 loss: 113.9528
env0_second_0:                 episode reward: 63.1000,                 loss: nan
env1_first_0:                 episode reward: -62.5500,                 loss: nan
env1_second_0:                 episode reward: 62.5500,                 loss: nan
env2_first_0:                 episode reward: -61.7000,                 loss: nan
env2_second_0:                 episode reward: 61.7000,                 loss: nan
env3_first_0:                 episode reward: -62.6500,                 loss: nan
env3_second_0:                 episode reward: 62.6500,                 loss: nan
env4_first_0:                 episode reward: -57.6500,                 loss: nan
env4_second_0:                 episode reward: 57.6500,                 loss: nan
Episode: 7801/10000 (78.0100%),                 avg. length: 267.15,                last time consumption/overall running time: 72.0673s / 30196.8595 s
env0_first_0:                 episode reward: -65.5500,                 loss: 116.1523
env0_second_0:                 episode reward: 65.5500,                 loss: nan
env1_first_0:                 episode reward: -67.0500,                 loss: nan
env1_second_0:                 episode reward: 67.0500,                 loss: nan
env2_first_0:                 episode reward: -58.5000,                 loss: nan
env2_second_0:                 episode reward: 58.5000,                 loss: nan
env3_first_0:                 episode reward: -51.9000,                 loss: nan
env3_second_0:                 episode reward: 51.9000,                 loss: nan
env4_first_0:                 episode reward: -65.4500,                 loss: nan
env4_second_0:                 episode reward: 65.4500,                 loss: nan
Episode: 7821/10000 (78.2100%),                 avg. length: 267.25,                last time consumption/overall running time: 72.8646s / 30269.7241 s
env0_first_0:                 episode reward: -65.1000,                 loss: 118.1236
env0_second_0:                 episode reward: 65.1000,                 loss: nan
env1_first_0:                 episode reward: -70.0500,                 loss: nan
env1_second_0:                 episode reward: 70.0500,                 loss: nan
env2_first_0:                 episode reward: -67.4500,                 loss: nan
env2_second_0:                 episode reward: 67.4500,                 loss: nan
env3_first_0:                 episode reward: -72.4500,                 loss: nan
env3_second_0:                 episode reward: 72.4500,                 loss: nan
env4_first_0:                 episode reward: -59.4000,                 loss: nan
env4_second_0:                 episode reward: 59.4000,                 loss: nan
Episode: 7841/10000 (78.4100%),                 avg. length: 266.2,                last time consumption/overall running time: 72.3360s / 30342.0601 s
env0_first_0:                 episode reward: -71.5500,                 loss: 104.3365
env0_second_0:                 episode reward: 71.5500,                 loss: nan
env1_first_0:                 episode reward: -82.7500,                 loss: nan
env1_second_0:                 episode reward: 82.7500,                 loss: nan
env2_first_0:                 episode reward: -66.4500,                 loss: nan
env2_second_0:                 episode reward: 66.4500,                 loss: nan
env3_first_0:                 episode reward: -70.5000,                 loss: nan
env3_second_0:                 episode reward: 70.5000,                 loss: nan
env4_first_0:                 episode reward: -68.9000,                 loss: nan
env4_second_0:                 episode reward: 68.9000,                 loss: nan
Episode: 7861/10000 (78.6100%),                 avg. length: 272.6,                last time consumption/overall running time: 73.3418s / 30415.4019 s
env0_first_0:                 episode reward: -60.0500,                 loss: 121.6515
env0_second_0:                 episode reward: 60.0500,                 loss: nan
env1_first_0:                 episode reward: -67.0000,                 loss: nan
env1_second_0:                 episode reward: 67.0000,                 loss: nan
env2_first_0:                 episode reward: -58.9000,                 loss: nan
env2_second_0:                 episode reward: 58.9000,                 loss: nan
env3_first_0:                 episode reward: -64.7000,                 loss: nan
env3_second_0:                 episode reward: 64.7000,                 loss: nan
env4_first_0:                 episode reward: -63.7000,                 loss: nan
env4_second_0:                 episode reward: 63.7000,                 loss: nan
Episode: 7881/10000 (78.8100%),                 avg. length: 262.05,                last time consumption/overall running time: 71.7197s / 30487.1216 s
env0_first_0:                 episode reward: -65.4500,                 loss: 118.7435
env0_second_0:                 episode reward: 65.4500,                 loss: nan
env1_first_0:                 episode reward: -67.4000,                 loss: nan
env1_second_0:                 episode reward: 67.4000,                 loss: nan
env2_first_0:                 episode reward: -73.5000,                 loss: nan
env2_second_0:                 episode reward: 73.5000,                 loss: nan
env3_first_0:                 episode reward: -70.3000,                 loss: nan
env3_second_0:                 episode reward: 70.3000,                 loss: nan
env4_first_0:                 episode reward: -63.5000,                 loss: nan
env4_second_0:                 episode reward: 63.5000,                 loss: nan
Episode: 7901/10000 (79.0100%),                 avg. length: 268.15,                last time consumption/overall running time: 71.9176s / 30559.0392 s
env0_first_0:                 episode reward: -63.3000,                 loss: 114.3610
env0_second_0:                 episode reward: 63.3000,                 loss: nan
env1_first_0:                 episode reward: -55.0000,                 loss: nan
env1_second_0:                 episode reward: 55.0000,                 loss: nan
env2_first_0:                 episode reward: -67.6000,                 loss: nan
env2_second_0:                 episode reward: 67.6000,                 loss: nan
env3_first_0:                 episode reward: -68.8000,                 loss: nan
env3_second_0:                 episode reward: 68.8000,                 loss: nan
env4_first_0:                 episode reward: -67.3500,                 loss: nan
env4_second_0:                 episode reward: 67.3500,                 loss: nan
Episode: 7921/10000 (79.2100%),                 avg. length: 277.75,                last time consumption/overall running time: 74.5467s / 30633.5859 s
env0_first_0:                 episode reward: -47.7000,                 loss: 120.0737
env0_second_0:                 episode reward: 47.7000,                 loss: nan
env1_first_0:                 episode reward: -48.2000,                 loss: nan
env1_second_0:                 episode reward: 48.2000,                 loss: nan
env2_first_0:                 episode reward: -50.3000,                 loss: nan
env2_second_0:                 episode reward: 50.3000,                 loss: nan
env3_first_0:                 episode reward: -33.2500,                 loss: nan
env3_second_0:                 episode reward: 33.2500,                 loss: nan
env4_first_0:                 episode reward: -51.2000,                 loss: nan
env4_second_0:                 episode reward: 51.2000,                 loss: nan
Episode: 7941/10000 (79.4100%),                 avg. length: 277.0,                last time consumption/overall running time: 74.0839s / 30707.6698 s
env0_first_0:                 episode reward: -53.3500,                 loss: 123.2660
env0_second_0:                 episode reward: 53.3500,                 loss: nan
env1_first_0:                 episode reward: -35.6000,                 loss: nan
env1_second_0:                 episode reward: 35.6000,                 loss: nan
env2_first_0:                 episode reward: -52.4500,                 loss: nan
env2_second_0:                 episode reward: 52.4500,                 loss: nan
env3_first_0:                 episode reward: -49.1000,                 loss: nan
env3_second_0:                 episode reward: 49.1000,                 loss: nan
env4_first_0:                 episode reward: -52.7500,                 loss: nan
env4_second_0:                 episode reward: 52.7500,                 loss: nan
Episode: 7961/10000 (79.6100%),                 avg. length: 282.05,                last time consumption/overall running time: 74.7651s / 30782.4350 s
env0_first_0:                 episode reward: -44.9500,                 loss: 109.9133
env0_second_0:                 episode reward: 44.9500,                 loss: nan
env1_first_0:                 episode reward: -48.9500,                 loss: nan
env1_second_0:                 episode reward: 48.9500,                 loss: nan
env2_first_0:                 episode reward: -61.5500,                 loss: nan
env2_second_0:                 episode reward: 61.5500,                 loss: nan
env3_first_0:                 episode reward: -58.7000,                 loss: nan
env3_second_0:                 episode reward: 58.7000,                 loss: nan
env4_first_0:                 episode reward: -46.5500,                 loss: nan
env4_second_0:                 episode reward: 46.5500,                 loss: nan
Episode: 7981/10000 (79.8100%),                 avg. length: 277.1,                last time consumption/overall running time: 73.8971s / 30856.3321 s
env0_first_0:                 episode reward: -50.4500,                 loss: 107.0807
env0_second_0:                 episode reward: 50.4500,                 loss: nan
env1_first_0:                 episode reward: -56.6000,                 loss: nan
env1_second_0:                 episode reward: 56.6000,                 loss: nan
env2_first_0:                 episode reward: -48.5500,                 loss: nan
env2_second_0:                 episode reward: 48.5500,                 loss: nan
env3_first_0:                 episode reward: -55.3500,                 loss: nan
env3_second_0:                 episode reward: 55.3500,                 loss: nan
env4_first_0:                 episode reward: -49.1500,                 loss: nan
env4_second_0:                 episode reward: 49.1500,                 loss: nan
Episode: 8001/10000 (80.0100%),                 avg. length: 269.15,                last time consumption/overall running time: 72.9618s / 30929.2938 s
env0_first_0:                 episode reward: -65.2500,                 loss: 90.3049
env0_second_0:                 episode reward: 65.2500,                 loss: nan
env1_first_0:                 episode reward: -75.9500,                 loss: nan
env1_second_0:                 episode reward: 75.9500,                 loss: nan
env2_first_0:                 episode reward: -60.7000,                 loss: nan
env2_second_0:                 episode reward: 60.7000,                 loss: nan
env3_first_0:                 episode reward: -67.1500,                 loss: nan
env3_second_0:                 episode reward: 67.1500,                 loss: nan
env4_first_0:                 episode reward: -78.4500,                 loss: nan
env4_second_0:                 episode reward: 78.4500,                 loss: nan
Episode: 8021/10000 (80.2100%),                 avg. length: 271.0,                last time consumption/overall running time: 73.1313s / 31002.4252 s
env0_first_0:                 episode reward: -63.4500,                 loss: 103.4087
env0_second_0:                 episode reward: 63.4500,                 loss: nan
env1_first_0:                 episode reward: -67.6500,                 loss: nan
env1_second_0:                 episode reward: 67.6500,                 loss: nan
env2_first_0:                 episode reward: -75.0000,                 loss: nan
env2_second_0:                 episode reward: 75.0000,                 loss: nan
env3_first_0:                 episode reward: -76.5500,                 loss: nan
env3_second_0:                 episode reward: 76.5500,                 loss: nan
env4_first_0:                 episode reward: -69.9500,                 loss: nan
env4_second_0:                 episode reward: 69.9500,                 loss: nan
Episode: 8041/10000 (80.4100%),                 avg. length: 271.55,                last time consumption/overall running time: 73.2141s / 31075.6392 s
env0_first_0:                 episode reward: -39.8000,                 loss: 126.1477
env0_second_0:                 episode reward: 39.8000,                 loss: nan
env1_first_0:                 episode reward: -56.2000,                 loss: nan
env1_second_0:                 episode reward: 56.2000,                 loss: nan
env2_first_0:                 episode reward: -46.5500,                 loss: nan
env2_second_0:                 episode reward: 46.5500,                 loss: nan
env3_first_0:                 episode reward: -38.7500,                 loss: nan
env3_second_0:                 episode reward: 38.7500,                 loss: nan
env4_first_0:                 episode reward: -33.3000,                 loss: nan
env4_second_0:                 episode reward: 33.3000,                 loss: nan
Episode: 8061/10000 (80.6100%),                 avg. length: 258.9,                last time consumption/overall running time: 71.5033s / 31147.1425 s
env0_first_0:                 episode reward: -49.7500,                 loss: 147.5795
env0_second_0:                 episode reward: 49.7500,                 loss: nan
env1_first_0:                 episode reward: -46.2000,                 loss: nan
env1_second_0:                 episode reward: 46.2000,                 loss: nan
env2_first_0:                 episode reward: -57.2000,                 loss: nan
env2_second_0:                 episode reward: 57.2000,                 loss: nan
env3_first_0:                 episode reward: -40.8000,                 loss: nan
env3_second_0:                 episode reward: 40.8000,                 loss: nan
env4_first_0:                 episode reward: -52.9000,                 loss: nan
env4_second_0:                 episode reward: 52.9000,                 loss: nan
Episode: 8081/10000 (80.8100%),                 avg. length: 244.8,                last time consumption/overall running time: 68.0807s / 31215.2232 s
env0_first_0:                 episode reward: -61.1500,                 loss: 134.2090
env0_second_0:                 episode reward: 61.1500,                 loss: nan
env1_first_0:                 episode reward: -53.2500,                 loss: nan
env1_second_0:                 episode reward: 53.2500,                 loss: nan
env2_first_0:                 episode reward: -38.7000,                 loss: nan
env2_second_0:                 episode reward: 38.7000,                 loss: nan
env3_first_0:                 episode reward: -63.7500,                 loss: nan
env3_second_0:                 episode reward: 63.7500,                 loss: nan
env4_first_0:                 episode reward: -49.3500,                 loss: nan
env4_second_0:                 episode reward: 49.3500,                 loss: nan
Episode: 8101/10000 (81.0100%),                 avg. length: 283.2,                last time consumption/overall running time: 74.6373s / 31289.8605 s
env0_first_0:                 episode reward: -37.9000,                 loss: 112.6193
env0_second_0:                 episode reward: 37.9000,                 loss: nan
env1_first_0:                 episode reward: -30.6000,                 loss: nan
env1_second_0:                 episode reward: 30.6000,                 loss: nan
env2_first_0:                 episode reward: -38.3000,                 loss: nan
env2_second_0:                 episode reward: 38.3000,                 loss: nan
env3_first_0:                 episode reward: -48.6000,                 loss: nan
env3_second_0:                 episode reward: 48.6000,                 loss: nan
env4_first_0:                 episode reward: -18.9500,                 loss: nan
env4_second_0:                 episode reward: 18.9500,                 loss: nan
Episode: 8121/10000 (81.2100%),                 avg. length: 277.9,                last time consumption/overall running time: 74.7244s / 31364.5849 s
env0_first_0:                 episode reward: -28.8500,                 loss: 121.0896
env0_second_0:                 episode reward: 28.8500,                 loss: nan
env1_first_0:                 episode reward: -51.5500,                 loss: nan
env1_second_0:                 episode reward: 51.5500,                 loss: nan
env2_first_0:                 episode reward: -24.3000,                 loss: nan
env2_second_0:                 episode reward: 24.3000,                 loss: nan
env3_first_0:                 episode reward: -34.4500,                 loss: nan
env3_second_0:                 episode reward: 34.4500,                 loss: nan
env4_first_0:                 episode reward: -44.8500,                 loss: nan
env4_second_0:                 episode reward: 44.8500,                 loss: nan
Episode: 8141/10000 (81.4100%),                 avg. length: 271.15,                last time consumption/overall running time: 73.6645s / 31438.2494 s
env0_first_0:                 episode reward: -50.9500,                 loss: 128.2726
env0_second_0:                 episode reward: 50.9500,                 loss: nan
env1_first_0:                 episode reward: -50.8000,                 loss: nan
env1_second_0:                 episode reward: 50.8000,                 loss: nan
env2_first_0:                 episode reward: -44.2000,                 loss: nan
env2_second_0:                 episode reward: 44.2000,                 loss: nan
env3_first_0:                 episode reward: -58.7500,                 loss: nan
env3_second_0:                 episode reward: 58.7500,                 loss: nan
env4_first_0:                 episode reward: -53.9000,                 loss: nan
env4_second_0:                 episode reward: 53.9000,                 loss: nan
Episode: 8161/10000 (81.6100%),                 avg. length: 279.5,                last time consumption/overall running time: 74.3036s / 31512.5530 s
env0_first_0:                 episode reward: -28.6500,                 loss: 130.8150
env0_second_0:                 episode reward: 28.6500,                 loss: nan
env1_first_0:                 episode reward: -35.9500,                 loss: nan
env1_second_0:                 episode reward: 35.9500,                 loss: nan
env2_first_0:                 episode reward: -32.2000,                 loss: nan
env2_second_0:                 episode reward: 32.2000,                 loss: nan
env3_first_0:                 episode reward: -40.6000,                 loss: nan
env3_second_0:                 episode reward: 40.6000,                 loss: nan
env4_first_0:                 episode reward: -41.9500,                 loss: nan
env4_second_0:                 episode reward: 41.9500,                 loss: nan
Episode: 8181/10000 (81.8100%),                 avg. length: 263.0,                last time consumption/overall running time: 72.5501s / 31585.1032 s
env0_first_0:                 episode reward: -42.2500,                 loss: 140.6417
env0_second_0:                 episode reward: 42.2500,                 loss: nan
env1_first_0:                 episode reward: -46.3500,                 loss: nan
env1_second_0:                 episode reward: 46.3500,                 loss: nan
env2_first_0:                 episode reward: -61.0000,                 loss: nan
env2_second_0:                 episode reward: 61.0000,                 loss: nan
env3_first_0:                 episode reward: -51.5500,                 loss: nan
env3_second_0:                 episode reward: 51.5500,                 loss: nan
env4_first_0:                 episode reward: -42.3000,                 loss: nan
env4_second_0:                 episode reward: 42.3000,                 loss: nan
Episode: 8201/10000 (82.0100%),                 avg. length: 248.95,                last time consumption/overall running time: 68.8596s / 31653.9627 s
env0_first_0:                 episode reward: -69.3500,                 loss: 111.7504
env0_second_0:                 episode reward: 69.3500,                 loss: nan
env1_first_0:                 episode reward: -70.0500,                 loss: nan
env1_second_0:                 episode reward: 70.0500,                 loss: nan
env2_first_0:                 episode reward: -62.8500,                 loss: nan
env2_second_0:                 episode reward: 62.8500,                 loss: nan
env3_first_0:                 episode reward: -69.3000,                 loss: nan
env3_second_0:                 episode reward: 69.3000,                 loss: nan
env4_first_0:                 episode reward: -66.8500,                 loss: nan
env4_second_0:                 episode reward: 66.8500,                 loss: nan
Episode: 8221/10000 (82.2100%),                 avg. length: 268.8,                last time consumption/overall running time: 74.1632s / 31728.1260 s
env0_first_0:                 episode reward: -53.5500,                 loss: 138.7564
env0_second_0:                 episode reward: 53.5500,                 loss: nan
env1_first_0:                 episode reward: -43.2000,                 loss: nan
env1_second_0:                 episode reward: 43.2000,                 loss: nan
env2_first_0:                 episode reward: -42.2500,                 loss: nan
env2_second_0:                 episode reward: 42.2500,                 loss: nan
env3_first_0:                 episode reward: -57.1500,                 loss: nan
env3_second_0:                 episode reward: 57.1500,                 loss: nan
env4_first_0:                 episode reward: -48.3000,                 loss: nan
env4_second_0:                 episode reward: 48.3000,                 loss: nan
Episode: 8241/10000 (82.4100%),                 avg. length: 272.8,                last time consumption/overall running time: 74.0006s / 31802.1266 s
env0_first_0:                 episode reward: -52.5500,                 loss: 138.7838
env0_second_0:                 episode reward: 52.5500,                 loss: nan
env1_first_0:                 episode reward: -24.7500,                 loss: nan
env1_second_0:                 episode reward: 24.7500,                 loss: nan
env2_first_0:                 episode reward: -32.4000,                 loss: nan
env2_second_0:                 episode reward: 32.4000,                 loss: nan
env3_first_0:                 episode reward: -41.2000,                 loss: nan
env3_second_0:                 episode reward: 41.2000,                 loss: nan
env4_first_0:                 episode reward: -26.2500,                 loss: nan
env4_second_0:                 episode reward: 26.2500,                 loss: nan
Episode: 8261/10000 (82.6100%),                 avg. length: 296.8,                last time consumption/overall running time: 77.4830s / 31879.6096 s
env0_first_0:                 episode reward: -31.2500,                 loss: 104.3835
env0_second_0:                 episode reward: 31.2500,                 loss: nan
env1_first_0:                 episode reward: -17.3500,                 loss: nan
env1_second_0:                 episode reward: 17.3500,                 loss: nan
env2_first_0:                 episode reward: -21.1500,                 loss: nan
env2_second_0:                 episode reward: 21.1500,                 loss: nan
env3_first_0:                 episode reward: -24.3000,                 loss: nan
env3_second_0:                 episode reward: 24.3000,                 loss: nan
env4_first_0:                 episode reward: -31.6000,                 loss: nan
env4_second_0:                 episode reward: 31.6000,                 loss: nan
Episode: 8281/10000 (82.8100%),                 avg. length: 292.5,                last time consumption/overall running time: 76.8960s / 31956.5056 s
env0_first_0:                 episode reward: -39.2000,                 loss: 112.1345
env0_second_0:                 episode reward: 39.2000,                 loss: nan
env1_first_0:                 episode reward: -37.6000,                 loss: nan
env1_second_0:                 episode reward: 37.6000,                 loss: nan
env2_first_0:                 episode reward: -43.0000,                 loss: nan
env2_second_0:                 episode reward: 43.0000,                 loss: nan
env3_first_0:                 episode reward: -44.3000,                 loss: nan
env3_second_0:                 episode reward: 44.3000,                 loss: nan
env4_first_0:                 episode reward: -42.6500,                 loss: nan
env4_second_0:                 episode reward: 42.6500,                 loss: nan
Episode: 8301/10000 (83.0100%),                 avg. length: 263.4,                last time consumption/overall running time: 70.4138s / 32026.9194 s
env0_first_0:                 episode reward: -39.0000,                 loss: 135.2944
env0_second_0:                 episode reward: 39.0000,                 loss: nan
env1_first_0:                 episode reward: -42.9500,                 loss: nan
env1_second_0:                 episode reward: 42.9500,                 loss: nan
env2_first_0:                 episode reward: -48.7500,                 loss: nan
env2_second_0:                 episode reward: 48.7500,                 loss: nan
env3_first_0:                 episode reward: -59.4500,                 loss: nan
env3_second_0:                 episode reward: 59.4500,                 loss: nan
env4_first_0:                 episode reward: -47.7500,                 loss: nan
env4_second_0:                 episode reward: 47.7500,                 loss: nan
Episode: 8321/10000 (83.2100%),                 avg. length: 278.5,                last time consumption/overall running time: 75.6009s / 32102.5203 s
env0_first_0:                 episode reward: -60.1000,                 loss: 113.2878
env0_second_0:                 episode reward: 60.1000,                 loss: nan
env1_first_0:                 episode reward: -51.5000,                 loss: nan
env1_second_0:                 episode reward: 51.5000,                 loss: nan
env2_first_0:                 episode reward: -67.5000,                 loss: nan
env2_second_0:                 episode reward: 67.5000,                 loss: nan
env3_first_0:                 episode reward: -57.3500,                 loss: nan
env3_second_0:                 episode reward: 57.3500,                 loss: nan
env4_first_0:                 episode reward: -53.0000,                 loss: nan
env4_second_0:                 episode reward: 53.0000,                 loss: nan
Episode: 8341/10000 (83.4100%),                 avg. length: 281.45,                last time consumption/overall running time: 74.1220s / 32176.6423 s
env0_first_0:                 episode reward: -31.6000,                 loss: 93.7139
env0_second_0:                 episode reward: 31.6000,                 loss: nan
env1_first_0:                 episode reward: -23.6000,                 loss: nan
env1_second_0:                 episode reward: 23.6000,                 loss: nan
env2_first_0:                 episode reward: -22.7500,                 loss: nan
env2_second_0:                 episode reward: 22.7500,                 loss: nan
env3_first_0:                 episode reward: -26.5500,                 loss: nan
env3_second_0:                 episode reward: 26.5500,                 loss: nan
env4_first_0:                 episode reward: -29.7500,                 loss: nan
env4_second_0:                 episode reward: 29.7500,                 loss: nan
Episode: 8361/10000 (83.6100%),                 avg. length: 297.0,                last time consumption/overall running time: 77.8659s / 32254.5082 s
env0_first_0:                 episode reward: -6.4000,                 loss: 101.7341
env0_second_0:                 episode reward: 6.4000,                 loss: nan
env1_first_0:                 episode reward: -10.9500,                 loss: nan
env1_second_0:                 episode reward: 10.9500,                 loss: nan
env2_first_0:                 episode reward: -9.5000,                 loss: nan
env2_second_0:                 episode reward: 9.5000,                 loss: nan
env3_first_0:                 episode reward: -23.0000,                 loss: nan
env3_second_0:                 episode reward: 23.0000,                 loss: nan
env4_first_0:                 episode reward: -21.3000,                 loss: nan
env4_second_0:                 episode reward: 21.3000,                 loss: nan
Episode: 8381/10000 (83.8100%),                 avg. length: 280.2,                last time consumption/overall running time: 76.0722s / 32330.5804 s
env0_first_0:                 episode reward: -56.7000,                 loss: 133.9450
env0_second_0:                 episode reward: 56.7000,                 loss: nan
env1_first_0:                 episode reward: -57.2000,                 loss: nan
env1_second_0:                 episode reward: 57.2000,                 loss: nan
env2_first_0:                 episode reward: -50.5500,                 loss: nan
env2_second_0:                 episode reward: 50.5500,                 loss: nan
env3_first_0:                 episode reward: -60.0500,                 loss: nan
env3_second_0:                 episode reward: 60.0500,                 loss: nan
env4_first_0:                 episode reward: -52.6000,                 loss: nan
env4_second_0:                 episode reward: 52.6000,                 loss: nan
Episode: 8401/10000 (84.0100%),                 avg. length: 277.5,                last time consumption/overall running time: 74.7862s / 32405.3666 s
env0_first_0:                 episode reward: -54.3000,                 loss: 142.1734
env0_second_0:                 episode reward: 54.3000,                 loss: nan
env1_first_0:                 episode reward: -50.1500,                 loss: nan
env1_second_0:                 episode reward: 50.1500,                 loss: nan
env2_first_0:                 episode reward: -37.6500,                 loss: nan
env2_second_0:                 episode reward: 37.6500,                 loss: nan
env3_first_0:                 episode reward: -49.6000,                 loss: nan
env3_second_0:                 episode reward: 49.6000,                 loss: nan
env4_first_0:                 episode reward: -38.2500,                 loss: nan
env4_second_0:                 episode reward: 38.2500,                 loss: nan
Episode: 8421/10000 (84.2100%),                 avg. length: 280.7,                last time consumption/overall running time: 76.0488s / 32481.4154 s
env0_first_0:                 episode reward: -37.3500,                 loss: 123.9167
env0_second_0:                 episode reward: 37.3500,                 loss: nan
env1_first_0:                 episode reward: -43.4000,                 loss: nan
env1_second_0:                 episode reward: 43.4000,                 loss: nan
env2_first_0:                 episode reward: -38.7000,                 loss: nan
env2_second_0:                 episode reward: 38.7000,                 loss: nan
env3_first_0:                 episode reward: -59.2500,                 loss: nan
env3_second_0:                 episode reward: 59.2500,                 loss: nan
env4_first_0:                 episode reward: -44.8500,                 loss: nan
env4_second_0:                 episode reward: 44.8500,                 loss: nan
Episode: 8441/10000 (84.4100%),                 avg. length: 289.2,                last time consumption/overall running time: 77.4831s / 32558.8985 s
env0_first_0:                 episode reward: -42.4500,                 loss: 113.0082
env0_second_0:                 episode reward: 42.4500,                 loss: nan
env1_first_0:                 episode reward: -25.0500,                 loss: nan
env1_second_0:                 episode reward: 25.0500,                 loss: nan
env2_first_0:                 episode reward: -20.3500,                 loss: nan
env2_second_0:                 episode reward: 20.3500,                 loss: nan
env3_first_0:                 episode reward: -23.6500,                 loss: nan
env3_second_0:                 episode reward: 23.6500,                 loss: nan
env4_first_0:                 episode reward: -24.7000,                 loss: nan
env4_second_0:                 episode reward: 24.7000,                 loss: nan
Episode: 8461/10000 (84.6100%),                 avg. length: 292.3,                last time consumption/overall running time: 78.3346s / 32637.2331 s
env0_first_0:                 episode reward: -12.0000,                 loss: 57.1912
env0_second_0:                 episode reward: 12.0000,                 loss: nan
env1_first_0:                 episode reward: -6.2000,                 loss: nan
env1_second_0:                 episode reward: 6.2000,                 loss: nan
env2_first_0:                 episode reward: -14.4500,                 loss: nan
env2_second_0:                 episode reward: 14.4500,                 loss: nan
env3_first_0:                 episode reward: -10.9000,                 loss: nan
env3_second_0:                 episode reward: 10.9000,                 loss: nan
env4_first_0:                 episode reward: -21.7000,                 loss: nan
env4_second_0:                 episode reward: 21.7000,                 loss: nan
Episode: 8481/10000 (84.8100%),                 avg. length: 289.35,                last time consumption/overall running time: 77.1306s / 32714.3637 s
env0_first_0:                 episode reward: -20.0000,                 loss: 107.8520
env0_second_0:                 episode reward: 20.0000,                 loss: nan
env1_first_0:                 episode reward: -20.0500,                 loss: nan
env1_second_0:                 episode reward: 20.0500,                 loss: nan
env2_first_0:                 episode reward: -39.8000,                 loss: nan
env2_second_0:                 episode reward: 39.8000,                 loss: nan
env3_first_0:                 episode reward: -12.7000,                 loss: nan
env3_second_0:                 episode reward: 12.7000,                 loss: nan
env4_first_0:                 episode reward: -15.5500,                 loss: nan
env4_second_0:                 episode reward: 15.5500,                 loss: nan
Episode: 8501/10000 (85.0100%),                 avg. length: 295.65,                last time consumption/overall running time: 77.0883s / 32791.4520 s
env0_first_0:                 episode reward: -15.9500,                 loss: 92.3089
env0_second_0:                 episode reward: 15.9500,                 loss: nan
env1_first_0:                 episode reward: -26.4500,                 loss: nan
env1_second_0:                 episode reward: 26.4500,                 loss: nan
env2_first_0:                 episode reward: -15.6000,                 loss: nan
env2_second_0:                 episode reward: 15.6000,                 loss: nan
env3_first_0:                 episode reward: -13.0500,                 loss: nan
env3_second_0:                 episode reward: 13.0500,                 loss: nan
env4_first_0:                 episode reward: -28.2500,                 loss: nan
env4_second_0:                 episode reward: 28.2500,                 loss: nan
Episode: 8521/10000 (85.2100%),                 avg. length: 286.9,                last time consumption/overall running time: 77.2038s / 32868.6558 s
env0_first_0:                 episode reward: -43.8500,                 loss: 140.0296
env0_second_0:                 episode reward: 43.8500,                 loss: nan
env1_first_0:                 episode reward: -26.0500,                 loss: nan
env1_second_0:                 episode reward: 26.0500,                 loss: nan
env2_first_0:                 episode reward: -38.9000,                 loss: nan
env2_second_0:                 episode reward: 38.9000,                 loss: nan
env3_first_0:                 episode reward: -30.7000,                 loss: nan
env3_second_0:                 episode reward: 30.7000,                 loss: nan
env4_first_0:                 episode reward: -27.4000,                 loss: nan
env4_second_0:                 episode reward: 27.4000,                 loss: nan
Episode: 8541/10000 (85.4100%),                 avg. length: 294.4,                last time consumption/overall running time: 78.4468s / 32947.1026 s
env0_first_0:                 episode reward: -47.6000,                 loss: 117.0707
env0_second_0:                 episode reward: 47.6000,                 loss: nan
env1_first_0:                 episode reward: -39.1500,                 loss: nan
env1_second_0:                 episode reward: 39.1500,                 loss: nan
env2_first_0:                 episode reward: -36.6000,                 loss: nan
env2_second_0:                 episode reward: 36.6000,                 loss: nan
env3_first_0:                 episode reward: -36.7000,                 loss: nan
env3_second_0:                 episode reward: 36.7000,                 loss: nan
env4_first_0:                 episode reward: -34.8500,                 loss: nan
env4_second_0:                 episode reward: 34.8500,                 loss: nan
Episode: 8561/10000 (85.6100%),                 avg. length: 261.75,                last time consumption/overall running time: 72.4616s / 33019.5642 s
env0_first_0:                 episode reward: -68.7500,                 loss: 114.2892
env0_second_0:                 episode reward: 68.7500,                 loss: nan
env1_first_0:                 episode reward: -74.8000,                 loss: nan
env1_second_0:                 episode reward: 74.8000,                 loss: nan
env2_first_0:                 episode reward: -54.8000,                 loss: nan
env2_second_0:                 episode reward: 54.8000,                 loss: nan
env3_first_0:                 episode reward: -65.0000,                 loss: nan
env3_second_0:                 episode reward: 65.0000,                 loss: nan
env4_first_0:                 episode reward: -71.7500,                 loss: nan
env4_second_0:                 episode reward: 71.7500,                 loss: nan
Episode: 8581/10000 (85.8100%),                 avg. length: 284.8,                last time consumption/overall running time: 74.8677s / 33094.4319 s
env0_first_0:                 episode reward: -63.1000,                 loss: 121.9521
env0_second_0:                 episode reward: 63.1000,                 loss: nan
env1_first_0:                 episode reward: -36.9000,                 loss: nan
env1_second_0:                 episode reward: 36.9000,                 loss: nan
env2_first_0:                 episode reward: -55.5000,                 loss: nan
env2_second_0:                 episode reward: 55.5000,                 loss: nan
env3_first_0:                 episode reward: -45.4000,                 loss: nan
env3_second_0:                 episode reward: 45.4000,                 loss: nan
env4_first_0:                 episode reward: -46.7500,                 loss: nan
env4_second_0:                 episode reward: 46.7500,                 loss: nan
Episode: 8601/10000 (86.0100%),                 avg. length: 283.85,                last time consumption/overall running time: 75.4699s / 33169.9018 s
env0_first_0:                 episode reward: -51.9500,                 loss: 141.5487
env0_second_0:                 episode reward: 51.9500,                 loss: nan
env1_first_0:                 episode reward: -46.3500,                 loss: nan
env1_second_0:                 episode reward: 46.3500,                 loss: nan
env2_first_0:                 episode reward: -42.2000,                 loss: nan
env2_second_0:                 episode reward: 42.2000,                 loss: nan
env3_first_0:                 episode reward: -39.9500,                 loss: nan
env3_second_0:                 episode reward: 39.9500,                 loss: nan
env4_first_0:                 episode reward: -38.1000,                 loss: nan
env4_second_0:                 episode reward: 38.1000,                 loss: nan
Episode: 8621/10000 (86.2100%),                 avg. length: 274.85,                last time consumption/overall running time: 74.2666s / 33244.1684 s
env0_first_0:                 episode reward: -29.2500,                 loss: 140.0775
env0_second_0:                 episode reward: 29.2500,                 loss: nan
env1_first_0:                 episode reward: -56.2500,                 loss: nan
env1_second_0:                 episode reward: 56.2500,                 loss: nan
env2_first_0:                 episode reward: -50.2000,                 loss: nan
env2_second_0:                 episode reward: 50.2000,                 loss: nan
env3_first_0:                 episode reward: -49.9000,                 loss: nan
env3_second_0:                 episode reward: 49.9000,                 loss: nan
env4_first_0:                 episode reward: -37.8500,                 loss: nan
env4_second_0:                 episode reward: 37.8500,                 loss: nan
Episode: 8641/10000 (86.4100%),                 avg. length: 271.95,                last time consumption/overall running time: 73.9971s / 33318.1655 s
env0_first_0:                 episode reward: -37.8500,                 loss: 146.7940
env0_second_0:                 episode reward: 37.8500,                 loss: nan
env1_first_0:                 episode reward: -57.8000,                 loss: nan
env1_second_0:                 episode reward: 57.8000,                 loss: nan
env2_first_0:                 episode reward: -58.7500,                 loss: nan
env2_second_0:                 episode reward: 58.7500,                 loss: nan
env3_first_0:                 episode reward: -48.3500,                 loss: nan
env3_second_0:                 episode reward: 48.3500,                 loss: nan
env4_first_0:                 episode reward: -51.7000,                 loss: nan
env4_second_0:                 episode reward: 51.7000,                 loss: nan
Episode: 8661/10000 (86.6100%),                 avg. length: 276.15,                last time consumption/overall running time: 73.5860s / 33391.7515 s
env0_first_0:                 episode reward: -51.2500,                 loss: 143.2174
env0_second_0:                 episode reward: 51.2500,                 loss: nan
env1_first_0:                 episode reward: -57.6500,                 loss: nan
env1_second_0:                 episode reward: 57.6500,                 loss: nan
env2_first_0:                 episode reward: -44.9500,                 loss: nan
env2_second_0:                 episode reward: 44.9500,                 loss: nan
env3_first_0:                 episode reward: -46.5000,                 loss: nan
env3_second_0:                 episode reward: 46.5000,                 loss: nan
env4_first_0:                 episode reward: -40.2000,                 loss: nan
env4_second_0:                 episode reward: 40.2000,                 loss: nan
Episode: 8681/10000 (86.8100%),                 avg. length: 276.65,                last time consumption/overall running time: 74.0672s / 33465.8187 s
env0_first_0:                 episode reward: -48.6500,                 loss: 141.5819
env0_second_0:                 episode reward: 48.6500,                 loss: nan
env1_first_0:                 episode reward: -48.2500,                 loss: nan
env1_second_0:                 episode reward: 48.2500,                 loss: nan
env2_first_0:                 episode reward: -46.0500,                 loss: nan
env2_second_0:                 episode reward: 46.0500,                 loss: nan
env3_first_0:                 episode reward: -53.6500,                 loss: nan
env3_second_0:                 episode reward: 53.6500,                 loss: nan
env4_first_0:                 episode reward: -52.5000,                 loss: nan
env4_second_0:                 episode reward: 52.5000,                 loss: nan
Episode: 8701/10000 (87.0100%),                 avg. length: 276.55,                last time consumption/overall running time: 73.3656s / 33539.1843 s
env0_first_0:                 episode reward: -40.2000,                 loss: 124.7282
env0_second_0:                 episode reward: 40.2000,                 loss: nan
env1_first_0:                 episode reward: -28.4500,                 loss: nan
env1_second_0:                 episode reward: 28.4500,                 loss: nan
env2_first_0:                 episode reward: -44.9000,                 loss: nan
env2_second_0:                 episode reward: 44.9000,                 loss: nan
env3_first_0:                 episode reward: -39.4000,                 loss: nan
env3_second_0:                 episode reward: 39.4000,                 loss: nan
env4_first_0:                 episode reward: -26.2000,                 loss: nan
env4_second_0:                 episode reward: 26.2000,                 loss: nan
Episode: 8721/10000 (87.2100%),                 avg. length: 276.7,                last time consumption/overall running time: 74.9792s / 33614.1635 s
env0_first_0:                 episode reward: -45.2500,                 loss: 145.2049
env0_second_0:                 episode reward: 45.2500,                 loss: nan
env1_first_0:                 episode reward: -40.4500,                 loss: nan
env1_second_0:                 episode reward: 40.4500,                 loss: nan
env2_first_0:                 episode reward: -53.7500,                 loss: nan
env2_second_0:                 episode reward: 53.7500,                 loss: nan
env3_first_0:                 episode reward: -36.9500,                 loss: nan
env3_second_0:                 episode reward: 36.9500,                 loss: nan
env4_first_0:                 episode reward: -40.3000,                 loss: nan
env4_second_0:                 episode reward: 40.3000,                 loss: nan
Episode: 8741/10000 (87.4100%),                 avg. length: 274.25,                last time consumption/overall running time: 74.5067s / 33688.6702 s
env0_first_0:                 episode reward: -36.8000,                 loss: 140.9565
env0_second_0:                 episode reward: 36.8000,                 loss: nan
env1_first_0:                 episode reward: -42.6000,                 loss: nan
env1_second_0:                 episode reward: 42.6000,                 loss: nan
env2_first_0:                 episode reward: -45.9500,                 loss: nan
env2_second_0:                 episode reward: 45.9500,                 loss: nan
env3_first_0:                 episode reward: -44.5500,                 loss: nan
env3_second_0:                 episode reward: 44.5500,                 loss: nan
env4_first_0:                 episode reward: -42.2500,                 loss: nan
env4_second_0:                 episode reward: 42.2500,                 loss: nan
Episode: 8761/10000 (87.6100%),                 avg. length: 279.1,                last time consumption/overall running time: 76.1863s / 33764.8564 s
env0_first_0:                 episode reward: -55.5000,                 loss: 133.4374
env0_second_0:                 episode reward: 55.5000,                 loss: nan
env1_first_0:                 episode reward: -39.3000,                 loss: nan
env1_second_0:                 episode reward: 39.3000,                 loss: nan
env2_first_0:                 episode reward: -57.1000,                 loss: nan
env2_second_0:                 episode reward: 57.1000,                 loss: nan
env3_first_0:                 episode reward: -47.6500,                 loss: nan
env3_second_0:                 episode reward: 47.6500,                 loss: nan
env4_first_0:                 episode reward: -47.0500,                 loss: nan
env4_second_0:                 episode reward: 47.0500,                 loss: nan
Episode: 8781/10000 (87.8100%),                 avg. length: 282.8,                last time consumption/overall running time: 75.7283s / 33840.5848 s
env0_first_0:                 episode reward: -46.0000,                 loss: 131.4889
env0_second_0:                 episode reward: 46.0000,                 loss: nan
env1_first_0:                 episode reward: -55.6500,                 loss: nan
env1_second_0:                 episode reward: 55.6500,                 loss: nan
env2_first_0:                 episode reward: -66.7000,                 loss: nan
env2_second_0:                 episode reward: 66.7000,                 loss: nan
env3_first_0:                 episode reward: -63.2500,                 loss: nan
env3_second_0:                 episode reward: 63.2500,                 loss: nan
env4_first_0:                 episode reward: -49.9500,                 loss: nan
env4_second_0:                 episode reward: 49.9500,                 loss: nan
Episode: 8801/10000 (88.0100%),                 avg. length: 287.4,                last time consumption/overall running time: 77.3363s / 33917.9211 s
env0_first_0:                 episode reward: -11.8000,                 loss: 123.2137
env0_second_0:                 episode reward: 11.8000,                 loss: nan
env1_first_0:                 episode reward: -32.1500,                 loss: nan
env1_second_0:                 episode reward: 32.1500,                 loss: nan
env2_first_0:                 episode reward: -20.9000,                 loss: nan
env2_second_0:                 episode reward: 20.9000,                 loss: nan
env3_first_0:                 episode reward: -44.6000,                 loss: nan
env3_second_0:                 episode reward: 44.6000,                 loss: nan
env4_first_0:                 episode reward: -31.8000,                 loss: nan
env4_second_0:                 episode reward: 31.8000,                 loss: nan
Episode: 8821/10000 (88.2100%),                 avg. length: 275.65,                last time consumption/overall running time: 74.0753s / 33991.9964 s
env0_first_0:                 episode reward: -48.4500,                 loss: 148.8893
env0_second_0:                 episode reward: 48.4500,                 loss: nan
env1_first_0:                 episode reward: -30.8000,                 loss: nan
env1_second_0:                 episode reward: 30.8000,                 loss: nan
env2_first_0:                 episode reward: -36.1500,                 loss: nan
env2_second_0:                 episode reward: 36.1500,                 loss: nan
env3_first_0:                 episode reward: -30.8500,                 loss: nan
env3_second_0:                 episode reward: 30.8500,                 loss: nan
env4_first_0:                 episode reward: -38.8500,                 loss: nan
env4_second_0:                 episode reward: 38.8500,                 loss: nan
Episode: 8841/10000 (88.4100%),                 avg. length: 279.65,                last time consumption/overall running time: 76.1362s / 34068.1326 s
env0_first_0:                 episode reward: -33.3500,                 loss: 144.8221
env0_second_0:                 episode reward: 33.3500,                 loss: nan
env1_first_0:                 episode reward: -39.7000,                 loss: nan
env1_second_0:                 episode reward: 39.7000,                 loss: nan
env2_first_0:                 episode reward: -43.1500,                 loss: nan
env2_second_0:                 episode reward: 43.1500,                 loss: nan
env3_first_0:                 episode reward: -43.6500,                 loss: nan
env3_second_0:                 episode reward: 43.6500,                 loss: nan
env4_first_0:                 episode reward: -39.4500,                 loss: nan
env4_second_0:                 episode reward: 39.4500,                 loss: nan
Episode: 8861/10000 (88.6100%),                 avg. length: 288.0,                last time consumption/overall running time: 78.0899s / 34146.2224 s
env0_first_0:                 episode reward: -16.6000,                 loss: 130.1355
env0_second_0:                 episode reward: 16.6000,                 loss: nan
env1_first_0:                 episode reward: -20.3500,                 loss: nan
env1_second_0:                 episode reward: 20.3500,                 loss: nan
env2_first_0:                 episode reward: -45.4000,                 loss: nan
env2_second_0:                 episode reward: 45.4000,                 loss: nan
env3_first_0:                 episode reward: -24.1500,                 loss: nan
env3_second_0:                 episode reward: 24.1500,                 loss: nan
env4_first_0:                 episode reward: -20.5000,                 loss: nan
env4_second_0:                 episode reward: 20.5000,                 loss: nan
Episode: 8881/10000 (88.8100%),                 avg. length: 281.1,                last time consumption/overall running time: 76.4924s / 34222.7149 s
env0_first_0:                 episode reward: -48.8500,                 loss: 142.3085
env0_second_0:                 episode reward: 48.8500,                 loss: nan
env1_first_0:                 episode reward: -29.4000,                 loss: nan
env1_second_0:                 episode reward: 29.4000,                 loss: nan
env2_first_0:                 episode reward: -32.1500,                 loss: nan
env2_second_0:                 episode reward: 32.1500,                 loss: nan
env3_first_0:                 episode reward: -60.2000,                 loss: nan
env3_second_0:                 episode reward: 60.2000,                 loss: nan
env4_first_0:                 episode reward: -40.2500,                 loss: nan
env4_second_0:                 episode reward: 40.2500,                 loss: nan
Episode: 8901/10000 (89.0100%),                 avg. length: 283.7,                last time consumption/overall running time: 77.4389s / 34300.1537 s
env0_first_0:                 episode reward: -48.3500,                 loss: 136.6418
env0_second_0:                 episode reward: 48.3500,                 loss: nan
env1_first_0:                 episode reward: -50.9000,                 loss: nan
env1_second_0:                 episode reward: 50.9000,                 loss: nan
env2_first_0:                 episode reward: -46.4000,                 loss: nan
env2_second_0:                 episode reward: 46.4000,                 loss: nan
env3_first_0:                 episode reward: -44.1000,                 loss: nan
env3_second_0:                 episode reward: 44.1000,                 loss: nan
env4_first_0:                 episode reward: -44.1500,                 loss: nan
env4_second_0:                 episode reward: 44.1500,                 loss: nan
Episode: 8921/10000 (89.2100%),                 avg. length: 263.2,                last time consumption/overall running time: 72.2997s / 34372.4534 s
env0_first_0:                 episode reward: -54.0500,                 loss: 155.4260
env0_second_0:                 episode reward: 54.0500,                 loss: nan
env1_first_0:                 episode reward: -61.3000,                 loss: nan
env1_second_0:                 episode reward: 61.3000,                 loss: nan
env2_first_0:                 episode reward: -57.3000,                 loss: nan
env2_second_0:                 episode reward: 57.3000,                 loss: nan
env3_first_0:                 episode reward: -59.8000,                 loss: nan
env3_second_0:                 episode reward: 59.8000,                 loss: nan
env4_first_0:                 episode reward: -50.9500,                 loss: nan
env4_second_0:                 episode reward: 50.9500,                 loss: nan
Episode: 8941/10000 (89.4100%),                 avg. length: 282.75,                last time consumption/overall running time: 74.9736s / 34447.4270 s
env0_first_0:                 episode reward: -46.0500,                 loss: 134.8905
env0_second_0:                 episode reward: 46.0500,                 loss: nan
env1_first_0:                 episode reward: -40.1000,                 loss: nan
env1_second_0:                 episode reward: 40.1000,                 loss: nan
env2_first_0:                 episode reward: -55.3000,                 loss: nan
env2_second_0:                 episode reward: 55.3000,                 loss: nan
env3_first_0:                 episode reward: -51.2000,                 loss: nan
env3_second_0:                 episode reward: 51.2000,                 loss: nan
env4_first_0:                 episode reward: -46.3000,                 loss: nan
env4_second_0:                 episode reward: 46.3000,                 loss: nan
Episode: 8961/10000 (89.6100%),                 avg. length: 279.95,                last time consumption/overall running time: 74.7796s / 34522.2067 s
env0_first_0:                 episode reward: -46.0000,                 loss: 155.7453
env0_second_0:                 episode reward: 46.0000,                 loss: nan
env1_first_0:                 episode reward: -51.2000,                 loss: nan
env1_second_0:                 episode reward: 51.2000,                 loss: nan
env2_first_0:                 episode reward: -42.5000,                 loss: nan
env2_second_0:                 episode reward: 42.5000,                 loss: nan
env3_first_0:                 episode reward: -44.7500,                 loss: nan
env3_second_0:                 episode reward: 44.7500,                 loss: nan
env4_first_0:                 episode reward: -63.8500,                 loss: nan
env4_second_0:                 episode reward: 63.8500,                 loss: nan
Episode: 8981/10000 (89.8100%),                 avg. length: 277.6,                last time consumption/overall running time: 74.4415s / 34596.6482 s
env0_first_0:                 episode reward: -58.6000,                 loss: 143.4703
env0_second_0:                 episode reward: 58.6000,                 loss: nan
env1_first_0:                 episode reward: -49.3500,                 loss: nan
env1_second_0:                 episode reward: 49.3500,                 loss: nan
env2_first_0:                 episode reward: -49.1000,                 loss: nan
env2_second_0:                 episode reward: 49.1000,                 loss: nan
env3_first_0:                 episode reward: -46.9500,                 loss: nan
env3_second_0:                 episode reward: 46.9500,                 loss: nan
env4_first_0:                 episode reward: -50.9500,                 loss: nan
env4_second_0:                 episode reward: 50.9500,                 loss: nan
Episode: 9001/10000 (90.0100%),                 avg. length: 259.1,                last time consumption/overall running time: 70.8933s / 34667.5416 s
env0_first_0:                 episode reward: -55.2000,                 loss: 145.5264
env0_second_0:                 episode reward: 55.2000,                 loss: nan
env1_first_0:                 episode reward: -56.3500,                 loss: nan
env1_second_0:                 episode reward: 56.3500,                 loss: nan
env2_first_0:                 episode reward: -62.1000,                 loss: nan
env2_second_0:                 episode reward: 62.1000,                 loss: nan
env3_first_0:                 episode reward: -49.3000,                 loss: nan
env3_second_0:                 episode reward: 49.3000,                 loss: nan
env4_first_0:                 episode reward: -57.2000,                 loss: nan
env4_second_0:                 episode reward: 57.2000,                 loss: nan
Episode: 9021/10000 (90.2100%),                 avg. length: 263.8,                last time consumption/overall running time: 72.0500s / 34739.5916 s
env0_first_0:                 episode reward: -63.7500,                 loss: 132.9722
env0_second_0:                 episode reward: 63.7500,                 loss: nan
env1_first_0:                 episode reward: -61.3000,                 loss: nan
env1_second_0:                 episode reward: 61.3000,                 loss: nan
env2_first_0:                 episode reward: -54.0500,                 loss: nan
env2_second_0:                 episode reward: 54.0500,                 loss: nan
env3_first_0:                 episode reward: -60.3000,                 loss: nan
env3_second_0:                 episode reward: 60.3000,                 loss: nan
env4_first_0:                 episode reward: -67.5500,                 loss: nan
env4_second_0:                 episode reward: 67.5500,                 loss: nan
Episode: 9041/10000 (90.4100%),                 avg. length: 276.65,                last time consumption/overall running time: 73.9900s / 34813.5816 s
env0_first_0:                 episode reward: -44.9500,                 loss: 109.9176
env0_second_0:                 episode reward: 44.9500,                 loss: nan
env1_first_0:                 episode reward: -45.0000,                 loss: nan
env1_second_0:                 episode reward: 45.0000,                 loss: nan
env2_first_0:                 episode reward: -44.7000,                 loss: nan
env2_second_0:                 episode reward: 44.7000,                 loss: nan
env3_first_0:                 episode reward: -56.7000,                 loss: nan
env3_second_0:                 episode reward: 56.7000,                 loss: nan
env4_first_0:                 episode reward: -37.0500,                 loss: nan
env4_second_0:                 episode reward: 37.0500,                 loss: nan
Episode: 9061/10000 (90.6100%),                 avg. length: 263.9,                last time consumption/overall running time: 72.5704s / 34886.1520 s
env0_first_0:                 episode reward: -20.0500,                 loss: 104.5488
env0_second_0:                 episode reward: 20.0500,                 loss: nan
env1_first_0:                 episode reward: -43.7500,                 loss: nan
env1_second_0:                 episode reward: 43.7500,                 loss: nan
env2_first_0:                 episode reward: -37.2500,                 loss: nan
env2_second_0:                 episode reward: 37.2500,                 loss: nan
env3_first_0:                 episode reward: -32.2000,                 loss: nan
env3_second_0:                 episode reward: 32.2000,                 loss: nan
env4_first_0:                 episode reward: -39.7500,                 loss: nan
env4_second_0:                 episode reward: 39.7500,                 loss: nan
Episode: 9081/10000 (90.8100%),                 avg. length: 287.8,                last time consumption/overall running time: 78.0454s / 34964.1974 s
env0_first_0:                 episode reward: -40.3500,                 loss: 101.6855
env0_second_0:                 episode reward: 40.3500,                 loss: nan
env1_first_0:                 episode reward: -48.0000,                 loss: nan
env1_second_0:                 episode reward: 48.0000,                 loss: nan
env2_first_0:                 episode reward: -31.3500,                 loss: nan
env2_second_0:                 episode reward: 31.3500,                 loss: nan
env3_first_0:                 episode reward: -43.9000,                 loss: nan
env3_second_0:                 episode reward: 43.9000,                 loss: nan
env4_first_0:                 episode reward: -45.9500,                 loss: nan
env4_second_0:                 episode reward: 45.9500,                 loss: nan
Episode: 9101/10000 (91.0100%),                 avg. length: 271.25,                last time consumption/overall running time: 73.3086s / 35037.5060 s
env0_first_0:                 episode reward: -51.3000,                 loss: 117.7146
env0_second_0:                 episode reward: 51.3000,                 loss: nan
env1_first_0:                 episode reward: -71.4500,                 loss: nan
env1_second_0:                 episode reward: 71.4500,                 loss: nan
env2_first_0:                 episode reward: -61.4500,                 loss: nan
env2_second_0:                 episode reward: 61.4500,                 loss: nan
env3_first_0:                 episode reward: -61.6500,                 loss: nan
env3_second_0:                 episode reward: 61.6500,                 loss: nan
env4_first_0:                 episode reward: -78.8500,                 loss: nan
env4_second_0:                 episode reward: 78.8500,                 loss: nan
Episode: 9121/10000 (91.2100%),                 avg. length: 276.45,                last time consumption/overall running time: 74.2637s / 35111.7697 s
env0_first_0:                 episode reward: -56.4000,                 loss: 117.0227
env0_second_0:                 episode reward: 56.4000,                 loss: nan
env1_first_0:                 episode reward: -62.4500,                 loss: nan
env1_second_0:                 episode reward: 62.4500,                 loss: nan
env2_first_0:                 episode reward: -66.8000,                 loss: nan
env2_second_0:                 episode reward: 66.8000,                 loss: nan
env3_first_0:                 episode reward: -61.4500,                 loss: nan
env3_second_0:                 episode reward: 61.4500,                 loss: nan
env4_first_0:                 episode reward: -49.2000,                 loss: nan
env4_second_0:                 episode reward: 49.2000,                 loss: nan
Episode: 9141/10000 (91.4100%),                 avg. length: 267.35,                last time consumption/overall running time: 72.5604s / 35184.3300 s
env0_first_0:                 episode reward: -72.3500,                 loss: 116.3192
env0_second_0:                 episode reward: 72.3500,                 loss: nan
env1_first_0:                 episode reward: -55.5500,                 loss: nan
env1_second_0:                 episode reward: 55.5500,                 loss: nan
env2_first_0:                 episode reward: -46.7000,                 loss: nan
env2_second_0:                 episode reward: 46.7000,                 loss: nan
env3_first_0:                 episode reward: -62.1500,                 loss: nan
env3_second_0:                 episode reward: 62.1500,                 loss: nan
env4_first_0:                 episode reward: -64.3000,                 loss: nan
env4_second_0:                 episode reward: 64.3000,                 loss: nan
Episode: 9161/10000 (91.6100%),                 avg. length: 261.9,                last time consumption/overall running time: 71.9498s / 35256.2799 s
env0_first_0:                 episode reward: -41.6000,                 loss: 146.9655
env0_second_0:                 episode reward: 41.6000,                 loss: nan
env1_first_0:                 episode reward: -62.9500,                 loss: nan
env1_second_0:                 episode reward: 62.9500,                 loss: nan
env2_first_0:                 episode reward: -53.6000,                 loss: nan
env2_second_0:                 episode reward: 53.6000,                 loss: nan
env3_first_0:                 episode reward: -51.1500,                 loss: nan
env3_second_0:                 episode reward: 51.1500,                 loss: nan
env4_first_0:                 episode reward: -56.7500,                 loss: nan
env4_second_0:                 episode reward: 56.7500,                 loss: nan
Episode: 9181/10000 (91.8100%),                 avg. length: 262.65,                last time consumption/overall running time: 70.9327s / 35327.2126 s
env0_first_0:                 episode reward: -52.7000,                 loss: 128.1625
env0_second_0:                 episode reward: 52.7000,                 loss: nan
env1_first_0:                 episode reward: -55.9000,                 loss: nan
env1_second_0:                 episode reward: 55.9000,                 loss: nan
env2_first_0:                 episode reward: -45.1500,                 loss: nan
env2_second_0:                 episode reward: 45.1500,                 loss: nan
env3_first_0:                 episode reward: -55.9500,                 loss: nan
env3_second_0:                 episode reward: 55.9500,                 loss: nan
env4_first_0:                 episode reward: -52.1500,                 loss: nan
env4_second_0:                 episode reward: 52.1500,                 loss: nan
Episode: 9201/10000 (92.0100%),                 avg. length: 263.9,                last time consumption/overall running time: 71.4390s / 35398.6516 s
env0_first_0:                 episode reward: -68.1500,                 loss: 139.4918
env0_second_0:                 episode reward: 68.1500,                 loss: nan
env1_first_0:                 episode reward: -61.8000,                 loss: nan
env1_second_0:                 episode reward: 61.8000,                 loss: nan
env2_first_0:                 episode reward: -64.8500,                 loss: nan
env2_second_0:                 episode reward: 64.8500,                 loss: nan
env3_first_0:                 episode reward: -41.2500,                 loss: nan
env3_second_0:                 episode reward: 41.2500,                 loss: nan
env4_first_0:                 episode reward: -58.7500,                 loss: nan
env4_second_0:                 episode reward: 58.7500,                 loss: nan
Episode: 9221/10000 (92.2100%),                 avg. length: 264.55,                last time consumption/overall running time: 71.6761s / 35470.3277 s
env0_first_0:                 episode reward: -50.7500,                 loss: 133.1673
env0_second_0:                 episode reward: 50.7500,                 loss: nan
env1_first_0:                 episode reward: -65.7500,                 loss: nan
env1_second_0:                 episode reward: 65.7500,                 loss: nan
env2_first_0:                 episode reward: -64.4000,                 loss: nan
env2_second_0:                 episode reward: 64.4000,                 loss: nan
env3_first_0:                 episode reward: -57.4500,                 loss: nan
env3_second_0:                 episode reward: 57.4500,                 loss: nan
env4_first_0:                 episode reward: -49.8500,                 loss: nan
env4_second_0:                 episode reward: 49.8500,                 loss: nan
Episode: 9241/10000 (92.4100%),                 avg. length: 257.05,                last time consumption/overall running time: 69.4670s / 35539.7947 s
env0_first_0:                 episode reward: -64.3500,                 loss: 135.9309
env0_second_0:                 episode reward: 64.3500,                 loss: nan
env1_first_0:                 episode reward: -64.7000,                 loss: nan
env1_second_0:                 episode reward: 64.7000,                 loss: nan
env2_first_0:                 episode reward: -56.3000,                 loss: nan
env2_second_0:                 episode reward: 56.3000,                 loss: nan
env3_first_0:                 episode reward: -60.6500,                 loss: nan
env3_second_0:                 episode reward: 60.6500,                 loss: nan
env4_first_0:                 episode reward: -61.4500,                 loss: nan
env4_second_0:                 episode reward: 61.4500,                 loss: nan
Episode: 9261/10000 (92.6100%),                 avg. length: 256.5,                last time consumption/overall running time: 69.8640s / 35609.6587 s
env0_first_0:                 episode reward: -70.9000,                 loss: 120.6119
env0_second_0:                 episode reward: 70.9000,                 loss: nan
env1_first_0:                 episode reward: -65.4000,                 loss: nan
env1_second_0:                 episode reward: 65.4000,                 loss: nan
env2_first_0:                 episode reward: -71.6500,                 loss: nan
env2_second_0:                 episode reward: 71.6500,                 loss: nan
env3_first_0:                 episode reward: -64.0500,                 loss: nan
env3_second_0:                 episode reward: 64.0500,                 loss: nan
env4_first_0:                 episode reward: -63.6000,                 loss: nan
env4_second_0:                 episode reward: 63.6000,                 loss: nan
Episode: 9281/10000 (92.8100%),                 avg. length: 243.3,                last time consumption/overall running time: 68.0806s / 35677.7393 s
env0_first_0:                 episode reward: -58.7000,                 loss: 112.4786
env0_second_0:                 episode reward: 58.7000,                 loss: nan
env1_first_0:                 episode reward: -42.5000,                 loss: nan
env1_second_0:                 episode reward: 42.5000,                 loss: nan
env2_first_0:                 episode reward: -47.0000,                 loss: nan
env2_second_0:                 episode reward: 47.0000,                 loss: nan
env3_first_0:                 episode reward: -54.3500,                 loss: nan
env3_second_0:                 episode reward: 54.3500,                 loss: nan
env4_first_0:                 episode reward: -40.5000,                 loss: nan
env4_second_0:                 episode reward: 40.5000,                 loss: nan
Episode: 9301/10000 (93.0100%),                 avg. length: 247.35,                last time consumption/overall running time: 68.3199s / 35746.0592 s
env0_first_0:                 episode reward: -65.3500,                 loss: 122.7923
env0_second_0:                 episode reward: 65.3500,                 loss: nan
env1_first_0:                 episode reward: -72.2500,                 loss: nan
env1_second_0:                 episode reward: 72.2500,                 loss: nan
env2_first_0:                 episode reward: -59.8500,                 loss: nan
env2_second_0:                 episode reward: 59.8500,                 loss: nan
env3_first_0:                 episode reward: -45.4500,                 loss: nan
env3_second_0:                 episode reward: 45.4500,                 loss: nan
env4_first_0:                 episode reward: -68.2000,                 loss: nan
env4_second_0:                 episode reward: 68.2000,                 loss: nan
Episode: 9321/10000 (93.2100%),                 avg. length: 259.25,                last time consumption/overall running time: 71.2752s / 35817.3343 s
env0_first_0:                 episode reward: -56.6500,                 loss: 140.7316
env0_second_0:                 episode reward: 56.6500,                 loss: nan
env1_first_0:                 episode reward: -59.7500,                 loss: nan
env1_second_0:                 episode reward: 59.7500,                 loss: nan
env2_first_0:                 episode reward: -59.5000,                 loss: nan
env2_second_0:                 episode reward: 59.5000,                 loss: nan
env3_first_0:                 episode reward: -60.4000,                 loss: nan
env3_second_0:                 episode reward: 60.4000,                 loss: nan
env4_first_0:                 episode reward: -57.2500,                 loss: nan
env4_second_0:                 episode reward: 57.2500,                 loss: nan
Episode: 9341/10000 (93.4100%),                 avg. length: 284.05,                last time consumption/overall running time: 76.1785s / 35893.5128 s
env0_first_0:                 episode reward: -59.0000,                 loss: 151.7136
env0_second_0:                 episode reward: 59.0000,                 loss: nan
env1_first_0:                 episode reward: -53.8500,                 loss: nan
env1_second_0:                 episode reward: 53.8500,                 loss: nan
env2_first_0:                 episode reward: -56.8500,                 loss: nan
env2_second_0:                 episode reward: 56.8500,                 loss: nan
env3_first_0:                 episode reward: -63.7000,                 loss: nan
env3_second_0:                 episode reward: 63.7000,                 loss: nan
env4_first_0:                 episode reward: -53.0500,                 loss: nan
env4_second_0:                 episode reward: 53.0500,                 loss: nan
Episode: 9361/10000 (93.6100%),                 avg. length: 254.25,                last time consumption/overall running time: 71.0784s / 35964.5912 s
env0_first_0:                 episode reward: -54.6000,                 loss: 149.3947
env0_second_0:                 episode reward: 54.6000,                 loss: nan
env1_first_0:                 episode reward: -55.7000,                 loss: nan
env1_second_0:                 episode reward: 55.7000,                 loss: nan
env2_first_0:                 episode reward: -60.2500,                 loss: nan
env2_second_0:                 episode reward: 60.2500,                 loss: nan
env3_first_0:                 episode reward: -67.1000,                 loss: nan
env3_second_0:                 episode reward: 67.1000,                 loss: nan
env4_first_0:                 episode reward: -65.6000,                 loss: nan
env4_second_0:                 episode reward: 65.6000,                 loss: nan
Episode: 9381/10000 (93.8100%),                 avg. length: 267.7,                last time consumption/overall running time: 73.6414s / 36038.2326 s
env0_first_0:                 episode reward: -54.7000,                 loss: 134.1242
env0_second_0:                 episode reward: 54.7000,                 loss: nan
env1_first_0:                 episode reward: -64.2000,                 loss: nan
env1_second_0:                 episode reward: 64.2000,                 loss: nan
env2_first_0:                 episode reward: -56.3000,                 loss: nan
env2_second_0:                 episode reward: 56.3000,                 loss: nan
env3_first_0:                 episode reward: -62.8500,                 loss: nan
env3_second_0:                 episode reward: 62.8500,                 loss: nan
env4_first_0:                 episode reward: -58.7000,                 loss: nan
env4_second_0:                 episode reward: 58.7000,                 loss: nan
Episode: 9401/10000 (94.0100%),                 avg. length: 268.45,                last time consumption/overall running time: 73.0494s / 36111.2820 s
env0_first_0:                 episode reward: -71.0000,                 loss: 136.1730
env0_second_0:                 episode reward: 71.0000,                 loss: nan
env1_first_0:                 episode reward: -66.2500,                 loss: nan
env1_second_0:                 episode reward: 66.2500,                 loss: nan
env2_first_0:                 episode reward: -57.6000,                 loss: nan
env2_second_0:                 episode reward: 57.6000,                 loss: nan
env3_first_0:                 episode reward: -58.6500,                 loss: nan
env3_second_0:                 episode reward: 58.6500,                 loss: nan
env4_first_0:                 episode reward: -61.6500,                 loss: nan
env4_second_0:                 episode reward: 61.6500,                 loss: nan
Episode: 9421/10000 (94.2100%),                 avg. length: 239.15,                last time consumption/overall running time: 67.2383s / 36178.5203 s
env0_first_0:                 episode reward: -59.6000,                 loss: 150.1454
env0_second_0:                 episode reward: 59.6000,                 loss: nan
env1_first_0:                 episode reward: -67.8000,                 loss: nan
env1_second_0:                 episode reward: 67.8000,                 loss: nan
env2_first_0:                 episode reward: -60.0500,                 loss: nan
env2_second_0:                 episode reward: 60.0500,                 loss: nan
env3_first_0:                 episode reward: -61.1500,                 loss: nan
env3_second_0:                 episode reward: 61.1500,                 loss: nan
env4_first_0:                 episode reward: -73.3000,                 loss: nan
env4_second_0:                 episode reward: 73.3000,                 loss: nan
Episode: 9441/10000 (94.4100%),                 avg. length: 255.25,                last time consumption/overall running time: 70.3091s / 36248.8294 s
env0_first_0:                 episode reward: -69.7000,                 loss: 132.2460
env0_second_0:                 episode reward: 69.7000,                 loss: nan
env1_first_0:                 episode reward: -65.4000,                 loss: nan
env1_second_0:                 episode reward: 65.4000,                 loss: nan
env2_first_0:                 episode reward: -66.6500,                 loss: nan
env2_second_0:                 episode reward: 66.6500,                 loss: nan
env3_first_0:                 episode reward: -65.6000,                 loss: nan
env3_second_0:                 episode reward: 65.6000,                 loss: nan
env4_first_0:                 episode reward: -67.4000,                 loss: nan
env4_second_0:                 episode reward: 67.4000,                 loss: nan
Episode: 9461/10000 (94.6100%),                 avg. length: 245.5,                last time consumption/overall running time: 67.4516s / 36316.2810 s
env0_first_0:                 episode reward: -58.0000,                 loss: 131.5435
env0_second_0:                 episode reward: 58.0000,                 loss: nan
env1_first_0:                 episode reward: -58.9000,                 loss: nan
env1_second_0:                 episode reward: 58.9000,                 loss: nan
env2_first_0:                 episode reward: -57.1000,                 loss: nan
env2_second_0:                 episode reward: 57.1000,                 loss: nan
env3_first_0:                 episode reward: -66.5000,                 loss: nan
env3_second_0:                 episode reward: 66.5000,                 loss: nan
env4_first_0:                 episode reward: -54.5000,                 loss: nan
env4_second_0:                 episode reward: 54.5000,                 loss: nan
Episode: 9481/10000 (94.8100%),                 avg. length: 296.2,                last time consumption/overall running time: 78.2869s / 36394.5678 s
env0_first_0:                 episode reward: -1.2500,                 loss: 25.2485
env0_second_0:                 episode reward: 1.2500,                 loss: nan
env1_first_0:                 episode reward: -4.1000,                 loss: nan
env1_second_0:                 episode reward: 4.1000,                 loss: nan
env2_first_0:                 episode reward: -5.6500,                 loss: nan
env2_second_0:                 episode reward: 5.6500,                 loss: nan
env3_first_0:                 episode reward: -1.4000,                 loss: nan
env3_second_0:                 episode reward: 1.4000,                 loss: nan
env4_first_0:                 episode reward: -1.1500,                 loss: nan
env4_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 9501/10000 (95.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.4330s / 36475.0008 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0730
env0_second_0:                 episode reward: -0.6000,                 loss: nan
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
env2_first_0:                 episode reward: 0.5000,                 loss: nan
env2_second_0:                 episode reward: -0.5000,                 loss: nan
env3_first_0:                 episode reward: 0.4000,                 loss: nan
env3_second_0:                 episode reward: -0.4000,                 loss: nan
env4_first_0:                 episode reward: 0.3500,                 loss: nan
env4_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 9521/10000 (95.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.0201s / 36555.0209 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2156
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 9541/10000 (95.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.8728s / 36634.8937 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2291
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 9561/10000 (95.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.0486s / 36713.9423 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2332
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.2000,                 loss: nan
env3_second_0:                 episode reward: -0.2000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 9581/10000 (95.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.9767s / 36792.9190 s
env0_first_0:                 episode reward: 1.4000,                 loss: 1.2121
env0_second_0:                 episode reward: -1.4000,                 loss: nan
env1_first_0:                 episode reward: 2.0000,                 loss: nan
env1_second_0:                 episode reward: -2.0000,                 loss: nan
env2_first_0:                 episode reward: 1.0500,                 loss: nan
env2_second_0:                 episode reward: -1.0500,                 loss: nan
env3_first_0:                 episode reward: 2.0500,                 loss: nan
env3_second_0:                 episode reward: -2.0500,                 loss: nan
env4_first_0:                 episode reward: 0.8000,                 loss: nan
env4_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 9601/10000 (96.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.7130s / 36872.6319 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0014
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 9621/10000 (96.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.2283s / 36951.8603 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0462
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 9641/10000 (96.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.1424s / 37031.0026 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0206
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 9661/10000 (96.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.3951s / 37111.3977 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0895
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 9681/10000 (96.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.5277s / 37191.9254 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.1056
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 9701/10000 (97.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.3685s / 37272.2939 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0834
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 9721/10000 (97.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.3402s / 37351.6341 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0599
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 9741/10000 (97.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.5242s / 37431.1583 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0684
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 9761/10000 (97.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.8663s / 37511.0246 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0741
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 9781/10000 (97.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.9561s / 37590.9807 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0711
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 9801/10000 (98.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.1293s / 37671.1100 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0777
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 9821/10000 (98.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.8159s / 37750.9259 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2124
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 9841/10000 (98.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.2702s / 37831.1961 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2780
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 9861/10000 (98.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.1873s / 37910.3835 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.1963
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 9881/10000 (98.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.0816s / 37990.4651 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2040
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 9901/10000 (99.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.7317s / 38069.1968 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2792
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 9921/10000 (99.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.0304s / 38149.2271 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.3850
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 9941/10000 (99.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.8753s / 38230.1024 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2781
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 9961/10000 (99.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.0539s / 38310.1563 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2243
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 9981/10000 (99.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.6994s / 38390.8557 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2919
env0_second_0:                 episode reward: 0.0000,                 loss: nanLoad boxing_v1 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
Load boxing_v1 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
Load boxing_v1 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
Load boxing_v1 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
Load boxing_v1 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
