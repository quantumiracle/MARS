pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
boxing_v1 pettingzoo
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
random seed: [91, 69]
<SubprocVectorEnv instance>
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
Agents No. [1] (index starting from 0) are not learnable.
Arguments:  {'env_name': 'boxing_v1', 'env_type': 'pettingzoo', 'num_envs': 2, 'ram': True, 'seed': 'random', 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nxdo2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'selfplay_score_delta': 80, 'trainable_agent_idx': 0, 'opponent_idx': 1}}
Save models to : /home/zihan/research/MARS/data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2. 
 Save logs to: /home/zihan/research/MARS/data/log/20220119_0524/pettingzoo_boxing_v1_nxdo2.
boxing_v1 pettingzoo
Load boxing_v1 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
random seed: 11
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
Episode: 1/10000 (0.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 27.5447s / 27.5447 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0122
env0_second_0:                 episode reward: -21.0000,                 loss: nan
env1_first_0:                 episode reward: 28.0000,                 loss: nan
env1_second_0:                 episode reward: -28.0000,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 1425.35,                last time consumption/overall running time: 556.0717s / 583.6164 s
env0_first_0:                 episode reward: 69.6000,                 loss: 0.0179
env0_second_0:                 episode reward: -69.6000,                 loss: nan
env1_first_0:                 episode reward: 74.2500,                 loss: nan
env1_second_0:                 episode reward: -74.2500,                 loss: nan
Score delta: 172.0, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/21_0.
Episode: 41/10000 (0.4100%),                 avg. length: 775.8,                last time consumption/overall running time: 335.9406s / 919.5570 s
env0_first_0:                 episode reward: -72.3000,                 loss: nan
env0_second_0:                 episode reward: 72.3000,                 loss: 0.0354
env1_first_0:                 episode reward: -86.0000,                 loss: nan
env1_second_0:                 episode reward: 86.0000,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 1432.5,                last time consumption/overall running time: 673.9106s / 1593.4676 s
env0_first_0:                 episode reward: -39.9000,                 loss: 0.0369
env0_second_0:                 episode reward: 39.9000,                 loss: 0.0377
env1_first_0:                 episode reward: -39.0500,                 loss: nan
env1_second_0:                 episode reward: 39.0500,                 loss: nan
Score delta: 186.2, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/42_1.
Episode: 81/10000 (0.8100%),                 avg. length: 1784.0,                last time consumption/overall running time: 798.4905s / 2391.9581 s
env0_first_0:                 episode reward: 9.3500,                 loss: 0.0482
env0_second_0:                 episode reward: -9.3500,                 loss: nan
env1_first_0:                 episode reward: 5.1500,                 loss: nan
env1_second_0:                 episode reward: -5.1500,                 loss: nan
Episode: 101/10000 (1.0100%),                 avg. length: 1635.2,                last time consumption/overall running time: 761.0887s / 3153.0468 s
env0_first_0:                 episode reward: 32.0500,                 loss: 0.0396
env0_second_0:                 episode reward: -32.0500,                 loss: 0.0577
env1_first_0:                 episode reward: 39.7500,                 loss: nan
env1_second_0:                 episode reward: -39.7500,                 loss: nan
Score delta: 80.6, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/90_0.
Episode: 121/10000 (1.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 796.9792s / 3950.0261 s
env0_first_0:                 episode reward: 17.9000,                 loss: nan
env0_second_0:                 episode reward: -17.9000,                 loss: 0.0643
env1_first_0:                 episode reward: 16.9000,                 loss: nan
env1_second_0:                 episode reward: -16.9000,                 loss: nan
Episode: 141/10000 (1.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 799.5872s / 4749.6133 s
env0_first_0:                 episode reward: -0.6500,                 loss: nan
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0336
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 161/10000 (1.6100%),                 avg. length: 1784.0,                last time consumption/overall running time: 799.6257s / 5549.2390 s
env0_first_0:                 episode reward: -1.9000,                 loss: nan
env0_second_0:                 episode reward: 1.9000,                 loss: 0.0125
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 181/10000 (1.8100%),                 avg. length: 1594.75,                last time consumption/overall running time: 792.1999s / 6341.4389 s
env0_first_0:                 episode reward: -40.8500,                 loss: 0.0484
env0_second_0:                 episode reward: 40.8500,                 loss: 0.0093
env1_first_0:                 episode reward: -37.2000,                 loss: nan
env1_second_0:                 episode reward: 37.2000,                 loss: nan
Score delta: 82.8, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/177_1.
Episode: 201/10000 (2.0100%),                 avg. length: 1733.1,                last time consumption/overall running time: 775.3901s / 7116.8290 s
env0_first_0:                 episode reward: -18.5500,                 loss: 0.0451
env0_second_0:                 episode reward: 18.5500,                 loss: nan
env1_first_0:                 episode reward: -13.2000,                 loss: nan
env1_second_0:                 episode reward: 13.2000,                 loss: nan
Episode: 221/10000 (2.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 798.4997s / 7915.3287 s
env0_first_0:                 episode reward: 5.5000,                 loss: 0.0275
env0_second_0:                 episode reward: -5.5000,                 loss: nan
env1_first_0:                 episode reward: 10.3500,                 loss: nan
env1_second_0:                 episode reward: -10.3500,                 loss: nan
Episode: 241/10000 (2.4100%),                 avg. length: 1699.25,                last time consumption/overall running time: 835.2378s / 8750.5665 s
env0_first_0:                 episode reward: 14.3500,                 loss: 0.0282
env0_second_0:                 episode reward: -14.3500,                 loss: 0.0197
env1_first_0:                 episode reward: 23.1000,                 loss: nan
env1_second_0:                 episode reward: -23.1000,                 loss: nan
Score delta: 80.8, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/233_0.
Episode: 261/10000 (2.6100%),                 avg. length: 1204.25,                last time consumption/overall running time: 655.5931s / 9406.1596 s
env0_first_0:                 episode reward: -71.9500,                 loss: 0.0524
env0_second_0:                 episode reward: 71.9500,                 loss: 0.0303
env1_first_0:                 episode reward: -53.1000,                 loss: nan
env1_second_0:                 episode reward: 53.1000,                 loss: nan
Score delta: 140.6, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/254_1.
Episode: 281/10000 (2.8100%),                 avg. length: 1784.0,                last time consumption/overall running time: 796.7433s / 10202.9029 s
env0_first_0:                 episode reward: -10.2000,                 loss: 0.0568
env0_second_0:                 episode reward: 10.2000,                 loss: nan
env1_first_0:                 episode reward: -8.9000,                 loss: nan
env1_second_0:                 episode reward: 8.9000,                 loss: nan
Episode: 301/10000 (3.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 802.8725s / 11005.7754 s
env0_first_0:                 episode reward: 1.6500,                 loss: 0.0377
env0_second_0:                 episode reward: -1.6500,                 loss: nan
env1_first_0:                 episode reward: 3.1500,                 loss: nan
env1_second_0:                 episode reward: -3.1500,                 loss: nan
Episode: 321/10000 (3.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 799.6479s / 11805.4233 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0241
env0_second_0:                 episode reward: -0.8500,                 loss: nan
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 341/10000 (3.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 797.0006s / 12602.4239 s
env0_first_0:                 episode reward: 9.4500,                 loss: 0.0164
env0_second_0:                 episode reward: -9.4500,                 loss: nan
env1_first_0:                 episode reward: 13.5500,                 loss: nan
env1_second_0:                 episode reward: -13.5500,                 loss: nan
Episode: 361/10000 (3.6100%),                 avg. length: 1724.2,                last time consumption/overall running time: 887.9897s / 13490.4135 s
env0_first_0:                 episode reward: 32.9000,                 loss: 0.0255
env0_second_0:                 episode reward: -32.9000,                 loss: 0.0363
env1_first_0:                 episode reward: 35.4500,                 loss: nan
env1_second_0:                 episode reward: -35.4500,                 loss: nan
Score delta: 84.2, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/360_0.
Episode: 381/10000 (3.8100%),                 avg. length: 1091.7,                last time consumption/overall running time: 488.3141s / 13978.7276 s
env0_first_0:                 episode reward: 6.9500,                 loss: nan
env0_second_0:                 episode reward: -6.9500,                 loss: 0.0478
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 401/10000 (4.0100%),                 avg. length: 1337.05,                last time consumption/overall running time: 598.4720s / 14577.1996 s
env0_first_0:                 episode reward: -1.2000,                 loss: nan
env0_second_0:                 episode reward: 1.2000,                 loss: 0.0838
env1_first_0:                 episode reward: 4.2000,                 loss: nan
env1_second_0:                 episode reward: -4.2000,                 loss: nan
Episode: 421/10000 (4.2100%),                 avg. length: 1296.65,                last time consumption/overall running time: 735.0066s / 15312.2062 s
env0_first_0:                 episode reward: -21.2500,                 loss: 0.0407
env0_second_0:                 episode reward: 21.2500,                 loss: 0.1012
env1_first_0:                 episode reward: -10.9500,                 loss: nan
env1_second_0:                 episode reward: 10.9500,                 loss: nan
Score delta: 87.0, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/411_1.
Episode: 441/10000 (4.4100%),                 avg. length: 1471.85,                last time consumption/overall running time: 757.0558s / 16069.2620 s
env0_first_0:                 episode reward: 22.0000,                 loss: 0.0617
env0_second_0:                 episode reward: -22.0000,                 loss: 0.1365
env1_first_0:                 episode reward: 24.4500,                 loss: nan
env1_second_0:                 episode reward: -24.4500,                 loss: nan
Score delta: 121.4, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/432_0.
Episode: 461/10000 (4.6100%),                 avg. length: 1193.0,                last time consumption/overall running time: 728.5467s / 16797.8087 s
env0_first_0:                 episode reward: -54.7000,                 loss: 0.0830
env0_second_0:                 episode reward: 54.7000,                 loss: 0.1672
env1_first_0:                 episode reward: -42.7000,                 loss: nan
env1_second_0:                 episode reward: 42.7000,                 loss: nan
Score delta: 108.6, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/453_1.
Episode: 481/10000 (4.8100%),                 avg. length: 1779.25,                last time consumption/overall running time: 784.9037s / 17582.7124 s
env0_first_0:                 episode reward: -5.8500,                 loss: 0.0772
env0_second_0:                 episode reward: 5.8500,                 loss: nan
env1_first_0:                 episode reward: 2.1500,                 loss: nan
env1_second_0:                 episode reward: -2.1500,                 loss: nan
Episode: 501/10000 (5.0100%),                 avg. length: 1687.2,                last time consumption/overall running time: 752.4698s / 18335.1822 s
env0_first_0:                 episode reward: 32.8000,                 loss: 0.0595
env0_second_0:                 episode reward: -32.8000,                 loss: nan
env1_first_0:                 episode reward: 25.0500,                 loss: nan
env1_second_0:                 episode reward: -25.0500,                 loss: nan
Episode: 521/10000 (5.2100%),                 avg. length: 969.35,                last time consumption/overall running time: 612.7494s / 18947.9316 s
env0_first_0:                 episode reward: -25.1500,                 loss: 0.0643
env0_second_0:                 episode reward: 25.1500,                 loss: 0.2125
env1_first_0:                 episode reward: -27.7000,                 loss: nan
env1_second_0:                 episode reward: 27.7000,                 loss: nan
Score delta: 80.4, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/506_0.
Episode: 541/10000 (5.4100%),                 avg. length: 576.5,                last time consumption/overall running time: 492.8689s / 19440.8005 s
env0_first_0:                 episode reward: -63.1500,                 loss: 0.0678
env0_second_0:                 episode reward: 63.1500,                 loss: 0.2684
env1_first_0:                 episode reward: -73.7000,                 loss: nan
env1_second_0:                 episode reward: 73.7000,                 loss: nan
Score delta: 104.8, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/527_1.
Episode: 561/10000 (5.6100%),                 avg. length: 1696.85,                last time consumption/overall running time: 759.0588s / 20199.8593 s
env0_first_0:                 episode reward: -8.8000,                 loss: 0.0806
env0_second_0:                 episode reward: 8.8000,                 loss: nan
env1_first_0:                 episode reward: -14.0500,                 loss: nan
env1_second_0:                 episode reward: 14.0500,                 loss: nan
Episode: 581/10000 (5.8100%),                 avg. length: 1650.85,                last time consumption/overall running time: 963.9851s / 21163.8444 s
env0_first_0:                 episode reward: 23.7000,                 loss: 0.0529
env0_second_0:                 episode reward: -23.7000,                 loss: 0.2735
env1_first_0:                 episode reward: 22.4000,                 loss: nan
env1_second_0:                 episode reward: -22.4000,                 loss: nan
Score delta: 81.4, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/580_0.
Episode: 601/10000 (6.0100%),                 avg. length: 1376.6,                last time consumption/overall running time: 612.4909s / 21776.3353 s
env0_first_0:                 episode reward: -12.0500,                 loss: nan
env0_second_0:                 episode reward: 12.0500,                 loss: 0.2173
env1_first_0:                 episode reward: -7.8500,                 loss: nan
env1_second_0:                 episode reward: 7.8500,                 loss: nan
Episode: 621/10000 (6.2100%),                 avg. length: 1213.55,                last time consumption/overall running time: 814.0254s / 22590.3607 s
env0_first_0:                 episode reward: -27.1000,                 loss: 0.0500
env0_second_0:                 episode reward: 27.1000,                 loss: 0.1911
env1_first_0:                 episode reward: -33.9500,                 loss: nan
env1_second_0:                 episode reward: 33.9500,                 loss: nan
Score delta: 89.0, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/612_1.
Episode: 641/10000 (6.4100%),                 avg. length: 1069.5,                last time consumption/overall running time: 732.3616s / 23322.7223 s
env0_first_0:                 episode reward: 9.1000,                 loss: 0.0663
env0_second_0:                 episode reward: -9.1000,                 loss: 0.2085
env1_first_0:                 episode reward: 11.2000,                 loss: nan
env1_second_0:                 episode reward: -11.2000,                 loss: nan
Score delta: 87.4, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/633_0.
Episode: 661/10000 (6.6100%),                 avg. length: 1133.55,                last time consumption/overall running time: 506.8632s / 23829.5855 s
env0_first_0:                 episode reward: -18.6500,                 loss: nan
env0_second_0:                 episode reward: 18.6500,                 loss: 0.2164
env1_first_0:                 episode reward: -38.3500,                 loss: nan
env1_second_0:                 episode reward: 38.3500,                 loss: nan
Episode: 681/10000 (6.8100%),                 avg. length: 1233.5,                last time consumption/overall running time: 863.4936s / 24693.0791 s
env0_first_0:                 episode reward: -18.7000,                 loss: 0.0793
env0_second_0:                 episode reward: 18.7000,                 loss: 0.2739
env1_first_0:                 episode reward: -20.3500,                 loss: nan
env1_second_0:                 episode reward: 20.3500,                 loss: nan
Score delta: 96.6, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/667_1.
Episode: 701/10000 (7.0100%),                 avg. length: 1025.5,                last time consumption/overall running time: 727.2224s / 25420.3015 s
env0_first_0:                 episode reward: 19.5000,                 loss: 0.0934
env0_second_0:                 episode reward: -19.5000,                 loss: 0.2684
env1_first_0:                 episode reward: 17.5500,                 loss: nan
env1_second_0:                 episode reward: -17.5500,                 loss: nan
Score delta: 81.2, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/688_0.
Episode: 721/10000 (7.2100%),                 avg. length: 1218.45,                last time consumption/overall running time: 545.9053s / 25966.2068 s
env0_first_0:                 episode reward: -1.3000,                 loss: nan
env0_second_0:                 episode reward: 1.3000,                 loss: 0.2390
env1_first_0:                 episode reward: -12.5500,                 loss: nan
env1_second_0:                 episode reward: 12.5500,                 loss: nan
Episode: 741/10000 (7.4100%),                 avg. length: 1214.65,                last time consumption/overall running time: 539.4183s / 26505.6251 s
env0_first_0:                 episode reward: -5.1000,                 loss: nan
env0_second_0:                 episode reward: 5.1000,                 loss: 0.2577
env1_first_0:                 episode reward: 7.5000,                 loss: nan
env1_second_0:                 episode reward: -7.5000,                 loss: nan
Episode: 761/10000 (7.6100%),                 avg. length: 998.75,                last time consumption/overall running time: 796.6758s / 27302.3009 s
env0_first_0:                 episode reward: -58.7000,                 loss: 0.0839
env0_second_0:                 episode reward: 58.7000,                 loss: 0.2437
env1_first_0:                 episode reward: -47.4000,                 loss: nan
env1_second_0:                 episode reward: 47.4000,                 loss: nan
Score delta: 91.0, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/751_1.
Episode: 781/10000 (7.8100%),                 avg. length: 1031.95,                last time consumption/overall running time: 459.7833s / 27762.0842 s
env0_first_0:                 episode reward: -63.1500,                 loss: 0.1353
env0_second_0:                 episode reward: 63.1500,                 loss: nan
env1_first_0:                 episode reward: -71.6000,                 loss: nan
env1_second_0:                 episode reward: 71.6000,                 loss: nan
Episode: 801/10000 (8.0100%),                 avg. length: 919.95,                last time consumption/overall running time: 408.9818s / 28171.0661 s
env0_first_0:                 episode reward: -61.4500,                 loss: 0.1940
env0_second_0:                 episode reward: 61.4500,                 loss: nan
env1_first_0:                 episode reward: -33.5000,                 loss: nan
env1_second_0:                 episode reward: 33.5000,                 loss: nan
Episode: 821/10000 (8.2100%),                 avg. length: 1188.7,                last time consumption/overall running time: 529.1273s / 28700.1934 s
env0_first_0:                 episode reward: -8.8500,                 loss: 0.2206
env0_second_0:                 episode reward: 8.8500,                 loss: nan
env1_first_0:                 episode reward: -33.8500,                 loss: nan
env1_second_0:                 episode reward: 33.8500,                 loss: nan
Episode: 841/10000 (8.4100%),                 avg. length: 1260.2,                last time consumption/overall running time: 562.6978s / 29262.8912 s
env0_first_0:                 episode reward: 24.1000,                 loss: 0.2090
env0_second_0:                 episode reward: -24.1000,                 loss: nan
env1_first_0:                 episode reward: 18.8000,                 loss: nan
env1_second_0:                 episode reward: -18.8000,                 loss: nan
Episode: 861/10000 (8.6100%),                 avg. length: 911.05,                last time consumption/overall running time: 408.5457s / 29671.4369 s
env0_first_0:                 episode reward: 10.9000,                 loss: 0.1958
env0_second_0:                 episode reward: -10.9000,                 loss: nan
env1_first_0:                 episode reward: 15.5500,                 loss: nan
env1_second_0:                 episode reward: -15.5500,                 loss: nan
Episode: 881/10000 (8.8100%),                 avg. length: 799.8,                last time consumption/overall running time: 604.8609s / 30276.2978 s
env0_first_0:                 episode reward: 31.2500,                 loss: 0.2176
env0_second_0:                 episode reward: -31.2500,                 loss: 0.2614
env1_first_0:                 episode reward: 41.2000,                 loss: nan
env1_second_0:                 episode reward: -41.2000,                 loss: nan
Score delta: 99.0, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/879_0.
Episode: 901/10000 (9.0100%),                 avg. length: 929.6,                last time consumption/overall running time: 415.9843s / 30692.2821 s
env0_first_0:                 episode reward: -3.7000,                 loss: nan
env0_second_0:                 episode reward: 3.7000,                 loss: 0.2820
env1_first_0:                 episode reward: 12.9000,                 loss: nan
env1_second_0:                 episode reward: -12.9000,                 loss: nan
Episode: 921/10000 (9.2100%),                 avg. length: 900.65,                last time consumption/overall running time: 788.5506s / 31480.8327 s
env0_first_0:                 episode reward: -5.4500,                 loss: 0.2483
env0_second_0:                 episode reward: 5.4500,                 loss: 0.3078
env1_first_0:                 episode reward: 9.7000,                 loss: nan
env1_second_0:                 episode reward: -9.7000,                 loss: nan
Score delta: 84.6, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/908_1.
Episode: 941/10000 (9.4100%),                 avg. length: 762.15,                last time consumption/overall running time: 654.2219s / 32135.0546 s
env0_first_0:                 episode reward: 6.4000,                 loss: 0.2669
env0_second_0:                 episode reward: -6.4000,                 loss: 0.3391
env1_first_0:                 episode reward: -14.6500,                 loss: nan
env1_second_0:                 episode reward: 14.6500,                 loss: nan
Score delta: 81.0, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/935_0.
Episode: 961/10000 (9.6100%),                 avg. length: 493.2,                last time consumption/overall running time: 647.2315s / 32782.2861 s
env0_first_0:                 episode reward: -71.4500,                 loss: 0.0638
env0_second_0:                 episode reward: 71.4500,                 loss: 0.3516
env1_first_0:                 episode reward: -75.9000,                 loss: nan
env1_second_0:                 episode reward: 75.9000,                 loss: nan
Score delta: 122.0, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/956_1.
Episode: 981/10000 (9.8100%),                 avg. length: 632.7,                last time consumption/overall running time: 282.9105s / 33065.1966 s
env0_first_0:                 episode reward: -82.1000,                 loss: 0.1001
env0_second_0:                 episode reward: 82.1000,                 loss: nan
env1_first_0:                 episode reward: -84.6000,                 loss: nan
env1_second_0:                 episode reward: 84.6000,                 loss: nan
Episode: 1001/10000 (10.0100%),                 avg. length: 446.55,                last time consumption/overall running time: 197.3898s / 33262.5864 s
env0_first_0:                 episode reward: -86.1000,                 loss: 0.2224
env0_second_0:                 episode reward: 86.1000,                 loss: nan
env1_first_0:                 episode reward: -78.8500,                 loss: nan
env1_second_0:                 episode reward: 78.8500,                 loss: nan
Episode: 1021/10000 (10.2100%),                 avg. length: 429.2,                last time consumption/overall running time: 189.2890s / 33451.8755 s
env0_first_0:                 episode reward: -84.1000,                 loss: 0.2912
env0_second_0:                 episode reward: 84.1000,                 loss: nan
env1_first_0:                 episode reward: -86.8000,                 loss: nan
env1_second_0:                 episode reward: 86.8000,                 loss: nan
Episode: 1041/10000 (10.4100%),                 avg. length: 968.4,                last time consumption/overall running time: 430.9752s / 33882.8506 s
env0_first_0:                 episode reward: -53.7500,                 loss: 0.3430
env0_second_0:                 episode reward: 53.7500,                 loss: nan
env1_first_0:                 episode reward: -61.8000,                 loss: nan
env1_second_0:                 episode reward: 61.8000,                 loss: nan
Episode: 1061/10000 (10.6100%),                 avg. length: 1490.85,                last time consumption/overall running time: 673.3063s / 34556.1569 s
env0_first_0:                 episode reward: -33.6500,                 loss: 0.2288
env0_second_0:                 episode reward: 33.6500,                 loss: nan
env1_first_0:                 episode reward: -32.8000,                 loss: nan
env1_second_0:                 episode reward: 32.8000,                 loss: nan
Episode: 1081/10000 (10.8100%),                 avg. length: 1483.8,                last time consumption/overall running time: 662.4008s / 35218.5577 s
env0_first_0:                 episode reward: -15.8000,                 loss: 0.1099
env0_second_0:                 episode reward: 15.8000,                 loss: nan
env1_first_0:                 episode reward: -25.5000,                 loss: nan
env1_second_0:                 episode reward: 25.5000,                 loss: nan
Episode: 1101/10000 (11.0100%),                 avg. length: 1708.15,                last time consumption/overall running time: 758.1044s / 35976.6621 s
env0_first_0:                 episode reward: -8.3500,                 loss: 0.0577
env0_second_0:                 episode reward: 8.3500,                 loss: nan
env1_first_0:                 episode reward: -8.3000,                 loss: nan
env1_second_0:                 episode reward: 8.3000,                 loss: nan
Episode: 1121/10000 (11.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 799.4939s / 36776.1560 s
env0_first_0:                 episode reward: -4.1000,                 loss: 0.0070
env0_second_0:                 episode reward: 4.1000,                 loss: nan
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 1141/10000 (11.4100%),                 avg. length: 1553.25,                last time consumption/overall running time: 721.6423s / 37497.7984 s
env0_first_0:                 episode reward: -19.0500,                 loss: 0.0138
env0_second_0:                 episode reward: 19.0500,                 loss: nan
env1_first_0:                 episode reward: -30.9000,                 loss: nan
env1_second_0:                 episode reward: 30.9000,                 loss: nan
Episode: 1161/10000 (11.6100%),                 avg. length: 1742.65,                last time consumption/overall running time: 919.6725s / 38417.4708 s
env0_first_0:                 episode reward: -8.4000,                 loss: 0.0185
env0_second_0:                 episode reward: 8.4000,                 loss: nan
env1_first_0:                 episode reward: -2.3000,                 loss: nan
env1_second_0:                 episode reward: 2.3000,                 loss: nan
Episode: 1181/10000 (11.8100%),                 avg. length: 1709.6,                last time consumption/overall running time: 904.9699s / 39322.4408 s
env0_first_0:                 episode reward: -5.3500,                 loss: 0.0065
env0_second_0:                 episode reward: 5.3500,                 loss: nan
env1_first_0:                 episode reward: -5.3000,                 loss: nan
env1_second_0:                 episode reward: 5.3000,                 loss: nan
Episode: 1201/10000 (12.0100%),                 avg. length: 1633.1,                last time consumption/overall running time: 866.4422s / 40188.8829 s
env0_first_0:                 episode reward: -10.9000,                 loss: 0.0035
env0_second_0:                 episode reward: 10.9000,                 loss: nan
env1_first_0:                 episode reward: -5.1500,                 loss: nan
env1_second_0:                 episode reward: 5.1500,                 loss: nan
Episode: 1221/10000 (12.2100%),                 avg. length: 1576.55,                last time consumption/overall running time: 834.3224s / 41023.2053 s
env0_first_0:                 episode reward: -22.3500,                 loss: 0.0136
env0_second_0:                 episode reward: 22.3500,                 loss: nan
env1_first_0:                 episode reward: -20.9500,                 loss: nan
env1_second_0:                 episode reward: 20.9500,                 loss: nan
Episode: 1241/10000 (12.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 942.7049s / 41965.9103 s
env0_first_0:                 episode reward: -2.9000,                 loss: 0.0181
env0_second_0:                 episode reward: 2.9000,                 loss: nan
env1_first_0:                 episode reward: -7.0500,                 loss: nan
env1_second_0:                 episode reward: 7.0500,                 loss: nan
Episode: 1261/10000 (12.6100%),                 avg. length: 1676.25,                last time consumption/overall running time: 887.0096s / 42852.9198 s
env0_first_0:                 episode reward: -17.0500,                 loss: 0.0069
env0_second_0:                 episode reward: 17.0500,                 loss: nan
env1_first_0:                 episode reward: -10.7500,                 loss: nan
env1_second_0:                 episode reward: 10.7500,                 loss: nan
Episode: 1281/10000 (12.8100%),                 avg. length: 1619.4,                last time consumption/overall running time: 858.3682s / 43711.2880 s
env0_first_0:                 episode reward: -12.2000,                 loss: 0.0106
env0_second_0:                 episode reward: 12.2000,                 loss: nan
env1_first_0:                 episode reward: -22.0500,                 loss: nan
env1_second_0:                 episode reward: 22.0500,                 loss: nan
Episode: 1301/10000 (13.0100%),                 avg. length: 1579.2,                last time consumption/overall running time: 838.8871s / 44550.1751 s
env0_first_0:                 episode reward: -20.4000,                 loss: 0.0101
env0_second_0:                 episode reward: 20.4000,                 loss: nan
env1_first_0:                 episode reward: -11.9500,                 loss: nan
env1_second_0:                 episode reward: 11.9500,                 loss: nan
Episode: 1321/10000 (13.2100%),                 avg. length: 1175.25,                last time consumption/overall running time: 622.8632s / 45173.0383 s
env0_first_0:                 episode reward: -18.5000,                 loss: 0.0129
env0_second_0:                 episode reward: 18.5000,                 loss: nan
env1_first_0:                 episode reward: -36.8500,                 loss: nan
env1_second_0:                 episode reward: 36.8500,                 loss: nan
Episode: 1341/10000 (13.4100%),                 avg. length: 1538.1,                last time consumption/overall running time: 814.6392s / 45987.6775 s
env0_first_0:                 episode reward: -30.9500,                 loss: 0.0240
env0_second_0:                 episode reward: 30.9500,                 loss: nan
env1_first_0:                 episode reward: -6.2500,                 loss: nan
env1_second_0:                 episode reward: 6.2500,                 loss: nan
Episode: 1361/10000 (13.6100%),                 avg. length: 1465.3,                last time consumption/overall running time: 775.5960s / 46763.2736 s
env0_first_0:                 episode reward: -29.7000,                 loss: 0.0242
env0_second_0:                 episode reward: 29.7000,                 loss: nan
env1_first_0:                 episode reward: -28.8500,                 loss: nan
env1_second_0:                 episode reward: 28.8500,                 loss: nan
Episode: 1381/10000 (13.8100%),                 avg. length: 1410.5,                last time consumption/overall running time: 740.6656s / 47503.9392 s
env0_first_0:                 episode reward: -33.3000,                 loss: 0.0178
env0_second_0:                 episode reward: 33.3000,                 loss: nan
env1_first_0:                 episode reward: -12.5500,                 loss: nan
env1_second_0:                 episode reward: 12.5500,                 loss: nan
Episode: 1401/10000 (14.0100%),                 avg. length: 1361.1,                last time consumption/overall running time: 718.2319s / 48222.1711 s
env0_first_0:                 episode reward: -56.5000,                 loss: 0.0322
env0_second_0:                 episode reward: 56.5000,                 loss: nan
env1_first_0:                 episode reward: -47.8500,                 loss: nan
env1_second_0:                 episode reward: 47.8500,                 loss: nan
Episode: 1421/10000 (14.2100%),                 avg. length: 1514.2,                last time consumption/overall running time: 799.4066s / 49021.5777 s
env0_first_0:                 episode reward: -20.9000,                 loss: 0.0497
env0_second_0:                 episode reward: 20.9000,                 loss: nan
env1_first_0:                 episode reward: -22.6500,                 loss: nan
env1_second_0:                 episode reward: 22.6500,                 loss: nan
Episode: 1441/10000 (14.4100%),                 avg. length: 1464.7,                last time consumption/overall running time: 777.4308s / 49799.0085 s
env0_first_0:                 episode reward: -21.5000,                 loss: 0.0240
env0_second_0:                 episode reward: 21.5000,                 loss: nan
env1_first_0:                 episode reward: -23.3500,                 loss: nan
env1_second_0:                 episode reward: 23.3500,                 loss: nan
Episode: 1461/10000 (14.6100%),                 avg. length: 1508.1,                last time consumption/overall running time: 798.6737s / 50597.6822 s
env0_first_0:                 episode reward: -21.5000,                 loss: 0.0173
env0_second_0:                 episode reward: 21.5000,                 loss: nan
env1_first_0:                 episode reward: -16.3000,                 loss: nan
env1_second_0:                 episode reward: 16.3000,                 loss: nan
Episode: 1481/10000 (14.8100%),                 avg. length: 1362.6,                last time consumption/overall running time: 719.8631s / 51317.5454 s
env0_first_0:                 episode reward: -29.0000,                 loss: 0.0193
env0_second_0:                 episode reward: 29.0000,                 loss: nan
env1_first_0:                 episode reward: -35.5500,                 loss: nan
env1_second_0:                 episode reward: 35.5500,                 loss: nan
Episode: 1501/10000 (15.0100%),                 avg. length: 1530.4,                last time consumption/overall running time: 806.1183s / 52123.6637 s
env0_first_0:                 episode reward: -21.9000,                 loss: 0.0222
env0_second_0:                 episode reward: 21.9000,                 loss: nan
env1_first_0:                 episode reward: -32.4000,                 loss: nan
env1_second_0:                 episode reward: 32.4000,                 loss: nan
Episode: 1521/10000 (15.2100%),                 avg. length: 1344.6,                last time consumption/overall running time: 710.1501s / 52833.8137 s
env0_first_0:                 episode reward: -37.2500,                 loss: 0.0263
env0_second_0:                 episode reward: 37.2500,                 loss: nan
env1_first_0:                 episode reward: -31.8500,                 loss: nan
env1_second_0:                 episode reward: 31.8500,                 loss: nan
Episode: 1541/10000 (15.4100%),                 avg. length: 1463.7,                last time consumption/overall running time: 773.3395s / 53607.1532 s
env0_first_0:                 episode reward: -16.5000,                 loss: 0.0205
env0_second_0:                 episode reward: 16.5000,                 loss: nan
env1_first_0:                 episode reward: -25.5500,                 loss: nan
env1_second_0:                 episode reward: 25.5500,                 loss: nan
Episode: 1561/10000 (15.6100%),                 avg. length: 1108.85,                last time consumption/overall running time: 583.1382s / 54190.2914 s
env0_first_0:                 episode reward: -58.2000,                 loss: 0.0278
env0_second_0:                 episode reward: 58.2000,                 loss: nan
env1_first_0:                 episode reward: -49.8500,                 loss: nan
env1_second_0:                 episode reward: 49.8500,                 loss: nan
Episode: 1581/10000 (15.8100%),                 avg. length: 1335.5,                last time consumption/overall running time: 703.7072s / 54893.9986 s
env0_first_0:                 episode reward: -52.3000,                 loss: 0.0540
env0_second_0:                 episode reward: 52.3000,                 loss: nan
env1_first_0:                 episode reward: -42.2000,                 loss: nan
env1_second_0:                 episode reward: 42.2000,                 loss: nan
Episode: 1601/10000 (16.0100%),                 avg. length: 1274.65,                last time consumption/overall running time: 673.8432s / 55567.8418 s
env0_first_0:                 episode reward: -51.9000,                 loss: 0.0668
env0_second_0:                 episode reward: 51.9000,                 loss: nan
env1_first_0:                 episode reward: -42.7000,                 loss: nan
env1_second_0:                 episode reward: 42.7000,                 loss: nan
Episode: 1621/10000 (16.2100%),                 avg. length: 1353.9,                last time consumption/overall running time: 709.7248s / 56277.5666 s
env0_first_0:                 episode reward: -32.0500,                 loss: 0.0488
env0_second_0:                 episode reward: 32.0500,                 loss: nan
env1_first_0:                 episode reward: -29.2500,                 loss: nan
env1_second_0:                 episode reward: 29.2500,                 loss: nan
Episode: 1641/10000 (16.4100%),                 avg. length: 1417.95,                last time consumption/overall running time: 741.6966s / 57019.2632 s
env0_first_0:                 episode reward: -34.1500,                 loss: 0.0442
env0_second_0:                 episode reward: 34.1500,                 loss: nan
env1_first_0:                 episode reward: -37.8000,                 loss: nan
env1_second_0:                 episode reward: 37.8000,                 loss: nan
Episode: 1661/10000 (16.6100%),                 avg. length: 1284.0,                last time consumption/overall running time: 675.7293s / 57694.9925 s
env0_first_0:                 episode reward: -23.9000,                 loss: 0.0485
env0_second_0:                 episode reward: 23.9000,                 loss: nan
env1_first_0:                 episode reward: -38.8000,                 loss: nan
env1_second_0:                 episode reward: 38.8000,                 loss: nan
Episode: 1681/10000 (16.8100%),                 avg. length: 1399.05,                last time consumption/overall running time: 734.6767s / 58429.6692 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0545
env0_second_0:                 episode reward: 0.9500,                 loss: nan
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 1701/10000 (17.0100%),                 avg. length: 914.0,                last time consumption/overall running time: 809.0428s / 59238.7121 s
env0_first_0:                 episode reward: -9.0500,                 loss: 0.0562
env0_second_0:                 episode reward: 9.0500,                 loss: 0.3724
env1_first_0:                 episode reward: -42.0000,                 loss: nan
env1_second_0:                 episode reward: 42.0000,                 loss: nan
Score delta: 93.8, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/1693_0.
Episode: 1721/10000 (17.2100%),                 avg. length: 474.85,                last time consumption/overall running time: 789.8163s / 60028.5284 s
env0_first_0:                 episode reward: -71.3500,                 loss: 0.2297
env0_second_0:                 episode reward: 71.3500,                 loss: 0.4156
env1_first_0:                 episode reward: -60.2500,                 loss: nan
env1_second_0:                 episode reward: 60.2500,                 loss: nan
Score delta: 130.2, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/1714_1.
Episode: 1741/10000 (17.4100%),                 avg. length: 790.25,                last time consumption/overall running time: 412.1593s / 60440.6877 s
env0_first_0:                 episode reward: -62.1500,                 loss: 0.1425
env0_second_0:                 episode reward: 62.1500,                 loss: nan
env1_first_0:                 episode reward: -64.2000,                 loss: nan
env1_second_0:                 episode reward: 64.2000,                 loss: nan
Episode: 1761/10000 (17.6100%),                 avg. length: 662.2,                last time consumption/overall running time: 350.9356s / 60791.6233 s
env0_first_0:                 episode reward: -67.2500,                 loss: 0.1553
env0_second_0:                 episode reward: 67.2500,                 loss: nan
env1_first_0:                 episode reward: -68.1000,                 loss: nan
env1_second_0:                 episode reward: 68.1000,                 loss: nan
Episode: 1781/10000 (17.8100%),                 avg. length: 843.0,                last time consumption/overall running time: 447.8177s / 61239.4410 s
env0_first_0:                 episode reward: -67.9500,                 loss: 0.2104
env0_second_0:                 episode reward: 67.9500,                 loss: nan
env1_first_0:                 episode reward: -65.9500,                 loss: nan
env1_second_0:                 episode reward: 65.9500,                 loss: nan
Episode: 1801/10000 (18.0100%),                 avg. length: 909.35,                last time consumption/overall running time: 473.3677s / 61712.8087 s
env0_first_0:                 episode reward: -50.9500,                 loss: 0.2484
env0_second_0:                 episode reward: 50.9500,                 loss: nan
env1_first_0:                 episode reward: -48.2000,                 loss: nan
env1_second_0:                 episode reward: 48.2000,                 loss: nan
Episode: 1821/10000 (18.2100%),                 avg. length: 1046.15,                last time consumption/overall running time: 549.0227s / 62261.8314 s
env0_first_0:                 episode reward: -55.4000,                 loss: 0.2153
env0_second_0:                 episode reward: 55.4000,                 loss: nan
env1_first_0:                 episode reward: -47.6000,                 loss: nan
env1_second_0:                 episode reward: 47.6000,                 loss: nan
Episode: 1841/10000 (18.4100%),                 avg. length: 972.05,                last time consumption/overall running time: 509.5253s / 62771.3567 s
env0_first_0:                 episode reward: -40.7500,                 loss: 0.1627
env0_second_0:                 episode reward: 40.7500,                 loss: nan
env1_first_0:                 episode reward: -40.7500,                 loss: nan
env1_second_0:                 episode reward: 40.7500,                 loss: nan
Episode: 1861/10000 (18.6100%),                 avg. length: 1140.85,                last time consumption/overall running time: 603.7654s / 63375.1221 s
env0_first_0:                 episode reward: -35.1000,                 loss: 0.1824
env0_second_0:                 episode reward: 35.1000,                 loss: nan
env1_first_0:                 episode reward: -33.3500,                 loss: nan
env1_second_0:                 episode reward: 33.3500,                 loss: nan
Episode: 1881/10000 (18.8100%),                 avg. length: 921.1,                last time consumption/overall running time: 491.3917s / 63866.5139 s
env0_first_0:                 episode reward: -34.1500,                 loss: 0.2074
env0_second_0:                 episode reward: 34.1500,                 loss: nan
env1_first_0:                 episode reward: -50.6000,                 loss: nan
env1_second_0:                 episode reward: 50.6000,                 loss: nan
Episode: 1901/10000 (19.0100%),                 avg. length: 612.55,                last time consumption/overall running time: 326.3174s / 64192.8312 s
env0_first_0:                 episode reward: -38.1500,                 loss: 0.2337
env0_second_0:                 episode reward: 38.1500,                 loss: nan
env1_first_0:                 episode reward: -54.8500,                 loss: nan
env1_second_0:                 episode reward: 54.8500,                 loss: nan
Episode: 1921/10000 (19.2100%),                 avg. length: 1064.3,                last time consumption/overall running time: 562.7273s / 64755.5585 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2181
env0_second_0:                 episode reward: 0.2500,                 loss: nan
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 1941/10000 (19.4100%),                 avg. length: 576.4,                last time consumption/overall running time: 775.8142s / 65531.3727 s
env0_first_0:                 episode reward: -31.6000,                 loss: 0.2134
env0_second_0:                 episode reward: 31.6000,                 loss: 0.4348
env1_first_0:                 episode reward: -61.0500,                 loss: nan
env1_second_0:                 episode reward: 61.0500,                 loss: nan
Score delta: 95.4, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/1929_0.
Episode: 1961/10000 (19.6100%),                 avg. length: 512.6,                last time consumption/overall running time: 859.4786s / 66390.8514 s
env0_first_0:                 episode reward: -77.2500,                 loss: 0.0596
env0_second_0:                 episode reward: 77.2500,                 loss: 0.4402
env1_first_0:                 episode reward: -80.6500,                 loss: nan
env1_second_0:                 episode reward: 80.6500,                 loss: nan
Score delta: 160.4, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/1950_1.
Episode: 1981/10000 (19.8100%),                 avg. length: 593.2,                last time consumption/overall running time: 310.3853s / 66701.2367 s
env0_first_0:                 episode reward: -70.4000,                 loss: 0.0824
env0_second_0:                 episode reward: 70.4000,                 loss: nan
env1_first_0:                 episode reward: -75.6500,                 loss: nan
env1_second_0:                 episode reward: 75.6500,                 loss: nan
Episode: 2001/10000 (20.0100%),                 avg. length: 810.35,                last time consumption/overall running time: 422.7275s / 67123.9642 s
env0_first_0:                 episode reward: -43.9500,                 loss: 0.1175
env0_second_0:                 episode reward: 43.9500,                 loss: nan
env1_first_0:                 episode reward: -78.3500,                 loss: nan
env1_second_0:                 episode reward: 78.3500,                 loss: nan
Episode: 2021/10000 (20.2100%),                 avg. length: 703.3,                last time consumption/overall running time: 371.5971s / 67495.5612 s
env0_first_0:                 episode reward: -72.8000,                 loss: 0.1592
env0_second_0:                 episode reward: 72.8000,                 loss: nan
env1_first_0:                 episode reward: -68.7500,                 loss: nan
env1_second_0:                 episode reward: 68.7500,                 loss: nan
Episode: 2041/10000 (20.4100%),                 avg. length: 1066.05,                last time consumption/overall running time: 565.1290s / 68060.6903 s
env0_first_0:                 episode reward: -66.9000,                 loss: 0.1622
env0_second_0:                 episode reward: 66.9000,                 loss: nan
env1_first_0:                 episode reward: -61.1500,                 loss: nan
env1_second_0:                 episode reward: 61.1500,                 loss: nan
Episode: 2061/10000 (20.6100%),                 avg. length: 1079.45,                last time consumption/overall running time: 574.3070s / 68634.9973 s
env0_first_0:                 episode reward: -47.7500,                 loss: 0.1461
env0_second_0:                 episode reward: 47.7500,                 loss: nan
env1_first_0:                 episode reward: -55.8500,                 loss: nan
env1_second_0:                 episode reward: 55.8500,                 loss: nan
Episode: 2081/10000 (20.8100%),                 avg. length: 1090.5,                last time consumption/overall running time: 576.6618s / 69211.6591 s
env0_first_0:                 episode reward: -56.0000,                 loss: 0.1380
env0_second_0:                 episode reward: 56.0000,                 loss: nan
env1_first_0:                 episode reward: -52.5500,                 loss: nan
env1_second_0:                 episode reward: 52.5500,                 loss: nan
Episode: 2101/10000 (21.0100%),                 avg. length: 700.8,                last time consumption/overall running time: 370.5098s / 69582.1689 s
env0_first_0:                 episode reward: -62.3000,                 loss: 0.1413
env0_second_0:                 episode reward: 62.3000,                 loss: nan
env1_first_0:                 episode reward: -64.9500,                 loss: nan
env1_second_0:                 episode reward: 64.9500,                 loss: nan
Episode: 2121/10000 (21.2100%),                 avg. length: 805.9,                last time consumption/overall running time: 427.0549s / 70009.2238 s
env0_first_0:                 episode reward: -58.9500,                 loss: 0.1551
env0_second_0:                 episode reward: 58.9500,                 loss: nan
env1_first_0:                 episode reward: -67.9500,                 loss: nan
env1_second_0:                 episode reward: 67.9500,                 loss: nan
Episode: 2141/10000 (21.4100%),                 avg. length: 692.4,                last time consumption/overall running time: 367.8783s / 70377.1021 s
env0_first_0:                 episode reward: -74.8000,                 loss: 0.1823
env0_second_0:                 episode reward: 74.8000,                 loss: nan
env1_first_0:                 episode reward: -68.1000,                 loss: nan
env1_second_0:                 episode reward: 68.1000,                 loss: nan
Episode: 2161/10000 (21.6100%),                 avg. length: 710.65,                last time consumption/overall running time: 378.8068s / 70755.9088 s
env0_first_0:                 episode reward: -70.5000,                 loss: 0.2037
env0_second_0:                 episode reward: 70.5000,                 loss: nan
env1_first_0:                 episode reward: -62.3000,                 loss: nan
env1_second_0:                 episode reward: 62.3000,                 loss: nan
Episode: 2181/10000 (21.8100%),                 avg. length: 713.25,                last time consumption/overall running time: 375.0797s / 71130.9885 s
env0_first_0:                 episode reward: -69.6500,                 loss: 0.2118
env0_second_0:                 episode reward: 69.6500,                 loss: nan
env1_first_0:                 episode reward: -55.6500,                 loss: nan
env1_second_0:                 episode reward: 55.6500,                 loss: nan
Episode: 2201/10000 (22.0100%),                 avg. length: 723.6,                last time consumption/overall running time: 381.2116s / 71512.2001 s
env0_first_0:                 episode reward: -52.8500,                 loss: 0.2142
env0_second_0:                 episode reward: 52.8500,                 loss: nan
env1_first_0:                 episode reward: -70.1000,                 loss: nan
env1_second_0:                 episode reward: 70.1000,                 loss: nan
Episode: 2221/10000 (22.2100%),                 avg. length: 785.25,                last time consumption/overall running time: 409.5030s / 71921.7032 s
env0_first_0:                 episode reward: -51.7000,                 loss: 0.2158
env0_second_0:                 episode reward: 51.7000,                 loss: nan
env1_first_0:                 episode reward: -64.4000,                 loss: nan
env1_second_0:                 episode reward: 64.4000,                 loss: nan
Episode: 2241/10000 (22.4100%),                 avg. length: 987.6,                last time consumption/overall running time: 510.6208s / 72432.3240 s
env0_first_0:                 episode reward: -46.1500,                 loss: 0.2373
env0_second_0:                 episode reward: 46.1500,                 loss: nan
env1_first_0:                 episode reward: -49.8000,                 loss: nan
env1_second_0:                 episode reward: 49.8000,                 loss: nan
Episode: 2261/10000 (22.6100%),                 avg. length: 970.6,                last time consumption/overall running time: 508.9156s / 72941.2396 s
env0_first_0:                 episode reward: -55.6000,                 loss: 0.2388
env0_second_0:                 episode reward: 55.6000,                 loss: nan
env1_first_0:                 episode reward: -45.4000,                 loss: nan
env1_second_0:                 episode reward: 45.4000,                 loss: nan
Episode: 2281/10000 (22.8100%),                 avg. length: 866.25,                last time consumption/overall running time: 451.6711s / 73392.9107 s
env0_first_0:                 episode reward: -59.0500,                 loss: 0.2247
env0_second_0:                 episode reward: 59.0500,                 loss: nan
env1_first_0:                 episode reward: -43.6500,                 loss: nan
env1_second_0:                 episode reward: 43.6500,                 loss: nan
Episode: 2301/10000 (23.0100%),                 avg. length: 933.35,                last time consumption/overall running time: 485.8455s / 73878.7562 s
env0_first_0:                 episode reward: -57.9000,                 loss: 0.2012
env0_second_0:                 episode reward: 57.9000,                 loss: nan
env1_first_0:                 episode reward: -46.7500,                 loss: nan
env1_second_0:                 episode reward: 46.7500,                 loss: nan
Episode: 2321/10000 (23.2100%),                 avg. length: 797.1,                last time consumption/overall running time: 415.5032s / 74294.2594 s
env0_first_0:                 episode reward: -46.6000,                 loss: 0.1904
env0_second_0:                 episode reward: 46.6000,                 loss: nan
env1_first_0:                 episode reward: -55.7000,                 loss: nan
env1_second_0:                 episode reward: 55.7000,                 loss: nan
Episode: 2341/10000 (23.4100%),                 avg. length: 788.05,                last time consumption/overall running time: 417.9657s / 74712.2251 s
env0_first_0:                 episode reward: -48.9500,                 loss: 0.2121
env0_second_0:                 episode reward: 48.9500,                 loss: nan
env1_first_0:                 episode reward: -56.0000,                 loss: nan
env1_second_0:                 episode reward: 56.0000,                 loss: nan
Episode: 2361/10000 (23.6100%),                 avg. length: 828.25,                last time consumption/overall running time: 440.5655s / 75152.7906 s
env0_first_0:                 episode reward: -46.4000,                 loss: 0.2407
env0_second_0:                 episode reward: 46.4000,                 loss: nan
env1_first_0:                 episode reward: -54.3000,                 loss: nan
env1_second_0:                 episode reward: 54.3000,                 loss: nan
Episode: 2381/10000 (23.8100%),                 avg. length: 739.45,                last time consumption/overall running time: 392.7957s / 75545.5862 s
env0_first_0:                 episode reward: -30.6500,                 loss: 0.2717
env0_second_0:                 episode reward: 30.6500,                 loss: nan
env1_first_0:                 episode reward: -46.5000,                 loss: nan
env1_second_0:                 episode reward: 46.5000,                 loss: nan
Episode: 2401/10000 (24.0100%),                 avg. length: 837.35,                last time consumption/overall running time: 444.6971s / 75990.2834 s
env0_first_0:                 episode reward: -41.7000,                 loss: 0.2637
env0_second_0:                 episode reward: 41.7000,                 loss: nan
env1_first_0:                 episode reward: -36.6500,                 loss: nan
env1_second_0:                 episode reward: 36.6500,                 loss: nan
Episode: 2421/10000 (24.2100%),                 avg. length: 740.9,                last time consumption/overall running time: 392.2014s / 76382.4848 s
env0_first_0:                 episode reward: -50.5000,                 loss: 0.2661
env0_second_0:                 episode reward: 50.5000,                 loss: nan
env1_first_0:                 episode reward: -57.8500,                 loss: nan
env1_second_0:                 episode reward: 57.8500,                 loss: nan
Episode: 2441/10000 (24.4100%),                 avg. length: 742.15,                last time consumption/overall running time: 394.0519s / 76776.5367 s
env0_first_0:                 episode reward: -51.4000,                 loss: 0.2860
env0_second_0:                 episode reward: 51.4000,                 loss: nan
env1_first_0:                 episode reward: -40.7000,                 loss: nan
env1_second_0:                 episode reward: 40.7000,                 loss: nan
Episode: 2461/10000 (24.6100%),                 avg. length: 767.75,                last time consumption/overall running time: 402.8609s / 77179.3975 s
env0_first_0:                 episode reward: -45.7500,                 loss: 0.2898
env0_second_0:                 episode reward: 45.7500,                 loss: nan
env1_first_0:                 episode reward: -47.9500,                 loss: nan
env1_second_0:                 episode reward: 47.9500,                 loss: nan
Episode: 2481/10000 (24.8100%),                 avg. length: 861.45,                last time consumption/overall running time: 454.5594s / 77633.9570 s
env0_first_0:                 episode reward: -51.0500,                 loss: 0.2924
env0_second_0:                 episode reward: 51.0500,                 loss: nan
env1_first_0:                 episode reward: -54.0000,                 loss: nan
env1_second_0:                 episode reward: 54.0000,                 loss: nan
Episode: 2501/10000 (25.0100%),                 avg. length: 785.95,                last time consumption/overall running time: 416.6231s / 78050.5801 s
env0_first_0:                 episode reward: -39.3000,                 loss: 0.3089
env0_second_0:                 episode reward: 39.3000,                 loss: nan
env1_first_0:                 episode reward: -49.7500,                 loss: nan
env1_second_0:                 episode reward: 49.7500,                 loss: nan
Episode: 2521/10000 (25.2100%),                 avg. length: 755.8,                last time consumption/overall running time: 396.5500s / 78447.1301 s
env0_first_0:                 episode reward: -29.3000,                 loss: 0.2997
env0_second_0:                 episode reward: 29.3000,                 loss: nan
env1_first_0:                 episode reward: -39.1500,                 loss: nan
env1_second_0:                 episode reward: 39.1500,                 loss: nan
Episode: 2541/10000 (25.4100%),                 avg. length: 901.7,                last time consumption/overall running time: 476.1254s / 78923.2555 s
env0_first_0:                 episode reward: -28.0500,                 loss: 0.3197
env0_second_0:                 episode reward: 28.0500,                 loss: nan
env1_first_0:                 episode reward: -34.6500,                 loss: nan
env1_second_0:                 episode reward: 34.6500,                 loss: nan
Episode: 2561/10000 (25.6100%),                 avg. length: 762.1,                last time consumption/overall running time: 403.8783s / 79327.1339 s
env0_first_0:                 episode reward: -34.4000,                 loss: 0.3012
env0_second_0:                 episode reward: 34.4000,                 loss: nan
env1_first_0:                 episode reward: -39.1000,                 loss: nan
env1_second_0:                 episode reward: 39.1000,                 loss: nan
Episode: 2581/10000 (25.8100%),                 avg. length: 881.4,                last time consumption/overall running time: 460.5476s / 79787.6815 s
env0_first_0:                 episode reward: -30.6000,                 loss: 0.2610
env0_second_0:                 episode reward: 30.6000,                 loss: nan
env1_first_0:                 episode reward: -18.6000,                 loss: nan
env1_second_0:                 episode reward: 18.6000,                 loss: nan
Episode: 2601/10000 (26.0100%),                 avg. length: 710.45,                last time consumption/overall running time: 375.7698s / 80163.4513 s
env0_first_0:                 episode reward: -32.4000,                 loss: 0.2369
env0_second_0:                 episode reward: 32.4000,                 loss: nan
env1_first_0:                 episode reward: -33.7500,                 loss: nan
env1_second_0:                 episode reward: 33.7500,                 loss: nan
Episode: 2621/10000 (26.2100%),                 avg. length: 636.85,                last time consumption/overall running time: 338.8789s / 80502.3303 s
env0_first_0:                 episode reward: -39.8500,                 loss: 0.2415
env0_second_0:                 episode reward: 39.8500,                 loss: nan
env1_first_0:                 episode reward: -36.9500,                 loss: nan
env1_second_0:                 episode reward: 36.9500,                 loss: nan
Episode: 2641/10000 (26.4100%),                 avg. length: 629.6,                last time consumption/overall running time: 334.6143s / 80836.9445 s
env0_first_0:                 episode reward: -47.0000,                 loss: 0.2493
env0_second_0:                 episode reward: 47.0000,                 loss: nan
env1_first_0:                 episode reward: -57.0500,                 loss: nan
env1_second_0:                 episode reward: 57.0500,                 loss: nan
Episode: 2661/10000 (26.6100%),                 avg. length: 677.35,                last time consumption/overall running time: 357.3677s / 81194.3122 s
env0_first_0:                 episode reward: -37.8500,                 loss: 0.2603
env0_second_0:                 episode reward: 37.8500,                 loss: nan
env1_first_0:                 episode reward: -47.7000,                 loss: nan
env1_second_0:                 episode reward: 47.7000,                 loss: nan
Episode: 2681/10000 (26.8100%),                 avg. length: 645.6,                last time consumption/overall running time: 341.0634s / 81535.3756 s
env0_first_0:                 episode reward: -48.1000,                 loss: 0.2682
env0_second_0:                 episode reward: 48.1000,                 loss: nan
env1_first_0:                 episode reward: -33.7500,                 loss: nan
env1_second_0:                 episode reward: 33.7500,                 loss: nan
Episode: 2701/10000 (27.0100%),                 avg. length: 820.95,                last time consumption/overall running time: 428.9619s / 81964.3375 s
env0_first_0:                 episode reward: -31.4000,                 loss: 0.2645
env0_second_0:                 episode reward: 31.4000,                 loss: nan
env1_first_0:                 episode reward: -20.1000,                 loss: nan
env1_second_0:                 episode reward: 20.1000,                 loss: nan
Episode: 2721/10000 (27.2100%),                 avg. length: 677.65,                last time consumption/overall running time: 354.0941s / 82318.4316 s
env0_first_0:                 episode reward: -40.3000,                 loss: 0.2458
env0_second_0:                 episode reward: 40.3000,                 loss: nan
env1_first_0:                 episode reward: -35.1500,                 loss: nan
env1_second_0:                 episode reward: 35.1500,                 loss: nan
Episode: 2741/10000 (27.4100%),                 avg. length: 513.65,                last time consumption/overall running time: 271.7864s / 82590.2180 s
env0_first_0:                 episode reward: -58.4000,                 loss: 0.2918
env0_second_0:                 episode reward: 58.4000,                 loss: nan
env1_first_0:                 episode reward: -51.4000,                 loss: nan
env1_second_0:                 episode reward: 51.4000,                 loss: nan
Episode: 2761/10000 (27.6100%),                 avg. length: 672.7,                last time consumption/overall running time: 357.3885s / 82947.6065 s
env0_first_0:                 episode reward: -46.0000,                 loss: 0.2934
env0_second_0:                 episode reward: 46.0000,                 loss: nan
env1_first_0:                 episode reward: -38.7500,                 loss: nan
env1_second_0:                 episode reward: 38.7500,                 loss: nan
Episode: 2781/10000 (27.8100%),                 avg. length: 879.2,                last time consumption/overall running time: 464.4785s / 83412.0850 s
env0_first_0:                 episode reward: -15.3500,                 loss: 0.3011
env0_second_0:                 episode reward: 15.3500,                 loss: nan
env1_first_0:                 episode reward: -28.0000,                 loss: nan
env1_second_0:                 episode reward: 28.0000,                 loss: nan
Episode: 2801/10000 (28.0100%),                 avg. length: 674.75,                last time consumption/overall running time: 355.2943s / 83767.3793 s
env0_first_0:                 episode reward: -50.6000,                 loss: 0.3144
env0_second_0:                 episode reward: 50.6000,                 loss: nan
env1_first_0:                 episode reward: -51.9500,                 loss: nan
env1_second_0:                 episode reward: 51.9500,                 loss: nan
Episode: 2821/10000 (28.2100%),                 avg. length: 893.35,                last time consumption/overall running time: 466.5477s / 84233.9270 s
env0_first_0:                 episode reward: 3.1000,                 loss: 0.3005
env0_second_0:                 episode reward: -3.1000,                 loss: nan
env1_first_0:                 episode reward: -18.8500,                 loss: nan
env1_second_0:                 episode reward: 18.8500,                 loss: nan
Episode: 2841/10000 (28.4100%),                 avg. length: 666.95,                last time consumption/overall running time: 347.0361s / 84580.9632 s
env0_first_0:                 episode reward: -31.5500,                 loss: 0.2851
env0_second_0:                 episode reward: 31.5500,                 loss: nan
env1_first_0:                 episode reward: -36.9500,                 loss: nan
env1_second_0:                 episode reward: 36.9500,                 loss: nan
Episode: 2861/10000 (28.6100%),                 avg. length: 721.95,                last time consumption/overall running time: 374.6984s / 84955.6616 s
env0_first_0:                 episode reward: -43.6000,                 loss: 0.3378
env0_second_0:                 episode reward: 43.6000,                 loss: nan
env1_first_0:                 episode reward: -35.1000,                 loss: nan
env1_second_0:                 episode reward: 35.1000,                 loss: nan
Episode: 2881/10000 (28.8100%),                 avg. length: 794.25,                last time consumption/overall running time: 415.6658s / 85371.3274 s
env0_first_0:                 episode reward: -23.1000,                 loss: 0.2970
env0_second_0:                 episode reward: 23.1000,                 loss: nan
env1_first_0:                 episode reward: -25.1000,                 loss: nan
env1_second_0:                 episode reward: 25.1000,                 loss: nan
Episode: 2901/10000 (29.0100%),                 avg. length: 674.65,                last time consumption/overall running time: 356.0725s / 85727.3999 s
env0_first_0:                 episode reward: -24.0000,                 loss: 0.3526
env0_second_0:                 episode reward: 24.0000,                 loss: nan
env1_first_0:                 episode reward: -42.1000,                 loss: nan
env1_second_0:                 episode reward: 42.1000,                 loss: nan
Episode: 2921/10000 (29.2100%),                 avg. length: 756.1,                last time consumption/overall running time: 401.5015s / 86128.9014 s
env0_first_0:                 episode reward: -19.7500,                 loss: 0.3764
env0_second_0:                 episode reward: 19.7500,                 loss: nan
env1_first_0:                 episode reward: -26.4000,                 loss: nan
env1_second_0:                 episode reward: 26.4000,                 loss: nan
Episode: 2941/10000 (29.4100%),                 avg. length: 708.2,                last time consumption/overall running time: 377.5902s / 86506.4916 s
env0_first_0:                 episode reward: -19.7500,                 loss: 0.4015
env0_second_0:                 episode reward: 19.7500,                 loss: nan
env1_first_0:                 episode reward: -27.1500,                 loss: nan
env1_second_0:                 episode reward: 27.1500,                 loss: nan
Episode: 2961/10000 (29.6100%),                 avg. length: 696.35,                last time consumption/overall running time: 369.5251s / 86876.0167 s
env0_first_0:                 episode reward: -35.7500,                 loss: 0.4154
env0_second_0:                 episode reward: 35.7500,                 loss: nan
env1_first_0:                 episode reward: -41.3500,                 loss: nan
env1_second_0:                 episode reward: 41.3500,                 loss: nan
Episode: 2981/10000 (29.8100%),                 avg. length: 622.35,                last time consumption/overall running time: 329.1077s / 87205.1244 s
env0_first_0:                 episode reward: -49.5500,                 loss: 0.4131
env0_second_0:                 episode reward: 49.5500,                 loss: nan
env1_first_0:                 episode reward: -56.4500,                 loss: nan
env1_second_0:                 episode reward: 56.4500,                 loss: nan
Episode: 3001/10000 (30.0100%),                 avg. length: 712.45,                last time consumption/overall running time: 378.6950s / 87583.8194 s
env0_first_0:                 episode reward: -18.4000,                 loss: 0.3931
env0_second_0:                 episode reward: 18.4000,                 loss: nan
env1_first_0:                 episode reward: -13.2500,                 loss: nan
env1_second_0:                 episode reward: 13.2500,                 loss: nan
Episode: 3021/10000 (30.2100%),                 avg. length: 731.95,                last time consumption/overall running time: 389.0757s / 87972.8951 s
env0_first_0:                 episode reward: -29.9500,                 loss: 0.3822
env0_second_0:                 episode reward: 29.9500,                 loss: nan
env1_first_0:                 episode reward: -38.9000,                 loss: nan
env1_second_0:                 episode reward: 38.9000,                 loss: nan
Episode: 3041/10000 (30.4100%),                 avg. length: 738.95,                last time consumption/overall running time: 392.3289s / 88365.2239 s
env0_first_0:                 episode reward: -40.5500,                 loss: 0.3740
env0_second_0:                 episode reward: 40.5500,                 loss: nan
env1_first_0:                 episode reward: -16.0500,                 loss: nan
env1_second_0:                 episode reward: 16.0500,                 loss: nan
Episode: 3061/10000 (30.6100%),                 avg. length: 687.9,                last time consumption/overall running time: 364.0876s / 88729.3115 s
env0_first_0:                 episode reward: -13.6000,                 loss: 0.3618
env0_second_0:                 episode reward: 13.6000,                 loss: nan
env1_first_0:                 episode reward: -25.9500,                 loss: nan
env1_second_0:                 episode reward: 25.9500,                 loss: nan
Episode: 3081/10000 (30.8100%),                 avg. length: 790.95,                last time consumption/overall running time: 418.0247s / 89147.3362 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.3458
env0_second_0:                 episode reward: 1.0500,                 loss: nan
env1_first_0:                 episode reward: -23.2000,                 loss: nan
env1_second_0:                 episode reward: 23.2000,                 loss: nan
Episode: 3101/10000 (31.0100%),                 avg. length: 685.55,                last time consumption/overall running time: 362.1951s / 89509.5314 s
env0_first_0:                 episode reward: -22.6000,                 loss: 0.3641
env0_second_0:                 episode reward: 22.6000,                 loss: nan
env1_first_0:                 episode reward: -32.5500,                 loss: nan
env1_second_0:                 episode reward: 32.5500,                 loss: nan
Episode: 3121/10000 (31.2100%),                 avg. length: 743.2,                last time consumption/overall running time: 392.9406s / 89902.4719 s
env0_first_0:                 episode reward: -16.5500,                 loss: 0.3629
env0_second_0:                 episode reward: 16.5500,                 loss: nan
env1_first_0:                 episode reward: -22.7500,                 loss: nan
env1_second_0:                 episode reward: 22.7500,                 loss: nan
Episode: 3141/10000 (31.4100%),                 avg. length: 632.75,                last time consumption/overall running time: 333.9916s / 90236.4635 s
env0_first_0:                 episode reward: -40.2500,                 loss: 0.3882
env0_second_0:                 episode reward: 40.2500,                 loss: nan
env1_first_0:                 episode reward: -36.6500,                 loss: nan
env1_second_0:                 episode reward: 36.6500,                 loss: nan
Episode: 3161/10000 (31.6100%),                 avg. length: 658.4,                last time consumption/overall running time: 346.6005s / 90583.0641 s
env0_first_0:                 episode reward: -22.8000,                 loss: 0.4253
env0_second_0:                 episode reward: 22.8000,                 loss: nan
env1_first_0:                 episode reward: -22.3500,                 loss: nan
env1_second_0:                 episode reward: 22.3500,                 loss: nan
Episode: 3181/10000 (31.8100%),                 avg. length: 821.15,                last time consumption/overall running time: 428.3722s / 91011.4362 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.4159
env0_second_0:                 episode reward: -0.2500,                 loss: nan
env1_first_0:                 episode reward: -16.2500,                 loss: nan
env1_second_0:                 episode reward: 16.2500,                 loss: nan
Episode: 3201/10000 (32.0100%),                 avg. length: 637.55,                last time consumption/overall running time: 332.7084s / 91344.1446 s
env0_first_0:                 episode reward: -30.8000,                 loss: 0.3845
env0_second_0:                 episode reward: 30.8000,                 loss: nan
env1_first_0:                 episode reward: -24.8000,                 loss: nan
env1_second_0:                 episode reward: 24.8000,                 loss: nan
Episode: 3221/10000 (32.2100%),                 avg. length: 597.35,                last time consumption/overall running time: 314.2982s / 91658.4428 s
env0_first_0:                 episode reward: -29.2500,                 loss: 0.4122
env0_second_0:                 episode reward: 29.2500,                 loss: nan
env1_first_0:                 episode reward: -42.3000,                 loss: nan
env1_second_0:                 episode reward: 42.3000,                 loss: nan
Episode: 3241/10000 (32.4100%),                 avg. length: 693.1,                last time consumption/overall running time: 367.2005s / 92025.6434 s
env0_first_0:                 episode reward: -27.7500,                 loss: 0.4436
env0_second_0:                 episode reward: 27.7500,                 loss: nan
env1_first_0:                 episode reward: -24.8000,                 loss: nan
env1_second_0:                 episode reward: 24.8000,                 loss: nan
Episode: 3261/10000 (32.6100%),                 avg. length: 590.6,                last time consumption/overall running time: 312.3996s / 92338.0429 s
env0_first_0:                 episode reward: -35.9500,                 loss: 0.4832
env0_second_0:                 episode reward: 35.9500,                 loss: nan
env1_first_0:                 episode reward: -45.8500,                 loss: nan
env1_second_0:                 episode reward: 45.8500,                 loss: nan
Episode: 3281/10000 (32.8100%),                 avg. length: 843.1,                last time consumption/overall running time: 443.6524s / 92781.6953 s
env0_first_0:                 episode reward: -22.3500,                 loss: 0.5033
env0_second_0:                 episode reward: 22.3500,                 loss: nan
env1_first_0:                 episode reward: -18.9500,                 loss: nan
env1_second_0:                 episode reward: 18.9500,                 loss: nan
Episode: 3301/10000 (33.0100%),                 avg. length: 765.8,                last time consumption/overall running time: 405.1305s / 93186.8258 s
env0_first_0:                 episode reward: -16.7000,                 loss: 0.4632
env0_second_0:                 episode reward: 16.7000,                 loss: nan
env1_first_0:                 episode reward: -20.4500,                 loss: nan
env1_second_0:                 episode reward: 20.4500,                 loss: nan
Episode: 3321/10000 (33.2100%),                 avg. length: 645.8,                last time consumption/overall running time: 342.2173s / 93529.0431 s
env0_first_0:                 episode reward: -34.1000,                 loss: 0.4263
env0_second_0:                 episode reward: 34.1000,                 loss: nan
env1_first_0:                 episode reward: -4.3000,                 loss: nan
env1_second_0:                 episode reward: 4.3000,                 loss: nan
Episode: 3341/10000 (33.4100%),                 avg. length: 692.25,                last time consumption/overall running time: 368.7865s / 93897.8296 s
env0_first_0:                 episode reward: -20.5500,                 loss: 0.4207
env0_second_0:                 episode reward: 20.5500,                 loss: nan
env1_first_0:                 episode reward: -12.4000,                 loss: nan
env1_second_0:                 episode reward: 12.4000,                 loss: nan
Episode: 3361/10000 (33.6100%),                 avg. length: 677.4,                last time consumption/overall running time: 362.0237s / 94259.8533 s
env0_first_0:                 episode reward: -23.4500,                 loss: 0.4158
env0_second_0:                 episode reward: 23.4500,                 loss: nan
env1_first_0:                 episode reward: -12.5000,                 loss: nan
env1_second_0:                 episode reward: 12.5000,                 loss: nan
Episode: 3381/10000 (33.8100%),                 avg. length: 724.9,                last time consumption/overall running time: 386.6335s / 94646.4868 s
env0_first_0:                 episode reward: -15.2500,                 loss: 0.4172
env0_second_0:                 episode reward: 15.2500,                 loss: nan
env1_first_0:                 episode reward: -29.0500,                 loss: nan
env1_second_0:                 episode reward: 29.0500,                 loss: nan
Episode: 3401/10000 (34.0100%),                 avg. length: 676.55,                last time consumption/overall running time: 359.5097s / 95005.9966 s
env0_first_0:                 episode reward: -43.0500,                 loss: 0.4059
env0_second_0:                 episode reward: 43.0500,                 loss: nan
env1_first_0:                 episode reward: -19.6000,                 loss: nan
env1_second_0:                 episode reward: 19.6000,                 loss: nan
Episode: 3421/10000 (34.2100%),                 avg. length: 714.1,                last time consumption/overall running time: 379.3457s / 95385.3423 s
env0_first_0:                 episode reward: -10.9000,                 loss: 0.4188
env0_second_0:                 episode reward: 10.9000,                 loss: nan
env1_first_0:                 episode reward: -14.9500,                 loss: nan
env1_second_0:                 episode reward: 14.9500,                 loss: nan
Episode: 3441/10000 (34.4100%),                 avg. length: 714.2,                last time consumption/overall running time: 375.8509s / 95761.1932 s
env0_first_0:                 episode reward: -10.4500,                 loss: 0.4090
env0_second_0:                 episode reward: 10.4500,                 loss: nan
env1_first_0:                 episode reward: -19.3500,                 loss: nan
env1_second_0:                 episode reward: 19.3500,                 loss: nan
Episode: 3461/10000 (34.6100%),                 avg. length: 718.6,                last time consumption/overall running time: 378.0296s / 96139.2228 s
env0_first_0:                 episode reward: -7.6000,                 loss: 0.4535
env0_second_0:                 episode reward: 7.6000,                 loss: nan
env1_first_0:                 episode reward: -39.2000,                 loss: nan
env1_second_0:                 episode reward: 39.2000,                 loss: nan
Episode: 3481/10000 (34.8100%),                 avg. length: 894.5,                last time consumption/overall running time: 470.3595s / 96609.5822 s
env0_first_0:                 episode reward: 9.8500,                 loss: 0.4290
env0_second_0:                 episode reward: -9.8500,                 loss: nan
env1_first_0:                 episode reward: 10.5000,                 loss: nan
env1_second_0:                 episode reward: -10.5000,                 loss: nan
Episode: 3501/10000 (35.0100%),                 avg. length: 693.2,                last time consumption/overall running time: 822.2075s / 97431.7898 s
env0_first_0:                 episode reward: -6.2500,                 loss: 0.4002
env0_second_0:                 episode reward: 6.2500,                 loss: 0.4472
env1_first_0:                 episode reward: -24.6500,                 loss: nan
env1_second_0:                 episode reward: 24.6500,                 loss: nan
Score delta: 85.4, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/3497_0.
Episode: 3521/10000 (35.2100%),                 avg. length: 365.7,                last time consumption/overall running time: 821.6581s / 98253.4478 s
env0_first_0:                 episode reward: -76.0500,                 loss: 0.2394
env0_second_0:                 episode reward: 76.0500,                 loss: 0.4585
env1_first_0:                 episode reward: -75.6500,                 loss: nan
env1_second_0:                 episode reward: 75.6500,                 loss: nan
Score delta: 178.0, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/3518_1.
Episode: 3541/10000 (35.4100%),                 avg. length: 294.1,                last time consumption/overall running time: 153.4378s / 98406.8857 s
env0_first_0:                 episode reward: -83.1000,                 loss: 0.2250
env0_second_0:                 episode reward: 83.1000,                 loss: nan
env1_first_0:                 episode reward: -84.9000,                 loss: nan
env1_second_0:                 episode reward: 84.9000,                 loss: nan
Episode: 3561/10000 (35.6100%),                 avg. length: 323.9,                last time consumption/overall running time: 168.4189s / 98575.3046 s
env0_first_0:                 episode reward: -78.7000,                 loss: 0.1966
env0_second_0:                 episode reward: 78.7000,                 loss: nan
env1_first_0:                 episode reward: -80.1500,                 loss: nan
env1_second_0:                 episode reward: 80.1500,                 loss: nan
Episode: 3581/10000 (35.8100%),                 avg. length: 417.5,                last time consumption/overall running time: 217.5317s / 98792.8363 s
env0_first_0:                 episode reward: -71.2500,                 loss: 0.2300
env0_second_0:                 episode reward: 71.2500,                 loss: nan
env1_first_0:                 episode reward: -76.9500,                 loss: nan
env1_second_0:                 episode reward: 76.9500,                 loss: nan
Episode: 3601/10000 (36.0100%),                 avg. length: 347.4,                last time consumption/overall running time: 181.6738s / 98974.5101 s
env0_first_0:                 episode reward: -74.4500,                 loss: 0.2804
env0_second_0:                 episode reward: 74.4500,                 loss: nan
env1_first_0:                 episode reward: -79.5500,                 loss: nan
env1_second_0:                 episode reward: 79.5500,                 loss: nan
Episode: 3621/10000 (36.2100%),                 avg. length: 411.15,                last time consumption/overall running time: 215.4904s / 99190.0005 s
env0_first_0:                 episode reward: -58.4000,                 loss: 0.3508
env0_second_0:                 episode reward: 58.4000,                 loss: nan
env1_first_0:                 episode reward: -56.9500,                 loss: nan
env1_second_0:                 episode reward: 56.9500,                 loss: nan
Episode: 3641/10000 (36.4100%),                 avg. length: 448.55,                last time consumption/overall running time: 235.2907s / 99425.2912 s
env0_first_0:                 episode reward: -43.6500,                 loss: 0.4309
env0_second_0:                 episode reward: 43.6500,                 loss: nan
env1_first_0:                 episode reward: -42.6000,                 loss: nan
env1_second_0:                 episode reward: 42.6000,                 loss: nan
Episode: 3661/10000 (36.6100%),                 avg. length: 456.9,                last time consumption/overall running time: 241.0246s / 99666.3158 s
env0_first_0:                 episode reward: -35.9000,                 loss: 0.4703
env0_second_0:                 episode reward: 35.9000,                 loss: nan
env1_first_0:                 episode reward: -18.5000,                 loss: nan
env1_second_0:                 episode reward: 18.5000,                 loss: nan
Episode: 3681/10000 (36.8100%),                 avg. length: 521.25,                last time consumption/overall running time: 274.7983s / 99941.1142 s
env0_first_0:                 episode reward: 13.2500,                 loss: 0.5038
env0_second_0:                 episode reward: -13.2500,                 loss: nan
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 3701/10000 (37.0100%),                 avg. length: 506.05,                last time consumption/overall running time: 266.8023s / 100207.9165 s
env0_first_0:                 episode reward: 2.0000,                 loss: 0.5179
env0_second_0:                 episode reward: -2.0000,                 loss: nan
env1_first_0:                 episode reward: 3.7500,                 loss: nan
env1_second_0:                 episode reward: -3.7500,                 loss: nan
Episode: 3721/10000 (37.2100%),                 avg. length: 335.65,                last time consumption/overall running time: 371.4346s / 100579.3511 s
env0_first_0:                 episode reward: 10.2000,                 loss: 0.5585
env0_second_0:                 episode reward: -10.2000,                 loss: 0.4809
env1_first_0:                 episode reward: 10.6000,                 loss: nan
env1_second_0:                 episode reward: -10.6000,                 loss: nan
Score delta: 95.4, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/3719_0.
Episode: 3741/10000 (37.4100%),                 avg. length: 483.6,                last time consumption/overall running time: 253.4480s / 100832.7991 s
env0_first_0:                 episode reward: 24.3500,                 loss: nan
env0_second_0:                 episode reward: -24.3500,                 loss: 0.5064
env1_first_0:                 episode reward: -14.7000,                 loss: nan
env1_second_0:                 episode reward: 14.7000,                 loss: nan
Episode: 3761/10000 (37.6100%),                 avg. length: 472.15,                last time consumption/overall running time: 922.0409s / 101754.8400 s
env0_first_0:                 episode reward: -42.1500,                 loss: 0.2668
env0_second_0:                 episode reward: 42.1500,                 loss: 0.5456
env1_first_0:                 episode reward: -49.4500,                 loss: nan
env1_second_0:                 episode reward: 49.4500,                 loss: nan
Score delta: 106.8, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/3757_1.
Episode: 3781/10000 (37.8100%),                 avg. length: 490.5,                last time consumption/overall running time: 261.3671s / 102016.2071 s
env0_first_0:                 episode reward: -76.3000,                 loss: 0.2623
env0_second_0:                 episode reward: 76.3000,                 loss: nan
env1_first_0:                 episode reward: -76.4500,                 loss: nan
env1_second_0:                 episode reward: 76.4500,                 loss: nan
Episode: 3801/10000 (38.0100%),                 avg. length: 412.3,                last time consumption/overall running time: 220.8542s / 102237.0613 s
env0_first_0:                 episode reward: -38.7500,                 loss: 0.3049
env0_second_0:                 episode reward: 38.7500,                 loss: nan
env1_first_0:                 episode reward: -33.2000,                 loss: nan
env1_second_0:                 episode reward: 33.2000,                 loss: nan
Episode: 3821/10000 (38.2100%),                 avg. length: 621.75,                last time consumption/overall running time: 331.9321s / 102568.9934 s
env0_first_0:                 episode reward: -28.2000,                 loss: 0.3426
env0_second_0:                 episode reward: 28.2000,                 loss: nan
env1_first_0:                 episode reward: -20.9000,                 loss: nan
env1_second_0:                 episode reward: 20.9000,                 loss: nan
Episode: 3841/10000 (38.4100%),                 avg. length: 420.4,                last time consumption/overall running time: 582.1317s / 103151.1251 s
env0_first_0:                 episode reward: -24.4500,                 loss: 0.3701
env0_second_0:                 episode reward: 24.4500,                 loss: 0.5618
env1_first_0:                 episode reward: -35.2500,                 loss: nan
env1_second_0:                 episode reward: 35.2500,                 loss: nan
Score delta: 86.8, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/3830_0.
Episode: 3861/10000 (38.6100%),                 avg. length: 410.0,                last time consumption/overall running time: 219.5500s / 103370.6751 s
env0_first_0:                 episode reward: -2.5500,                 loss: nan
env0_second_0:                 episode reward: 2.5500,                 loss: 0.6141
env1_first_0:                 episode reward: 14.3500,                 loss: nan
env1_second_0:                 episode reward: -14.3500,                 loss: nan
Episode: 3881/10000 (38.8100%),                 avg. length: 436.3,                last time consumption/overall running time: 232.2654s / 103602.9405 s
env0_first_0:                 episode reward: 18.6500,                 loss: nan
env0_second_0:                 episode reward: -18.6500,                 loss: 0.5781
env1_first_0:                 episode reward: 30.4500,                 loss: nan
env1_second_0:                 episode reward: -30.4500,                 loss: nan
Episode: 3901/10000 (39.0100%),                 avg. length: 373.75,                last time consumption/overall running time: 197.4749s / 103800.4154 s
env0_first_0:                 episode reward: 3.4500,                 loss: nan
env0_second_0:                 episode reward: -3.4500,                 loss: 0.5830
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 3921/10000 (39.2100%),                 avg. length: 505.9,                last time consumption/overall running time: 264.6225s / 104065.0379 s
env0_first_0:                 episode reward: -14.8500,                 loss: nan
env0_second_0:                 episode reward: 14.8500,                 loss: 0.6186
env1_first_0:                 episode reward: -22.6000,                 loss: nan
env1_second_0:                 episode reward: 22.6000,                 loss: nan
Episode: 3941/10000 (39.4100%),                 avg. length: 386.05,                last time consumption/overall running time: 201.9731s / 104267.0110 s
env0_first_0:                 episode reward: -17.9500,                 loss: nan
env0_second_0:                 episode reward: 17.9500,                 loss: 0.6148
env1_first_0:                 episode reward: -43.3500,                 loss: nan
env1_second_0:                 episode reward: 43.3500,                 loss: nan
Episode: 3961/10000 (39.6100%),                 avg. length: 1210.3,                last time consumption/overall running time: 1367.4105s / 105634.4216 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.3146
env0_second_0:                 episode reward: -1.2500,                 loss: 0.6222
env1_first_0:                 episode reward: -10.2000,                 loss: nan
env1_second_0:                 episode reward: 10.2000,                 loss: nan
Score delta: 85.4, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/3945_1.
Episode: 3981/10000 (39.8100%),                 avg. length: 898.15,                last time consumption/overall running time: 472.0024s / 106106.4239 s
env0_first_0:                 episode reward: -16.6500,                 loss: 0.2083
env0_second_0:                 episode reward: 16.6500,                 loss: nan
env1_first_0:                 episode reward: -9.8000,                 loss: nan
env1_second_0:                 episode reward: 9.8000,                 loss: nan
Episode: 4001/10000 (40.0100%),                 avg. length: 1202.8,                last time consumption/overall running time: 939.6917s / 107046.1157 s
env0_first_0:                 episode reward: 11.4500,                 loss: 0.1553
env0_second_0:                 episode reward: -11.4500,                 loss: 0.5588
env1_first_0:                 episode reward: 2.6000,                 loss: nan
env1_second_0:                 episode reward: -2.6000,                 loss: nan
Score delta: 85.2, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/3988_0.
Episode: 4021/10000 (40.2100%),                 avg. length: 535.6,                last time consumption/overall running time: 1056.6264s / 108102.7421 s
env0_first_0:                 episode reward: -50.0500,                 loss: 0.0681
env0_second_0:                 episode reward: 50.0500,                 loss: 0.4981
env1_first_0:                 episode reward: -46.7000,                 loss: nan
env1_second_0:                 episode reward: 46.7000,                 loss: nan
Score delta: 83.6, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/4010_1.
Episode: 4041/10000 (40.4100%),                 avg. length: 587.8,                last time consumption/overall running time: 312.5487s / 108415.2907 s
env0_first_0:                 episode reward: -54.0000,                 loss: 0.0944
env0_second_0:                 episode reward: 54.0000,                 loss: nan
env1_first_0:                 episode reward: -54.7500,                 loss: nan
env1_second_0:                 episode reward: 54.7500,                 loss: nan
Episode: 4061/10000 (40.6100%),                 avg. length: 598.25,                last time consumption/overall running time: 318.8451s / 108734.1358 s
env0_first_0:                 episode reward: 9.2500,                 loss: 0.1580
env0_second_0:                 episode reward: -9.2500,                 loss: nan
env1_first_0:                 episode reward: 4.5000,                 loss: nan
env1_second_0:                 episode reward: -4.5000,                 loss: nan
Episode: 4081/10000 (40.8100%),                 avg. length: 520.05,                last time consumption/overall running time: 779.8194s / 109513.9552 s
env0_first_0:                 episode reward: 7.9000,                 loss: 0.1928
env0_second_0:                 episode reward: -7.9000,                 loss: 0.4880
env1_first_0:                 episode reward: -21.1000,                 loss: nan
env1_second_0:                 episode reward: 21.1000,                 loss: nan
Score delta: 86.4, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/4065_0.
Episode: 4101/10000 (41.0100%),                 avg. length: 732.65,                last time consumption/overall running time: 1212.8974s / 110726.8526 s
env0_first_0:                 episode reward: -29.0000,                 loss: 0.3620
env0_second_0:                 episode reward: 29.0000,                 loss: 0.4846
env1_first_0:                 episode reward: -46.7500,                 loss: nan
env1_second_0:                 episode reward: 46.7500,                 loss: nan
Score delta: 89.4, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/4092_1.
Episode: 4121/10000 (41.2100%),                 avg. length: 1399.0,                last time consumption/overall running time: 730.9967s / 111457.8493 s
env0_first_0:                 episode reward: 3.1500,                 loss: 0.2514
env0_second_0:                 episode reward: -3.1500,                 loss: nan
env1_first_0:                 episode reward: 22.4500,                 loss: nan
env1_second_0:                 episode reward: -22.4500,                 loss: nan
Episode: 4141/10000 (41.4100%),                 avg. length: 523.3,                last time consumption/overall running time: 1023.0496s / 112480.8989 s
env0_first_0:                 episode reward: 8.1000,                 loss: 0.1919
env0_second_0:                 episode reward: -8.1000,                 loss: 0.5052
env1_first_0:                 episode reward: 8.4000,                 loss: nan
env1_second_0:                 episode reward: -8.4000,                 loss: nan
Score delta: 88.0, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/4138_0.
Episode: 4161/10000 (41.6100%),                 avg. length: 519.3,                last time consumption/overall running time: 1142.7068s / 113623.6057 s
env0_first_0:                 episode reward: -76.7500,                 loss: 0.1580
env0_second_0:                 episode reward: 76.7500,                 loss: 0.5366
env1_first_0:                 episode reward: -64.0000,                 loss: nan
env1_second_0:                 episode reward: 64.0000,                 loss: nan
Score delta: 177.6, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/4159_1.
Episode: 4181/10000 (41.8100%),                 avg. length: 749.25,                last time consumption/overall running time: 397.0744s / 114020.6801 s
env0_first_0:                 episode reward: -67.3000,                 loss: 0.1372
env0_second_0:                 episode reward: 67.3000,                 loss: nan
env1_first_0:                 episode reward: -48.5000,                 loss: nan
env1_second_0:                 episode reward: 48.5000,                 loss: nan
Episode: 4201/10000 (42.0100%),                 avg. length: 481.2,                last time consumption/overall running time: 255.7322s / 114276.4122 s
env0_first_0:                 episode reward: -61.8500,                 loss: 0.2249
env0_second_0:                 episode reward: 61.8500,                 loss: nan
env1_first_0:                 episode reward: -74.4500,                 loss: nan
env1_second_0:                 episode reward: 74.4500,                 loss: nan
Episode: 4221/10000 (42.2100%),                 avg. length: 979.05,                last time consumption/overall running time: 517.5386s / 114793.9508 s
env0_first_0:                 episode reward: -50.8500,                 loss: 0.3423
env0_second_0:                 episode reward: 50.8500,                 loss: nan
env1_first_0:                 episode reward: -26.3000,                 loss: nan
env1_second_0:                 episode reward: 26.3000,                 loss: nan
Episode: 4241/10000 (42.4100%),                 avg. length: 984.25,                last time consumption/overall running time: 523.6300s / 115317.5808 s
env0_first_0:                 episode reward: -35.3500,                 loss: 0.3312
env0_second_0:                 episode reward: 35.3500,                 loss: nan
env1_first_0:                 episode reward: -48.8500,                 loss: nan
env1_second_0:                 episode reward: 48.8500,                 loss: nan
Episode: 4261/10000 (42.6100%),                 avg. length: 534.5,                last time consumption/overall running time: 285.5035s / 115603.0843 s
env0_first_0:                 episode reward: -27.3500,                 loss: 0.3025
env0_second_0:                 episode reward: 27.3500,                 loss: nan
env1_first_0:                 episode reward: -43.6500,                 loss: nan
env1_second_0:                 episode reward: 43.6500,                 loss: nan
Episode: 4281/10000 (42.8100%),                 avg. length: 754.2,                last time consumption/overall running time: 1051.3976s / 116654.4819 s
env0_first_0:                 episode reward: 9.0000,                 loss: 0.3188
env0_second_0:                 episode reward: -9.0000,                 loss: 0.5074
env1_first_0:                 episode reward: 12.5000,                 loss: nan
env1_second_0:                 episode reward: -12.5000,                 loss: nan
Score delta: 94.6, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/4279_0.
Episode: 4301/10000 (43.0100%),                 avg. length: 659.55,                last time consumption/overall running time: 1247.5313s / 117902.0133 s
env0_first_0:                 episode reward: -70.0000,                 loss: 0.0878
env0_second_0:                 episode reward: 70.0000,                 loss: 0.5168
env1_first_0:                 episode reward: -59.8500,                 loss: nan
env1_second_0:                 episode reward: 59.8500,                 loss: nan
Score delta: 118.6, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/4300_1.
Episode: 4321/10000 (43.2100%),                 avg. length: 285.95,                last time consumption/overall running time: 149.0988s / 118051.1120 s
env0_first_0:                 episode reward: -90.1500,                 loss: 0.0789
env0_second_0:                 episode reward: 90.1500,                 loss: nan
env1_first_0:                 episode reward: -88.2000,                 loss: nan
env1_second_0:                 episode reward: 88.2000,                 loss: nan
Episode: 4341/10000 (43.4100%),                 avg. length: 232.4,                last time consumption/overall running time: 121.3083s / 118172.4204 s
env0_first_0:                 episode reward: -97.1000,                 loss: 0.1002
env0_second_0:                 episode reward: 97.1000,                 loss: nan
env1_first_0:                 episode reward: -94.3500,                 loss: nan
env1_second_0:                 episode reward: 94.3500,                 loss: nan
Episode: 4361/10000 (43.6100%),                 avg. length: 245.85,                last time consumption/overall running time: 128.2158s / 118300.6361 s
env0_first_0:                 episode reward: -94.4500,                 loss: 0.1284
env0_second_0:                 episode reward: 94.4500,                 loss: nan
env1_first_0:                 episode reward: -92.3000,                 loss: nan
env1_second_0:                 episode reward: 92.3000,                 loss: nan
Episode: 4381/10000 (43.8100%),                 avg. length: 242.8,                last time consumption/overall running time: 127.1248s / 118427.7609 s
env0_first_0:                 episode reward: -89.7500,                 loss: 0.1603
env0_second_0:                 episode reward: 89.7500,                 loss: nan
env1_first_0:                 episode reward: -90.0000,                 loss: nan
env1_second_0:                 episode reward: 90.0000,                 loss: nan
Episode: 4401/10000 (44.0100%),                 avg. length: 330.7,                last time consumption/overall running time: 172.3965s / 118600.1574 s
env0_first_0:                 episode reward: -88.3500,                 loss: 0.1913
env0_second_0:                 episode reward: 88.3500,                 loss: nan
env1_first_0:                 episode reward: -86.4500,                 loss: nan
env1_second_0:                 episode reward: 86.4500,                 loss: nan
Episode: 4421/10000 (44.2100%),                 avg. length: 611.4,                last time consumption/overall running time: 320.6389s / 118920.7963 s
env0_first_0:                 episode reward: -61.3000,                 loss: 0.2657
env0_second_0:                 episode reward: 61.3000,                 loss: nan
env1_first_0:                 episode reward: -63.7000,                 loss: nan
env1_second_0:                 episode reward: 63.7000,                 loss: nan
Episode: 4441/10000 (44.4100%),                 avg. length: 417.0,                last time consumption/overall running time: 221.1810s / 119141.9773 s
env0_first_0:                 episode reward: -82.4000,                 loss: 0.3186
env0_second_0:                 episode reward: 82.4000,                 loss: nan
env1_first_0:                 episode reward: -75.1500,                 loss: nan
env1_second_0:                 episode reward: 75.1500,                 loss: nan
Episode: 4461/10000 (44.6100%),                 avg. length: 774.05,                last time consumption/overall running time: 411.3548s / 119553.3321 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.3399
env0_second_0:                 episode reward: -0.2000,                 loss: nan
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 4481/10000 (44.8100%),                 avg. length: 1208.55,                last time consumption/overall running time: 1484.1238s / 121037.4559 s
env0_first_0:                 episode reward: 22.0500,                 loss: 0.2507
env0_second_0:                 episode reward: -22.0500,                 loss: 0.5334
env1_first_0:                 episode reward: -3.2500,                 loss: nan
env1_second_0:                 episode reward: 3.2500,                 loss: nan
Score delta: 99.0, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/4478_0.
Episode: 4501/10000 (45.0100%),                 avg. length: 350.1,                last time consumption/overall running time: 1150.3503s / 122187.8062 s
env0_first_0:                 episode reward: -70.1500,                 loss: 0.0649
env0_second_0:                 episode reward: 70.1500,                 loss: 0.5910
env1_first_0:                 episode reward: -80.5500,                 loss: nan
env1_second_0:                 episode reward: 80.5500,                 loss: nan
Score delta: 114.4, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/4499_1.
Episode: 4521/10000 (45.2100%),                 avg. length: 280.2,                last time consumption/overall running time: 149.5912s / 122337.3974 s
env0_first_0:                 episode reward: -93.1000,                 loss: 0.0499
env0_second_0:                 episode reward: 93.1000,                 loss: nan
env1_first_0:                 episode reward: -94.4500,                 loss: nan
env1_second_0:                 episode reward: 94.4500,                 loss: nan
Episode: 4541/10000 (45.4100%),                 avg. length: 235.3,                last time consumption/overall running time: 126.0839s / 122463.4814 s
env0_first_0:                 episode reward: -96.9000,                 loss: 0.0623
env0_second_0:                 episode reward: 96.9000,                 loss: nan
env1_first_0:                 episode reward: -91.1000,                 loss: nan
env1_second_0:                 episode reward: 91.1000,                 loss: nan
Episode: 4561/10000 (45.6100%),                 avg. length: 250.05,                last time consumption/overall running time: 133.8630s / 122597.3444 s
env0_first_0:                 episode reward: -88.1000,                 loss: 0.0818
env0_second_0:                 episode reward: 88.1000,                 loss: nan
env1_first_0:                 episode reward: -93.1000,                 loss: nan
env1_second_0:                 episode reward: 93.1000,                 loss: nan
Episode: 4581/10000 (45.8100%),                 avg. length: 252.25,                last time consumption/overall running time: 134.8928s / 122732.2372 s
env0_first_0:                 episode reward: -90.4000,                 loss: 0.0952
env0_second_0:                 episode reward: 90.4000,                 loss: nan
env1_first_0:                 episode reward: -90.1000,                 loss: nan
env1_second_0:                 episode reward: 90.1000,                 loss: nan
Episode: 4601/10000 (46.0100%),                 avg. length: 587.8,                last time consumption/overall running time: 312.4406s / 123044.6778 s
env0_first_0:                 episode reward: -52.0500,                 loss: 0.1484
env0_second_0:                 episode reward: 52.0500,                 loss: nan
env1_first_0:                 episode reward: -45.8500,                 loss: nan
env1_second_0:                 episode reward: 45.8500,                 loss: nan
Episode: 4621/10000 (46.2100%),                 avg. length: 323.15,                last time consumption/overall running time: 172.5516s / 123217.2294 s
env0_first_0:                 episode reward: -72.1500,                 loss: 0.2263
env0_second_0:                 episode reward: 72.1500,                 loss: nan
env1_first_0:                 episode reward: -69.5000,                 loss: nan
env1_second_0:                 episode reward: 69.5000,                 loss: nan
Episode: 4641/10000 (46.4100%),                 avg. length: 340.3,                last time consumption/overall running time: 181.4417s / 123398.6711 s
env0_first_0:                 episode reward: -58.1000,                 loss: 0.2826
env0_second_0:                 episode reward: 58.1000,                 loss: nan
env1_first_0:                 episode reward: -66.6000,                 loss: nan
env1_second_0:                 episode reward: 66.6000,                 loss: nan
Episode: 4661/10000 (46.6100%),                 avg. length: 772.45,                last time consumption/overall running time: 410.0563s / 123808.7274 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.3218
env0_second_0:                 episode reward: 0.1500,                 loss: nan
env1_first_0:                 episode reward: -16.5500,                 loss: nan
env1_second_0:                 episode reward: 16.5500,                 loss: nan
Episode: 4681/10000 (46.8100%),                 avg. length: 420.5,                last time consumption/overall running time: 224.3069s / 124033.0343 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.3299
env0_second_0:                 episode reward: 0.9500,                 loss: nan
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 4701/10000 (47.0100%),                 avg. length: 492.35,                last time consumption/overall running time: 261.1969s / 124294.2311 s
env0_first_0:                 episode reward: -22.8000,                 loss: 0.3429
env0_second_0:                 episode reward: 22.8000,                 loss: nan
env1_first_0:                 episode reward: -22.8500,                 loss: nan
env1_second_0:                 episode reward: 22.8500,                 loss: nan
Episode: 4721/10000 (47.2100%),                 avg. length: 583.5,                last time consumption/overall running time: 913.2315s / 125207.4626 s
env0_first_0:                 episode reward: 22.9000,                 loss: 0.3246
env0_second_0:                 episode reward: -22.9000,                 loss: nan
env1_first_0:                 episode reward: 20.8500,                 loss: nan
env1_second_0:                 episode reward: -20.8500,                 loss: nan
Score delta: 99.2, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/4721_0.
Episode: 4741/10000 (47.4100%),                 avg. length: 470.1,                last time consumption/overall running time: 243.1807s / 125450.6433 s
env0_first_0:                 episode reward: -43.0500,                 loss: nan
env0_second_0:                 episode reward: 43.0500,                 loss: 0.6546
env1_first_0:                 episode reward: -40.7000,                 loss: nan
env1_second_0:                 episode reward: 40.7000,                 loss: nan
Episode: 4761/10000 (47.6100%),                 avg. length: 243.9,                last time consumption/overall running time: 1124.4983s / 126575.1416 s
env0_first_0:                 episode reward: -85.3500,                 loss: 0.6072
env0_second_0:                 episode reward: 85.3500,                 loss: 0.6436
env1_first_0:                 episode reward: -95.0000,                 loss: nan
env1_second_0:                 episode reward: 95.0000,                 loss: nan
Score delta: 110.2, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/4742_1.
Episode: 4781/10000 (47.8100%),                 avg. length: 251.45,                last time consumption/overall running time: 134.8989s / 126710.0405 s
env0_first_0:                 episode reward: -89.5500,                 loss: 0.5303
env0_second_0:                 episode reward: 89.5500,                 loss: nan
env1_first_0:                 episode reward: -86.7000,                 loss: nan
env1_second_0:                 episode reward: 86.7000,                 loss: nan
Episode: 4801/10000 (48.0100%),                 avg. length: 433.8,                last time consumption/overall running time: 230.0478s / 126940.0883 s
env0_first_0:                 episode reward: -65.9500,                 loss: 0.4183
env0_second_0:                 episode reward: 65.9500,                 loss: nan
env1_first_0:                 episode reward: -82.0000,                 loss: nan
env1_second_0:                 episode reward: 82.0000,                 loss: nan
Episode: 4821/10000 (48.2100%),                 avg. length: 368.6,                last time consumption/overall running time: 195.5166s / 127135.6049 s
env0_first_0:                 episode reward: -82.6500,                 loss: 0.3466
env0_second_0:                 episode reward: 82.6500,                 loss: nan
env1_first_0:                 episode reward: -80.3000,                 loss: nan
env1_second_0:                 episode reward: 80.3000,                 loss: nan
Episode: 4841/10000 (48.4100%),                 avg. length: 364.6,                last time consumption/overall running time: 192.5570s / 127328.1620 s
env0_first_0:                 episode reward: -67.9500,                 loss: 0.3630
env0_second_0:                 episode reward: 67.9500,                 loss: nan
env1_first_0:                 episode reward: -83.8000,                 loss: nan
env1_second_0:                 episode reward: 83.8000,                 loss: nan
Episode: 4861/10000 (48.6100%),                 avg. length: 503.95,                last time consumption/overall running time: 264.5177s / 127592.6796 s
env0_first_0:                 episode reward: -53.7000,                 loss: 0.3910
env0_second_0:                 episode reward: 53.7000,                 loss: nan
env1_first_0:                 episode reward: -63.5500,                 loss: nan
env1_second_0:                 episode reward: 63.5500,                 loss: nan
Episode: 4881/10000 (48.8100%),                 avg. length: 331.5,                last time consumption/overall running time: 174.4927s / 127767.1724 s
env0_first_0:                 episode reward: -79.3500,                 loss: 0.4133
env0_second_0:                 episode reward: 79.3500,                 loss: nan
env1_first_0:                 episode reward: -69.0000,                 loss: nan
env1_second_0:                 episode reward: 69.0000,                 loss: nan
Episode: 4901/10000 (49.0100%),                 avg. length: 391.9,                last time consumption/overall running time: 206.1649s / 127973.3373 s
env0_first_0:                 episode reward: -69.4500,                 loss: 0.4322
env0_second_0:                 episode reward: 69.4500,                 loss: nan
env1_first_0:                 episode reward: -50.0000,                 loss: nan
env1_second_0:                 episode reward: 50.0000,                 loss: nan
Episode: 4921/10000 (49.2100%),                 avg. length: 404.35,                last time consumption/overall running time: 212.6849s / 128186.0222 s
env0_first_0:                 episode reward: -63.1500,                 loss: 0.4635
env0_second_0:                 episode reward: 63.1500,                 loss: nan
env1_first_0:                 episode reward: -58.8000,                 loss: nan
env1_second_0:                 episode reward: 58.8000,                 loss: nan
Episode: 4941/10000 (49.4100%),                 avg. length: 572.35,                last time consumption/overall running time: 300.9391s / 128486.9613 s
env0_first_0:                 episode reward: -17.0500,                 loss: 0.4579
env0_second_0:                 episode reward: 17.0500,                 loss: nan
env1_first_0:                 episode reward: 2.4000,                 loss: nan
env1_second_0:                 episode reward: -2.4000,                 loss: nan
Episode: 4961/10000 (49.6100%),                 avg. length: 534.8,                last time consumption/overall running time: 930.0168s / 129416.9780 s
env0_first_0:                 episode reward: -17.5500,                 loss: 0.4128
env0_second_0:                 episode reward: 17.5500,                 loss: 0.7006
env1_first_0:                 episode reward: -13.8000,                 loss: nan
env1_second_0:                 episode reward: 13.8000,                 loss: nan
Score delta: 118.4, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/4948_0.
Episode: 4981/10000 (49.8100%),                 avg. length: 242.8,                last time consumption/overall running time: 1180.4021s / 130597.3801 s
env0_first_0:                 episode reward: -75.5000,                 loss: 0.1916
env0_second_0:                 episode reward: 75.5000,                 loss: 0.7018
env1_first_0:                 episode reward: -86.2000,                 loss: nan
env1_second_0:                 episode reward: 86.2000,                 loss: nan
Score delta: 96.0, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/4969_1.
Episode: 5001/10000 (50.0100%),                 avg. length: 328.05,                last time consumption/overall running time: 173.9369s / 130771.3171 s
env0_first_0:                 episode reward: -89.8500,                 loss: 0.1966
env0_second_0:                 episode reward: 89.8500,                 loss: nan
env1_first_0:                 episode reward: -85.8000,                 loss: nan
env1_second_0:                 episode reward: 85.8000,                 loss: nan
Episode: 5021/10000 (50.2100%),                 avg. length: 476.05,                last time consumption/overall running time: 251.5483s / 131022.8654 s
env0_first_0:                 episode reward: -42.0000,                 loss: 0.2157
env0_second_0:                 episode reward: 42.0000,                 loss: nan
env1_first_0:                 episode reward: -31.1500,                 loss: nan
env1_second_0:                 episode reward: 31.1500,                 loss: nan
Episode: 5041/10000 (50.4100%),                 avg. length: 542.15,                last time consumption/overall running time: 1050.7659s / 132073.6313 s
env0_first_0:                 episode reward: 25.1500,                 loss: 0.2739
env0_second_0:                 episode reward: -25.1500,                 loss: 0.6690
env1_first_0:                 episode reward: 18.8500,                 loss: nan
env1_second_0:                 episode reward: -18.8500,                 loss: nan
Score delta: 111.8, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/5034_0.
Episode: 5061/10000 (50.6100%),                 avg. length: 280.65,                last time consumption/overall running time: 1227.8576s / 133301.4889 s
env0_first_0:                 episode reward: -73.3000,                 loss: 0.1391
env0_second_0:                 episode reward: 73.3000,                 loss: 0.6723
env1_first_0:                 episode reward: -64.0000,                 loss: nan
env1_second_0:                 episode reward: 64.0000,                 loss: nan
Score delta: 131.0, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/5055_1.
Episode: 5081/10000 (50.8100%),                 avg. length: 252.65,                last time consumption/overall running time: 133.4431s / 133434.9320 s
env0_first_0:                 episode reward: -86.4500,                 loss: 0.1246
env0_second_0:                 episode reward: 86.4500,                 loss: nan
env1_first_0:                 episode reward: -89.6500,                 loss: nan
env1_second_0:                 episode reward: 89.6500,                 loss: nan
Episode: 5101/10000 (51.0100%),                 avg. length: 239.2,                last time consumption/overall running time: 126.3547s / 133561.2866 s
env0_first_0:                 episode reward: -84.9000,                 loss: 0.1230
env0_second_0:                 episode reward: 84.9000,                 loss: nan
env1_first_0:                 episode reward: -91.2500,                 loss: nan
env1_second_0:                 episode reward: 91.2500,                 loss: nan
Episode: 5121/10000 (51.2100%),                 avg. length: 310.4,                last time consumption/overall running time: 163.6466s / 133724.9332 s
env0_first_0:                 episode reward: -73.2500,                 loss: 0.1346
env0_second_0:                 episode reward: 73.2500,                 loss: nan
env1_first_0:                 episode reward: -83.7500,                 loss: nan
env1_second_0:                 episode reward: 83.7500,                 loss: nan
Episode: 5141/10000 (51.4100%),                 avg. length: 344.1,                last time consumption/overall running time: 181.5112s / 133906.4444 s
env0_first_0:                 episode reward: -51.8500,                 loss: 0.1668
env0_second_0:                 episode reward: 51.8500,                 loss: nan
env1_first_0:                 episode reward: -59.7500,                 loss: nan
env1_second_0:                 episode reward: 59.7500,                 loss: nan
Episode: 5161/10000 (51.6100%),                 avg. length: 316.05,                last time consumption/overall running time: 166.5883s / 134073.0327 s
env0_first_0:                 episode reward: -73.9000,                 loss: 0.2120
env0_second_0:                 episode reward: 73.9000,                 loss: nan
env1_first_0:                 episode reward: -76.8000,                 loss: nan
env1_second_0:                 episode reward: 76.8000,                 loss: nan
Episode: 5181/10000 (51.8100%),                 avg. length: 373.35,                last time consumption/overall running time: 197.0362s / 134270.0689 s
env0_first_0:                 episode reward: -63.0500,                 loss: 0.2422
env0_second_0:                 episode reward: 63.0500,                 loss: nan
env1_first_0:                 episode reward: -62.5000,                 loss: nan
env1_second_0:                 episode reward: 62.5000,                 loss: nan
Episode: 5201/10000 (52.0100%),                 avg. length: 444.75,                last time consumption/overall running time: 236.3876s / 134506.4566 s
env0_first_0:                 episode reward: -68.0000,                 loss: 0.2824
env0_second_0:                 episode reward: 68.0000,                 loss: nan
env1_first_0:                 episode reward: -53.5000,                 loss: nan
env1_second_0:                 episode reward: 53.5000,                 loss: nan
Episode: 5221/10000 (52.2100%),                 avg. length: 416.25,                last time consumption/overall running time: 221.0601s / 134727.5167 s
env0_first_0:                 episode reward: -42.4500,                 loss: 0.3007
env0_second_0:                 episode reward: 42.4500,                 loss: nan
env1_first_0:                 episode reward: -51.2000,                 loss: nan
env1_second_0:                 episode reward: 51.2000,                 loss: nan
Episode: 5241/10000 (52.4100%),                 avg. length: 435.8,                last time consumption/overall running time: 854.4202s / 135581.9369 s
env0_first_0:                 episode reward: -6.5000,                 loss: 0.3405
env0_second_0:                 episode reward: 6.5000,                 loss: 0.6843
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Score delta: 80.6, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/5234_0.
Episode: 5261/10000 (52.6100%),                 avg. length: 608.35,                last time consumption/overall running time: 1473.5292s / 137055.4661 s
env0_first_0:                 episode reward: -44.8500,                 loss: 0.3679
env0_second_0:                 episode reward: 44.8500,                 loss: 0.6836
env1_first_0:                 episode reward: -65.8000,                 loss: nan
env1_second_0:                 episode reward: 65.8000,                 loss: nan
Score delta: 123.4, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/5255_1.
Episode: 5281/10000 (52.8100%),                 avg. length: 479.35,                last time consumption/overall running time: 255.3607s / 137310.8268 s
env0_first_0:                 episode reward: -71.7500,                 loss: 0.3111
env0_second_0:                 episode reward: 71.7500,                 loss: nan
env1_first_0:                 episode reward: -78.1500,                 loss: nan
env1_second_0:                 episode reward: 78.1500,                 loss: nan
Episode: 5301/10000 (53.0100%),                 avg. length: 455.8,                last time consumption/overall running time: 242.7209s / 137553.5477 s
env0_first_0:                 episode reward: -65.5000,                 loss: 0.3201
env0_second_0:                 episode reward: 65.5000,                 loss: nan
env1_first_0:                 episode reward: -67.4000,                 loss: nan
env1_second_0:                 episode reward: 67.4000,                 loss: nan
Episode: 5321/10000 (53.2100%),                 avg. length: 561.2,                last time consumption/overall running time: 298.0422s / 137851.5899 s
env0_first_0:                 episode reward: -20.2500,                 loss: 0.3661
env0_second_0:                 episode reward: 20.2500,                 loss: nan
env1_first_0:                 episode reward: -6.1000,                 loss: nan
env1_second_0:                 episode reward: 6.1000,                 loss: nan
Episode: 5341/10000 (53.4100%),                 avg. length: 293.95,                last time consumption/overall running time: 884.8734s / 138736.4634 s
env0_first_0:                 episode reward: 2.4500,                 loss: 0.4199
env0_second_0:                 episode reward: -2.4500,                 loss: 0.7753
env1_first_0:                 episode reward: -8.0500,                 loss: nan
env1_second_0:                 episode reward: 8.0500,                 loss: nan
Score delta: 85.6, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/5339_0.
Episode: 5361/10000 (53.6100%),                 avg. length: 360.2,                last time consumption/overall running time: 1367.7637s / 140104.2271 s
env0_first_0:                 episode reward: -82.9000,                 loss: 0.5889
env0_second_0:                 episode reward: 82.9000,                 loss: 0.7489
env1_first_0:                 episode reward: -69.9000,                 loss: nan
env1_second_0:                 episode reward: 69.9000,                 loss: nan
Score delta: 176.4, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/5360_1.
Episode: 5381/10000 (53.8100%),                 avg. length: 630.7,                last time consumption/overall running time: 331.1016s / 140435.3287 s
env0_first_0:                 episode reward: -42.0000,                 loss: 0.5194
env0_second_0:                 episode reward: 42.0000,                 loss: nan
env1_first_0:                 episode reward: -24.1000,                 loss: nan
env1_second_0:                 episode reward: 24.1000,                 loss: nan
Episode: 5401/10000 (54.0100%),                 avg. length: 427.4,                last time consumption/overall running time: 225.7481s / 140661.0768 s
env0_first_0:                 episode reward: 5.4000,                 loss: 0.6301
env0_second_0:                 episode reward: -5.4000,                 loss: nan
env1_first_0:                 episode reward: 9.4500,                 loss: nan
env1_second_0:                 episode reward: -9.4500,                 loss: nan
Episode: 5421/10000 (54.2100%),                 avg. length: 330.45,                last time consumption/overall running time: 175.2039s / 140836.2806 s
env0_first_0:                 episode reward: -11.5500,                 loss: 0.7220
env0_second_0:                 episode reward: 11.5500,                 loss: nan
env1_first_0:                 episode reward: -30.1500,                 loss: nan
env1_second_0:                 episode reward: 30.1500,                 loss: nan
Episode: 5441/10000 (54.4100%),                 avg. length: 352.35,                last time consumption/overall running time: 730.1977s / 141566.4783 s
env0_first_0:                 episode reward: 3.4500,                 loss: 0.7784
env0_second_0:                 episode reward: -3.4500,                 loss: 0.7375
env1_first_0:                 episode reward: 14.9000,                 loss: nan
env1_second_0:                 episode reward: -14.9000,                 loss: nan
Score delta: 87.0, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/5431_0.
Episode: 5461/10000 (54.6100%),                 avg. length: 435.2,                last time consumption/overall running time: 1453.5009s / 143019.9792 s
env0_first_0:                 episode reward: -65.0000,                 loss: 0.1777
env0_second_0:                 episode reward: 65.0000,                 loss: 0.6931
env1_first_0:                 episode reward: -65.4500,                 loss: nan
env1_second_0:                 episode reward: 65.4500,                 loss: nan
Score delta: 83.8, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/5453_1.
Episode: 5481/10000 (54.8100%),                 avg. length: 474.35,                last time consumption/overall running time: 249.8659s / 143269.8451 s
env0_first_0:                 episode reward: -87.6500,                 loss: 0.1496
env0_second_0:                 episode reward: 87.6500,                 loss: nan
env1_first_0:                 episode reward: -66.0500,                 loss: nan
env1_second_0:                 episode reward: 66.0500,                 loss: nan
Episode: 5501/10000 (55.0100%),                 avg. length: 239.6,                last time consumption/overall running time: 126.7952s / 143396.6403 s
env0_first_0:                 episode reward: -84.3500,                 loss: 0.1867
env0_second_0:                 episode reward: 84.3500,                 loss: nan
env1_first_0:                 episode reward: -89.8500,                 loss: nan
env1_second_0:                 episode reward: 89.8500,                 loss: nan
Episode: 5521/10000 (55.2100%),                 avg. length: 334.95,                last time consumption/overall running time: 176.8982s / 143573.5385 s
env0_first_0:                 episode reward: -86.5500,                 loss: 0.2477
env0_second_0:                 episode reward: 86.5500,                 loss: nan
env1_first_0:                 episode reward: -90.9500,                 loss: nan
env1_second_0:                 episode reward: 90.9500,                 loss: nan
Episode: 5541/10000 (55.4100%),                 avg. length: 248.8,                last time consumption/overall running time: 132.1171s / 143705.6556 s
env0_first_0:                 episode reward: -91.9000,                 loss: 0.2979
env0_second_0:                 episode reward: 91.9000,                 loss: nan
env1_first_0:                 episode reward: -87.5500,                 loss: nan
env1_second_0:                 episode reward: 87.5500,                 loss: nan
Episode: 5561/10000 (55.6100%),                 avg. length: 369.55,                last time consumption/overall running time: 195.4129s / 143901.0685 s
env0_first_0:                 episode reward: -82.3500,                 loss: 0.3665
env0_second_0:                 episode reward: 82.3500,                 loss: nan
env1_first_0:                 episode reward: -79.5500,                 loss: nan
env1_second_0:                 episode reward: 79.5500,                 loss: nan
Episode: 5581/10000 (55.8100%),                 avg. length: 472.9,                last time consumption/overall running time: 250.7083s / 144151.7768 s
env0_first_0:                 episode reward: -81.0500,                 loss: 0.3860
env0_second_0:                 episode reward: 81.0500,                 loss: nan
env1_first_0:                 episode reward: -74.3500,                 loss: nan
env1_second_0:                 episode reward: 74.3500,                 loss: nan
Episode: 5601/10000 (56.0100%),                 avg. length: 493.55,                last time consumption/overall running time: 261.6711s / 144413.4479 s
env0_first_0:                 episode reward: -72.8000,                 loss: 0.3792
env0_second_0:                 episode reward: 72.8000,                 loss: nan
env1_first_0:                 episode reward: -63.4500,                 loss: nan
env1_second_0:                 episode reward: 63.4500,                 loss: nan
Episode: 5621/10000 (56.2100%),                 avg. length: 363.3,                last time consumption/overall running time: 193.2078s / 144606.6557 s
env0_first_0:                 episode reward: -73.5000,                 loss: 0.4050
env0_second_0:                 episode reward: 73.5000,                 loss: nan
env1_first_0:                 episode reward: -72.7500,                 loss: nan
env1_second_0:                 episode reward: 72.7500,                 loss: nan
Episode: 5641/10000 (56.4100%),                 avg. length: 322.3,                last time consumption/overall running time: 171.5898s / 144778.2455 s
env0_first_0:                 episode reward: -70.3500,                 loss: 0.3920
env0_second_0:                 episode reward: 70.3500,                 loss: nan
env1_first_0:                 episode reward: -67.4500,                 loss: nan
env1_second_0:                 episode reward: 67.4500,                 loss: nan
Episode: 5661/10000 (56.6100%),                 avg. length: 455.7,                last time consumption/overall running time: 242.0308s / 145020.2763 s
env0_first_0:                 episode reward: -42.2000,                 loss: 0.4051
env0_second_0:                 episode reward: 42.2000,                 loss: nan
env1_first_0:                 episode reward: -60.3500,                 loss: nan
env1_second_0:                 episode reward: 60.3500,                 loss: nan
Episode: 5681/10000 (56.8100%),                 avg. length: 675.5,                last time consumption/overall running time: 354.1604s / 145374.4367 s
env0_first_0:                 episode reward: -47.5500,                 loss: 0.4057
env0_second_0:                 episode reward: 47.5500,                 loss: nan
env1_first_0:                 episode reward: -34.5000,                 loss: nan
env1_second_0:                 episode reward: 34.5000,                 loss: nan
Episode: 5701/10000 (57.0100%),                 avg. length: 568.1,                last time consumption/overall running time: 298.5810s / 145673.0177 s
env0_first_0:                 episode reward: -32.2000,                 loss: 0.4227
env0_second_0:                 episode reward: 32.2000,                 loss: nan
env1_first_0:                 episode reward: -40.1500,                 loss: nan
env1_second_0:                 episode reward: 40.1500,                 loss: nan
Episode: 5721/10000 (57.2100%),                 avg. length: 742.65,                last time consumption/overall running time: 388.1063s / 146061.1240 s
env0_first_0:                 episode reward: -11.9500,                 loss: 0.4006
env0_second_0:                 episode reward: 11.9500,                 loss: nan
env1_first_0:                 episode reward: 6.9000,                 loss: nan
env1_second_0:                 episode reward: -6.9000,                 loss: nan
Episode: 5741/10000 (57.4100%),                 avg. length: 718.85,                last time consumption/overall running time: 373.7944s / 146434.9185 s
env0_first_0:                 episode reward: -10.5500,                 loss: 0.2972
env0_second_0:                 episode reward: 10.5500,                 loss: nan
env1_first_0:                 episode reward: -25.8500,                 loss: nan
env1_second_0:                 episode reward: 25.8500,                 loss: nan
Episode: 5761/10000 (57.6100%),                 avg. length: 843.2,                last time consumption/overall running time: 438.0432s / 146872.9616 s
env0_first_0:                 episode reward: -9.1000,                 loss: 0.2373
env0_second_0:                 episode reward: 9.1000,                 loss: nan
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 5781/10000 (57.8100%),                 avg. length: 1139.5,                last time consumption/overall running time: 591.6967s / 147464.6584 s
env0_first_0:                 episode reward: 5.5500,                 loss: 0.2045
env0_second_0:                 episode reward: -5.5500,                 loss: nan
env1_first_0:                 episode reward: 25.5500,                 loss: nan
env1_second_0:                 episode reward: -25.5500,                 loss: nan
Episode: 5801/10000 (58.0100%),                 avg. length: 645.0,                last time consumption/overall running time: 336.2560s / 147800.9144 s
env0_first_0:                 episode reward: -32.7500,                 loss: 0.2360
env0_second_0:                 episode reward: 32.7500,                 loss: nan
env1_first_0:                 episode reward: -25.9500,                 loss: nan
env1_second_0:                 episode reward: 25.9500,                 loss: nan
Episode: 5821/10000 (58.2100%),                 avg. length: 866.95,                last time consumption/overall running time: 452.3883s / 148253.3027 s
env0_first_0:                 episode reward: 3.8000,                 loss: 0.2466
env0_second_0:                 episode reward: -3.8000,                 loss: nan
env1_first_0:                 episode reward: 20.0000,                 loss: nan
env1_second_0:                 episode reward: -20.0000,                 loss: nan
Episode: 5841/10000 (58.4100%),                 avg. length: 875.15,                last time consumption/overall running time: 460.6993s / 148714.0020 s
env0_first_0:                 episode reward: 8.1000,                 loss: 0.2350
env0_second_0:                 episode reward: -8.1000,                 loss: nan
env1_first_0:                 episode reward: 9.0500,                 loss: nan
env1_second_0:                 episode reward: -9.0500,                 loss: nan
Episode: 5861/10000 (58.6100%),                 avg. length: 897.85,                last time consumption/overall running time: 1474.9748s / 150188.9769 s
env0_first_0:                 episode reward: 21.5000,                 loss: 0.2218
env0_second_0:                 episode reward: -21.5000,                 loss: 0.6715
env1_first_0:                 episode reward: -22.1000,                 loss: nan
env1_second_0:                 episode reward: 22.1000,                 loss: nan
Score delta: 81.2, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/5853_0.
Episode: 5881/10000 (58.8100%),                 avg. length: 466.2,                last time consumption/overall running time: 1523.5331s / 151712.5100 s
env0_first_0:                 episode reward: -51.0000,                 loss: 0.3144
env0_second_0:                 episode reward: 51.0000,                 loss: 0.6582
env1_first_0:                 episode reward: -70.1500,                 loss: nan
env1_second_0:                 episode reward: 70.1500,                 loss: nan
Score delta: 81.8, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/5874_1.
Episode: 5901/10000 (59.0100%),                 avg. length: 657.85,                last time consumption/overall running time: 345.8978s / 152058.4078 s
env0_first_0:                 episode reward: -61.7500,                 loss: 0.2221
env0_second_0:                 episode reward: 61.7500,                 loss: nan
env1_first_0:                 episode reward: -53.3000,                 loss: nan
env1_second_0:                 episode reward: 53.3000,                 loss: nan
Episode: 5921/10000 (59.2100%),                 avg. length: 317.2,                last time consumption/overall running time: 167.7954s / 152226.2033 s
env0_first_0:                 episode reward: -77.9500,                 loss: 0.2014
env0_second_0:                 episode reward: 77.9500,                 loss: nan
env1_first_0:                 episode reward: -95.8500,                 loss: nan
env1_second_0:                 episode reward: 95.8500,                 loss: nan
Episode: 5941/10000 (59.4100%),                 avg. length: 285.3,                last time consumption/overall running time: 151.4080s / 152377.6112 s
env0_first_0:                 episode reward: -51.2500,                 loss: 0.2165
env0_second_0:                 episode reward: 51.2500,                 loss: nan
env1_first_0:                 episode reward: -59.2000,                 loss: nan
env1_second_0:                 episode reward: 59.2000,                 loss: nan
Episode: 5961/10000 (59.6100%),                 avg. length: 389.75,                last time consumption/overall running time: 205.8727s / 152583.4839 s
env0_first_0:                 episode reward: -65.6500,                 loss: 0.2640
env0_second_0:                 episode reward: 65.6500,                 loss: nan
env1_first_0:                 episode reward: -72.0000,                 loss: nan
env1_second_0:                 episode reward: 72.0000,                 loss: nan
Episode: 5981/10000 (59.8100%),                 avg. length: 517.45,                last time consumption/overall running time: 273.8691s / 152857.3530 s
env0_first_0:                 episode reward: -59.6000,                 loss: 0.3373
env0_second_0:                 episode reward: 59.6000,                 loss: nan
env1_first_0:                 episode reward: -59.5500,                 loss: nan
env1_second_0:                 episode reward: 59.5500,                 loss: nan
Episode: 6001/10000 (60.0100%),                 avg. length: 539.0,                last time consumption/overall running time: 285.5275s / 153142.8805 s
env0_first_0:                 episode reward: -27.0000,                 loss: 0.4064
env0_second_0:                 episode reward: 27.0000,                 loss: nan
env1_first_0:                 episode reward: -37.6500,                 loss: nan
env1_second_0:                 episode reward: 37.6500,                 loss: nan
Episode: 6021/10000 (60.2100%),                 avg. length: 509.7,                last time consumption/overall running time: 860.5650s / 154003.4455 s
env0_first_0:                 episode reward: 17.0000,                 loss: 0.4739
env0_second_0:                 episode reward: -17.0000,                 loss: 0.6544
env1_first_0:                 episode reward: 43.6500,                 loss: nan
env1_second_0:                 episode reward: -43.6500,                 loss: nan
Score delta: 81.4, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/6019_0.
Episode: 6041/10000 (60.4100%),                 avg. length: 337.75,                last time consumption/overall running time: 177.2248s / 154180.6703 s
env0_first_0:                 episode reward: -39.8000,                 loss: nan
env0_second_0:                 episode reward: 39.8000,                 loss: 0.6853
env1_first_0:                 episode reward: -49.0000,                 loss: nan
env1_second_0:                 episode reward: 49.0000,                 loss: nan
Episode: 6061/10000 (60.6100%),                 avg. length: 250.9,                last time consumption/overall running time: 1437.4228s / 155618.0931 s
env0_first_0:                 episode reward: -79.6000,                 loss: 0.4312
env0_second_0:                 episode reward: 79.6000,                 loss: 0.6842
env1_first_0:                 episode reward: -66.8000,                 loss: nan
env1_second_0:                 episode reward: 66.8000,                 loss: nan
Score delta: 87.8, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/6046_1.
Episode: 6081/10000 (60.8100%),                 avg. length: 336.1,                last time consumption/overall running time: 176.6508s / 155794.7440 s
env0_first_0:                 episode reward: -73.1000,                 loss: 0.3800
env0_second_0:                 episode reward: 73.1000,                 loss: nan
env1_first_0:                 episode reward: -78.4500,                 loss: nan
env1_second_0:                 episode reward: 78.4500,                 loss: nan
Episode: 6101/10000 (61.0100%),                 avg. length: 394.45,                last time consumption/overall running time: 208.2261s / 156002.9701 s
env0_first_0:                 episode reward: -59.3000,                 loss: 0.3595
env0_second_0:                 episode reward: 59.3000,                 loss: nan
env1_first_0:                 episode reward: -64.2000,                 loss: nan
env1_second_0:                 episode reward: 64.2000,                 loss: nan
Episode: 6121/10000 (61.2100%),                 avg. length: 717.05,                last time consumption/overall running time: 1172.3027s / 157175.2728 s
env0_first_0:                 episode reward: 17.4500,                 loss: 0.3602
env0_second_0:                 episode reward: -17.4500,                 loss: nan
env1_first_0:                 episode reward: -6.7000,                 loss: nan
env1_second_0:                 episode reward: 6.7000,                 loss: nan
Score delta: 96.8, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/6121_0.
Episode: 6141/10000 (61.4100%),                 avg. length: 704.8,                last time consumption/overall running time: 373.2113s / 157548.4841 s
env0_first_0:                 episode reward: 9.6500,                 loss: nan
env0_second_0:                 episode reward: -9.6500,                 loss: 0.6974
env1_first_0:                 episode reward: 7.8000,                 loss: nan
env1_second_0:                 episode reward: -7.8000,                 loss: nan
Episode: 6161/10000 (61.6100%),                 avg. length: 633.6,                last time consumption/overall running time: 337.6025s / 157886.0866 s
env0_first_0:                 episode reward: -26.1000,                 loss: nan
env0_second_0:                 episode reward: 26.1000,                 loss: 0.6078
env1_first_0:                 episode reward: 17.2500,                 loss: nan
env1_second_0:                 episode reward: -17.2500,                 loss: nan
Episode: 6181/10000 (61.8100%),                 avg. length: 401.1,                last time consumption/overall running time: 1571.3926s / 159457.4792 s
env0_first_0:                 episode reward: -51.1500,                 loss: 0.4939
env0_second_0:                 episode reward: 51.1500,                 loss: 0.5884
env1_first_0:                 episode reward: -49.8000,                 loss: nan
env1_second_0:                 episode reward: 49.8000,                 loss: nan
Score delta: 106.2, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/6162_1.
Episode: 6201/10000 (62.0100%),                 avg. length: 717.1,                last time consumption/overall running time: 376.9648s / 159834.4439 s
env0_first_0:                 episode reward: -15.9000,                 loss: 0.4021
env0_second_0:                 episode reward: 15.9000,                 loss: nan
env1_first_0:                 episode reward: 11.4000,                 loss: nan
env1_second_0:                 episode reward: -11.4000,                 loss: nan
Episode: 6221/10000 (62.2100%),                 avg. length: 782.05,                last time consumption/overall running time: 413.7584s / 160248.2023 s
env0_first_0:                 episode reward: -2.9500,                 loss: 0.4205
env0_second_0:                 episode reward: 2.9500,                 loss: nan
env1_first_0:                 episode reward: 12.5000,                 loss: nan
env1_second_0:                 episode reward: -12.5000,                 loss: nan
Episode: 6241/10000 (62.4100%),                 avg. length: 323.4,                last time consumption/overall running time: 1009.9642s / 161258.1665 s
env0_first_0:                 episode reward: -16.6000,                 loss: 0.4484
env0_second_0:                 episode reward: 16.6000,                 loss: 0.6746
env1_first_0:                 episode reward: -32.5000,                 loss: nan
env1_second_0:                 episode reward: 32.5000,                 loss: nan
Score delta: 110.4, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/6224_0.
Episode: 6261/10000 (62.6100%),                 avg. length: 434.65,                last time consumption/overall running time: 1598.4055s / 162856.5720 s
env0_first_0:                 episode reward: -55.0000,                 loss: 0.4698
env0_second_0:                 episode reward: 55.0000,                 loss: 0.6550
env1_first_0:                 episode reward: -61.1000,                 loss: nan
env1_second_0:                 episode reward: 61.1000,                 loss: nan
Score delta: 83.6, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/6247_1.
Episode: 6281/10000 (62.8100%),                 avg. length: 798.45,                last time consumption/overall running time: 415.1407s / 163271.7127 s
env0_first_0:                 episode reward: -48.9000,                 loss: 0.3465
env0_second_0:                 episode reward: 48.9000,                 loss: nan
env1_first_0:                 episode reward: -39.1500,                 loss: nan
env1_second_0:                 episode reward: 39.1500,                 loss: nan
Episode: 6301/10000 (63.0100%),                 avg. length: 763.0,                last time consumption/overall running time: 401.0440s / 163672.7567 s
env0_first_0:                 episode reward: -39.2500,                 loss: 0.2976
env0_second_0:                 episode reward: 39.2500,                 loss: nan
env1_first_0:                 episode reward: -14.3500,                 loss: nan
env1_second_0:                 episode reward: 14.3500,                 loss: nan
Episode: 6321/10000 (63.2100%),                 avg. length: 946.05,                last time consumption/overall running time: 497.8786s / 164170.6353 s
env0_first_0:                 episode reward: -33.1000,                 loss: 0.2538
env0_second_0:                 episode reward: 33.1000,                 loss: nan
env1_first_0:                 episode reward: -25.4000,                 loss: nan
env1_second_0:                 episode reward: 25.4000,                 loss: nan
Episode: 6341/10000 (63.4100%),                 avg. length: 747.05,                last time consumption/overall running time: 394.8757s / 164565.5110 s
env0_first_0:                 episode reward: -34.1000,                 loss: 0.2211
env0_second_0:                 episode reward: 34.1000,                 loss: nan
env1_first_0:                 episode reward: -27.0500,                 loss: nan
env1_second_0:                 episode reward: 27.0500,                 loss: nan
Episode: 6361/10000 (63.6100%),                 avg. length: 419.4,                last time consumption/overall running time: 223.0745s / 164788.5856 s
env0_first_0:                 episode reward: -44.4500,                 loss: 0.2749
env0_second_0:                 episode reward: 44.4500,                 loss: nan
env1_first_0:                 episode reward: -63.6500,                 loss: nan
env1_second_0:                 episode reward: 63.6500,                 loss: nan
Episode: 6381/10000 (63.8100%),                 avg. length: 479.55,                last time consumption/overall running time: 253.9196s / 165042.5051 s
env0_first_0:                 episode reward: -24.9500,                 loss: 0.3358
env0_second_0:                 episode reward: 24.9500,                 loss: nan
env1_first_0:                 episode reward: -7.4500,                 loss: nan
env1_second_0:                 episode reward: 7.4500,                 loss: nan
Episode: 6401/10000 (64.0100%),                 avg. length: 622.1,                last time consumption/overall running time: 329.1562s / 165371.6614 s
env0_first_0:                 episode reward: -48.7500,                 loss: 0.4153
env0_second_0:                 episode reward: 48.7500,                 loss: nan
env1_first_0:                 episode reward: -43.2500,                 loss: nan
env1_second_0:                 episode reward: 43.2500,                 loss: nan
Episode: 6421/10000 (64.2100%),                 avg. length: 595.5,                last time consumption/overall running time: 315.0151s / 165686.6765 s
env0_first_0:                 episode reward: -41.3000,                 loss: 0.4858
env0_second_0:                 episode reward: 41.3000,                 loss: nan
env1_first_0:                 episode reward: -55.5000,                 loss: nan
env1_second_0:                 episode reward: 55.5000,                 loss: nan
Episode: 6441/10000 (64.4100%),                 avg. length: 419.45,                last time consumption/overall running time: 223.4042s / 165910.0807 s
env0_first_0:                 episode reward: 1.5500,                 loss: 0.5205
env0_second_0:                 episode reward: -1.5500,                 loss: nan
env1_first_0:                 episode reward: -10.5000,                 loss: nan
env1_second_0:                 episode reward: 10.5000,                 loss: nan
Episode: 6461/10000 (64.6100%),                 avg. length: 512.55,                last time consumption/overall running time: 273.2049s / 166183.2855 s
env0_first_0:                 episode reward: -8.2500,                 loss: 0.5712
env0_second_0:                 episode reward: 8.2500,                 loss: nan
env1_first_0:                 episode reward: 2.7000,                 loss: nan
env1_second_0:                 episode reward: -2.7000,                 loss: nan
Episode: 6481/10000 (64.8100%),                 avg. length: 448.15,                last time consumption/overall running time: 239.3283s / 166422.6138 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.6348
env0_second_0:                 episode reward: 1.2500,                 loss: nan
env1_first_0:                 episode reward: 25.5000,                 loss: nan
env1_second_0:                 episode reward: -25.5000,                 loss: nan
Episode: 6501/10000 (65.0100%),                 avg. length: 317.95,                last time consumption/overall running time: 577.2103s / 166999.8241 s
env0_first_0:                 episode reward: -10.4000,                 loss: 0.6547
env0_second_0:                 episode reward: 10.4000,                 loss: 0.5168
env1_first_0:                 episode reward: -16.3000,                 loss: nan
env1_second_0:                 episode reward: 16.3000,                 loss: nan
Score delta: 90.4, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/6498_0.
Episode: 6521/10000 (65.2100%),                 avg. length: 810.9,                last time consumption/overall running time: 1881.9618s / 168881.7860 s
env0_first_0:                 episode reward: -29.1500,                 loss: 0.6348
env0_second_0:                 episode reward: 29.1500,                 loss: 0.4088
env1_first_0:                 episode reward: -7.6500,                 loss: nan
env1_second_0:                 episode reward: 7.6500,                 loss: nan
Score delta: 102.6, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/6519_1.
Episode: 6541/10000 (65.4100%),                 avg. length: 679.8,                last time consumption/overall running time: 356.1286s / 169237.9146 s
env0_first_0:                 episode reward: -21.9000,                 loss: 0.5920
env0_second_0:                 episode reward: 21.9000,                 loss: nan
env1_first_0:                 episode reward: -12.7000,                 loss: nan
env1_second_0:                 episode reward: 12.7000,                 loss: nan
Episode: 6561/10000 (65.6100%),                 avg. length: 576.6,                last time consumption/overall running time: 301.8439s / 169539.7585 s
env0_first_0:                 episode reward: 3.7000,                 loss: 0.6457
env0_second_0:                 episode reward: -3.7000,                 loss: nan
env1_first_0:                 episode reward: 20.9500,                 loss: nan
env1_second_0:                 episode reward: -20.9500,                 loss: nan
Episode: 6581/10000 (65.8100%),                 avg. length: 490.6,                last time consumption/overall running time: 829.8479s / 170369.6064 s
env0_first_0:                 episode reward: 5.4500,                 loss: 0.6985
env0_second_0:                 episode reward: -5.4500,                 loss: 0.4262
env1_first_0:                 episode reward: -2.3000,                 loss: nan
env1_second_0:                 episode reward: 2.3000,                 loss: nan
Score delta: 97.8, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/6566_0.
Episode: 6601/10000 (66.0100%),                 avg. length: 293.3,                last time consumption/overall running time: 1637.2368s / 172006.8432 s
env0_first_0:                 episode reward: -67.2000,                 loss: 0.0930
env0_second_0:                 episode reward: 67.2000,                 loss: 0.4774
env1_first_0:                 episode reward: -71.3500,                 loss: nan
env1_second_0:                 episode reward: 71.3500,                 loss: nan
Score delta: 96.6, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/6588_1.
Episode: 6621/10000 (66.2100%),                 avg. length: 536.0,                last time consumption/overall running time: 280.8429s / 172287.6861 s
env0_first_0:                 episode reward: -75.3000,                 loss: 0.1051
env0_second_0:                 episode reward: 75.3000,                 loss: nan
env1_first_0:                 episode reward: -82.0500,                 loss: nan
env1_second_0:                 episode reward: 82.0500,                 loss: nan
Episode: 6641/10000 (66.4100%),                 avg. length: 612.55,                last time consumption/overall running time: 321.1509s / 172608.8370 s
env0_first_0:                 episode reward: -68.1500,                 loss: 0.1642
env0_second_0:                 episode reward: 68.1500,                 loss: nan
env1_first_0:                 episode reward: -75.7000,                 loss: nan
env1_second_0:                 episode reward: 75.7000,                 loss: nan
Episode: 6661/10000 (66.6100%),                 avg. length: 554.4,                last time consumption/overall running time: 290.8902s / 172899.7271 s
env0_first_0:                 episode reward: -69.0000,                 loss: 0.2000
env0_second_0:                 episode reward: 69.0000,                 loss: nan
env1_first_0:                 episode reward: -77.0500,                 loss: nan
env1_second_0:                 episode reward: 77.0500,                 loss: nan
Episode: 6681/10000 (66.8100%),                 avg. length: 368.55,                last time consumption/overall running time: 194.5135s / 173094.2407 s
env0_first_0:                 episode reward: -80.4000,                 loss: 0.2423
env0_second_0:                 episode reward: 80.4000,                 loss: nan
env1_first_0:                 episode reward: -87.1500,                 loss: nan
env1_second_0:                 episode reward: 87.1500,                 loss: nan
Episode: 6701/10000 (67.0100%),                 avg. length: 753.7,                last time consumption/overall running time: 399.0242s / 173493.2649 s
env0_first_0:                 episode reward: -60.4000,                 loss: 0.2277
env0_second_0:                 episode reward: 60.4000,                 loss: nan
env1_first_0:                 episode reward: -60.6500,                 loss: nan
env1_second_0:                 episode reward: 60.6500,                 loss: nan
Episode: 6721/10000 (67.2100%),                 avg. length: 1386.0,                last time consumption/overall running time: 731.7412s / 174225.0060 s
env0_first_0:                 episode reward: -19.0500,                 loss: 0.1763
env0_second_0:                 episode reward: 19.0500,                 loss: nan
env1_first_0:                 episode reward: -29.6500,                 loss: nan
env1_second_0:                 episode reward: 29.6500,                 loss: nan
Episode: 6741/10000 (67.4100%),                 avg. length: 1282.15,                last time consumption/overall running time: 677.7833s / 174902.7894 s
env0_first_0:                 episode reward: -25.8000,                 loss: 0.0756
env0_second_0:                 episode reward: 25.8000,                 loss: nan
env1_first_0:                 episode reward: -19.8500,                 loss: nan
env1_second_0:                 episode reward: 19.8500,                 loss: nan
Episode: 6761/10000 (67.6100%),                 avg. length: 1252.7,                last time consumption/overall running time: 662.0583s / 175564.8477 s
env0_first_0:                 episode reward: -34.2000,                 loss: 0.0394
env0_second_0:                 episode reward: 34.2000,                 loss: nan
env1_first_0:                 episode reward: -22.7000,                 loss: nan
env1_second_0:                 episode reward: 22.7000,                 loss: nan
Episode: 6781/10000 (67.8100%),                 avg. length: 829.9,                last time consumption/overall running time: 439.7352s / 176004.5829 s
env0_first_0:                 episode reward: -46.6000,                 loss: 0.0547
env0_second_0:                 episode reward: 46.6000,                 loss: nan
env1_first_0:                 episode reward: -60.6000,                 loss: nan
env1_second_0:                 episode reward: 60.6000,                 loss: nan
Episode: 6801/10000 (68.0100%),                 avg. length: 936.3,                last time consumption/overall running time: 494.8187s / 176499.4016 s
env0_first_0:                 episode reward: -44.6000,                 loss: 0.0870
env0_second_0:                 episode reward: 44.6000,                 loss: nan
env1_first_0:                 episode reward: -59.4000,                 loss: nan
env1_second_0:                 episode reward: 59.4000,                 loss: nan
Episode: 6821/10000 (68.2100%),                 avg. length: 913.9,                last time consumption/overall running time: 479.2843s / 176978.6859 s
env0_first_0:                 episode reward: -51.3500,                 loss: 0.1413
env0_second_0:                 episode reward: 51.3500,                 loss: nan
env1_first_0:                 episode reward: -57.6500,                 loss: nan
env1_second_0:                 episode reward: 57.6500,                 loss: nan
Episode: 6841/10000 (68.4100%),                 avg. length: 1017.8,                last time consumption/overall running time: 529.7561s / 177508.4421 s
env0_first_0:                 episode reward: -58.4500,                 loss: 0.1522
env0_second_0:                 episode reward: 58.4500,                 loss: nan
env1_first_0:                 episode reward: -39.5000,                 loss: nan
env1_second_0:                 episode reward: 39.5000,                 loss: nan
Episode: 6861/10000 (68.6100%),                 avg. length: 1215.9,                last time consumption/overall running time: 629.5245s / 178137.9666 s
env0_first_0:                 episode reward: -29.4500,                 loss: 0.1445
env0_second_0:                 episode reward: 29.4500,                 loss: nan
env1_first_0:                 episode reward: -42.0000,                 loss: nan
env1_second_0:                 episode reward: 42.0000,                 loss: nan
Episode: 6881/10000 (68.8100%),                 avg. length: 844.6,                last time consumption/overall running time: 437.2550s / 178575.2215 s
env0_first_0:                 episode reward: -61.6000,                 loss: 0.1237
env0_second_0:                 episode reward: 61.6000,                 loss: nan
env1_first_0:                 episode reward: -40.7500,                 loss: nan
env1_second_0:                 episode reward: 40.7500,                 loss: nan
Episode: 6901/10000 (69.0100%),                 avg. length: 1054.4,                last time consumption/overall running time: 545.5603s / 179120.7818 s
env0_first_0:                 episode reward: -45.2500,                 loss: 0.1446
env0_second_0:                 episode reward: 45.2500,                 loss: nan
env1_first_0:                 episode reward: -30.4500,                 loss: nan
env1_second_0:                 episode reward: 30.4500,                 loss: nan
Episode: 6921/10000 (69.2100%),                 avg. length: 1292.15,                last time consumption/overall running time: 675.0663s / 179795.8481 s
env0_first_0:                 episode reward: -23.8500,                 loss: 0.1481
env0_second_0:                 episode reward: 23.8500,                 loss: nan
env1_first_0:                 episode reward: -38.0500,                 loss: nan
env1_second_0:                 episode reward: 38.0500,                 loss: nan
Episode: 6941/10000 (69.4100%),                 avg. length: 870.6,                last time consumption/overall running time: 456.3762s / 180252.2242 s
env0_first_0:                 episode reward: -50.0000,                 loss: 0.1557
env0_second_0:                 episode reward: 50.0000,                 loss: nan
env1_first_0:                 episode reward: -46.3500,                 loss: nan
env1_second_0:                 episode reward: 46.3500,                 loss: nan
Episode: 6961/10000 (69.6100%),                 avg. length: 792.75,                last time consumption/overall running time: 415.4569s / 180667.6811 s
env0_first_0:                 episode reward: -57.3000,                 loss: 0.1744
env0_second_0:                 episode reward: 57.3000,                 loss: nan
env1_first_0:                 episode reward: -58.8500,                 loss: nan
env1_second_0:                 episode reward: 58.8500,                 loss: nan
Episode: 6981/10000 (69.8100%),                 avg. length: 949.45,                last time consumption/overall running time: 496.6928s / 181164.3739 s
env0_first_0:                 episode reward: -41.4500,                 loss: 0.2128
env0_second_0:                 episode reward: 41.4500,                 loss: nan
env1_first_0:                 episode reward: -55.5000,                 loss: nan
env1_second_0:                 episode reward: 55.5000,                 loss: nan
Episode: 7001/10000 (70.0100%),                 avg. length: 836.85,                last time consumption/overall running time: 437.0838s / 181601.4577 s
env0_first_0:                 episode reward: -54.8000,                 loss: 0.2104
env0_second_0:                 episode reward: 54.8000,                 loss: nan
env1_first_0:                 episode reward: -58.8500,                 loss: nan
env1_second_0:                 episode reward: 58.8500,                 loss: nan
Episode: 7021/10000 (70.2100%),                 avg. length: 932.35,                last time consumption/overall running time: 489.6395s / 182091.0972 s
env0_first_0:                 episode reward: -42.5500,                 loss: 0.2180
env0_second_0:                 episode reward: 42.5500,                 loss: nan
env1_first_0:                 episode reward: -70.5000,                 loss: nan
env1_second_0:                 episode reward: 70.5000,                 loss: nan
Episode: 7041/10000 (70.4100%),                 avg. length: 772.65,                last time consumption/overall running time: 406.0964s / 182497.1936 s
env0_first_0:                 episode reward: -57.9500,                 loss: 0.2396
env0_second_0:                 episode reward: 57.9500,                 loss: nan
env1_first_0:                 episode reward: -46.2500,                 loss: nan
env1_second_0:                 episode reward: 46.2500,                 loss: nan
Episode: 7061/10000 (70.6100%),                 avg. length: 956.2,                last time consumption/overall running time: 502.7469s / 182999.9405 s
env0_first_0:                 episode reward: -45.0500,                 loss: 0.2695
env0_second_0:                 episode reward: 45.0500,                 loss: nan
env1_first_0:                 episode reward: -51.7000,                 loss: nan
env1_second_0:                 episode reward: 51.7000,                 loss: nan
Episode: 7081/10000 (70.8100%),                 avg. length: 739.55,                last time consumption/overall running time: 391.6565s / 183391.5970 s
env0_first_0:                 episode reward: -70.7000,                 loss: 0.2770
env0_second_0:                 episode reward: 70.7000,                 loss: nan
env1_first_0:                 episode reward: -52.7500,                 loss: nan
env1_second_0:                 episode reward: 52.7500,                 loss: nan
Episode: 7101/10000 (71.0100%),                 avg. length: 575.35,                last time consumption/overall running time: 304.5878s / 183696.1849 s
env0_first_0:                 episode reward: -69.4500,                 loss: 0.3475
env0_second_0:                 episode reward: 69.4500,                 loss: nan
env1_first_0:                 episode reward: -56.4500,                 loss: nan
env1_second_0:                 episode reward: 56.4500,                 loss: nan
Episode: 7121/10000 (71.2100%),                 avg. length: 1052.65,                last time consumption/overall running time: 554.2832s / 184250.4680 s
env0_first_0:                 episode reward: -31.8000,                 loss: 0.3911
env0_second_0:                 episode reward: 31.8000,                 loss: nan
env1_first_0:                 episode reward: -39.6000,                 loss: nan
env1_second_0:                 episode reward: 39.6000,                 loss: nan
Episode: 7141/10000 (71.4100%),                 avg. length: 837.0,                last time consumption/overall running time: 439.0270s / 184689.4951 s
env0_first_0:                 episode reward: -48.4500,                 loss: 0.4013
env0_second_0:                 episode reward: 48.4500,                 loss: nan
env1_first_0:                 episode reward: -63.7000,                 loss: nan
env1_second_0:                 episode reward: 63.7000,                 loss: nan
Episode: 7161/10000 (71.6100%),                 avg. length: 698.2,                last time consumption/overall running time: 365.1930s / 185054.6881 s
env0_first_0:                 episode reward: -43.2000,                 loss: 0.4066
env0_second_0:                 episode reward: 43.2000,                 loss: nan
env1_first_0:                 episode reward: -70.8500,                 loss: nan
env1_second_0:                 episode reward: 70.8500,                 loss: nan
Episode: 7181/10000 (71.8100%),                 avg. length: 876.55,                last time consumption/overall running time: 458.3684s / 185513.0564 s
env0_first_0:                 episode reward: -37.7500,                 loss: 0.4222
env0_second_0:                 episode reward: 37.7500,                 loss: nan
env1_first_0:                 episode reward: -57.4500,                 loss: nan
env1_second_0:                 episode reward: 57.4500,                 loss: nan
Episode: 7201/10000 (72.0100%),                 avg. length: 688.35,                last time consumption/overall running time: 352.7862s / 185865.8427 s
env0_first_0:                 episode reward: -58.4500,                 loss: 0.4912
env0_second_0:                 episode reward: 58.4500,                 loss: nan
env1_first_0:                 episode reward: -56.6000,                 loss: nan
env1_second_0:                 episode reward: 56.6000,                 loss: nan
Episode: 7221/10000 (72.2100%),                 avg. length: 980.5,                last time consumption/overall running time: 484.5174s / 186350.3601 s
env0_first_0:                 episode reward: -39.9500,                 loss: 0.4607
env0_second_0:                 episode reward: 39.9500,                 loss: nan
env1_first_0:                 episode reward: -48.6500,                 loss: nan
env1_second_0:                 episode reward: 48.6500,                 loss: nan
Episode: 7241/10000 (72.4100%),                 avg. length: 742.2,                last time consumption/overall running time: 367.2152s / 186717.5753 s
env0_first_0:                 episode reward: -35.1000,                 loss: 0.4521
env0_second_0:                 episode reward: 35.1000,                 loss: nan
env1_first_0:                 episode reward: -52.0000,                 loss: nan
env1_second_0:                 episode reward: 52.0000,                 loss: nan
Episode: 7261/10000 (72.6100%),                 avg. length: 739.45,                last time consumption/overall running time: 367.3855s / 187084.9607 s
env0_first_0:                 episode reward: -48.6000,                 loss: 0.4749
env0_second_0:                 episode reward: 48.6000,                 loss: nan
env1_first_0:                 episode reward: -42.9500,                 loss: nan
env1_second_0:                 episode reward: 42.9500,                 loss: nan
Episode: 7281/10000 (72.8100%),                 avg. length: 799.45,                last time consumption/overall running time: 399.5446s / 187484.5053 s
env0_first_0:                 episode reward: -36.4000,                 loss: 0.5125
env0_second_0:                 episode reward: 36.4000,                 loss: nan
env1_first_0:                 episode reward: -43.5000,                 loss: nan
env1_second_0:                 episode reward: 43.5000,                 loss: nan
Episode: 7301/10000 (73.0100%),                 avg. length: 856.15,                last time consumption/overall running time: 431.1107s / 187915.6161 s
env0_first_0:                 episode reward: -37.5500,                 loss: 0.5531
env0_second_0:                 episode reward: 37.5500,                 loss: nan
env1_first_0:                 episode reward: -34.0000,                 loss: nan
env1_second_0:                 episode reward: 34.0000,                 loss: nan
Episode: 7321/10000 (73.2100%),                 avg. length: 668.3,                last time consumption/overall running time: 336.8231s / 188252.4391 s
env0_first_0:                 episode reward: -54.1000,                 loss: 0.5500
env0_second_0:                 episode reward: 54.1000,                 loss: nan
env1_first_0:                 episode reward: -50.6500,                 loss: nan
env1_second_0:                 episode reward: 50.6500,                 loss: nan
Episode: 7341/10000 (73.4100%),                 avg. length: 766.05,                last time consumption/overall running time: 386.7726s / 188639.2118 s
env0_first_0:                 episode reward: -2.8000,                 loss: 0.5302
env0_second_0:                 episode reward: 2.8000,                 loss: nan
env1_first_0:                 episode reward: -15.8000,                 loss: nan
env1_second_0:                 episode reward: 15.8000,                 loss: nan
Episode: 7361/10000 (73.6100%),                 avg. length: 589.85,                last time consumption/overall running time: 299.0124s / 188938.2241 s
env0_first_0:                 episode reward: -26.3500,                 loss: 0.5382
env0_second_0:                 episode reward: 26.3500,                 loss: nan
env1_first_0:                 episode reward: -45.2500,                 loss: nan
env1_second_0:                 episode reward: 45.2500,                 loss: nan
Episode: 7381/10000 (73.8100%),                 avg. length: 536.6,                last time consumption/overall running time: 271.8810s / 189210.1051 s
env0_first_0:                 episode reward: -59.2500,                 loss: 0.5554
env0_second_0:                 episode reward: 59.2500,                 loss: nan
env1_first_0:                 episode reward: -32.8000,                 loss: nan
env1_second_0:                 episode reward: 32.8000,                 loss: nan
Episode: 7401/10000 (74.0100%),                 avg. length: 616.3,                last time consumption/overall running time: 312.0831s / 189522.1882 s
env0_first_0:                 episode reward: -35.4500,                 loss: 0.6006
env0_second_0:                 episode reward: 35.4500,                 loss: nan
env1_first_0:                 episode reward: -27.9000,                 loss: nan
env1_second_0:                 episode reward: 27.9000,                 loss: nan
Episode: 7421/10000 (74.2100%),                 avg. length: 541.65,                last time consumption/overall running time: 274.7151s / 189796.9033 s
env0_first_0:                 episode reward: -44.4500,                 loss: 0.6208
env0_second_0:                 episode reward: 44.4500,                 loss: nan
env1_first_0:                 episode reward: -37.9000,                 loss: nan
env1_second_0:                 episode reward: 37.9000,                 loss: nan
Episode: 7441/10000 (74.4100%),                 avg. length: 496.7,                last time consumption/overall running time: 251.5736s / 190048.4769 s
env0_first_0:                 episode reward: -17.8500,                 loss: 0.6797
env0_second_0:                 episode reward: 17.8500,                 loss: nan
env1_first_0:                 episode reward: -40.4500,                 loss: nan
env1_second_0:                 episode reward: 40.4500,                 loss: nan
Episode: 7461/10000 (74.6100%),                 avg. length: 480.65,                last time consumption/overall running time: 242.3646s / 190290.8415 s
env0_first_0:                 episode reward: -25.9000,                 loss: 0.7741
env0_second_0:                 episode reward: 25.9000,                 loss: nan
env1_first_0:                 episode reward: -27.0500,                 loss: nan
env1_second_0:                 episode reward: 27.0500,                 loss: nan
Episode: 7481/10000 (74.8100%),                 avg. length: 458.8,                last time consumption/overall running time: 230.3288s / 190521.1703 s
env0_first_0:                 episode reward: -22.6500,                 loss: 0.8198
env0_second_0:                 episode reward: 22.6500,                 loss: nan
env1_first_0:                 episode reward: -23.6500,                 loss: nan
env1_second_0:                 episode reward: 23.6500,                 loss: nan
Episode: 7501/10000 (75.0100%),                 avg. length: 383.9,                last time consumption/overall running time: 193.0259s / 190714.1962 s
env0_first_0:                 episode reward: -41.4000,                 loss: 0.9425
env0_second_0:                 episode reward: 41.4000,                 loss: nan
env1_first_0:                 episode reward: -33.5500,                 loss: nan
env1_second_0:                 episode reward: 33.5500,                 loss: nan
Episode: 7521/10000 (75.2100%),                 avg. length: 546.0,                last time consumption/overall running time: 274.4940s / 190988.6902 s
env0_first_0:                 episode reward: -35.3500,                 loss: 1.0317
env0_second_0:                 episode reward: 35.3500,                 loss: nan
env1_first_0:                 episode reward: -49.6500,                 loss: nan
env1_second_0:                 episode reward: 49.6500,                 loss: nan
Episode: 7541/10000 (75.4100%),                 avg. length: 370.55,                last time consumption/overall running time: 186.3427s / 191175.0329 s
env0_first_0:                 episode reward: -21.7500,                 loss: 1.0458
env0_second_0:                 episode reward: 21.7500,                 loss: nan
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 7561/10000 (75.6100%),                 avg. length: 460.0,                last time consumption/overall running time: 230.7517s / 191405.7846 s
env0_first_0:                 episode reward: 11.0000,                 loss: 1.0820
env0_second_0:                 episode reward: -11.0000,                 loss: nan
env1_first_0:                 episode reward: -12.5500,                 loss: nan
env1_second_0:                 episode reward: 12.5500,                 loss: nan
Episode: 7581/10000 (75.8100%),                 avg. length: 329.9,                last time consumption/overall running time: 165.5425s / 191571.3271 s
env0_first_0:                 episode reward: -24.2000,                 loss: 1.0434
env0_second_0:                 episode reward: 24.2000,                 loss: nan
env1_first_0:                 episode reward: -29.9500,                 loss: nan
env1_second_0:                 episode reward: 29.9500,                 loss: nan
Episode: 7601/10000 (76.0100%),                 avg. length: 316.75,                last time consumption/overall running time: 158.6975s / 191730.0246 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.9684
env0_second_0:                 episode reward: -0.5500,                 loss: nan
env1_first_0:                 episode reward: -6.6500,                 loss: nan
env1_second_0:                 episode reward: 6.6500,                 loss: nan
Episode: 7621/10000 (76.2100%),                 avg. length: 365.0,                last time consumption/overall running time: 182.8374s / 191912.8620 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.9872
env0_second_0:                 episode reward: -0.5000,                 loss: nan
env1_first_0:                 episode reward: 19.9500,                 loss: nan
env1_second_0:                 episode reward: -19.9500,                 loss: nan
Episode: 7641/10000 (76.4100%),                 avg. length: 408.3,                last time consumption/overall running time: 202.9975s / 192115.8595 s
env0_first_0:                 episode reward: -31.5500,                 loss: 1.0347
env0_second_0:                 episode reward: 31.5500,                 loss: nan
env1_first_0:                 episode reward: -41.1000,                 loss: nan
env1_second_0:                 episode reward: 41.1000,                 loss: nan
Episode: 7661/10000 (76.6100%),                 avg. length: 447.15,                last time consumption/overall running time: 690.6824s / 192806.5419 s
env0_first_0:                 episode reward: 39.9500,                 loss: 1.0165
env0_second_0:                 episode reward: -39.9500,                 loss: 0.4713
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Score delta: 86.8, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/7659_0.
Episode: 7681/10000 (76.8100%),                 avg. length: 528.15,                last time consumption/overall running time: 259.6072s / 193066.1491 s
env0_first_0:                 episode reward: 21.4000,                 loss: nan
env0_second_0:                 episode reward: -21.4000,                 loss: 0.5297
env1_first_0:                 episode reward: 19.4000,                 loss: nan
env1_second_0:                 episode reward: -19.4000,                 loss: nan
Episode: 7701/10000 (77.0100%),                 avg. length: 544.65,                last time consumption/overall running time: 267.9852s / 193334.1343 s
env0_first_0:                 episode reward: -2.4500,                 loss: nan
env0_second_0:                 episode reward: 2.4500,                 loss: 0.5989
env1_first_0:                 episode reward: -22.3500,                 loss: nan
env1_second_0:                 episode reward: 22.3500,                 loss: nan
Episode: 7721/10000 (77.2100%),                 avg. length: 433.55,                last time consumption/overall running time: 214.1662s / 193548.3005 s
env0_first_0:                 episode reward: -0.4500,                 loss: nan
env0_second_0:                 episode reward: 0.4500,                 loss: 0.6050
env1_first_0:                 episode reward: 22.9500,                 loss: nan
env1_second_0:                 episode reward: -22.9500,                 loss: nan
Episode: 7741/10000 (77.4100%),                 avg. length: 605.8,                last time consumption/overall running time: 1749.8202s / 195298.1207 s
env0_first_0:                 episode reward: -67.4000,                 loss: 0.7733
env0_second_0:                 episode reward: 67.4000,                 loss: 0.5999
env1_first_0:                 episode reward: -58.5000,                 loss: nan
env1_second_0:                 episode reward: 58.5000,                 loss: nan
Score delta: 100.4, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/7726_1.
Episode: 7761/10000 (77.6100%),                 avg. length: 692.75,                last time consumption/overall running time: 346.0482s / 195644.1689 s
env0_first_0:                 episode reward: -59.5500,                 loss: 0.7069
env0_second_0:                 episode reward: 59.5500,                 loss: nan
env1_first_0:                 episode reward: -54.8000,                 loss: nan
env1_second_0:                 episode reward: 54.8000,                 loss: nan
Episode: 7781/10000 (77.8100%),                 avg. length: 1094.8,                last time consumption/overall running time: 544.2279s / 196188.3968 s
env0_first_0:                 episode reward: -23.5500,                 loss: 0.5688
env0_second_0:                 episode reward: 23.5500,                 loss: nan
env1_first_0:                 episode reward: -17.8000,                 loss: nan
env1_second_0:                 episode reward: 17.8000,                 loss: nan
Episode: 7801/10000 (78.0100%),                 avg. length: 568.4,                last time consumption/overall running time: 284.6894s / 196473.0863 s
env0_first_0:                 episode reward: -24.5500,                 loss: 0.4065
env0_second_0:                 episode reward: 24.5500,                 loss: nan
env1_first_0:                 episode reward: -37.5500,                 loss: nan
env1_second_0:                 episode reward: 37.5500,                 loss: nan
Episode: 7821/10000 (78.2100%),                 avg. length: 362.15,                last time consumption/overall running time: 182.7638s / 196655.8501 s
env0_first_0:                 episode reward: -18.9500,                 loss: 0.4108
env0_second_0:                 episode reward: 18.9500,                 loss: nan
env1_first_0:                 episode reward: -23.0000,                 loss: nan
env1_second_0:                 episode reward: 23.0000,                 loss: nan
Episode: 7841/10000 (78.4100%),                 avg. length: 459.55,                last time consumption/overall running time: 230.0710s / 196885.9211 s
env0_first_0:                 episode reward: -6.3500,                 loss: 0.4520
env0_second_0:                 episode reward: 6.3500,                 loss: nan
env1_first_0:                 episode reward: -25.7000,                 loss: nan
env1_second_0:                 episode reward: 25.7000,                 loss: nan
Episode: 7861/10000 (78.6100%),                 avg. length: 295.0,                last time consumption/overall running time: 148.1424s / 197034.0635 s
env0_first_0:                 episode reward: -17.9500,                 loss: 0.5478
env0_second_0:                 episode reward: 17.9500,                 loss: nan
env1_first_0:                 episode reward: -27.3500,                 loss: nan
env1_second_0:                 episode reward: 27.3500,                 loss: nan
Episode: 7881/10000 (78.8100%),                 avg. length: 323.7,                last time consumption/overall running time: 750.1844s / 197784.2479 s
env0_first_0:                 episode reward: 44.4000,                 loss: 0.6184
env0_second_0:                 episode reward: -44.4000,                 loss: 0.7407
env1_first_0:                 episode reward: 28.4000,                 loss: nan
env1_second_0:                 episode reward: -28.4000,                 loss: nan
Score delta: 82.6, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/7873_0.
Episode: 7901/10000 (79.0100%),                 avg. length: 478.45,                last time consumption/overall running time: 240.0541s / 198024.3020 s
env0_first_0:                 episode reward: 7.1000,                 loss: nan
env0_second_0:                 episode reward: -7.1000,                 loss: 0.7030
env1_first_0:                 episode reward: 17.4500,                 loss: nan
env1_second_0:                 episode reward: -17.4500,                 loss: nan
Episode: 7921/10000 (79.2100%),                 avg. length: 500.5,                last time consumption/overall running time: 1758.0089s / 199782.3109 s
env0_first_0:                 episode reward: -30.4000,                 loss: 0.5731
env0_second_0:                 episode reward: 30.4000,                 loss: 0.6935
env1_first_0:                 episode reward: -15.8500,                 loss: nan
env1_second_0:                 episode reward: 15.8500,                 loss: nan
Score delta: 93.4, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/7917_1.
Episode: 7941/10000 (79.4100%),                 avg. length: 955.5,                last time consumption/overall running time: 470.4099s / 200252.7208 s
env0_first_0:                 episode reward: -55.0000,                 loss: 0.5598
env0_second_0:                 episode reward: 55.0000,                 loss: nan
env1_first_0:                 episode reward: -66.1000,                 loss: nan
env1_second_0:                 episode reward: 66.1000,                 loss: nan
Episode: 7961/10000 (79.6100%),                 avg. length: 894.3,                last time consumption/overall running time: 439.7029s / 200692.4238 s
env0_first_0:                 episode reward: -58.2000,                 loss: 0.5129
env0_second_0:                 episode reward: 58.2000,                 loss: nan
env1_first_0:                 episode reward: -55.8500,                 loss: nan
env1_second_0:                 episode reward: 55.8500,                 loss: nan
Episode: 7981/10000 (79.8100%),                 avg. length: 886.7,                last time consumption/overall running time: 435.7314s / 201128.1551 s
env0_first_0:                 episode reward: -47.5000,                 loss: 0.4136
env0_second_0:                 episode reward: 47.5000,                 loss: nan
env1_first_0:                 episode reward: -58.2000,                 loss: nan
env1_second_0:                 episode reward: 58.2000,                 loss: nan
Episode: 8001/10000 (80.0100%),                 avg. length: 904.9,                last time consumption/overall running time: 444.1750s / 201572.3301 s
env0_first_0:                 episode reward: -23.8000,                 loss: 0.3440
env0_second_0:                 episode reward: 23.8000,                 loss: nan
env1_first_0:                 episode reward: -13.3500,                 loss: nan
env1_second_0:                 episode reward: 13.3500,                 loss: nan
Episode: 8021/10000 (80.2100%),                 avg. length: 893.6,                last time consumption/overall running time: 439.7643s / 202012.0944 s
env0_first_0:                 episode reward: 12.2500,                 loss: 0.3713
env0_second_0:                 episode reward: -12.2500,                 loss: nan
env1_first_0:                 episode reward: 5.9000,                 loss: nan
env1_second_0:                 episode reward: -5.9000,                 loss: nan
Episode: 8041/10000 (80.4100%),                 avg. length: 634.9,                last time consumption/overall running time: 1166.6957s / 203178.7901 s
env0_first_0:                 episode reward: 6.0500,                 loss: 0.3815
env0_second_0:                 episode reward: -6.0500,                 loss: 0.4169
env1_first_0:                 episode reward: 13.3000,                 loss: nan
env1_second_0:                 episode reward: -13.3000,                 loss: nan
Score delta: 83.0, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/8023_0.
Episode: 8061/10000 (80.6100%),                 avg. length: 591.1,                last time consumption/overall running time: 295.6775s / 203474.4675 s
env0_first_0:                 episode reward: -12.0500,                 loss: nan
env0_second_0:                 episode reward: 12.0500,                 loss: 0.4632
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 8081/10000 (80.8100%),                 avg. length: 709.85,                last time consumption/overall running time: 352.9780s / 203827.4455 s
env0_first_0:                 episode reward: -16.4000,                 loss: nan
env0_second_0:                 episode reward: 16.4000,                 loss: 0.5753
env1_first_0:                 episode reward: 1.7500,                 loss: nan
env1_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 8101/10000 (81.0100%),                 avg. length: 609.55,                last time consumption/overall running time: 1846.4306s / 205673.8761 s
env0_first_0:                 episode reward: -71.3500,                 loss: 0.2199
env0_second_0:                 episode reward: 71.3500,                 loss: 0.6332
env1_first_0:                 episode reward: -71.9500,                 loss: nan
env1_second_0:                 episode reward: 71.9500,                 loss: nan
Score delta: 87.8, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/8082_1.
Episode: 8121/10000 (81.2100%),                 avg. length: 1279.4,                last time consumption/overall running time: 637.4120s / 206311.2881 s
env0_first_0:                 episode reward: -20.8500,                 loss: 0.1737
env0_second_0:                 episode reward: 20.8500,                 loss: nan
env1_first_0:                 episode reward: -26.5500,                 loss: nan
env1_second_0:                 episode reward: 26.5500,                 loss: nan
Episode: 8141/10000 (81.4100%),                 avg. length: 678.1,                last time consumption/overall running time: 339.6604s / 206650.9485 s
env0_first_0:                 episode reward: -73.2500,                 loss: 0.1905
env0_second_0:                 episode reward: 73.2500,                 loss: nan
env1_first_0:                 episode reward: -73.7500,                 loss: nan
env1_second_0:                 episode reward: 73.7500,                 loss: nan
Episode: 8161/10000 (81.6100%),                 avg. length: 638.8,                last time consumption/overall running time: 320.3811s / 206971.3296 s
env0_first_0:                 episode reward: -70.4000,                 loss: 0.1958
env0_second_0:                 episode reward: 70.4000,                 loss: nan
env1_first_0:                 episode reward: -68.8500,                 loss: nan
env1_second_0:                 episode reward: 68.8500,                 loss: nan
Episode: 8181/10000 (81.8100%),                 avg. length: 428.55,                last time consumption/overall running time: 215.7698s / 207187.0993 s
env0_first_0:                 episode reward: -53.7500,                 loss: 0.2417
env0_second_0:                 episode reward: 53.7500,                 loss: nan
env1_first_0:                 episode reward: -71.0500,                 loss: nan
env1_second_0:                 episode reward: 71.0500,                 loss: nan
Episode: 8201/10000 (82.0100%),                 avg. length: 622.1,                last time consumption/overall running time: 310.3178s / 207497.4171 s
env0_first_0:                 episode reward: -70.2000,                 loss: 0.3391
env0_second_0:                 episode reward: 70.2000,                 loss: nan
env1_first_0:                 episode reward: -71.5000,                 loss: nan
env1_second_0:                 episode reward: 71.5000,                 loss: nan
Episode: 8221/10000 (82.2100%),                 avg. length: 676.3,                last time consumption/overall running time: 338.0082s / 207835.4253 s
env0_first_0:                 episode reward: -42.4000,                 loss: 0.4051
env0_second_0:                 episode reward: 42.4000,                 loss: nan
env1_first_0:                 episode reward: -53.2500,                 loss: nan
env1_second_0:                 episode reward: 53.2500,                 loss: nan
Episode: 8241/10000 (82.4100%),                 avg. length: 671.45,                last time consumption/overall running time: 336.8372s / 208172.2625 s
env0_first_0:                 episode reward: -32.3000,                 loss: 0.4352
env0_second_0:                 episode reward: 32.3000,                 loss: nan
env1_first_0:                 episode reward: -59.2500,                 loss: nan
env1_second_0:                 episode reward: 59.2500,                 loss: nan
Episode: 8261/10000 (82.6100%),                 avg. length: 656.4,                last time consumption/overall running time: 326.2275s / 208498.4900 s
env0_first_0:                 episode reward: -34.3500,                 loss: 0.4413
env0_second_0:                 episode reward: 34.3500,                 loss: nan
env1_first_0:                 episode reward: -58.9500,                 loss: nan
env1_second_0:                 episode reward: 58.9500,                 loss: nan
Episode: 8281/10000 (82.8100%),                 avg. length: 544.45,                last time consumption/overall running time: 270.2947s / 208768.7848 s
env0_first_0:                 episode reward: -57.8000,                 loss: 0.4425
env0_second_0:                 episode reward: 57.8000,                 loss: nan
env1_first_0:                 episode reward: -47.5500,                 loss: nan
env1_second_0:                 episode reward: 47.5500,                 loss: nan
Episode: 8301/10000 (83.0100%),                 avg. length: 534.55,                last time consumption/overall running time: 265.8024s / 209034.5872 s
env0_first_0:                 episode reward: -47.4500,                 loss: 0.4481
env0_second_0:                 episode reward: 47.4500,                 loss: nan
env1_first_0:                 episode reward: -39.3000,                 loss: nan
env1_second_0:                 episode reward: 39.3000,                 loss: nan
Episode: 8321/10000 (83.2100%),                 avg. length: 698.0,                last time consumption/overall running time: 345.5377s / 209380.1249 s
env0_first_0:                 episode reward: -24.1000,                 loss: 0.4669
env0_second_0:                 episode reward: 24.1000,                 loss: nan
env1_first_0:                 episode reward: -33.9500,                 loss: nan
env1_second_0:                 episode reward: 33.9500,                 loss: nan
Episode: 8341/10000 (83.4100%),                 avg. length: 598.75,                last time consumption/overall running time: 297.0334s / 209677.1583 s
env0_first_0:                 episode reward: -9.0000,                 loss: 0.4903
env0_second_0:                 episode reward: 9.0000,                 loss: nan
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 8361/10000 (83.6100%),                 avg. length: 397.65,                last time consumption/overall running time: 197.8388s / 209874.9972 s
env0_first_0:                 episode reward: 15.2500,                 loss: 0.4745
env0_second_0:                 episode reward: -15.2500,                 loss: nan
env1_first_0:                 episode reward: 13.6000,                 loss: nan
env1_second_0:                 episode reward: -13.6000,                 loss: nan
Episode: 8381/10000 (83.8100%),                 avg. length: 488.6,                last time consumption/overall running time: 1198.1987s / 211073.1959 s
env0_first_0:                 episode reward: -24.9000,                 loss: 0.4455
env0_second_0:                 episode reward: 24.9000,                 loss: 0.6506
env1_first_0:                 episode reward: -12.8500,                 loss: nan
env1_second_0:                 episode reward: 12.8500,                 loss: nan
Score delta: 86.4, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/8368_0.
Episode: 8401/10000 (84.0100%),                 avg. length: 624.65,                last time consumption/overall running time: 1909.1823s / 212982.3782 s
env0_first_0:                 episode reward: -56.1000,                 loss: 0.4070
env0_second_0:                 episode reward: 56.1000,                 loss: 0.6624
env1_first_0:                 episode reward: -49.8000,                 loss: nan
env1_second_0:                 episode reward: 49.8000,                 loss: nan
Score delta: 84.2, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/8391_1.
Episode: 8421/10000 (84.2100%),                 avg. length: 654.25,                last time consumption/overall running time: 328.3908s / 213310.7689 s
env0_first_0:                 episode reward: -44.8500,                 loss: 0.2930
env0_second_0:                 episode reward: 44.8500,                 loss: nan
env1_first_0:                 episode reward: -58.8000,                 loss: nan
env1_second_0:                 episode reward: 58.8000,                 loss: nan
Episode: 8441/10000 (84.4100%),                 avg. length: 599.7,                last time consumption/overall running time: 302.3065s / 213613.0754 s
env0_first_0:                 episode reward: -44.9500,                 loss: 0.2676
env0_second_0:                 episode reward: 44.9500,                 loss: nan
env1_first_0:                 episode reward: -21.4000,                 loss: nan
env1_second_0:                 episode reward: 21.4000,                 loss: nan
Episode: 8461/10000 (84.6100%),                 avg. length: 615.6,                last time consumption/overall running time: 310.2702s / 213923.3457 s
env0_first_0:                 episode reward: -13.1500,                 loss: 0.2645
env0_second_0:                 episode reward: 13.1500,                 loss: nan
env1_first_0:                 episode reward: 16.6500,                 loss: nan
env1_second_0:                 episode reward: -16.6500,                 loss: nan
Episode: 8481/10000 (84.8100%),                 avg. length: 918.2,                last time consumption/overall running time: 1262.4210s / 215185.7666 s
env0_first_0:                 episode reward: -18.3500,                 loss: 0.2368
env0_second_0:                 episode reward: 18.3500,                 loss: 0.6664
env1_first_0:                 episode reward: -24.5000,                 loss: nan
env1_second_0:                 episode reward: 24.5000,                 loss: nan
Score delta: 93.4, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/8464_0.
Episode: 8501/10000 (85.0100%),                 avg. length: 921.6,                last time consumption/overall running time: 460.8348s / 215646.6014 s
env0_first_0:                 episode reward: -10.6500,                 loss: nan
env0_second_0:                 episode reward: 10.6500,                 loss: 0.3943
env1_first_0:                 episode reward: -4.9500,                 loss: nan
env1_second_0:                 episode reward: 4.9500,                 loss: nan
Episode: 8521/10000 (85.2100%),                 avg. length: 407.25,                last time consumption/overall running time: 1809.7409s / 217456.3423 s
env0_first_0:                 episode reward: -44.4000,                 loss: 0.3539
env0_second_0:                 episode reward: 44.4000,                 loss: 0.3967
env1_first_0:                 episode reward: -32.1000,                 loss: nan
env1_second_0:                 episode reward: 32.1000,                 loss: nan
Score delta: 89.8, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/8519_1.
Episode: 8541/10000 (85.4100%),                 avg. length: 570.05,                last time consumption/overall running time: 269.4966s / 217725.8389 s
env0_first_0:                 episode reward: -53.8000,                 loss: 0.2664
env0_second_0:                 episode reward: 53.8000,                 loss: nan
env1_first_0:                 episode reward: -63.2500,                 loss: nan
env1_second_0:                 episode reward: 63.2500,                 loss: nan
Episode: 8561/10000 (85.6100%),                 avg. length: 809.85,                last time consumption/overall running time: 380.7852s / 218106.6241 s
env0_first_0:                 episode reward: -30.5000,                 loss: 0.2443
env0_second_0:                 episode reward: 30.5000,                 loss: nan
env1_first_0:                 episode reward: -27.9000,                 loss: nan
env1_second_0:                 episode reward: 27.9000,                 loss: nan
Episode: 8581/10000 (85.8100%),                 avg. length: 445.05,                last time consumption/overall running time: 210.2569s / 218316.8810 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.3199
env0_second_0:                 episode reward: -0.3000,                 loss: nan
env1_first_0:                 episode reward: -60.4000,                 loss: nan
env1_second_0:                 episode reward: 60.4000,                 loss: nan
Episode: 8601/10000 (86.0100%),                 avg. length: 452.6,                last time consumption/overall running time: 214.7869s / 218531.6680 s
env0_first_0:                 episode reward: -26.8500,                 loss: 0.3636
env0_second_0:                 episode reward: 26.8500,                 loss: nan
env1_first_0:                 episode reward: -44.6500,                 loss: nan
env1_second_0:                 episode reward: 44.6500,                 loss: nan
Episode: 8621/10000 (86.2100%),                 avg. length: 390.95,                last time consumption/overall running time: 185.4730s / 218717.1410 s
env0_first_0:                 episode reward: -22.1000,                 loss: 0.4368
env0_second_0:                 episode reward: 22.1000,                 loss: nan
env1_first_0:                 episode reward: 6.1500,                 loss: nan
env1_second_0:                 episode reward: -6.1500,                 loss: nan
Episode: 8641/10000 (86.4100%),                 avg. length: 392.75,                last time consumption/overall running time: 186.2230s / 218903.3640 s
env0_first_0:                 episode reward: -8.4500,                 loss: 0.4971
env0_second_0:                 episode reward: 8.4500,                 loss: nan
env1_first_0:                 episode reward: -25.9000,                 loss: nan
env1_second_0:                 episode reward: 25.9000,                 loss: nan
Episode: 8661/10000 (86.6100%),                 avg. length: 453.35,                last time consumption/overall running time: 917.1025s / 219820.4665 s
env0_first_0:                 episode reward: 26.4500,                 loss: 0.5680
env0_second_0:                 episode reward: -26.4500,                 loss: 0.4215
env1_first_0:                 episode reward: 14.4500,                 loss: nan
env1_second_0:                 episode reward: -14.4500,                 loss: nan
Score delta: 88.0, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/8655_0.
Episode: 8681/10000 (86.8100%),                 avg. length: 722.4,                last time consumption/overall running time: 1952.4077s / 221772.8742 s
env0_first_0:                 episode reward: -54.1000,                 loss: 0.3700
env0_second_0:                 episode reward: 54.1000,                 loss: 0.4414
env1_first_0:                 episode reward: -24.1500,                 loss: nan
env1_second_0:                 episode reward: 24.1500,                 loss: nan
Score delta: 102.8, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/8676_1.
Episode: 8701/10000 (87.0100%),                 avg. length: 635.35,                last time consumption/overall running time: 303.4207s / 222076.2950 s
env0_first_0:                 episode reward: -74.8000,                 loss: 0.2826
env0_second_0:                 episode reward: 74.8000,                 loss: nan
env1_first_0:                 episode reward: -71.1500,                 loss: nan
env1_second_0:                 episode reward: 71.1500,                 loss: nan
Episode: 8721/10000 (87.2100%),                 avg. length: 698.55,                last time consumption/overall running time: 332.3987s / 222408.6937 s
env0_first_0:                 episode reward: -57.7000,                 loss: 0.2763
env0_second_0:                 episode reward: 57.7000,                 loss: nan
env1_first_0:                 episode reward: -59.8500,                 loss: nan
env1_second_0:                 episode reward: 59.8500,                 loss: nan
Episode: 8741/10000 (87.4100%),                 avg. length: 1104.8,                last time consumption/overall running time: 521.2604s / 222929.9541 s
env0_first_0:                 episode reward: -21.5500,                 loss: 0.2272
env0_second_0:                 episode reward: 21.5500,                 loss: nan
env1_first_0:                 episode reward: -35.8000,                 loss: nan
env1_second_0:                 episode reward: 35.8000,                 loss: nan
Episode: 8761/10000 (87.6100%),                 avg. length: 824.45,                last time consumption/overall running time: 388.5631s / 223318.5172 s
env0_first_0:                 episode reward: -35.9500,                 loss: 0.1946
env0_second_0:                 episode reward: 35.9500,                 loss: nan
env1_first_0:                 episode reward: -46.1500,                 loss: nan
env1_second_0:                 episode reward: 46.1500,                 loss: nan
Episode: 8781/10000 (87.8100%),                 avg. length: 738.55,                last time consumption/overall running time: 348.7497s / 223667.2669 s
env0_first_0:                 episode reward: -41.7000,                 loss: 0.2238
env0_second_0:                 episode reward: 41.7000,                 loss: nan
env1_first_0:                 episode reward: -66.4500,                 loss: nan
env1_second_0:                 episode reward: 66.4500,                 loss: nan
Episode: 8801/10000 (88.0100%),                 avg. length: 752.0,                last time consumption/overall running time: 353.8264s / 224021.0933 s
env0_first_0:                 episode reward: -51.7500,                 loss: 0.2364
env0_second_0:                 episode reward: 51.7500,                 loss: nan
env1_first_0:                 episode reward: -51.0500,                 loss: nan
env1_second_0:                 episode reward: 51.0500,                 loss: nan
Episode: 8821/10000 (88.2100%),                 avg. length: 959.45,                last time consumption/overall running time: 447.8636s / 224468.9569 s
env0_first_0:                 episode reward: -42.0000,                 loss: 0.2613
env0_second_0:                 episode reward: 42.0000,                 loss: nan
env1_first_0:                 episode reward: -35.0500,                 loss: nan
env1_second_0:                 episode reward: 35.0500,                 loss: nan
Episode: 8841/10000 (88.4100%),                 avg. length: 1316.45,                last time consumption/overall running time: 616.7791s / 225085.7360 s
env0_first_0:                 episode reward: -26.5000,                 loss: 0.2082
env0_second_0:                 episode reward: 26.5000,                 loss: nan
env1_first_0:                 episode reward: -27.8000,                 loss: nan
env1_second_0:                 episode reward: 27.8000,                 loss: nan
Episode: 8861/10000 (88.6100%),                 avg. length: 1095.45,                last time consumption/overall running time: 515.9661s / 225601.7021 s
env0_first_0:                 episode reward: -34.9000,                 loss: 0.1343
env0_second_0:                 episode reward: 34.9000,                 loss: nan
env1_first_0:                 episode reward: -26.0500,                 loss: nan
env1_second_0:                 episode reward: 26.0500,                 loss: nan
Episode: 8881/10000 (88.8100%),                 avg. length: 945.05,                last time consumption/overall running time: 446.1408s / 226047.8429 s
env0_first_0:                 episode reward: -34.6500,                 loss: 0.1079
env0_second_0:                 episode reward: 34.6500,                 loss: nan
env1_first_0:                 episode reward: -39.9000,                 loss: nan
env1_second_0:                 episode reward: 39.9000,                 loss: nan
Episode: 8901/10000 (89.0100%),                 avg. length: 1179.3,                last time consumption/overall running time: 555.3788s / 226603.2217 s
env0_first_0:                 episode reward: 5.5500,                 loss: 0.1218
env0_second_0:                 episode reward: -5.5500,                 loss: nan
env1_first_0:                 episode reward: -8.2500,                 loss: nan
env1_second_0:                 episode reward: 8.2500,                 loss: nan
Episode: 8921/10000 (89.2100%),                 avg. length: 843.55,                last time consumption/overall running time: 399.9121s / 227003.1338 s
env0_first_0:                 episode reward: -22.7000,                 loss: 0.1110
env0_second_0:                 episode reward: 22.7000,                 loss: nan
env1_first_0:                 episode reward: -31.7000,                 loss: nan
env1_second_0:                 episode reward: 31.7000,                 loss: nan
Episode: 8941/10000 (89.4100%),                 avg. length: 575.95,                last time consumption/overall running time: 274.9185s / 227278.0523 s
env0_first_0:                 episode reward: -62.0500,                 loss: 0.1779
env0_second_0:                 episode reward: 62.0500,                 loss: nan
env1_first_0:                 episode reward: -55.9000,                 loss: nan
env1_second_0:                 episode reward: 55.9000,                 loss: nan
Episode: 8961/10000 (89.6100%),                 avg. length: 544.65,                last time consumption/overall running time: 260.6697s / 227538.7221 s
env0_first_0:                 episode reward: -72.4000,                 loss: 0.2196
env0_second_0:                 episode reward: 72.4000,                 loss: nan
env1_first_0:                 episode reward: -61.9500,                 loss: nan
env1_second_0:                 episode reward: 61.9500,                 loss: nan
Episode: 8981/10000 (89.8100%),                 avg. length: 683.35,                last time consumption/overall running time: 325.2290s / 227863.9510 s
env0_first_0:                 episode reward: -18.8500,                 loss: 0.2925
env0_second_0:                 episode reward: 18.8500,                 loss: nan
env1_first_0:                 episode reward: -22.5500,                 loss: nan
env1_second_0:                 episode reward: 22.5500,                 loss: nan
Episode: 9001/10000 (90.0100%),                 avg. length: 538.5,                last time consumption/overall running time: 256.2393s / 228120.1904 s
env0_first_0:                 episode reward: -33.1500,                 loss: 0.3713
env0_second_0:                 episode reward: 33.1500,                 loss: nan
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 9021/10000 (90.2100%),                 avg. length: 579.1,                last time consumption/overall running time: 275.0326s / 228395.2230 s
env0_first_0:                 episode reward: -30.3500,                 loss: 0.3974
env0_second_0:                 episode reward: 30.3500,                 loss: nan
env1_first_0:                 episode reward: -12.0500,                 loss: nan
env1_second_0:                 episode reward: 12.0500,                 loss: nan
Episode: 9041/10000 (90.4100%),                 avg. length: 751.75,                last time consumption/overall running time: 356.9987s / 228752.2217 s
env0_first_0:                 episode reward: -30.9500,                 loss: 0.3501
env0_second_0:                 episode reward: 30.9500,                 loss: nan
env1_first_0:                 episode reward: -28.8000,                 loss: nan
env1_second_0:                 episode reward: 28.8000,                 loss: nan
Episode: 9061/10000 (90.6100%),                 avg. length: 835.15,                last time consumption/overall running time: 395.4264s / 229147.6481 s
env0_first_0:                 episode reward: -1.7500,                 loss: 0.2753
env0_second_0:                 episode reward: 1.7500,                 loss: nan
env1_first_0:                 episode reward: -8.7500,                 loss: nan
env1_second_0:                 episode reward: 8.7500,                 loss: nan
Episode: 9081/10000 (90.8100%),                 avg. length: 869.0,                last time consumption/overall running time: 410.9400s / 229558.5881 s
env0_first_0:                 episode reward: -6.3500,                 loss: 0.2301
env0_second_0:                 episode reward: 6.3500,                 loss: nan
env1_first_0:                 episode reward: -20.6000,                 loss: nan
env1_second_0:                 episode reward: 20.6000,                 loss: nan
Episode: 9101/10000 (91.0100%),                 avg. length: 672.2,                last time consumption/overall running time: 317.9313s / 229876.5194 s
env0_first_0:                 episode reward: 5.3500,                 loss: 0.2038
env0_second_0:                 episode reward: -5.3500,                 loss: nan
env1_first_0:                 episode reward: 6.4500,                 loss: nan
env1_second_0:                 episode reward: -6.4500,                 loss: nan
Episode: 9121/10000 (91.2100%),                 avg. length: 774.6,                last time consumption/overall running time: 1142.8685s / 231019.3879 s
env0_first_0:                 episode reward: 25.8000,                 loss: 0.2022
env0_second_0:                 episode reward: -25.8000,                 loss: 0.4759
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
Score delta: 93.6, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/9103_0.
Episode: 9141/10000 (91.4100%),                 avg. length: 592.15,                last time consumption/overall running time: 279.6636s / 231299.0515 s
env0_first_0:                 episode reward: 0.8000,                 loss: nan
env0_second_0:                 episode reward: -0.8000,                 loss: 0.5526
env1_first_0:                 episode reward: 6.1000,                 loss: nan
env1_second_0:                 episode reward: -6.1000,                 loss: nan
Episode: 9161/10000 (91.6100%),                 avg. length: 325.85,                last time consumption/overall running time: 1746.8228s / 233045.8743 s
env0_first_0:                 episode reward: -73.1500,                 loss: 0.2937
env0_second_0:                 episode reward: 73.1500,                 loss: 0.5780
env1_first_0:                 episode reward: -55.6500,                 loss: nan
env1_second_0:                 episode reward: 55.6500,                 loss: nan
Score delta: 91.6, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/9148_1.
Episode: 9181/10000 (91.8100%),                 avg. length: 770.5,                last time consumption/overall running time: 358.6188s / 233404.4931 s
env0_first_0:                 episode reward: -50.4000,                 loss: 0.2542
env0_second_0:                 episode reward: 50.4000,                 loss: nan
env1_first_0:                 episode reward: -57.7500,                 loss: nan
env1_second_0:                 episode reward: 57.7500,                 loss: nan
Episode: 9201/10000 (92.0100%),                 avg. length: 1043.4,                last time consumption/overall running time: 484.4057s / 233888.8988 s
env0_first_0:                 episode reward: -41.9000,                 loss: 0.2095
env0_second_0:                 episode reward: 41.9000,                 loss: nan
env1_first_0:                 episode reward: -45.5000,                 loss: nan
env1_second_0:                 episode reward: 45.5000,                 loss: nan
Episode: 9221/10000 (92.2100%),                 avg. length: 1047.15,                last time consumption/overall running time: 488.6863s / 234377.5851 s
env0_first_0:                 episode reward: -35.2500,                 loss: 0.1489
env0_second_0:                 episode reward: 35.2500,                 loss: nan
env1_first_0:                 episode reward: -42.8500,                 loss: nan
env1_second_0:                 episode reward: 42.8500,                 loss: nan
Episode: 9241/10000 (92.4100%),                 avg. length: 1388.1,                last time consumption/overall running time: 652.2132s / 235029.7983 s
env0_first_0:                 episode reward: -26.6500,                 loss: 0.1275
env0_second_0:                 episode reward: 26.6500,                 loss: nan
env1_first_0:                 episode reward: -16.8500,                 loss: nan
env1_second_0:                 episode reward: 16.8500,                 loss: nan
Episode: 9261/10000 (92.6100%),                 avg. length: 1267.2,                last time consumption/overall running time: 601.7632s / 235631.5615 s
env0_first_0:                 episode reward: -17.6500,                 loss: 0.1009
env0_second_0:                 episode reward: 17.6500,                 loss: nan
env1_first_0:                 episode reward: -3.0000,                 loss: nan
env1_second_0:                 episode reward: 3.0000,                 loss: nan
Episode: 9281/10000 (92.8100%),                 avg. length: 825.85,                last time consumption/overall running time: 393.9723s / 236025.5338 s
env0_first_0:                 episode reward: 6.2000,                 loss: 0.1165
env0_second_0:                 episode reward: -6.2000,                 loss: nan
env1_first_0:                 episode reward: 6.1000,                 loss: nan
env1_second_0:                 episode reward: -6.1000,                 loss: nan
Episode: 9301/10000 (93.0100%),                 avg. length: 621.9,                last time consumption/overall running time: 296.6507s / 236322.1845 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.1779
env0_second_0:                 episode reward: -0.7500,                 loss: nan
env1_first_0:                 episode reward: -12.8000,                 loss: nan
env1_second_0:                 episode reward: 12.8000,                 loss: nan
Episode: 9321/10000 (93.2100%),                 avg. length: 491.05,                last time consumption/overall running time: 1482.4912s / 237804.6757 s
env0_first_0:                 episode reward: -19.8500,                 loss: 0.2103
env0_second_0:                 episode reward: 19.8500,                 loss: 0.6024
env1_first_0:                 episode reward: -21.0500,                 loss: nan
env1_second_0:                 episode reward: 21.0500,                 loss: nan
Score delta: 81.4, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/9306_0.
Episode: 9341/10000 (93.4100%),                 avg. length: 371.3,                last time consumption/overall running time: 1831.8199s / 239636.4956 s
env0_first_0:                 episode reward: -59.8000,                 loss: 0.1616
env0_second_0:                 episode reward: 59.8000,                 loss: 0.5554
env1_first_0:                 episode reward: -72.9000,                 loss: nan
env1_second_0:                 episode reward: 72.9000,                 loss: nan
Score delta: 105.4, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/9330_1.
Episode: 9361/10000 (93.6100%),                 avg. length: 398.15,                last time consumption/overall running time: 188.8528s / 239825.3484 s
env0_first_0:                 episode reward: -79.2000,                 loss: 0.1962
env0_second_0:                 episode reward: 79.2000,                 loss: nan
env1_first_0:                 episode reward: -87.9500,                 loss: nan
env1_second_0:                 episode reward: 87.9500,                 loss: nan
Episode: 9381/10000 (93.8100%),                 avg. length: 977.05,                last time consumption/overall running time: 460.7246s / 240286.0730 s
env0_first_0:                 episode reward: -61.0000,                 loss: 0.2564
env0_second_0:                 episode reward: 61.0000,                 loss: nan
env1_first_0:                 episode reward: -44.5000,                 loss: nan
env1_second_0:                 episode reward: 44.5000,                 loss: nan
Episode: 9401/10000 (94.0100%),                 avg. length: 1202.25,                last time consumption/overall running time: 565.9660s / 240852.0390 s
env0_first_0:                 episode reward: -61.9000,                 loss: 0.2542
env0_second_0:                 episode reward: 61.9000,                 loss: nan
env1_first_0:                 episode reward: -57.0000,                 loss: nan
env1_second_0:                 episode reward: 57.0000,                 loss: nan
Episode: 9421/10000 (94.2100%),                 avg. length: 961.45,                last time consumption/overall running time: 451.8205s / 241303.8595 s
env0_first_0:                 episode reward: -51.7000,                 loss: 0.1933
env0_second_0:                 episode reward: 51.7000,                 loss: nan
env1_first_0:                 episode reward: -64.2000,                 loss: nan
env1_second_0:                 episode reward: 64.2000,                 loss: nan
Episode: 9441/10000 (94.4100%),                 avg. length: 1056.85,                last time consumption/overall running time: 497.3798s / 241801.2394 s
env0_first_0:                 episode reward: -56.8000,                 loss: 0.1991
env0_second_0:                 episode reward: 56.8000,                 loss: nan
env1_first_0:                 episode reward: -49.3500,                 loss: nan
env1_second_0:                 episode reward: 49.3500,                 loss: nan
Episode: 9461/10000 (94.6100%),                 avg. length: 1005.8,                last time consumption/overall running time: 473.3352s / 242274.5746 s
env0_first_0:                 episode reward: -43.8500,                 loss: 0.2170
env0_second_0:                 episode reward: 43.8500,                 loss: nan
env1_first_0:                 episode reward: -54.3000,                 loss: nan
env1_second_0:                 episode reward: 54.3000,                 loss: nan
Episode: 9481/10000 (94.8100%),                 avg. length: 1458.65,                last time consumption/overall running time: 690.6685s / 242965.2430 s
env0_first_0:                 episode reward: -32.5500,                 loss: 0.2024
env0_second_0:                 episode reward: 32.5500,                 loss: nan
env1_first_0:                 episode reward: -37.5500,                 loss: nan
env1_second_0:                 episode reward: 37.5500,                 loss: nan
Episode: 9501/10000 (95.0100%),                 avg. length: 1331.05,                last time consumption/overall running time: 631.8293s / 243597.0723 s
env0_first_0:                 episode reward: -41.9500,                 loss: 0.1731
env0_second_0:                 episode reward: 41.9500,                 loss: nan
env1_first_0:                 episode reward: -37.7500,                 loss: nan
env1_second_0:                 episode reward: 37.7500,                 loss: nan
Episode: 9521/10000 (95.2100%),                 avg. length: 1109.8,                last time consumption/overall running time: 525.2425s / 244122.3147 s
env0_first_0:                 episode reward: -46.3000,                 loss: 0.2062
env0_second_0:                 episode reward: 46.3000,                 loss: nan
env1_first_0:                 episode reward: -34.5000,                 loss: nan
env1_second_0:                 episode reward: 34.5000,                 loss: nan
Episode: 9541/10000 (95.4100%),                 avg. length: 1059.8,                last time consumption/overall running time: 500.1588s / 244622.4735 s
env0_first_0:                 episode reward: -6.2500,                 loss: 0.2553
env0_second_0:                 episode reward: 6.2500,                 loss: nan
env1_first_0:                 episode reward: -28.9500,                 loss: nan
env1_second_0:                 episode reward: 28.9500,                 loss: nan
Episode: 9561/10000 (95.6100%),                 avg. length: 699.5,                last time consumption/overall running time: 1337.1251s / 245959.5986 s
env0_first_0:                 episode reward: 2.2500,                 loss: 0.2677
env0_second_0:                 episode reward: -2.2500,                 loss: 0.5231
env1_first_0:                 episode reward: -2.0500,                 loss: nan
env1_second_0:                 episode reward: 2.0500,                 loss: nan
Score delta: 81.8, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/9550_0.
Episode: 9581/10000 (95.8100%),                 avg. length: 511.3,                last time consumption/overall running time: 1952.8734s / 247912.4720 s
env0_first_0:                 episode reward: -65.2000,                 loss: 0.3136
env0_second_0:                 episode reward: 65.2000,                 loss: 0.5258
env1_first_0:                 episode reward: -53.5500,                 loss: nan
env1_second_0:                 episode reward: 53.5500,                 loss: nan
Score delta: 80.2, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/9571_1.
Episode: 9601/10000 (96.0100%),                 avg. length: 685.45,                last time consumption/overall running time: 323.3948s / 248235.8668 s
env0_first_0:                 episode reward: -70.1000,                 loss: 0.3353
env0_second_0:                 episode reward: 70.1000,                 loss: nan
env1_first_0:                 episode reward: -71.1500,                 loss: nan
env1_second_0:                 episode reward: 71.1500,                 loss: nan
Episode: 9621/10000 (96.2100%),                 avg. length: 807.1,                last time consumption/overall running time: 380.2925s / 248616.1593 s
env0_first_0:                 episode reward: -51.9500,                 loss: 0.2695
env0_second_0:                 episode reward: 51.9500,                 loss: nan
env1_first_0:                 episode reward: -66.4500,                 loss: nan
env1_second_0:                 episode reward: 66.4500,                 loss: nan
Episode: 9641/10000 (96.4100%),                 avg. length: 1100.05,                last time consumption/overall running time: 516.7658s / 249132.9251 s
env0_first_0:                 episode reward: -40.2000,                 loss: 0.2148
env0_second_0:                 episode reward: 40.2000,                 loss: nan
env1_first_0:                 episode reward: -30.8500,                 loss: nan
env1_second_0:                 episode reward: 30.8500,                 loss: nan
Episode: 9661/10000 (96.6100%),                 avg. length: 1193.6,                last time consumption/overall running time: 560.4349s / 249693.3600 s
env0_first_0:                 episode reward: -33.2500,                 loss: 0.1439
env0_second_0:                 episode reward: 33.2500,                 loss: nan
env1_first_0:                 episode reward: -26.6000,                 loss: nan
env1_second_0:                 episode reward: 26.6000,                 loss: nan
Episode: 9681/10000 (96.8100%),                 avg. length: 975.65,                last time consumption/overall running time: 459.0888s / 250152.4488 s
env0_first_0:                 episode reward: -23.7000,                 loss: 0.1354
env0_second_0:                 episode reward: 23.7000,                 loss: nan
env1_first_0:                 episode reward: -52.7000,                 loss: nan
env1_second_0:                 episode reward: 52.7000,                 loss: nan
Episode: 9701/10000 (97.0100%),                 avg. length: 1127.4,                last time consumption/overall running time: 530.6479s / 250683.0967 s
env0_first_0:                 episode reward: -28.4500,                 loss: 0.1475
env0_second_0:                 episode reward: 28.4500,                 loss: nan
env1_first_0:                 episode reward: -25.6000,                 loss: nan
env1_second_0:                 episode reward: 25.6000,                 loss: nan
Episode: 9721/10000 (97.2100%),                 avg. length: 696.3,                last time consumption/overall running time: 330.5950s / 251013.6917 s
env0_first_0:                 episode reward: -47.7500,                 loss: 0.1850Load boxing_v1 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
Load boxing_v1 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
/home/zihan/research/MARS/mars/rollout.py:21: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rollout_normal(env, model, save_id, args)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/shape_base.py:420: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arrays = [asanyarray(arr) for arr in arrays]
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/lib/npyio.py:528: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr = np.asanyarray(arr)

env0_second_0:                 episode reward: 47.7500,                 loss: nan
env1_first_0:                 episode reward: -25.7000,                 loss: nan
env1_second_0:                 episode reward: 25.7000,                 loss: nan
Episode: 9741/10000 (97.4100%),                 avg. length: 565.75,                last time consumption/overall running time: 269.9660s / 251283.6577 s
env0_first_0:                 episode reward: -57.0500,                 loss: 0.2165
env0_second_0:                 episode reward: 57.0500,                 loss: nan
env1_first_0:                 episode reward: -5.0000,                 loss: nan
env1_second_0:                 episode reward: 5.0000,                 loss: nan
Episode: 9761/10000 (97.6100%),                 avg. length: 881.5,                last time consumption/overall running time: 419.6483s / 251703.3060 s
env0_first_0:                 episode reward: -16.7000,                 loss: 0.2361
env0_second_0:                 episode reward: 16.7000,                 loss: nan
env1_first_0:                 episode reward: 8.5500,                 loss: nan
env1_second_0:                 episode reward: -8.5500,                 loss: nan
Episode: 9781/10000 (97.8100%),                 avg. length: 818.7,                last time consumption/overall running time: 389.5636s / 252092.8696 s
env0_first_0:                 episode reward: -15.3000,                 loss: 0.2749
env0_second_0:                 episode reward: 15.3000,                 loss: nan
env1_first_0:                 episode reward: -1.5000,                 loss: nan
env1_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 9801/10000 (98.0100%),                 avg. length: 735.25,                last time consumption/overall running time: 345.9393s / 252438.8089 s
env0_first_0:                 episode reward: -16.9500,                 loss: 0.2761
env0_second_0:                 episode reward: 16.9500,                 loss: nan
env1_first_0:                 episode reward: -24.0500,                 loss: nan
env1_second_0:                 episode reward: 24.0500,                 loss: nan
Episode: 9821/10000 (98.2100%),                 avg. length: 889.4,                last time consumption/overall running time: 416.5659s / 252855.3749 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.2653
env0_second_0:                 episode reward: 0.8500,                 loss: nan
env1_first_0:                 episode reward: 16.0000,                 loss: nan
env1_second_0:                 episode reward: -16.0000,                 loss: nan
Episode: 9841/10000 (98.4100%),                 avg. length: 1109.7,                last time consumption/overall running time: 520.8370s / 253376.2118 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2052
env0_second_0:                 episode reward: -0.1500,                 loss: nan
env1_first_0:                 episode reward: 9.6000,                 loss: nan
env1_second_0:                 episode reward: -9.6000,                 loss: nan
Episode: 9861/10000 (98.6100%),                 avg. length: 962.15,                last time consumption/overall running time: 1429.9733s / 254806.1851 s
env0_first_0:                 episode reward: 21.3500,                 loss: 0.1794
env0_second_0:                 episode reward: -21.3500,                 loss: 0.5186
env1_first_0:                 episode reward: 19.2000,                 loss: nan
env1_second_0:                 episode reward: -19.2000,                 loss: nan
Score delta: 83.6, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/9860_0.
Episode: 9881/10000 (98.8100%),                 avg. length: 319.45,                last time consumption/overall running time: 1906.0709s / 256712.2560 s
env0_first_0:                 episode reward: -57.1500,                 loss: nan
env0_second_0:                 episode reward: 57.1500,                 loss: 0.6110
env1_first_0:                 episode reward: -71.1000,                 loss: nan
env1_second_0:                 episode reward: 71.1000,                 loss: nan
Score delta: 103.2, save the model to .//data/model/20220119_0524/pettingzoo_boxing_v1_nxdo2/9881_1.
Episode: 9901/10000 (99.0100%),                 avg. length: 390.55,                last time consumption/overall running time: 181.3971s / 256893.6531 s
env0_first_0:                 episode reward: -69.7500,                 loss: 0.3630
env0_second_0:                 episode reward: 69.7500,                 loss: nan
env1_first_0:                 episode reward: -80.5500,                 loss: nan
env1_second_0:                 episode reward: 80.5500,                 loss: nan
Episode: 9921/10000 (99.2100%),                 avg. length: 449.55,                last time consumption/overall running time: 197.2061s / 257090.8592 s
env0_first_0:                 episode reward: -77.7000,                 loss: 0.3539
env0_second_0:                 episode reward: 77.7000,                 loss: nan
env1_first_0:                 episode reward: -81.3000,                 loss: nan
env1_second_0:                 episode reward: 81.3000,                 loss: nan
Episode: 9941/10000 (99.4100%),                 avg. length: 448.8,                last time consumption/overall running time: 197.0161s / 257287.8753 s
env0_first_0:                 episode reward: -63.2000,                 loss: 0.4070
env0_second_0:                 episode reward: 63.2000,                 loss: nan
env1_first_0:                 episode reward: -78.4500,                 loss: nan
env1_second_0:                 episode reward: 78.4500,                 loss: nan
Episode: 9961/10000 (99.6100%),                 avg. length: 505.1,                last time consumption/overall running time: 221.2872s / 257509.1625 s
env0_first_0:                 episode reward: -63.3500,                 loss: 0.4387
env0_second_0:                 episode reward: 63.3500,                 loss: nan
env1_first_0:                 episode reward: -59.2000,                 loss: nan
env1_second_0:                 episode reward: 59.2000,                 loss: nan
Episode: 9981/10000 (99.8100%),                 avg. length: 767.3,                last time consumption/overall running time: 334.9624s / 257844.1248 s
env0_first_0:                 episode reward: -45.5500,                 loss: 0.4862
env0_second_0:                 episode reward: 45.5500,                 loss: nan
env1_first_0:                 episode reward: -45.4500,                 loss: nan
env1_second_0:                 episode reward: 45.4500,                 loss: nan
