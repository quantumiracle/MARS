pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 12.0, (1,), float32) action space: Discrete(3)
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7f2420e4dc88>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
Error: no exploited model index given!
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  data/model/20220518033032/mdp_arbitrary_mdp_nfsp/20000_0
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': '1i', 'algorithm': 'NFSP', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.0, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 640, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 10000, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220518033032/mdp_arbitrary_mdp_nfsp/20000_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False, 'policy': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': 'Softmax'}}, 'marl_method': 'nfsp', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'eta': 0.1}, 'against_baseline': False}
Save models to : /home/zihan/research/MARS/data/model/20220518033032_exploit_20000/mdp_arbitrary_mdp_nfsp. 
 Save logs to: /home/zihan/research/MARS/data/log/20220518033032_exploit_20000/mdp_arbitrary_mdp_nfsp.
Episode: 1/30000 (0.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6048s / 0.6048 s
agent0:                 episode reward: -1.2083,                 loss: nan
agent1:                 episode reward: 1.2083,                 loss: nan
Episode: 21/30000 (0.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0770s / 0.6819 s
agent0:                 episode reward: 0.2218,                 loss: nan
agent1:                 episode reward: -0.2218,                 loss: nan
Episode: 41/30000 (0.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0735s / 0.7554 s
agent0:                 episode reward: 0.3444,                 loss: nan
agent1:                 episode reward: -0.3444,                 loss: nan
Episode: 61/30000 (0.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0748s / 0.8301 s
agent0:                 episode reward: 0.6733,                 loss: nan
agent1:                 episode reward: -0.6733,                 loss: nan
Episode: 81/30000 (0.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0764s / 0.9065 s
agent0:                 episode reward: 0.3650,                 loss: nan
agent1:                 episode reward: -0.3650,                 loss: nan
Episode: 101/30000 (0.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0723s / 0.9788 s
agent0:                 episode reward: 0.3405,                 loss: nan
agent1:                 episode reward: -0.3405,                 loss: nan
Episode: 121/30000 (0.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1844s / 1.1632 s
agent0:                 episode reward: 0.3658,                 loss: nan
agent1:                 episode reward: -0.3658,                 loss: nan
Episode: 141/30000 (0.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1920s / 1.3552 s
agent0:                 episode reward: 0.3632,                 loss: nan
agent1:                 episode reward: -0.3632,                 loss: nan
Episode: 161/30000 (0.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1995s / 1.5547 s
agent0:                 episode reward: 0.5353,                 loss: nan
agent1:                 episode reward: -0.5353,                 loss: nan
Episode: 181/30000 (0.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2018s / 1.7565 s
agent0:                 episode reward: -0.1854,                 loss: nan
agent1:                 episode reward: 0.1854,                 loss: nan
Episode: 201/30000 (0.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1995s / 1.9560 s
agent0:                 episode reward: 0.4126,                 loss: nan
agent1:                 episode reward: -0.4126,                 loss: nan
Episode: 221/30000 (0.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1987s / 2.1547 s
agent0:                 episode reward: 0.5383,                 loss: nan
agent1:                 episode reward: -0.5383,                 loss: nan
Episode: 241/30000 (0.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1983s / 2.3530 s
agent0:                 episode reward: 0.1711,                 loss: nan
agent1:                 episode reward: -0.1711,                 loss: nan
Episode: 261/30000 (0.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1994s / 2.5524 s
agent0:                 episode reward: 0.1237,                 loss: nan
agent1:                 episode reward: -0.1237,                 loss: nan
Episode: 281/30000 (0.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2072s / 2.7596 s
agent0:                 episode reward: 0.6210,                 loss: nan
agent1:                 episode reward: -0.6210,                 loss: nan
Episode: 301/30000 (1.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1923s / 2.9519 s
agent0:                 episode reward: 0.5683,                 loss: nan
agent1:                 episode reward: -0.5683,                 loss: nan
Episode: 321/30000 (1.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2006s / 3.1524 s
agent0:                 episode reward: 0.0854,                 loss: nan
agent1:                 episode reward: -0.0854,                 loss: nan
Episode: 341/30000 (1.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1993s / 3.3517 s
agent0:                 episode reward: 0.0852,                 loss: nan
agent1:                 episode reward: -0.0852,                 loss: nan
Episode: 361/30000 (1.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1978s / 3.5496 s
agent0:                 episode reward: 0.2835,                 loss: nan
agent1:                 episode reward: -0.2835,                 loss: nan
Episode: 381/30000 (1.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2001s / 3.7497 s
agent0:                 episode reward: 0.4471,                 loss: nan
agent1:                 episode reward: -0.4471,                 loss: nan
Episode: 401/30000 (1.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2018s / 3.9515 s
agent0:                 episode reward: 0.3725,                 loss: nan
agent1:                 episode reward: -0.3725,                 loss: nan
Episode: 421/30000 (1.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2014s / 4.1529 s
agent0:                 episode reward: 0.3843,                 loss: nan
agent1:                 episode reward: -0.3843,                 loss: nan
Episode: 441/30000 (1.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2025s / 4.3554 s
agent0:                 episode reward: 0.2241,                 loss: nan
agent1:                 episode reward: -0.2241,                 loss: nan
Episode: 461/30000 (1.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1963s / 4.5518 s
agent0:                 episode reward: 0.1629,                 loss: nan
agent1:                 episode reward: -0.1629,                 loss: nan
Episode: 481/30000 (1.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2009s / 4.7527 s
agent0:                 episode reward: 0.3831,                 loss: nan
agent1:                 episode reward: -0.3831,                 loss: nan
Episode: 501/30000 (1.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2017s / 4.9544 s
agent0:                 episode reward: 0.0714,                 loss: nan
agent1:                 episode reward: -0.0714,                 loss: nan
Episode: 521/30000 (1.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1968s / 5.1512 s
agent0:                 episode reward: 0.3827,                 loss: nan
agent1:                 episode reward: -0.3827,                 loss: nan
Episode: 541/30000 (1.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1955s / 5.3467 s
agent0:                 episode reward: 0.3010,                 loss: nan
agent1:                 episode reward: -0.3010,                 loss: nan
Episode: 561/30000 (1.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2026s / 5.5493 s
agent0:                 episode reward: 0.5354,                 loss: nan
agent1:                 episode reward: -0.5354,                 loss: nan
Episode: 581/30000 (1.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2004s / 5.7497 s
agent0:                 episode reward: 0.2698,                 loss: nan
agent1:                 episode reward: -0.2698,                 loss: nan
Episode: 601/30000 (2.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1972s / 5.9469 s
agent0:                 episode reward: 0.1995,                 loss: nan
agent1:                 episode reward: -0.1995,                 loss: nan
Episode: 621/30000 (2.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1997s / 6.1466 s
agent0:                 episode reward: -0.0593,                 loss: nan
agent1:                 episode reward: 0.0593,                 loss: nan
Episode: 641/30000 (2.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1997s / 6.3463 s
agent0:                 episode reward: 0.4536,                 loss: nan
agent1:                 episode reward: -0.4536,                 loss: nan
Episode: 661/30000 (2.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1942s / 6.5405 s
agent0:                 episode reward: 0.8738,                 loss: nan
agent1:                 episode reward: -0.8738,                 loss: nan
Episode: 681/30000 (2.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2015s / 6.7420 s
agent0:                 episode reward: 0.1316,                 loss: nan
agent1:                 episode reward: -0.1316,                 loss: nan
Episode: 701/30000 (2.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2000s / 6.9419 s
agent0:                 episode reward: 0.3763,                 loss: nan
agent1:                 episode reward: -0.3763,                 loss: nan
Episode: 721/30000 (2.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2012s / 7.1431 s
agent0:                 episode reward: -0.1188,                 loss: nan
agent1:                 episode reward: 0.1188,                 loss: nan
Episode: 741/30000 (2.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1995s / 7.3427 s
agent0:                 episode reward: 0.5845,                 loss: nan
agent1:                 episode reward: -0.5845,                 loss: nan
Episode: 761/30000 (2.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1974s / 7.5401 s
agent0:                 episode reward: 0.4824,                 loss: nan
agent1:                 episode reward: -0.4824,                 loss: nan
Episode: 781/30000 (2.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2007s / 7.7408 s
agent0:                 episode reward: 0.4322,                 loss: nan
agent1:                 episode reward: -0.4322,                 loss: nan
Episode: 801/30000 (2.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1980s / 7.9388 s
agent0:                 episode reward: 0.2314,                 loss: nan
agent1:                 episode reward: -0.2314,                 loss: nan
Episode: 821/30000 (2.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2005s / 8.1393 s
agent0:                 episode reward: 0.1263,                 loss: nan
agent1:                 episode reward: -0.1263,                 loss: nan
Episode: 841/30000 (2.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2015s / 8.3408 s
agent0:                 episode reward: 0.2339,                 loss: nan
agent1:                 episode reward: -0.2339,                 loss: nan
Episode: 861/30000 (2.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1985s / 8.5392 s
agent0:                 episode reward: 0.3614,                 loss: nan
agent1:                 episode reward: -0.3614,                 loss: nan
Episode: 881/30000 (2.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2027s / 8.7419 s
agent0:                 episode reward: 0.5081,                 loss: nan
agent1:                 episode reward: -0.5081,                 loss: nan
Episode: 901/30000 (3.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1965s / 8.9384 s
agent0:                 episode reward: 0.5848,                 loss: nan
agent1:                 episode reward: -0.5848,                 loss: nan
Episode: 921/30000 (3.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1998s / 9.1382 s
agent0:                 episode reward: 0.2791,                 loss: nan
agent1:                 episode reward: -0.2791,                 loss: nan
Episode: 941/30000 (3.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2011s / 9.3393 s
agent0:                 episode reward: 0.6109,                 loss: nan
agent1:                 episode reward: -0.6109,                 loss: nan
Episode: 961/30000 (3.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1996s / 9.5389 s
agent0:                 episode reward: 0.1301,                 loss: nan
agent1:                 episode reward: -0.1301,                 loss: nan
Episode: 981/30000 (3.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1978s / 9.7367 s
agent0:                 episode reward: 0.2965,                 loss: nan
agent1:                 episode reward: -0.2965,                 loss: nan
Episode: 1001/30000 (3.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1980s / 9.9347 s
agent0:                 episode reward: 0.4249,                 loss: nan
agent1:                 episode reward: -0.4249,                 loss: nan
Episode: 1021/30000 (3.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1981s / 10.1328 s
agent0:                 episode reward: 0.7064,                 loss: nan
agent1:                 episode reward: -0.7064,                 loss: nan
Episode: 1041/30000 (3.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1981s / 10.3309 s
agent0:                 episode reward: 0.0948,                 loss: nan
agent1:                 episode reward: -0.0948,                 loss: nan
Episode: 1061/30000 (3.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2046s / 10.5355 s
agent0:                 episode reward: 0.1463,                 loss: nan
agent1:                 episode reward: -0.1463,                 loss: nan
Episode: 1081/30000 (3.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2021s / 10.7377 s
agent0:                 episode reward: 0.5752,                 loss: nan
agent1:                 episode reward: -0.5752,                 loss: nan
Episode: 1101/30000 (3.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1983s / 10.9359 s
agent0:                 episode reward: 0.4144,                 loss: nan
agent1:                 episode reward: -0.4144,                 loss: nan
Episode: 1121/30000 (3.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1994s / 11.1353 s
agent0:                 episode reward: 0.3765,                 loss: nan
agent1:                 episode reward: -0.3765,                 loss: nan
Episode: 1141/30000 (3.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1977s / 11.3330 s
agent0:                 episode reward: 0.6678,                 loss: nan
agent1:                 episode reward: -0.6678,                 loss: nan
Episode: 1161/30000 (3.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1947s / 11.5277 s
agent0:                 episode reward: 0.4321,                 loss: nan
agent1:                 episode reward: -0.4321,                 loss: nan
Episode: 1181/30000 (3.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1947s / 11.7224 s
agent0:                 episode reward: 0.4151,                 loss: nan
agent1:                 episode reward: -0.4151,                 loss: nan
Episode: 1201/30000 (4.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1983s / 11.9206 s
agent0:                 episode reward: 0.4461,                 loss: nan
agent1:                 episode reward: -0.4461,                 loss: nan
Episode: 1221/30000 (4.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1998s / 12.1204 s
agent0:                 episode reward: 0.4198,                 loss: nan
agent1:                 episode reward: -0.4198,                 loss: nan
Episode: 1241/30000 (4.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1991s / 12.3195 s
agent0:                 episode reward: 0.3353,                 loss: nan
agent1:                 episode reward: -0.3353,                 loss: nan
Episode: 1261/30000 (4.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1980s / 12.5176 s
agent0:                 episode reward: 0.4562,                 loss: nan
agent1:                 episode reward: -0.4562,                 loss: nan
Episode: 1281/30000 (4.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1965s / 12.7141 s
agent0:                 episode reward: 0.2789,                 loss: nan
agent1:                 episode reward: -0.2789,                 loss: nan
Episode: 1301/30000 (4.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2034s / 12.9175 s
agent0:                 episode reward: -0.1129,                 loss: nan
agent1:                 episode reward: 0.1129,                 loss: nan
Episode: 1321/30000 (4.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1959s / 13.1134 s
agent0:                 episode reward: -0.1163,                 loss: nan
agent1:                 episode reward: 0.1163,                 loss: nan
Episode: 1341/30000 (4.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2000s / 13.3135 s
agent0:                 episode reward: 0.6905,                 loss: nan
agent1:                 episode reward: -0.6905,                 loss: nan
Episode: 1361/30000 (4.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2000s / 13.5135 s
agent0:                 episode reward: 0.3796,                 loss: nan
agent1:                 episode reward: -0.3796,                 loss: nan
Episode: 1381/30000 (4.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1945s / 13.7079 s
agent0:                 episode reward: 0.5687,                 loss: nan
agent1:                 episode reward: -0.5687,                 loss: nan
Episode: 1401/30000 (4.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1993s / 13.9072 s
agent0:                 episode reward: 0.1839,                 loss: nan
agent1:                 episode reward: -0.1839,                 loss: nan
Episode: 1421/30000 (4.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1955s / 14.1027 s
agent0:                 episode reward: 0.0593,                 loss: nan
agent1:                 episode reward: -0.0593,                 loss: nan
Episode: 1441/30000 (4.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1989s / 14.3016 s
agent0:                 episode reward: 0.1794,                 loss: nan
agent1:                 episode reward: -0.1794,                 loss: nan
Episode: 1461/30000 (4.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1992s / 14.5008 s
agent0:                 episode reward: -0.0111,                 loss: nan
agent1:                 episode reward: 0.0111,                 loss: nan
Episode: 1481/30000 (4.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2004s / 14.7012 s
agent0:                 episode reward: 0.6101,                 loss: nan
agent1:                 episode reward: -0.6101,                 loss: nan
Episode: 1501/30000 (5.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1964s / 14.8975 s
agent0:                 episode reward: 0.1835,                 loss: nan
agent1:                 episode reward: -0.1835,                 loss: nan
Episode: 1521/30000 (5.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1990s / 15.0966 s
agent0:                 episode reward: 0.5630,                 loss: nan
agent1:                 episode reward: -0.5630,                 loss: nan
Episode: 1541/30000 (5.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2011s / 15.2977 s
agent0:                 episode reward: -0.0663,                 loss: nan
agent1:                 episode reward: 0.0663,                 loss: nan
Episode: 1561/30000 (5.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2028s / 15.5005 s
agent0:                 episode reward: 0.5389,                 loss: nan
agent1:                 episode reward: -0.5389,                 loss: nan
Episode: 1581/30000 (5.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1960s / 15.6965 s
agent0:                 episode reward: 0.4483,                 loss: nan
agent1:                 episode reward: -0.4483,                 loss: nan
Episode: 1601/30000 (5.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2007s / 15.8972 s
agent0:                 episode reward: 0.2732,                 loss: nan
agent1:                 episode reward: -0.2732,                 loss: nan
Episode: 1621/30000 (5.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2025s / 16.0997 s
agent0:                 episode reward: 0.5238,                 loss: nan
agent1:                 episode reward: -0.5238,                 loss: nan
Episode: 1641/30000 (5.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1973s / 16.2971 s
agent0:                 episode reward: 0.7121,                 loss: nan
agent1:                 episode reward: -0.7121,                 loss: nan
Episode: 1661/30000 (5.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1987s / 16.4958 s
agent0:                 episode reward: 0.3108,                 loss: nan
agent1:                 episode reward: -0.3108,                 loss: nan
Episode: 1681/30000 (5.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1999s / 16.6957 s
agent0:                 episode reward: 0.4522,                 loss: nan
agent1:                 episode reward: -0.4522,                 loss: nan
Episode: 1701/30000 (5.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2019s / 16.8975 s
agent0:                 episode reward: 0.5645,                 loss: nan
agent1:                 episode reward: -0.5645,                 loss: nan
Episode: 1721/30000 (5.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2003s / 17.0978 s
agent0:                 episode reward: 0.3566,                 loss: nan
agent1:                 episode reward: -0.3566,                 loss: nan
Episode: 1741/30000 (5.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1985s / 17.2964 s
agent0:                 episode reward: 0.1651,                 loss: nan
agent1:                 episode reward: -0.1651,                 loss: nan
Episode: 1761/30000 (5.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1981s / 17.4944 s
agent0:                 episode reward: -0.3345,                 loss: nan
agent1:                 episode reward: 0.3345,                 loss: nan
Episode: 1781/30000 (5.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1934s / 17.6879 s
agent0:                 episode reward: 0.4107,                 loss: nan
agent1:                 episode reward: -0.4107,                 loss: nan
Episode: 1801/30000 (6.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1966s / 17.8845 s
agent0:                 episode reward: 0.3263,                 loss: nan
agent1:                 episode reward: -0.3263,                 loss: nan
Episode: 1821/30000 (6.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2011s / 18.0856 s
agent0:                 episode reward: 0.6303,                 loss: nan
agent1:                 episode reward: -0.6303,                 loss: nan
Episode: 1841/30000 (6.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1995s / 18.2851 s
agent0:                 episode reward: -0.1563,                 loss: nan
agent1:                 episode reward: 0.1563,                 loss: nan
Episode: 1861/30000 (6.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1986s / 18.4837 s
agent0:                 episode reward: 0.5764,                 loss: nan
agent1:                 episode reward: -0.5764,                 loss: nan
Episode: 1881/30000 (6.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2015s / 18.6852 s
agent0:                 episode reward: 0.4596,                 loss: nan
agent1:                 episode reward: -0.4596,                 loss: nan
Episode: 1901/30000 (6.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1961s / 18.8813 s
agent0:                 episode reward: 0.0778,                 loss: nan
agent1:                 episode reward: -0.0778,                 loss: nan
Episode: 1921/30000 (6.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1983s / 19.0796 s
agent0:                 episode reward: 0.3248,                 loss: nan
agent1:                 episode reward: -0.3248,                 loss: nan
Episode: 1941/30000 (6.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1991s / 19.2787 s
agent0:                 episode reward: 0.1840,                 loss: nan
agent1:                 episode reward: -0.1840,                 loss: nan
Episode: 1961/30000 (6.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1979s / 19.4766 s
agent0:                 episode reward: 0.7070,                 loss: nan
agent1:                 episode reward: -0.7070,                 loss: nan
Episode: 1981/30000 (6.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2058s / 19.6823 s
agent0:                 episode reward: 0.4344,                 loss: nan
agent1:                 episode reward: -0.4344,                 loss: nan
Episode: 2001/30000 (6.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1940s / 19.8763 s
agent0:                 episode reward: 0.4122,                 loss: nan
agent1:                 episode reward: -0.4122,                 loss: nan
Episode: 2021/30000 (6.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2017s / 20.0780 s
agent0:                 episode reward: 0.2331,                 loss: nan
agent1:                 episode reward: -0.2331,                 loss: nan
Episode: 2041/30000 (6.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1993s / 20.2774 s
agent0:                 episode reward: 0.1595,                 loss: nan
agent1:                 episode reward: -0.1595,                 loss: nan
Episode: 2061/30000 (6.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1961s / 20.4735 s
agent0:                 episode reward: 0.4286,                 loss: nan
agent1:                 episode reward: -0.4286,                 loss: nan
Episode: 2081/30000 (6.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1997s / 20.6733 s
agent0:                 episode reward: 0.5854,                 loss: nan
agent1:                 episode reward: -0.5854,                 loss: nan
Episode: 2101/30000 (7.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2001s / 20.8734 s
agent0:                 episode reward: 0.2913,                 loss: nan
agent1:                 episode reward: -0.2913,                 loss: nan
Episode: 2121/30000 (7.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1967s / 21.0701 s
agent0:                 episode reward: 0.3876,                 loss: nan
agent1:                 episode reward: -0.3876,                 loss: nan
Episode: 2141/30000 (7.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1994s / 21.2694 s
agent0:                 episode reward: 0.3935,                 loss: nan
agent1:                 episode reward: -0.3935,                 loss: nan
Episode: 2161/30000 (7.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1914s / 21.4608 s
agent0:                 episode reward: 0.1438,                 loss: nan
agent1:                 episode reward: -0.1438,                 loss: nan
Episode: 2181/30000 (7.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2007s / 21.6615 s
agent0:                 episode reward: 0.2963,                 loss: nan
agent1:                 episode reward: -0.2963,                 loss: nan
Episode: 2201/30000 (7.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1994s / 21.8609 s
agent0:                 episode reward: -0.0104,                 loss: nan
agent1:                 episode reward: 0.0104,                 loss: nan
Episode: 2221/30000 (7.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1950s / 22.0559 s
agent0:                 episode reward: 0.3830,                 loss: nan
agent1:                 episode reward: -0.3830,                 loss: nan
Episode: 2241/30000 (7.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1979s / 22.2538 s
agent0:                 episode reward: 0.4509,                 loss: nan
agent1:                 episode reward: -0.4509,                 loss: nan
Episode: 2261/30000 (7.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1997s / 22.4535 s
agent0:                 episode reward: -0.0302,                 loss: nan
agent1:                 episode reward: 0.0302,                 loss: nan
Episode: 2281/30000 (7.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2005s / 22.6540 s
agent0:                 episode reward: 0.4583,                 loss: nan
agent1:                 episode reward: -0.4583,                 loss: nan
Episode: 2301/30000 (7.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1972s / 22.8512 s
agent0:                 episode reward: 0.1698,                 loss: nan
agent1:                 episode reward: -0.1698,                 loss: nan
Episode: 2321/30000 (7.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1968s / 23.0480 s
agent0:                 episode reward: 0.3935,                 loss: nan
agent1:                 episode reward: -0.3935,                 loss: nan
Episode: 2341/30000 (7.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1933s / 23.2412 s
agent0:                 episode reward: 0.1557,                 loss: nan
agent1:                 episode reward: -0.1557,                 loss: nan
Episode: 2361/30000 (7.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1997s / 23.4410 s
agent0:                 episode reward: 0.3066,                 loss: nan
agent1:                 episode reward: -0.3066,                 loss: nan
Episode: 2381/30000 (7.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1953s / 23.6363 s
agent0:                 episode reward: 0.6016,                 loss: nan
agent1:                 episode reward: -0.6016,                 loss: nan
Episode: 2401/30000 (8.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1958s / 23.8321 s
agent0:                 episode reward: 0.1531,                 loss: nan
agent1:                 episode reward: -0.1531,                 loss: nan
Episode: 2421/30000 (8.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2019s / 24.0340 s
agent0:                 episode reward: 0.6223,                 loss: nan
agent1:                 episode reward: -0.6223,                 loss: nan
Episode: 2441/30000 (8.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2021s / 24.2361 s
agent0:                 episode reward: -0.0506,                 loss: nan
agent1:                 episode reward: 0.0506,                 loss: nan
Episode: 2461/30000 (8.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1964s / 24.4326 s
agent0:                 episode reward: 0.2888,                 loss: nan
agent1:                 episode reward: -0.2888,                 loss: nan
Episode: 2481/30000 (8.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1988s / 24.6314 s
agent0:                 episode reward: 0.1997,                 loss: nan
agent1:                 episode reward: -0.1997,                 loss: nan
Episode: 2501/30000 (8.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1978s / 24.8292 s
agent0:                 episode reward: 0.2426,                 loss: nan
agent1:                 episode reward: -0.2426,                 loss: nan
Episode: 2521/30000 (8.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1959s / 25.0251 s
agent0:                 episode reward: 0.3770,                 loss: nan
agent1:                 episode reward: -0.3770,                 loss: nan
Episode: 2541/30000 (8.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1996s / 25.2247 s
agent0:                 episode reward: 0.2791,                 loss: nan
agent1:                 episode reward: -0.2791,                 loss: nan
Episode: 2561/30000 (8.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1990s / 25.4237 s
agent0:                 episode reward: 0.2591,                 loss: nan
agent1:                 episode reward: -0.2591,                 loss: nan
Episode: 2581/30000 (8.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2011s / 25.6247 s
agent0:                 episode reward: 0.1965,                 loss: nan
agent1:                 episode reward: -0.1965,                 loss: nan
Episode: 2601/30000 (8.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1984s / 25.8231 s
agent0:                 episode reward: 0.4729,                 loss: nan
agent1:                 episode reward: -0.4729,                 loss: nan
Episode: 2621/30000 (8.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2000s / 26.0231 s
agent0:                 episode reward: -0.0166,                 loss: nan
agent1:                 episode reward: 0.0166,                 loss: nan
Episode: 2641/30000 (8.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1961s / 26.2193 s
agent0:                 episode reward: 0.2290,                 loss: nan
agent1:                 episode reward: -0.2290,                 loss: nan
Episode: 2661/30000 (8.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1990s / 26.4183 s
agent0:                 episode reward: 0.1716,                 loss: nan
agent1:                 episode reward: -0.1716,                 loss: nan
Episode: 2681/30000 (8.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2201s / 26.6384 s
agent0:                 episode reward: 0.3536,                 loss: nan
agent1:                 episode reward: -0.3536,                 loss: nan
Episode: 2701/30000 (9.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2054s / 26.8438 s
agent0:                 episode reward: 0.2611,                 loss: nan
agent1:                 episode reward: -0.2611,                 loss: nan
Episode: 2721/30000 (9.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2065s / 27.0503 s
agent0:                 episode reward: 0.3783,                 loss: nan
agent1:                 episode reward: -0.3783,                 loss: nan
Episode: 2741/30000 (9.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2055s / 27.2558 s
agent0:                 episode reward: 0.4341,                 loss: nan
agent1:                 episode reward: -0.4341,                 loss: nan
Episode: 2761/30000 (9.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2812s / 27.5370 s
agent0:                 episode reward: 0.5741,                 loss: nan
agent1:                 episode reward: -0.5741,                 loss: nan
Episode: 2781/30000 (9.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2036s / 27.7407 s
agent0:                 episode reward: 0.2805,                 loss: nan
agent1:                 episode reward: -0.2805,                 loss: nan
Episode: 2801/30000 (9.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2013s / 27.9420 s
agent0:                 episode reward: 0.3473,                 loss: nan
agent1:                 episode reward: -0.3473,                 loss: nan
Episode: 2821/30000 (9.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2010s / 28.1430 s
agent0:                 episode reward: 0.0454,                 loss: nan
agent1:                 episode reward: -0.0454,                 loss: nan
Episode: 2841/30000 (9.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1566s / 28.2997 s
agent0:                 episode reward: 0.1258,                 loss: nan
agent1:                 episode reward: -0.1258,                 loss: nan
Episode: 2861/30000 (9.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1935s / 28.4931 s
agent0:                 episode reward: 0.4224,                 loss: nan
agent1:                 episode reward: -0.4224,                 loss: nan
Episode: 2881/30000 (9.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1986s / 28.6917 s
agent0:                 episode reward: 0.5528,                 loss: nan
agent1:                 episode reward: -0.5528,                 loss: nan
Episode: 2901/30000 (9.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1958s / 28.8875 s
agent0:                 episode reward: 0.2618,                 loss: nan
agent1:                 episode reward: -0.2618,                 loss: nan
Episode: 2921/30000 (9.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1954s / 29.0829 s
agent0:                 episode reward: 0.3950,                 loss: nan
agent1:                 episode reward: -0.3950,                 loss: nan
Episode: 2941/30000 (9.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1948s / 29.2777 s
agent0:                 episode reward: 0.1289,                 loss: nan
agent1:                 episode reward: -0.1289,                 loss: nan
Episode: 2961/30000 (9.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1963s / 29.4740 s
agent0:                 episode reward: -0.1363,                 loss: nan
agent1:                 episode reward: 0.1363,                 loss: nan
Episode: 2981/30000 (9.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1996s / 29.6736 s
agent0:                 episode reward: 0.6906,                 loss: nan
agent1:                 episode reward: -0.6906,                 loss: nan
Episode: 3001/30000 (10.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2046s / 29.8783 s
agent0:                 episode reward: 0.3157,                 loss: nan
agent1:                 episode reward: -0.3157,                 loss: nan
Episode: 3021/30000 (10.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2024s / 30.0807 s
agent0:                 episode reward: 0.1884,                 loss: nan
agent1:                 episode reward: -0.1884,                 loss: nan
Episode: 3041/30000 (10.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1975s / 30.2782 s
agent0:                 episode reward: 0.2810,                 loss: nan
agent1:                 episode reward: -0.2810,                 loss: nan
Episode: 3061/30000 (10.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1964s / 30.4746 s
agent0:                 episode reward: 0.3504,                 loss: nan
agent1:                 episode reward: -0.3504,                 loss: nan
Episode: 3081/30000 (10.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2010s / 30.6755 s
agent0:                 episode reward: 0.2402,                 loss: nan
agent1:                 episode reward: -0.2402,                 loss: nan
Episode: 3101/30000 (10.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1987s / 30.8742 s
agent0:                 episode reward: 0.4081,                 loss: nan
agent1:                 episode reward: -0.4081,                 loss: nan
Episode: 3121/30000 (10.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2041s / 31.0782 s
agent0:                 episode reward: 0.2370,                 loss: nan
agent1:                 episode reward: -0.2370,                 loss: nan
Episode: 3141/30000 (10.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2002s / 31.2785 s
agent0:                 episode reward: 0.1579,                 loss: nan
agent1:                 episode reward: -0.1579,                 loss: nan
Episode: 3161/30000 (10.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1981s / 31.4765 s
agent0:                 episode reward: 0.1887,                 loss: nan
agent1:                 episode reward: -0.1887,                 loss: nan
Episode: 3181/30000 (10.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1988s / 31.6753 s
agent0:                 episode reward: 0.1335,                 loss: nan
agent1:                 episode reward: -0.1335,                 loss: nan
Episode: 3201/30000 (10.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1988s / 31.8742 s
agent0:                 episode reward: 0.3105,                 loss: nan
agent1:                 episode reward: -0.3105,                 loss: nan
Episode: 3221/30000 (10.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1998s / 32.0740 s
agent0:                 episode reward: 0.2624,                 loss: nan
agent1:                 episode reward: -0.2624,                 loss: nan
Episode: 3241/30000 (10.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1965s / 32.2706 s
agent0:                 episode reward: 0.3027,                 loss: nan
agent1:                 episode reward: -0.3027,                 loss: nan
Episode: 3261/30000 (10.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2012s / 32.4717 s
agent0:                 episode reward: 0.1520,                 loss: nan
agent1:                 episode reward: -0.1520,                 loss: nan
Episode: 3281/30000 (10.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2022s / 32.6739 s
agent0:                 episode reward: 0.2160,                 loss: nan
agent1:                 episode reward: -0.2160,                 loss: nan
Episode: 3301/30000 (11.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1985s / 32.8724 s
agent0:                 episode reward: 0.2911,                 loss: nan
agent1:                 episode reward: -0.2911,                 loss: nan
Episode: 3321/30000 (11.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2031s / 33.0754 s
agent0:                 episode reward: 0.6193,                 loss: nan
agent1:                 episode reward: -0.6193,                 loss: nan
Episode: 3341/30000 (11.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3638s / 33.4393 s
agent0:                 episode reward: 0.5440,                 loss: nan
agent1:                 episode reward: -0.5440,                 loss: 0.4466
Episode: 3361/30000 (11.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6162s / 34.0554 s
agent0:                 episode reward: -0.0430,                 loss: nan
agent1:                 episode reward: 0.0430,                 loss: 0.4333
Episode: 3381/30000 (11.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5859s / 34.6413 s
agent0:                 episode reward: -0.3088,                 loss: nan
agent1:                 episode reward: 0.3088,                 loss: 0.4264
Episode: 3401/30000 (11.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5762s / 35.2176 s
agent0:                 episode reward: 0.3321,                 loss: nan
agent1:                 episode reward: -0.3321,                 loss: 0.4248
Episode: 3421/30000 (11.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5941s / 35.8116 s
agent0:                 episode reward: 0.0663,                 loss: nan
agent1:                 episode reward: -0.0663,                 loss: 0.4183
Episode: 3441/30000 (11.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5775s / 36.3891 s
agent0:                 episode reward: 0.4157,                 loss: nan
agent1:                 episode reward: -0.4157,                 loss: 0.4148
Episode: 3461/30000 (11.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5807s / 36.9697 s
agent0:                 episode reward: 0.0851,                 loss: nan
agent1:                 episode reward: -0.0851,                 loss: 0.4102
Episode: 3481/30000 (11.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5886s / 37.5583 s
agent0:                 episode reward: -0.0761,                 loss: nan
agent1:                 episode reward: 0.0761,                 loss: 0.4059
Episode: 3501/30000 (11.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5707s / 38.1291 s
agent0:                 episode reward: 0.1778,                 loss: nan
agent1:                 episode reward: -0.1778,                 loss: 0.4021
Episode: 3521/30000 (11.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5818s / 38.7109 s
agent0:                 episode reward: 0.1498,                 loss: nan
agent1:                 episode reward: -0.1498,                 loss: 0.3983
Episode: 3541/30000 (11.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5882s / 39.2991 s
agent0:                 episode reward: -0.0498,                 loss: nan
agent1:                 episode reward: 0.0498,                 loss: 0.3972
Episode: 3561/30000 (11.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5737s / 39.8728 s
agent0:                 episode reward: -0.0380,                 loss: nan
agent1:                 episode reward: 0.0380,                 loss: 0.3945
Episode: 3581/30000 (11.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5909s / 40.4637 s
agent0:                 episode reward: -0.0225,                 loss: nan
agent1:                 episode reward: 0.0225,                 loss: 0.3952
Episode: 3601/30000 (12.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5749s / 41.0386 s
agent0:                 episode reward: 0.0767,                 loss: nan
agent1:                 episode reward: -0.0767,                 loss: 0.3909
Episode: 3621/30000 (12.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5758s / 41.6144 s
agent0:                 episode reward: 0.1141,                 loss: nan
agent1:                 episode reward: -0.1141,                 loss: 0.3898
Episode: 3641/30000 (12.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5791s / 42.1935 s
agent0:                 episode reward: 0.0255,                 loss: nan
agent1:                 episode reward: -0.0255,                 loss: 0.3903
Episode: 3661/30000 (12.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5900s / 42.7835 s
agent0:                 episode reward: -0.0346,                 loss: nan
agent1:                 episode reward: 0.0346,                 loss: 0.3862
Episode: 3681/30000 (12.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5849s / 43.3684 s
agent0:                 episode reward: 0.0541,                 loss: nan
agent1:                 episode reward: -0.0541,                 loss: 0.3956
Episode: 3701/30000 (12.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5833s / 43.9517 s
agent0:                 episode reward: 0.2500,                 loss: nan
agent1:                 episode reward: -0.2500,                 loss: 0.3828
Episode: 3721/30000 (12.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5860s / 44.5377 s
agent0:                 episode reward: -0.1408,                 loss: nan
agent1:                 episode reward: 0.1408,                 loss: 0.3817
Episode: 3741/30000 (12.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5832s / 45.1209 s
agent0:                 episode reward: -0.4834,                 loss: nan
agent1:                 episode reward: 0.4834,                 loss: 0.3780
Episode: 3761/30000 (12.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5794s / 45.7003 s
agent0:                 episode reward: -0.0901,                 loss: nan
agent1:                 episode reward: 0.0901,                 loss: 0.3803
Episode: 3781/30000 (12.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5838s / 46.2841 s
agent0:                 episode reward: -0.3120,                 loss: nan
agent1:                 episode reward: 0.3120,                 loss: 0.3779
Episode: 3801/30000 (12.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5885s / 46.8726 s
agent0:                 episode reward: -0.1289,                 loss: nan
agent1:                 episode reward: 0.1289,                 loss: 0.3768
Episode: 3821/30000 (12.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5797s / 47.4523 s
agent0:                 episode reward: -0.4172,                 loss: nan
agent1:                 episode reward: 0.4172,                 loss: 0.3791
Episode: 3841/30000 (12.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5772s / 48.0295 s
agent0:                 episode reward: -0.1146,                 loss: nan
agent1:                 episode reward: 0.1146,                 loss: 0.3777
Episode: 3861/30000 (12.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5810s / 48.6105 s
agent0:                 episode reward: 0.1615,                 loss: nan
agent1:                 episode reward: -0.1615,                 loss: 0.3799
Episode: 3881/30000 (12.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5792s / 49.1897 s
agent0:                 episode reward: -0.0372,                 loss: nan
agent1:                 episode reward: 0.0372,                 loss: 0.3785
Episode: 3901/30000 (13.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5746s / 49.7642 s
agent0:                 episode reward: 0.0941,                 loss: nan
agent1:                 episode reward: -0.0941,                 loss: 0.3781
Episode: 3921/30000 (13.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5759s / 50.3401 s
agent0:                 episode reward: -0.3379,                 loss: nan
agent1:                 episode reward: 0.3379,                 loss: 0.3766
Episode: 3941/30000 (13.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5784s / 50.9185 s
agent0:                 episode reward: -0.2251,                 loss: nan
agent1:                 episode reward: 0.2251,                 loss: 0.3746
Episode: 3961/30000 (13.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5830s / 51.5015 s
agent0:                 episode reward: 0.0880,                 loss: nan
agent1:                 episode reward: -0.0880,                 loss: 0.3780
Episode: 3981/30000 (13.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5789s / 52.0804 s
agent0:                 episode reward: -0.0403,                 loss: nan
agent1:                 episode reward: 0.0403,                 loss: 0.3741
Episode: 4001/30000 (13.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5745s / 52.6549 s
agent0:                 episode reward: 0.2596,                 loss: nan
agent1:                 episode reward: -0.2596,                 loss: 0.3748
Episode: 4021/30000 (13.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5795s / 53.2344 s
agent0:                 episode reward: -0.1184,                 loss: nan
agent1:                 episode reward: 0.1184,                 loss: 0.3988
Episode: 4041/30000 (13.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5736s / 53.8080 s
agent0:                 episode reward: -0.4163,                 loss: nan
agent1:                 episode reward: 0.4163,                 loss: 0.3979
Episode: 4061/30000 (13.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5893s / 54.3972 s
agent0:                 episode reward: -0.0188,                 loss: nan
agent1:                 episode reward: 0.0188,                 loss: 0.3978
Episode: 4081/30000 (13.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5792s / 54.9765 s
agent0:                 episode reward: -0.2008,                 loss: nan
agent1:                 episode reward: 0.2008,                 loss: 0.3960
Episode: 4101/30000 (13.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5800s / 55.5565 s
agent0:                 episode reward: 0.0213,                 loss: nan
agent1:                 episode reward: -0.0213,                 loss: 0.3926
Episode: 4121/30000 (13.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5771s / 56.1336 s
agent0:                 episode reward: -0.0646,                 loss: nan
agent1:                 episode reward: 0.0646,                 loss: 0.3906
Episode: 4141/30000 (13.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5801s / 56.7138 s
agent0:                 episode reward: -0.2177,                 loss: nan
agent1:                 episode reward: 0.2177,                 loss: 0.3880
Episode: 4161/30000 (13.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5778s / 57.2915 s
agent0:                 episode reward: -0.0867,                 loss: nan
agent1:                 episode reward: 0.0867,                 loss: 0.3902
Episode: 4181/30000 (13.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5979s / 57.8894 s
agent0:                 episode reward: 0.0343,                 loss: nan
agent1:                 episode reward: -0.0343,                 loss: 0.3877
Episode: 4201/30000 (14.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5922s / 58.4816 s
agent0:                 episode reward: 0.0311,                 loss: nan
agent1:                 episode reward: -0.0311,                 loss: 0.3938
Episode: 4221/30000 (14.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5853s / 59.0669 s
agent0:                 episode reward: -0.2736,                 loss: nan
agent1:                 episode reward: 0.2736,                 loss: 0.3881
Episode: 4241/30000 (14.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5902s / 59.6571 s
agent0:                 episode reward: -0.1462,                 loss: nan
agent1:                 episode reward: 0.1462,                 loss: 0.3871
Episode: 4261/30000 (14.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5904s / 60.2475 s
agent0:                 episode reward: -0.2448,                 loss: nan
agent1:                 episode reward: 0.2448,                 loss: 0.3872
Episode: 4281/30000 (14.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5803s / 60.8278 s
agent0:                 episode reward: -0.3187,                 loss: nan
agent1:                 episode reward: 0.3187,                 loss: 0.3858
Episode: 4301/30000 (14.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6176s / 61.4454 s
agent0:                 episode reward: -0.2950,                 loss: nan
agent1:                 episode reward: 0.2950,                 loss: 0.3865
Episode: 4321/30000 (14.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6897s / 62.1351 s
agent0:                 episode reward: -0.1317,                 loss: nan
agent1:                 episode reward: 0.1317,                 loss: 0.3826
Episode: 4341/30000 (14.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6584s / 62.7935 s
agent0:                 episode reward: -0.2096,                 loss: nan
agent1:                 episode reward: 0.2096,                 loss: 0.3785
Episode: 4361/30000 (14.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6070s / 63.4005 s
agent0:                 episode reward: 0.4250,                 loss: nan
agent1:                 episode reward: -0.4250,                 loss: 0.3666
Episode: 4381/30000 (14.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6201s / 64.0206 s
agent0:                 episode reward: 0.0549,                 loss: nan
agent1:                 episode reward: -0.0549,                 loss: 0.3642
Episode: 4401/30000 (14.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5919s / 64.6125 s
agent0:                 episode reward: 0.0138,                 loss: nan
agent1:                 episode reward: -0.0138,                 loss: 0.3663
Episode: 4421/30000 (14.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5838s / 65.1963 s
agent0:                 episode reward: 0.0774,                 loss: nan
agent1:                 episode reward: -0.0774,                 loss: 0.3637
Episode: 4441/30000 (14.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5842s / 65.7804 s
agent0:                 episode reward: -0.5588,                 loss: nan
agent1:                 episode reward: 0.5588,                 loss: 0.3641
Episode: 4461/30000 (14.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5896s / 66.3700 s
agent0:                 episode reward: -0.0266,                 loss: nan
agent1:                 episode reward: 0.0266,                 loss: 0.3607
Episode: 4481/30000 (14.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5879s / 66.9579 s
agent0:                 episode reward: -0.4460,                 loss: nan
agent1:                 episode reward: 0.4460,                 loss: 0.3603
Episode: 4501/30000 (15.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5867s / 67.5446 s
agent0:                 episode reward: -0.1548,                 loss: nan
agent1:                 episode reward: 0.1548,                 loss: 0.3550
Episode: 4521/30000 (15.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5976s / 68.1422 s
agent0:                 episode reward: -0.1778,                 loss: nan
agent1:                 episode reward: 0.1778,                 loss: 0.3583
Episode: 4541/30000 (15.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5851s / 68.7273 s
agent0:                 episode reward: -0.3828,                 loss: nan
agent1:                 episode reward: 0.3828,                 loss: 0.3561
Episode: 4561/30000 (15.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5871s / 69.3143 s
agent0:                 episode reward: -0.0553,                 loss: nan
agent1:                 episode reward: 0.0553,                 loss: 0.3565
Episode: 4581/30000 (15.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5896s / 69.9039 s
agent0:                 episode reward: 0.0616,                 loss: nan
agent1:                 episode reward: -0.0616,                 loss: 0.3597
Episode: 4601/30000 (15.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5869s / 70.4909 s
agent0:                 episode reward: -0.4415,                 loss: nan
agent1:                 episode reward: 0.4415,                 loss: 0.3539
Episode: 4621/30000 (15.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5843s / 71.0752 s
agent0:                 episode reward: -0.2135,                 loss: nan
agent1:                 episode reward: 0.2135,                 loss: 0.3535
Episode: 4641/30000 (15.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5959s / 71.6710 s
agent0:                 episode reward: -0.0154,                 loss: nan
agent1:                 episode reward: 0.0154,                 loss: 0.3563
Episode: 4661/30000 (15.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5898s / 72.2609 s
agent0:                 episode reward: -0.4098,                 loss: nan
agent1:                 episode reward: 0.4098,                 loss: 0.3565
Episode: 4681/30000 (15.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5931s / 72.8540 s
agent0:                 episode reward: -0.4359,                 loss: nan
agent1:                 episode reward: 0.4359,                 loss: 0.3579
Episode: 4701/30000 (15.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5881s / 73.4421 s
agent0:                 episode reward: -0.4796,                 loss: nan
agent1:                 episode reward: 0.4796,                 loss: 0.3482
Episode: 4721/30000 (15.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5978s / 74.0399 s
agent0:                 episode reward: -0.1881,                 loss: nan
agent1:                 episode reward: 0.1881,                 loss: 0.3528
Episode: 4741/30000 (15.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5902s / 74.6300 s
agent0:                 episode reward: -0.3880,                 loss: nan
agent1:                 episode reward: 0.3880,                 loss: 0.3501
Episode: 4761/30000 (15.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5837s / 75.2137 s
agent0:                 episode reward: 0.0087,                 loss: nan
agent1:                 episode reward: -0.0087,                 loss: 0.3501
Episode: 4781/30000 (15.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5798s / 75.7935 s
agent0:                 episode reward: -0.3917,                 loss: nan
agent1:                 episode reward: 0.3917,                 loss: 0.3472
Episode: 4801/30000 (16.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5867s / 76.3802 s
agent0:                 episode reward: -0.3120,                 loss: nan
agent1:                 episode reward: 0.3120,                 loss: 0.3468
Episode: 4821/30000 (16.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5799s / 76.9601 s
agent0:                 episode reward: -0.2208,                 loss: nan
agent1:                 episode reward: 0.2208,                 loss: 0.3451
Episode: 4841/30000 (16.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5942s / 77.5543 s
agent0:                 episode reward: -0.4332,                 loss: nan
agent1:                 episode reward: 0.4332,                 loss: 0.3472
Episode: 4861/30000 (16.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5845s / 78.1388 s
agent0:                 episode reward: -0.2665,                 loss: nan
agent1:                 episode reward: 0.2665,                 loss: 0.3484
Episode: 4881/30000 (16.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5999s / 78.7388 s
agent0:                 episode reward: -0.3759,                 loss: nan
agent1:                 episode reward: 0.3759,                 loss: 0.3454
Episode: 4901/30000 (16.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5877s / 79.3265 s
agent0:                 episode reward: -0.0018,                 loss: nan
agent1:                 episode reward: 0.0018,                 loss: 0.3424
Episode: 4921/30000 (16.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5806s / 79.9071 s
agent0:                 episode reward: -0.6149,                 loss: nan
agent1:                 episode reward: 0.6149,                 loss: 0.3463
Episode: 4941/30000 (16.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5947s / 80.5018 s
agent0:                 episode reward: -0.1480,                 loss: nan
agent1:                 episode reward: 0.1480,                 loss: 0.3435
Episode: 4961/30000 (16.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5935s / 81.0953 s
agent0:                 episode reward: -0.5220,                 loss: nan
agent1:                 episode reward: 0.5220,                 loss: 0.3385
Episode: 4981/30000 (16.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5832s / 81.6785 s
agent0:                 episode reward: -0.7992,                 loss: nan
agent1:                 episode reward: 0.7992,                 loss: 0.3394
Episode: 5001/30000 (16.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5910s / 82.2695 s
agent0:                 episode reward: -0.6255,                 loss: nan
agent1:                 episode reward: 0.6255,                 loss: 0.3469
Episode: 5021/30000 (16.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5880s / 82.8575 s
agent0:                 episode reward: -0.3696,                 loss: nan
agent1:                 episode reward: 0.3696,                 loss: 0.3621
Episode: 5041/30000 (16.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5879s / 83.4454 s
agent0:                 episode reward: 0.1996,                 loss: nan
agent1:                 episode reward: -0.1996,                 loss: 0.3597
Episode: 5061/30000 (16.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6010s / 84.0464 s
agent0:                 episode reward: -0.3798,                 loss: nan
agent1:                 episode reward: 0.3798,                 loss: 0.3567
Episode: 5081/30000 (16.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5768s / 84.6231 s
agent0:                 episode reward: -0.0609,                 loss: nan
agent1:                 episode reward: 0.0609,                 loss: 0.3603
Episode: 5101/30000 (17.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5853s / 85.2084 s
agent0:                 episode reward: -0.1986,                 loss: nan
agent1:                 episode reward: 0.1986,                 loss: 0.3601
Episode: 5121/30000 (17.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5956s / 85.8040 s
agent0:                 episode reward: -0.9376,                 loss: nan
agent1:                 episode reward: 0.9376,                 loss: 0.3563
Episode: 5141/30000 (17.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5967s / 86.4007 s
agent0:                 episode reward: -0.6559,                 loss: nan
agent1:                 episode reward: 0.6559,                 loss: 0.3618
Episode: 5161/30000 (17.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5942s / 86.9949 s
agent0:                 episode reward: -0.4808,                 loss: nan
agent1:                 episode reward: 0.4808,                 loss: 0.3584
Episode: 5181/30000 (17.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5906s / 87.5855 s
agent0:                 episode reward: -0.6700,                 loss: nan
agent1:                 episode reward: 0.6700,                 loss: 0.3573
Episode: 5201/30000 (17.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5952s / 88.1807 s
agent0:                 episode reward: -0.6509,                 loss: nan
agent1:                 episode reward: 0.6509,                 loss: 0.3553
Episode: 5221/30000 (17.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5988s / 88.7795 s
agent0:                 episode reward: -0.5039,                 loss: nan
agent1:                 episode reward: 0.5039,                 loss: 0.3558
Episode: 5241/30000 (17.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5939s / 89.3734 s
agent0:                 episode reward: -0.8069,                 loss: nan
agent1:                 episode reward: 0.8069,                 loss: 0.3563
Episode: 5261/30000 (17.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5922s / 89.9655 s
agent0:                 episode reward: -0.9469,                 loss: nan
agent1:                 episode reward: 0.9469,                 loss: 0.3532
Episode: 5281/30000 (17.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5919s / 90.5575 s
agent0:                 episode reward: -0.5245,                 loss: nan
agent1:                 episode reward: 0.5245,                 loss: 0.3569
Episode: 5301/30000 (17.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5947s / 91.1521 s
agent0:                 episode reward: -0.5273,                 loss: nan
agent1:                 episode reward: 0.5273,                 loss: 0.3523
Episode: 5321/30000 (17.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5905s / 91.7426 s
agent0:                 episode reward: -0.6660,                 loss: nan
agent1:                 episode reward: 0.6660,                 loss: 0.3534
Episode: 5341/30000 (17.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5982s / 92.3408 s
agent0:                 episode reward: -0.7455,                 loss: nan
agent1:                 episode reward: 0.7455,                 loss: 0.3376
Episode: 5361/30000 (17.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5975s / 92.9383 s
agent0:                 episode reward: -0.7614,                 loss: nan
agent1:                 episode reward: 0.7614,                 loss: 0.3098
Episode: 5381/30000 (17.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5945s / 93.5328 s
agent0:                 episode reward: -0.6963,                 loss: nan
agent1:                 episode reward: 0.6963,                 loss: 0.3111
Episode: 5401/30000 (18.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5947s / 94.1275 s
agent0:                 episode reward: -0.7786,                 loss: nan
agent1:                 episode reward: 0.7786,                 loss: 0.3068
Episode: 5421/30000 (18.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5923s / 94.7199 s
agent0:                 episode reward: -0.5005,                 loss: nan
agent1:                 episode reward: 0.5005,                 loss: 0.3124
Episode: 5441/30000 (18.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5962s / 95.3161 s
agent0:                 episode reward: -0.5393,                 loss: nan
agent1:                 episode reward: 0.5393,                 loss: 0.3145
Episode: 5461/30000 (18.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5912s / 95.9073 s
agent0:                 episode reward: -0.5522,                 loss: nan
agent1:                 episode reward: 0.5522,                 loss: 0.3108
Episode: 5481/30000 (18.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5954s / 96.5027 s
agent0:                 episode reward: -0.2577,                 loss: nan
agent1:                 episode reward: 0.2577,                 loss: 0.3089
Episode: 5501/30000 (18.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5899s / 97.0925 s
agent0:                 episode reward: -0.4861,                 loss: nan
agent1:                 episode reward: 0.4861,                 loss: 0.3091
Episode: 5521/30000 (18.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5936s / 97.6861 s
agent0:                 episode reward: -0.4539,                 loss: nan
agent1:                 episode reward: 0.4539,                 loss: 0.3081
Episode: 5541/30000 (18.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5936s / 98.2798 s
agent0:                 episode reward: -0.2332,                 loss: nan
agent1:                 episode reward: 0.2332,                 loss: 0.3086
Episode: 5561/30000 (18.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5896s / 98.8693 s
agent0:                 episode reward: -0.3816,                 loss: nan
agent1:                 episode reward: 0.3816,                 loss: 0.3090
Episode: 5581/30000 (18.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5993s / 99.4687 s
agent0:                 episode reward: -0.3378,                 loss: nan
agent1:                 episode reward: 0.3378,                 loss: 0.3052
Episode: 5601/30000 (18.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5822s / 100.0508 s
agent0:                 episode reward: -0.3470,                 loss: nan
agent1:                 episode reward: 0.3470,                 loss: 0.3120
Episode: 5621/30000 (18.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5910s / 100.6418 s
agent0:                 episode reward: -0.4053,                 loss: nan
agent1:                 episode reward: 0.4053,                 loss: 0.3083
Episode: 5641/30000 (18.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5954s / 101.2372 s
agent0:                 episode reward: -0.4974,                 loss: nan
agent1:                 episode reward: 0.4974,                 loss: 0.3107
Episode: 5661/30000 (18.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5946s / 101.8319 s
agent0:                 episode reward: -0.6311,                 loss: nan
agent1:                 episode reward: 0.6311,                 loss: 0.3094
Episode: 5681/30000 (18.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5856s / 102.4175 s
agent0:                 episode reward: -0.4375,                 loss: nan
agent1:                 episode reward: 0.4375,                 loss: 0.3096
Episode: 5701/30000 (19.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5932s / 103.0107 s
agent0:                 episode reward: -0.0581,                 loss: nan
agent1:                 episode reward: 0.0581,                 loss: 0.3081
Episode: 5721/30000 (19.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5889s / 103.5996 s
agent0:                 episode reward: -0.6232,                 loss: nan
agent1:                 episode reward: 0.6232,                 loss: 0.3113
Episode: 5741/30000 (19.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5908s / 104.1904 s
agent0:                 episode reward: -0.2344,                 loss: nan
agent1:                 episode reward: 0.2344,                 loss: 0.3067
Episode: 5761/30000 (19.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5943s / 104.7847 s
agent0:                 episode reward: -0.8480,                 loss: nan
agent1:                 episode reward: 0.8480,                 loss: 0.3058
Episode: 5781/30000 (19.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5969s / 105.3816 s
agent0:                 episode reward: -0.1148,                 loss: nan
agent1:                 episode reward: 0.1148,                 loss: 0.3107
Episode: 5801/30000 (19.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5942s / 105.9758 s
agent0:                 episode reward: -0.2945,                 loss: nan
agent1:                 episode reward: 0.2945,                 loss: 0.3095
Episode: 5821/30000 (19.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5893s / 106.5651 s
agent0:                 episode reward: -0.4196,                 loss: nan
agent1:                 episode reward: 0.4196,                 loss: 0.3113
Episode: 5841/30000 (19.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5941s / 107.1592 s
agent0:                 episode reward: -0.5185,                 loss: nan
agent1:                 episode reward: 0.5185,                 loss: 0.3114
Episode: 5861/30000 (19.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5864s / 107.7456 s
agent0:                 episode reward: -0.3778,                 loss: nan
agent1:                 episode reward: 0.3778,                 loss: 0.3091
Episode: 5881/30000 (19.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5926s / 108.3382 s
agent0:                 episode reward: -0.0044,                 loss: nan
agent1:                 episode reward: 0.0044,                 loss: 0.3093
Episode: 5901/30000 (19.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5876s / 108.9259 s
agent0:                 episode reward: -0.3433,                 loss: nan
agent1:                 episode reward: 0.3433,                 loss: 0.3095
Episode: 5921/30000 (19.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5898s / 109.5157 s
agent0:                 episode reward: -0.2588,                 loss: nan
agent1:                 episode reward: 0.2588,                 loss: 0.3133
Episode: 5941/30000 (19.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5895s / 110.1051 s
agent0:                 episode reward: -0.4571,                 loss: nan
agent1:                 episode reward: 0.4571,                 loss: 0.3109
Episode: 5961/30000 (19.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5984s / 110.7036 s
agent0:                 episode reward: -0.2704,                 loss: nan
agent1:                 episode reward: 0.2704,                 loss: 0.3123
Episode: 5981/30000 (19.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5904s / 111.2939 s
agent0:                 episode reward: -0.9099,                 loss: nan
agent1:                 episode reward: 0.9099,                 loss: 0.3136
Episode: 6001/30000 (20.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6087s / 111.9026 s
agent0:                 episode reward: -0.1702,                 loss: nan
agent1:                 episode reward: 0.1702,                 loss: 0.3101
Episode: 6021/30000 (20.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6124s / 112.5151 s
agent0:                 episode reward: -0.5787,                 loss: nan
agent1:                 episode reward: 0.5787,                 loss: 0.3356
Episode: 6041/30000 (20.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6075s / 113.1226 s
agent0:                 episode reward: -0.3629,                 loss: nan
agent1:                 episode reward: 0.3629,                 loss: 0.3319
Episode: 6061/30000 (20.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5999s / 113.7225 s
agent0:                 episode reward: -0.7119,                 loss: nan
agent1:                 episode reward: 0.7119,                 loss: 0.3347
Episode: 6081/30000 (20.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6033s / 114.3257 s
agent0:                 episode reward: -0.5485,                 loss: nan
agent1:                 episode reward: 0.5485,                 loss: 0.3312
Episode: 6101/30000 (20.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6002s / 114.9260 s
agent0:                 episode reward: -0.6801,                 loss: nan
agent1:                 episode reward: 0.6801,                 loss: 0.3313
Episode: 6121/30000 (20.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5903s / 115.5162 s
agent0:                 episode reward: -0.3092,                 loss: nan
agent1:                 episode reward: 0.3092,                 loss: 0.3349
Episode: 6141/30000 (20.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5976s / 116.1138 s
agent0:                 episode reward: -0.3439,                 loss: nan
agent1:                 episode reward: 0.3439,                 loss: 0.3337
Episode: 6161/30000 (20.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5942s / 116.7080 s
agent0:                 episode reward: -0.7064,                 loss: nan
agent1:                 episode reward: 0.7064,                 loss: 0.3303
Episode: 6181/30000 (20.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5970s / 117.3050 s
agent0:                 episode reward: -0.6825,                 loss: nan
agent1:                 episode reward: 0.6825,                 loss: 0.3352
Episode: 6201/30000 (20.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6018s / 117.9069 s
agent0:                 episode reward: -0.7604,                 loss: nan
agent1:                 episode reward: 0.7604,                 loss: 0.3322
Episode: 6221/30000 (20.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5902s / 118.4971 s
agent0:                 episode reward: -0.3110,                 loss: nan
agent1:                 episode reward: 0.3110,                 loss: 0.3334
Episode: 6241/30000 (20.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5848s / 119.0819 s
agent0:                 episode reward: -0.5285,                 loss: nan
agent1:                 episode reward: 0.5285,                 loss: 0.3297
Episode: 6261/30000 (20.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6004s / 119.6823 s
agent0:                 episode reward: -0.9015,                 loss: nan
agent1:                 episode reward: 0.9015,                 loss: 0.3311
Episode: 6281/30000 (20.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5920s / 120.2743 s
agent0:                 episode reward: -0.5823,                 loss: nan
agent1:                 episode reward: 0.5823,                 loss: 0.3337
Episode: 6301/30000 (21.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5910s / 120.8653 s
agent0:                 episode reward: -0.4498,                 loss: nan
agent1:                 episode reward: 0.4498,                 loss: 0.3359
Episode: 6321/30000 (21.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5930s / 121.4584 s
agent0:                 episode reward: -0.5983,                 loss: nan
agent1:                 episode reward: 0.5983,                 loss: 0.3341
Episode: 6341/30000 (21.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5989s / 122.0573 s
agent0:                 episode reward: -0.4465,                 loss: nan
agent1:                 episode reward: 0.4465,                 loss: 0.3276
Episode: 6361/30000 (21.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6053s / 122.6626 s
agent0:                 episode reward: -0.5202,                 loss: nan
agent1:                 episode reward: 0.5202,                 loss: 0.3224
Episode: 6381/30000 (21.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5993s / 123.2619 s
agent0:                 episode reward: -0.4303,                 loss: nan
agent1:                 episode reward: 0.4303,                 loss: 0.3216
Episode: 6401/30000 (21.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6019s / 123.8639 s
agent0:                 episode reward: -0.2643,                 loss: nan
agent1:                 episode reward: 0.2643,                 loss: 0.3248
Episode: 6421/30000 (21.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5948s / 124.4586 s
agent0:                 episode reward: -0.4023,                 loss: nan
agent1:                 episode reward: 0.4023,                 loss: 0.3245
Episode: 6441/30000 (21.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5979s / 125.0565 s
agent0:                 episode reward: -0.6471,                 loss: nan
agent1:                 episode reward: 0.6471,                 loss: 0.3184
Episode: 6461/30000 (21.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6039s / 125.6604 s
agent0:                 episode reward: -0.2282,                 loss: nan
agent1:                 episode reward: 0.2282,                 loss: 0.3225
Episode: 6481/30000 (21.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5968s / 126.2573 s
agent0:                 episode reward: -0.4697,                 loss: nan
agent1:                 episode reward: 0.4697,                 loss: 0.3236
Episode: 6501/30000 (21.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5980s / 126.8552 s
agent0:                 episode reward: -0.5969,                 loss: nan
agent1:                 episode reward: 0.5969,                 loss: 0.3248
Episode: 6521/30000 (21.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5984s / 127.4537 s
agent0:                 episode reward: -0.2844,                 loss: nan
agent1:                 episode reward: 0.2844,                 loss: 0.3229
Episode: 6541/30000 (21.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5969s / 128.0506 s
agent0:                 episode reward: -0.6261,                 loss: nan
agent1:                 episode reward: 0.6261,                 loss: 0.3215
Episode: 6561/30000 (21.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6149s / 128.6656 s
agent0:                 episode reward: -0.8002,                 loss: nan
agent1:                 episode reward: 0.8002,                 loss: 0.3240
Episode: 6581/30000 (21.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5976s / 129.2632 s
agent0:                 episode reward: -0.9330,                 loss: nan
agent1:                 episode reward: 0.9330,                 loss: 0.3176
Episode: 6601/30000 (22.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5964s / 129.8596 s
agent0:                 episode reward: -0.4585,                 loss: nan
agent1:                 episode reward: 0.4585,                 loss: 0.3203
Episode: 6621/30000 (22.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5982s / 130.4577 s
agent0:                 episode reward: -0.4819,                 loss: nan
agent1:                 episode reward: 0.4819,                 loss: 0.3218
Episode: 6641/30000 (22.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6006s / 131.0583 s
agent0:                 episode reward: -0.3299,                 loss: nan
agent1:                 episode reward: 0.3299,                 loss: 0.3203
Episode: 6661/30000 (22.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5968s / 131.6551 s
agent0:                 episode reward: -0.5191,                 loss: nan
agent1:                 episode reward: 0.5191,                 loss: 0.3192
Episode: 6681/30000 (22.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6051s / 132.2602 s
agent0:                 episode reward: -0.5444,                 loss: nan
agent1:                 episode reward: 0.5444,                 loss: 0.3163
Episode: 6701/30000 (22.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6003s / 132.8605 s
agent0:                 episode reward: -0.1813,                 loss: nan
agent1:                 episode reward: 0.1813,                 loss: 0.3206
Episode: 6721/30000 (22.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5900s / 133.4505 s
agent0:                 episode reward: -0.5471,                 loss: nan
agent1:                 episode reward: 0.5471,                 loss: 0.3225
Episode: 6741/30000 (22.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5942s / 134.0447 s
agent0:                 episode reward: -0.6469,                 loss: nan
agent1:                 episode reward: 0.6469,                 loss: 0.3202
Episode: 6761/30000 (22.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5995s / 134.6442 s
agent0:                 episode reward: -0.6443,                 loss: nan
agent1:                 episode reward: 0.6443,                 loss: 0.3193
Episode: 6781/30000 (22.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5935s / 135.2377 s
agent0:                 episode reward: -0.4789,                 loss: nan
agent1:                 episode reward: 0.4789,                 loss: 0.3193
Episode: 6801/30000 (22.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5913s / 135.8290 s
agent0:                 episode reward: -0.4838,                 loss: nan
agent1:                 episode reward: 0.4838,                 loss: 0.3222
Episode: 6821/30000 (22.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6484s / 136.4774 s
agent0:                 episode reward: -0.6226,                 loss: nan
agent1:                 episode reward: 0.6226,                 loss: 0.3234
Episode: 6841/30000 (22.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6147s / 137.0921 s
agent0:                 episode reward: -0.5750,                 loss: nan
agent1:                 episode reward: 0.5750,                 loss: 0.3229
Episode: 6861/30000 (22.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5928s / 137.6850 s
agent0:                 episode reward: -0.6856,                 loss: nan
agent1:                 episode reward: 0.6856,                 loss: 0.3214
Episode: 6881/30000 (22.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5972s / 138.2822 s
agent0:                 episode reward: -0.7307,                 loss: nan
agent1:                 episode reward: 0.7307,                 loss: 0.3208
Episode: 6901/30000 (23.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5973s / 138.8795 s
agent0:                 episode reward: -0.4659,                 loss: nan
agent1:                 episode reward: 0.4659,                 loss: 0.3208
Episode: 6921/30000 (23.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5874s / 139.4669 s
agent0:                 episode reward: -0.5531,                 loss: nan
agent1:                 episode reward: 0.5531,                 loss: 0.3216
Episode: 6941/30000 (23.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6047s / 140.0717 s
agent0:                 episode reward: -0.2388,                 loss: nan
agent1:                 episode reward: 0.2388,                 loss: 0.3210
Episode: 6961/30000 (23.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5980s / 140.6697 s
agent0:                 episode reward: -0.3111,                 loss: nan
agent1:                 episode reward: 0.3111,                 loss: 0.3199
Episode: 6981/30000 (23.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5969s / 141.2666 s
agent0:                 episode reward: -0.2603,                 loss: nan
agent1:                 episode reward: 0.2603,                 loss: 0.3196
Episode: 7001/30000 (23.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5987s / 141.8654 s
agent0:                 episode reward: -0.5373,                 loss: nan
agent1:                 episode reward: 0.5373,                 loss: 0.3232
Episode: 7021/30000 (23.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5943s / 142.4597 s
agent0:                 episode reward: -0.4541,                 loss: nan
agent1:                 episode reward: 0.4541,                 loss: 0.3282
Episode: 7041/30000 (23.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6019s / 143.0616 s
agent0:                 episode reward: -0.8932,                 loss: nan
agent1:                 episode reward: 0.8932,                 loss: 0.3276
Episode: 7061/30000 (23.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5990s / 143.6606 s
agent0:                 episode reward: -0.9510,                 loss: nan
agent1:                 episode reward: 0.9510,                 loss: 0.3338
Episode: 7081/30000 (23.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6038s / 144.2645 s
agent0:                 episode reward: -0.7673,                 loss: nan
agent1:                 episode reward: 0.7673,                 loss: 0.3359
Episode: 7101/30000 (23.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5994s / 144.8638 s
agent0:                 episode reward: -0.3948,                 loss: nan
agent1:                 episode reward: 0.3948,                 loss: 0.3345
Episode: 7121/30000 (23.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6024s / 145.4662 s
agent0:                 episode reward: -0.4208,                 loss: nan
agent1:                 episode reward: 0.4208,                 loss: 0.3294
Episode: 7141/30000 (23.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6009s / 146.0670 s
agent0:                 episode reward: -0.6918,                 loss: nan
agent1:                 episode reward: 0.6918,                 loss: 0.3323
Episode: 7161/30000 (23.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6057s / 146.6727 s
agent0:                 episode reward: -0.6652,                 loss: nan
agent1:                 episode reward: 0.6652,                 loss: 0.3318
Episode: 7181/30000 (23.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6057s / 147.2784 s
agent0:                 episode reward: -0.6062,                 loss: nan
agent1:                 episode reward: 0.6062,                 loss: 0.3324
Episode: 7201/30000 (24.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6035s / 147.8819 s
agent0:                 episode reward: -0.6003,                 loss: nan
agent1:                 episode reward: 0.6003,                 loss: 0.3315
Episode: 7221/30000 (24.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6025s / 148.4844 s
agent0:                 episode reward: -0.6768,                 loss: nan
agent1:                 episode reward: 0.6768,                 loss: 0.3362
Episode: 7241/30000 (24.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5967s / 149.0811 s
agent0:                 episode reward: -0.8894,                 loss: nan
agent1:                 episode reward: 0.8894,                 loss: 0.3363
Episode: 7261/30000 (24.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5984s / 149.6794 s
agent0:                 episode reward: -0.5689,                 loss: nan
agent1:                 episode reward: 0.5689,                 loss: 0.3322
Episode: 7281/30000 (24.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6197s / 150.2992 s
agent0:                 episode reward: -0.5043,                 loss: nan
agent1:                 episode reward: 0.5043,                 loss: 0.3348
Episode: 7301/30000 (24.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 1.0260s / 151.3252 s
agent0:                 episode reward: -1.1341,                 loss: nan
agent1:                 episode reward: 1.1341,                 loss: 0.3295
Episode: 7321/30000 (24.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9816s / 152.3067 s
agent0:                 episode reward: -0.8945,                 loss: nan
agent1:                 episode reward: 0.8945,                 loss: 0.3356
Episode: 7341/30000 (24.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8989s / 153.2056 s
agent0:                 episode reward: -0.6336,                 loss: nan
agent1:                 episode reward: 0.6336,                 loss: 0.3292
Episode: 7361/30000 (24.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8232s / 154.0288 s
agent0:                 episode reward: -0.3971,                 loss: nan
agent1:                 episode reward: 0.3971,                 loss: 0.3246
Episode: 7381/30000 (24.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7403s / 154.7691 s
agent0:                 episode reward: -0.7199,                 loss: nan
agent1:                 episode reward: 0.7199,                 loss: 0.3252
Episode: 7401/30000 (24.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6900s / 155.4591 s
agent0:                 episode reward: -0.5531,                 loss: nan
agent1:                 episode reward: 0.5531,                 loss: 0.3227
Episode: 7421/30000 (24.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6405s / 156.0996 s
agent0:                 episode reward: -0.5907,                 loss: nan
agent1:                 episode reward: 0.5907,                 loss: 0.3234
Episode: 7441/30000 (24.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6064s / 156.7061 s
agent0:                 episode reward: -0.8001,                 loss: nan
agent1:                 episode reward: 0.8001,                 loss: 0.3273
Episode: 7461/30000 (24.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5995s / 157.3056 s
agent0:                 episode reward: -0.4507,                 loss: nan
agent1:                 episode reward: 0.4507,                 loss: 0.3246
Episode: 7481/30000 (24.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5964s / 157.9020 s
agent0:                 episode reward: -0.6043,                 loss: nan
agent1:                 episode reward: 0.6043,                 loss: 0.3287
Episode: 7501/30000 (25.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6044s / 158.5063 s
agent0:                 episode reward: -0.3660,                 loss: nan
agent1:                 episode reward: 0.3660,                 loss: 0.3250
Episode: 7521/30000 (25.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5990s / 159.1053 s
agent0:                 episode reward: -0.3584,                 loss: nan
agent1:                 episode reward: 0.3584,                 loss: 0.3242
Episode: 7541/30000 (25.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6010s / 159.7063 s
agent0:                 episode reward: -0.6971,                 loss: nan
agent1:                 episode reward: 0.6971,                 loss: 0.3273
Episode: 7561/30000 (25.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5937s / 160.3000 s
agent0:                 episode reward: -0.6447,                 loss: nan
agent1:                 episode reward: 0.6447,                 loss: 0.3239
Episode: 7581/30000 (25.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6078s / 160.9078 s
agent0:                 episode reward: -0.5961,                 loss: nan
agent1:                 episode reward: 0.5961,                 loss: 0.3247
Episode: 7601/30000 (25.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6058s / 161.5136 s
agent0:                 episode reward: -0.6365,                 loss: nan
agent1:                 episode reward: 0.6365,                 loss: 0.3247
Episode: 7621/30000 (25.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5926s / 162.1062 s
agent0:                 episode reward: -0.4154,                 loss: nan
agent1:                 episode reward: 0.4154,                 loss: 0.3244
Episode: 7641/30000 (25.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5978s / 162.7040 s
agent0:                 episode reward: -0.4921,                 loss: nan
agent1:                 episode reward: 0.4921,                 loss: 0.3267
Episode: 7661/30000 (25.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6055s / 163.3095 s
agent0:                 episode reward: -0.5619,                 loss: nan
agent1:                 episode reward: 0.5619,                 loss: 0.3296
Episode: 7681/30000 (25.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6027s / 163.9122 s
agent0:                 episode reward: -0.4723,                 loss: nan
agent1:                 episode reward: 0.4723,                 loss: 0.3294
Episode: 7701/30000 (25.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6025s / 164.5147 s
agent0:                 episode reward: -0.4874,                 loss: nan
agent1:                 episode reward: 0.4874,                 loss: 0.3330
Episode: 7721/30000 (25.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5994s / 165.1141 s
agent0:                 episode reward: -0.8051,                 loss: nan
agent1:                 episode reward: 0.8051,                 loss: 0.3340
Episode: 7741/30000 (25.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6032s / 165.7172 s
agent0:                 episode reward: -0.5137,                 loss: nan
agent1:                 episode reward: 0.5137,                 loss: 0.3329
Episode: 7761/30000 (25.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6057s / 166.3230 s
agent0:                 episode reward: -0.8449,                 loss: nan
agent1:                 episode reward: 0.8449,                 loss: 0.3337
Episode: 7781/30000 (25.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6059s / 166.9289 s
agent0:                 episode reward: -0.5304,                 loss: nan
agent1:                 episode reward: 0.5304,                 loss: 0.3363
Episode: 7801/30000 (26.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6022s / 167.5310 s
agent0:                 episode reward: -0.7613,                 loss: nan
agent1:                 episode reward: 0.7613,                 loss: 0.3335
Episode: 7821/30000 (26.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6013s / 168.1323 s
agent0:                 episode reward: -0.4293,                 loss: nan
agent1:                 episode reward: 0.4293,                 loss: 0.3299
Episode: 7841/30000 (26.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6077s / 168.7400 s
agent0:                 episode reward: -0.5911,                 loss: nan
agent1:                 episode reward: 0.5911,                 loss: 0.3309
Episode: 7861/30000 (26.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5980s / 169.3380 s
agent0:                 episode reward: -0.3113,                 loss: nan
agent1:                 episode reward: 0.3113,                 loss: 0.3310
Episode: 7881/30000 (26.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6034s / 169.9414 s
agent0:                 episode reward: -0.2861,                 loss: nan
agent1:                 episode reward: 0.2861,                 loss: 0.3330
Episode: 7901/30000 (26.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6029s / 170.5442 s
agent0:                 episode reward: -0.1446,                 loss: nan
agent1:                 episode reward: 0.1446,                 loss: 0.3339
Episode: 7921/30000 (26.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6017s / 171.1460 s
agent0:                 episode reward: -0.8210,                 loss: nan
agent1:                 episode reward: 0.8210,                 loss: 0.3322
Episode: 7941/30000 (26.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6080s / 171.7540 s
agent0:                 episode reward: -0.9111,                 loss: nan
agent1:                 episode reward: 0.9111,                 loss: 0.3335
Episode: 7961/30000 (26.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6138s / 172.3678 s
agent0:                 episode reward: -0.5878,                 loss: nan
agent1:                 episode reward: 0.5878,                 loss: 0.3300
Episode: 7981/30000 (26.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6111s / 172.9790 s
agent0:                 episode reward: -0.5190,                 loss: nan
agent1:                 episode reward: 0.5190,                 loss: 0.3323
Episode: 8001/30000 (26.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6080s / 173.5870 s
agent0:                 episode reward: -0.5797,                 loss: nan
agent1:                 episode reward: 0.5797,                 loss: 0.3318
Episode: 8021/30000 (26.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6150s / 174.2020 s
agent0:                 episode reward: -0.6646,                 loss: nan
agent1:                 episode reward: 0.6646,                 loss: 0.3248
Episode: 8041/30000 (26.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6064s / 174.8084 s
agent0:                 episode reward: -0.6312,                 loss: nan
agent1:                 episode reward: 0.6312,                 loss: 0.3238
Episode: 8061/30000 (26.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6099s / 175.4184 s
agent0:                 episode reward: -0.6061,                 loss: nan
agent1:                 episode reward: 0.6061,                 loss: 0.3270
Episode: 8081/30000 (26.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6076s / 176.0260 s
agent0:                 episode reward: -0.5552,                 loss: nan
agent1:                 episode reward: 0.5552,                 loss: 0.3222
Episode: 8101/30000 (27.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6166s / 176.6426 s
agent0:                 episode reward: -0.4940,                 loss: nan
agent1:                 episode reward: 0.4940,                 loss: 0.3251
Episode: 8121/30000 (27.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6123s / 177.2549 s
agent0:                 episode reward: -0.6305,                 loss: nan
agent1:                 episode reward: 0.6305,                 loss: 0.3282
Episode: 8141/30000 (27.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6184s / 177.8733 s
agent0:                 episode reward: -0.7250,                 loss: nan
agent1:                 episode reward: 0.7250,                 loss: 0.3255
Episode: 8161/30000 (27.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6132s / 178.4865 s
agent0:                 episode reward: -0.8694,                 loss: nan
agent1:                 episode reward: 0.8694,                 loss: 0.3281
Episode: 8181/30000 (27.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7195s / 179.2060 s
agent0:                 episode reward: -0.1834,                 loss: nan
agent1:                 episode reward: 0.1834,                 loss: 0.3272
Episode: 8201/30000 (27.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6434s / 179.8493 s
agent0:                 episode reward: -0.8717,                 loss: nan
agent1:                 episode reward: 0.8717,                 loss: 0.3255
Episode: 8221/30000 (27.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6161s / 180.4654 s
agent0:                 episode reward: -0.6298,                 loss: nan
agent1:                 episode reward: 0.6298,                 loss: 0.3208
Episode: 8241/30000 (27.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6107s / 181.0760 s
agent0:                 episode reward: -0.4897,                 loss: nan
agent1:                 episode reward: 0.4897,                 loss: 0.3277
Episode: 8261/30000 (27.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6119s / 181.6880 s
agent0:                 episode reward: -0.5633,                 loss: nan
agent1:                 episode reward: 0.5633,                 loss: 0.3224
Episode: 8281/30000 (27.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6082s / 182.2962 s
agent0:                 episode reward: -0.6467,                 loss: nan
agent1:                 episode reward: 0.6467,                 loss: 0.3265
Episode: 8301/30000 (27.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6100s / 182.9062 s
agent0:                 episode reward: -0.9173,                 loss: nan
agent1:                 episode reward: 0.9173,                 loss: 0.3268
Episode: 8321/30000 (27.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6124s / 183.5186 s
agent0:                 episode reward: -0.5842,                 loss: nan
agent1:                 episode reward: 0.5842,                 loss: 0.3271
Episode: 8341/30000 (27.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6104s / 184.1290 s
agent0:                 episode reward: -0.5983,                 loss: nan
agent1:                 episode reward: 0.5983,                 loss: 0.3296
Episode: 8361/30000 (27.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6018s / 184.7308 s
agent0:                 episode reward: -0.6398,                 loss: nan
agent1:                 episode reward: 0.6398,                 loss: 0.3382
Episode: 8381/30000 (27.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6082s / 185.3390 s
agent0:                 episode reward: -1.0643,                 loss: nan
agent1:                 episode reward: 1.0643,                 loss: 0.3346
Episode: 8401/30000 (28.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6136s / 185.9526 s
agent0:                 episode reward: -0.5064,                 loss: nan
agent1:                 episode reward: 0.5064,                 loss: 0.3331
Episode: 8421/30000 (28.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6092s / 186.5618 s
agent0:                 episode reward: -0.3441,                 loss: nan
agent1:                 episode reward: 0.3441,                 loss: 0.3374
Episode: 8441/30000 (28.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6049s / 187.1666 s
agent0:                 episode reward: -0.4167,                 loss: nan
agent1:                 episode reward: 0.4167,                 loss: 0.3348
Episode: 8461/30000 (28.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6065s / 187.7731 s
agent0:                 episode reward: -0.4490,                 loss: nan
agent1:                 episode reward: 0.4490,                 loss: 0.3351
Episode: 8481/30000 (28.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6161s / 188.3892 s
agent0:                 episode reward: -0.7960,                 loss: nan
agent1:                 episode reward: 0.7960,                 loss: 0.3397
Episode: 8501/30000 (28.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6117s / 189.0010 s
agent0:                 episode reward: -0.5248,                 loss: nan
agent1:                 episode reward: 0.5248,                 loss: 0.3364
Episode: 8521/30000 (28.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6070s / 189.6080 s
agent0:                 episode reward: -0.5863,                 loss: nan
agent1:                 episode reward: 0.5863,                 loss: 0.3400
Episode: 8541/30000 (28.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6136s / 190.2215 s
agent0:                 episode reward: -0.5663,                 loss: nan
agent1:                 episode reward: 0.5663,                 loss: 0.3339
Episode: 8561/30000 (28.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6177s / 190.8392 s
agent0:                 episode reward: -0.5394,                 loss: nan
agent1:                 episode reward: 0.5394,                 loss: 0.3374
Episode: 8581/30000 (28.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6204s / 191.4596 s
agent0:                 episode reward: -0.6640,                 loss: nan
agent1:                 episode reward: 0.6640,                 loss: 0.3355
Episode: 8601/30000 (28.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6196s / 192.0793 s
agent0:                 episode reward: -0.4393,                 loss: nan
agent1:                 episode reward: 0.4393,                 loss: 0.3370
Episode: 8621/30000 (28.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6165s / 192.6958 s
agent0:                 episode reward: -0.7896,                 loss: nan
agent1:                 episode reward: 0.7896,                 loss: 0.3349
Episode: 8641/30000 (28.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6186s / 193.3144 s
agent0:                 episode reward: -0.4159,                 loss: nan
agent1:                 episode reward: 0.4159,                 loss: 0.3407
Episode: 8661/30000 (28.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6227s / 193.9371 s
agent0:                 episode reward: -0.5125,                 loss: nan
agent1:                 episode reward: 0.5125,                 loss: 0.3391
Episode: 8681/30000 (28.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6093s / 194.5465 s
agent0:                 episode reward: -0.2457,                 loss: nan
agent1:                 episode reward: 0.2457,                 loss: 0.3294
Episode: 8701/30000 (29.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6150s / 195.1614 s
agent0:                 episode reward: -0.5439,                 loss: nan
agent1:                 episode reward: 0.5439,                 loss: 0.3234
Episode: 8721/30000 (29.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6122s / 195.7736 s
agent0:                 episode reward: -0.2085,                 loss: nan
agent1:                 episode reward: 0.2085,                 loss: 0.3221
Episode: 8741/30000 (29.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6055s / 196.3792 s
agent0:                 episode reward: -0.6684,                 loss: nan
agent1:                 episode reward: 0.6684,                 loss: 0.3236
Episode: 8761/30000 (29.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6097s / 196.9888 s
agent0:                 episode reward: -0.6876,                 loss: nan
agent1:                 episode reward: 0.6876,                 loss: 0.3224
Episode: 8781/30000 (29.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6011s / 197.5899 s
agent0:                 episode reward: -0.6133,                 loss: nan
agent1:                 episode reward: 0.6133,                 loss: 0.3245
Episode: 8801/30000 (29.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6205s / 198.2104 s
agent0:                 episode reward: -0.8384,                 loss: nan
agent1:                 episode reward: 0.8384,                 loss: 0.3212
Episode: 8821/30000 (29.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6092s / 198.8196 s
agent0:                 episode reward: -0.6447,                 loss: nan
agent1:                 episode reward: 0.6447,                 loss: 0.3228
Episode: 8841/30000 (29.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6112s / 199.4308 s
agent0:                 episode reward: -0.6757,                 loss: nan
agent1:                 episode reward: 0.6757,                 loss: 0.3217
Episode: 8861/30000 (29.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6169s / 200.0476 s
agent0:                 episode reward: -0.7391,                 loss: nan
agent1:                 episode reward: 0.7391,                 loss: 0.3236
Episode: 8881/30000 (29.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6124s / 200.6601 s
agent0:                 episode reward: -0.7159,                 loss: nan
agent1:                 episode reward: 0.7159,                 loss: 0.3243
Episode: 8901/30000 (29.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6158s / 201.2759 s
agent0:                 episode reward: -0.5822,                 loss: nan
agent1:                 episode reward: 0.5822,                 loss: 0.3220
Episode: 8921/30000 (29.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6168s / 201.8927 s
agent0:                 episode reward: -0.6190,                 loss: nan
agent1:                 episode reward: 0.6190,                 loss: 0.3203
Episode: 8941/30000 (29.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6112s / 202.5039 s
agent0:                 episode reward: -0.7236,                 loss: nan
agent1:                 episode reward: 0.7236,                 loss: 0.3225
Episode: 8961/30000 (29.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6173s / 203.1212 s
agent0:                 episode reward: -0.6476,                 loss: nan
agent1:                 episode reward: 0.6476,                 loss: 0.3222
Episode: 8981/30000 (29.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6089s / 203.7301 s
agent0:                 episode reward: -0.6768,                 loss: nan
agent1:                 episode reward: 0.6768,                 loss: 0.3237
Episode: 9001/30000 (30.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6113s / 204.3413 s
agent0:                 episode reward: -0.3996,                 loss: nan
agent1:                 episode reward: 0.3996,                 loss: 0.3264
Episode: 9021/30000 (30.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6178s / 204.9591 s
agent0:                 episode reward: -0.5732,                 loss: nan
agent1:                 episode reward: 0.5732,                 loss: 0.3381
Episode: 9041/30000 (30.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6512s / 205.6104 s
agent0:                 episode reward: -0.8606,                 loss: nan
agent1:                 episode reward: 0.8606,                 loss: 0.3388
Episode: 9061/30000 (30.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6105s / 206.2208 s
agent0:                 episode reward: -0.6457,                 loss: nan
agent1:                 episode reward: 0.6457,                 loss: 0.3417
Episode: 9081/30000 (30.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6098s / 206.8307 s
agent0:                 episode reward: -0.8284,                 loss: nan
agent1:                 episode reward: 0.8284,                 loss: 0.3429
Episode: 9101/30000 (30.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6147s / 207.4454 s
agent0:                 episode reward: -0.7321,                 loss: nan
agent1:                 episode reward: 0.7321,                 loss: 0.3422
Episode: 9121/30000 (30.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6142s / 208.0595 s
agent0:                 episode reward: -0.8599,                 loss: nan
agent1:                 episode reward: 0.8599,                 loss: 0.3383
Episode: 9141/30000 (30.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6144s / 208.6740 s
agent0:                 episode reward: -0.7419,                 loss: nan
agent1:                 episode reward: 0.7419,                 loss: 0.3413
Episode: 9161/30000 (30.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6170s / 209.2910 s
agent0:                 episode reward: -0.6306,                 loss: nan
agent1:                 episode reward: 0.6306,                 loss: 0.3395
Episode: 9181/30000 (30.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6210s / 209.9120 s
agent0:                 episode reward: -0.3735,                 loss: nan
agent1:                 episode reward: 0.3735,                 loss: 0.3376
Episode: 9201/30000 (30.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6146s / 210.5266 s
agent0:                 episode reward: -0.5178,                 loss: nan
agent1:                 episode reward: 0.5178,                 loss: 0.3395
Episode: 9221/30000 (30.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6235s / 211.1501 s
agent0:                 episode reward: -0.7816,                 loss: nan
agent1:                 episode reward: 0.7816,                 loss: 0.3400
Episode: 9241/30000 (30.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6187s / 211.7688 s
agent0:                 episode reward: -0.3458,                 loss: nan
agent1:                 episode reward: 0.3458,                 loss: 0.3438
Episode: 9261/30000 (30.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6130s / 212.3818 s
agent0:                 episode reward: -0.2342,                 loss: nan
agent1:                 episode reward: 0.2342,                 loss: 0.3425
Episode: 9281/30000 (30.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6153s / 212.9971 s
agent0:                 episode reward: -0.2437,                 loss: nan
agent1:                 episode reward: 0.2437,                 loss: 0.3360
Episode: 9301/30000 (31.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6221s / 213.6192 s
agent0:                 episode reward: -0.7897,                 loss: nan
agent1:                 episode reward: 0.7897,                 loss: 0.3408
Episode: 9321/30000 (31.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6195s / 214.2388 s
agent0:                 episode reward: -0.6278,                 loss: nan
agent1:                 episode reward: 0.6278,                 loss: 0.3371
Episode: 9341/30000 (31.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6183s / 214.8571 s
agent0:                 episode reward: -0.8390,                 loss: nan
agent1:                 episode reward: 0.8390,                 loss: 0.3354
Episode: 9361/30000 (31.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6142s / 215.4712 s
agent0:                 episode reward: -0.8457,                 loss: nan
agent1:                 episode reward: 0.8457,                 loss: 0.3225
Episode: 9381/30000 (31.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6162s / 216.0874 s
agent0:                 episode reward: -0.2298,                 loss: nan
agent1:                 episode reward: 0.2298,                 loss: 0.3253
Episode: 9401/30000 (31.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6270s / 216.7144 s
agent0:                 episode reward: -0.5850,                 loss: nan
agent1:                 episode reward: 0.5850,                 loss: 0.3228
Episode: 9421/30000 (31.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6148s / 217.3291 s
agent0:                 episode reward: -0.4273,                 loss: nan
agent1:                 episode reward: 0.4273,                 loss: 0.3233
Episode: 9441/30000 (31.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6230s / 217.9521 s
agent0:                 episode reward: -0.3609,                 loss: nan
agent1:                 episode reward: 0.3609,                 loss: 0.3261
Episode: 9461/30000 (31.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6132s / 218.5653 s
agent0:                 episode reward: -0.6770,                 loss: nan
agent1:                 episode reward: 0.6770,                 loss: 0.3284
Episode: 9481/30000 (31.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6158s / 219.1811 s
agent0:                 episode reward: -0.5266,                 loss: nan
agent1:                 episode reward: 0.5266,                 loss: 0.3251
Episode: 9501/30000 (31.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6243s / 219.8054 s
agent0:                 episode reward: -0.8479,                 loss: nan
agent1:                 episode reward: 0.8479,                 loss: 0.3264
Episode: 9521/30000 (31.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6189s / 220.4244 s
agent0:                 episode reward: -0.5949,                 loss: nan
agent1:                 episode reward: 0.5949,                 loss: 0.3243
Episode: 9541/30000 (31.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6113s / 221.0356 s
agent0:                 episode reward: -0.5090,                 loss: nan
agent1:                 episode reward: 0.5090,                 loss: 0.3272
Episode: 9561/30000 (31.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6217s / 221.6573 s
agent0:                 episode reward: -0.8315,                 loss: nan
agent1:                 episode reward: 0.8315,                 loss: 0.3232
Episode: 9581/30000 (31.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6160s / 222.2734 s
agent0:                 episode reward: -0.6088,                 loss: nan
agent1:                 episode reward: 0.6088,                 loss: 0.3243
Episode: 9601/30000 (32.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6163s / 222.8897 s
agent0:                 episode reward: -0.5561,                 loss: nan
agent1:                 episode reward: 0.5561,                 loss: 0.3250
Episode: 9621/30000 (32.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6244s / 223.5141 s
agent0:                 episode reward: -0.6835,                 loss: nan
agent1:                 episode reward: 0.6835,                 loss: 0.3270
Episode: 9641/30000 (32.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6232s / 224.1373 s
agent0:                 episode reward: -0.7485,                 loss: nan
agent1:                 episode reward: 0.7485,                 loss: 0.3241
Episode: 9661/30000 (32.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6186s / 224.7559 s
agent0:                 episode reward: -0.7012,                 loss: nan
agent1:                 episode reward: 0.7012,                 loss: 0.3242
Episode: 9681/30000 (32.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6254s / 225.3813 s
agent0:                 episode reward: -0.8513,                 loss: nan
agent1:                 episode reward: 0.8513,                 loss: 0.3389
Episode: 9701/30000 (32.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6248s / 226.0062 s
agent0:                 episode reward: -1.0415,                 loss: nan
agent1:                 episode reward: 1.0415,                 loss: 0.3400
Episode: 9721/30000 (32.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6175s / 226.6237 s
agent0:                 episode reward: -0.4684,                 loss: nan
agent1:                 episode reward: 0.4684,                 loss: 0.3391
Episode: 9741/30000 (32.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6227s / 227.2463 s
agent0:                 episode reward: -1.0049,                 loss: nan
agent1:                 episode reward: 1.0049,                 loss: 0.3382
Episode: 9761/30000 (32.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6192s / 227.8655 s
agent0:                 episode reward: -0.5059,                 loss: nan
agent1:                 episode reward: 0.5059,                 loss: 0.3443
Episode: 9781/30000 (32.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6212s / 228.4867 s
agent0:                 episode reward: -0.5260,                 loss: nan
agent1:                 episode reward: 0.5260,                 loss: 0.3377
Episode: 9801/30000 (32.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6279s / 229.1146 s
agent0:                 episode reward: -0.5037,                 loss: nan
agent1:                 episode reward: 0.5037,                 loss: 0.3432
Episode: 9821/30000 (32.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6294s / 229.7440 s
agent0:                 episode reward: -0.4601,                 loss: nan
agent1:                 episode reward: 0.4601,                 loss: 0.3436
Episode: 9841/30000 (32.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6303s / 230.3743 s
agent0:                 episode reward: -0.7543,                 loss: nan
agent1:                 episode reward: 0.7543,                 loss: 0.3394
Episode: 9861/30000 (32.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6252s / 230.9996 s
agent0:                 episode reward: -0.6693,                 loss: nan
agent1:                 episode reward: 0.6693,                 loss: 0.3448
Episode: 9881/30000 (32.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6178s / 231.6174 s
agent0:                 episode reward: -0.6423,                 loss: nan
agent1:                 episode reward: 0.6423,                 loss: 0.3353
Episode: 9901/30000 (33.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6250s / 232.2424 s
agent0:                 episode reward: -0.6263,                 loss: nan
agent1:                 episode reward: 0.6263,                 loss: 0.3407
Episode: 9921/30000 (33.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6184s / 232.8608 s
agent0:                 episode reward: -0.8857,                 loss: nan
agent1:                 episode reward: 0.8857,                 loss: 0.3418
Episode: 9941/30000 (33.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6174s / 233.4782 s
agent0:                 episode reward: -0.4520,                 loss: nan
agent1:                 episode reward: 0.4520,                 loss: 0.3392
Episode: 9961/30000 (33.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6112s / 234.0894 s
agent0:                 episode reward: -0.7319,                 loss: nan
agent1:                 episode reward: 0.7319,                 loss: 0.3387
Episode: 9981/30000 (33.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6158s / 234.7053 s
agent0:                 episode reward: -0.6830,                 loss: nan
agent1:                 episode reward: 0.6830,                 loss: 0.3403
Episode: 10001/30000 (33.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6209s / 235.3261 s
agent0:                 episode reward: -0.4817,                 loss: nan
agent1:                 episode reward: 0.4817,                 loss: 0.3395
Episode: 10021/30000 (33.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6355s / 235.9616 s
agent0:                 episode reward: -0.1912,                 loss: nan
agent1:                 episode reward: 0.1912,                 loss: 0.3252
Episode: 10041/30000 (33.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6112s / 236.5728 s
agent0:                 episode reward: -0.4088,                 loss: nan
agent1:                 episode reward: 0.4088,                 loss: 0.3207
Episode: 10061/30000 (33.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6275s / 237.2003 s
agent0:                 episode reward: -0.4612,                 loss: nan
agent1:                 episode reward: 0.4612,                 loss: 0.3224
Episode: 10081/30000 (33.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6237s / 237.8240 s
agent0:                 episode reward: -0.6256,                 loss: nan
agent1:                 episode reward: 0.6256,                 loss: 0.3204
Episode: 10101/30000 (33.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6135s / 238.4375 s
agent0:                 episode reward: -0.8655,                 loss: nan
agent1:                 episode reward: 0.8655,                 loss: 0.3177
Episode: 10121/30000 (33.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6178s / 239.0553 s
agent0:                 episode reward: -0.2168,                 loss: nan
agent1:                 episode reward: 0.2168,                 loss: 0.3205
Episode: 10141/30000 (33.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6167s / 239.6720 s
agent0:                 episode reward: -0.4121,                 loss: nan
agent1:                 episode reward: 0.4121,                 loss: 0.3271
Episode: 10161/30000 (33.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6142s / 240.2862 s
agent0:                 episode reward: -0.3444,                 loss: nan
agent1:                 episode reward: 0.3444,                 loss: 0.3230
Episode: 10181/30000 (33.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6191s / 240.9054 s
agent0:                 episode reward: -0.5312,                 loss: nan
agent1:                 episode reward: 0.5312,                 loss: 0.3244
Episode: 10201/30000 (34.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6243s / 241.5297 s
agent0:                 episode reward: -0.6909,                 loss: nan
agent1:                 episode reward: 0.6909,                 loss: 0.3259
Episode: 10221/30000 (34.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6188s / 242.1485 s
agent0:                 episode reward: -0.5671,                 loss: nan
agent1:                 episode reward: 0.5671,                 loss: 0.3239
Episode: 10241/30000 (34.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6168s / 242.7653 s
agent0:                 episode reward: -0.4198,                 loss: nan
agent1:                 episode reward: 0.4198,                 loss: 0.3251
Episode: 10261/30000 (34.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6191s / 243.3844 s
agent0:                 episode reward: -0.4307,                 loss: nan
agent1:                 episode reward: 0.4307,                 loss: 0.3238
Episode: 10281/30000 (34.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6235s / 244.0078 s
agent0:                 episode reward: -0.8317,                 loss: nan
agent1:                 episode reward: 0.8317,                 loss: 0.3225
Episode: 10301/30000 (34.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6166s / 244.6244 s
agent0:                 episode reward: -0.3308,                 loss: nan
agent1:                 episode reward: 0.3308,                 loss: 0.3251
Episode: 10321/30000 (34.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6191s / 245.2435 s
agent0:                 episode reward: -0.6167,                 loss: nan
agent1:                 episode reward: 0.6167,                 loss: 0.3212
Episode: 10341/30000 (34.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6203s / 245.8638 s
agent0:                 episode reward: -0.3805,                 loss: nan
agent1:                 episode reward: 0.3805,                 loss: 0.3357
Episode: 10361/30000 (34.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6316s / 246.4955 s
agent0:                 episode reward: -0.5319,                 loss: nan
agent1:                 episode reward: 0.5319,                 loss: 0.3521
Episode: 10381/30000 (34.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6280s / 247.1234 s
agent0:                 episode reward: -0.3665,                 loss: nan
agent1:                 episode reward: 0.3665,                 loss: 0.3500
Episode: 10401/30000 (34.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6330s / 247.7564 s
agent0:                 episode reward: -0.6329,                 loss: nan
agent1:                 episode reward: 0.6329,                 loss: 0.3509
Episode: 10421/30000 (34.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6413s / 248.3977 s
agent0:                 episode reward: -0.5584,                 loss: nan
agent1:                 episode reward: 0.5584,                 loss: 0.3537
Episode: 10441/30000 (34.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6285s / 249.0262 s
agent0:                 episode reward: -0.8833,                 loss: nan
agent1:                 episode reward: 0.8833,                 loss: 0.3509
Episode: 10461/30000 (34.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6318s / 249.6580 s
agent0:                 episode reward: -0.3933,                 loss: nan
agent1:                 episode reward: 0.3933,                 loss: 0.3521
Episode: 10481/30000 (34.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6234s / 250.2814 s
agent0:                 episode reward: -0.5790,                 loss: nan
agent1:                 episode reward: 0.5790,                 loss: 0.3532
Episode: 10501/30000 (35.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6251s / 250.9065 s
agent0:                 episode reward: -0.0313,                 loss: nan
agent1:                 episode reward: 0.0313,                 loss: 0.3492
Episode: 10521/30000 (35.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6161s / 251.5226 s
agent0:                 episode reward: -0.6394,                 loss: nan
agent1:                 episode reward: 0.6394,                 loss: 0.3460
Episode: 10541/30000 (35.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6261s / 252.1487 s
agent0:                 episode reward: -0.5356,                 loss: nan
agent1:                 episode reward: 0.5356,                 loss: 0.3501
Episode: 10561/30000 (35.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6281s / 252.7768 s
agent0:                 episode reward: -0.5608,                 loss: nan
agent1:                 episode reward: 0.5608,                 loss: 0.3496
Episode: 10581/30000 (35.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6292s / 253.4060 s
agent0:                 episode reward: -0.5749,                 loss: nan
agent1:                 episode reward: 0.5749,                 loss: 0.3503
Episode: 10601/30000 (35.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6298s / 254.0358 s
agent0:                 episode reward: -0.5393,                 loss: nan
agent1:                 episode reward: 0.5393,                 loss: 0.3512
Episode: 10621/30000 (35.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6263s / 254.6621 s
agent0:                 episode reward: -0.4345,                 loss: nan
agent1:                 episode reward: 0.4345,                 loss: 0.3544
Episode: 10641/30000 (35.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6394s / 255.3015 s
agent0:                 episode reward: -0.2005,                 loss: nan
agent1:                 episode reward: 0.2005,                 loss: 0.3538
Episode: 10661/30000 (35.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6246s / 255.9261 s
agent0:                 episode reward: -0.5932,                 loss: nan
agent1:                 episode reward: 0.5932,                 loss: 0.3505
Episode: 10681/30000 (35.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6280s / 256.5541 s
agent0:                 episode reward: -0.4706,                 loss: nan
agent1:                 episode reward: 0.4706,                 loss: 0.3347
Episode: 10701/30000 (35.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6265s / 257.1806 s
agent0:                 episode reward: -0.4431,                 loss: nan
agent1:                 episode reward: 0.4431,                 loss: 0.3228
Episode: 10721/30000 (35.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6252s / 257.8058 s
agent0:                 episode reward: -0.6157,                 loss: nan
agent1:                 episode reward: 0.6157,                 loss: 0.3216
Episode: 10741/30000 (35.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6316s / 258.4374 s
agent0:                 episode reward: -0.4059,                 loss: nan
agent1:                 episode reward: 0.4059,                 loss: 0.3208
Episode: 10761/30000 (35.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6390s / 259.0764 s
agent0:                 episode reward: -0.5673,                 loss: nan
agent1:                 episode reward: 0.5673,                 loss: 0.3214
Episode: 10781/30000 (35.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6351s / 259.7115 s
agent0:                 episode reward: -0.6490,                 loss: nan
agent1:                 episode reward: 0.6490,                 loss: 0.3249
Episode: 10801/30000 (36.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6418s / 260.3532 s
agent0:                 episode reward: -0.3105,                 loss: nan
agent1:                 episode reward: 0.3105,                 loss: 0.3230
Episode: 10821/30000 (36.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6325s / 260.9857 s
agent0:                 episode reward: -0.2411,                 loss: nan
agent1:                 episode reward: 0.2411,                 loss: 0.3242
Episode: 10841/30000 (36.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6345s / 261.6202 s
agent0:                 episode reward: -0.4277,                 loss: nan
agent1:                 episode reward: 0.4277,                 loss: 0.3258
Episode: 10861/30000 (36.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6290s / 262.2491 s
agent0:                 episode reward: -0.4529,                 loss: nan
agent1:                 episode reward: 0.4529,                 loss: 0.3230
Episode: 10881/30000 (36.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6302s / 262.8793 s
agent0:                 episode reward: -0.6080,                 loss: nan
agent1:                 episode reward: 0.6080,                 loss: 0.3231
Episode: 10901/30000 (36.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6367s / 263.5160 s
agent0:                 episode reward: -0.6821,                 loss: nan
agent1:                 episode reward: 0.6821,                 loss: 0.3199
Episode: 10921/30000 (36.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6385s / 264.1545 s
agent0:                 episode reward: -0.3571,                 loss: nan
agent1:                 episode reward: 0.3571,                 loss: 0.3246
Episode: 10941/30000 (36.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6294s / 264.7839 s
agent0:                 episode reward: -0.5545,                 loss: nan
agent1:                 episode reward: 0.5545,                 loss: 0.3216
Episode: 10961/30000 (36.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6340s / 265.4179 s
agent0:                 episode reward: -0.5516,                 loss: nan
agent1:                 episode reward: 0.5516,                 loss: 0.3232
Episode: 10981/30000 (36.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6316s / 266.0495 s
agent0:                 episode reward: -0.5883,                 loss: nan
agent1:                 episode reward: 0.5883,                 loss: 0.3226
Episode: 11001/30000 (36.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6388s / 266.6883 s
agent0:                 episode reward: -0.7204,                 loss: nan
agent1:                 episode reward: 0.7204,                 loss: 0.3226
Episode: 11021/30000 (36.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6418s / 267.3300 s
agent0:                 episode reward: -0.5116,                 loss: nan
agent1:                 episode reward: 0.5116,                 loss: 0.3437
Episode: 11041/30000 (36.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6356s / 267.9656 s
agent0:                 episode reward: -0.5525,                 loss: nan
agent1:                 episode reward: 0.5525,                 loss: 0.3446
Episode: 11061/30000 (36.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6375s / 268.6031 s
agent0:                 episode reward: -0.7536,                 loss: nan
agent1:                 episode reward: 0.7536,                 loss: 0.3450
Episode: 11081/30000 (36.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6383s / 269.2414 s
agent0:                 episode reward: -0.6037,                 loss: nan
agent1:                 episode reward: 0.6037,                 loss: 0.3441
Episode: 11101/30000 (37.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6926s / 269.9340 s
agent0:                 episode reward: -0.5607,                 loss: nan
agent1:                 episode reward: 0.5607,                 loss: 0.3478
Episode: 11121/30000 (37.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6453s / 270.5793 s
agent0:                 episode reward: -0.5601,                 loss: nan
agent1:                 episode reward: 0.5601,                 loss: 0.3406
Episode: 11141/30000 (37.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6412s / 271.2205 s
agent0:                 episode reward: -0.7148,                 loss: nan
agent1:                 episode reward: 0.7148,                 loss: 0.3423
Episode: 11161/30000 (37.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6572s / 271.8776 s
agent0:                 episode reward: -0.5695,                 loss: nan
agent1:                 episode reward: 0.5695,                 loss: 0.3432
Episode: 11181/30000 (37.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6524s / 272.5300 s
agent0:                 episode reward: -0.8005,                 loss: nan
agent1:                 episode reward: 0.8005,                 loss: 0.3451
Episode: 11201/30000 (37.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6381s / 273.1681 s
agent0:                 episode reward: -0.3477,                 loss: nan
agent1:                 episode reward: 0.3477,                 loss: 0.3390
Episode: 11221/30000 (37.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6416s / 273.8097 s
agent0:                 episode reward: -0.6822,                 loss: nan
agent1:                 episode reward: 0.6822,                 loss: 0.3408
Episode: 11241/30000 (37.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6327s / 274.4424 s
agent0:                 episode reward: -0.6119,                 loss: nan
agent1:                 episode reward: 0.6119,                 loss: 0.3448
Episode: 11261/30000 (37.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6443s / 275.0867 s
agent0:                 episode reward: -0.4385,                 loss: nan
agent1:                 episode reward: 0.4385,                 loss: 0.3472
Episode: 11281/30000 (37.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6437s / 275.7304 s
agent0:                 episode reward: -0.5195,                 loss: nan
agent1:                 episode reward: 0.5195,                 loss: 0.3456
Episode: 11301/30000 (37.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6307s / 276.3610 s
agent0:                 episode reward: -0.2695,                 loss: nan
agent1:                 episode reward: 0.2695,                 loss: 0.3422
Episode: 11321/30000 (37.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6432s / 277.0042 s
agent0:                 episode reward: -0.5687,                 loss: nan
agent1:                 episode reward: 0.5687,                 loss: 0.3463
Episode: 11341/30000 (37.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6404s / 277.6447 s
agent0:                 episode reward: -0.4407,                 loss: nan
agent1:                 episode reward: 0.4407,                 loss: 0.3462
Episode: 11361/30000 (37.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6392s / 278.2839 s
agent0:                 episode reward: -0.8720,                 loss: nan
agent1:                 episode reward: 0.8720,                 loss: 0.3450
Episode: 11381/30000 (37.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6368s / 278.9207 s
agent0:                 episode reward: -0.7818,                 loss: nan
agent1:                 episode reward: 0.7818,                 loss: 0.3468
Episode: 11401/30000 (38.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6765s / 279.5972 s
agent0:                 episode reward: -0.7683,                 loss: nan
agent1:                 episode reward: 0.7683,                 loss: 0.3469
Episode: 11421/30000 (38.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6508s / 280.2480 s
agent0:                 episode reward: -0.5709,                 loss: nan
agent1:                 episode reward: 0.5709,                 loss: 0.3451
Episode: 11441/30000 (38.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6412s / 280.8892 s
agent0:                 episode reward: -0.4530,                 loss: nan
agent1:                 episode reward: 0.4530,                 loss: 0.3488
Episode: 11461/30000 (38.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6384s / 281.5276 s
agent0:                 episode reward: -0.6492,                 loss: nan
agent1:                 episode reward: 0.6492,                 loss: 0.3437
Episode: 11481/30000 (38.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6340s / 282.1616 s
agent0:                 episode reward: -0.2229,                 loss: nan
agent1:                 episode reward: 0.2229,                 loss: 0.3475
Episode: 11501/30000 (38.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6573s / 282.8189 s
agent0:                 episode reward: -0.6724,                 loss: nan
agent1:                 episode reward: 0.6724,                 loss: 0.3467
Episode: 11521/30000 (38.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6444s / 283.4634 s
agent0:                 episode reward: -0.5278,                 loss: nan
agent1:                 episode reward: 0.5278,                 loss: 0.3434
Episode: 11541/30000 (38.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6425s / 284.1058 s
agent0:                 episode reward: -0.6210,                 loss: nan
agent1:                 episode reward: 0.6210,                 loss: 0.3448
Episode: 11561/30000 (38.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6520s / 284.7578 s
agent0:                 episode reward: -0.9649,                 loss: nan
agent1:                 episode reward: 0.9649,                 loss: 0.3471
Episode: 11581/30000 (38.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6471s / 285.4049 s
agent0:                 episode reward: -0.6237,                 loss: nan
agent1:                 episode reward: 0.6237,                 loss: 0.3484
Episode: 11601/30000 (38.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6408s / 286.0457 s
agent0:                 episode reward: -0.5250,                 loss: nan
agent1:                 episode reward: 0.5250,                 loss: 0.3463
Episode: 11621/30000 (38.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6335s / 286.6792 s
agent0:                 episode reward: -0.3636,                 loss: nan
agent1:                 episode reward: 0.3636,                 loss: 0.3467
Episode: 11641/30000 (38.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6386s / 287.3178 s
agent0:                 episode reward: -0.4584,                 loss: nan
agent1:                 episode reward: 0.4584,                 loss: 0.3440
Episode: 11661/30000 (38.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6414s / 287.9592 s
agent0:                 episode reward: -1.1100,                 loss: nan
agent1:                 episode reward: 1.1100,                 loss: 0.3457
Episode: 11681/30000 (38.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6820s / 288.6412 s
agent0:                 episode reward: -0.7315,                 loss: nan
agent1:                 episode reward: 0.7315,                 loss: 0.3336
Episode: 11701/30000 (39.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6681s / 289.3093 s
agent0:                 episode reward: -0.4858,                 loss: nan
agent1:                 episode reward: 0.4858,                 loss: 0.3287
Episode: 11721/30000 (39.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6386s / 289.9479 s
agent0:                 episode reward: -0.3417,                 loss: nan
agent1:                 episode reward: 0.3417,                 loss: 0.3216
Episode: 11741/30000 (39.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6361s / 290.5840 s
agent0:                 episode reward: -0.6197,                 loss: nan
agent1:                 episode reward: 0.6197,                 loss: 0.3246
Episode: 11761/30000 (39.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6325s / 291.2165 s
agent0:                 episode reward: -0.5064,                 loss: nan
agent1:                 episode reward: 0.5064,                 loss: 0.3241
Episode: 11781/30000 (39.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6424s / 291.8589 s
agent0:                 episode reward: -0.3231,                 loss: nan
agent1:                 episode reward: 0.3231,                 loss: 0.3268
Episode: 11801/30000 (39.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6412s / 292.5001 s
agent0:                 episode reward: -0.6929,                 loss: nan
agent1:                 episode reward: 0.6929,                 loss: 0.3210
Episode: 11821/30000 (39.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6389s / 293.1390 s
agent0:                 episode reward: -0.6284,                 loss: nan
agent1:                 episode reward: 0.6284,                 loss: 0.3269
Episode: 11841/30000 (39.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6505s / 293.7894 s
agent0:                 episode reward: -0.6415,                 loss: nan
agent1:                 episode reward: 0.6415,                 loss: 0.3242
Episode: 11861/30000 (39.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6540s / 294.4434 s
agent0:                 episode reward: -0.6358,                 loss: nan
agent1:                 episode reward: 0.6358,                 loss: 0.3243
Episode: 11881/30000 (39.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6422s / 295.0856 s
agent0:                 episode reward: -0.8656,                 loss: nan
agent1:                 episode reward: 0.8656,                 loss: 0.3267
Episode: 11901/30000 (39.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6553s / 295.7409 s
agent0:                 episode reward: -0.4768,                 loss: nan
agent1:                 episode reward: 0.4768,                 loss: 0.3259
Episode: 11921/30000 (39.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6517s / 296.3926 s
agent0:                 episode reward: -0.8547,                 loss: nan
agent1:                 episode reward: 0.8547,                 loss: 0.3261
Episode: 11941/30000 (39.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6507s / 297.0433 s
agent0:                 episode reward: -0.7944,                 loss: nan
agent1:                 episode reward: 0.7944,                 loss: 0.3268
Episode: 11961/30000 (39.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6466s / 297.6900 s
agent0:                 episode reward: -0.3800,                 loss: nan
agent1:                 episode reward: 0.3800,                 loss: 0.3242
Episode: 11981/30000 (39.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6458s / 298.3358 s
agent0:                 episode reward: -0.4868,                 loss: nan
agent1:                 episode reward: 0.4868,                 loss: 0.3230
Episode: 12001/30000 (40.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6465s / 298.9823 s
agent0:                 episode reward: -0.6667,                 loss: nan
agent1:                 episode reward: 0.6667,                 loss: 0.3269
Episode: 12021/30000 (40.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6608s / 299.6431 s
agent0:                 episode reward: -0.3678,                 loss: nan
agent1:                 episode reward: 0.3678,                 loss: 0.3397
Episode: 12041/30000 (40.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6933s / 300.3364 s
agent0:                 episode reward: -0.7813,                 loss: nan
agent1:                 episode reward: 0.7813,                 loss: 0.3398
Episode: 12061/30000 (40.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6441s / 300.9805 s
agent0:                 episode reward: -0.5501,                 loss: nan
agent1:                 episode reward: 0.5501,                 loss: 0.3398
Episode: 12081/30000 (40.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6376s / 301.6181 s
agent0:                 episode reward: -0.4278,                 loss: nan
agent1:                 episode reward: 0.4278,                 loss: 0.3382
Episode: 12101/30000 (40.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6594s / 302.2775 s
agent0:                 episode reward: -0.2975,                 loss: nan
agent1:                 episode reward: 0.2975,                 loss: 0.3379
Episode: 12121/30000 (40.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6472s / 302.9246 s
agent0:                 episode reward: -0.5115,                 loss: nan
agent1:                 episode reward: 0.5115,                 loss: 0.3401
Episode: 12141/30000 (40.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6431s / 303.5677 s
agent0:                 episode reward: -0.4852,                 loss: nan
agent1:                 episode reward: 0.4852,                 loss: 0.3341
Episode: 12161/30000 (40.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6438s / 304.2115 s
agent0:                 episode reward: -0.5327,                 loss: nan
agent1:                 episode reward: 0.5327,                 loss: 0.3367
Episode: 12181/30000 (40.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6451s / 304.8566 s
agent0:                 episode reward: -0.7735,                 loss: nan
agent1:                 episode reward: 0.7735,                 loss: 0.3376
Episode: 12201/30000 (40.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6456s / 305.5022 s
agent0:                 episode reward: -0.5313,                 loss: nan
agent1:                 episode reward: 0.5313,                 loss: 0.3377
Episode: 12221/30000 (40.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6402s / 306.1425 s
agent0:                 episode reward: -0.1980,                 loss: nan
agent1:                 episode reward: 0.1980,                 loss: 0.3390
Episode: 12241/30000 (40.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6528s / 306.7953 s
agent0:                 episode reward: -0.1135,                 loss: nan
agent1:                 episode reward: 0.1135,                 loss: 0.3381
Episode: 12261/30000 (40.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6519s / 307.4472 s
agent0:                 episode reward: -0.3573,                 loss: nan
agent1:                 episode reward: 0.3573,                 loss: 0.3388
Episode: 12281/30000 (40.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6538s / 308.1010 s
agent0:                 episode reward: -0.2380,                 loss: nan
agent1:                 episode reward: 0.2380,                 loss: 0.3361
Episode: 12301/30000 (41.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6530s / 308.7540 s
agent0:                 episode reward: -0.6717,                 loss: nan
agent1:                 episode reward: 0.6717,                 loss: 0.3376
Episode: 12321/30000 (41.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6684s / 309.4224 s
agent0:                 episode reward: -0.7466,                 loss: nan
agent1:                 episode reward: 0.7466,                 loss: 0.3406
Episode: 12341/30000 (41.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6575s / 310.0799 s
agent0:                 episode reward: -0.7949,                 loss: nan
agent1:                 episode reward: 0.7949,                 loss: 0.3485
Episode: 12361/30000 (41.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6544s / 310.7343 s
agent0:                 episode reward: -0.7027,                 loss: nan
agent1:                 episode reward: 0.7027,                 loss: 0.3551
Episode: 12381/30000 (41.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6499s / 311.3841 s
agent0:                 episode reward: -0.8221,                 loss: nan
agent1:                 episode reward: 0.8221,                 loss: 0.3562
Episode: 12401/30000 (41.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6534s / 312.0375 s
agent0:                 episode reward: -0.6993,                 loss: nan
agent1:                 episode reward: 0.6993,                 loss: 0.3520
Episode: 12421/30000 (41.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6656s / 312.7031 s
agent0:                 episode reward: -0.5747,                 loss: nan
agent1:                 episode reward: 0.5747,                 loss: 0.3490
Episode: 12441/30000 (41.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6597s / 313.3627 s
agent0:                 episode reward: -0.6599,                 loss: nan
agent1:                 episode reward: 0.6599,                 loss: 0.3527
Episode: 12461/30000 (41.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6547s / 314.0174 s
agent0:                 episode reward: -0.5935,                 loss: nan
agent1:                 episode reward: 0.5935,                 loss: 0.3519
Episode: 12481/30000 (41.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6621s / 314.6795 s
agent0:                 episode reward: -0.7423,                 loss: nan
agent1:                 episode reward: 0.7423,                 loss: 0.3511
Episode: 12501/30000 (41.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6606s / 315.3401 s
agent0:                 episode reward: -0.7251,                 loss: nan
agent1:                 episode reward: 0.7251,                 loss: 0.3522
Episode: 12521/30000 (41.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6583s / 315.9984 s
agent0:                 episode reward: -0.2204,                 loss: nan
agent1:                 episode reward: 0.2204,                 loss: 0.3573
Episode: 12541/30000 (41.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6611s / 316.6595 s
agent0:                 episode reward: -0.3079,                 loss: nan
agent1:                 episode reward: 0.3079,                 loss: 0.3527
Episode: 12561/30000 (41.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6514s / 317.3109 s
agent0:                 episode reward: -0.6918,                 loss: nan
agent1:                 episode reward: 0.6918,                 loss: 0.3512
Episode: 12581/30000 (41.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6541s / 317.9650 s
agent0:                 episode reward: -0.5150,                 loss: nan
agent1:                 episode reward: 0.5150,                 loss: 0.3515
Episode: 12601/30000 (42.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6467s / 318.6117 s
agent0:                 episode reward: -0.7809,                 loss: nan
agent1:                 episode reward: 0.7809,                 loss: 0.3570
Episode: 12621/30000 (42.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6669s / 319.2786 s
agent0:                 episode reward: -0.4732,                 loss: nan
agent1:                 episode reward: 0.4732,                 loss: 0.3511
Episode: 12641/30000 (42.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6564s / 319.9350 s
agent0:                 episode reward: -0.6776,                 loss: nan
agent1:                 episode reward: 0.6776,                 loss: 0.3552
Episode: 12661/30000 (42.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6512s / 320.5861 s
agent0:                 episode reward: -1.0105,                 loss: nan
agent1:                 episode reward: 1.0105,                 loss: 0.3534
Episode: 12681/30000 (42.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6654s / 321.2515 s
agent0:                 episode reward: -0.4483,                 loss: nan
agent1:                 episode reward: 0.4483,                 loss: 0.3350
Episode: 12701/30000 (42.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6530s / 321.9044 s
agent0:                 episode reward: -0.5524,                 loss: nan
agent1:                 episode reward: 0.5524,                 loss: 0.3249
Episode: 12721/30000 (42.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6571s / 322.5615 s
agent0:                 episode reward: -0.4211,                 loss: nan
agent1:                 episode reward: 0.4211,                 loss: 0.3266
Episode: 12741/30000 (42.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6602s / 323.2218 s
agent0:                 episode reward: -0.8648,                 loss: nan
agent1:                 episode reward: 0.8648,                 loss: 0.3229
Episode: 12761/30000 (42.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6556s / 323.8773 s
agent0:                 episode reward: -0.5049,                 loss: nan
agent1:                 episode reward: 0.5049,                 loss: 0.3226
Episode: 12781/30000 (42.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6466s / 324.5240 s
agent0:                 episode reward: -0.5049,                 loss: nan
agent1:                 episode reward: 0.5049,                 loss: 0.3212
Episode: 12801/30000 (42.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6494s / 325.1734 s
agent0:                 episode reward: -0.5716,                 loss: nan
agent1:                 episode reward: 0.5716,                 loss: 0.3259
Episode: 12821/30000 (42.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6611s / 325.8344 s
agent0:                 episode reward: -0.7062,                 loss: nan
agent1:                 episode reward: 0.7062,                 loss: 0.3259
Episode: 12841/30000 (42.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6535s / 326.4879 s
agent0:                 episode reward: -0.4411,                 loss: nan
agent1:                 episode reward: 0.4411,                 loss: 0.3201
Episode: 12861/30000 (42.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6537s / 327.1416 s
agent0:                 episode reward: -0.5862,                 loss: nan
agent1:                 episode reward: 0.5862,                 loss: 0.3269
Episode: 12881/30000 (42.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6518s / 327.7934 s
agent0:                 episode reward: -0.4295,                 loss: nan
agent1:                 episode reward: 0.4295,                 loss: 0.3215
Episode: 12901/30000 (43.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6488s / 328.4422 s
agent0:                 episode reward: -0.4885,                 loss: nan
agent1:                 episode reward: 0.4885,                 loss: 0.3244
Episode: 12921/30000 (43.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6481s / 329.0903 s
agent0:                 episode reward: -0.5653,                 loss: nan
agent1:                 episode reward: 0.5653,                 loss: 0.3223
Episode: 12941/30000 (43.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6488s / 329.7391 s
agent0:                 episode reward: -0.7072,                 loss: nan
agent1:                 episode reward: 0.7072,                 loss: 0.3248
Episode: 12961/30000 (43.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6592s / 330.3983 s
agent0:                 episode reward: -0.3520,                 loss: nan
agent1:                 episode reward: 0.3520,                 loss: 0.3262
Episode: 12981/30000 (43.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6572s / 331.0555 s
agent0:                 episode reward: -0.3771,                 loss: nan
agent1:                 episode reward: 0.3771,                 loss: 0.3222
Episode: 13001/30000 (43.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6611s / 331.7167 s
agent0:                 episode reward: -0.4396,                 loss: nan
agent1:                 episode reward: 0.4396,                 loss: 0.3212
Episode: 13021/30000 (43.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6581s / 332.3747 s
agent0:                 episode reward: -0.4268,                 loss: nan
agent1:                 episode reward: 0.4268,                 loss: 0.3401
Episode: 13041/30000 (43.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6556s / 333.0304 s
agent0:                 episode reward: -0.4603,                 loss: nan
agent1:                 episode reward: 0.4603,                 loss: 0.3390
Episode: 13061/30000 (43.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6632s / 333.6936 s
agent0:                 episode reward: -0.4864,                 loss: nan
agent1:                 episode reward: 0.4864,                 loss: 0.3396
Episode: 13081/30000 (43.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6677s / 334.3613 s
agent0:                 episode reward: -0.6293,                 loss: nan
agent1:                 episode reward: 0.6293,                 loss: 0.3396
Episode: 13101/30000 (43.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6499s / 335.0112 s
agent0:                 episode reward: -0.5238,                 loss: nan
agent1:                 episode reward: 0.5238,                 loss: 0.3380
Episode: 13121/30000 (43.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6589s / 335.6702 s
agent0:                 episode reward: -0.8381,                 loss: nan
agent1:                 episode reward: 0.8381,                 loss: 0.3386
Episode: 13141/30000 (43.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6532s / 336.3234 s
agent0:                 episode reward: -0.4451,                 loss: nan
agent1:                 episode reward: 0.4451,                 loss: 0.3421
Episode: 13161/30000 (43.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6524s / 336.9758 s
agent0:                 episode reward: -0.7527,                 loss: nan
agent1:                 episode reward: 0.7527,                 loss: 0.3427
Episode: 13181/30000 (43.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6568s / 337.6326 s
agent0:                 episode reward: -0.5738,                 loss: nan
agent1:                 episode reward: 0.5738,                 loss: 0.3391
Episode: 13201/30000 (44.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6556s / 338.2882 s
agent0:                 episode reward: -1.1403,                 loss: nan
agent1:                 episode reward: 1.1403,                 loss: 0.3366
Episode: 13221/30000 (44.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6557s / 338.9438 s
agent0:                 episode reward: -0.7344,                 loss: nan
agent1:                 episode reward: 0.7344,                 loss: 0.3403
Episode: 13241/30000 (44.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6518s / 339.5956 s
agent0:                 episode reward: -0.6566,                 loss: nan
agent1:                 episode reward: 0.6566,                 loss: 0.3344
Episode: 13261/30000 (44.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6510s / 340.2466 s
agent0:                 episode reward: -0.5916,                 loss: nan
agent1:                 episode reward: 0.5916,                 loss: 0.3403
Episode: 13281/30000 (44.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6594s / 340.9060 s
agent0:                 episode reward: -0.3719,                 loss: nan
agent1:                 episode reward: 0.3719,                 loss: 0.3373
Episode: 13301/30000 (44.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6571s / 341.5630 s
agent0:                 episode reward: -0.6070,                 loss: nan
agent1:                 episode reward: 0.6070,                 loss: 0.3444
Episode: 13321/30000 (44.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6688s / 342.2318 s
agent0:                 episode reward: -0.4641,                 loss: nan
agent1:                 episode reward: 0.4641,                 loss: 0.3406
Episode: 13341/30000 (44.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6643s / 342.8961 s
agent0:                 episode reward: -0.3839,                 loss: nan
agent1:                 episode reward: 0.3839,                 loss: 0.3520
Episode: 13361/30000 (44.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6618s / 343.5579 s
agent0:                 episode reward: -0.2142,                 loss: nan
agent1:                 episode reward: 0.2142,                 loss: 0.3620
Episode: 13381/30000 (44.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6691s / 344.2270 s
agent0:                 episode reward: -0.7676,                 loss: nan
agent1:                 episode reward: 0.7676,                 loss: 0.3607
Episode: 13401/30000 (44.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6650s / 344.8920 s
agent0:                 episode reward: -0.9546,                 loss: nan
agent1:                 episode reward: 0.9546,                 loss: 0.3591
Episode: 13421/30000 (44.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6628s / 345.5547 s
agent0:                 episode reward: -0.8266,                 loss: nan
agent1:                 episode reward: 0.8266,                 loss: 0.3602
Episode: 13441/30000 (44.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6671s / 346.2218 s
agent0:                 episode reward: -0.8644,                 loss: nan
agent1:                 episode reward: 0.8644,                 loss: 0.3591
Episode: 13461/30000 (44.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6750s / 346.8968 s
agent0:                 episode reward: -0.5693,                 loss: nan
agent1:                 episode reward: 0.5693,                 loss: 0.3568
Episode: 13481/30000 (44.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6649s / 347.5617 s
agent0:                 episode reward: -0.7150,                 loss: nan
agent1:                 episode reward: 0.7150,                 loss: 0.3566
Episode: 13501/30000 (45.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6623s / 348.2240 s
agent0:                 episode reward: -0.5810,                 loss: nan
agent1:                 episode reward: 0.5810,                 loss: 0.3574
Episode: 13521/30000 (45.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6663s / 348.8902 s
agent0:                 episode reward: -0.5712,                 loss: nan
agent1:                 episode reward: 0.5712,                 loss: 0.3605
Episode: 13541/30000 (45.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6674s / 349.5576 s
agent0:                 episode reward: -0.8006,                 loss: nan
agent1:                 episode reward: 0.8006,                 loss: 0.3607
Episode: 13561/30000 (45.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6694s / 350.2271 s
agent0:                 episode reward: -0.5621,                 loss: nan
agent1:                 episode reward: 0.5621,                 loss: 0.3587
Episode: 13581/30000 (45.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6735s / 350.9006 s
agent0:                 episode reward: -0.3799,                 loss: nan
agent1:                 episode reward: 0.3799,                 loss: 0.3596
Episode: 13601/30000 (45.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6734s / 351.5740 s
agent0:                 episode reward: -0.5684,                 loss: nan
agent1:                 episode reward: 0.5684,                 loss: 0.3577
Episode: 13621/30000 (45.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6622s / 352.2363 s
agent0:                 episode reward: -0.7607,                 loss: nan
agent1:                 episode reward: 0.7607,                 loss: 0.3581
Episode: 13641/30000 (45.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6674s / 352.9037 s
agent0:                 episode reward: -0.7056,                 loss: nan
agent1:                 episode reward: 0.7056,                 loss: 0.3618
Episode: 13661/30000 (45.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6670s / 353.5706 s
agent0:                 episode reward: -0.4850,                 loss: nan
agent1:                 episode reward: 0.4850,                 loss: 0.3563
Episode: 13681/30000 (45.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6760s / 354.2466 s
agent0:                 episode reward: -0.6530,                 loss: nan
agent1:                 episode reward: 0.6530,                 loss: 0.3414
Episode: 13701/30000 (45.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6723s / 354.9189 s
agent0:                 episode reward: -0.6185,                 loss: nan
agent1:                 episode reward: 0.6185,                 loss: 0.3319
Episode: 13721/30000 (45.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6683s / 355.5872 s
agent0:                 episode reward: -0.5168,                 loss: nan
agent1:                 episode reward: 0.5168,                 loss: 0.3289
Episode: 13741/30000 (45.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6840s / 356.2712 s
agent0:                 episode reward: -0.1681,                 loss: nan
agent1:                 episode reward: 0.1681,                 loss: 0.3313
Episode: 13761/30000 (45.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6672s / 356.9385 s
agent0:                 episode reward: -0.5275,                 loss: nan
agent1:                 episode reward: 0.5275,                 loss: 0.3314
Episode: 13781/30000 (45.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6853s / 357.6238 s
agent0:                 episode reward: -0.6872,                 loss: nan
agent1:                 episode reward: 0.6872,                 loss: 0.3310
Episode: 13801/30000 (46.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6832s / 358.3070 s
agent0:                 episode reward: -0.6346,                 loss: nan
agent1:                 episode reward: 0.6346,                 loss: 0.3309
Episode: 13821/30000 (46.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6748s / 358.9818 s
agent0:                 episode reward: -0.4906,                 loss: nan
agent1:                 episode reward: 0.4906,                 loss: 0.3283
Episode: 13841/30000 (46.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6798s / 359.6616 s
agent0:                 episode reward: -0.1847,                 loss: nan
agent1:                 episode reward: 0.1847,                 loss: 0.3285
Episode: 13861/30000 (46.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6842s / 360.3457 s
agent0:                 episode reward: -0.6337,                 loss: nan
agent1:                 episode reward: 0.6337,                 loss: 0.3267
Episode: 13881/30000 (46.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6736s / 361.0194 s
agent0:                 episode reward: -0.4244,                 loss: nan
agent1:                 episode reward: 0.4244,                 loss: 0.3292
Episode: 13901/30000 (46.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6860s / 361.7054 s
agent0:                 episode reward: -0.9082,                 loss: nan
agent1:                 episode reward: 0.9082,                 loss: 0.3304
Episode: 13921/30000 (46.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6793s / 362.3847 s
agent0:                 episode reward: -0.5968,                 loss: nan
agent1:                 episode reward: 0.5968,                 loss: 0.3297
Episode: 13941/30000 (46.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6670s / 363.0516 s
agent0:                 episode reward: -0.6269,                 loss: nan
agent1:                 episode reward: 0.6269,                 loss: 0.3278
Episode: 13961/30000 (46.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6548s / 363.7064 s
agent0:                 episode reward: -0.8776,                 loss: nan
agent1:                 episode reward: 0.8776,                 loss: 0.3302
Episode: 13981/30000 (46.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6634s / 364.3698 s
agent0:                 episode reward: -0.3714,                 loss: nan
agent1:                 episode reward: 0.3714,                 loss: 0.3314
Episode: 14001/30000 (46.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6612s / 365.0309 s
agent0:                 episode reward: -0.4967,                 loss: nan
agent1:                 episode reward: 0.4967,                 loss: 0.3283
Episode: 14021/30000 (46.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6717s / 365.7026 s
agent0:                 episode reward: -0.2852,                 loss: nan
agent1:                 episode reward: 0.2852,                 loss: 0.3539
Episode: 14041/30000 (46.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6609s / 366.3635 s
agent0:                 episode reward: -0.2064,                 loss: nan
agent1:                 episode reward: 0.2064,                 loss: 0.3553
Episode: 14061/30000 (46.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6706s / 367.0341 s
agent0:                 episode reward: -0.5579,                 loss: nan
agent1:                 episode reward: 0.5579,                 loss: 0.3505
Episode: 14081/30000 (46.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6664s / 367.7005 s
agent0:                 episode reward: -1.1574,                 loss: nan
agent1:                 episode reward: 1.1574,                 loss: 0.3511
Episode: 14101/30000 (47.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6665s / 368.3670 s
agent0:                 episode reward: -0.4742,                 loss: nan
agent1:                 episode reward: 0.4742,                 loss: 0.3515
Episode: 14121/30000 (47.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6785s / 369.0455 s
agent0:                 episode reward: -0.6764,                 loss: nan
agent1:                 episode reward: 0.6764,                 loss: 0.3478
Episode: 14141/30000 (47.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6616s / 369.7070 s
agent0:                 episode reward: -0.1826,                 loss: nan
agent1:                 episode reward: 0.1826,                 loss: 0.3483
Episode: 14161/30000 (47.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6683s / 370.3753 s
agent0:                 episode reward: -0.6689,                 loss: nan
agent1:                 episode reward: 0.6689,                 loss: 0.3474
Episode: 14181/30000 (47.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6653s / 371.0406 s
agent0:                 episode reward: -0.7033,                 loss: nan
agent1:                 episode reward: 0.7033,                 loss: 0.3527
Episode: 14201/30000 (47.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6707s / 371.7112 s
agent0:                 episode reward: -0.4955,                 loss: nan
agent1:                 episode reward: 0.4955,                 loss: 0.3488
Episode: 14221/30000 (47.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6785s / 372.3897 s
agent0:                 episode reward: -0.5731,                 loss: nan
agent1:                 episode reward: 0.5731,                 loss: 0.3499
Episode: 14241/30000 (47.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6725s / 373.0622 s
agent0:                 episode reward: -0.6007,                 loss: nan
agent1:                 episode reward: 0.6007,                 loss: 0.3492
Episode: 14261/30000 (47.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6733s / 373.7355 s
agent0:                 episode reward: -0.4513,                 loss: nan
agent1:                 episode reward: 0.4513,                 loss: 0.3526
Episode: 14281/30000 (47.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6701s / 374.4056 s
agent0:                 episode reward: -0.4899,                 loss: nan
agent1:                 episode reward: 0.4899,                 loss: 0.3475
Episode: 14301/30000 (47.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6802s / 375.0859 s
agent0:                 episode reward: -0.4695,                 loss: nan
agent1:                 episode reward: 0.4695,                 loss: 0.3486
Episode: 14321/30000 (47.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6738s / 375.7596 s
agent0:                 episode reward: -0.5722,                 loss: nan
agent1:                 episode reward: 0.5722,                 loss: 0.3506
Episode: 14341/30000 (47.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6690s / 376.4287 s
agent0:                 episode reward: -0.4517,                 loss: nan
agent1:                 episode reward: 0.4517,                 loss: 0.3534
Episode: 14361/30000 (47.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6850s / 377.1136 s
agent0:                 episode reward: -0.4199,                 loss: nan
agent1:                 episode reward: 0.4199,                 loss: 0.3542
Episode: 14381/30000 (47.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6812s / 377.7948 s
agent0:                 episode reward: -0.6501,                 loss: nan
agent1:                 episode reward: 0.6501,                 loss: 0.3513
Episode: 14401/30000 (48.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7180s / 378.5128 s
agent0:                 episode reward: -0.6073,                 loss: nan
agent1:                 episode reward: 0.6073,                 loss: 0.3536
Episode: 14421/30000 (48.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6944s / 379.2072 s
agent0:                 episode reward: -0.5916,                 loss: nan
agent1:                 episode reward: 0.5916,                 loss: 0.3567
Episode: 14441/30000 (48.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6867s / 379.8939 s
agent0:                 episode reward: -0.7947,                 loss: nan
agent1:                 episode reward: 0.7947,                 loss: 0.3550
Episode: 14461/30000 (48.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6709s / 380.5648 s
agent0:                 episode reward: -0.7791,                 loss: nan
agent1:                 episode reward: 0.7791,                 loss: 0.3520
Episode: 14481/30000 (48.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6780s / 381.2427 s
agent0:                 episode reward: -0.3789,                 loss: nan
agent1:                 episode reward: 0.3789,                 loss: 0.3519
Episode: 14501/30000 (48.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6811s / 381.9239 s
agent0:                 episode reward: -0.6602,                 loss: nan
agent1:                 episode reward: 0.6602,                 loss: 0.3472
Episode: 14521/30000 (48.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6802s / 382.6041 s
agent0:                 episode reward: -0.4311,                 loss: nan
agent1:                 episode reward: 0.4311,                 loss: 0.3551
Episode: 14541/30000 (48.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6929s / 383.2970 s
agent0:                 episode reward: -0.4311,                 loss: nan
agent1:                 episode reward: 0.4311,                 loss: 0.3499
Episode: 14561/30000 (48.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6881s / 383.9851 s
agent0:                 episode reward: -0.4795,                 loss: nan
agent1:                 episode reward: 0.4795,                 loss: 0.3555
Episode: 14581/30000 (48.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6768s / 384.6619 s
agent0:                 episode reward: -0.6673,                 loss: nan
agent1:                 episode reward: 0.6673,                 loss: 0.3518
Episode: 14601/30000 (48.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6795s / 385.3414 s
agent0:                 episode reward: -0.5637,                 loss: nan
agent1:                 episode reward: 0.5637,                 loss: 0.3557
Episode: 14621/30000 (48.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6745s / 386.0159 s
agent0:                 episode reward: -0.5772,                 loss: nan
agent1:                 episode reward: 0.5772,                 loss: 0.3550
Episode: 14641/30000 (48.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6854s / 386.7013 s
agent0:                 episode reward: -0.6082,                 loss: nan
agent1:                 episode reward: 0.6082,                 loss: 0.3591
Episode: 14661/30000 (48.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6707s / 387.3720 s
agent0:                 episode reward: -0.5951,                 loss: nan
agent1:                 episode reward: 0.5951,                 loss: 0.3554
Episode: 14681/30000 (48.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6761s / 388.0481 s
agent0:                 episode reward: -0.6110,                 loss: nan
agent1:                 episode reward: 0.6110,                 loss: 0.3431
Episode: 14701/30000 (49.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6775s / 388.7256 s
agent0:                 episode reward: -0.6287,                 loss: nan
agent1:                 episode reward: 0.6287,                 loss: 0.3288
Episode: 14721/30000 (49.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6757s / 389.4013 s
agent0:                 episode reward: -0.7367,                 loss: nan
agent1:                 episode reward: 0.7367,                 loss: 0.3272
Episode: 14741/30000 (49.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6764s / 390.0777 s
agent0:                 episode reward: -0.2678,                 loss: nan
agent1:                 episode reward: 0.2678,                 loss: 0.3255
Episode: 14761/30000 (49.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6859s / 390.7636 s
agent0:                 episode reward: -0.5519,                 loss: nan
agent1:                 episode reward: 0.5519,                 loss: 0.3283
Episode: 14781/30000 (49.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6782s / 391.4418 s
agent0:                 episode reward: -0.3100,                 loss: nan
agent1:                 episode reward: 0.3100,                 loss: 0.3283
Episode: 14801/30000 (49.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6837s / 392.1255 s
agent0:                 episode reward: -0.3947,                 loss: nan
agent1:                 episode reward: 0.3947,                 loss: 0.3260
Episode: 14821/30000 (49.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6824s / 392.8079 s
agent0:                 episode reward: -0.7239,                 loss: nan
agent1:                 episode reward: 0.7239,                 loss: 0.3281
Episode: 14841/30000 (49.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6824s / 393.4904 s
agent0:                 episode reward: -0.4639,                 loss: nan
agent1:                 episode reward: 0.4639,                 loss: 0.3256
Episode: 14861/30000 (49.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 1.0505s / 394.5408 s
agent0:                 episode reward: -0.7817,                 loss: nan
agent1:                 episode reward: 0.7817,                 loss: 0.3246
Episode: 14881/30000 (49.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9736s / 395.5144 s
agent0:                 episode reward: -0.7517,                 loss: nan
agent1:                 episode reward: 0.7517,                 loss: 0.3315
Episode: 14901/30000 (49.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9002s / 396.4146 s
agent0:                 episode reward: -0.4178,                 loss: nan
agent1:                 episode reward: 0.4178,                 loss: 0.3295
Episode: 14921/30000 (49.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8239s / 397.2385 s
agent0:                 episode reward: -0.5276,                 loss: nan
agent1:                 episode reward: 0.5276,                 loss: 0.3262
Episode: 14941/30000 (49.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7286s / 397.9671 s
agent0:                 episode reward: -0.4294,                 loss: nan
agent1:                 episode reward: 0.4294,                 loss: 0.3271
Episode: 14961/30000 (49.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6982s / 398.6653 s
agent0:                 episode reward: -0.2986,                 loss: nan
agent1:                 episode reward: 0.2986,                 loss: 0.3291
Episode: 14981/30000 (49.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6785s / 399.3438 s
agent0:                 episode reward: -0.3350,                 loss: nan
agent1:                 episode reward: 0.3350,                 loss: 0.3261
Episode: 15001/30000 (50.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6751s / 400.0189 s
agent0:                 episode reward: -0.4458,                 loss: nan
agent1:                 episode reward: 0.4458,                 loss: 0.3296
Episode: 15021/30000 (50.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6658s / 400.6846 s
agent0:                 episode reward: -0.6690,                 loss: nan
agent1:                 episode reward: 0.6690,                 loss: 0.3615
Episode: 15041/30000 (50.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6699s / 401.3546 s
agent0:                 episode reward: -0.4212,                 loss: nan
agent1:                 episode reward: 0.4212,                 loss: 0.3621
Episode: 15061/30000 (50.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6763s / 402.0309 s
agent0:                 episode reward: -0.6309,                 loss: nan
agent1:                 episode reward: 0.6309,                 loss: 0.3637
Episode: 15081/30000 (50.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6772s / 402.7081 s
agent0:                 episode reward: -0.6756,                 loss: nan
agent1:                 episode reward: 0.6756,                 loss: 0.3610
Episode: 15101/30000 (50.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6688s / 403.3769 s
agent0:                 episode reward: -0.7437,                 loss: nan
agent1:                 episode reward: 0.7437,                 loss: 0.3615
Episode: 15121/30000 (50.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6794s / 404.0563 s
agent0:                 episode reward: -0.6613,                 loss: nan
agent1:                 episode reward: 0.6613,                 loss: 0.3622
Episode: 15141/30000 (50.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6749s / 404.7312 s
agent0:                 episode reward: -0.6288,                 loss: nan
agent1:                 episode reward: 0.6288,                 loss: 0.3627
Episode: 15161/30000 (50.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6864s / 405.4177 s
agent0:                 episode reward: -0.4748,                 loss: nan
agent1:                 episode reward: 0.4748,                 loss: 0.3649
Episode: 15181/30000 (50.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6795s / 406.0972 s
agent0:                 episode reward: -0.5657,                 loss: nan
agent1:                 episode reward: 0.5657,                 loss: 0.3662
Episode: 15201/30000 (50.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6682s / 406.7654 s
agent0:                 episode reward: -0.8253,                 loss: nan
agent1:                 episode reward: 0.8253,                 loss: 0.3631
Episode: 15221/30000 (50.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6775s / 407.4429 s
agent0:                 episode reward: -0.6138,                 loss: nan
agent1:                 episode reward: 0.6138,                 loss: 0.3622
Episode: 15241/30000 (50.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6715s / 408.1143 s
agent0:                 episode reward: -0.5753,                 loss: nan
agent1:                 episode reward: 0.5753,                 loss: 0.3632
Episode: 15261/30000 (50.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6739s / 408.7882 s
agent0:                 episode reward: -0.7029,                 loss: nan
agent1:                 episode reward: 0.7029,                 loss: 0.3621
Episode: 15281/30000 (50.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6824s / 409.4706 s
agent0:                 episode reward: -0.5204,                 loss: nan
agent1:                 episode reward: 0.5204,                 loss: 0.3637
Episode: 15301/30000 (51.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6698s / 410.1404 s
agent0:                 episode reward: -0.6999,                 loss: nan
agent1:                 episode reward: 0.6999,                 loss: 0.3618
Episode: 15321/30000 (51.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6810s / 410.8214 s
agent0:                 episode reward: -0.6429,                 loss: nan
agent1:                 episode reward: 0.6429,                 loss: 0.3597
Episode: 15341/30000 (51.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6854s / 411.5068 s
agent0:                 episode reward: -0.5674,                 loss: nan
agent1:                 episode reward: 0.5674,                 loss: 0.3606
Episode: 15361/30000 (51.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6746s / 412.1814 s
agent0:                 episode reward: -0.7014,                 loss: nan
agent1:                 episode reward: 0.7014,                 loss: 0.3490
Episode: 15381/30000 (51.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6820s / 412.8634 s
agent0:                 episode reward: -0.6693,                 loss: nan
agent1:                 episode reward: 0.6693,                 loss: 0.3455
Episode: 15401/30000 (51.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6791s / 413.5425 s
agent0:                 episode reward: -0.1601,                 loss: nan
agent1:                 episode reward: 0.1601,                 loss: 0.3460
Episode: 15421/30000 (51.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6790s / 414.2215 s
agent0:                 episode reward: -0.6098,                 loss: nan
agent1:                 episode reward: 0.6098,                 loss: 0.3468
Episode: 15441/30000 (51.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6871s / 414.9085 s
agent0:                 episode reward: -0.5441,                 loss: nan
agent1:                 episode reward: 0.5441,                 loss: 0.3471
Episode: 15461/30000 (51.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6825s / 415.5910 s
agent0:                 episode reward: -0.6061,                 loss: nan
agent1:                 episode reward: 0.6061,                 loss: 0.3440
Episode: 15481/30000 (51.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6826s / 416.2736 s
agent0:                 episode reward: -0.9724,                 loss: nan
agent1:                 episode reward: 0.9724,                 loss: 0.3482
Episode: 15501/30000 (51.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6903s / 416.9639 s
agent0:                 episode reward: -0.5165,                 loss: nan
agent1:                 episode reward: 0.5165,                 loss: 0.3462
Episode: 15521/30000 (51.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7431s / 417.7071 s
agent0:                 episode reward: -0.7964,                 loss: nan
agent1:                 episode reward: 0.7964,                 loss: 0.3452
Episode: 15541/30000 (51.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 1.0237s / 418.7307 s
agent0:                 episode reward: -0.5060,                 loss: nan
agent1:                 episode reward: 0.5060,                 loss: 0.3457
Episode: 15561/30000 (51.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9611s / 419.6918 s
agent0:                 episode reward: -0.5172,                 loss: nan
agent1:                 episode reward: 0.5172,                 loss: 0.3439
Episode: 15581/30000 (51.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8725s / 420.5644 s
agent0:                 episode reward: -0.3163,                 loss: nan
agent1:                 episode reward: 0.3163,                 loss: 0.3425
Episode: 15601/30000 (52.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7656s / 421.3300 s
agent0:                 episode reward: -0.5628,                 loss: nan
agent1:                 episode reward: 0.5628,                 loss: 0.3458
Episode: 15621/30000 (52.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6807s / 422.0106 s
agent0:                 episode reward: -0.3134,                 loss: nan
agent1:                 episode reward: 0.3134,                 loss: 0.3463
Episode: 15641/30000 (52.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6964s / 422.7070 s
agent0:                 episode reward: -0.6355,                 loss: nan
agent1:                 episode reward: 0.6355,                 loss: 0.3450
Episode: 15661/30000 (52.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6878s / 423.3948 s
agent0:                 episode reward: -0.3701,                 loss: nan
agent1:                 episode reward: 0.3701,                 loss: 0.3460
Episode: 15681/30000 (52.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6833s / 424.0780 s
agent0:                 episode reward: -0.6907,                 loss: nan
agent1:                 episode reward: 0.6907,                 loss: 0.3410
Episode: 15701/30000 (52.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6798s / 424.7578 s
agent0:                 episode reward: -0.5573,                 loss: nan
agent1:                 episode reward: 0.5573,                 loss: 0.3329
Episode: 15721/30000 (52.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6855s / 425.4434 s
agent0:                 episode reward: -0.7982,                 loss: nan
agent1:                 episode reward: 0.7982,                 loss: 0.3348
Episode: 15741/30000 (52.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6929s / 426.1363 s
agent0:                 episode reward: -0.6581,                 loss: nan
agent1:                 episode reward: 0.6581,                 loss: 0.3368
Episode: 15761/30000 (52.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6866s / 426.8228 s
agent0:                 episode reward: -0.5892,                 loss: nan
agent1:                 episode reward: 0.5892,                 loss: 0.3355
Episode: 15781/30000 (52.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6859s / 427.5088 s
agent0:                 episode reward: -0.3301,                 loss: nan
agent1:                 episode reward: 0.3301,                 loss: 0.3337
Episode: 15801/30000 (52.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6746s / 428.1834 s
agent0:                 episode reward: -0.4606,                 loss: nan
agent1:                 episode reward: 0.4606,                 loss: 0.3355
Episode: 15821/30000 (52.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6826s / 428.8660 s
agent0:                 episode reward: -0.5078,                 loss: nan
agent1:                 episode reward: 0.5078,                 loss: 0.3386
Episode: 15841/30000 (52.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6757s / 429.5416 s
agent0:                 episode reward: -0.3785,                 loss: nan
agent1:                 episode reward: 0.3785,                 loss: 0.3355
Episode: 15861/30000 (52.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6875s / 430.2291 s
agent0:                 episode reward: -0.5197,                 loss: nan
agent1:                 episode reward: 0.5197,                 loss: 0.3335
Episode: 15881/30000 (52.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6878s / 430.9170 s
agent0:                 episode reward: -0.4681,                 loss: nan
agent1:                 episode reward: 0.4681,                 loss: 0.3379
Episode: 15901/30000 (53.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6818s / 431.5988 s
agent0:                 episode reward: -0.6787,                 loss: nan
agent1:                 episode reward: 0.6787,                 loss: 0.3359
Episode: 15921/30000 (53.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6877s / 432.2865 s
agent0:                 episode reward: -0.6719,                 loss: nan
agent1:                 episode reward: 0.6719,                 loss: 0.3357
Episode: 15941/30000 (53.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8151s / 433.1016 s
agent0:                 episode reward: -1.0763,                 loss: nan
agent1:                 episode reward: 1.0763,                 loss: 0.3378
Episode: 15961/30000 (53.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8639s / 433.9654 s
agent0:                 episode reward: -0.6335,                 loss: nan
agent1:                 episode reward: 0.6335,                 loss: 0.3349
Episode: 15981/30000 (53.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7503s / 434.7157 s
agent0:                 episode reward: -0.9455,                 loss: nan
agent1:                 episode reward: 0.9455,                 loss: 0.3340
Episode: 16001/30000 (53.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7014s / 435.4171 s
agent0:                 episode reward: -0.3352,                 loss: nan
agent1:                 episode reward: 0.3352,                 loss: 0.3339
Episode: 16021/30000 (53.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6953s / 436.1124 s
agent0:                 episode reward: -0.8698,                 loss: nan
agent1:                 episode reward: 0.8698,                 loss: 0.3621
Episode: 16041/30000 (53.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6961s / 436.8085 s
agent0:                 episode reward: -0.7047,                 loss: nan
agent1:                 episode reward: 0.7047,                 loss: 0.3557
Episode: 16061/30000 (53.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6841s / 437.4926 s
agent0:                 episode reward: -0.7813,                 loss: nan
agent1:                 episode reward: 0.7813,                 loss: 0.3590
Episode: 16081/30000 (53.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6807s / 438.1734 s
agent0:                 episode reward: -0.5010,                 loss: nan
agent1:                 episode reward: 0.5010,                 loss: 0.3575
Episode: 16101/30000 (53.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6885s / 438.8618 s
agent0:                 episode reward: -0.8013,                 loss: nan
agent1:                 episode reward: 0.8013,                 loss: 0.3551
Episode: 16121/30000 (53.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6886s / 439.5504 s
agent0:                 episode reward: -0.7527,                 loss: nan
agent1:                 episode reward: 0.7527,                 loss: 0.3599
Episode: 16141/30000 (53.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7589s / 440.3093 s
agent0:                 episode reward: -0.6741,                 loss: nan
agent1:                 episode reward: 0.6741,                 loss: 0.3565
Episode: 16161/30000 (53.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9966s / 441.3059 s
agent0:                 episode reward: -0.5097,                 loss: nan
agent1:                 episode reward: 0.5097,                 loss: 0.3585
Episode: 16181/30000 (53.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9064s / 442.2123 s
agent0:                 episode reward: -0.3950,                 loss: nan
agent1:                 episode reward: 0.3950,                 loss: 0.3564
Episode: 16201/30000 (54.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8071s / 443.0193 s
agent0:                 episode reward: -0.5343,                 loss: nan
agent1:                 episode reward: 0.5343,                 loss: 0.3569
Episode: 16221/30000 (54.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7188s / 443.7382 s
agent0:                 episode reward: -0.3505,                 loss: nan
agent1:                 episode reward: 0.3505,                 loss: 0.3559
Episode: 16241/30000 (54.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7021s / 444.4402 s
agent0:                 episode reward: -0.5513,                 loss: nan
agent1:                 episode reward: 0.5513,                 loss: 0.3570
Episode: 16261/30000 (54.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6962s / 445.1364 s
agent0:                 episode reward: -0.6123,                 loss: nan
agent1:                 episode reward: 0.6123,                 loss: 0.3562
Episode: 16281/30000 (54.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6924s / 445.8288 s
agent0:                 episode reward: -0.3863,                 loss: nan
agent1:                 episode reward: 0.3863,                 loss: 0.3580
Episode: 16301/30000 (54.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6829s / 446.5117 s
agent0:                 episode reward: -0.2172,                 loss: nan
agent1:                 episode reward: 0.2172,                 loss: 0.3581
Episode: 16321/30000 (54.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6954s / 447.2071 s
agent0:                 episode reward: -0.3918,                 loss: nan
agent1:                 episode reward: 0.3918,                 loss: 0.3573
Episode: 16341/30000 (54.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6969s / 447.9040 s
agent0:                 episode reward: -0.5156,                 loss: nan
agent1:                 episode reward: 0.5156,                 loss: 0.3577
Episode: 16361/30000 (54.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6861s / 448.5901 s
agent0:                 episode reward: -0.3667,                 loss: nan
agent1:                 episode reward: 0.3667,                 loss: 0.3469
Episode: 16381/30000 (54.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6935s / 449.2835 s
agent0:                 episode reward: -0.3948,                 loss: nan
agent1:                 episode reward: 0.3948,                 loss: 0.3472
Episode: 16401/30000 (54.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6899s / 449.9734 s
agent0:                 episode reward: -0.6312,                 loss: nan
agent1:                 episode reward: 0.6312,                 loss: 0.3457
Episode: 16421/30000 (54.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6946s / 450.6681 s
agent0:                 episode reward: -0.7073,                 loss: nan
agent1:                 episode reward: 0.7073,                 loss: 0.3458
Episode: 16441/30000 (54.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6921s / 451.3602 s
agent0:                 episode reward: -1.0819,                 loss: nan
agent1:                 episode reward: 1.0819,                 loss: 0.3465
Episode: 16461/30000 (54.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6914s / 452.0516 s
agent0:                 episode reward: -0.4743,                 loss: nan
agent1:                 episode reward: 0.4743,                 loss: 0.3460
Episode: 16481/30000 (54.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6913s / 452.7429 s
agent0:                 episode reward: -0.7125,                 loss: nan
agent1:                 episode reward: 0.7125,                 loss: 0.3436
Episode: 16501/30000 (55.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6824s / 453.4253 s
agent0:                 episode reward: -0.8564,                 loss: nan
agent1:                 episode reward: 0.8564,                 loss: 0.3476
Episode: 16521/30000 (55.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6888s / 454.1141 s
agent0:                 episode reward: -0.6888,                 loss: nan
agent1:                 episode reward: 0.6888,                 loss: 0.3468
Episode: 16541/30000 (55.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6919s / 454.8060 s
agent0:                 episode reward: -0.4570,                 loss: nan
agent1:                 episode reward: 0.4570,                 loss: 0.3477
Episode: 16561/30000 (55.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6888s / 455.4948 s
agent0:                 episode reward: -0.3718,                 loss: nan
agent1:                 episode reward: 0.3718,                 loss: 0.3483
Episode: 16581/30000 (55.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6921s / 456.1869 s
agent0:                 episode reward: -0.4611,                 loss: nan
agent1:                 episode reward: 0.4611,                 loss: 0.3474
Episode: 16601/30000 (55.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7002s / 456.8871 s
agent0:                 episode reward: -0.5525,                 loss: nan
agent1:                 episode reward: 0.5525,                 loss: 0.3444
Episode: 16621/30000 (55.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7005s / 457.5876 s
agent0:                 episode reward: -0.5931,                 loss: nan
agent1:                 episode reward: 0.5931,                 loss: 0.3484
Episode: 16641/30000 (55.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6974s / 458.2850 s
agent0:                 episode reward: -0.6182,                 loss: nan
agent1:                 episode reward: 0.6182,                 loss: 0.3452
Episode: 16661/30000 (55.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6974s / 458.9824 s
agent0:                 episode reward: -0.3513,                 loss: nan
agent1:                 episode reward: 0.3513,                 loss: 0.3465
Episode: 16681/30000 (55.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6949s / 459.6774 s
agent0:                 episode reward: -0.5621,                 loss: nan
agent1:                 episode reward: 0.5621,                 loss: 0.3405
Episode: 16701/30000 (55.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7049s / 460.3823 s
agent0:                 episode reward: -0.6009,                 loss: nan
agent1:                 episode reward: 0.6009,                 loss: 0.3279
Episode: 16721/30000 (55.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7013s / 461.0836 s
agent0:                 episode reward: -0.6444,                 loss: nan
agent1:                 episode reward: 0.6444,                 loss: 0.3288
Episode: 16741/30000 (55.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6920s / 461.7756 s
agent0:                 episode reward: -0.7715,                 loss: nan
agent1:                 episode reward: 0.7715,                 loss: 0.3303
Episode: 16761/30000 (55.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7063s / 462.4819 s
agent0:                 episode reward: -0.6005,                 loss: nan
agent1:                 episode reward: 0.6005,                 loss: 0.3298
Episode: 16781/30000 (55.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7107s / 463.1926 s
agent0:                 episode reward: -0.3995,                 loss: nan
agent1:                 episode reward: 0.3995,                 loss: 0.3303
Episode: 16801/30000 (56.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7085s / 463.9011 s
agent0:                 episode reward: -0.5653,                 loss: nan
agent1:                 episode reward: 0.5653,                 loss: 0.3286
Episode: 16821/30000 (56.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7076s / 464.6087 s
agent0:                 episode reward: -0.6237,                 loss: nan
agent1:                 episode reward: 0.6237,                 loss: 0.3301
Episode: 16841/30000 (56.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7063s / 465.3150 s
agent0:                 episode reward: -0.6911,                 loss: nan
agent1:                 episode reward: 0.6911,                 loss: 0.3278
Episode: 16861/30000 (56.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6989s / 466.0139 s
agent0:                 episode reward: -0.7333,                 loss: nan
agent1:                 episode reward: 0.7333,                 loss: 0.3295
Episode: 16881/30000 (56.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7045s / 466.7184 s
agent0:                 episode reward: -0.3805,                 loss: nan
agent1:                 episode reward: 0.3805,                 loss: 0.3300
Episode: 16901/30000 (56.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7098s / 467.4282 s
agent0:                 episode reward: -0.5732,                 loss: nan
agent1:                 episode reward: 0.5732,                 loss: 0.3315
Episode: 16921/30000 (56.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7004s / 468.1286 s
agent0:                 episode reward: -0.3448,                 loss: nan
agent1:                 episode reward: 0.3448,                 loss: 0.3282
Episode: 16941/30000 (56.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7074s / 468.8360 s
agent0:                 episode reward: -1.0023,                 loss: nan
agent1:                 episode reward: 1.0023,                 loss: 0.3281
Episode: 16961/30000 (56.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6971s / 469.5331 s
agent0:                 episode reward: -0.5061,                 loss: nan
agent1:                 episode reward: 0.5061,                 loss: 0.3251
Episode: 16981/30000 (56.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7007s / 470.2337 s
agent0:                 episode reward: -0.5259,                 loss: nan
agent1:                 episode reward: 0.5259,                 loss: 0.3295
Episode: 17001/30000 (56.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7055s / 470.9393 s
agent0:                 episode reward: -0.1870,                 loss: nan
agent1:                 episode reward: 0.1870,                 loss: 0.3333
Episode: 17021/30000 (56.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6970s / 471.6362 s
agent0:                 episode reward: -0.4541,                 loss: nan
agent1:                 episode reward: 0.4541,                 loss: 0.3769
Episode: 17041/30000 (56.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7006s / 472.3369 s
agent0:                 episode reward: -0.7261,                 loss: nan
agent1:                 episode reward: 0.7261,                 loss: 0.3634
Episode: 17061/30000 (56.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7075s / 473.0444 s
agent0:                 episode reward: -0.4981,                 loss: nan
agent1:                 episode reward: 0.4981,                 loss: 0.3683
Episode: 17081/30000 (56.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7104s / 473.7548 s
agent0:                 episode reward: -0.4677,                 loss: nan
agent1:                 episode reward: 0.4677,                 loss: 0.3645
Episode: 17101/30000 (57.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7065s / 474.4613 s
agent0:                 episode reward: -0.7823,                 loss: nan
agent1:                 episode reward: 0.7823,                 loss: 0.3647
Episode: 17121/30000 (57.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6944s / 475.1557 s
agent0:                 episode reward: -0.5505,                 loss: nan
agent1:                 episode reward: 0.5505,                 loss: 0.3658
Episode: 17141/30000 (57.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7019s / 475.8576 s
agent0:                 episode reward: -0.5463,                 loss: nan
agent1:                 episode reward: 0.5463,                 loss: 0.3660
Episode: 17161/30000 (57.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7007s / 476.5583 s
agent0:                 episode reward: -0.6165,                 loss: nan
agent1:                 episode reward: 0.6165,                 loss: 0.3648
Episode: 17181/30000 (57.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6970s / 477.2553 s
agent0:                 episode reward: -0.6987,                 loss: nan
agent1:                 episode reward: 0.6987,                 loss: 0.3628
Episode: 17201/30000 (57.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7023s / 477.9576 s
agent0:                 episode reward: -0.6204,                 loss: nan
agent1:                 episode reward: 0.6204,                 loss: 0.3651
Episode: 17221/30000 (57.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7036s / 478.6612 s
agent0:                 episode reward: -0.9157,                 loss: nan
agent1:                 episode reward: 0.9157,                 loss: 0.3629
Episode: 17241/30000 (57.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7027s / 479.3640 s
agent0:                 episode reward: -0.7256,                 loss: nan
agent1:                 episode reward: 0.7256,                 loss: 0.3672
Episode: 17261/30000 (57.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7057s / 480.0696 s
agent0:                 episode reward: -0.6177,                 loss: nan
agent1:                 episode reward: 0.6177,                 loss: 0.3640
Episode: 17281/30000 (57.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6956s / 480.7652 s
agent0:                 episode reward: -0.4801,                 loss: nan
agent1:                 episode reward: 0.4801,                 loss: 0.3649
Episode: 17301/30000 (57.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6999s / 481.4652 s
agent0:                 episode reward: -0.8055,                 loss: nan
agent1:                 episode reward: 0.8055,                 loss: 0.3658
Episode: 17321/30000 (57.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7050s / 482.1702 s
agent0:                 episode reward: -0.2392,                 loss: nan
agent1:                 episode reward: 0.2392,                 loss: 0.3663
Episode: 17341/30000 (57.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7103s / 482.8805 s
agent0:                 episode reward: -0.4419,                 loss: nan
agent1:                 episode reward: 0.4419,                 loss: 0.3553
Episode: 17361/30000 (57.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7094s / 483.5899 s
agent0:                 episode reward: -0.7628,                 loss: nan
agent1:                 episode reward: 0.7628,                 loss: 0.3363
Episode: 17381/30000 (57.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7091s / 484.2990 s
agent0:                 episode reward: -0.4703,                 loss: nan
agent1:                 episode reward: 0.4703,                 loss: 0.3330
Episode: 17401/30000 (58.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7057s / 485.0047 s
agent0:                 episode reward: -0.5134,                 loss: nan
agent1:                 episode reward: 0.5134,                 loss: 0.3370
Episode: 17421/30000 (58.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7116s / 485.7163 s
agent0:                 episode reward: -0.5461,                 loss: nan
agent1:                 episode reward: 0.5461,                 loss: 0.3327
Episode: 17441/30000 (58.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7099s / 486.4262 s
agent0:                 episode reward: -0.6578,                 loss: nan
agent1:                 episode reward: 0.6578,                 loss: 0.3343
Episode: 17461/30000 (58.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7008s / 487.1270 s
agent0:                 episode reward: -0.3328,                 loss: nan
agent1:                 episode reward: 0.3328,                 loss: 0.3321
Episode: 17481/30000 (58.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7199s / 487.8468 s
agent0:                 episode reward: -0.7147,                 loss: nan
agent1:                 episode reward: 0.7147,                 loss: 0.3367
Episode: 17501/30000 (58.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7077s / 488.5545 s
agent0:                 episode reward: -0.7455,                 loss: nan
agent1:                 episode reward: 0.7455,                 loss: 0.3297
Episode: 17521/30000 (58.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7046s / 489.2591 s
agent0:                 episode reward: -0.5016,                 loss: nan
agent1:                 episode reward: 0.5016,                 loss: 0.3307
Episode: 17541/30000 (58.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7106s / 489.9697 s
agent0:                 episode reward: -0.6843,                 loss: nan
agent1:                 episode reward: 0.6843,                 loss: 0.3342
Episode: 17561/30000 (58.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7065s / 490.6762 s
agent0:                 episode reward: -0.7588,                 loss: nan
agent1:                 episode reward: 0.7588,                 loss: 0.3344
Episode: 17581/30000 (58.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7128s / 491.3890 s
agent0:                 episode reward: -0.3854,                 loss: nan
agent1:                 episode reward: 0.3854,                 loss: 0.3336
Episode: 17601/30000 (58.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7034s / 492.0924 s
agent0:                 episode reward: -0.3781,                 loss: nan
agent1:                 episode reward: 0.3781,                 loss: 0.3399
Episode: 17621/30000 (58.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7091s / 492.8015 s
agent0:                 episode reward: -0.8017,                 loss: nan
agent1:                 episode reward: 0.8017,                 loss: 0.3350
Episode: 17641/30000 (58.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7127s / 493.5142 s
agent0:                 episode reward: -0.4860,                 loss: nan
agent1:                 episode reward: 0.4860,                 loss: 0.3335
Episode: 17661/30000 (58.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7208s / 494.2350 s
agent0:                 episode reward: -0.5798,                 loss: nan
agent1:                 episode reward: 0.5798,                 loss: 0.3302
Episode: 17681/30000 (58.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7177s / 494.9527 s
agent0:                 episode reward: -0.7343,                 loss: nan
agent1:                 episode reward: 0.7343,                 loss: 0.3367
Episode: 17701/30000 (59.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7079s / 495.6606 s
agent0:                 episode reward: -0.4656,                 loss: nan
agent1:                 episode reward: 0.4656,                 loss: 0.3307
Episode: 17721/30000 (59.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7069s / 496.3674 s
agent0:                 episode reward: -0.2148,                 loss: nan
agent1:                 episode reward: 0.2148,                 loss: 0.3273
Episode: 17741/30000 (59.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7098s / 497.0772 s
agent0:                 episode reward: -0.0648,                 loss: nan
agent1:                 episode reward: 0.0648,                 loss: 0.3263
Episode: 17761/30000 (59.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7283s / 497.8056 s
agent0:                 episode reward: -0.5087,                 loss: nan
agent1:                 episode reward: 0.5087,                 loss: 0.3257
Episode: 17781/30000 (59.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7222s / 498.5278 s
agent0:                 episode reward: -0.4676,                 loss: nan
agent1:                 episode reward: 0.4676,                 loss: 0.3314
Episode: 17801/30000 (59.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7081s / 499.2359 s
agent0:                 episode reward: -0.7683,                 loss: nan
agent1:                 episode reward: 0.7683,                 loss: 0.3243
Episode: 17821/30000 (59.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7086s / 499.9445 s
agent0:                 episode reward: -0.5545,                 loss: nan
agent1:                 episode reward: 0.5545,                 loss: 0.3258
Episode: 17841/30000 (59.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7116s / 500.6561 s
agent0:                 episode reward: -0.4933,                 loss: nan
agent1:                 episode reward: 0.4933,                 loss: 0.3303
Episode: 17861/30000 (59.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7056s / 501.3618 s
agent0:                 episode reward: -0.8824,                 loss: nan
agent1:                 episode reward: 0.8824,                 loss: 0.3274
Episode: 17881/30000 (59.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7170s / 502.0787 s
agent0:                 episode reward: -0.6141,                 loss: nan
agent1:                 episode reward: 0.6141,                 loss: 0.3218
Episode: 17901/30000 (59.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7165s / 502.7952 s
agent0:                 episode reward: -0.3165,                 loss: nan
agent1:                 episode reward: 0.3165,                 loss: 0.3245
Episode: 17921/30000 (59.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7136s / 503.5088 s
agent0:                 episode reward: -0.7588,                 loss: nan
agent1:                 episode reward: 0.7588,                 loss: 0.3285
Episode: 17941/30000 (59.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7214s / 504.2303 s
agent0:                 episode reward: -0.4380,                 loss: nan
agent1:                 episode reward: 0.4380,                 loss: 0.3277
Episode: 17961/30000 (59.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7298s / 504.9601 s
agent0:                 episode reward: -0.4533,                 loss: nan
agent1:                 episode reward: 0.4533,                 loss: 0.3289
Episode: 17981/30000 (59.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7131s / 505.6732 s
agent0:                 episode reward: -0.6614,                 loss: nan
agent1:                 episode reward: 0.6614,                 loss: 0.3224
Episode: 18001/30000 (60.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7245s / 506.3977 s
agent0:                 episode reward: -0.4209,                 loss: nan
agent1:                 episode reward: 0.4209,                 loss: 0.3321
Episode: 18021/30000 (60.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7309s / 507.1286 s
agent0:                 episode reward: -0.5642,                 loss: nan
agent1:                 episode reward: 0.5642,                 loss: 0.3788
Episode: 18041/30000 (60.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7206s / 507.8491 s
agent0:                 episode reward: -0.9850,                 loss: nan
agent1:                 episode reward: 0.9850,                 loss: 0.3687
Episode: 18061/30000 (60.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7111s / 508.5602 s
agent0:                 episode reward: -0.4935,                 loss: nan
agent1:                 episode reward: 0.4935,                 loss: 0.3676
Episode: 18081/30000 (60.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7604s / 509.3206 s
agent0:                 episode reward: -0.5259,                 loss: nan
agent1:                 episode reward: 0.5259,                 loss: 0.3685
Episode: 18101/30000 (60.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7214s / 510.0420 s
agent0:                 episode reward: -0.9136,                 loss: nan
agent1:                 episode reward: 0.9136,                 loss: 0.3667
Episode: 18121/30000 (60.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7396s / 510.7817 s
agent0:                 episode reward: -0.4081,                 loss: nan
agent1:                 episode reward: 0.4081,                 loss: 0.3677
Episode: 18141/30000 (60.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7102s / 511.4919 s
agent0:                 episode reward: -0.2486,                 loss: nan
agent1:                 episode reward: 0.2486,                 loss: 0.3687
Episode: 18161/30000 (60.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7232s / 512.2151 s
agent0:                 episode reward: -0.6025,                 loss: nan
agent1:                 episode reward: 0.6025,                 loss: 0.3683
Episode: 18181/30000 (60.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7268s / 512.9419 s
agent0:                 episode reward: -0.4481,                 loss: nan
agent1:                 episode reward: 0.4481,                 loss: 0.3665
Episode: 18201/30000 (60.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7205s / 513.6625 s
agent0:                 episode reward: -0.1925,                 loss: nan
agent1:                 episode reward: 0.1925,                 loss: 0.3661
Episode: 18221/30000 (60.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7111s / 514.3735 s
agent0:                 episode reward: -0.6674,                 loss: nan
agent1:                 episode reward: 0.6674,                 loss: 0.3683
Episode: 18241/30000 (60.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7148s / 515.0883 s
agent0:                 episode reward: -0.8135,                 loss: nan
agent1:                 episode reward: 0.8135,                 loss: 0.3658
Episode: 18261/30000 (60.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7242s / 515.8125 s
agent0:                 episode reward: -0.5166,                 loss: nan
agent1:                 episode reward: 0.5166,                 loss: 0.3697
Episode: 18281/30000 (60.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9652s / 516.7777 s
agent0:                 episode reward: -0.4569,                 loss: nan
agent1:                 episode reward: 0.4569,                 loss: 0.3635
Episode: 18301/30000 (61.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8193s / 517.5970 s
agent0:                 episode reward: -0.4559,                 loss: nan
agent1:                 episode reward: 0.4559,                 loss: 0.3667
Episode: 18321/30000 (61.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8184s / 518.4154 s
agent0:                 episode reward: -0.6773,                 loss: nan
agent1:                 episode reward: 0.6773,                 loss: 0.3647
Episode: 18341/30000 (61.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7622s / 519.1776 s
agent0:                 episode reward: -0.5905,                 loss: nan
agent1:                 episode reward: 0.5905,                 loss: 0.3586
Episode: 18361/30000 (61.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7374s / 519.9150 s
agent0:                 episode reward: -0.5844,                 loss: nan
agent1:                 episode reward: 0.5844,                 loss: 0.3267
Episode: 18381/30000 (61.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7343s / 520.6493 s
agent0:                 episode reward: -0.5811,                 loss: nan
agent1:                 episode reward: 0.5811,                 loss: 0.3325
Episode: 18401/30000 (61.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7160s / 521.3653 s
agent0:                 episode reward: -0.2978,                 loss: nan
agent1:                 episode reward: 0.2978,                 loss: 0.3255
Episode: 18421/30000 (61.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7138s / 522.0791 s
agent0:                 episode reward: -0.5265,                 loss: nan
agent1:                 episode reward: 0.5265,                 loss: 0.3240
Episode: 18441/30000 (61.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7222s / 522.8013 s
agent0:                 episode reward: -0.5113,                 loss: nan
agent1:                 episode reward: 0.5113,                 loss: 0.3182
Episode: 18461/30000 (61.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7218s / 523.5231 s
agent0:                 episode reward: -0.7003,                 loss: nan
agent1:                 episode reward: 0.7003,                 loss: 0.3202
Episode: 18481/30000 (61.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7342s / 524.2573 s
agent0:                 episode reward: -0.4962,                 loss: nan
agent1:                 episode reward: 0.4962,                 loss: 0.3250
Episode: 18501/30000 (61.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7145s / 524.9717 s
agent0:                 episode reward: -0.7532,                 loss: nan
agent1:                 episode reward: 0.7532,                 loss: 0.3263
Episode: 18521/30000 (61.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7243s / 525.6961 s
agent0:                 episode reward: -0.7410,                 loss: nan
agent1:                 episode reward: 0.7410,                 loss: 0.3282
Episode: 18541/30000 (61.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7178s / 526.4138 s
agent0:                 episode reward: -0.5169,                 loss: nan
agent1:                 episode reward: 0.5169,                 loss: 0.3253
Episode: 18561/30000 (61.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7340s / 527.1479 s
agent0:                 episode reward: -0.3349,                 loss: nan
agent1:                 episode reward: 0.3349,                 loss: 0.3258
Episode: 18581/30000 (61.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7288s / 527.8767 s
agent0:                 episode reward: -0.6495,                 loss: nan
agent1:                 episode reward: 0.6495,                 loss: 0.3252
Episode: 18601/30000 (62.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7299s / 528.6066 s
agent0:                 episode reward: -0.6185,                 loss: nan
agent1:                 episode reward: 0.6185,                 loss: 0.3225
Episode: 18621/30000 (62.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7224s / 529.3290 s
agent0:                 episode reward: -0.5493,                 loss: nan
agent1:                 episode reward: 0.5493,                 loss: 0.3254
Episode: 18641/30000 (62.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7216s / 530.0505 s
agent0:                 episode reward: -0.9532,                 loss: nan
agent1:                 episode reward: 0.9532,                 loss: 0.3262
Episode: 18661/30000 (62.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7205s / 530.7711 s
agent0:                 episode reward: -0.7221,                 loss: nan
agent1:                 episode reward: 0.7221,                 loss: 0.3263
Episode: 18681/30000 (62.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7343s / 531.5054 s
agent0:                 episode reward: -0.4007,                 loss: nan
agent1:                 episode reward: 0.4007,                 loss: 0.3428
Episode: 18701/30000 (62.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7359s / 532.2413 s
agent0:                 episode reward: -0.5512,                 loss: nan
agent1:                 episode reward: 0.5512,                 loss: 0.3434
Episode: 18721/30000 (62.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7273s / 532.9686 s
agent0:                 episode reward: -0.4693,                 loss: nan
agent1:                 episode reward: 0.4693,                 loss: 0.3451
Episode: 18741/30000 (62.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7167s / 533.6853 s
agent0:                 episode reward: -0.8409,                 loss: nan
agent1:                 episode reward: 0.8409,                 loss: 0.3462
Episode: 18761/30000 (62.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7395s / 534.4248 s
agent0:                 episode reward: -0.7886,                 loss: nan
agent1:                 episode reward: 0.7886,                 loss: 0.3428
Episode: 18781/30000 (62.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7390s / 535.1638 s
agent0:                 episode reward: -0.7097,                 loss: nan
agent1:                 episode reward: 0.7097,                 loss: 0.3468
Episode: 18801/30000 (62.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7302s / 535.8940 s
agent0:                 episode reward: -0.4476,                 loss: nan
agent1:                 episode reward: 0.4476,                 loss: 0.3399
Episode: 18821/30000 (62.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7293s / 536.6233 s
agent0:                 episode reward: -0.1957,                 loss: nan
agent1:                 episode reward: 0.1957,                 loss: 0.3458
Episode: 18841/30000 (62.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7299s / 537.3532 s
agent0:                 episode reward: -0.5323,                 loss: nan
agent1:                 episode reward: 0.5323,                 loss: 0.3438
Episode: 18861/30000 (62.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7358s / 538.0890 s
agent0:                 episode reward: -0.5692,                 loss: nan
agent1:                 episode reward: 0.5692,                 loss: 0.3422
Episode: 18881/30000 (62.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7241s / 538.8130 s
agent0:                 episode reward: -0.7524,                 loss: nan
agent1:                 episode reward: 0.7524,                 loss: 0.3413
Episode: 18901/30000 (63.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7275s / 539.5406 s
agent0:                 episode reward: -0.8833,                 loss: nan
agent1:                 episode reward: 0.8833,                 loss: 0.3438
Episode: 18921/30000 (63.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7413s / 540.2819 s
agent0:                 episode reward: -0.5480,                 loss: nan
agent1:                 episode reward: 0.5480,                 loss: 0.3419
Episode: 18941/30000 (63.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7352s / 541.0171 s
agent0:                 episode reward: -0.7229,                 loss: nan
agent1:                 episode reward: 0.7229,                 loss: 0.3450
Episode: 18961/30000 (63.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 1.3313s / 542.3484 s
agent0:                 episode reward: -0.5055,                 loss: nan
agent1:                 episode reward: 0.5055,                 loss: 0.3425
Episode: 18981/30000 (63.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 1.4993s / 543.8477 s
agent0:                 episode reward: -0.8287,                 loss: nan
agent1:                 episode reward: 0.8287,                 loss: 0.3446
Episode: 19001/30000 (63.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 1.1560s / 545.0037 s
agent0:                 episode reward: -0.7335,                 loss: nan
agent1:                 episode reward: 0.7335,                 loss: 0.3483
Episode: 19021/30000 (63.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9028s / 545.9064 s
agent0:                 episode reward: -0.5683,                 loss: nan
agent1:                 episode reward: 0.5683,                 loss: 0.3725
Episode: 19041/30000 (63.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7909s / 546.6973 s
agent0:                 episode reward: -0.3903,                 loss: nan
agent1:                 episode reward: 0.3903,                 loss: 0.3603
Episode: 19061/30000 (63.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7507s / 547.4480 s
agent0:                 episode reward: -0.6656,                 loss: nan
agent1:                 episode reward: 0.6656,                 loss: 0.3593
Episode: 19081/30000 (63.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7252s / 548.1732 s
agent0:                 episode reward: -0.5604,                 loss: nan
agent1:                 episode reward: 0.5604,                 loss: 0.3570
Episode: 19101/30000 (63.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7335s / 548.9067 s
agent0:                 episode reward: -0.7523,                 loss: nan
agent1:                 episode reward: 0.7523,                 loss: 0.3618
Episode: 19121/30000 (63.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7433s / 549.6500 s
agent0:                 episode reward: -0.3613,                 loss: nan
agent1:                 episode reward: 0.3613,                 loss: 0.3612
Episode: 19141/30000 (63.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7364s / 550.3864 s
agent0:                 episode reward: -0.8460,                 loss: nan
agent1:                 episode reward: 0.8460,                 loss: 0.3597
Episode: 19161/30000 (63.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7479s / 551.1343 s
agent0:                 episode reward: -0.5562,                 loss: nan
agent1:                 episode reward: 0.5562,                 loss: 0.3609
Episode: 19181/30000 (63.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7385s / 551.8728 s
agent0:                 episode reward: -0.7278,                 loss: nan
agent1:                 episode reward: 0.7278,                 loss: 0.3588
Episode: 19201/30000 (64.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7474s / 552.6201 s
agent0:                 episode reward: -0.3971,                 loss: nan
agent1:                 episode reward: 0.3971,                 loss: 0.3582
Episode: 19221/30000 (64.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7416s / 553.3618 s
agent0:                 episode reward: -0.1346,                 loss: nan
agent1:                 episode reward: 0.1346,                 loss: 0.3567
Episode: 19241/30000 (64.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7481s / 554.1099 s
agent0:                 episode reward: -0.6555,                 loss: nan
agent1:                 episode reward: 0.6555,                 loss: 0.3585
Episode: 19261/30000 (64.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7382s / 554.8481 s
agent0:                 episode reward: -0.3143,                 loss: nan
agent1:                 episode reward: 0.3143,                 loss: 0.3616
Episode: 19281/30000 (64.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7341s / 555.5821 s
agent0:                 episode reward: -0.5337,                 loss: nan
agent1:                 episode reward: 0.5337,                 loss: 0.3587
Episode: 19301/30000 (64.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7541s / 556.3362 s
agent0:                 episode reward: -0.4602,                 loss: nan
agent1:                 episode reward: 0.4602,                 loss: 0.3592
Episode: 19321/30000 (64.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7457s / 557.0819 s
agent0:                 episode reward: -0.4864,                 loss: nan
agent1:                 episode reward: 0.4864,                 loss: 0.3551
Episode: 19341/30000 (64.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7445s / 557.8264 s
agent0:                 episode reward: -0.5475,                 loss: nan
agent1:                 episode reward: 0.5475,                 loss: 0.3540
Episode: 19361/30000 (64.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7364s / 558.5628 s
agent0:                 episode reward: -0.6584,                 loss: nan
agent1:                 episode reward: 0.6584,                 loss: 0.3227
Episode: 19381/30000 (64.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 1.3868s / 559.9496 s
agent0:                 episode reward: -0.3762,                 loss: nan
agent1:                 episode reward: 0.3762,                 loss: 0.3187
Episode: 19401/30000 (64.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 1.3020s / 561.2516 s
agent0:                 episode reward: -0.7045,                 loss: nan
agent1:                 episode reward: 0.7045,                 loss: 0.3172
Episode: 19421/30000 (64.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 1.2299s / 562.4815 s
agent0:                 episode reward: -0.5548,                 loss: nan
agent1:                 episode reward: 0.5548,                 loss: 0.3147
Episode: 19441/30000 (64.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 1.0825s / 563.5641 s
agent0:                 episode reward: -0.8156,                 loss: nan
agent1:                 episode reward: 0.8156,                 loss: 0.3167
Episode: 19461/30000 (64.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8896s / 564.4537 s
agent0:                 episode reward: -0.5048,                 loss: nan
agent1:                 episode reward: 0.5048,                 loss: 0.3175
Episode: 19481/30000 (64.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9405s / 565.3942 s
agent0:                 episode reward: -0.6592,                 loss: nan
agent1:                 episode reward: 0.6592,                 loss: 0.3197
Episode: 19501/30000 (65.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8540s / 566.2482 s
agent0:                 episode reward: -0.5730,                 loss: nan
agent1:                 episode reward: 0.5730,                 loss: 0.3162
Episode: 19521/30000 (65.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7500s / 566.9983 s
agent0:                 episode reward: -0.8758,                 loss: nan
agent1:                 episode reward: 0.8758,                 loss: 0.3155
Episode: 19541/30000 (65.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7447s / 567.7429 s
agent0:                 episode reward: -0.4648,                 loss: nan
agent1:                 episode reward: 0.4648,                 loss: 0.3166
Episode: 19561/30000 (65.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7434s / 568.4864 s
agent0:                 episode reward: -0.4945,                 loss: nan
agent1:                 episode reward: 0.4945,                 loss: 0.3154
Episode: 19581/30000 (65.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7457s / 569.2321 s
agent0:                 episode reward: -0.7324,                 loss: nan
agent1:                 episode reward: 0.7324,                 loss: 0.3157
Episode: 19601/30000 (65.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7537s / 569.9858 s
agent0:                 episode reward: -0.5918,                 loss: nan
agent1:                 episode reward: 0.5918,                 loss: 0.3162
Episode: 19621/30000 (65.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8586s / 570.8444 s
agent0:                 episode reward: -0.6322,                 loss: nan
agent1:                 episode reward: 0.6322,                 loss: 0.3226
Episode: 19641/30000 (65.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7581s / 571.6025 s
agent0:                 episode reward: -0.7361,                 loss: nan
agent1:                 episode reward: 0.7361,                 loss: 0.3197
Episode: 19661/30000 (65.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7382s / 572.3407 s
agent0:                 episode reward: -0.6861,                 loss: nan
agent1:                 episode reward: 0.6861,                 loss: 0.3197
Episode: 19681/30000 (65.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7478s / 573.0885 s
agent0:                 episode reward: -0.3187,                 loss: nan
agent1:                 episode reward: 0.3187,                 loss: 0.3440
Episode: 19701/30000 (65.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7480s / 573.8364 s
agent0:                 episode reward: -0.5923,                 loss: nan
agent1:                 episode reward: 0.5923,                 loss: 0.3486
Episode: 19721/30000 (65.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7390s / 574.5754 s
agent0:                 episode reward: -0.1891,                 loss: nan
agent1:                 episode reward: 0.1891,                 loss: 0.3476
Episode: 19741/30000 (65.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7420s / 575.3174 s
agent0:                 episode reward: -0.5208,                 loss: nan
agent1:                 episode reward: 0.5208,                 loss: 0.3485
Episode: 19761/30000 (65.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7422s / 576.0595 s
agent0:                 episode reward: -0.6505,                 loss: nan
agent1:                 episode reward: 0.6505,                 loss: 0.3472
Episode: 19781/30000 (65.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7516s / 576.8112 s
agent0:                 episode reward: -0.6815,                 loss: nan
agent1:                 episode reward: 0.6815,                 loss: 0.3488
Episode: 19801/30000 (66.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7425s / 577.5537 s
agent0:                 episode reward: -0.7234,                 loss: nan
agent1:                 episode reward: 0.7234,                 loss: 0.3474
Episode: 19821/30000 (66.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7438s / 578.2975 s
agent0:                 episode reward: -0.6894,                 loss: nan
agent1:                 episode reward: 0.6894,                 loss: 0.3453
Episode: 19841/30000 (66.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7497s / 579.0472 s
agent0:                 episode reward: -0.5749,                 loss: nan
agent1:                 episode reward: 0.5749,                 loss: 0.3512
Episode: 19861/30000 (66.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7512s / 579.7984 s
agent0:                 episode reward: -0.1284,                 loss: nan
agent1:                 episode reward: 0.1284,                 loss: 0.3499
Episode: 19881/30000 (66.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7588s / 580.5572 s
agent0:                 episode reward: -0.2739,                 loss: nan
agent1:                 episode reward: 0.2739,                 loss: 0.3479
Episode: 19901/30000 (66.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7482s / 581.3054 s
agent0:                 episode reward: -0.4741,                 loss: nan
agent1:                 episode reward: 0.4741,                 loss: 0.3499
Episode: 19921/30000 (66.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7517s / 582.0570 s
agent0:                 episode reward: -0.6748,                 loss: nan
agent1:                 episode reward: 0.6748,                 loss: 0.3523
Episode: 19941/30000 (66.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7462s / 582.8032 s
agent0:                 episode reward: -0.3523,                 loss: nan
agent1:                 episode reward: 0.3523,                 loss: 0.3486
Episode: 19961/30000 (66.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7483s / 583.5515 s
agent0:                 episode reward: -0.6778,                 loss: nan
agent1:                 episode reward: 0.6778,                 loss: 0.3486
Episode: 19981/30000 (66.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7482s / 584.2998 s
agent0:                 episode reward: -0.6797,                 loss: nan
agent1:                 episode reward: 0.6797,                 loss: 0.3474
Episode: 20001/30000 (66.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7557s / 585.0554 s
agent0:                 episode reward: -0.4669,                 loss: nan
agent1:                 episode reward: 0.4669,                 loss: 0.3530
Episode: 20021/30000 (66.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7533s / 585.8088 s
agent0:                 episode reward: -0.3716,                 loss: nan
agent1:                 episode reward: 0.3716,                 loss: 0.3699
Episode: 20041/30000 (66.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7501s / 586.5589 s
agent0:                 episode reward: -0.5304,                 loss: nan
agent1:                 episode reward: 0.5304,                 loss: 0.3594
Episode: 20061/30000 (66.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7410s / 587.2999 s
agent0:                 episode reward: -0.6558,                 loss: nan
agent1:                 episode reward: 0.6558,                 loss: 0.3558
Episode: 20081/30000 (66.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7544s / 588.0544 s
agent0:                 episode reward: -0.6294,                 loss: nan
agent1:                 episode reward: 0.6294,                 loss: 0.3568
Episode: 20101/30000 (67.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7426s / 588.7970 s
agent0:                 episode reward: -0.8173,                 loss: nan
agent1:                 episode reward: 0.8173,                 loss: 0.3541
Episode: 20121/30000 (67.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7543s / 589.5513 s
agent0:                 episode reward: -0.7475,                 loss: nan
agent1:                 episode reward: 0.7475,                 loss: 0.3545
Episode: 20141/30000 (67.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7557s / 590.3070 s
agent0:                 episode reward: -0.4357,                 loss: nan
agent1:                 episode reward: 0.4357,                 loss: 0.3537
Episode: 20161/30000 (67.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7456s / 591.0526 s
agent0:                 episode reward: -0.3184,                 loss: nan
agent1:                 episode reward: 0.3184,                 loss: 0.3536
Episode: 20181/30000 (67.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7545s / 591.8071 s
agent0:                 episode reward: -0.5733,                 loss: nan
agent1:                 episode reward: 0.5733,                 loss: 0.3556
Episode: 20201/30000 (67.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7586s / 592.5657 s
agent0:                 episode reward: -0.2076,                 loss: nan
agent1:                 episode reward: 0.2076,                 loss: 0.3530
Episode: 20221/30000 (67.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7577s / 593.3233 s
agent0:                 episode reward: -0.4187,                 loss: nan
agent1:                 episode reward: 0.4187,                 loss: 0.3540
Episode: 20241/30000 (67.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7514s / 594.0748 s
agent0:                 episode reward: -0.6127,                 loss: nan
agent1:                 episode reward: 0.6127,                 loss: 0.3535
Episode: 20261/30000 (67.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7523s / 594.8271 s
agent0:                 episode reward: -0.2183,                 loss: nan
agent1:                 episode reward: 0.2183,                 loss: 0.3551
Episode: 20281/30000 (67.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7567s / 595.5838 s
agent0:                 episode reward: -0.3473,                 loss: nan
agent1:                 episode reward: 0.3473,                 loss: 0.3525
Episode: 20301/30000 (67.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7622s / 596.3460 s
agent0:                 episode reward: -0.3697,                 loss: nan
agent1:                 episode reward: 0.3697,                 loss: 0.3538
Episode: 20321/30000 (67.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7484s / 597.0944 s
agent0:                 episode reward: -0.5993,                 loss: nan
agent1:                 episode reward: 0.5993,                 loss: 0.3564
Episode: 20341/30000 (67.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7543s / 597.8487 s
agent0:                 episode reward: -0.5642,                 loss: nan
agent1:                 episode reward: 0.5642,                 loss: 0.3532
Episode: 20361/30000 (67.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7632s / 598.6118 s
agent0:                 episode reward: -0.3059,                 loss: nan
agent1:                 episode reward: 0.3059,                 loss: 0.3067
Episode: 20381/30000 (67.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7586s / 599.3704 s
agent0:                 episode reward: -0.1116,                 loss: nan
agent1:                 episode reward: 0.1116,                 loss: 0.3074
Episode: 20401/30000 (68.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7528s / 600.1232 s
agent0:                 episode reward: -0.2830,                 loss: nan
agent1:                 episode reward: 0.2830,                 loss: 0.3080
Episode: 20421/30000 (68.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7797s / 600.9029 s
agent0:                 episode reward: -0.2498,                 loss: nan
agent1:                 episode reward: 0.2498,                 loss: 0.3077
Episode: 20441/30000 (68.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7547s / 601.6577 s
agent0:                 episode reward: -0.7059,                 loss: nan
agent1:                 episode reward: 0.7059,                 loss: 0.3077
Episode: 20461/30000 (68.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7611s / 602.4188 s
agent0:                 episode reward: -0.4451,                 loss: nan
agent1:                 episode reward: 0.4451,                 loss: 0.3078
Episode: 20481/30000 (68.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7614s / 603.1802 s
agent0:                 episode reward: -0.6255,                 loss: nan
agent1:                 episode reward: 0.6255,                 loss: 0.3076
Episode: 20501/30000 (68.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7698s / 603.9499 s
agent0:                 episode reward: -0.6354,                 loss: nan
agent1:                 episode reward: 0.6354,                 loss: 0.3073
Episode: 20521/30000 (68.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7623s / 604.7122 s
agent0:                 episode reward: -0.6076,                 loss: nan
agent1:                 episode reward: 0.6076,                 loss: 0.3048
Episode: 20541/30000 (68.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7583s / 605.4705 s
agent0:                 episode reward: -0.5269,                 loss: nan
agent1:                 episode reward: 0.5269,                 loss: 0.3059
Episode: 20561/30000 (68.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7625s / 606.2330 s
agent0:                 episode reward: -0.4139,                 loss: nan
agent1:                 episode reward: 0.4139,                 loss: 0.3028
Episode: 20581/30000 (68.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7584s / 606.9914 s
agent0:                 episode reward: -0.6350,                 loss: nan
agent1:                 episode reward: 0.6350,                 loss: 0.3070
Episode: 20601/30000 (68.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7742s / 607.7656 s
agent0:                 episode reward: -0.8320,                 loss: nan
agent1:                 episode reward: 0.8320,                 loss: 0.3072
Episode: 20621/30000 (68.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7637s / 608.5293 s
agent0:                 episode reward: -0.6714,                 loss: nan
agent1:                 episode reward: 0.6714,                 loss: 0.3066
Episode: 20641/30000 (68.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7701s / 609.2994 s
agent0:                 episode reward: 0.1025,                 loss: nan
agent1:                 episode reward: -0.1025,                 loss: 0.3044
Episode: 20661/30000 (68.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7658s / 610.0652 s
agent0:                 episode reward: -0.7510,                 loss: nan
agent1:                 episode reward: 0.7510,                 loss: 0.3055
Episode: 20681/30000 (68.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7747s / 610.8398 s
agent0:                 episode reward: -0.6118,                 loss: nan
agent1:                 episode reward: 0.6118,                 loss: 0.3608
Episode: 20701/30000 (69.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7532s / 611.5930 s
agent0:                 episode reward: -1.0669,                 loss: nan
agent1:                 episode reward: 1.0669,                 loss: 0.3697
Episode: 20721/30000 (69.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7554s / 612.3484 s
agent0:                 episode reward: -0.5801,                 loss: nan
agent1:                 episode reward: 0.5801,                 loss: 0.3685
Episode: 20741/30000 (69.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7598s / 613.1083 s
agent0:                 episode reward: -0.1322,                 loss: nan
agent1:                 episode reward: 0.1322,                 loss: 0.3619
Episode: 20761/30000 (69.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7639s / 613.8721 s
agent0:                 episode reward: -0.5235,                 loss: nan
agent1:                 episode reward: 0.5235,                 loss: 0.3668
Episode: 20781/30000 (69.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7619s / 614.6341 s
agent0:                 episode reward: -0.5189,                 loss: nan
agent1:                 episode reward: 0.5189,                 loss: 0.3660
Episode: 20801/30000 (69.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7652s / 615.3992 s
agent0:                 episode reward: -0.3909,                 loss: nan
agent1:                 episode reward: 0.3909,                 loss: 0.3667
Episode: 20821/30000 (69.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7612s / 616.1604 s
agent0:                 episode reward: -0.4463,                 loss: nan
agent1:                 episode reward: 0.4463,                 loss: 0.3669
Episode: 20841/30000 (69.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7743s / 616.9347 s
agent0:                 episode reward: -0.5851,                 loss: nan
agent1:                 episode reward: 0.5851,                 loss: 0.3665
Episode: 20861/30000 (69.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7641s / 617.6988 s
agent0:                 episode reward: -0.6410,                 loss: nan
agent1:                 episode reward: 0.6410,                 loss: 0.3692
Episode: 20881/30000 (69.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7860s / 618.4848 s
agent0:                 episode reward: -0.7475,                 loss: nan
agent1:                 episode reward: 0.7475,                 loss: 0.3669
Episode: 20901/30000 (69.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7746s / 619.2595 s
agent0:                 episode reward: -0.2341,                 loss: nan
agent1:                 episode reward: 0.2341,                 loss: 0.3639
Episode: 20921/30000 (69.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7578s / 620.0173 s
agent0:                 episode reward: -0.3747,                 loss: nan
agent1:                 episode reward: 0.3747,                 loss: 0.3652
Episode: 20941/30000 (69.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7681s / 620.7854 s
agent0:                 episode reward: -0.6987,                 loss: nan
agent1:                 episode reward: 0.6987,                 loss: 0.3661
Episode: 20961/30000 (69.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7624s / 621.5478 s
agent0:                 episode reward: -0.3339,                 loss: nan
agent1:                 episode reward: 0.3339,                 loss: 0.3663
Episode: 20981/30000 (69.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7845s / 622.3323 s
agent0:                 episode reward: -0.6972,                 loss: nan
agent1:                 episode reward: 0.6972,                 loss: 0.3661
Episode: 21001/30000 (70.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7739s / 623.1062 s
agent0:                 episode reward: -0.5697,                 loss: nan
agent1:                 episode reward: 0.5697,                 loss: 0.3662
Episode: 21021/30000 (70.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7633s / 623.8694 s
agent0:                 episode reward: -0.4781,                 loss: nan
agent1:                 episode reward: 0.4781,                 loss: 0.3669
Episode: 21041/30000 (70.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7606s / 624.6300 s
agent0:                 episode reward: -0.6393,                 loss: nan
agent1:                 episode reward: 0.6393,                 loss: 0.3542
Episode: 21061/30000 (70.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7884s / 625.4183 s
agent0:                 episode reward: -0.3955,                 loss: nan
agent1:                 episode reward: 0.3955,                 loss: 0.3523
Episode: 21081/30000 (70.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7634s / 626.1817 s
agent0:                 episode reward: -0.4903,                 loss: nan
agent1:                 episode reward: 0.4903,                 loss: 0.3558
Episode: 21101/30000 (70.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7585s / 626.9402 s
agent0:                 episode reward: -0.6238,                 loss: nan
agent1:                 episode reward: 0.6238,                 loss: 0.3550
Episode: 21121/30000 (70.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7640s / 627.7042 s
agent0:                 episode reward: -0.4385,                 loss: nan
agent1:                 episode reward: 0.4385,                 loss: 0.3552
Episode: 21141/30000 (70.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7703s / 628.4745 s
agent0:                 episode reward: -0.5575,                 loss: nan
agent1:                 episode reward: 0.5575,                 loss: 0.3551
Episode: 21161/30000 (70.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7848s / 629.2593 s
agent0:                 episode reward: -0.2822,                 loss: nan
agent1:                 episode reward: 0.2822,                 loss: 0.3498
Episode: 21181/30000 (70.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7754s / 630.0348 s
agent0:                 episode reward: -0.6334,                 loss: nan
agent1:                 episode reward: 0.6334,                 loss: 0.3573
Episode: 21201/30000 (70.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7714s / 630.8062 s
agent0:                 episode reward: -0.3873,                 loss: nan
agent1:                 episode reward: 0.3873,                 loss: 0.3538
Episode: 21221/30000 (70.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7774s / 631.5835 s
agent0:                 episode reward: -0.6108,                 loss: nan
agent1:                 episode reward: 0.6108,                 loss: 0.3549
Episode: 21241/30000 (70.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7782s / 632.3617 s
agent0:                 episode reward: -0.6032,                 loss: nan
agent1:                 episode reward: 0.6032,                 loss: 0.3543
Episode: 21261/30000 (70.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7806s / 633.1423 s
agent0:                 episode reward: -0.5170,                 loss: nan
agent1:                 episode reward: 0.5170,                 loss: 0.3532
Episode: 21281/30000 (70.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7776s / 633.9199 s
agent0:                 episode reward: -0.6021,                 loss: nan
agent1:                 episode reward: 0.6021,                 loss: 0.3538
Episode: 21301/30000 (71.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7775s / 634.6974 s
agent0:                 episode reward: -0.7167,                 loss: nan
agent1:                 episode reward: 0.7167,                 loss: 0.3559
Episode: 21321/30000 (71.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7755s / 635.4729 s
agent0:                 episode reward: -0.9415,                 loss: nan
agent1:                 episode reward: 0.9415,                 loss: 0.3530
Episode: 21341/30000 (71.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8178s / 636.2907 s
agent0:                 episode reward: -0.5031,                 loss: nan
agent1:                 episode reward: 0.5031,                 loss: 0.3574
Episode: 21361/30000 (71.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7853s / 637.0760 s
agent0:                 episode reward: -0.5666,                 loss: nan
agent1:                 episode reward: 0.5666,                 loss: 0.3146
Episode: 21381/30000 (71.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7745s / 637.8505 s
agent0:                 episode reward: -0.5225,                 loss: nan
agent1:                 episode reward: 0.5225,                 loss: 0.3128
Episode: 21401/30000 (71.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7834s / 638.6339 s
agent0:                 episode reward: -0.5573,                 loss: nan
agent1:                 episode reward: 0.5573,                 loss: 0.3136
Episode: 21421/30000 (71.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7722s / 639.4061 s
agent0:                 episode reward: -0.5536,                 loss: nan
agent1:                 episode reward: 0.5536,                 loss: 0.3127
Episode: 21441/30000 (71.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7974s / 640.2036 s
agent0:                 episode reward: -0.7207,                 loss: nan
agent1:                 episode reward: 0.7207,                 loss: 0.3107
Episode: 21461/30000 (71.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7882s / 640.9918 s
agent0:                 episode reward: -0.7975,                 loss: nan
agent1:                 episode reward: 0.7975,                 loss: 0.3125
Episode: 21481/30000 (71.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7852s / 641.7769 s
agent0:                 episode reward: -0.3592,                 loss: nan
agent1:                 episode reward: 0.3592,                 loss: 0.3143
Episode: 21501/30000 (71.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7883s / 642.5652 s
agent0:                 episode reward: -0.5266,                 loss: nan
agent1:                 episode reward: 0.5266,                 loss: 0.3138
Episode: 21521/30000 (71.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7796s / 643.3448 s
agent0:                 episode reward: -0.7888,                 loss: nan
agent1:                 episode reward: 0.7888,                 loss: 0.3101
Episode: 21541/30000 (71.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7786s / 644.1235 s
agent0:                 episode reward: -0.4658,                 loss: nan
agent1:                 episode reward: 0.4658,                 loss: 0.3139
Episode: 21561/30000 (71.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7898s / 644.9133 s
agent0:                 episode reward: -0.5465,                 loss: nan
agent1:                 episode reward: 0.5465,                 loss: 0.3092
Episode: 21581/30000 (71.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7742s / 645.6875 s
agent0:                 episode reward: -0.2677,                 loss: nan
agent1:                 episode reward: 0.2677,                 loss: 0.3094
Episode: 21601/30000 (72.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7744s / 646.4619 s
agent0:                 episode reward: -0.3295,                 loss: nan
agent1:                 episode reward: 0.3295,                 loss: 0.3127
Episode: 21621/30000 (72.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7690s / 647.2310 s
agent0:                 episode reward: -0.3398,                 loss: nan
agent1:                 episode reward: 0.3398,                 loss: 0.3129
Episode: 21641/30000 (72.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7914s / 648.0224 s
agent0:                 episode reward: -0.2960,                 loss: nan
agent1:                 episode reward: 0.2960,                 loss: 0.3117
Episode: 21661/30000 (72.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7732s / 648.7956 s
agent0:                 episode reward: -0.4081,                 loss: nan
agent1:                 episode reward: 0.4081,                 loss: 0.3155
Episode: 21681/30000 (72.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7843s / 649.5799 s
agent0:                 episode reward: -0.5032,                 loss: nan
agent1:                 episode reward: 0.5032,                 loss: 0.3620
Episode: 21701/30000 (72.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7893s / 650.3692 s
agent0:                 episode reward: -0.9550,                 loss: nan
agent1:                 episode reward: 0.9550,                 loss: 0.3664
Episode: 21721/30000 (72.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7962s / 651.1654 s
agent0:                 episode reward: -0.5349,                 loss: nan
agent1:                 episode reward: 0.5349,                 loss: 0.3693
Episode: 21741/30000 (72.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7865s / 651.9519 s
agent0:                 episode reward: -0.4359,                 loss: nan
agent1:                 episode reward: 0.4359,                 loss: 0.3704
Episode: 21761/30000 (72.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7915s / 652.7433 s
agent0:                 episode reward: -0.5072,                 loss: nan
agent1:                 episode reward: 0.5072,                 loss: 0.3715
Episode: 21781/30000 (72.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7770s / 653.5203 s
agent0:                 episode reward: -0.5884,                 loss: nan
agent1:                 episode reward: 0.5884,                 loss: 0.3704
Episode: 21801/30000 (72.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8137s / 654.3340 s
agent0:                 episode reward: -0.5601,                 loss: nan
agent1:                 episode reward: 0.5601,                 loss: 0.3695
Episode: 21821/30000 (72.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8145s / 655.1485 s
agent0:                 episode reward: -0.4824,                 loss: nan
agent1:                 episode reward: 0.4824,                 loss: 0.3705
Episode: 21841/30000 (72.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7765s / 655.9250 s
agent0:                 episode reward: -0.6163,                 loss: nan
agent1:                 episode reward: 0.6163,                 loss: 0.3675
Episode: 21861/30000 (72.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7764s / 656.7014 s
agent0:                 episode reward: -0.5705,                 loss: nan
agent1:                 episode reward: 0.5705,                 loss: 0.3768
Episode: 21881/30000 (72.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7981s / 657.4995 s
agent0:                 episode reward: -0.5748,                 loss: nan
agent1:                 episode reward: 0.5748,                 loss: 0.3667
Episode: 21901/30000 (73.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8719s / 658.3714 s
agent0:                 episode reward: -0.5243,                 loss: nan
agent1:                 episode reward: 0.5243,                 loss: 0.3722
Episode: 21921/30000 (73.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7841s / 659.1555 s
agent0:                 episode reward: -0.9800,                 loss: nan
agent1:                 episode reward: 0.9800,                 loss: 0.3716
Episode: 21941/30000 (73.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7900s / 659.9454 s
agent0:                 episode reward: -0.6871,                 loss: nan
agent1:                 episode reward: 0.6871,                 loss: 0.3739
Episode: 21961/30000 (73.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8025s / 660.7479 s
agent0:                 episode reward: -0.5709,                 loss: nan
agent1:                 episode reward: 0.5709,                 loss: 0.3701
Episode: 21981/30000 (73.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7831s / 661.5310 s
agent0:                 episode reward: -0.6528,                 loss: nan
agent1:                 episode reward: 0.6528,                 loss: 0.3711
Episode: 22001/30000 (73.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7794s / 662.3105 s
agent0:                 episode reward: -0.5298,                 loss: nan
agent1:                 episode reward: 0.5298,                 loss: 0.3691
Episode: 22021/30000 (73.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7833s / 663.0938 s
agent0:                 episode reward: -0.4328,                 loss: nan
agent1:                 episode reward: 0.4328,                 loss: 0.3571
Episode: 22041/30000 (73.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7879s / 663.8817 s
agent0:                 episode reward: -0.7885,                 loss: nan
agent1:                 episode reward: 0.7885,                 loss: 0.3572
Episode: 22061/30000 (73.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8021s / 664.6837 s
agent0:                 episode reward: -0.2048,                 loss: nan
agent1:                 episode reward: 0.2048,                 loss: 0.3543
Episode: 22081/30000 (73.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8265s / 665.5102 s
agent0:                 episode reward: -0.6071,                 loss: nan
agent1:                 episode reward: 0.6071,                 loss: 0.3524
Episode: 22101/30000 (73.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8023s / 666.3125 s
agent0:                 episode reward: -0.5170,                 loss: nan
agent1:                 episode reward: 0.5170,                 loss: 0.3543
Episode: 22121/30000 (73.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7856s / 667.0981 s
agent0:                 episode reward: -0.5155,                 loss: nan
agent1:                 episode reward: 0.5155,                 loss: 0.3576
Episode: 22141/30000 (73.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7900s / 667.8881 s
agent0:                 episode reward: -0.6455,                 loss: nan
agent1:                 episode reward: 0.6455,                 loss: 0.3519
Episode: 22161/30000 (73.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7890s / 668.6772 s
agent0:                 episode reward: -0.6388,                 loss: nan
agent1:                 episode reward: 0.6388,                 loss: 0.3535
Episode: 22181/30000 (73.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7866s / 669.4638 s
agent0:                 episode reward: -0.7953,                 loss: nan
agent1:                 episode reward: 0.7953,                 loss: 0.3535
Episode: 22201/30000 (74.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8871s / 670.3509 s
agent0:                 episode reward: -0.4514,                 loss: nan
agent1:                 episode reward: 0.4514,                 loss: 0.3492
Episode: 22221/30000 (74.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8103s / 671.1612 s
agent0:                 episode reward: -0.3561,                 loss: nan
agent1:                 episode reward: 0.3561,                 loss: 0.3542
Episode: 22241/30000 (74.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7916s / 671.9527 s
agent0:                 episode reward: -0.6513,                 loss: nan
agent1:                 episode reward: 0.6513,                 loss: 0.3548
Episode: 22261/30000 (74.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7835s / 672.7362 s
agent0:                 episode reward: -0.8466,                 loss: nan
agent1:                 episode reward: 0.8466,                 loss: 0.3550
Episode: 22281/30000 (74.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7873s / 673.5236 s
agent0:                 episode reward: -0.3021,                 loss: nan
agent1:                 episode reward: 0.3021,                 loss: 0.3536
Episode: 22301/30000 (74.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7951s / 674.3187 s
agent0:                 episode reward: -0.3347,                 loss: nan
agent1:                 episode reward: 0.3347,                 loss: 0.3536
Episode: 22321/30000 (74.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7856s / 675.1043 s
agent0:                 episode reward: -0.5867,                 loss: nan
agent1:                 episode reward: 0.5867,                 loss: 0.3540
Episode: 22341/30000 (74.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7863s / 675.8906 s
agent0:                 episode reward: -0.3093,                 loss: nan
agent1:                 episode reward: 0.3093,                 loss: 0.3536
Episode: 22361/30000 (74.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7933s / 676.6839 s
agent0:                 episode reward: -0.5110,                 loss: nan
agent1:                 episode reward: 0.5110,                 loss: 0.3333
Episode: 22381/30000 (74.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7883s / 677.4721 s
agent0:                 episode reward: -0.6517,                 loss: nan
agent1:                 episode reward: 0.6517,                 loss: 0.3335
Episode: 22401/30000 (74.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7916s / 678.2638 s
agent0:                 episode reward: -0.5872,                 loss: nan
agent1:                 episode reward: 0.5872,                 loss: 0.3315
Episode: 22421/30000 (74.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 1.0376s / 679.3014 s
agent0:                 episode reward: -0.5388,                 loss: nan
agent1:                 episode reward: 0.5388,                 loss: 0.3330
Episode: 22441/30000 (74.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 1.2092s / 680.5106 s
agent0:                 episode reward: -0.4569,                 loss: nan
agent1:                 episode reward: 0.4569,                 loss: 0.3332
Episode: 22461/30000 (74.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 1.0466s / 681.5572 s
agent0:                 episode reward: -0.9871,                 loss: nan
agent1:                 episode reward: 0.9871,                 loss: 0.3327
Episode: 22481/30000 (74.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9280s / 682.4852 s
agent0:                 episode reward: -0.4045,                 loss: nan
agent1:                 episode reward: 0.4045,                 loss: 0.3308
Episode: 22501/30000 (75.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8349s / 683.3201 s
agent0:                 episode reward: -0.3218,                 loss: nan
agent1:                 episode reward: 0.3218,                 loss: 0.3256
Episode: 22521/30000 (75.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8092s / 684.1292 s
agent0:                 episode reward: -0.4419,                 loss: nan
agent1:                 episode reward: 0.4419,                 loss: 0.3287
Episode: 22541/30000 (75.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8664s / 684.9957 s
agent0:                 episode reward: -0.7673,                 loss: nan
agent1:                 episode reward: 0.7673,                 loss: 0.3280
Episode: 22561/30000 (75.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 1.0250s / 686.0206 s
agent0:                 episode reward: -0.6526,                 loss: nan
agent1:                 episode reward: 0.6526,                 loss: 0.3279
Episode: 22581/30000 (75.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9110s / 686.9316 s
agent0:                 episode reward: -0.5708,                 loss: nan
agent1:                 episode reward: 0.5708,                 loss: 0.3336
Episode: 22601/30000 (75.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8105s / 687.7422 s
agent0:                 episode reward: -1.1316,                 loss: nan
agent1:                 episode reward: 1.1316,                 loss: 0.3302
Episode: 22621/30000 (75.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7981s / 688.5403 s
agent0:                 episode reward: -0.3922,                 loss: nan
agent1:                 episode reward: 0.3922,                 loss: 0.3307
Episode: 22641/30000 (75.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8020s / 689.3423 s
agent0:                 episode reward: -0.3923,                 loss: nan
agent1:                 episode reward: 0.3923,                 loss: 0.3337
Episode: 22661/30000 (75.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7838s / 690.1261 s
agent0:                 episode reward: -0.6520,                 loss: nan
agent1:                 episode reward: 0.6520,                 loss: 0.3324
Episode: 22681/30000 (75.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7997s / 690.9258 s
agent0:                 episode reward: -0.6657,                 loss: nan
agent1:                 episode reward: 0.6657,                 loss: 0.3616
Episode: 22701/30000 (75.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7997s / 691.7255 s
agent0:                 episode reward: -0.4360,                 loss: nan
agent1:                 episode reward: 0.4360,                 loss: 0.3717
Episode: 22721/30000 (75.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7956s / 692.5211 s
agent0:                 episode reward: -0.5432,                 loss: nan
agent1:                 episode reward: 0.5432,                 loss: 0.3696
Episode: 22741/30000 (75.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8017s / 693.3228 s
agent0:                 episode reward: -0.1566,                 loss: nan
agent1:                 episode reward: 0.1566,                 loss: 0.3705
Episode: 22761/30000 (75.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8003s / 694.1231 s
agent0:                 episode reward: -0.7698,                 loss: nan
agent1:                 episode reward: 0.7698,                 loss: 0.3706
Episode: 22781/30000 (75.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8070s / 694.9301 s
agent0:                 episode reward: -0.6089,                 loss: nan
agent1:                 episode reward: 0.6089,                 loss: 0.3710
Episode: 22801/30000 (76.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7920s / 695.7221 s
agent0:                 episode reward: -0.2899,                 loss: nan
agent1:                 episode reward: 0.2899,                 loss: 0.3721
Episode: 22821/30000 (76.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8069s / 696.5290 s
agent0:                 episode reward: -0.8005,                 loss: nan
agent1:                 episode reward: 0.8005,                 loss: 0.3725
Episode: 22841/30000 (76.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8661s / 697.3951 s
agent0:                 episode reward: -0.6892,                 loss: nan
agent1:                 episode reward: 0.6892,                 loss: 0.3687
Episode: 22861/30000 (76.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 1.4755s / 698.8706 s
agent0:                 episode reward: -0.2470,                 loss: nan
agent1:                 episode reward: 0.2470,                 loss: 0.3723
Episode: 22881/30000 (76.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 1.2311s / 700.1017 s
agent0:                 episode reward: -0.8109,                 loss: nan
agent1:                 episode reward: 0.8109,                 loss: 0.3721
Episode: 22901/30000 (76.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 1.0966s / 701.1983 s
agent0:                 episode reward: -0.3945,                 loss: nan
agent1:                 episode reward: 0.3945,                 loss: 0.3698
Episode: 22921/30000 (76.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9623s / 702.1606 s
agent0:                 episode reward: -0.4572,                 loss: nan
agent1:                 episode reward: 0.4572,                 loss: 0.3677
Episode: 22941/30000 (76.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8263s / 702.9869 s
agent0:                 episode reward: -0.5021,                 loss: nan
agent1:                 episode reward: 0.5021,                 loss: 0.3709
Episode: 22961/30000 (76.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8039s / 703.7909 s
agent0:                 episode reward: -0.7588,                 loss: nan
agent1:                 episode reward: 0.7588,                 loss: 0.3741
Episode: 22981/30000 (76.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7948s / 704.5857 s
agent0:                 episode reward: -0.7453,                 loss: nan
agent1:                 episode reward: 0.7453,                 loss: 0.3709
Episode: 23001/30000 (76.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7927s / 705.3784 s
agent0:                 episode reward: -0.4407,                 loss: nan
agent1:                 episode reward: 0.4407,                 loss: 0.3733
Episode: 23021/30000 (76.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8058s / 706.1842 s
agent0:                 episode reward: -0.6245,                 loss: nan
agent1:                 episode reward: 0.6245,                 loss: 0.3539
Episode: 23041/30000 (76.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 1.1826s / 707.3668 s
agent0:                 episode reward: -0.8016,                 loss: nan
agent1:                 episode reward: 0.8016,                 loss: 0.3537
Episode: 23061/30000 (76.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 1.1569s / 708.5236 s
agent0:                 episode reward: -0.6487,                 loss: nan
agent1:                 episode reward: 0.6487,                 loss: 0.3530
Episode: 23081/30000 (76.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 1.0316s / 709.5553 s
agent0:                 episode reward: -0.3901,                 loss: nan
agent1:                 episode reward: 0.3901,                 loss: 0.3523
Episode: 23101/30000 (77.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8691s / 710.4243 s
agent0:                 episode reward: -0.2119,                 loss: nan
agent1:                 episode reward: 0.2119,                 loss: 0.3542
Episode: 23121/30000 (77.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8230s / 711.2474 s
agent0:                 episode reward: -0.6756,                 loss: nan
agent1:                 episode reward: 0.6756,                 loss: 0.3546
Episode: 23141/30000 (77.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8188s / 712.0661 s
agent0:                 episode reward: -0.6890,                 loss: nan
agent1:                 episode reward: 0.6890,                 loss: 0.3507
Episode: 23161/30000 (77.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8239s / 712.8900 s
agent0:                 episode reward: -0.8267,                 loss: nan
agent1:                 episode reward: 0.8267,                 loss: 0.3546
Episode: 23181/30000 (77.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8002s / 713.6902 s
agent0:                 episode reward: -0.7989,                 loss: nan
agent1:                 episode reward: 0.7989,                 loss: 0.3530
Episode: 23201/30000 (77.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8045s / 714.4948 s
agent0:                 episode reward: -0.2757,                 loss: nan
agent1:                 episode reward: 0.2757,                 loss: 0.3552
Episode: 23221/30000 (77.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8134s / 715.3082 s
agent0:                 episode reward: -0.6437,                 loss: nan
agent1:                 episode reward: 0.6437,                 loss: 0.3501
Episode: 23241/30000 (77.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8124s / 716.1206 s
agent0:                 episode reward: -0.5894,                 loss: nan
agent1:                 episode reward: 0.5894,                 loss: 0.3526
Episode: 23261/30000 (77.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8073s / 716.9280 s
agent0:                 episode reward: -0.8623,                 loss: nan
agent1:                 episode reward: 0.8623,                 loss: 0.3494
Episode: 23281/30000 (77.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8168s / 717.7447 s
agent0:                 episode reward: -0.6329,                 loss: nan
agent1:                 episode reward: 0.6329,                 loss: 0.3556
Episode: 23301/30000 (77.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7979s / 718.5427 s
agent0:                 episode reward: -0.6190,                 loss: nan
agent1:                 episode reward: 0.6190,                 loss: 0.3513
Episode: 23321/30000 (77.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8143s / 719.3570 s
agent0:                 episode reward: -0.6515,                 loss: nan
agent1:                 episode reward: 0.6515,                 loss: 0.3518
Episode: 23341/30000 (77.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8129s / 720.1699 s
agent0:                 episode reward: -0.6376,                 loss: nan
agent1:                 episode reward: 0.6376,                 loss: 0.3507
Episode: 23361/30000 (77.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8248s / 720.9948 s
agent0:                 episode reward: -0.5582,                 loss: nan
agent1:                 episode reward: 0.5582,                 loss: 0.3184
Episode: 23381/30000 (77.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8228s / 721.8175 s
agent0:                 episode reward: -0.4001,                 loss: nan
agent1:                 episode reward: 0.4001,                 loss: 0.3161
Episode: 23401/30000 (78.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8136s / 722.6311 s
agent0:                 episode reward: -0.3963,                 loss: nan
agent1:                 episode reward: 0.3963,                 loss: 0.3154
Episode: 23421/30000 (78.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8085s / 723.4396 s
agent0:                 episode reward: -0.3893,                 loss: nan
agent1:                 episode reward: 0.3893,                 loss: 0.3142
Episode: 23441/30000 (78.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8114s / 724.2510 s
agent0:                 episode reward: -0.6427,                 loss: nan
agent1:                 episode reward: 0.6427,                 loss: 0.3137
Episode: 23461/30000 (78.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8060s / 725.0570 s
agent0:                 episode reward: -0.7212,                 loss: nan
agent1:                 episode reward: 0.7212,                 loss: 0.3142
Episode: 23481/30000 (78.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8069s / 725.8639 s
agent0:                 episode reward: -0.6856,                 loss: nan
agent1:                 episode reward: 0.6856,                 loss: 0.3145
Episode: 23501/30000 (78.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8292s / 726.6932 s
agent0:                 episode reward: -0.3884,                 loss: nan
agent1:                 episode reward: 0.3884,                 loss: 0.3102
Episode: 23521/30000 (78.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8063s / 727.4995 s
agent0:                 episode reward: -0.5599,                 loss: nan
agent1:                 episode reward: 0.5599,                 loss: 0.3133
Episode: 23541/30000 (78.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8078s / 728.3073 s
agent0:                 episode reward: -0.6997,                 loss: nan
agent1:                 episode reward: 0.6997,                 loss: 0.3158
Episode: 23561/30000 (78.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8083s / 729.1156 s
agent0:                 episode reward: -1.1093,                 loss: nan
agent1:                 episode reward: 1.1093,                 loss: 0.3128
Episode: 23581/30000 (78.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8231s / 729.9387 s
agent0:                 episode reward: -0.7929,                 loss: nan
agent1:                 episode reward: 0.7929,                 loss: 0.3106
Episode: 23601/30000 (78.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8141s / 730.7528 s
agent0:                 episode reward: -0.3860,                 loss: nan
agent1:                 episode reward: 0.3860,                 loss: 0.3163
Episode: 23621/30000 (78.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8216s / 731.5743 s
agent0:                 episode reward: -0.5513,                 loss: nan
agent1:                 episode reward: 0.5513,                 loss: 0.3150
Episode: 23641/30000 (78.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8180s / 732.3924 s
agent0:                 episode reward: -0.4995,                 loss: nan
agent1:                 episode reward: 0.4995,                 loss: 0.3131
Episode: 23661/30000 (78.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8111s / 733.2034 s
agent0:                 episode reward: -0.4403,                 loss: nan
agent1:                 episode reward: 0.4403,                 loss: 0.3132
Episode: 23681/30000 (78.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8107s / 734.0141 s
agent0:                 episode reward: -0.5768,                 loss: nan
agent1:                 episode reward: 0.5768,                 loss: 0.3677
Episode: 23701/30000 (79.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8084s / 734.8226 s
agent0:                 episode reward: -0.4842,                 loss: nan
agent1:                 episode reward: 0.4842,                 loss: 0.3723
Episode: 23721/30000 (79.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8096s / 735.6321 s
agent0:                 episode reward: -0.5998,                 loss: nan
agent1:                 episode reward: 0.5998,                 loss: 0.3736
Episode: 23741/30000 (79.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8066s / 736.4388 s
agent0:                 episode reward: -0.7340,                 loss: nan
agent1:                 episode reward: 0.7340,                 loss: 0.3702
Episode: 23761/30000 (79.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8110s / 737.2498 s
agent0:                 episode reward: -0.8453,                 loss: nan
agent1:                 episode reward: 0.8453,                 loss: 0.3726
Episode: 23781/30000 (79.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8174s / 738.0672 s
agent0:                 episode reward: -0.9073,                 loss: nan
agent1:                 episode reward: 0.9073,                 loss: 0.3743
Episode: 23801/30000 (79.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8170s / 738.8843 s
agent0:                 episode reward: -0.3184,                 loss: nan
agent1:                 episode reward: 0.3184,                 loss: 0.3719
Episode: 23821/30000 (79.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8139s / 739.6982 s
agent0:                 episode reward: -0.4685,                 loss: nan
agent1:                 episode reward: 0.4685,                 loss: 0.3730
Episode: 23841/30000 (79.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8261s / 740.5243 s
agent0:                 episode reward: -0.5645,                 loss: nan
agent1:                 episode reward: 0.5645,                 loss: 0.3729
Episode: 23861/30000 (79.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8149s / 741.3392 s
agent0:                 episode reward: -0.3203,                 loss: nan
agent1:                 episode reward: 0.3203,                 loss: 0.3712
Episode: 23881/30000 (79.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8136s / 742.1528 s
agent0:                 episode reward: -0.7211,                 loss: nan
agent1:                 episode reward: 0.7211,                 loss: 0.3700
Episode: 23901/30000 (79.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8307s / 742.9835 s
agent0:                 episode reward: -0.5012,                 loss: nan
agent1:                 episode reward: 0.5012,                 loss: 0.3740
Episode: 23921/30000 (79.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8348s / 743.8183 s
agent0:                 episode reward: -0.5869,                 loss: nan
agent1:                 episode reward: 0.5869,                 loss: 0.3688
Episode: 23941/30000 (79.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8172s / 744.6355 s
agent0:                 episode reward: -0.6768,                 loss: nan
agent1:                 episode reward: 0.6768,                 loss: 0.3728
Episode: 23961/30000 (79.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8178s / 745.4533 s
agent0:                 episode reward: -0.6005,                 loss: nan
agent1:                 episode reward: 0.6005,                 loss: 0.3712
Episode: 23981/30000 (79.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8278s / 746.2811 s
agent0:                 episode reward: -0.5065,                 loss: nan
agent1:                 episode reward: 0.5065,                 loss: 0.3732
Episode: 24001/30000 (80.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8418s / 747.1229 s
agent0:                 episode reward: -0.3839,                 loss: nan
agent1:                 episode reward: 0.3839,                 loss: 0.3719
Episode: 24021/30000 (80.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8340s / 747.9569 s
agent0:                 episode reward: -0.6115,                 loss: nan
agent1:                 episode reward: 0.6115,                 loss: 0.3490
Episode: 24041/30000 (80.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8165s / 748.7734 s
agent0:                 episode reward: -0.5853,                 loss: nan
agent1:                 episode reward: 0.5853,                 loss: 0.3424
Episode: 24061/30000 (80.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8247s / 749.5981 s
agent0:                 episode reward: -0.5877,                 loss: nan
agent1:                 episode reward: 0.5877,                 loss: 0.3412
Episode: 24081/30000 (80.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8283s / 750.4263 s
agent0:                 episode reward: -0.4868,                 loss: nan
agent1:                 episode reward: 0.4868,                 loss: 0.3424
Episode: 24101/30000 (80.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8211s / 751.2475 s
agent0:                 episode reward: -0.5155,                 loss: nan
agent1:                 episode reward: 0.5155,                 loss: 0.3388
Episode: 24121/30000 (80.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8246s / 752.0721 s
agent0:                 episode reward: -0.6645,                 loss: nan
agent1:                 episode reward: 0.6645,                 loss: 0.3413
Episode: 24141/30000 (80.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8173s / 752.8894 s
agent0:                 episode reward: -0.3378,                 loss: nan
agent1:                 episode reward: 0.3378,                 loss: 0.3391
Episode: 24161/30000 (80.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8279s / 753.7173 s
agent0:                 episode reward: -0.5526,                 loss: nan
agent1:                 episode reward: 0.5526,                 loss: 0.3420
Episode: 24181/30000 (80.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8218s / 754.5391 s
agent0:                 episode reward: -0.6976,                 loss: nan
agent1:                 episode reward: 0.6976,                 loss: 0.3418
Episode: 24201/30000 (80.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8232s / 755.3623 s
agent0:                 episode reward: -0.6388,                 loss: nan
agent1:                 episode reward: 0.6388,                 loss: 0.3390
Episode: 24221/30000 (80.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8282s / 756.1905 s
agent0:                 episode reward: -0.5801,                 loss: nan
agent1:                 episode reward: 0.5801,                 loss: 0.3395
Episode: 24241/30000 (80.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8330s / 757.0235 s
agent0:                 episode reward: -0.6790,                 loss: nan
agent1:                 episode reward: 0.6790,                 loss: 0.3410
Episode: 24261/30000 (80.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8458s / 757.8692 s
agent0:                 episode reward: -0.4259,                 loss: nan
agent1:                 episode reward: 0.4259,                 loss: 0.3409
Episode: 24281/30000 (80.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8226s / 758.6918 s
agent0:                 episode reward: -0.5017,                 loss: nan
agent1:                 episode reward: 0.5017,                 loss: 0.3408
Episode: 24301/30000 (81.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8462s / 759.5381 s
agent0:                 episode reward: -0.7276,                 loss: nan
agent1:                 episode reward: 0.7276,                 loss: 0.3406
Episode: 24321/30000 (81.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8297s / 760.3677 s
agent0:                 episode reward: -0.6784,                 loss: nan
agent1:                 episode reward: 0.6784,                 loss: 0.3420
Episode: 24341/30000 (81.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8354s / 761.2031 s
agent0:                 episode reward: -0.1987,                 loss: nan
agent1:                 episode reward: 0.1987,                 loss: 0.3454
Episode: 24361/30000 (81.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8406s / 762.0437 s
agent0:                 episode reward: -0.5372,                 loss: nan
agent1:                 episode reward: 0.5372,                 loss: 0.3086
Episode: 24381/30000 (81.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8363s / 762.8800 s
agent0:                 episode reward: -0.7253,                 loss: nan
agent1:                 episode reward: 0.7253,                 loss: 0.3068
Episode: 24401/30000 (81.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8300s / 763.7100 s
agent0:                 episode reward: -0.3705,                 loss: nan
agent1:                 episode reward: 0.3705,                 loss: 0.3001
Episode: 24421/30000 (81.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8420s / 764.5520 s
agent0:                 episode reward: -0.4616,                 loss: nan
agent1:                 episode reward: 0.4616,                 loss: 0.3026
Episode: 24441/30000 (81.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8422s / 765.3942 s
agent0:                 episode reward: -0.1068,                 loss: nan
agent1:                 episode reward: 0.1068,                 loss: 0.3043
Episode: 24461/30000 (81.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8310s / 766.2252 s
agent0:                 episode reward: -0.4913,                 loss: nan
agent1:                 episode reward: 0.4913,                 loss: 0.3010
Episode: 24481/30000 (81.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8292s / 767.0544 s
agent0:                 episode reward: -0.5681,                 loss: nan
agent1:                 episode reward: 0.5681,                 loss: 0.3048
Episode: 24501/30000 (81.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8376s / 767.8920 s
agent0:                 episode reward: -0.2277,                 loss: nan
agent1:                 episode reward: 0.2277,                 loss: 0.3049
Episode: 24521/30000 (81.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8286s / 768.7206 s
agent0:                 episode reward: -0.6937,                 loss: nan
agent1:                 episode reward: 0.6937,                 loss: 0.3038
Episode: 24541/30000 (81.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8354s / 769.5560 s
agent0:                 episode reward: -0.7107,                 loss: nan
agent1:                 episode reward: 0.7107,                 loss: 0.3068
Episode: 24561/30000 (81.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8248s / 770.3808 s
agent0:                 episode reward: -0.3481,                 loss: nan
agent1:                 episode reward: 0.3481,                 loss: 0.2993
Episode: 24581/30000 (81.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8367s / 771.2175 s
agent0:                 episode reward: -0.9249,                 loss: nan
agent1:                 episode reward: 0.9249,                 loss: 0.2987
Episode: 24601/30000 (82.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8366s / 772.0540 s
agent0:                 episode reward: -0.3144,                 loss: nan
agent1:                 episode reward: 0.3144,                 loss: 0.3024
Episode: 24621/30000 (82.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8227s / 772.8768 s
agent0:                 episode reward: -0.5220,                 loss: nan
agent1:                 episode reward: 0.5220,                 loss: 0.3056
Episode: 24641/30000 (82.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8392s / 773.7160 s
agent0:                 episode reward: -0.5258,                 loss: nan
agent1:                 episode reward: 0.5258,                 loss: 0.3053
Episode: 24661/30000 (82.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8422s / 774.5581 s
agent0:                 episode reward: -0.7679,                 loss: nan
agent1:                 episode reward: 0.7679,                 loss: 0.3038
Episode: 24681/30000 (82.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8350s / 775.3931 s
agent0:                 episode reward: -0.5271,                 loss: nan
agent1:                 episode reward: 0.5271,                 loss: 0.3760
Episode: 24701/30000 (82.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8312s / 776.2243 s
agent0:                 episode reward: -0.6549,                 loss: nan
agent1:                 episode reward: 0.6549,                 loss: 0.3596
Episode: 24721/30000 (82.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8338s / 777.0581 s
agent0:                 episode reward: -0.3257,                 loss: nan
agent1:                 episode reward: 0.3257,                 loss: 0.3592
Episode: 24741/30000 (82.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8332s / 777.8913 s
agent0:                 episode reward: -0.6526,                 loss: nan
agent1:                 episode reward: 0.6526,                 loss: 0.3618
Episode: 24761/30000 (82.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8256s / 778.7169 s
agent0:                 episode reward: -0.4968,                 loss: nan
agent1:                 episode reward: 0.4968,                 loss: 0.3587
Episode: 24781/30000 (82.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8330s / 779.5499 s
agent0:                 episode reward: -0.8846,                 loss: nan
agent1:                 episode reward: 0.8846,                 loss: 0.3636
Episode: 24801/30000 (82.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8350s / 780.3849 s
agent0:                 episode reward: -0.7850,                 loss: nan
agent1:                 episode reward: 0.7850,                 loss: 0.3573
Episode: 24821/30000 (82.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8544s / 781.2393 s
agent0:                 episode reward: -0.4730,                 loss: nan
agent1:                 episode reward: 0.4730,                 loss: 0.3600
Episode: 24841/30000 (82.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8373s / 782.0766 s
agent0:                 episode reward: -0.6448,                 loss: nan
agent1:                 episode reward: 0.6448,                 loss: 0.3605
Episode: 24861/30000 (82.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8555s / 782.9321 s
agent0:                 episode reward: -0.6236,                 loss: nan
agent1:                 episode reward: 0.6236,                 loss: 0.3605
Episode: 24881/30000 (82.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8643s / 783.7964 s
agent0:                 episode reward: -0.3999,                 loss: nan
agent1:                 episode reward: 0.3999,                 loss: 0.3609
Episode: 24901/30000 (83.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8333s / 784.6297 s
agent0:                 episode reward: -0.8518,                 loss: nan
agent1:                 episode reward: 0.8518,                 loss: 0.3619
Episode: 24921/30000 (83.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8440s / 785.4736 s
agent0:                 episode reward: -0.5015,                 loss: nan
agent1:                 episode reward: 0.5015,                 loss: 0.3615
Episode: 24941/30000 (83.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8404s / 786.3140 s
agent0:                 episode reward: -0.2856,                 loss: nan
agent1:                 episode reward: 0.2856,                 loss: 0.3611
Episode: 24961/30000 (83.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8561s / 787.1702 s
agent0:                 episode reward: -0.3115,                 loss: nan
agent1:                 episode reward: 0.3115,                 loss: 0.3585
Episode: 24981/30000 (83.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8587s / 788.0288 s
agent0:                 episode reward: -0.6221,                 loss: nan
agent1:                 episode reward: 0.6221,                 loss: 0.3584
Episode: 25001/30000 (83.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8346s / 788.8634 s
agent0:                 episode reward: -0.6495,                 loss: nan
agent1:                 episode reward: 0.6495,                 loss: 0.3583
Episode: 25021/30000 (83.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8485s / 789.7120 s
agent0:                 episode reward: -0.8432,                 loss: nan
agent1:                 episode reward: 0.8432,                 loss: 0.3413
Episode: 25041/30000 (83.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8538s / 790.5658 s
agent0:                 episode reward: -0.7210,                 loss: nan
agent1:                 episode reward: 0.7210,                 loss: 0.3308
Episode: 25061/30000 (83.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8456s / 791.4114 s
agent0:                 episode reward: -0.5836,                 loss: nan
agent1:                 episode reward: 0.5836,                 loss: 0.3333
Episode: 25081/30000 (83.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8542s / 792.2656 s
agent0:                 episode reward: -0.3875,                 loss: nan
agent1:                 episode reward: 0.3875,                 loss: 0.3279
Episode: 25101/30000 (83.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8466s / 793.1122 s
agent0:                 episode reward: -0.6910,                 loss: nan
agent1:                 episode reward: 0.6910,                 loss: 0.3303
Episode: 25121/30000 (83.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8639s / 793.9761 s
agent0:                 episode reward: -0.6572,                 loss: nan
agent1:                 episode reward: 0.6572,                 loss: 0.3287
Episode: 25141/30000 (83.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8529s / 794.8290 s
agent0:                 episode reward: -0.5873,                 loss: nan
agent1:                 episode reward: 0.5873,                 loss: 0.3320
Episode: 25161/30000 (83.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8447s / 795.6738 s
agent0:                 episode reward: -0.4333,                 loss: nan
agent1:                 episode reward: 0.4333,                 loss: 0.3332
Episode: 25181/30000 (83.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8561s / 796.5299 s
agent0:                 episode reward: -0.6146,                 loss: nan
agent1:                 episode reward: 0.6146,                 loss: 0.3334
Episode: 25201/30000 (84.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8364s / 797.3663 s
agent0:                 episode reward: -0.7274,                 loss: nan
agent1:                 episode reward: 0.7274,                 loss: 0.3281
Episode: 25221/30000 (84.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8505s / 798.2168 s
agent0:                 episode reward: -0.1873,                 loss: nan
agent1:                 episode reward: 0.1873,                 loss: 0.3279
Episode: 25241/30000 (84.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8529s / 799.0697 s
agent0:                 episode reward: -0.8246,                 loss: nan
agent1:                 episode reward: 0.8246,                 loss: 0.3289
Episode: 25261/30000 (84.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8506s / 799.9203 s
agent0:                 episode reward: -0.5811,                 loss: nan
agent1:                 episode reward: 0.5811,                 loss: 0.3266
Episode: 25281/30000 (84.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9253s / 800.8456 s
agent0:                 episode reward: -0.4113,                 loss: nan
agent1:                 episode reward: 0.4113,                 loss: 0.3305
Episode: 25301/30000 (84.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8644s / 801.7100 s
agent0:                 episode reward: -0.7245,                 loss: nan
agent1:                 episode reward: 0.7245,                 loss: 0.3299
Episode: 25321/30000 (84.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8519s / 802.5619 s
agent0:                 episode reward: -0.4073,                 loss: nan
agent1:                 episode reward: 0.4073,                 loss: 0.3277
Episode: 25341/30000 (84.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8417s / 803.4036 s
agent0:                 episode reward: -0.7212,                 loss: nan
agent1:                 episode reward: 0.7212,                 loss: 0.3421
Episode: 25361/30000 (84.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8707s / 804.2743 s
agent0:                 episode reward: -0.5765,                 loss: nan
agent1:                 episode reward: 0.5765,                 loss: 0.3193
Episode: 25381/30000 (84.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9702s / 805.2445 s
agent0:                 episode reward: -0.4306,                 loss: nan
agent1:                 episode reward: 0.4306,                 loss: 0.3198
Episode: 25401/30000 (84.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8578s / 806.1023 s
agent0:                 episode reward: -0.8643,                 loss: nan
agent1:                 episode reward: 0.8643,                 loss: 0.3155
Episode: 25421/30000 (84.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8532s / 806.9554 s
agent0:                 episode reward: -0.5309,                 loss: nan
agent1:                 episode reward: 0.5309,                 loss: 0.3166
Episode: 25441/30000 (84.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8731s / 807.8285 s
agent0:                 episode reward: -0.7335,                 loss: nan
agent1:                 episode reward: 0.7335,                 loss: 0.3189
Episode: 25461/30000 (84.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9597s / 808.7882 s
agent0:                 episode reward: -0.5535,                 loss: nan
agent1:                 episode reward: 0.5535,                 loss: 0.3184
Episode: 25481/30000 (84.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8694s / 809.6576 s
agent0:                 episode reward: -0.5501,                 loss: nan
agent1:                 episode reward: 0.5501,                 loss: 0.3174
Episode: 25501/30000 (85.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8538s / 810.5114 s
agent0:                 episode reward: -0.5072,                 loss: nan
agent1:                 episode reward: 0.5072,                 loss: 0.3155
Episode: 25521/30000 (85.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8593s / 811.3707 s
agent0:                 episode reward: -0.5159,                 loss: nan
agent1:                 episode reward: 0.5159,                 loss: 0.3163
Episode: 25541/30000 (85.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8658s / 812.2365 s
agent0:                 episode reward: -0.2461,                 loss: nan
agent1:                 episode reward: 0.2461,                 loss: 0.3197
Episode: 25561/30000 (85.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9371s / 813.1736 s
agent0:                 episode reward: -0.9533,                 loss: nan
agent1:                 episode reward: 0.9533,                 loss: 0.3180
Episode: 25581/30000 (85.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8582s / 814.0318 s
agent0:                 episode reward: -0.7643,                 loss: nan
agent1:                 episode reward: 0.7643,                 loss: 0.3168
Episode: 25601/30000 (85.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8833s / 814.9151 s
agent0:                 episode reward: -0.2993,                 loss: nan
agent1:                 episode reward: 0.2993,                 loss: 0.3154
Episode: 25621/30000 (85.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8488s / 815.7639 s
agent0:                 episode reward: -0.8120,                 loss: nan
agent1:                 episode reward: 0.8120,                 loss: 0.3203
Episode: 25641/30000 (85.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8707s / 816.6346 s
agent0:                 episode reward: -0.3823,                 loss: nan
agent1:                 episode reward: 0.3823,                 loss: 0.3187
Episode: 25661/30000 (85.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8559s / 817.4905 s
agent0:                 episode reward: -0.5924,                 loss: nan
agent1:                 episode reward: 0.5924,                 loss: 0.3184
Episode: 25681/30000 (85.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8565s / 818.3470 s
agent0:                 episode reward: -0.5624,                 loss: nan
agent1:                 episode reward: 0.5624,                 loss: 0.3732
Episode: 25701/30000 (85.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8845s / 819.2315 s
agent0:                 episode reward: -0.6054,                 loss: nan
agent1:                 episode reward: 0.6054,                 loss: 0.3544
Episode: 25721/30000 (85.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8407s / 820.0722 s
agent0:                 episode reward: -0.5179,                 loss: nan
agent1:                 episode reward: 0.5179,                 loss: 0.3513
Episode: 25741/30000 (85.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8785s / 820.9507 s
agent0:                 episode reward: -0.6645,                 loss: nan
agent1:                 episode reward: 0.6645,                 loss: 0.3535
Episode: 25761/30000 (85.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8548s / 821.8055 s
agent0:                 episode reward: -0.4241,                 loss: nan
agent1:                 episode reward: 0.4241,                 loss: 0.3533
Episode: 25781/30000 (85.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8653s / 822.6708 s
agent0:                 episode reward: -0.3741,                 loss: nan
agent1:                 episode reward: 0.3741,                 loss: 0.3541
Episode: 25801/30000 (86.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8689s / 823.5397 s
agent0:                 episode reward: -0.6308,                 loss: nan
agent1:                 episode reward: 0.6308,                 loss: 0.3523
Episode: 25821/30000 (86.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8686s / 824.4083 s
agent0:                 episode reward: -0.7146,                 loss: nan
agent1:                 episode reward: 0.7146,                 loss: 0.3544
Episode: 25841/30000 (86.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8558s / 825.2642 s
agent0:                 episode reward: -0.7207,                 loss: nan
agent1:                 episode reward: 0.7207,                 loss: 0.3494
Episode: 25861/30000 (86.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8679s / 826.1321 s
agent0:                 episode reward: -0.5263,                 loss: nan
agent1:                 episode reward: 0.5263,                 loss: 0.3524
Episode: 25881/30000 (86.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8658s / 826.9979 s
agent0:                 episode reward: -0.6828,                 loss: nan
agent1:                 episode reward: 0.6828,                 loss: 0.3533
Episode: 25901/30000 (86.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8715s / 827.8695 s
agent0:                 episode reward: -0.3751,                 loss: nan
agent1:                 episode reward: 0.3751,                 loss: 0.3539
Episode: 25921/30000 (86.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 1.1450s / 829.0144 s
agent0:                 episode reward: -0.7851,                 loss: nan
agent1:                 episode reward: 0.7851,                 loss: 0.3553
Episode: 25941/30000 (86.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9455s / 829.9599 s
agent0:                 episode reward: -0.7262,                 loss: nan
agent1:                 episode reward: 0.7262,                 loss: 0.3539
Episode: 25961/30000 (86.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8764s / 830.8363 s
agent0:                 episode reward: -0.5497,                 loss: nan
agent1:                 episode reward: 0.5497,                 loss: 0.3526
Episode: 25981/30000 (86.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8556s / 831.6919 s
agent0:                 episode reward: -0.6759,                 loss: nan
agent1:                 episode reward: 0.6759,                 loss: 0.3526
Episode: 26001/30000 (86.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8645s / 832.5564 s
agent0:                 episode reward: -0.4744,                 loss: nan
agent1:                 episode reward: 0.4744,                 loss: 0.3568
Episode: 26021/30000 (86.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8694s / 833.4257 s
agent0:                 episode reward: -0.4079,                 loss: nan
agent1:                 episode reward: 0.4079,                 loss: 0.3349
Episode: 26041/30000 (86.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8658s / 834.2915 s
agent0:                 episode reward: -0.7973,                 loss: nan
agent1:                 episode reward: 0.7973,                 loss: 0.3165
Episode: 26061/30000 (86.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8696s / 835.1611 s
agent0:                 episode reward: -0.6191,                 loss: nan
agent1:                 episode reward: 0.6191,                 loss: 0.3136
Episode: 26081/30000 (86.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8734s / 836.0345 s
agent0:                 episode reward: -0.5058,                 loss: nan
agent1:                 episode reward: 0.5058,                 loss: 0.3166
Episode: 26101/30000 (87.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 1.0178s / 837.0523 s
agent0:                 episode reward: -0.8499,                 loss: nan
agent1:                 episode reward: 0.8499,                 loss: 0.3128
Episode: 26121/30000 (87.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 1.1047s / 838.1569 s
agent0:                 episode reward: -0.4778,                 loss: nan
agent1:                 episode reward: 0.4778,                 loss: 0.3143
Episode: 26141/30000 (87.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9360s / 839.0930 s
agent0:                 episode reward: -0.2751,                 loss: nan
agent1:                 episode reward: 0.2751,                 loss: 0.3129
Episode: 26161/30000 (87.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8681s / 839.9611 s
agent0:                 episode reward: -0.5308,                 loss: nan
agent1:                 episode reward: 0.5308,                 loss: 0.3148
Episode: 26181/30000 (87.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8808s / 840.8419 s
agent0:                 episode reward: -0.5305,                 loss: nan
agent1:                 episode reward: 0.5305,                 loss: 0.3119
Episode: 26201/30000 (87.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8641s / 841.7060 s
agent0:                 episode reward: -0.7849,                 loss: nan
agent1:                 episode reward: 0.7849,                 loss: 0.3167
Episode: 26221/30000 (87.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8793s / 842.5852 s
agent0:                 episode reward: -0.9687,                 loss: nan
agent1:                 episode reward: 0.9687,                 loss: 0.3134
Episode: 26241/30000 (87.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9826s / 843.5678 s
agent0:                 episode reward: -0.7523,                 loss: nan
agent1:                 episode reward: 0.7523,                 loss: 0.3169
Episode: 26261/30000 (87.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9889s / 844.5567 s
agent0:                 episode reward: -0.3348,                 loss: nan
agent1:                 episode reward: 0.3348,                 loss: 0.3129
Episode: 26281/30000 (87.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9021s / 845.4588 s
agent0:                 episode reward: -0.6953,                 loss: nan
agent1:                 episode reward: 0.6953,                 loss: 0.3137
Episode: 26301/30000 (87.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8748s / 846.3336 s
agent0:                 episode reward: -0.6384,                 loss: nan
agent1:                 episode reward: 0.6384,                 loss: 0.3139
Episode: 26321/30000 (87.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8585s / 847.1920 s
agent0:                 episode reward: -0.8742,                 loss: nan
agent1:                 episode reward: 0.8742,                 loss: 0.3175
Episode: 26341/30000 (87.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8819s / 848.0740 s
agent0:                 episode reward: -0.5386,                 loss: nan
agent1:                 episode reward: 0.5386,                 loss: 0.3326
Episode: 26361/30000 (87.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8785s / 848.9524 s
agent0:                 episode reward: -0.8162,                 loss: nan
agent1:                 episode reward: 0.8162,                 loss: 0.3344
Episode: 26381/30000 (87.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8745s / 849.8269 s
agent0:                 episode reward: -0.4350,                 loss: nan
agent1:                 episode reward: 0.4350,                 loss: 0.3309
Episode: 26401/30000 (88.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8992s / 850.7261 s
agent0:                 episode reward: -0.7603,                 loss: nan
agent1:                 episode reward: 0.7603,                 loss: 0.3344
Episode: 26421/30000 (88.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 1.2077s / 851.9338 s
agent0:                 episode reward: -0.9160,                 loss: nan
agent1:                 episode reward: 0.9160,                 loss: 0.3279
Episode: 26441/30000 (88.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 1.0422s / 852.9760 s
agent0:                 episode reward: -0.3431,                 loss: nan
agent1:                 episode reward: 0.3431,                 loss: 0.3290
Episode: 26461/30000 (88.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8795s / 853.8555 s
agent0:                 episode reward: -0.7862,                 loss: nan
agent1:                 episode reward: 0.7862,                 loss: 0.3271
Episode: 26481/30000 (88.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8962s / 854.7517 s
agent0:                 episode reward: -0.4591,                 loss: nan
agent1:                 episode reward: 0.4591,                 loss: 0.3279
Episode: 26501/30000 (88.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8888s / 855.6405 s
agent0:                 episode reward: -0.5214,                 loss: nan
agent1:                 episode reward: 0.5214,                 loss: 0.3282
Episode: 26521/30000 (88.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8705s / 856.5110 s
agent0:                 episode reward: -0.8182,                 loss: nan
agent1:                 episode reward: 0.8182,                 loss: 0.3261
Episode: 26541/30000 (88.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8781s / 857.3892 s
agent0:                 episode reward: -0.3901,                 loss: nan
agent1:                 episode reward: 0.3901,                 loss: 0.3310
Episode: 26561/30000 (88.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8815s / 858.2707 s
agent0:                 episode reward: -0.6659,                 loss: nan
agent1:                 episode reward: 0.6659,                 loss: 0.3254
Episode: 26581/30000 (88.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8933s / 859.1639 s
agent0:                 episode reward: -0.1795,                 loss: nan
agent1:                 episode reward: 0.1795,                 loss: 0.3303
Episode: 26601/30000 (88.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8838s / 860.0477 s
agent0:                 episode reward: -0.2580,                 loss: nan
agent1:                 episode reward: 0.2580,                 loss: 0.3288
Episode: 26621/30000 (88.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8907s / 860.9384 s
agent0:                 episode reward: -0.4780,                 loss: nan
agent1:                 episode reward: 0.4780,                 loss: 0.3308
Episode: 26641/30000 (88.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8792s / 861.8176 s
agent0:                 episode reward: -0.7828,                 loss: nan
agent1:                 episode reward: 0.7828,                 loss: 0.3285
Episode: 26661/30000 (88.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8950s / 862.7126 s
agent0:                 episode reward: -0.5351,                 loss: nan
agent1:                 episode reward: 0.5351,                 loss: 0.3266
Episode: 26681/30000 (88.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8920s / 863.6046 s
agent0:                 episode reward: -0.4355,                 loss: nan
agent1:                 episode reward: 0.4355,                 loss: 0.3702
Episode: 26701/30000 (89.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8745s / 864.4792 s
agent0:                 episode reward: -0.2709,                 loss: nan
agent1:                 episode reward: 0.2709,                 loss: 0.3393
Episode: 26721/30000 (89.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8765s / 865.3557 s
agent0:                 episode reward: -0.5056,                 loss: nan
agent1:                 episode reward: 0.5056,                 loss: 0.3351
Episode: 26741/30000 (89.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8829s / 866.2386 s
agent0:                 episode reward: -0.6146,                 loss: nan
agent1:                 episode reward: 0.6146,                 loss: 0.3344
Episode: 26761/30000 (89.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8768s / 867.1154 s
agent0:                 episode reward: -0.7350,                 loss: nan
agent1:                 episode reward: 0.7350,                 loss: 0.3384
Episode: 26781/30000 (89.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8750s / 867.9904 s
agent0:                 episode reward: -0.8937,                 loss: nan
agent1:                 episode reward: 0.8937,                 loss: 0.3341
Episode: 26801/30000 (89.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8930s / 868.8834 s
agent0:                 episode reward: -0.5421,                 loss: nan
agent1:                 episode reward: 0.5421,                 loss: 0.3368
Episode: 26821/30000 (89.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9034s / 869.7868 s
agent0:                 episode reward: -0.6495,                 loss: nan
agent1:                 episode reward: 0.6495,                 loss: 0.3324
Episode: 26841/30000 (89.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8972s / 870.6839 s
agent0:                 episode reward: -0.6894,                 loss: nan
agent1:                 episode reward: 0.6894,                 loss: 0.3374
Episode: 26861/30000 (89.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8840s / 871.5680 s
agent0:                 episode reward: -0.7319,                 loss: nan
agent1:                 episode reward: 0.7319,                 loss: 0.3374
Episode: 26881/30000 (89.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8972s / 872.4651 s
agent0:                 episode reward: -0.7578,                 loss: nan
agent1:                 episode reward: 0.7578,                 loss: 0.3357
Episode: 26901/30000 (89.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9083s / 873.3735 s
agent0:                 episode reward: -0.6698,                 loss: nan
agent1:                 episode reward: 0.6698,                 loss: 0.3342
Episode: 26921/30000 (89.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8808s / 874.2542 s
agent0:                 episode reward: -0.5280,                 loss: nan
agent1:                 episode reward: 0.5280,                 loss: 0.3392
Episode: 26941/30000 (89.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8916s / 875.1459 s
agent0:                 episode reward: -0.8132,                 loss: nan
agent1:                 episode reward: 0.8132,                 loss: 0.3355
Episode: 26961/30000 (89.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8979s / 876.0437 s
agent0:                 episode reward: -0.4668,                 loss: nan
agent1:                 episode reward: 0.4668,                 loss: 0.3377
Episode: 26981/30000 (89.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8771s / 876.9208 s
agent0:                 episode reward: -0.4030,                 loss: nan
agent1:                 episode reward: 0.4030,                 loss: 0.3387
Episode: 27001/30000 (90.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8941s / 877.8149 s
agent0:                 episode reward: -0.5564,                 loss: nan
agent1:                 episode reward: 0.5564,                 loss: 0.3436
Episode: 27021/30000 (90.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8793s / 878.6942 s
agent0:                 episode reward: -0.6258,                 loss: nan
agent1:                 episode reward: 0.6258,                 loss: 0.3244
Episode: 27041/30000 (90.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8889s / 879.5831 s
agent0:                 episode reward: -0.7580,                 loss: nan
agent1:                 episode reward: 0.7580,                 loss: 0.2990
Episode: 27061/30000 (90.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9016s / 880.4847 s
agent0:                 episode reward: -0.3429,                 loss: nan
agent1:                 episode reward: 0.3429,                 loss: 0.2973
Episode: 27081/30000 (90.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8767s / 881.3613 s
agent0:                 episode reward: -0.7759,                 loss: nan
agent1:                 episode reward: 0.7759,                 loss: 0.2962
Episode: 27101/30000 (90.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8926s / 882.2540 s
agent0:                 episode reward: -0.7162,                 loss: nan
agent1:                 episode reward: 0.7162,                 loss: 0.2984
Episode: 27121/30000 (90.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8817s / 883.1356 s
agent0:                 episode reward: -0.6963,                 loss: nan
agent1:                 episode reward: 0.6963,                 loss: 0.3007
Episode: 27141/30000 (90.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8976s / 884.0332 s
agent0:                 episode reward: -0.3404,                 loss: nan
agent1:                 episode reward: 0.3404,                 loss: 0.2997
Episode: 27161/30000 (90.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8985s / 884.9317 s
agent0:                 episode reward: -0.7022,                 loss: nan
agent1:                 episode reward: 0.7022,                 loss: 0.2966
Episode: 27181/30000 (90.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8958s / 885.8275 s
agent0:                 episode reward: -0.5992,                 loss: nan
agent1:                 episode reward: 0.5992,                 loss: 0.2999
Episode: 27201/30000 (90.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8958s / 886.7234 s
agent0:                 episode reward: -0.6068,                 loss: nan
agent1:                 episode reward: 0.6068,                 loss: 0.2948
Episode: 27221/30000 (90.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8926s / 887.6160 s
agent0:                 episode reward: -0.7187,                 loss: nan
agent1:                 episode reward: 0.7187,                 loss: 0.2980
Episode: 27241/30000 (90.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9042s / 888.5202 s
agent0:                 episode reward: -0.6848,                 loss: nan
agent1:                 episode reward: 0.6848,                 loss: 0.2990
Episode: 27261/30000 (90.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9013s / 889.4215 s
agent0:                 episode reward: -0.5580,                 loss: nan
agent1:                 episode reward: 0.5580,                 loss: 0.2962
Episode: 27281/30000 (90.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9017s / 890.3232 s
agent0:                 episode reward: -0.4890,                 loss: nan
agent1:                 episode reward: 0.4890,                 loss: 0.3003
Episode: 27301/30000 (91.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9223s / 891.2455 s
agent0:                 episode reward: -0.4526,                 loss: nan
agent1:                 episode reward: 0.4526,                 loss: 0.2995
Episode: 27321/30000 (91.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8943s / 892.1398 s
agent0:                 episode reward: -0.2154,                 loss: nan
agent1:                 episode reward: 0.2154,                 loss: 0.2984
Episode: 27341/30000 (91.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9160s / 893.0558 s
agent0:                 episode reward: -0.8258,                 loss: nan
agent1:                 episode reward: 0.8258,                 loss: 0.3230
Episode: 27361/30000 (91.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8985s / 893.9543 s
agent0:                 episode reward: -0.4718,                 loss: nan
agent1:                 episode reward: 0.4718,                 loss: 0.3391
Episode: 27381/30000 (91.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9109s / 894.8652 s
agent0:                 episode reward: -0.7033,                 loss: nan
agent1:                 episode reward: 0.7033,                 loss: 0.3401
Episode: 27401/30000 (91.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9182s / 895.7833 s
agent0:                 episode reward: -0.3716,                 loss: nan
agent1:                 episode reward: 0.3716,                 loss: 0.3369
Episode: 27421/30000 (91.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8909s / 896.6743 s
agent0:                 episode reward: -0.3567,                 loss: nan
agent1:                 episode reward: 0.3567,                 loss: 0.3378
Episode: 27441/30000 (91.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8928s / 897.5670 s
agent0:                 episode reward: -0.2099,                 loss: nan
agent1:                 episode reward: 0.2099,                 loss: 0.3364
Episode: 27461/30000 (91.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8967s / 898.4638 s
agent0:                 episode reward: -0.5705,                 loss: nan
agent1:                 episode reward: 0.5705,                 loss: 0.3370
Episode: 27481/30000 (91.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9136s / 899.3773 s
agent0:                 episode reward: -0.4010,                 loss: nan
agent1:                 episode reward: 0.4010,                 loss: 0.3359
Episode: 27501/30000 (91.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8973s / 900.2746 s
agent0:                 episode reward: -0.8202,                 loss: nan
agent1:                 episode reward: 0.8202,                 loss: 0.3398
Episode: 27521/30000 (91.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9050s / 901.1796 s
agent0:                 episode reward: -0.5180,                 loss: nan
agent1:                 episode reward: 0.5180,                 loss: 0.3396
Episode: 27541/30000 (91.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9018s / 902.0814 s
agent0:                 episode reward: -0.5837,                 loss: nan
agent1:                 episode reward: 0.5837,                 loss: 0.3382
Episode: 27561/30000 (91.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9121s / 902.9935 s
agent0:                 episode reward: -0.5860,                 loss: nan
agent1:                 episode reward: 0.5860,                 loss: 0.3395
Episode: 27581/30000 (91.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8999s / 903.8934 s
agent0:                 episode reward: -0.3419,                 loss: nan
agent1:                 episode reward: 0.3419,                 loss: 0.3352
Episode: 27601/30000 (92.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9138s / 904.8072 s
agent0:                 episode reward: -1.0172,                 loss: nan
agent1:                 episode reward: 1.0172,                 loss: 0.3428
Episode: 27621/30000 (92.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9080s / 905.7152 s
agent0:                 episode reward: -0.4003,                 loss: nan
agent1:                 episode reward: 0.4003,                 loss: 0.3338
Episode: 27641/30000 (92.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8931s / 906.6083 s
agent0:                 episode reward: -0.4031,                 loss: nan
agent1:                 episode reward: 0.4031,                 loss: 0.3397
Episode: 27661/30000 (92.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9028s / 907.5111 s
agent0:                 episode reward: -0.1323,                 loss: nan
agent1:                 episode reward: 0.1323,                 loss: 0.3369
Episode: 27681/30000 (92.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9011s / 908.4122 s
agent0:                 episode reward: -0.4058,                 loss: nan
agent1:                 episode reward: 0.4058,                 loss: 0.3718
Episode: 27701/30000 (92.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9028s / 909.3150 s
agent0:                 episode reward: -0.5257,                 loss: nan
agent1:                 episode reward: 0.5257,                 loss: 0.3346
Episode: 27721/30000 (92.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8982s / 910.2132 s
agent0:                 episode reward: -0.4647,                 loss: nan
agent1:                 episode reward: 0.4647,                 loss: 0.3348
Episode: 27741/30000 (92.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9108s / 911.1241 s
agent0:                 episode reward: -0.5297,                 loss: nan
agent1:                 episode reward: 0.5297,                 loss: 0.3372
Episode: 27761/30000 (92.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9013s / 912.0253 s
agent0:                 episode reward: -0.3447,                 loss: nan
agent1:                 episode reward: 0.3447,                 loss: 0.3325
Episode: 27781/30000 (92.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9016s / 912.9269 s
agent0:                 episode reward: -0.4567,                 loss: nan
agent1:                 episode reward: 0.4567,                 loss: 0.3361
Episode: 27801/30000 (92.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9093s / 913.8362 s
agent0:                 episode reward: -0.5308,                 loss: nan
agent1:                 episode reward: 0.5308,                 loss: 0.3353
Episode: 27821/30000 (92.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9163s / 914.7525 s
agent0:                 episode reward: -0.8617,                 loss: nan
agent1:                 episode reward: 0.8617,                 loss: 0.3335
Episode: 27841/30000 (92.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9037s / 915.6562 s
agent0:                 episode reward: -0.7104,                 loss: nan
agent1:                 episode reward: 0.7104,                 loss: 0.3352
Episode: 27861/30000 (92.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9042s / 916.5604 s
agent0:                 episode reward: -0.5198,                 loss: nan
agent1:                 episode reward: 0.5198,                 loss: 0.3362
Episode: 27881/30000 (92.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9100s / 917.4704 s
agent0:                 episode reward: -0.9433,                 loss: nan
agent1:                 episode reward: 0.9433,                 loss: 0.3352
Episode: 27901/30000 (93.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9164s / 918.3869 s
agent0:                 episode reward: -0.6521,                 loss: nan
agent1:                 episode reward: 0.6521,                 loss: 0.3366
Episode: 27921/30000 (93.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8905s / 919.2774 s
agent0:                 episode reward: -0.4400,                 loss: nan
agent1:                 episode reward: 0.4400,                 loss: 0.3361
Episode: 27941/30000 (93.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9130s / 920.1904 s
agent0:                 episode reward: -0.6633,                 loss: nan
agent1:                 episode reward: 0.6633,                 loss: 0.3340
Episode: 27961/30000 (93.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9108s / 921.1012 s
agent0:                 episode reward: -0.5087,                 loss: nan
agent1:                 episode reward: 0.5087,                 loss: 0.3360
Episode: 27981/30000 (93.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9015s / 922.0027 s
agent0:                 episode reward: -0.9187,                 loss: nan
agent1:                 episode reward: 0.9187,                 loss: 0.3370
Episode: 28001/30000 (93.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9039s / 922.9066 s
agent0:                 episode reward: -0.5079,                 loss: nan
agent1:                 episode reward: 0.5079,                 loss: 0.3410
Episode: 28021/30000 (93.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8988s / 923.8054 s
agent0:                 episode reward: -0.3780,                 loss: nan
agent1:                 episode reward: 0.3780,                 loss: 0.3172
Episode: 28041/30000 (93.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8974s / 924.7029 s
agent0:                 episode reward: -0.4461,                 loss: nan
agent1:                 episode reward: 0.4461,                 loss: 0.2994
Episode: 28061/30000 (93.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8994s / 925.6022 s
agent0:                 episode reward: -0.5187,                 loss: nan
agent1:                 episode reward: 0.5187,                 loss: 0.2929
Episode: 28081/30000 (93.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9094s / 926.5116 s
agent0:                 episode reward: -0.4551,                 loss: nan
agent1:                 episode reward: 0.4551,                 loss: 0.2974
Episode: 28101/30000 (93.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9151s / 927.4267 s
agent0:                 episode reward: -0.9975,                 loss: nan
agent1:                 episode reward: 0.9975,                 loss: 0.2995
Episode: 28121/30000 (93.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9185s / 928.3452 s
agent0:                 episode reward: -0.3101,                 loss: nan
agent1:                 episode reward: 0.3101,                 loss: 0.2997
Episode: 28141/30000 (93.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9051s / 929.2503 s
agent0:                 episode reward: -0.5846,                 loss: nan
agent1:                 episode reward: 0.5846,                 loss: 0.2950
Episode: 28161/30000 (93.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9175s / 930.1678 s
agent0:                 episode reward: -0.5870,                 loss: nan
agent1:                 episode reward: 0.5870,                 loss: 0.2954
Episode: 28181/30000 (93.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9178s / 931.0856 s
agent0:                 episode reward: -0.3249,                 loss: nan
agent1:                 episode reward: 0.3249,                 loss: 0.2983
Episode: 28201/30000 (94.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9135s / 931.9991 s
agent0:                 episode reward: -0.6819,                 loss: nan
agent1:                 episode reward: 0.6819,                 loss: 0.2985
Episode: 28221/30000 (94.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9125s / 932.9116 s
agent0:                 episode reward: -0.4318,                 loss: nan
agent1:                 episode reward: 0.4318,                 loss: 0.3000
Episode: 28241/30000 (94.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9095s / 933.8212 s
agent0:                 episode reward: -0.4459,                 loss: nan
agent1:                 episode reward: 0.4459,                 loss: 0.2933
Episode: 28261/30000 (94.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9336s / 934.7548 s
agent0:                 episode reward: -0.4187,                 loss: nan
agent1:                 episode reward: 0.4187,                 loss: 0.2966
Episode: 28281/30000 (94.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9165s / 935.6713 s
agent0:                 episode reward: -0.6066,                 loss: nan
agent1:                 episode reward: 0.6066,                 loss: 0.2940
Episode: 28301/30000 (94.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9172s / 936.5885 s
agent0:                 episode reward: -0.6557,                 loss: nan
agent1:                 episode reward: 0.6557,                 loss: 0.2996
Episode: 28321/30000 (94.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9222s / 937.5107 s
agent0:                 episode reward: -0.2520,                 loss: nan
agent1:                 episode reward: 0.2520,                 loss: 0.2986
Episode: 28341/30000 (94.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9183s / 938.4290 s
agent0:                 episode reward: -0.5279,                 loss: nan
agent1:                 episode reward: 0.5279,                 loss: 0.3267
Episode: 28361/30000 (94.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9171s / 939.3460 s
agent0:                 episode reward: -0.3062,                 loss: nan
agent1:                 episode reward: 0.3062,                 loss: 0.3603
Episode: 28381/30000 (94.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9117s / 940.2577 s
agent0:                 episode reward: -0.5054,                 loss: nan
agent1:                 episode reward: 0.5054,                 loss: 0.3596
Episode: 28401/30000 (94.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9208s / 941.1785 s
agent0:                 episode reward: -0.8141,                 loss: nan
agent1:                 episode reward: 0.8141,                 loss: 0.3574
Episode: 28421/30000 (94.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9128s / 942.0913 s
agent0:                 episode reward: -0.4698,                 loss: nan
agent1:                 episode reward: 0.4698,                 loss: 0.3588
Episode: 28441/30000 (94.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9175s / 943.0088 s
agent0:                 episode reward: -0.6257,                 loss: nan
agent1:                 episode reward: 0.6257,                 loss: 0.3583
Episode: 28461/30000 (94.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9080s / 943.9168 s
agent0:                 episode reward: -0.5868,                 loss: nan
agent1:                 episode reward: 0.5868,                 loss: 0.3604
Episode: 28481/30000 (94.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9078s / 944.8246 s
agent0:                 episode reward: -0.5169,                 loss: nan
agent1:                 episode reward: 0.5169,                 loss: 0.3586
Episode: 28501/30000 (95.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9079s / 945.7326 s
agent0:                 episode reward: -0.3102,                 loss: nan
agent1:                 episode reward: 0.3102,                 loss: 0.3602
Episode: 28521/30000 (95.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9108s / 946.6434 s
agent0:                 episode reward: -0.6255,                 loss: nan
agent1:                 episode reward: 0.6255,                 loss: 0.3619
Episode: 28541/30000 (95.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9054s / 947.5488 s
agent0:                 episode reward: -0.5984,                 loss: nan
agent1:                 episode reward: 0.5984,                 loss: 0.3614
Episode: 28561/30000 (95.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9266s / 948.4754 s
agent0:                 episode reward: -0.6635,                 loss: nan
agent1:                 episode reward: 0.6635,                 loss: 0.3569
Episode: 28581/30000 (95.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9106s / 949.3860 s
agent0:                 episode reward: -0.7122,                 loss: nan
agent1:                 episode reward: 0.7122,                 loss: 0.3581
Episode: 28601/30000 (95.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9217s / 950.3077 s
agent0:                 episode reward: -0.8783,                 loss: nan
agent1:                 episode reward: 0.8783,                 loss: 0.3579
Episode: 28621/30000 (95.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9261s / 951.2338 s
agent0:                 episode reward: -0.5373,                 loss: nan
agent1:                 episode reward: 0.5373,                 loss: 0.3602
Episode: 28641/30000 (95.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9217s / 952.1555 s
agent0:                 episode reward: -0.7312,                 loss: nan
agent1:                 episode reward: 0.7312,                 loss: 0.3615
Episode: 28661/30000 (95.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9210s / 953.0765 s
agent0:                 episode reward: -0.8661,                 loss: nan
agent1:                 episode reward: 0.8661,                 loss: 0.3605
Episode: 28681/30000 (95.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9140s / 953.9905 s
agent0:                 episode reward: -0.6665,                 loss: nan
agent1:                 episode reward: 0.6665,                 loss: 0.3670
Episode: 28701/30000 (95.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9242s / 954.9147 s
agent0:                 episode reward: -0.6151,                 loss: nan
agent1:                 episode reward: 0.6151,                 loss: 0.3344
Episode: 28721/30000 (95.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9311s / 955.8458 s
agent0:                 episode reward: -0.7240,                 loss: nan
agent1:                 episode reward: 0.7240,                 loss: 0.3360
Episode: 28741/30000 (95.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9215s / 956.7673 s
agent0:                 episode reward: -0.5095,                 loss: nan
agent1:                 episode reward: 0.5095,                 loss: 0.3359
Episode: 28761/30000 (95.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9268s / 957.6940 s
agent0:                 episode reward: -0.7743,                 loss: nan
agent1:                 episode reward: 0.7743,                 loss: 0.3335
Episode: 28781/30000 (95.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9514s / 958.6454 s
agent0:                 episode reward: -0.7414,                 loss: nan
agent1:                 episode reward: 0.7414,                 loss: 0.3355
Episode: 28801/30000 (96.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9400s / 959.5854 s
agent0:                 episode reward: -0.5056,                 loss: nan
agent1:                 episode reward: 0.5056,                 loss: 0.3330
Episode: 28821/30000 (96.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9422s / 960.5276 s
agent0:                 episode reward: -0.4940,                 loss: nan
agent1:                 episode reward: 0.4940,                 loss: 0.3361
Episode: 28841/30000 (96.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9276s / 961.4552 s
agent0:                 episode reward: -0.5073,                 loss: nan
agent1:                 episode reward: 0.5073,                 loss: 0.3356
Episode: 28861/30000 (96.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9271s / 962.3823 s
agent0:                 episode reward: -0.6413,                 loss: nan
agent1:                 episode reward: 0.6413,                 loss: 0.3330
Episode: 28881/30000 (96.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9427s / 963.3250 s
agent0:                 episode reward: -0.5826,                 loss: nan
agent1:                 episode reward: 0.5826,                 loss: 0.3366
Episode: 28901/30000 (96.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9353s / 964.2602 s
agent0:                 episode reward: -0.5373,                 loss: nan
agent1:                 episode reward: 0.5373,                 loss: 0.3365
Episode: 28921/30000 (96.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9197s / 965.1799 s
agent0:                 episode reward: -0.4958,                 loss: nan
agent1:                 episode reward: 0.4958,                 loss: 0.3367
Episode: 28941/30000 (96.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9300s / 966.1099 s
agent0:                 episode reward: -0.3849,                 loss: nan
agent1:                 episode reward: 0.3849,                 loss: 0.3353
Episode: 28961/30000 (96.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9208s / 967.0307 s
agent0:                 episode reward: -0.5893,                 loss: nan
agent1:                 episode reward: 0.5893,                 loss: 0.3367
Episode: 28981/30000 (96.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9220s / 967.9527 s
agent0:                 episode reward: -0.6372,                 loss: nan
agent1:                 episode reward: 0.6372,                 loss: 0.3338
Episode: 29001/30000 (96.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9306s / 968.8833 s
agent0:                 episode reward: -1.0438,                 loss: nan
agent1:                 episode reward: 1.0438,                 loss: 0.3421
Episode: 29021/30000 (96.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9225s / 969.8058 s
agent0:                 episode reward: -0.7539,                 loss: nan
agent1:                 episode reward: 0.7539,                 loss: 0.3101
Episode: 29041/30000 (96.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9291s / 970.7348 s
agent0:                 episode reward: -0.4902,                 loss: nan
agent1:                 episode reward: 0.4902,                 loss: 0.2857
Episode: 29061/30000 (96.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9281s / 971.6629 s
agent0:                 episode reward: -0.6201,                 loss: nan
agent1:                 episode reward: 0.6201,                 loss: 0.2847
Episode: 29081/30000 (96.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9349s / 972.5978 s
agent0:                 episode reward: -0.3896,                 loss: nan
agent1:                 episode reward: 0.3896,                 loss: 0.2816
Episode: 29101/30000 (97.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9223s / 973.5201 s
agent0:                 episode reward: -0.5527,                 loss: nan
agent1:                 episode reward: 0.5527,                 loss: 0.2871
Episode: 29121/30000 (97.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9317s / 974.4519 s
agent0:                 episode reward: -0.7791,                 loss: nan
agent1:                 episode reward: 0.7791,                 loss: 0.2830
Episode: 29141/30000 (97.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9501s / 975.4020 s
agent0:                 episode reward: -0.5065,                 loss: nan
agent1:                 episode reward: 0.5065,                 loss: 0.2843
Episode: 29161/30000 (97.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9332s / 976.3352 s
agent0:                 episode reward: -0.9541,                 loss: nan
agent1:                 episode reward: 0.9541,                 loss: 0.2850
Episode: 29181/30000 (97.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9247s / 977.2599 s
agent0:                 episode reward: -0.6771,                 loss: nan
agent1:                 episode reward: 0.6771,                 loss: 0.2871
Episode: 29201/30000 (97.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9295s / 978.1894 s
agent0:                 episode reward: -0.6267,                 loss: nan
agent1:                 episode reward: 0.6267,                 loss: 0.2864
Episode: 29221/30000 (97.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9268s / 979.1162 s
agent0:                 episode reward: -0.7962,                 loss: nan
agent1:                 episode reward: 0.7962,                 loss: 0.2855
Episode: 29241/30000 (97.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9279s / 980.0441 s
agent0:                 episode reward: -0.6243,                 loss: nan
agent1:                 episode reward: 0.6243,                 loss: 0.2824
Episode: 29261/30000 (97.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 1.0606s / 981.1048 s
agent0:                 episode reward: -0.4039,                 loss: nan
agent1:                 episode reward: 0.4039,                 loss: 0.2843
Episode: 29281/30000 (97.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 1.1945s / 982.2993 s
agent0:                 episode reward: -0.2710,                 loss: nan
agent1:                 episode reward: 0.2710,                 loss: 0.2809
Episode: 29301/30000 (97.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 1.0545s / 983.3537 s
agent0:                 episode reward: -0.4708,                 loss: nan
agent1:                 episode reward: 0.4708,                 loss: 0.2846
Episode: 29321/30000 (97.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9587s / 984.3124 s
agent0:                 episode reward: -0.4184,                 loss: nan
agent1:                 episode reward: 0.4184,                 loss: 0.2856
Episode: 29341/30000 (97.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9331s / 985.2455 s
agent0:                 episode reward: -0.9715,                 loss: nan
agent1:                 episode reward: 0.9715,                 loss: 0.3284
Episode: 29361/30000 (97.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9208s / 986.1663 s
agent0:                 episode reward: -0.5049,                 loss: nan
agent1:                 episode reward: 0.5049,                 loss: 0.3745
Episode: 29381/30000 (97.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9448s / 987.1111 s
agent0:                 episode reward: -0.5640,                 loss: nan
agent1:                 episode reward: 0.5640,                 loss: 0.3698
Episode: 29401/30000 (98.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9442s / 988.0553 s
agent0:                 episode reward: -0.4222,                 loss: nan
agent1:                 episode reward: 0.4222,                 loss: 0.3716
Episode: 29421/30000 (98.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9286s / 988.9838 s
agent0:                 episode reward: -0.5539,                 loss: nan
agent1:                 episode reward: 0.5539,                 loss: 0.3703
Episode: 29441/30000 (98.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9230s / 989.9069 s
agent0:                 episode reward: -0.6675,                 loss: nan
agent1:                 episode reward: 0.6675,                 loss: 0.3697
Episode: 29461/30000 (98.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9369s / 990.8437 s
agent0:                 episode reward: -0.8284,                 loss: nan
agent1:                 episode reward: 0.8284,                 loss: 0.3707
Episode: 29481/30000 (98.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9282s / 991.7720 s
agent0:                 episode reward: -0.5320,                 loss: nan
agent1:                 episode reward: 0.5320,                 loss: 0.3693
Episode: 29501/30000 (98.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9409s / 992.7128 s
agent0:                 episode reward: -0.6858,                 loss: nan
agent1:                 episode reward: 0.6858,                 loss: 0.3715
Episode: 29521/30000 (98.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9331s / 993.6459 s
agent0:                 episode reward: -0.3807,                 loss: nan
agent1:                 episode reward: 0.3807,                 loss: 0.3706
Episode: 29541/30000 (98.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9430s / 994.5890 s
agent0:                 episode reward: -0.6011,                 loss: nan
agent1:                 episode reward: 0.6011,                 loss: 0.3709
Episode: 29561/30000 (98.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9290s / 995.5180 s
agent0:                 episode reward: -0.5348,                 loss: nan
agent1:                 episode reward: 0.5348,                 loss: 0.3726
Episode: 29581/30000 (98.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9234s / 996.4413 s
agent0:                 episode reward: -0.4273,                 loss: nan
agent1:                 episode reward: 0.4273,                 loss: 0.3714
Episode: 29601/30000 (98.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9103s / 997.3516 s
agent0:                 episode reward: -0.5227,                 loss: nan
agent1:                 episode reward: 0.5227,                 loss: 0.3701
Episode: 29621/30000 (98.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8928s / 998.2444 s
agent0:                 episode reward: -0.7297,                 loss: nan
agent1:                 episode reward: 0.7297,                 loss: 0.3711/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

Episode: 29641/30000 (98.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8847s / 999.1291 s
agent0:                 episode reward: -0.5287,                 loss: nan
agent1:                 episode reward: 0.5287,                 loss: 0.3733
Episode: 29661/30000 (98.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8737s / 1000.0028 s
agent0:                 episode reward: -0.4340,                 loss: nan
agent1:                 episode reward: 0.4340,                 loss: 0.3707
Episode: 29681/30000 (98.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8688s / 1000.8717 s
agent0:                 episode reward: -0.4409,                 loss: nan
agent1:                 episode reward: 0.4409,                 loss: 0.3646
Episode: 29701/30000 (99.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8592s / 1001.7309 s
agent0:                 episode reward: -0.4827,                 loss: nan
agent1:                 episode reward: 0.4827,                 loss: 0.3427
Episode: 29721/30000 (99.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8612s / 1002.5920 s
agent0:                 episode reward: -0.5903,                 loss: nan
agent1:                 episode reward: 0.5903,                 loss: 0.3409
Episode: 29741/30000 (99.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9318s / 1003.5238 s
agent0:                 episode reward: -0.7997,                 loss: nan
agent1:                 episode reward: 0.7997,                 loss: 0.3412
Episode: 29761/30000 (99.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9825s / 1004.5063 s
agent0:                 episode reward: -0.4596,                 loss: nan
agent1:                 episode reward: 0.4596,                 loss: 0.3425
Episode: 29781/30000 (99.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9520s / 1005.4583 s
agent0:                 episode reward: -0.7470,                 loss: nan
agent1:                 episode reward: 0.7470,                 loss: 0.3437
Episode: 29801/30000 (99.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9318s / 1006.3901 s
agent0:                 episode reward: -0.5234,                 loss: nan
agent1:                 episode reward: 0.5234,                 loss: 0.3414
Episode: 29821/30000 (99.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9584s / 1007.3485 s
agent0:                 episode reward: -0.5448,                 loss: nan
agent1:                 episode reward: 0.5448,                 loss: 0.3408
Episode: 29841/30000 (99.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9202s / 1008.2687 s
agent0:                 episode reward: -0.6924,                 loss: nan
agent1:                 episode reward: 0.6924,                 loss: 0.3441
Episode: 29861/30000 (99.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9237s / 1009.1924 s
agent0:                 episode reward: -0.5124,                 loss: nan
agent1:                 episode reward: 0.5124,                 loss: 0.3425
Episode: 29881/30000 (99.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9215s / 1010.1139 s
agent0:                 episode reward: -0.5815,                 loss: nan
agent1:                 episode reward: 0.5815,                 loss: 0.3419
Episode: 29901/30000 (99.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9556s / 1011.0695 s
agent0:                 episode reward: -0.2676,                 loss: nan
agent1:                 episode reward: 0.2676,                 loss: 0.3425
Episode: 29921/30000 (99.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9412s / 1012.0107 s
agent0:                 episode reward: -0.6607,                 loss: nan
agent1:                 episode reward: 0.6607,                 loss: 0.3413
Episode: 29941/30000 (99.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9216s / 1012.9323 s
agent0:                 episode reward: -0.8489,                 loss: nan
agent1:                 episode reward: 0.8489,                 loss: 0.3426
Episode: 29961/30000 (99.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9088s / 1013.8411 s
agent0:                 episode reward: -0.9820,                 loss: nan
agent1:                 episode reward: 0.9820,                 loss: 0.3421
Episode: 29981/30000 (99.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9236s / 1014.7647 s
agent0:                 episode reward: -0.8237,                 loss: nan
agent1:                 episode reward: 0.8237,                 loss: 0.3422
