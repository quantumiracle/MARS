2022-05-11 12:44:18.218954: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia:/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia
2022-05-11 12:44:18.219025: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia:/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia
2022-05-11 12:44:18.219030: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
pygame 2.0.1 (SDL 2.0.14, Python 3.6.13)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 12.0, (1,), float32) action space: Discrete(3)
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7fd8536966d8>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=32, bias=True)
      (3): ReLU()
      (4): Linear(in_features=32, out_features=32, bias=True)
      (5): ReLU()
      (6): Linear(in_features=32, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=32, bias=True)
      (3): ReLU()
      (4): Linear(in_features=32, out_features=32, bias=True)
      (5): ReLU()
      (6): Linear(in_features=32, out_features=3, bias=True)
    )
  )
)
Error: no exploited model index given!
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  data/model/20220511124050/mdp_arbitrary_mdp_selfplay2/2000_0
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': 1, 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 1.0, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 8000}, 'num_process': 1, 'batch_size': 640, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220511124050/mdp_arbitrary_mdp_selfplay2/2000_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 1000, 'net_architecture': {'hidden_dim_list': [32, 32, 32], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'selfplay2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'selfplay_score_delta': 1.5, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'against_baseline': False}
Save models to : /home/quantumiracle/research/MARS/data/model/20220511124050_exploit_2000/mdp_arbitrary_mdp_selfplay2. 
 Save logs to: /home/quantumiracle/research/MARS/data/log/20220511124050_exploit_2000/mdp_arbitrary_mdp_selfplay2.
Episode: 1/10000 (0.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7639s / 0.7639 s
agent0:                 episode reward: 1.1190,                 loss: nan
agent1:                 episode reward: -1.1190,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0227s / 0.7866 s
agent0:                 episode reward: 0.0958,                 loss: nan
agent1:                 episode reward: -0.0958,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0215s / 0.8081 s
agent0:                 episode reward: -0.3557,                 loss: nan
agent1:                 episode reward: 0.3557,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0221s / 0.8302 s
agent0:                 episode reward: 0.3041,                 loss: nan
agent1:                 episode reward: -0.3041,                 loss: nan
Episode: 81/10000 (0.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0218s / 0.8520 s
agent0:                 episode reward: 0.1648,                 loss: nan
agent1:                 episode reward: -0.1648,                 loss: nan
Episode: 101/10000 (1.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0219s / 0.8738 s
agent0:                 episode reward: 0.2057,                 loss: nan
agent1:                 episode reward: -0.2057,                 loss: nan
Episode: 121/10000 (1.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0291s / 0.9030 s
agent0:                 episode reward: 0.2452,                 loss: nan
agent1:                 episode reward: -0.2452,                 loss: nan
Episode: 141/10000 (1.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0229s / 0.9259 s
agent0:                 episode reward: -0.2050,                 loss: nan
agent1:                 episode reward: 0.2050,                 loss: nan
Episode: 161/10000 (1.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0227s / 0.9486 s
agent0:                 episode reward: 0.1232,                 loss: nan
agent1:                 episode reward: -0.1232,                 loss: nan
Episode: 181/10000 (1.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0230s / 0.9716 s
agent0:                 episode reward: 0.0129,                 loss: nan
agent1:                 episode reward: -0.0129,                 loss: nan
Episode: 201/10000 (2.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0229s / 0.9945 s
agent0:                 episode reward: 0.4220,                 loss: nan
agent1:                 episode reward: -0.4220,                 loss: nan
Episode: 221/10000 (2.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0906s / 1.0851 s
agent0:                 episode reward: -0.1669,                 loss: nan
agent1:                 episode reward: 0.1669,                 loss: 0.4582
Episode: 241/10000 (2.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1968s / 1.2819 s
agent0:                 episode reward: 0.2528,                 loss: nan
agent1:                 episode reward: -0.2528,                 loss: 0.4456
Episode: 261/10000 (2.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1968s / 1.4786 s
agent0:                 episode reward: -0.1485,                 loss: nan
agent1:                 episode reward: 0.1485,                 loss: 0.4380
Episode: 281/10000 (2.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2000s / 1.6787 s
agent0:                 episode reward: 0.2325,                 loss: nan
agent1:                 episode reward: -0.2325,                 loss: 0.4330
Episode: 301/10000 (3.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1993s / 1.8780 s
agent0:                 episode reward: -0.0488,                 loss: nan
agent1:                 episode reward: 0.0488,                 loss: 0.4290
Episode: 321/10000 (3.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2161s / 2.0941 s
agent0:                 episode reward: 0.0232,                 loss: nan
agent1:                 episode reward: -0.0232,                 loss: 0.4237
Episode: 341/10000 (3.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2090s / 2.3031 s
agent0:                 episode reward: -0.2680,                 loss: nan
agent1:                 episode reward: 0.2680,                 loss: 0.4186
Episode: 361/10000 (3.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1999s / 2.5031 s
agent0:                 episode reward: -0.1257,                 loss: nan
agent1:                 episode reward: 0.1257,                 loss: 0.4148
Episode: 381/10000 (3.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2014s / 2.7045 s
agent0:                 episode reward: 0.2248,                 loss: nan
agent1:                 episode reward: -0.2248,                 loss: 0.4116
Episode: 401/10000 (4.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2014s / 2.9058 s
agent0:                 episode reward: -0.0183,                 loss: nan
agent1:                 episode reward: 0.0183,                 loss: 0.4072
Episode: 421/10000 (4.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2041s / 3.1100 s
agent0:                 episode reward: 0.0656,                 loss: nan
agent1:                 episode reward: -0.0656,                 loss: 0.4059
Episode: 441/10000 (4.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2299s / 3.3399 s
agent0:                 episode reward: -0.2471,                 loss: nan
agent1:                 episode reward: 0.2471,                 loss: 0.4026
Episode: 461/10000 (4.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2439s / 3.5838 s
agent0:                 episode reward: -0.1407,                 loss: nan
agent1:                 episode reward: 0.1407,                 loss: 0.3995
Episode: 481/10000 (4.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2088s / 3.7926 s
agent0:                 episode reward: -0.0145,                 loss: nan
agent1:                 episode reward: 0.0145,                 loss: 0.3987
Episode: 501/10000 (5.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2038s / 3.9964 s
agent0:                 episode reward: 0.0277,                 loss: nan
agent1:                 episode reward: -0.0277,                 loss: 0.3984
Episode: 521/10000 (5.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1978s / 4.1942 s
agent0:                 episode reward: 0.0279,                 loss: nan
agent1:                 episode reward: -0.0279,                 loss: 0.3988
Episode: 541/10000 (5.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2051s / 4.3993 s
agent0:                 episode reward: 0.0933,                 loss: nan
agent1:                 episode reward: -0.0933,                 loss: 0.3993
Episode: 561/10000 (5.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2027s / 4.6020 s
agent0:                 episode reward: -0.0431,                 loss: nan
agent1:                 episode reward: 0.0431,                 loss: 0.3995
Episode: 581/10000 (5.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2052s / 4.8072 s
agent0:                 episode reward: -0.0650,                 loss: nan
agent1:                 episode reward: 0.0650,                 loss: 0.3989
Episode: 601/10000 (6.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2022s / 5.0094 s
agent0:                 episode reward: -0.0482,                 loss: nan
agent1:                 episode reward: 0.0482,                 loss: 0.3946
Episode: 621/10000 (6.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2041s / 5.2135 s
agent0:                 episode reward: -0.0031,                 loss: nan
agent1:                 episode reward: 0.0031,                 loss: 0.3949
Episode: 641/10000 (6.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1982s / 5.4117 s
agent0:                 episode reward: 0.3729,                 loss: nan
agent1:                 episode reward: -0.3729,                 loss: 0.3925
Episode: 661/10000 (6.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2049s / 5.6166 s
agent0:                 episode reward: 0.2495,                 loss: nan
agent1:                 episode reward: -0.2495,                 loss: 0.3915
Episode: 681/10000 (6.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2095s / 5.8261 s
agent0:                 episode reward: -0.1734,                 loss: nan
agent1:                 episode reward: 0.1734,                 loss: 0.3905
Episode: 701/10000 (7.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2048s / 6.0309 s
agent0:                 episode reward: 0.3573,                 loss: nan
agent1:                 episode reward: -0.3573,                 loss: 0.3878
Episode: 721/10000 (7.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2052s / 6.2361 s
agent0:                 episode reward: -0.0563,                 loss: nan
agent1:                 episode reward: 0.0563,                 loss: 0.3865
Episode: 741/10000 (7.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2118s / 6.4479 s
agent0:                 episode reward: -0.0264,                 loss: nan
agent1:                 episode reward: 0.0264,                 loss: 0.3864
Episode: 761/10000 (7.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2282s / 6.6761 s
agent0:                 episode reward: 0.0880,                 loss: nan
agent1:                 episode reward: -0.0880,                 loss: 0.3827
Episode: 781/10000 (7.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2076s / 6.8837 s
agent0:                 episode reward: -0.1130,                 loss: nan
agent1:                 episode reward: 0.1130,                 loss: 0.3827
Episode: 801/10000 (8.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2078s / 7.0915 s
agent0:                 episode reward: -0.0829,                 loss: nan
agent1:                 episode reward: 0.0829,                 loss: 0.3797
Episode: 821/10000 (8.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2090s / 7.3005 s
agent0:                 episode reward: -0.2421,                 loss: nan
agent1:                 episode reward: 0.2421,                 loss: 0.3802
Episode: 841/10000 (8.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2098s / 7.5103 s
agent0:                 episode reward: -0.2000,                 loss: nan
agent1:                 episode reward: 0.2000,                 loss: 0.3786
Episode: 861/10000 (8.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2050s / 7.7153 s
agent0:                 episode reward: -0.0273,                 loss: nan
agent1:                 episode reward: 0.0273,                 loss: 0.3783
Episode: 881/10000 (8.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2038s / 7.9191 s
agent0:                 episode reward: 0.1860,                 loss: nan
agent1:                 episode reward: -0.1860,                 loss: 0.3788
Episode: 901/10000 (9.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2101s / 8.1292 s
agent0:                 episode reward: -0.1848,                 loss: nan
agent1:                 episode reward: 0.1848,                 loss: 0.3963
Episode: 921/10000 (9.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2083s / 8.3375 s
agent0:                 episode reward: -0.2392,                 loss: nan
agent1:                 episode reward: 0.2392,                 loss: 0.3937
Episode: 941/10000 (9.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2063s / 8.5438 s
agent0:                 episode reward: -0.1800,                 loss: nan
agent1:                 episode reward: 0.1800,                 loss: 0.3940
Episode: 961/10000 (9.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2095s / 8.7533 s
agent0:                 episode reward: 0.0572,                 loss: nan
agent1:                 episode reward: -0.0572,                 loss: 0.3927
Episode: 981/10000 (9.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2119s / 8.9652 s
agent0:                 episode reward: -0.1529,                 loss: nan
agent1:                 episode reward: 0.1529,                 loss: 0.3935
Episode: 1001/10000 (10.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2069s / 9.1720 s
agent0:                 episode reward: 0.2944,                 loss: nan
agent1:                 episode reward: -0.2944,                 loss: 0.3899
Episode: 1021/10000 (10.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2145s / 9.3866 s
agent0:                 episode reward: -0.4389,                 loss: nan
agent1:                 episode reward: 0.4389,                 loss: 0.3919
Episode: 1041/10000 (10.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2118s / 9.5984 s
agent0:                 episode reward: -0.1915,                 loss: nan
agent1:                 episode reward: 0.1915,                 loss: 0.3901
Episode: 1061/10000 (10.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2108s / 9.8092 s
agent0:                 episode reward: -0.0152,                 loss: nan
agent1:                 episode reward: 0.0152,                 loss: 0.3870
Episode: 1081/10000 (10.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2106s / 10.0198 s
agent0:                 episode reward: -0.3994,                 loss: nan
agent1:                 episode reward: 0.3994,                 loss: 0.3871
Episode: 1101/10000 (11.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2137s / 10.2335 s
agent0:                 episode reward: -0.1899,                 loss: nan
agent1:                 episode reward: 0.1899,                 loss: 0.3856
Episode: 1121/10000 (11.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2293s / 10.4628 s
agent0:                 episode reward: -0.0986,                 loss: nan
agent1:                 episode reward: 0.0986,                 loss: 0.3874
Episode: 1141/10000 (11.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2114s / 10.6742 s
agent0:                 episode reward: -0.3155,                 loss: nan
agent1:                 episode reward: 0.3155,                 loss: 0.3831
Episode: 1161/10000 (11.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2126s / 10.8868 s
agent0:                 episode reward: -0.1428,                 loss: nan
agent1:                 episode reward: 0.1428,                 loss: 0.3839
Episode: 1181/10000 (11.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2164s / 11.1032 s
agent0:                 episode reward: -0.3759,                 loss: nan
agent1:                 episode reward: 0.3759,                 loss: 0.3805
Episode: 1201/10000 (12.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2146s / 11.3178 s
agent0:                 episode reward: -0.2653,                 loss: nan
agent1:                 episode reward: 0.2653,                 loss: 0.3822
Episode: 1221/10000 (12.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2161s / 11.5339 s
agent0:                 episode reward: -0.1765,                 loss: nan
agent1:                 episode reward: 0.1765,                 loss: 0.3757
Episode: 1241/10000 (12.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2146s / 11.7484 s
agent0:                 episode reward: -0.1963,                 loss: nan
agent1:                 episode reward: 0.1963,                 loss: 0.3617
Episode: 1261/10000 (12.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2149s / 11.9633 s
agent0:                 episode reward: -0.1926,                 loss: nan
agent1:                 episode reward: 0.1926,                 loss: 0.3614
Episode: 1281/10000 (12.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2156s / 12.1789 s
agent0:                 episode reward: 0.0300,                 loss: nan
agent1:                 episode reward: -0.0300,                 loss: 0.3575
Episode: 1301/10000 (13.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2322s / 12.4111 s
agent0:                 episode reward: -0.2085,                 loss: nan
agent1:                 episode reward: 0.2085,                 loss: 0.3567
Episode: 1321/10000 (13.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2241s / 12.6352 s
agent0:                 episode reward: -0.4339,                 loss: nan
agent1:                 episode reward: 0.4339,                 loss: 0.3560
Episode: 1341/10000 (13.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2212s / 12.8564 s
agent0:                 episode reward: -0.3231,                 loss: nan
agent1:                 episode reward: 0.3231,                 loss: 0.3537
Episode: 1361/10000 (13.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2149s / 13.0712 s
agent0:                 episode reward: -0.1787,                 loss: nan
agent1:                 episode reward: 0.1787,                 loss: 0.3553
Episode: 1381/10000 (13.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2174s / 13.2886 s
agent0:                 episode reward: -0.1893,                 loss: nan
agent1:                 episode reward: 0.1893,                 loss: 0.3524
Episode: 1401/10000 (14.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2160s / 13.5047 s
agent0:                 episode reward: -0.6123,                 loss: nan
agent1:                 episode reward: 0.6123,                 loss: 0.3544
Episode: 1421/10000 (14.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2679s / 13.7726 s
agent0:                 episode reward: -0.6055,                 loss: nan
agent1:                 episode reward: 0.6055,                 loss: 0.3513
Episode: 1441/10000 (14.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2178s / 13.9904 s
agent0:                 episode reward: -0.2579,                 loss: nan
agent1:                 episode reward: 0.2579,                 loss: 0.3523
Episode: 1461/10000 (14.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2154s / 14.2057 s
agent0:                 episode reward: -0.2091,                 loss: nan
agent1:                 episode reward: 0.2091,                 loss: 0.3528
Episode: 1481/10000 (14.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2209s / 14.4267 s
agent0:                 episode reward: -0.3093,                 loss: nan
agent1:                 episode reward: 0.3093,                 loss: 0.3493
Episode: 1501/10000 (15.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2180s / 14.6447 s
agent0:                 episode reward: 0.1195,                 loss: nan
agent1:                 episode reward: -0.1195,                 loss: 0.3495
Episode: 1521/10000 (15.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2212s / 14.8659 s
agent0:                 episode reward: -0.6779,                 loss: nan
agent1:                 episode reward: 0.6779,                 loss: 0.3492
Episode: 1541/10000 (15.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2177s / 15.0836 s
agent0:                 episode reward: -0.1338,                 loss: nan
agent1:                 episode reward: 0.1338,                 loss: 0.3467
Episode: 1561/10000 (15.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2202s / 15.3038 s
agent0:                 episode reward: -0.6553,                 loss: nan
agent1:                 episode reward: 0.6553,                 loss: 0.3336
Episode: 1581/10000 (15.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2284s / 15.5322 s
agent0:                 episode reward: -0.2654,                 loss: nan
agent1:                 episode reward: 0.2654,                 loss: 0.3286
Episode: 1601/10000 (16.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2180s / 15.7502 s
agent0:                 episode reward: 0.0289,                 loss: nan
agent1:                 episode reward: -0.0289,                 loss: 0.3270
Episode: 1621/10000 (16.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2197s / 15.9699 s
agent0:                 episode reward: 0.0190,                 loss: nan
agent1:                 episode reward: -0.0190,                 loss: 0.3248
Episode: 1641/10000 (16.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2169s / 16.1868 s
agent0:                 episode reward: -0.6900,                 loss: nan
agent1:                 episode reward: 0.6900,                 loss: 0.3276
Episode: 1661/10000 (16.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2226s / 16.4094 s
agent0:                 episode reward: -0.4965,                 loss: nan
agent1:                 episode reward: 0.4965,                 loss: 0.3253
Episode: 1681/10000 (16.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2194s / 16.6288 s
agent0:                 episode reward: -0.6447,                 loss: nan
agent1:                 episode reward: 0.6447,                 loss: 0.3234
Episode: 1701/10000 (17.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2212s / 16.8500 s
agent0:                 episode reward: -0.7266,                 loss: nan
agent1:                 episode reward: 0.7266,                 loss: 0.3216
Episode: 1721/10000 (17.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2239s / 17.0739 s
agent0:                 episode reward: -0.3147,                 loss: nan
agent1:                 episode reward: 0.3147,                 loss: 0.3241
Episode: 1741/10000 (17.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2252s / 17.2991 s
agent0:                 episode reward: -0.2721,                 loss: nan
agent1:                 episode reward: 0.2721,                 loss: 0.3244
Episode: 1761/10000 (17.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2221s / 17.5212 s
agent0:                 episode reward: -0.5163,                 loss: nan
agent1:                 episode reward: 0.5163,                 loss: 0.3231
Episode: 1781/10000 (17.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2224s / 17.7436 s
agent0:                 episode reward: -0.3851,                 loss: nan
agent1:                 episode reward: 0.3851,                 loss: 0.3192
Episode: 1801/10000 (18.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2228s / 17.9664 s
agent0:                 episode reward: -0.3733,                 loss: nan
agent1:                 episode reward: 0.3733,                 loss: 0.3169
Episode: 1821/10000 (18.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2213s / 18.1877 s
agent0:                 episode reward: -0.2686,                 loss: nan
agent1:                 episode reward: 0.2686,                 loss: 0.3196
Episode: 1841/10000 (18.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2291s / 18.4168 s
agent0:                 episode reward: -0.2599,                 loss: nan
agent1:                 episode reward: 0.2599,                 loss: 0.3147
Episode: 1861/10000 (18.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2360s / 18.6528 s
agent0:                 episode reward: -0.3425,                 loss: nan
agent1:                 episode reward: 0.3425,                 loss: 0.3184
Episode: 1881/10000 (18.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2309s / 18.8837 s
agent0:                 episode reward: -0.2806,                 loss: nan
agent1:                 episode reward: 0.2806,                 loss: 0.3199
Episode: 1901/10000 (19.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2198s / 19.1035 s
agent0:                 episode reward: -0.4022,                 loss: nan
agent1:                 episode reward: 0.4022,                 loss: 0.3124
Episode: 1921/10000 (19.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2245s / 19.3280 s
agent0:                 episode reward: -0.3344,                 loss: nan
agent1:                 episode reward: 0.3344,                 loss: 0.3100
Episode: 1941/10000 (19.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2238s / 19.5518 s
agent0:                 episode reward: -0.3319,                 loss: nan
agent1:                 episode reward: 0.3319,                 loss: 0.3127
Episode: 1961/10000 (19.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2272s / 19.7790 s
agent0:                 episode reward: -0.2695,                 loss: nan
agent1:                 episode reward: 0.2695,                 loss: 0.3098
Episode: 1981/10000 (19.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2238s / 20.0028 s
agent0:                 episode reward: -0.2833,                 loss: nan
agent1:                 episode reward: 0.2833,                 loss: 0.3146
Episode: 2001/10000 (20.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2243s / 20.2271 s
agent0:                 episode reward: -0.4305,                 loss: nan
agent1:                 episode reward: 0.4305,                 loss: 0.3088
Episode: 2021/10000 (20.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2286s / 20.4558 s
agent0:                 episode reward: -0.9174,                 loss: nan
agent1:                 episode reward: 0.9174,                 loss: 0.3105
Episode: 2041/10000 (20.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2223s / 20.6781 s
agent0:                 episode reward: -0.3606,                 loss: nan
agent1:                 episode reward: 0.3606,                 loss: 0.3076
Episode: 2061/10000 (20.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2293s / 20.9074 s
agent0:                 episode reward: -0.1706,                 loss: nan
agent1:                 episode reward: 0.1706,                 loss: 0.3058
Episode: 2081/10000 (20.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2300s / 21.1375 s
agent0:                 episode reward: -0.5303,                 loss: nan
agent1:                 episode reward: 0.5303,                 loss: 0.3074
Episode: 2101/10000 (21.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2298s / 21.3673 s
agent0:                 episode reward: -0.2426,                 loss: nan
agent1:                 episode reward: 0.2426,                 loss: 0.3066
Episode: 2121/10000 (21.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2341s / 21.6013 s
agent0:                 episode reward: -0.4269,                 loss: nan
agent1:                 episode reward: 0.4269,                 loss: 0.3050
Episode: 2141/10000 (21.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2311s / 21.8324 s
agent0:                 episode reward: -0.3030,                 loss: nan
agent1:                 episode reward: 0.3030,                 loss: 0.3044
Episode: 2161/10000 (21.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2289s / 22.0613 s
agent0:                 episode reward: 0.1628,                 loss: nan
agent1:                 episode reward: -0.1628,                 loss: 0.3013
Episode: 2181/10000 (21.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2308s / 22.2922 s
agent0:                 episode reward: -0.3456,                 loss: nan
agent1:                 episode reward: 0.3456,                 loss: 0.2994
Episode: 2201/10000 (22.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2296s / 22.5217 s
agent0:                 episode reward: -0.1325,                 loss: nan
agent1:                 episode reward: 0.1325,                 loss: 0.3010
Episode: 2221/10000 (22.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2295s / 22.7512 s
agent0:                 episode reward: -0.4651,                 loss: nan
agent1:                 episode reward: 0.4651,                 loss: 0.3016
Episode: 2241/10000 (22.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2361s / 22.9874 s
agent0:                 episode reward: -0.1298,                 loss: nan
agent1:                 episode reward: 0.1298,                 loss: 0.3035
Episode: 2261/10000 (22.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2329s / 23.2202 s
agent0:                 episode reward: -0.6349,                 loss: nan
agent1:                 episode reward: 0.6349,                 loss: 0.3029
Episode: 2281/10000 (22.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2352s / 23.4554 s
agent0:                 episode reward: -0.0998,                 loss: nan
agent1:                 episode reward: 0.0998,                 loss: 0.3038
Episode: 2301/10000 (23.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2306s / 23.6860 s
agent0:                 episode reward: 0.2262,                 loss: nan
agent1:                 episode reward: -0.2262,                 loss: 0.3017
Episode: 2321/10000 (23.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2807s / 23.9668 s
agent0:                 episode reward: -0.3509,                 loss: nan
agent1:                 episode reward: 0.3509,                 loss: 0.3021
Episode: 2341/10000 (23.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2301s / 24.1969 s
agent0:                 episode reward: -0.3289,                 loss: nan
agent1:                 episode reward: 0.3289,                 loss: 0.3007
Episode: 2361/10000 (23.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2347s / 24.4316 s
agent0:                 episode reward: -0.2883,                 loss: nan
agent1:                 episode reward: 0.2883,                 loss: 0.2993
Episode: 2381/10000 (23.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2350s / 24.6666 s
agent0:                 episode reward: -0.1725,                 loss: nan
agent1:                 episode reward: 0.1725,                 loss: 0.3011
Episode: 2401/10000 (24.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2356s / 24.9022 s
agent0:                 episode reward: -0.8412,                 loss: nan
agent1:                 episode reward: 0.8412,                 loss: 0.2984
Episode: 2421/10000 (24.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2316s / 25.1338 s
agent0:                 episode reward: -0.6514,                 loss: nan
agent1:                 episode reward: 0.6514,                 loss: 0.2992
Episode: 2441/10000 (24.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2336s / 25.3674 s
agent0:                 episode reward: -0.7398,                 loss: nan
agent1:                 episode reward: 0.7398,                 loss: 0.2993
Episode: 2461/10000 (24.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2319s / 25.5992 s
agent0:                 episode reward: -0.6208,                 loss: nan
agent1:                 episode reward: 0.6208,                 loss: 0.2961
Episode: 2481/10000 (24.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2326s / 25.8319 s
agent0:                 episode reward: -0.5793,                 loss: nan
agent1:                 episode reward: 0.5793,                 loss: 0.2964
Episode: 2501/10000 (25.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2351s / 26.0669 s
agent0:                 episode reward: -0.3862,                 loss: nan
agent1:                 episode reward: 0.3862,                 loss: 0.2947
Episode: 2521/10000 (25.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2363s / 26.3032 s
agent0:                 episode reward: -0.8026,                 loss: nan
agent1:                 episode reward: 0.8026,                 loss: 0.2947
Episode: 2541/10000 (25.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2339s / 26.5371 s
agent0:                 episode reward: -0.7371,                 loss: nan
agent1:                 episode reward: 0.7371,                 loss: 0.2960
Episode: 2561/10000 (25.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2345s / 26.7716 s
agent0:                 episode reward: -0.3980,                 loss: nan
agent1:                 episode reward: 0.3980,                 loss: 0.2921
Episode: 2581/10000 (25.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2521s / 27.0237 s
agent0:                 episode reward: -0.3022,                 loss: nan
agent1:                 episode reward: 0.3022,                 loss: 0.2912
Episode: 2601/10000 (26.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2381s / 27.2618 s
agent0:                 episode reward: -0.0775,                 loss: nan
agent1:                 episode reward: 0.0775,                 loss: 0.2895
Episode: 2621/10000 (26.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2493s / 27.5111 s
agent0:                 episode reward: -0.3646,                 loss: nan
agent1:                 episode reward: 0.3646,                 loss: 0.2899
Episode: 2641/10000 (26.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2377s / 27.7487 s
agent0:                 episode reward: -0.5408,                 loss: nan
agent1:                 episode reward: 0.5408,                 loss: 0.2868
Episode: 2661/10000 (26.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2368s / 27.9855 s
agent0:                 episode reward: -0.5534,                 loss: nan
agent1:                 episode reward: 0.5534,                 loss: 0.2844
Episode: 2681/10000 (26.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2404s / 28.2259 s
agent0:                 episode reward: -0.3813,                 loss: nan
agent1:                 episode reward: 0.3813,                 loss: 0.2844
Episode: 2701/10000 (27.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2338s / 28.4596 s
agent0:                 episode reward: -0.2651,                 loss: nan
agent1:                 episode reward: 0.2651,                 loss: 0.2798
Episode: 2721/10000 (27.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2366s / 28.6963 s
agent0:                 episode reward: -0.4145,                 loss: nan
agent1:                 episode reward: 0.4145,                 loss: 0.2849
Episode: 2741/10000 (27.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2370s / 28.9332 s
agent0:                 episode reward: -0.7630,                 loss: nan
agent1:                 episode reward: 0.7630,                 loss: 0.2783
Episode: 2761/10000 (27.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2348s / 29.1680 s
agent0:                 episode reward: -0.4840,                 loss: nan
agent1:                 episode reward: 0.4840,                 loss: 0.2794
Episode: 2781/10000 (27.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2347s / 29.4027 s
agent0:                 episode reward: -0.6037,                 loss: nan
agent1:                 episode reward: 0.6037,                 loss: 0.2768
Episode: 2801/10000 (28.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2345s / 29.6372 s
agent0:                 episode reward: -0.9974,                 loss: nan
agent1:                 episode reward: 0.9974,                 loss: 0.2760
Episode: 2821/10000 (28.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2402s / 29.8774 s
agent0:                 episode reward: -0.3312,                 loss: nan
agent1:                 episode reward: 0.3312,                 loss: 0.2774
Episode: 2841/10000 (28.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2389s / 30.1163 s
agent0:                 episode reward: -0.6589,                 loss: nan
agent1:                 episode reward: 0.6589,                 loss: 0.2754
Episode: 2861/10000 (28.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2419s / 30.3582 s
agent0:                 episode reward: -0.4816,                 loss: nan
agent1:                 episode reward: 0.4816,                 loss: 0.2704
Episode: 2881/10000 (28.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2683s / 30.6265 s
agent0:                 episode reward: -0.6269,                 loss: nan
agent1:                 episode reward: 0.6269,                 loss: 0.2735
Episode: 2901/10000 (29.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2385s / 30.8650 s
agent0:                 episode reward: -0.5291,                 loss: nan
agent1:                 episode reward: 0.5291,                 loss: 0.2675
Episode: 2921/10000 (29.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2388s / 31.1038 s
agent0:                 episode reward: -0.7757,                 loss: nan
agent1:                 episode reward: 0.7757,                 loss: 0.2636
Episode: 2941/10000 (29.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2399s / 31.3437 s
agent0:                 episode reward: -0.5304,                 loss: nan
agent1:                 episode reward: 0.5304,                 loss: 0.2651
Episode: 2961/10000 (29.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2408s / 31.5845 s
agent0:                 episode reward: -0.2435,                 loss: nan
agent1:                 episode reward: 0.2435,                 loss: 0.2616
Episode: 2981/10000 (29.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2422s / 31.8266 s
agent0:                 episode reward: -0.5414,                 loss: nan
agent1:                 episode reward: 0.5414,                 loss: 0.2628
Episode: 3001/10000 (30.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2427s / 32.0694 s
agent0:                 episode reward: -0.6927,                 loss: nan
agent1:                 episode reward: 0.6927,                 loss: 0.2594
Episode: 3021/10000 (30.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2470s / 32.3163 s
agent0:                 episode reward: -0.9382,                 loss: nan
agent1:                 episode reward: 0.9382,                 loss: 0.2615
Episode: 3041/10000 (30.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2413s / 32.5577 s
agent0:                 episode reward: -0.3532,                 loss: nan
agent1:                 episode reward: 0.3532,                 loss: 0.2599
Episode: 3061/10000 (30.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2424s / 32.8000 s
agent0:                 episode reward: -0.6603,                 loss: nan
agent1:                 episode reward: 0.6603,                 loss: 0.2633
Episode: 3081/10000 (30.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2440s / 33.0440 s
agent0:                 episode reward: -0.1163,                 loss: nan
agent1:                 episode reward: 0.1163,                 loss: 0.2594
Episode: 3101/10000 (31.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2521s / 33.2961 s
agent0:                 episode reward: -0.4846,                 loss: nan
agent1:                 episode reward: 0.4846,                 loss: 0.2591
Episode: 3121/10000 (31.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2528s / 33.5489 s
agent0:                 episode reward: -0.8136,                 loss: nan
agent1:                 episode reward: 0.8136,                 loss: 0.2560
Episode: 3141/10000 (31.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2456s / 33.7944 s
agent0:                 episode reward: -0.3346,                 loss: nan
agent1:                 episode reward: 0.3346,                 loss: 0.2591
Episode: 3161/10000 (31.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2590s / 34.0534 s
agent0:                 episode reward: -0.6792,                 loss: nan
agent1:                 episode reward: 0.6792,                 loss: 0.2598
Episode: 3181/10000 (31.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2854s / 34.3388 s
agent0:                 episode reward: -0.7455,                 loss: nan
agent1:                 episode reward: 0.7455,                 loss: 0.2589
Episode: 3201/10000 (32.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2427s / 34.5815 s
agent0:                 episode reward: -0.6032,                 loss: nan
agent1:                 episode reward: 0.6032,                 loss: 0.2596
Episode: 3221/10000 (32.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2450s / 34.8265 s
agent0:                 episode reward: -0.7115,                 loss: nan
agent1:                 episode reward: 0.7115,                 loss: 0.2573
Episode: 3241/10000 (32.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2451s / 35.0716 s
agent0:                 episode reward: -0.9936,                 loss: nan
agent1:                 episode reward: 0.9936,                 loss: 0.2571
Episode: 3261/10000 (32.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2624s / 35.3340 s
agent0:                 episode reward: -0.5712,                 loss: nan
agent1:                 episode reward: 0.5712,                 loss: 0.2567
Episode: 3281/10000 (32.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2465s / 35.5805 s
agent0:                 episode reward: -0.3797,                 loss: nan
agent1:                 episode reward: 0.3797,                 loss: 0.2563
Episode: 3301/10000 (33.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2493s / 35.8298 s
agent0:                 episode reward: -0.8133,                 loss: nan
agent1:                 episode reward: 0.8133,                 loss: 0.2522
Episode: 3321/10000 (33.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2488s / 36.0786 s
agent0:                 episode reward: -0.6602,                 loss: nan
agent1:                 episode reward: 0.6602,                 loss: 0.2556
Episode: 3341/10000 (33.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2486s / 36.3271 s
agent0:                 episode reward: -0.6940,                 loss: nan
agent1:                 episode reward: 0.6940,                 loss: 0.2537
Episode: 3361/10000 (33.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2553s / 36.5825 s
agent0:                 episode reward: -0.7293,                 loss: nan
agent1:                 episode reward: 0.7293,                 loss: 0.2578
Episode: 3381/10000 (33.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2503s / 36.8327 s
agent0:                 episode reward: -0.5656,                 loss: nan
agent1:                 episode reward: 0.5656,                 loss: 0.2574
Episode: 3401/10000 (34.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2450s / 37.0777 s
agent0:                 episode reward: -1.1531,                 loss: nan
agent1:                 episode reward: 1.1531,                 loss: 0.2548
Episode: 3421/10000 (34.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2487s / 37.3264 s
agent0:                 episode reward: -0.8098,                 loss: nan
agent1:                 episode reward: 0.8098,                 loss: 0.2548
Episode: 3441/10000 (34.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2463s / 37.5728 s
agent0:                 episode reward: -0.8812,                 loss: nan
agent1:                 episode reward: 0.8812,                 loss: 0.2542
Episode: 3461/10000 (34.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2484s / 37.8211 s
agent0:                 episode reward: -0.5790,                 loss: nan
agent1:                 episode reward: 0.5790,                 loss: 0.2527
Episode: 3481/10000 (34.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2475s / 38.0687 s
agent0:                 episode reward: -0.7536,                 loss: nan
agent1:                 episode reward: 0.7536,                 loss: 0.2558
Episode: 3501/10000 (35.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2478s / 38.3164 s
agent0:                 episode reward: -0.0852,                 loss: nan
agent1:                 episode reward: 0.0852,                 loss: 0.2580
Episode: 3521/10000 (35.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2485s / 38.5650 s
agent0:                 episode reward: -0.6206,                 loss: nan
agent1:                 episode reward: 0.6206,                 loss: 0.2554
Episode: 3541/10000 (35.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2492s / 38.8141 s
agent0:                 episode reward: -1.0965,                 loss: nan
agent1:                 episode reward: 1.0965,                 loss: 0.2514
Episode: 3561/10000 (35.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2477s / 39.0618 s
agent0:                 episode reward: -0.4949,                 loss: nan
agent1:                 episode reward: 0.4949,                 loss: 0.2508
Episode: 3581/10000 (35.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2477s / 39.3096 s
agent0:                 episode reward: -0.2820,                 loss: nan
agent1:                 episode reward: 0.2820,                 loss: 0.2551
Episode: 3601/10000 (36.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2566s / 39.5661 s
agent0:                 episode reward: -0.7102,                 loss: nan
agent1:                 episode reward: 0.7102,                 loss: 0.2528
Episode: 3621/10000 (36.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2532s / 39.8193 s
agent0:                 episode reward: -0.6043,                 loss: nan
agent1:                 episode reward: 0.6043,                 loss: 0.2492
Episode: 3641/10000 (36.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2505s / 40.0699 s
agent0:                 episode reward: -1.0579,                 loss: nan
agent1:                 episode reward: 1.0579,                 loss: 0.2503
Episode: 3661/10000 (36.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2482s / 40.3180 s
agent0:                 episode reward: -0.5836,                 loss: nan
agent1:                 episode reward: 0.5836,                 loss: 0.2520
Episode: 3681/10000 (36.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2510s / 40.5691 s
agent0:                 episode reward: -1.0245,                 loss: nan
agent1:                 episode reward: 1.0245,                 loss: 0.2491
Episode: 3701/10000 (37.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2500s / 40.8191 s
agent0:                 episode reward: -0.6245,                 loss: nan
agent1:                 episode reward: 0.6245,                 loss: 0.2479
Episode: 3721/10000 (37.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2490s / 41.0681 s
agent0:                 episode reward: -0.8321,                 loss: nan
agent1:                 episode reward: 0.8321,                 loss: 0.2502
Episode: 3741/10000 (37.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2504s / 41.3185 s
agent0:                 episode reward: -0.5599,                 loss: nan
agent1:                 episode reward: 0.5599,                 loss: 0.2506
Episode: 3761/10000 (37.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2504s / 41.5689 s
agent0:                 episode reward: -0.8117,                 loss: nan
agent1:                 episode reward: 0.8117,                 loss: 0.2501
Episode: 3781/10000 (37.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2516s / 41.8206 s
agent0:                 episode reward: -0.5032,                 loss: nan
agent1:                 episode reward: 0.5032,                 loss: 0.2495
Episode: 3801/10000 (38.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2488s / 42.0694 s
agent0:                 episode reward: -0.9856,                 loss: nan
agent1:                 episode reward: 0.9856,                 loss: 0.2472
Episode: 3821/10000 (38.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2540s / 42.3234 s
agent0:                 episode reward: -0.3766,                 loss: nan
agent1:                 episode reward: 0.3766,                 loss: 0.2516
Episode: 3841/10000 (38.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2613s / 42.5847 s
agent0:                 episode reward: -0.5378,                 loss: nan
agent1:                 episode reward: 0.5378,                 loss: 0.2483
Episode: 3861/10000 (38.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2499s / 42.8346 s
agent0:                 episode reward: -0.4207,                 loss: nan
agent1:                 episode reward: 0.4207,                 loss: 0.2467
Episode: 3881/10000 (38.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2544s / 43.0890 s
agent0:                 episode reward: -0.6915,                 loss: nan
agent1:                 episode reward: 0.6915,                 loss: 0.2459
Episode: 3901/10000 (39.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2668s / 43.3558 s
agent0:                 episode reward: -1.0590,                 loss: nan
agent1:                 episode reward: 1.0590,                 loss: 0.2460
Episode: 3921/10000 (39.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2626s / 43.6184 s
agent0:                 episode reward: -0.9277,                 loss: nan
agent1:                 episode reward: 0.9277,                 loss: 0.2441
Episode: 3941/10000 (39.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2581s / 43.8765 s
agent0:                 episode reward: -0.6792,                 loss: nan
agent1:                 episode reward: 0.6792,                 loss: 0.2444
Episode: 3961/10000 (39.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2579s / 44.1344 s
agent0:                 episode reward: -0.6315,                 loss: nan
agent1:                 episode reward: 0.6315,                 loss: 0.2444
Episode: 3981/10000 (39.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3107s / 44.4450 s
agent0:                 episode reward: -0.5890,                 loss: nan
agent1:                 episode reward: 0.5890,                 loss: 0.2447
Episode: 4001/10000 (40.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2584s / 44.7035 s
agent0:                 episode reward: -0.5219,                 loss: nan
agent1:                 episode reward: 0.5219,                 loss: 0.2438
Episode: 4021/10000 (40.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2630s / 44.9665 s
agent0:                 episode reward: -0.5691,                 loss: nan
agent1:                 episode reward: 0.5691,                 loss: 0.2446
Episode: 4041/10000 (40.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2526s / 45.2191 s
agent0:                 episode reward: -0.8496,                 loss: nan
agent1:                 episode reward: 0.8496,                 loss: 0.2420
Episode: 4061/10000 (40.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2546s / 45.4737 s
agent0:                 episode reward: -0.5528,                 loss: nan
agent1:                 episode reward: 0.5528,                 loss: 0.2438
Episode: 4081/10000 (40.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2678s / 45.7415 s
agent0:                 episode reward: -0.5775,                 loss: nan
agent1:                 episode reward: 0.5775,                 loss: 0.2449
Episode: 4101/10000 (41.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2546s / 45.9961 s
agent0:                 episode reward: -0.9722,                 loss: nan
agent1:                 episode reward: 0.9722,                 loss: 0.2426
Episode: 4121/10000 (41.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2532s / 46.2493 s
agent0:                 episode reward: -0.7512,                 loss: nan
agent1:                 episode reward: 0.7512,                 loss: 0.2411
Episode: 4141/10000 (41.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2565s / 46.5057 s
agent0:                 episode reward: -0.2436,                 loss: nan
agent1:                 episode reward: 0.2436,                 loss: 0.2441
Episode: 4161/10000 (41.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2582s / 46.7640 s
agent0:                 episode reward: -0.7408,                 loss: nan
agent1:                 episode reward: 0.7408,                 loss: 0.2411
Episode: 4181/10000 (41.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2541s / 47.0180 s
agent0:                 episode reward: -0.6811,                 loss: nan
agent1:                 episode reward: 0.6811,                 loss: 0.2432
Episode: 4201/10000 (42.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2585s / 47.2766 s
agent0:                 episode reward: -0.5413,                 loss: nan
agent1:                 episode reward: 0.5413,                 loss: 0.2465
Episode: 4221/10000 (42.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2566s / 47.5332 s
agent0:                 episode reward: -0.2448,                 loss: nan
agent1:                 episode reward: 0.2448,                 loss: 0.2460
Episode: 4241/10000 (42.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2585s / 47.7917 s
agent0:                 episode reward: -0.8438,                 loss: nan
agent1:                 episode reward: 0.8438,                 loss: 0.2458
Episode: 4261/10000 (42.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2602s / 48.0519 s
agent0:                 episode reward: -0.3156,                 loss: nan
agent1:                 episode reward: 0.3156,                 loss: 0.2456
Episode: 4281/10000 (42.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2584s / 48.3103 s
agent0:                 episode reward: -0.4948,                 loss: nan
agent1:                 episode reward: 0.4948,                 loss: 0.2448
Episode: 4301/10000 (43.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2785s / 48.5888 s
agent0:                 episode reward: -0.9951,                 loss: nan
agent1:                 episode reward: 0.9951,                 loss: 0.2450
Episode: 4321/10000 (43.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2744s / 48.8632 s
agent0:                 episode reward: -1.1144,                 loss: nan
agent1:                 episode reward: 1.1144,                 loss: 0.2454
Episode: 4341/10000 (43.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2569s / 49.1201 s
agent0:                 episode reward: -0.8788,                 loss: nan
agent1:                 episode reward: 0.8788,                 loss: 0.2478
Episode: 4361/10000 (43.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2601s / 49.3803 s
agent0:                 episode reward: -0.5696,                 loss: nan
agent1:                 episode reward: 0.5696,                 loss: 0.2460
Episode: 4381/10000 (43.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2602s / 49.6404 s
agent0:                 episode reward: -0.3386,                 loss: nan
agent1:                 episode reward: 0.3386,                 loss: 0.2449
Episode: 4401/10000 (44.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2526s / 49.8931 s
agent0:                 episode reward: -0.2469,                 loss: nan
agent1:                 episode reward: 0.2469,                 loss: 0.2441
Episode: 4421/10000 (44.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2563s / 50.1494 s
agent0:                 episode reward: -0.9186,                 loss: nan
agent1:                 episode reward: 0.9186,                 loss: 0.2477
Episode: 4441/10000 (44.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2592s / 50.4086 s
agent0:                 episode reward: -0.9712,                 loss: nan
agent1:                 episode reward: 0.9712,                 loss: 0.2461
Episode: 4461/10000 (44.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2641s / 50.6727 s
agent0:                 episode reward: -0.8947,                 loss: nan
agent1:                 episode reward: 0.8947,                 loss: 0.2435
Episode: 4481/10000 (44.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2607s / 50.9334 s
agent0:                 episode reward: -0.6126,                 loss: nan
agent1:                 episode reward: 0.6126,                 loss: 0.2454
Episode: 4501/10000 (45.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2576s / 51.1911 s
agent0:                 episode reward: -0.7980,                 loss: nan
agent1:                 episode reward: 0.7980,                 loss: 0.2420
Episode: 4521/10000 (45.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2632s / 51.4543 s
agent0:                 episode reward: -0.8036,                 loss: nan
agent1:                 episode reward: 0.8036,                 loss: 0.2446
Episode: 4541/10000 (45.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2717s / 51.7260 s
agent0:                 episode reward: -0.8276,                 loss: nan
agent1:                 episode reward: 0.8276,                 loss: 0.2438
Episode: 4561/10000 (45.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3021s / 52.0281 s
agent0:                 episode reward: -0.9135,                 loss: nan
agent1:                 episode reward: 0.9135,                 loss: 0.2433
Episode: 4581/10000 (45.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2620s / 52.2901 s
agent0:                 episode reward: -0.4171,                 loss: nan
agent1:                 episode reward: 0.4171,                 loss: 0.2441
Episode: 4601/10000 (46.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2618s / 52.5518 s
agent0:                 episode reward: -0.5376,                 loss: nan
agent1:                 episode reward: 0.5376,                 loss: 0.2453
Episode: 4621/10000 (46.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2634s / 52.8153 s
agent0:                 episode reward: -0.8658,                 loss: nan
agent1:                 episode reward: 0.8658,                 loss: 0.2434
Episode: 4641/10000 (46.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2626s / 53.0779 s
agent0:                 episode reward: -0.6694,                 loss: nan
agent1:                 episode reward: 0.6694,                 loss: 0.2477
Episode: 4661/10000 (46.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2644s / 53.3423 s
agent0:                 episode reward: -0.7304,                 loss: nan
agent1:                 episode reward: 0.7304,                 loss: 0.2438
Episode: 4681/10000 (46.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2670s / 53.6093 s
agent0:                 episode reward: -0.7855,                 loss: nan
agent1:                 episode reward: 0.7855,                 loss: 0.2474
Episode: 4701/10000 (47.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2644s / 53.8737 s
agent0:                 episode reward: -0.9448,                 loss: nan
agent1:                 episode reward: 0.9448,                 loss: 0.2446
Episode: 4721/10000 (47.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2675s / 54.1412 s
agent0:                 episode reward: -0.8766,                 loss: nan
agent1:                 episode reward: 0.8766,                 loss: 0.2445
Episode: 4741/10000 (47.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2631s / 54.4043 s
agent0:                 episode reward: -1.0716,                 loss: nan
agent1:                 episode reward: 1.0716,                 loss: 0.2465
Episode: 4761/10000 (47.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3193s / 54.7236 s
agent0:                 episode reward: -0.7935,                 loss: nan
agent1:                 episode reward: 0.7935,                 loss: 0.2447
Episode: 4781/10000 (47.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2625s / 54.9861 s
agent0:                 episode reward: -0.7703,                 loss: nan
agent1:                 episode reward: 0.7703,                 loss: 0.2465
Episode: 4801/10000 (48.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2639s / 55.2500 s
agent0:                 episode reward: -0.5969,                 loss: nan
agent1:                 episode reward: 0.5969,                 loss: 0.2440
Episode: 4821/10000 (48.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2651s / 55.5151 s
agent0:                 episode reward: -0.6770,                 loss: nan
agent1:                 episode reward: 0.6770,                 loss: 0.2467
Episode: 4841/10000 (48.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2642s / 55.7792 s
agent0:                 episode reward: -0.4446,                 loss: nan
agent1:                 episode reward: 0.4446,                 loss: 0.2445
Episode: 4861/10000 (48.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2664s / 56.0456 s
agent0:                 episode reward: -0.6108,                 loss: nan
agent1:                 episode reward: 0.6108,                 loss: 0.2428
Episode: 4881/10000 (48.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2691s / 56.3147 s
agent0:                 episode reward: -0.8029,                 loss: nan
agent1:                 episode reward: 0.8029,                 loss: 0.2411
Episode: 4901/10000 (49.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2665s / 56.5812 s
agent0:                 episode reward: -0.8410,                 loss: nan
agent1:                 episode reward: 0.8410,                 loss: 0.2383
Episode: 4921/10000 (49.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2647s / 56.8459 s
agent0:                 episode reward: -0.6798,                 loss: nan
agent1:                 episode reward: 0.6798,                 loss: 0.2413
Episode: 4941/10000 (49.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2640s / 57.1099 s
agent0:                 episode reward: -0.7988,                 loss: nan
agent1:                 episode reward: 0.7988,                 loss: 0.2352
Episode: 4961/10000 (49.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2661s / 57.3760 s
agent0:                 episode reward: -0.7839,                 loss: nan
agent1:                 episode reward: 0.7839,                 loss: 0.2372
Episode: 4981/10000 (49.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2813s / 57.6573 s
agent0:                 episode reward: -0.8399,                 loss: nan
agent1:                 episode reward: 0.8399,                 loss: 0.2368
Episode: 5001/10000 (50.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2695s / 57.9268 s
agent0:                 episode reward: -1.0138,                 loss: nan
agent1:                 episode reward: 1.0138,                 loss: 0.2400
Episode: 5021/10000 (50.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2702s / 58.1970 s
agent0:                 episode reward: -0.8268,                 loss: nan
agent1:                 episode reward: 0.8268,                 loss: 0.2399
Episode: 5041/10000 (50.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2678s / 58.4648 s
agent0:                 episode reward: -0.8000,                 loss: nan
agent1:                 episode reward: 0.8000,                 loss: 0.2381
Episode: 5061/10000 (50.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2643s / 58.7291 s
agent0:                 episode reward: -0.6883,                 loss: nan
agent1:                 episode reward: 0.6883,                 loss: 0.2345
Episode: 5081/10000 (50.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2756s / 59.0047 s
agent0:                 episode reward: -1.0464,                 loss: nan
agent1:                 episode reward: 1.0464,                 loss: 0.2368
Episode: 5101/10000 (51.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2724s / 59.2770 s
agent0:                 episode reward: -0.6317,                 loss: nan
agent1:                 episode reward: 0.6317,                 loss: 0.2363
Episode: 5121/10000 (51.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2744s / 59.5515 s
agent0:                 episode reward: -0.3361,                 loss: nan
agent1:                 episode reward: 0.3361,                 loss: 0.2336
Episode: 5141/10000 (51.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2769s / 59.8284 s
agent0:                 episode reward: -0.8415,                 loss: nan
agent1:                 episode reward: 0.8415,                 loss: 0.2395
Episode: 5161/10000 (51.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2709s / 60.0992 s
agent0:                 episode reward: -0.9435,                 loss: nan
agent1:                 episode reward: 0.9435,                 loss: 0.2391
Episode: 5181/10000 (51.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2925s / 60.3917 s
agent0:                 episode reward: -0.9677,                 loss: nan
agent1:                 episode reward: 0.9677,                 loss: 0.2388
Episode: 5201/10000 (52.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2684s / 60.6602 s
agent0:                 episode reward: -0.8905,                 loss: nan
agent1:                 episode reward: 0.8905,                 loss: 0.2392
Episode: 5221/10000 (52.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2722s / 60.9323 s
agent0:                 episode reward: -0.3968,                 loss: nan
agent1:                 episode reward: 0.3968,                 loss: 0.2394
Episode: 5241/10000 (52.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2649s / 61.1972 s
agent0:                 episode reward: -0.6249,                 loss: nan
agent1:                 episode reward: 0.6249,                 loss: 0.2474
Episode: 5261/10000 (52.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2679s / 61.4651 s
agent0:                 episode reward: -0.6669,                 loss: nan
agent1:                 episode reward: 0.6669,                 loss: 0.2453
Episode: 5281/10000 (52.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2671s / 61.7322 s
agent0:                 episode reward: -0.7177,                 loss: nan
agent1:                 episode reward: 0.7177,                 loss: 0.2449
Episode: 5301/10000 (53.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2726s / 62.0048 s
agent0:                 episode reward: -0.6824,                 loss: nan
agent1:                 episode reward: 0.6824,                 loss: 0.2465
Episode: 5321/10000 (53.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2700s / 62.2748 s
agent0:                 episode reward: -0.8057,                 loss: nan
agent1:                 episode reward: 0.8057,                 loss: 0.2460
Episode: 5341/10000 (53.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2660s / 62.5408 s
agent0:                 episode reward: -0.7750,                 loss: nan
agent1:                 episode reward: 0.7750,                 loss: 0.2467
Episode: 5361/10000 (53.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2700s / 62.8108 s
agent0:                 episode reward: -0.5813,                 loss: nan
agent1:                 episode reward: 0.5813,                 loss: 0.2462
Episode: 5381/10000 (53.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2693s / 63.0801 s
agent0:                 episode reward: -0.9827,                 loss: nan
agent1:                 episode reward: 0.9827,                 loss: 0.2440
Episode: 5401/10000 (54.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2683s / 63.3484 s
agent0:                 episode reward: -0.8437,                 loss: nan
agent1:                 episode reward: 0.8437,                 loss: 0.2441
Episode: 5421/10000 (54.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2924s / 63.6408 s
agent0:                 episode reward: -0.9704,                 loss: nan
agent1:                 episode reward: 0.9704,                 loss: 0.2450
Episode: 5441/10000 (54.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2741s / 63.9149 s
agent0:                 episode reward: -1.0976,                 loss: nan
agent1:                 episode reward: 1.0976,                 loss: 0.2454
Episode: 5461/10000 (54.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2691s / 64.1840 s
agent0:                 episode reward: -0.7367,                 loss: nan
agent1:                 episode reward: 0.7367,                 loss: 0.2433
Episode: 5481/10000 (54.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2709s / 64.4549 s
agent0:                 episode reward: -0.4904,                 loss: nan
agent1:                 episode reward: 0.4904,                 loss: 0.2438
Episode: 5501/10000 (55.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2719s / 64.7268 s
agent0:                 episode reward: -0.7550,                 loss: nan
agent1:                 episode reward: 0.7550,                 loss: 0.2439
Episode: 5521/10000 (55.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3254s / 65.0522 s
agent0:                 episode reward: -1.0395,                 loss: nan
agent1:                 episode reward: 1.0395,                 loss: 0.2437
Episode: 5541/10000 (55.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2748s / 65.3271 s
agent0:                 episode reward: -0.8862,                 loss: nan
agent1:                 episode reward: 0.8862,                 loss: 0.2454
Episode: 5561/10000 (55.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2726s / 65.5997 s
agent0:                 episode reward: -1.2053,                 loss: nan
agent1:                 episode reward: 1.2053,                 loss: 0.2451
Episode: 5581/10000 (55.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2783s / 65.8781 s
agent0:                 episode reward: -0.7997,                 loss: nan
agent1:                 episode reward: 0.7997,                 loss: 0.2421
Episode: 5601/10000 (56.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2739s / 66.1520 s
agent0:                 episode reward: -0.3956,                 loss: nan
agent1:                 episode reward: 0.3956,                 loss: 0.2386
Episode: 5621/10000 (56.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2725s / 66.4245 s
agent0:                 episode reward: -1.1320,                 loss: nan
agent1:                 episode reward: 1.1320,                 loss: 0.2369
Episode: 5641/10000 (56.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2842s / 66.7087 s
agent0:                 episode reward: -0.7983,                 loss: nan
agent1:                 episode reward: 0.7983,                 loss: 0.2420
Episode: 5661/10000 (56.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2781s / 66.9868 s
agent0:                 episode reward: -0.6110,                 loss: nan
agent1:                 episode reward: 0.6110,                 loss: 0.2420
Episode: 5681/10000 (56.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2735s / 67.2603 s
agent0:                 episode reward: -1.0018,                 loss: nan
agent1:                 episode reward: 1.0018,                 loss: 0.2384
Episode: 5701/10000 (57.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2760s / 67.5364 s
agent0:                 episode reward: -0.4558,                 loss: nan
agent1:                 episode reward: 0.4558,                 loss: 0.2357
Episode: 5721/10000 (57.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2708s / 67.8072 s
agent0:                 episode reward: -0.4384,                 loss: nan
agent1:                 episode reward: 0.4384,                 loss: 0.2424
Episode: 5741/10000 (57.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2732s / 68.0803 s
agent0:                 episode reward: -0.5841,                 loss: nan
agent1:                 episode reward: 0.5841,                 loss: 0.2388
Episode: 5761/10000 (57.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2757s / 68.3561 s
agent0:                 episode reward: -0.7718,                 loss: nan
agent1:                 episode reward: 0.7718,                 loss: 0.2403
Episode: 5781/10000 (57.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2940s / 68.6500 s
agent0:                 episode reward: -0.6211,                 loss: nan
agent1:                 episode reward: 0.6211,                 loss: 0.2349
Episode: 5801/10000 (58.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2788s / 68.9288 s
agent0:                 episode reward: -0.8315,                 loss: nan
agent1:                 episode reward: 0.8315,                 loss: 0.2386
Episode: 5821/10000 (58.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2761s / 69.2049 s
agent0:                 episode reward: -0.6785,                 loss: nan
agent1:                 episode reward: 0.6785,                 loss: 0.2385
Episode: 5841/10000 (58.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2826s / 69.4875 s
agent0:                 episode reward: -0.5932,                 loss: nan
agent1:                 episode reward: 0.5932,                 loss: 0.2418
Episode: 5861/10000 (58.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3038s / 69.7913 s
agent0:                 episode reward: -0.8235,                 loss: nan
agent1:                 episode reward: 0.8235,                 loss: 0.2394
Episode: 5881/10000 (58.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2790s / 70.0703 s
agent0:                 episode reward: -1.2351,                 loss: nan
agent1:                 episode reward: 1.2351,                 loss: 0.2398
Episode: 5901/10000 (59.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2838s / 70.3542 s
agent0:                 episode reward: -0.8557,                 loss: nan
agent1:                 episode reward: 0.8557,                 loss: 0.2378
Episode: 5921/10000 (59.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2784s / 70.6326 s
agent0:                 episode reward: -0.5191,                 loss: nan
agent1:                 episode reward: 0.5191,                 loss: 0.2366
Episode: 5941/10000 (59.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2820s / 70.9146 s
agent0:                 episode reward: -0.6747,                 loss: nan
agent1:                 episode reward: 0.6747,                 loss: 0.2387
Episode: 5961/10000 (59.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2745s / 71.1891 s
agent0:                 episode reward: -0.7382,                 loss: nan
agent1:                 episode reward: 0.7382,                 loss: 0.2362
Episode: 5981/10000 (59.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2795s / 71.4686 s
agent0:                 episode reward: -0.6395,                 loss: nan
agent1:                 episode reward: 0.6395,                 loss: 0.2367
Episode: 6001/10000 (60.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2798s / 71.7484 s
agent0:                 episode reward: -0.9652,                 loss: nan
agent1:                 episode reward: 0.9652,                 loss: 0.2368
Episode: 6021/10000 (60.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2809s / 72.0293 s
agent0:                 episode reward: -0.7172,                 loss: nan
agent1:                 episode reward: 0.7172,                 loss: 0.2344
Episode: 6041/10000 (60.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2805s / 72.3097 s
agent0:                 episode reward: -1.1988,                 loss: nan
agent1:                 episode reward: 1.1988,                 loss: 0.2363
Episode: 6061/10000 (60.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2914s / 72.6011 s
agent0:                 episode reward: -0.9099,                 loss: nan
agent1:                 episode reward: 0.9099,                 loss: 0.2372
Episode: 6081/10000 (60.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2835s / 72.8845 s
agent0:                 episode reward: -0.6788,                 loss: nan
agent1:                 episode reward: 0.6788,                 loss: 0.2375
Episode: 6101/10000 (61.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2836s / 73.1682 s
agent0:                 episode reward: -0.5551,                 loss: nan
agent1:                 episode reward: 0.5551,                 loss: 0.2380
Episode: 6121/10000 (61.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2829s / 73.4510 s
agent0:                 episode reward: -0.8265,                 loss: nan
agent1:                 episode reward: 0.8265,                 loss: 0.2378
Episode: 6141/10000 (61.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2931s / 73.7441 s
agent0:                 episode reward: -0.7735,                 loss: nan
agent1:                 episode reward: 0.7735,                 loss: 0.2381
Episode: 6161/10000 (61.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2832s / 74.0273 s
agent0:                 episode reward: -0.9326,                 loss: nan
agent1:                 episode reward: 0.9326,                 loss: 0.2366
Episode: 6181/10000 (61.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2844s / 74.3117 s
agent0:                 episode reward: -0.6745,                 loss: nan
agent1:                 episode reward: 0.6745,                 loss: 0.2351
Episode: 6201/10000 (62.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2837s / 74.5954 s
agent0:                 episode reward: -0.7419,                 loss: nan
agent1:                 episode reward: 0.7419,                 loss: 0.2401
Episode: 6221/10000 (62.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2835s / 74.8789 s
agent0:                 episode reward: -0.6671,                 loss: nan
agent1:                 episode reward: 0.6671,                 loss: 0.2427
Episode: 6241/10000 (62.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3297s / 75.2087 s
agent0:                 episode reward: -0.6728,                 loss: nan
agent1:                 episode reward: 0.6728,                 loss: 0.2495
Episode: 6261/10000 (62.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2858s / 75.4945 s
agent0:                 episode reward: -0.7352,                 loss: nan
agent1:                 episode reward: 0.7352,                 loss: 0.2490
Episode: 6281/10000 (62.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2932s / 75.7877 s
agent0:                 episode reward: -0.9488,                 loss: nan
agent1:                 episode reward: 0.9488,                 loss: 0.2471
Episode: 6301/10000 (63.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2833s / 76.0710 s
agent0:                 episode reward: -1.0286,                 loss: nan
agent1:                 episode reward: 1.0286,                 loss: 0.2461
Episode: 6321/10000 (63.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3101s / 76.3811 s
agent0:                 episode reward: -0.8914,                 loss: nan
agent1:                 episode reward: 0.8914,                 loss: 0.2480
Episode: 6341/10000 (63.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2851s / 76.6662 s
agent0:                 episode reward: -0.6156,                 loss: nan
agent1:                 episode reward: 0.6156,                 loss: 0.2495
Episode: 6361/10000 (63.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3054s / 76.9716 s
agent0:                 episode reward: -0.9773,                 loss: nan
agent1:                 episode reward: 0.9773,                 loss: 0.2516
Episode: 6381/10000 (63.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2838s / 77.2553 s
agent0:                 episode reward: -0.7354,                 loss: nan
agent1:                 episode reward: 0.7354,                 loss: 0.2538
Episode: 6401/10000 (64.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2828s / 77.5382 s
agent0:                 episode reward: -0.5828,                 loss: nan
agent1:                 episode reward: 0.5828,                 loss: 0.2506
Episode: 6421/10000 (64.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3369s / 77.8751 s
agent0:                 episode reward: -0.7391,                 loss: nan
agent1:                 episode reward: 0.7391,                 loss: 0.2525
Episode: 6441/10000 (64.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2863s / 78.1614 s
agent0:                 episode reward: -0.8708,                 loss: nan
agent1:                 episode reward: 0.8708,                 loss: 0.2501
Episode: 6461/10000 (64.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2832s / 78.4446 s
agent0:                 episode reward: -0.8773,                 loss: nan
agent1:                 episode reward: 0.8773,                 loss: 0.2504
Episode: 6481/10000 (64.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2971s / 78.7417 s
agent0:                 episode reward: -0.8208,                 loss: nan
agent1:                 episode reward: 0.8208,                 loss: 0.2477
Episode: 6501/10000 (65.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2862s / 79.0279 s
agent0:                 episode reward: -0.6332,                 loss: nan
agent1:                 episode reward: 0.6332,                 loss: 0.2484
Episode: 6521/10000 (65.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2822s / 79.3101 s
agent0:                 episode reward: -0.5949,                 loss: nan
agent1:                 episode reward: 0.5949,                 loss: 0.2501
Episode: 6541/10000 (65.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2866s / 79.5967 s
agent0:                 episode reward: -0.9999,                 loss: nan
agent1:                 episode reward: 0.9999,                 loss: 0.2474
Episode: 6561/10000 (65.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2898s / 79.8865 s
agent0:                 episode reward: -1.1332,                 loss: nan
agent1:                 episode reward: 1.1332,                 loss: 0.2442
Episode: 6581/10000 (65.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2870s / 80.1735 s
agent0:                 episode reward: -0.7949,                 loss: nan
agent1:                 episode reward: 0.7949,                 loss: 0.2438
Episode: 6601/10000 (66.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2867s / 80.4602 s
agent0:                 episode reward: -0.9077,                 loss: nan
agent1:                 episode reward: 0.9077,                 loss: 0.2399
Episode: 6621/10000 (66.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2942s / 80.7544 s
agent0:                 episode reward: -0.6164,                 loss: nan
agent1:                 episode reward: 0.6164,                 loss: 0.2382
Episode: 6641/10000 (66.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2868s / 81.0413 s
agent0:                 episode reward: -0.7881,                 loss: nan
agent1:                 episode reward: 0.7881,                 loss: 0.2413
Episode: 6661/10000 (66.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2913s / 81.3325 s
agent0:                 episode reward: -1.1788,                 loss: nan
agent1:                 episode reward: 1.1788,                 loss: 0.2430
Episode: 6681/10000 (66.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2982s / 81.6307 s
agent0:                 episode reward: -0.9639,                 loss: nan
agent1:                 episode reward: 0.9639,                 loss: 0.2392
Episode: 6701/10000 (67.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2901s / 81.9209 s
agent0:                 episode reward: -0.6331,                 loss: nan
agent1:                 episode reward: 0.6331,                 loss: 0.2427
Episode: 6721/10000 (67.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2895s / 82.2103 s
agent0:                 episode reward: -0.7668,                 loss: nan
agent1:                 episode reward: 0.7668,                 loss: 0.2404
Episode: 6741/10000 (67.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2903s / 82.5006 s
agent0:                 episode reward: -1.2463,                 loss: nan
agent1:                 episode reward: 1.2463,                 loss: 0.2422
Episode: 6761/10000 (67.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2907s / 82.7914 s
agent0:                 episode reward: -0.9799,                 loss: nan
agent1:                 episode reward: 0.9799,                 loss: 0.2429
Episode: 6781/10000 (67.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2923s / 83.0837 s
agent0:                 episode reward: -0.8016,                 loss: nan
agent1:                 episode reward: 0.8016,                 loss: 0.2423
Episode: 6801/10000 (68.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2935s / 83.3772 s
agent0:                 episode reward: -0.8189,                 loss: nan
agent1:                 episode reward: 0.8189,                 loss: 0.2427
Episode: 6821/10000 (68.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2930s / 83.6702 s
agent0:                 episode reward: -1.0093,                 loss: nan
agent1:                 episode reward: 1.0093,                 loss: 0.2400
Episode: 6841/10000 (68.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3050s / 83.9751 s
agent0:                 episode reward: -0.7174,                 loss: nan
agent1:                 episode reward: 0.7174,                 loss: 0.2375
Episode: 6861/10000 (68.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2946s / 84.2697 s
agent0:                 episode reward: -0.7614,                 loss: nan
agent1:                 episode reward: 0.7614,                 loss: 0.2409
Episode: 6881/10000 (68.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2970s / 84.5667 s
agent0:                 episode reward: -0.9313,                 loss: nan
agent1:                 episode reward: 0.9313,                 loss: 0.2417
Episode: 6901/10000 (69.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3005s / 84.8672 s
agent0:                 episode reward: -0.8605,                 loss: nan
agent1:                 episode reward: 0.8605,                 loss: 0.2455
Episode: 6921/10000 (69.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2906s / 85.1578 s
agent0:                 episode reward: -0.5103,                 loss: nan
agent1:                 episode reward: 0.5103,                 loss: 0.2434
Episode: 6941/10000 (69.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3624s / 85.5202 s
agent0:                 episode reward: -0.9371,                 loss: nan
agent1:                 episode reward: 0.9371,                 loss: 0.2424
Episode: 6961/10000 (69.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2956s / 85.8158 s
agent0:                 episode reward: -0.6131,                 loss: nan
agent1:                 episode reward: 0.6131,                 loss: 0.2417
Episode: 6981/10000 (69.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2933s / 86.1092 s
agent0:                 episode reward: -0.8905,                 loss: nan
agent1:                 episode reward: 0.8905,                 loss: 0.2460
Episode: 7001/10000 (70.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2978s / 86.4069 s
agent0:                 episode reward: -1.0984,                 loss: nan
agent1:                 episode reward: 1.0984,                 loss: 0.2403
Episode: 7021/10000 (70.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2955s / 86.7024 s
agent0:                 episode reward: -0.5668,                 loss: nan
agent1:                 episode reward: 0.5668,                 loss: 0.2421
Episode: 7041/10000 (70.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2925s / 86.9949 s
agent0:                 episode reward: -0.5475,                 loss: nan
agent1:                 episode reward: 0.5475,                 loss: 0.2428
Episode: 7061/10000 (70.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2962s / 87.2912 s
agent0:                 episode reward: -0.8387,                 loss: nan
agent1:                 episode reward: 0.8387,                 loss: 0.2455
Episode: 7081/10000 (70.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3060s / 87.5972 s
agent0:                 episode reward: -0.8334,                 loss: nan
agent1:                 episode reward: 0.8334,                 loss: 0.2421
Episode: 7101/10000 (71.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3186s / 87.9158 s
agent0:                 episode reward: -0.6309,                 loss: nan
agent1:                 episode reward: 0.6309,                 loss: 0.2386
Episode: 7121/10000 (71.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3002s / 88.2159 s
agent0:                 episode reward: -0.9722,                 loss: nan
agent1:                 episode reward: 0.9722,                 loss: 0.2439
Episode: 7141/10000 (71.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2932s / 88.5092 s
agent0:                 episode reward: -0.6824,                 loss: nan
agent1:                 episode reward: 0.6824,                 loss: 0.2426
Episode: 7161/10000 (71.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2967s / 88.8059 s
agent0:                 episode reward: -0.8473,                 loss: nan
agent1:                 episode reward: 0.8473,                 loss: 0.2406
Episode: 7181/10000 (71.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2987s / 89.1046 s
agent0:                 episode reward: -0.8067,                 loss: nan
agent1:                 episode reward: 0.8067,                 loss: 0.2411
Episode: 7201/10000 (72.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2982s / 89.4028 s
agent0:                 episode reward: -1.1034,                 loss: nan
agent1:                 episode reward: 1.1034,                 loss: 0.2444
Episode: 7221/10000 (72.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3011s / 89.7038 s
agent0:                 episode reward: -0.9700,                 loss: nan
agent1:                 episode reward: 0.9700,                 loss: 0.2475
Episode: 7241/10000 (72.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3006s / 90.0044 s
agent0:                 episode reward: -0.6715,                 loss: nan
agent1:                 episode reward: 0.6715,                 loss: 0.2526
Episode: 7261/10000 (72.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2997s / 90.3041 s
agent0:                 episode reward: -0.9873,                 loss: nan
agent1:                 episode reward: 0.9873,                 loss: 0.2487
Episode: 7281/10000 (72.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2994s / 90.6035 s
agent0:                 episode reward: -1.1293,                 loss: nan
agent1:                 episode reward: 1.1293,                 loss: 0.2495
Episode: 7301/10000 (73.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3018s / 90.9053 s
agent0:                 episode reward: -0.8689,                 loss: nan
agent1:                 episode reward: 0.8689,                 loss: 0.2529
Episode: 7321/10000 (73.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2962s / 91.2015 s
agent0:                 episode reward: -0.9708,                 loss: nan
agent1:                 episode reward: 0.9708,                 loss: 0.2482
Episode: 7341/10000 (73.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2995s / 91.5010 s
agent0:                 episode reward: -0.9623,                 loss: nan
agent1:                 episode reward: 0.9623,                 loss: 0.2493
Episode: 7361/10000 (73.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3062s / 91.8072 s
agent0:                 episode reward: -0.9079,                 loss: nan
agent1:                 episode reward: 0.9079,                 loss: 0.2524
Episode: 7381/10000 (73.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2977s / 92.1049 s
agent0:                 episode reward: -0.6331,                 loss: nan
agent1:                 episode reward: 0.6331,                 loss: 0.2499
Episode: 7401/10000 (74.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2999s / 92.4048 s
agent0:                 episode reward: -0.8615,                 loss: nan
agent1:                 episode reward: 0.8615,                 loss: 0.2485
Episode: 7421/10000 (74.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2963s / 92.7011 s
agent0:                 episode reward: -0.5145,                 loss: nan
agent1:                 episode reward: 0.5145,                 loss: 0.2456
Episode: 7441/10000 (74.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2997s / 93.0008 s
agent0:                 episode reward: -1.1531,                 loss: nan
agent1:                 episode reward: 1.1531,                 loss: 0.2492
Episode: 7461/10000 (74.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3044s / 93.3051 s
agent0:                 episode reward: -0.7752,                 loss: nan
agent1:                 episode reward: 0.7752,                 loss: 0.2480
Episode: 7481/10000 (74.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3230s / 93.6282 s
agent0:                 episode reward: -0.8549,                 loss: nan
agent1:                 episode reward: 0.8549,                 loss: 0.2474
Episode: 7501/10000 (75.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3160s / 93.9442 s
agent0:                 episode reward: -0.9323,                 loss: nan
agent1:                 episode reward: 0.9323,                 loss: 0.2498
Episode: 7521/10000 (75.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3025s / 94.2467 s
agent0:                 episode reward: -1.0112,                 loss: nan
agent1:                 episode reward: 1.0112,                 loss: 0.2520
Episode: 7541/10000 (75.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3069s / 94.5536 s
agent0:                 episode reward: -0.6150,                 loss: nan
agent1:                 episode reward: 0.6150,                 loss: 0.2475
Episode: 7561/10000 (75.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3016s / 94.8553 s
agent0:                 episode reward: -0.9922,                 loss: nan
agent1:                 episode reward: 0.9922,                 loss: 0.2439
Episode: 7581/10000 (75.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3005s / 95.1558 s
agent0:                 episode reward: -0.9556,                 loss: nan
agent1:                 episode reward: 0.9556,                 loss: 0.2405
Episode: 7601/10000 (76.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3004s / 95.4562 s
agent0:                 episode reward: -1.2760,                 loss: nan
agent1:                 episode reward: 1.2760,                 loss: 0.2418
Episode: 7621/10000 (76.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3435s / 95.7998 s
agent0:                 episode reward: -1.1680,                 loss: nan
agent1:                 episode reward: 1.1680,                 loss: 0.2419
Episode: 7641/10000 (76.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3102s / 96.1099 s
agent0:                 episode reward: -1.1018,                 loss: nan
agent1:                 episode reward: 1.1018,                 loss: 0.2381
Episode: 7661/10000 (76.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3070s / 96.4169 s
agent0:                 episode reward: -0.8317,                 loss: nan
agent1:                 episode reward: 0.8317,                 loss: 0.2414
Episode: 7681/10000 (76.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3116s / 96.7286 s
agent0:                 episode reward: -0.7081,                 loss: nan
agent1:                 episode reward: 0.7081,                 loss: 0.2403
Episode: 7701/10000 (77.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3024s / 97.0309 s
agent0:                 episode reward: -0.9338,                 loss: nan
agent1:                 episode reward: 0.9338,                 loss: 0.2449
Episode: 7721/10000 (77.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3066s / 97.3376 s
agent0:                 episode reward: -0.9081,                 loss: nan
agent1:                 episode reward: 0.9081,                 loss: 0.2428
Episode: 7741/10000 (77.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3051s / 97.6427 s
agent0:                 episode reward: -0.9970,                 loss: nan
agent1:                 episode reward: 0.9970,                 loss: 0.2453
Episode: 7761/10000 (77.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2987s / 97.9414 s
agent0:                 episode reward: -0.9780,                 loss: nan
agent1:                 episode reward: 0.9780,                 loss: 0.2403
Episode: 7781/10000 (77.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3034s / 98.2448 s
agent0:                 episode reward: -0.5992,                 loss: nan
agent1:                 episode reward: 0.5992,                 loss: 0.2433
Episode: 7801/10000 (78.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3090s / 98.5538 s
agent0:                 episode reward: -0.8845,                 loss: nan
agent1:                 episode reward: 0.8845,                 loss: 0.2431
Episode: 7821/10000 (78.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3071s / 98.8608 s
agent0:                 episode reward: -0.8531,                 loss: nan
agent1:                 episode reward: 0.8531,                 loss: 0.2420
Episode: 7841/10000 (78.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3034s / 99.1642 s
agent0:                 episode reward: -1.0053,                 loss: nan
agent1:                 episode reward: 1.0053,                 loss: 0.2428
Episode: 7861/10000 (78.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3096s / 99.4738 s
agent0:                 episode reward: -0.9082,                 loss: nan
agent1:                 episode reward: 0.9082,                 loss: 0.2420
Episode: 7881/10000 (78.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3229s / 99.7967 s
agent0:                 episode reward: -0.9175,                 loss: nan
agent1:                 episode reward: 0.9175,                 loss: 0.2424
Episode: 7901/10000 (79.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3038s / 100.1005 s
agent0:                 episode reward: -0.7501,                 loss: nan
agent1:                 episode reward: 0.7501,                 loss: 0.2454
Episode: 7921/10000 (79.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3046s / 100.4051 s
agent0:                 episode reward: -0.9218,                 loss: nan
agent1:                 episode reward: 0.9218,                 loss: 0.2489
Episode: 7941/10000 (79.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3049s / 100.7100 s
agent0:                 episode reward: -1.0940,                 loss: nan
agent1:                 episode reward: 1.0940,                 loss: 0.2458
Episode: 7961/10000 (79.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3321s / 101.0421 s
agent0:                 episode reward: -0.6384,                 loss: nan
agent1:                 episode reward: 0.6384,                 loss: 0.2442
Episode: 7981/10000 (79.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3085s / 101.3506 s
agent0:                 episode reward: -0.8115,                 loss: nan
agent1:                 episode reward: 0.8115,                 loss: 0.2420
Episode: 8001/10000 (80.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3080s / 101.6586 s
agent0:                 episode reward: -0.8445,                 loss: nan
agent1:                 episode reward: 0.8445,                 loss: 0.2479
Episode: 8021/10000 (80.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3263s / 101.9849 s
agent0:                 episode reward: -1.2064,                 loss: nan
agent1:                 episode reward: 1.2064,                 loss: 0.2481
Episode: 8041/10000 (80.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3117s / 102.2966 s
agent0:                 episode reward: -1.0187,                 loss: nan
agent1:                 episode reward: 1.0187,                 loss: 0.2445
Episode: 8061/10000 (80.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3023s / 102.5989 s
agent0:                 episode reward: -0.9325,                 loss: nan
agent1:                 episode reward: 0.9325,                 loss: 0.2463
Episode: 8081/10000 (80.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3166s / 102.9155 s
agent0:                 episode reward: -1.0659,                 loss: nan
agent1:                 episode reward: 1.0659,                 loss: 0.2471
Episode: 8101/10000 (81.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3086s / 103.2242 s
agent0:                 episode reward: -1.0411,                 loss: nan
agent1:                 episode reward: 1.0411,                 loss: 0.2437
Episode: 8121/10000 (81.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3102s / 103.5344 s
agent0:                 episode reward: -1.0922,                 loss: nan
agent1:                 episode reward: 1.0922,                 loss: 0.2437
Episode: 8141/10000 (81.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3058s / 103.8401 s
agent0:                 episode reward: -0.9879,                 loss: nan
agent1:                 episode reward: 0.9879,                 loss: 0.2472
Episode: 8161/10000 (81.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3182s / 104.1584 s
agent0:                 episode reward: -0.6921,                 loss: nan
agent1:                 episode reward: 0.6921,                 loss: 0.2461
Episode: 8181/10000 (81.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3111s / 104.4695 s
agent0:                 episode reward: -0.7519,                 loss: nan
agent1:                 episode reward: 0.7519,                 loss: 0.2411
Episode: 8201/10000 (82.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3125s / 104.7820 s
agent0:                 episode reward: -0.6565,                 loss: nan
agent1:                 episode reward: 0.6565,                 loss: 0.2460
Episode: 8221/10000 (82.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3073s / 105.0893 s
agent0:                 episode reward: -0.8957,                 loss: nan
agent1:                 episode reward: 0.8957,                 loss: 0.2542
Episode: 8241/10000 (82.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3117s / 105.4010 s
agent0:                 episode reward: -1.1005,                 loss: nan
agent1:                 episode reward: 1.1005,                 loss: 0.2585
Episode: 8261/10000 (82.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3274s / 105.7284 s
agent0:                 episode reward: -1.1859,                 loss: nan
agent1:                 episode reward: 1.1859,                 loss: 0.2540
Episode: 8281/10000 (82.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3685s / 106.0969 s
agent0:                 episode reward: -0.9196,                 loss: nan
agent1:                 episode reward: 0.9196,                 loss: 0.2584
Episode: 8301/10000 (83.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3111s / 106.4080 s
agent0:                 episode reward: -0.9099,                 loss: nan
agent1:                 episode reward: 0.9099,                 loss: 0.2530
Episode: 8321/10000 (83.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3094s / 106.7174 s
agent0:                 episode reward: -0.9983,                 loss: nan
agent1:                 episode reward: 0.9983,                 loss: 0.2528
Episode: 8341/10000 (83.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3144s / 107.0317 s
agent0:                 episode reward: -0.8941,                 loss: nan
agent1:                 episode reward: 0.8941,                 loss: 0.2567
Episode: 8361/10000 (83.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3125s / 107.3442 s
agent0:                 episode reward: -0.7322,                 loss: nan
agent1:                 episode reward: 0.7322,                 loss: 0.2566
Episode: 8381/10000 (83.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3118s / 107.6560 s
agent0:                 episode reward: -0.6289,                 loss: nan
agent1:                 episode reward: 0.6289,                 loss: 0.2504
Episode: 8401/10000 (84.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3109s / 107.9669 s
agent0:                 episode reward: -0.7084,                 loss: nan
agent1:                 episode reward: 0.7084,                 loss: 0.2553
Episode: 8421/10000 (84.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3161s / 108.2830 s
agent0:                 episode reward: -0.6324,                 loss: nan
agent1:                 episode reward: 0.6324,                 loss: 0.2554
Episode: 8441/10000 (84.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3120s / 108.5949 s
agent0:                 episode reward: -0.8045,                 loss: nan
agent1:                 episode reward: 0.8045,                 loss: 0.2541
Episode: 8461/10000 (84.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3255s / 108.9204 s
agent0:                 episode reward: -1.2484,                 loss: nan
agent1:                 episode reward: 1.2484,                 loss: 0.2563
Episode: 8481/10000 (84.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3141s / 109.2345 s
agent0:                 episode reward: -0.5860,                 loss: nan
agent1:                 episode reward: 0.5860,                 loss: 0.2529
Episode: 8501/10000 (85.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3129s / 109.5474 s
agent0:                 episode reward: -0.7898,                 loss: nan
agent1:                 episode reward: 0.7898,                 loss: 0.2530
Episode: 8521/10000 (85.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3155s / 109.8629 s
agent0:                 episode reward: -0.7418,                 loss: nan
agent1:                 episode reward: 0.7418,                 loss: 0.2558
Episode: 8541/10000 (85.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3134s / 110.1763 s
agent0:                 episode reward: -1.0791,                 loss: nan
agent1:                 episode reward: 1.0791,                 loss: 0.2562
Episode: 8561/10000 (85.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3343s / 110.5106 s
agent0:                 episode reward: -1.1088,                 loss: nan
agent1:                 episode reward: 1.1088,                 loss: 0.2453
Episode: 8581/10000 (85.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3125s / 110.8231 s
agent0:                 episode reward: -0.9321,                 loss: nan
agent1:                 episode reward: 0.9321,                 loss: 0.2354
Episode: 8601/10000 (86.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3103s / 111.1334 s
agent0:                 episode reward: -0.4963,                 loss: nan
agent1:                 episode reward: 0.4963,                 loss: 0.2387
Episode: 8621/10000 (86.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3132s / 111.4467 s
agent0:                 episode reward: -1.1266,                 loss: nan
agent1:                 episode reward: 1.1266,                 loss: 0.2332
Episode: 8641/10000 (86.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3236s / 111.7703 s
agent0:                 episode reward: -0.5269,                 loss: nan
agent1:                 episode reward: 0.5269,                 loss: 0.2375
Episode: 8661/10000 (86.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3165s / 112.0868 s
agent0:                 episode reward: -1.1980,                 loss: nan
agent1:                 episode reward: 1.1980,                 loss: 0.2355
Episode: 8681/10000 (86.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3121s / 112.3989 s
agent0:                 episode reward: -0.7327,                 loss: nan
agent1:                 episode reward: 0.7327,                 loss: 0.2330
Episode: 8701/10000 (87.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3221s / 112.7211 s
agent0:                 episode reward: -0.7279,                 loss: nan
agent1:                 episode reward: 0.7279,                 loss: 0.2331
Episode: 8721/10000 (87.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3164s / 113.0375 s
agent0:                 episode reward: -0.8225,                 loss: nan
agent1:                 episode reward: 0.8225,                 loss: 0.2391
Episode: 8741/10000 (87.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3149s / 113.3524 s
agent0:                 episode reward: -0.6888,                 loss: nan
agent1:                 episode reward: 0.6888,                 loss: 0.2377
Episode: 8761/10000 (87.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3133s / 113.6657 s
agent0:                 episode reward: -0.8766,                 loss: nan
agent1:                 episode reward: 0.8766,                 loss: 0.2349
Episode: 8781/10000 (87.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3162s / 113.9819 s
agent0:                 episode reward: -0.7698,                 loss: nan
agent1:                 episode reward: 0.7698,                 loss: 0.2359
Episode: 8801/10000 (88.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3280s / 114.3099 s
agent0:                 episode reward: -0.6983,                 loss: nan
agent1:                 episode reward: 0.6983,                 loss: 0.2375
Episode: 8821/10000 (88.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3128s / 114.6227 s
agent0:                 episode reward: -1.1132,                 loss: nan
agent1:                 episode reward: 1.1132,                 loss: 0.2339
Episode: 8841/10000 (88.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3298s / 114.9525 s
agent0:                 episode reward: -0.9549,                 loss: nan
agent1:                 episode reward: 0.9549,                 loss: 0.2388
Episode: 8861/10000 (88.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3161s / 115.2687 s
agent0:                 episode reward: -0.6391,                 loss: nan
agent1:                 episode reward: 0.6391,                 loss: 0.2337
Episode: 8881/10000 (88.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3164s / 115.5851 s
agent0:                 episode reward: -0.8079,                 loss: nan
agent1:                 episode reward: 0.8079,                 loss: 0.2345
Episode: 8901/10000 (89.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3222s / 115.9073 s
agent0:                 episode reward: -0.6624,                 loss: nan
agent1:                 episode reward: 0.6624,                 loss: 0.2506
Episode: 8921/10000 (89.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3973s / 116.3046 s
agent0:                 episode reward: -1.2317,                 loss: nan
agent1:                 episode reward: 1.2317,                 loss: 0.2543
Episode: 8941/10000 (89.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3156s / 116.6202 s
agent0:                 episode reward: -0.8651,                 loss: nan
agent1:                 episode reward: 0.8651,                 loss: 0.2538
Episode: 8961/10000 (89.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3190s / 116.9392 s
agent0:                 episode reward: -0.7792,                 loss: nan
agent1:                 episode reward: 0.7792,                 loss: 0.2514
Episode: 8981/10000 (89.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3180s / 117.2572 s
agent0:                 episode reward: -0.9930,                 loss: nan
agent1:                 episode reward: 0.9930,                 loss: 0.2507
Episode: 9001/10000 (90.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3178s / 117.5750 s
agent0:                 episode reward: -0.5717,                 loss: nan
agent1:                 episode reward: 0.5717,                 loss: 0.2543
Episode: 9021/10000 (90.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3213s / 117.8963 s
agent0:                 episode reward: -1.0836,                 loss: nan
agent1:                 episode reward: 1.0836,                 loss: 0.2536
Episode: 9041/10000 (90.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3241s / 118.2204 s
agent0:                 episode reward: -0.8316,                 loss: nan
agent1:                 episode reward: 0.8316,                 loss: 0.2509
Episode: 9061/10000 (90.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3333s / 118.5537 s
agent0:                 episode reward: -0.9137,                 loss: nan
agent1:                 episode reward: 0.9137,                 loss: 0.2524
Episode: 9081/10000 (90.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3229s / 118.8765 s
agent0:                 episode reward: -0.7983,                 loss: nan
agent1:                 episode reward: 0.7983,                 loss: 0.2505
Episode: 9101/10000 (91.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3246s / 119.2011 s
agent0:                 episode reward: -0.7064,                 loss: nan
agent1:                 episode reward: 0.7064,                 loss: 0.2532
Episode: 9121/10000 (91.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3225s / 119.5236 s
agent0:                 episode reward: -0.8454,                 loss: nan
agent1:                 episode reward: 0.8454,                 loss: 0.2509
Episode: 9141/10000 (91.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3194s / 119.8430 s
agent0:                 episode reward: -0.9065,                 loss: nan
agent1:                 episode reward: 0.9065,                 loss: 0.2528
Episode: 9161/10000 (91.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3190s / 120.1620 s
agent0:                 episode reward: -0.7801,                 loss: nan
agent1:                 episode reward: 0.7801,                 loss: 0.2552
Episode: 9181/10000 (91.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3204s / 120.4824 s
agent0:                 episode reward: -0.8209,                 loss: nan
agent1:                 episode reward: 0.8209,                 loss: 0.2503
Episode: 9201/10000 (92.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3355s / 120.8180 s
agent0:                 episode reward: -1.1982,                 loss: nan
agent1:                 episode reward: 1.1982,                 loss: 0.2504
Episode: 9221/10000 (92.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3206s / 121.1386 s
agent0:                 episode reward: -0.9041,                 loss: nan
agent1:                 episode reward: 0.9041,                 loss: 0.2550
Episode: 9241/10000 (92.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3245s / 121.4631 s
agent0:                 episode reward: -0.8116,                 loss: nan
agent1:                 episode reward: 0.8116,                 loss: 0.2560
Episode: 9261/10000 (92.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3228s / 121.7859 s
agent0:                 episode reward: -1.0390,                 loss: nan
agent1:                 episode reward: 1.0390,                 loss: 0.2574
Episode: 9281/10000 (92.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3201s / 122.1060 s
agent0:                 episode reward: -0.7455,                 loss: nan
agent1:                 episode reward: 0.7455,                 loss: 0.2559
Episode: 9301/10000 (93.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3270s / 122.4331 s
agent0:                 episode reward: -0.9612,                 loss: nan
agent1:                 episode reward: 0.9612,                 loss: 0.2560
Episode: 9321/10000 (93.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3189s / 122.7519 s
agent0:                 episode reward: -0.8860,                 loss: nan
agent1:                 episode reward: 0.8860,                 loss: 0.2544
Episode: 9341/10000 (93.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3195s / 123.0714 s
agent0:                 episode reward: -0.9153,                 loss: nan
agent1:                 episode reward: 0.9153,                 loss: 0.2586
Episode: 9361/10000 (93.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3212s / 123.3927 s
agent0:                 episode reward: -1.0104,                 loss: nan
agent1:                 episode reward: 1.0104,                 loss: 0.2551
Episode: 9381/10000 (93.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3327s / 123.7253 s
agent0:                 episode reward: -0.8128,                 loss: nan
agent1:                 episode reward: 0.8128,                 loss: 0.2560
Episode: 9401/10000 (94.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3239s / 124.0492 s
agent0:                 episode reward: -0.4551,                 loss: nan
agent1:                 episode reward: 0.4551,                 loss: 0.2568
Episode: 9421/10000 (94.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3400s / 124.3892 s
agent0:                 episode reward: -1.1354,                 loss: nan
agent1:                 episode reward: 1.1354,                 loss: 0.2557
Episode: 9441/10000 (94.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3242s / 124.7134 s
agent0:                 episode reward: -1.1155,                 loss: nan
agent1:                 episode reward: 1.1155,                 loss: 0.2571
Episode: 9461/10000 (94.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3241s / 125.0375 s
agent0:                 episode reward: -0.7654,                 loss: nan
agent1:                 episode reward: 0.7654,                 loss: 0.2572
Episode: 9481/10000 (94.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3233s / 125.3608 s
agent0:                 episode reward: -1.0134,                 loss: nan
agent1:                 episode reward: 1.0134,                 loss: 0.2584
Episode: 9501/10000 (95.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3270s / 125.6879 s
agent0:                 episode reward: -0.7141,                 loss: nan
agent1:                 episode reward: 0.7141,                 loss: 0.2600
Episode: 9521/10000 (95.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3234s / 126.0112 s
agent0:                 episode reward: -0.5368,                 loss: nan
agent1:                 episode reward: 0.5368,                 loss: 0.2572
Episode: 9541/10000 (95.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3702s / 126.3815 s
agent0:                 episode reward: -0.8316,                 loss: nan
agent1:                 episode reward: 0.8316,                 loss: 0.2563
Episode: 9561/10000 (95.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3445s / 126.7260 s
agent0:                 episode reward: -0.8964,                 loss: nan
agent1:                 episode reward: 0.8964,                 loss: 0.2454
Episode: 9581/10000 (95.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3483s / 127.0743 s
agent0:                 episode reward: -0.6615,                 loss: nan
agent1:                 episode reward: 0.6615,                 loss: 0.2369
Episode: 9601/10000 (96.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3237s / 127.3980 s
agent0:                 episode reward: -1.1308,                 loss: nan
agent1:                 episode reward: 1.1308,                 loss: 0.2386
Episode: 9621/10000 (96.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3272s / 127.7251 s
agent0:                 episode reward: -0.8934,                 loss: nan
agent1:                 episode reward: 0.8934,                 loss: 0.2395
Episode: 9641/10000 (96.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3249s / 128.0500 s
agent0:                 episode reward: -0.9050,                 loss: nan
agent1:                 episode reward: 0.9050,                 loss: 0.2416
Episode: 9661/10000 (96.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3267s / 128.3767 s
agent0:                 episode reward: -0.9538,                 loss: nan
agent1:                 episode reward: 0.9538,                 loss: 0.2383
Episode: 9681/10000 (96.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3263s / 128.7030 s
agent0:                 episode reward: -1.1010,                 loss: nan
agent1:                 episode reward: 1.1010,                 loss: 0.2390
Episode: 9701/10000 (97.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3258s / 129.0288 s
agent0:                 episode reward: -1.0654,                 loss: nan
agent1:                 episode reward: 1.0654,                 loss: 0.2374
Episode: 9721/10000 (97.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3318s / 129.3606 s
agent0:                 episode reward: -1.0191,                 loss: nan
agent1:                 episode reward: 1.0191,                 loss: 0.2385
Episode: 9741/10000 (97.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3350s / 129.6956 s
agent0:                 episode reward: -0.7608,                 loss: nan
agent1:                 episode reward: 0.7608,                 loss: 0.2381
Episode: 9761/10000 (97.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3319s / 130.0274 s
agent0:                 episode reward: -0.8735,                 loss: nan
agent1:                 episode reward: 0.8735,                 loss: 0.2387
Episode: 9781/10000 (97.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3296s / 130.3570 s
agent0:                 episode reward: -0.5907,                 loss: nan
agent1:                 episode reward: 0.5907,                 loss: 0.2351
Episode: 9801/10000 (98.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3273s / 130.6843 s
agent0:                 episode reward: -0.9589,                 loss: nan
agent1:                 episode reward: 0.9589,                 loss: 0.2381
Episode: 9821/10000 (98.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3273s / 131.0116 s
agent0:                 episode reward: -0.6867,                 loss: nan
agent1:                 episode reward: 0.6867,                 loss: 0.2406
Episode: 9841/10000 (98.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3283s / 131.3399 s
agent0:                 episode reward: -0.9634,                 loss: nan
agent1:                 episode reward: 0.9634,                 loss: 0.2358
Episode: 9861/10000 (98.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3286s / 131.6685 s
agent0:                 episode reward: -0.9460,                 loss: nan
agent1:                 episode reward: 0.9460,                 loss: 0.2379/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

Episode: 9881/10000 (98.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3293s / 131.9978 s
agent0:                 episode reward: -0.7961,                 loss: nan
agent1:                 episode reward: 0.7961,                 loss: 0.2374
Episode: 9901/10000 (99.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3268s / 132.3246 s
agent0:                 episode reward: -1.0512,                 loss: nan
agent1:                 episode reward: 1.0512,                 loss: 0.2575
Episode: 9921/10000 (99.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3304s / 132.6550 s
agent0:                 episode reward: -0.7531,                 loss: nan
agent1:                 episode reward: 0.7531,                 loss: 0.2530
Episode: 9941/10000 (99.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3404s / 132.9954 s
agent0:                 episode reward: -0.8620,                 loss: nan
agent1:                 episode reward: 0.8620,                 loss: 0.2582
Episode: 9961/10000 (99.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3288s / 133.3242 s
agent0:                 episode reward: -1.1191,                 loss: nan
agent1:                 episode reward: 1.1191,                 loss: 0.2558
Episode: 9981/10000 (99.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3294s / 133.6536 s
agent0:                 episode reward: -0.8125,                 loss: nan
agent1:                 episode reward: 0.8125,                 loss: 0.2567
