/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
slimevolley_SlimeVolley-v0
default:  {'env_name': 'SlimeVolley-v0', 'env_type': 'slimevolley', 'num_envs': 5, 'ram': True, 'seed': 'random', 'record_video': False, 'against_baseline': False, 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'save_id': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'wandb_activate': False, 'wandb_entity': '', 'wandb_project': '', 'wandb_group': '', 'wandb_name': '', 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'psro', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'selfplay_score_delta': 3, 'trainable_agent_idx': 0, 'opponent_idx': 1}}
{'env_name': 'SlimeVolley-v0', 'env_type': 'slimevolley', 'num_envs': 5, 'ram': True, 'seed': 'random', 'record_video': False, 'against_baseline': False, 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'save_id': 202209252250, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'wandb_activate': False, 'wandb_entity': '', 'wandb_project': '', 'wandb_group': '', 'wandb_name': '', 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'psro', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'selfplay_score_delta': 3, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'load_id': 202209201541, 'to_exploit': 'first_1'}
SlimeVolley-v0 slimevolley
record video: interval 100, length 300
Load SlimeVolley-v0 environment in type slimevolley.
Env observation space: Box(-3.4028235e+38, 3.4028235e+38, (12,), float32) action space: Discrete(6)
random seed: 984
<mars.env.wrappers.mars_wrappers.Dict2TupleWrapper object at 0x7f9775303cc0>
discrete_policy 6 Discrete(6)
Traceback (most recent call last):
  File "general_exploit.py", line 48, in <module>
    launch()
  File "general_exploit.py", line 30, in launch
    trained_model = eval(args.algorithm)(env, args)
  File "/data/zihan/research/MARS/mars/rl/agents/dqn.py", line 19, in __init__
    self._init_model(env, args)
  File "/data/zihan/research/MARS/mars/rl/agents/dqn.py", line 38, in _init_model
    self.model = self._select_type(env, args).to(self.device)
  File "/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
slimevolley_SlimeVolley-v0
default:  {'env_name': 'SlimeVolley-v0', 'env_type': 'slimevolley', 'num_envs': 5, 'ram': True, 'seed': 'random', 'record_video': False, 'against_baseline': False, 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'save_id': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'wandb_activate': False, 'wandb_entity': '', 'wandb_project': '', 'wandb_group': '', 'wandb_name': '', 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'psro', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'selfplay_score_delta': 3, 'trainable_agent_idx': 0, 'opponent_idx': 1}}
{'env_name': 'SlimeVolley-v0', 'env_type': 'slimevolley', 'num_envs': 5, 'ram': True, 'seed': 'random', 'record_video': False, 'against_baseline': False, 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'save_id': 202209252254, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'wandb_activate': False, 'wandb_entity': '', 'wandb_project': '', 'wandb_group': '', 'wandb_name': '', 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'psro', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'selfplay_score_delta': 3, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'load_id': 202209201541, 'to_exploit': 'first_1'}
SlimeVolley-v0 slimevolley
record video: interval 100, length 300
Load SlimeVolley-v0 environment in type slimevolley.
Env observation space: Box(-3.4028235e+38, 3.4028235e+38, (12,), float32) action space: Discrete(6)
random seed: 621
<mars.env.wrappers.mars_wrappers.Dict2TupleWrapper object at 0x7f9ede7fde80>
discrete_policy 6 Discrete(6)
discrete_policy 6 Discrete(6)
discrete_policy 6 Discrete(6)
Agents No. [0] (index starting from 0) are not learnable.
Load meta strategy:  [array([0.   , 0.286, 0.   , 0.714]) array([0.429, 0.   , 0.571])]
Load checkpoints (policy family):  [list(['1032', '4082', '4803', '6301']) list(['2854', '4398', '5022'])]
Arguments:  {'env_name': 'SlimeVolley-v0', 'env_type': 'slimevolley', 'num_envs': 1, 'ram': True, 'seed': 'random', 'record_video': False, 'against_baseline': False, 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 50000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'save_id': 202209252254, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': './data/model/202209201541/slimevolley_SlimeVolley-v0_psro/', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'wandb_activate': False, 'wandb_entity': '', 'wandb_project': '', 'wandb_group': '', 'wandb_name': '', 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'psro', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'selfplay_score_delta': 3, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'load_id': 202209201541, 'to_exploit': 'first_1', 'idx_exploited_model': 0}
Save models to : /data/zihan/research/MARS/data/model/202209201541_exploit_first/slimevolley_SlimeVolley-v0_psro. 
 Save logs to: /data/zihan/research/MARS/data/log/202209201541_exploit_first/slimevolley_SlimeVolley-v0_psro.
Traceback (most recent call last):
  File "general_exploit.py", line 48, in <module>
    launch()
  File "general_exploit.py", line 45, in launch
    rollout(env, model, exploitation_args, save_id = str(args.load_id)+f'_exploit_{to_exploit}') # save results of exploitation in a separate folder
  File "/data/zihan/research/MARS/mars/rollout.py", line 21, in rollout
    rollout_normal(env, model, save_id, args)
  File "/data/zihan/research/MARS/mars/rollout.py", line 128, in rollout_normal
    obs_, reward, done, info = env.step(action)  # required action shape: (envs, agents, dim)
  File "/data/zihan/research/MARS/mars/env/wrappers/mars_wrappers.py", line 535, in step
    obs, rewards, dones, infos = self.env.step(actions)
  File "/data/zihan/research/MARS/mars/env/wrappers/mars_wrappers.py", line 475, in step
    obs0, reward, done, info = self.env.step(*actions_)  # gym!=0.18 will break this line
TypeError: step() takes 2 positional arguments but 3 were given
slimevolley_SlimeVolley-v0
default:  {'env_name': 'SlimeVolley-v0', 'env_type': 'slimevolley', 'num_envs': 5, 'ram': True, 'seed': 'random', 'record_video': False, 'against_baseline': False, 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'save_id': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'wandb_activate': False, 'wandb_entity': '', 'wandb_project': '', 'wandb_group': '', 'wandb_name': '', 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'psro', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'selfplay_score_delta': 3, 'trainable_agent_idx': 0, 'opponent_idx': 1}}
{'env_name': 'SlimeVolley-v0', 'env_type': 'slimevolley', 'num_envs': 5, 'ram': True, 'seed': 'random', 'record_video': False, 'against_baseline': False, 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'save_id': 202209252301, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'wandb_activate': False, 'wandb_entity': '', 'wandb_project': '', 'wandb_group': '', 'wandb_name': '', 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'psro', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'selfplay_score_delta': 3, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'load_id': 202209201541, 'to_exploit': 'first_1'}
SlimeVolley-v0 slimevolley
record video: interval 100, length 300
Load SlimeVolley-v0 environment in type slimevolley.
Env observation space: Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (12,), float32) action space: Discrete(6)
random seed: 337
<mars.env.wrappers.mars_wrappers.Dict2TupleWrapper object at 0x7f3c8939cb00>
discrete_policy 6 Discrete(6)
discrete_policy 6 Discrete(6)
discrete_policy 6 Discrete(6)
Agents No. [0] (index starting from 0) are not learnable.
Load meta strategy:  [array([0.   , 0.286, 0.   , 0.714]) array([0.429, 0.   , 0.571])]
Load checkpoints (policy family):  [list(['1032', '4082', '4803', '6301']) list(['2854', '4398', '5022'])]
Arguments:  {'env_name': 'SlimeVolley-v0', 'env_type': 'slimevolley', 'num_envs': 1, 'ram': True, 'seed': 'random', 'record_video': False, 'against_baseline': False, 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 50000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'save_id': 202209252301, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': './data/model/202209201541/slimevolley_SlimeVolley-v0_psro/', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'wandb_activate': False, 'wandb_entity': '', 'wandb_project': '', 'wandb_group': '', 'wandb_name': '', 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'psro', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'selfplay_score_delta': 3, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'load_id': 202209201541, 'to_exploit': 'first_1', 'idx_exploited_model': 0}
Save models to : /data/zihan/research/MARS/data/model/202209201541_exploit_first/slimevolley_SlimeVolley-v0_psro. 
 Save logs to: /data/zihan/research/MARS/data/log/202209201541_exploit_first/slimevolley_SlimeVolley-v0_psro.
Episode: 1/50000 (0.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 6.51s / 6.51 s
first_0:                 episode reward: 1.0000,                 loss: nan
second_0:                 episode reward: -1.0000,                 loss: 0.8384
Episode: 21/50000 (0.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 120.63s / 127.14 s
first_0:                 episode reward: 0.8500,                 loss: nan
second_0:                 episode reward: -0.8500,                 loss: 0.1722
Episode: 41/50000 (0.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 123.45s / 250.58 s
first_0:                 episode reward: 1.3500,                 loss: nan
second_0:                 episode reward: -1.3500,                 loss: 0.0546
Episode: 61/50000 (0.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 124.92s / 375.50 s
first_0:                 episode reward: 1.5000,                 loss: nan
second_0:                 episode reward: -1.5000,                 loss: 0.0543
Episode: 81/50000 (0.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 125.79s / 501.29 s
first_0:                 episode reward: 1.5500,                 loss: nan
second_0:                 episode reward: -1.5500,                 loss: 0.0520
Episode: 101/50000 (0.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 127.09s / 628.37 s
first_0:                 episode reward: 1.2000,                 loss: nan
second_0:                 episode reward: -1.2000,                 loss: 0.0516
Episode: 121/50000 (0.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 127.70s / 756.07 s
first_0:                 episode reward: 1.3000,                 loss: nan
second_0:                 episode reward: -1.3000,                 loss: 0.0565
Episode: 141/50000 (0.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 128.21s / 884.28 s
first_0:                 episode reward: 1.4500,                 loss: nan
second_0:                 episode reward: -1.4500,                 loss: 0.0653
Episode: 161/50000 (0.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 128.20s / 1012.48 s
first_0:                 episode reward: 1.3500,                 loss: nan
second_0:                 episode reward: -1.3500,                 loss: 0.0725
Episode: 181/50000 (0.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 129.36s / 1141.84 s
first_0:                 episode reward: 1.7500,                 loss: nan
second_0:                 episode reward: -1.7500,                 loss: 0.0749
Episode: 201/50000 (0.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 129.83s / 1271.67 s
first_0:                 episode reward: 1.2000,                 loss: nan
second_0:                 episode reward: -1.2000,                 loss: 0.0733
Episode: 221/50000 (0.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 129.98s / 1401.65 s
first_0:                 episode reward: 1.7500,                 loss: nan
second_0:                 episode reward: -1.7500,                 loss: 0.0715
Episode: 241/50000 (0.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 130.62s / 1532.26 s
first_0:                 episode reward: 1.2000,                 loss: nan
second_0:                 episode reward: -1.2000,                 loss: 0.0662
Episode: 261/50000 (0.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 130.30s / 1662.56 s
first_0:                 episode reward: 1.8500,                 loss: nan
second_0:                 episode reward: -1.8500,                 loss: 0.0572
Episode: 281/50000 (0.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 130.54s / 1793.11 s
first_0:                 episode reward: 1.7500,                 loss: nan
second_0:                 episode reward: -1.7500,                 loss: 0.0502
Episode: 301/50000 (0.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 131.22s / 1924.33 s
first_0:                 episode reward: 1.0500,                 loss: nan
second_0:                 episode reward: -1.0500,                 loss: 0.0464
Episode: 321/50000 (0.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 131.96s / 2056.29 s
first_0:                 episode reward: 1.5500,                 loss: nan
second_0:                 episode reward: -1.5500,                 loss: 0.0429
Episode: 341/50000 (0.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 131.42s / 2187.71 s
first_0:                 episode reward: 1.6000,                 loss: nan
second_0:                 episode reward: -1.6000,                 loss: 0.0444
Episode: 361/50000 (0.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 132.48s / 2320.19 s
first_0:                 episode reward: 1.9500,                 loss: nan
second_0:                 episode reward: -1.9500,                 loss: 0.0460
Episode: 381/50000 (0.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 133.12s / 2453.31 s
first_0:                 episode reward: 1.8500,                 loss: nan
second_0:                 episode reward: -1.8500,                 loss: 0.0468
Episode: 401/50000 (0.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 132.94s / 2586.24 s
first_0:                 episode reward: 1.3000,                 loss: nan
second_0:                 episode reward: -1.3000,                 loss: 0.0457
Episode: 421/50000 (0.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 132.93s / 2719.18 s
first_0:                 episode reward: 1.2500,                 loss: nan
second_0:                 episode reward: -1.2500,                 loss: 0.0458
Episode: 441/50000 (0.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 132.86s / 2852.04 s
first_0:                 episode reward: 1.0000,                 loss: nan
second_0:                 episode reward: -1.0000,                 loss: 0.0437
Episode: 461/50000 (0.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 133.12s / 2985.16 s
first_0:                 episode reward: 0.9500,                 loss: nan
second_0:                 episode reward: -0.9500,                 loss: 0.0421
Episode: 481/50000 (0.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 133.75s / 3118.91 s
first_0:                 episode reward: 1.7500,                 loss: nan
second_0:                 episode reward: -1.7500,                 loss: 0.0408
Episode: 501/50000 (1.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 133.11s / 3252.02 s
first_0:                 episode reward: 1.5000,                 loss: nan
second_0:                 episode reward: -1.5000,                 loss: 0.0404
Episode: 521/50000 (1.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 134.20s / 3386.22 s
first_0:                 episode reward: 1.0000,                 loss: nan
second_0:                 episode reward: -1.0000,                 loss: 0.0412
Episode: 541/50000 (1.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 133.59s / 3519.81 s
first_0:                 episode reward: 1.7000,                 loss: nan
second_0:                 episode reward: -1.7000,                 loss: 0.0407
Episode: 561/50000 (1.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 133.74s / 3653.55 s
first_0:                 episode reward: 0.9500,                 loss: nan
second_0:                 episode reward: -0.9500,                 loss: 0.0400
Episode: 581/50000 (1.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 134.31s / 3787.86 s
first_0:                 episode reward: 0.6000,                 loss: nan
second_0:                 episode reward: -0.6000,                 loss: 0.0389
Episode: 601/50000 (1.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 134.25s / 3922.11 s
first_0:                 episode reward: 1.1000,                 loss: nan
second_0:                 episode reward: -1.1000,                 loss: 0.0396
Episode: 621/50000 (1.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 134.40s / 4056.51 s
first_0:                 episode reward: 1.0500,                 loss: nan
second_0:                 episode reward: -1.0500,                 loss: 0.0392
Episode: 641/50000 (1.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 133.74s / 4190.25 s
first_0:                 episode reward: 0.9500,                 loss: nan
second_0:                 episode reward: -0.9500,                 loss: 0.0395
Episode: 661/50000 (1.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 134.00s / 4324.25 s
first_0:                 episode reward: 1.2500,                 loss: nan
second_0:                 episode reward: -1.2500,                 loss: 0.0391
Episode: 681/50000 (1.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 133.86s / 4458.10 s
first_0:                 episode reward: 0.5500,                 loss: nan
second_0:                 episode reward: -0.5500,                 loss: 0.0375
Episode: 701/50000 (1.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 134.05s / 4592.16 s
first_0:                 episode reward: 1.0500,                 loss: nan
second_0:                 episode reward: -1.0500,                 loss: 0.0377
Episode: 721/50000 (1.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 135.04s / 4727.20 s
first_0:                 episode reward: 1.2500,                 loss: nan
second_0:                 episode reward: -1.2500,                 loss: 0.0367
Episode: 741/50000 (1.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 134.23s / 4861.43 s
first_0:                 episode reward: 1.2000,                 loss: nan
second_0:                 episode reward: -1.2000,                 loss: 0.0375
Episode: 761/50000 (1.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 134.52s / 4995.95 s
first_0:                 episode reward: 0.9000,                 loss: nan
second_0:                 episode reward: -0.9000,                 loss: 0.0382
Episode: 781/50000 (1.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 134.38s / 5130.32 s
first_0:                 episode reward: 0.6500,                 loss: nan
second_0:                 episode reward: -0.6500,                 loss: 0.0379
Episode: 801/50000 (1.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 135.10s / 5265.43 s
first_0:                 episode reward: 1.0500,                 loss: nan
second_0:                 episode reward: -1.0500,                 loss: 0.0385
Episode: 821/50000 (1.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 134.35s / 5399.78 s
first_0:                 episode reward: 0.9000,                 loss: nan
second_0:                 episode reward: -0.9000,                 loss: 0.0387
Episode: 841/50000 (1.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 134.55s / 5534.33 s
first_0:                 episode reward: 1.2500,                 loss: nan
second_0:                 episode reward: -1.2500,                 loss: 0.0380
Episode: 861/50000 (1.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 135.43s / 5669.76 s
first_0:                 episode reward: 1.3500,                 loss: nan
second_0:                 episode reward: -1.3500,                 loss: 0.0382
Episode: 881/50000 (1.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 135.50s / 5805.26 s
first_0:                 episode reward: 0.7500,                 loss: nan
second_0:                 episode reward: -0.7500,                 loss: 0.0367
Episode: 901/50000 (1.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 135.58s / 5940.84 s
first_0:                 episode reward: 0.8000,                 loss: nan
second_0:                 episode reward: -0.8000,                 loss: 0.0364
Episode: 921/50000 (1.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 134.90s / 6075.74 s
first_0:                 episode reward: 1.0000,                 loss: nan
second_0:                 episode reward: -1.0000,                 loss: 0.0355
Episode: 941/50000 (1.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 135.45s / 6211.19 s
first_0:                 episode reward: 0.9500,                 loss: nan
second_0:                 episode reward: -0.9500,                 loss: 0.0365
Episode: 961/50000 (1.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 135.08s / 6346.27 s
first_0:                 episode reward: 1.1000,                 loss: nan
second_0:                 episode reward: -1.1000,                 loss: 0.0378
Episode: 981/50000 (1.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 135.44s / 6481.71 s
first_0:                 episode reward: 1.5000,                 loss: nan
second_0:                 episode reward: -1.5000,                 loss: 0.0377
Episode: 1001/50000 (2.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 134.81s / 6616.52 s
first_0:                 episode reward: 1.1000,                 loss: nan
second_0:                 episode reward: -1.1000,                 loss: 0.0378
Episode: 1021/50000 (2.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 135.23s / 6751.75 s
first_0:                 episode reward: 1.1000,                 loss: nan
second_0:                 episode reward: -1.1000,                 loss: 0.0375
Episode: 1041/50000 (2.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 135.00s / 6886.75 s
first_0:                 episode reward: 1.0000,                 loss: nan
second_0:                 episode reward: -1.0000,                 loss: 0.0373
Episode: 1061/50000 (2.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 135.90s / 7022.65 s
first_0:                 episode reward: 0.9500,                 loss: nan
second_0:                 episode reward: -0.9500,                 loss: 0.0368
Episode: 1081/50000 (2.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 136.00s / 7158.65 s
first_0:                 episode reward: 1.8000,                 loss: nan
second_0:                 episode reward: -1.8000,                 loss: 0.0363
Episode: 1101/50000 (2.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 135.42s / 7294.07 s
first_0:                 episode reward: 0.5500,                 loss: nan
second_0:                 episode reward: -0.5500,                 loss: 0.0370
Episode: 1121/50000 (2.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 134.95s / 7429.02 s
first_0:                 episode reward: 1.0000,                 loss: nan
second_0:                 episode reward: -1.0000,                 loss: 0.0359
Episode: 1141/50000 (2.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 135.14s / 7564.15 s
first_0:                 episode reward: 1.2000,                 loss: nan
second_0:                 episode reward: -1.2000,                 loss: 0.0362
Episode: 1161/50000 (2.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 135.70s / 7699.85 s
first_0:                 episode reward: 0.6000,                 loss: nan
second_0:                 episode reward: -0.6000,                 loss: 0.0370
Episode: 1181/50000 (2.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 134.57s / 7834.42 s
first_0:                 episode reward: 0.9000,                 loss: nan
second_0:                 episode reward: -0.9000,                 loss: 0.0371
Episode: 1201/50000 (2.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 135.87s / 7970.29 s
first_0:                 episode reward: 1.0000,                 loss: nan
second_0:                 episode reward: -1.0000,                 loss: 0.0371
Episode: 1221/50000 (2.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 135.24s / 8105.53 s
first_0:                 episode reward: 1.1500,                 loss: nan
second_0:                 episode reward: -1.1500,                 loss: 0.0372
Episode: 1241/50000 (2.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 135.22s / 8240.75 s
first_0:                 episode reward: 1.4000,                 loss: nan
second_0:                 episode reward: -1.4000,                 loss: 0.0374
Episode: 1261/50000 (2.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.33s / 8377.08 s
first_0:                 episode reward: 1.0500,                 loss: nan
second_0:                 episode reward: -1.0500,                 loss: 0.0375
Episode: 1281/50000 (2.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 135.24s / 8512.31 s
first_0:                 episode reward: 1.8500,                 loss: nan
second_0:                 episode reward: -1.8500,                 loss: 0.0394
Episode: 1301/50000 (2.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 135.20s / 8647.51 s
first_0:                 episode reward: 1.1500,                 loss: nan
second_0:                 episode reward: -1.1500,                 loss: 0.0385
Episode: 1321/50000 (2.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 134.94s / 8782.45 s
first_0:                 episode reward: 1.2500,                 loss: nan
second_0:                 episode reward: -1.2500,                 loss: 0.0397
Episode: 1341/50000 (2.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 135.37s / 8917.82 s
first_0:                 episode reward: 1.4000,                 loss: nan
second_0:                 episode reward: -1.4000,                 loss: 0.0395
Episode: 1361/50000 (2.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 135.92s / 9053.74 s
first_0:                 episode reward: 1.3000,                 loss: nan
second_0:                 episode reward: -1.3000,                 loss: 0.0399
Episode: 1381/50000 (2.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 135.93s / 9189.67 s
first_0:                 episode reward: 1.0500,                 loss: nan
second_0:                 episode reward: -1.0500,                 loss: 0.0395
Episode: 1401/50000 (2.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 135.09s / 9324.75 s
first_0:                 episode reward: 0.7000,                 loss: nan
second_0:                 episode reward: -0.7000,                 loss: 0.0402
Episode: 1421/50000 (2.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 135.44s / 9460.19 s
first_0:                 episode reward: 0.8500,                 loss: nan
second_0:                 episode reward: -0.8500,                 loss: 0.0407
Episode: 1441/50000 (2.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 135.23s / 9595.42 s
first_0:                 episode reward: 1.4000,                 loss: nan
second_0:                 episode reward: -1.4000,                 loss: 0.0406
Episode: 1461/50000 (2.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.23s / 9731.65 s
first_0:                 episode reward: 0.9500,                 loss: nan
second_0:                 episode reward: -0.9500,                 loss: 0.0405
Episode: 1481/50000 (2.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 135.43s / 9867.08 s
first_0:                 episode reward: 1.1500,                 loss: nan
second_0:                 episode reward: -1.1500,                 loss: 0.0397
Episode: 1501/50000 (3.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 135.29s / 10002.37 s
first_0:                 episode reward: 0.0000,                 loss: nan
second_0:                 episode reward: 0.0000,                 loss: 0.0396
Episode: 1521/50000 (3.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.20s / 10138.58 s
first_0:                 episode reward: 0.5500,                 loss: nan
second_0:                 episode reward: -0.5500,                 loss: 0.0393
Episode: 1541/50000 (3.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 135.43s / 10274.01 s
first_0:                 episode reward: 0.8500,                 loss: nan
second_0:                 episode reward: -0.8500,                 loss: 0.0397
Episode: 1561/50000 (3.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.15s / 10410.15 s
first_0:                 episode reward: 1.0500,                 loss: nan
second_0:                 episode reward: -1.0500,                 loss: 0.0379
Episode: 1581/50000 (3.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 136.11s / 10546.26 s
first_0:                 episode reward: 1.2500,                 loss: nan
second_0:                 episode reward: -1.2500,                 loss: 0.0375
Episode: 1601/50000 (3.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.63s / 10682.89 s
first_0:                 episode reward: 1.0000,                 loss: nan
second_0:                 episode reward: -1.0000,                 loss: 0.0390
Episode: 1621/50000 (3.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.40s / 10819.29 s
first_0:                 episode reward: 1.0000,                 loss: nan
second_0:                 episode reward: -1.0000,                 loss: 0.0392
Episode: 1641/50000 (3.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.30s / 10955.58 s
first_0:                 episode reward: 0.5000,                 loss: nan
second_0:                 episode reward: -0.5000,                 loss: 0.0384
Episode: 1661/50000 (3.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.56s / 11092.15 s
first_0:                 episode reward: 0.3000,                 loss: nan
second_0:                 episode reward: -0.3000,                 loss: 0.0397
Episode: 1681/50000 (3.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 136.47s / 11228.62 s
first_0:                 episode reward: 1.4500,                 loss: nan
second_0:                 episode reward: -1.4500,                 loss: 0.0398
Episode: 1701/50000 (3.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.30s / 11364.92 s
first_0:                 episode reward: 1.3500,                 loss: nan
second_0:                 episode reward: -1.3500,                 loss: 0.0390
Episode: 1721/50000 (3.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 135.66s / 11500.58 s
first_0:                 episode reward: 0.7500,                 loss: nan
second_0:                 episode reward: -0.7500,                 loss: 0.0377
Episode: 1741/50000 (3.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 135.67s / 11636.25 s
first_0:                 episode reward: 0.8000,                 loss: nan
second_0:                 episode reward: -0.8000,                 loss: 0.0371
Episode: 1761/50000 (3.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 135.45s / 11771.70 s
first_0:                 episode reward: 1.3000,                 loss: nan
second_0:                 episode reward: -1.3000,                 loss: 0.0377
Episode: 1781/50000 (3.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 136.20s / 11907.90 s
first_0:                 episode reward: 0.8000,                 loss: nan
second_0:                 episode reward: -0.8000,                 loss: 0.0377
Episode: 1801/50000 (3.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 135.34s / 12043.24 s
first_0:                 episode reward: 0.9000,                 loss: nan
second_0:                 episode reward: -0.9000,                 loss: 0.0371
Episode: 1821/50000 (3.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 135.84s / 12179.08 s
first_0:                 episode reward: 1.0000,                 loss: nan
second_0:                 episode reward: -1.0000,                 loss: 0.0384
Episode: 1841/50000 (3.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.50s / 12315.58 s
first_0:                 episode reward: 0.9000,                 loss: nan
second_0:                 episode reward: -0.9000,                 loss: 0.0387
Episode: 1861/50000 (3.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 135.86s / 12451.44 s
first_0:                 episode reward: 1.0500,                 loss: nan
second_0:                 episode reward: -1.0500,                 loss: 0.0373
Episode: 1881/50000 (3.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 135.29s / 12586.73 s
first_0:                 episode reward: 0.9500,                 loss: nan
second_0:                 episode reward: -0.9500,                 loss: 0.0382
Episode: 1901/50000 (3.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.34s / 12723.07 s
first_0:                 episode reward: 0.9500,                 loss: nan
second_0:                 episode reward: -0.9500,                 loss: 0.0390
Episode: 1921/50000 (3.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.67s / 12859.75 s
first_0:                 episode reward: 0.9000,                 loss: nan
second_0:                 episode reward: -0.9000,                 loss: 0.0403
Episode: 1941/50000 (3.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 135.71s / 12995.45 s
first_0:                 episode reward: 0.8000,                 loss: nan
second_0:                 episode reward: -0.8000,                 loss: 0.0393
Episode: 1961/50000 (3.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.63s / 13132.08 s
first_0:                 episode reward: 0.9500,                 loss: nan
second_0:                 episode reward: -0.9500,                 loss: 0.0390
Episode: 1981/50000 (3.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 136.15s / 13268.23 s
first_0:                 episode reward: 1.2500,                 loss: nan
second_0:                 episode reward: -1.2500,                 loss: 0.0385
Episode: 2001/50000 (4.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.64s / 13404.87 s
first_0:                 episode reward: 0.8500,                 loss: nan
second_0:                 episode reward: -0.8500,                 loss: 0.0386
Episode: 2021/50000 (4.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.40s / 13541.27 s
first_0:                 episode reward: 1.3000,                 loss: nan
second_0:                 episode reward: -1.3000,                 loss: 0.0379
Episode: 2041/50000 (4.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.49s / 13677.76 s
first_0:                 episode reward: 0.8000,                 loss: nan
second_0:                 episode reward: -0.8000,                 loss: 0.0381
Episode: 2061/50000 (4.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.30s / 13814.06 s
first_0:                 episode reward: 1.0500,                 loss: nan
second_0:                 episode reward: -1.0500,                 loss: 0.0383
Episode: 2081/50000 (4.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 135.50s / 13949.56 s
first_0:                 episode reward: 0.6000,                 loss: nan
second_0:                 episode reward: -0.6000,                 loss: 0.0390
Episode: 2101/50000 (4.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 135.83s / 14085.40 s
first_0:                 episode reward: 0.8500,                 loss: nan
second_0:                 episode reward: -0.8500,                 loss: 0.0389
Episode: 2121/50000 (4.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 135.43s / 14220.83 s
first_0:                 episode reward: 0.8500,                 loss: nan
second_0:                 episode reward: -0.8500,                 loss: 0.0390
Episode: 2141/50000 (4.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 137.13s / 14357.96 s
first_0:                 episode reward: 0.9500,                 loss: nan
second_0:                 episode reward: -0.9500,                 loss: 0.0388
Episode: 2161/50000 (4.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 135.82s / 14493.77 s
first_0:                 episode reward: 0.5500,                 loss: nan
second_0:                 episode reward: -0.5500,                 loss: 0.0383
Episode: 2181/50000 (4.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 135.68s / 14629.45 s
first_0:                 episode reward: 0.4000,                 loss: nan
second_0:                 episode reward: -0.4000,                 loss: 0.0379
Episode: 2201/50000 (4.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.50s / 14765.95 s
first_0:                 episode reward: 1.3000,                 loss: nan
second_0:                 episode reward: -1.3000,                 loss: 0.0388
Episode: 2221/50000 (4.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 135.64s / 14901.59 s
first_0:                 episode reward: 0.9000,                 loss: nan
second_0:                 episode reward: -0.9000,                 loss: 0.0392
Episode: 2241/50000 (4.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.82s / 15038.41 s
first_0:                 episode reward: 0.9000,                 loss: nan
second_0:                 episode reward: -0.9000,                 loss: 0.0383
Episode: 2261/50000 (4.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 135.94s / 15174.35 s
first_0:                 episode reward: 1.1500,                 loss: nan
second_0:                 episode reward: -1.1500,                 loss: 0.0390
Episode: 2281/50000 (4.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 135.82s / 15310.17 s
first_0:                 episode reward: 0.6000,                 loss: nan
second_0:                 episode reward: -0.6000,                 loss: 0.0391
Episode: 2301/50000 (4.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 137.09s / 15447.26 s
first_0:                 episode reward: 1.2000,                 loss: nan
second_0:                 episode reward: -1.2000,                 loss: 0.0396
Episode: 2321/50000 (4.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.76s / 15584.02 s
first_0:                 episode reward: 0.8500,                 loss: nan
second_0:                 episode reward: -0.8500,                 loss: 0.0381
Episode: 2341/50000 (4.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.79s / 15720.81 s
first_0:                 episode reward: 1.1000,                 loss: nan
second_0:                 episode reward: -1.1000,                 loss: 0.0381
Episode: 2361/50000 (4.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.38s / 15857.19 s
first_0:                 episode reward: 0.7000,                 loss: nan
second_0:                 episode reward: -0.7000,                 loss: 0.0379
Episode: 2381/50000 (4.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 135.08s / 15992.27 s
first_0:                 episode reward: 1.0000,                 loss: nan
second_0:                 episode reward: -1.0000,                 loss: 0.0391
Episode: 2401/50000 (4.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 135.00s / 16127.28 s
first_0:                 episode reward: 1.1500,                 loss: nan
second_0:                 episode reward: -1.1500,                 loss: 0.0389
Episode: 2421/50000 (4.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.03s / 16263.30 s
first_0:                 episode reward: 0.6500,                 loss: nan
second_0:                 episode reward: -0.6500,                 loss: 0.0389
Episode: 2441/50000 (4.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.23s / 16399.53 s
first_0:                 episode reward: 0.8500,                 loss: nan
second_0:                 episode reward: -0.8500,                 loss: 0.0374
Episode: 2461/50000 (4.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 135.65s / 16535.18 s
first_0:                 episode reward: 1.1500,                 loss: nan
second_0:                 episode reward: -1.1500,                 loss: 0.0374
Episode: 2481/50000 (4.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 135.62s / 16670.80 s
first_0:                 episode reward: 0.6500,                 loss: nan
second_0:                 episode reward: -0.6500,                 loss: 0.0358
Episode: 2501/50000 (5.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 135.26s / 16806.07 s
first_0:                 episode reward: 0.9500,                 loss: nan
second_0:                 episode reward: -0.9500,                 loss: 0.0366
Episode: 2521/50000 (5.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 135.29s / 16941.35 s
first_0:                 episode reward: 1.2000,                 loss: nan
second_0:                 episode reward: -1.2000,                 loss: 0.0364
Episode: 2541/50000 (5.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.20s / 17077.56 s
first_0:                 episode reward: 1.4500,                 loss: nan
second_0:                 episode reward: -1.4500,                 loss: 0.0368
Episode: 2561/50000 (5.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 135.81s / 17213.37 s
first_0:                 episode reward: 0.6000,                 loss: nan
second_0:                 episode reward: -0.6000,                 loss: 0.0369
Episode: 2581/50000 (5.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 136.04s / 17349.40 s
first_0:                 episode reward: 0.9000,                 loss: nan
second_0:                 episode reward: -0.9000,                 loss: 0.0371
Episode: 2601/50000 (5.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.17s / 17485.57 s
first_0:                 episode reward: 0.7500,                 loss: nan
second_0:                 episode reward: -0.7500,                 loss: 0.0379
Episode: 2621/50000 (5.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.11s / 17621.68 s
first_0:                 episode reward: 1.0000,                 loss: nan
second_0:                 episode reward: -1.0000,                 loss: 0.0379
Episode: 2641/50000 (5.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.05s / 17757.73 s
first_0:                 episode reward: 1.0000,                 loss: nan
second_0:                 episode reward: -1.0000,                 loss: 0.0388
Episode: 2661/50000 (5.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 135.51s / 17893.23 s
first_0:                 episode reward: 1.0000,                 loss: nan
second_0:                 episode reward: -1.0000,                 loss: 0.0387
Episode: 2681/50000 (5.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 135.98s / 18029.21 s
first_0:                 episode reward: 0.3000,                 loss: nan
second_0:                 episode reward: -0.3000,                 loss: 0.0389
Episode: 2701/50000 (5.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.78s / 18166.00 s
first_0:                 episode reward: 1.5500,                 loss: nan
second_0:                 episode reward: -1.5500,                 loss: 0.0387
Episode: 2721/50000 (5.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.35s / 18302.35 s
first_0:                 episode reward: 1.3500,                 loss: nan
second_0:                 episode reward: -1.3500,                 loss: 0.0396
Episode: 2741/50000 (5.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.31s / 18438.66 s
first_0:                 episode reward: 1.0500,                 loss: nan
second_0:                 episode reward: -1.0500,                 loss: 0.0406
Episode: 2761/50000 (5.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.27s / 18574.93 s
first_0:                 episode reward: 0.8500,                 loss: nan
second_0:                 episode reward: -0.8500,                 loss: 0.0411
Episode: 2781/50000 (5.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 136.08s / 18711.01 s
first_0:                 episode reward: 0.8000,                 loss: nan
second_0:                 episode reward: -0.8000,                 loss: 0.0397
Episode: 2801/50000 (5.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.43s / 18847.44 s
first_0:                 episode reward: 0.6000,                 loss: nan
second_0:                 episode reward: -0.6000,                 loss: 0.0390
Episode: 2821/50000 (5.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 135.77s / 18983.21 s
first_0:                 episode reward: 0.7000,                 loss: nan
second_0:                 episode reward: -0.7000,                 loss: 0.0398
Episode: 2841/50000 (5.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 137.28s / 19120.49 s
first_0:                 episode reward: 0.4000,                 loss: nan
second_0:                 episode reward: -0.4000,                 loss: 0.0382
Episode: 2861/50000 (5.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 135.79s / 19256.28 s
first_0:                 episode reward: 0.6000,                 loss: nan
second_0:                 episode reward: -0.6000,                 loss: 0.0398
Episode: 2881/50000 (5.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 136.45s / 19392.73 s
first_0:                 episode reward: 1.1000,                 loss: nan
second_0:                 episode reward: -1.1000,                 loss: 0.0378
Episode: 2901/50000 (5.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.41s / 19529.14 s
first_0:                 episode reward: 0.9000,                 loss: nan
second_0:                 episode reward: -0.9000,                 loss: 0.0387
Episode: 2921/50000 (5.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.16s / 19665.30 s
first_0:                 episode reward: 1.0000,                 loss: nan
second_0:                 episode reward: -1.0000,                 loss: 0.0389
Episode: 2941/50000 (5.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 137.81s / 19803.11 s
first_0:                 episode reward: 1.1500,                 loss: nan
second_0:                 episode reward: -1.1500,                 loss: 0.0390
Episode: 2961/50000 (5.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.02s / 19939.13 s
first_0:                 episode reward: 0.6500,                 loss: nan
second_0:                 episode reward: -0.6500,                 loss: 0.0390
Episode: 2981/50000 (5.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 136.49s / 20075.63 s
first_0:                 episode reward: 1.1000,                 loss: nan
second_0:                 episode reward: -1.1000,                 loss: 0.0376
Episode: 3001/50000 (6.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 134.93s / 20210.56 s
first_0:                 episode reward: 1.1000,                 loss: nan
second_0:                 episode reward: -1.1000,                 loss: 0.0383
Episode: 3021/50000 (6.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.20s / 20346.76 s
first_0:                 episode reward: 0.7000,                 loss: nan
second_0:                 episode reward: -0.7000,                 loss: 0.0382
Episode: 3041/50000 (6.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 135.79s / 20482.55 s
first_0:                 episode reward: 0.3500,                 loss: nan
second_0:                 episode reward: -0.3500,                 loss: 0.0382
Episode: 3061/50000 (6.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.27s / 20618.82 s
first_0:                 episode reward: 1.0500,                 loss: nan
second_0:                 episode reward: -1.0500,                 loss: 0.0374
Episode: 3081/50000 (6.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 136.91s / 20755.72 s
first_0:                 episode reward: 0.9000,                 loss: nan
second_0:                 episode reward: -0.9000,                 loss: 0.0374
Episode: 3101/50000 (6.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 135.92s / 20891.64 s
first_0:                 episode reward: 0.4500,                 loss: nan
second_0:                 episode reward: -0.4500,                 loss: 0.0374
Episode: 3121/50000 (6.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 135.76s / 21027.41 s
first_0:                 episode reward: 1.2000,                 loss: nan
second_0:                 episode reward: -1.2000,                 loss: 0.0385
Episode: 3141/50000 (6.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.62s / 21164.02 s
first_0:                 episode reward: 0.8000,                 loss: nan
second_0:                 episode reward: -0.8000,                 loss: 0.0369
Episode: 3161/50000 (6.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 135.64s / 21299.66 s
first_0:                 episode reward: 1.3500,                 loss: nan
second_0:                 episode reward: -1.3500,                 loss: 0.0366
Episode: 3181/50000 (6.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 135.87s / 21435.53 s
first_0:                 episode reward: 1.0000,                 loss: nan
second_0:                 episode reward: -1.0000,                 loss: 0.0352
Episode: 3201/50000 (6.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 135.43s / 21570.95 s
first_0:                 episode reward: 0.4000,                 loss: nan
second_0:                 episode reward: -0.4000,                 loss: 0.0381
Episode: 3221/50000 (6.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 135.54s / 21706.50 s
first_0:                 episode reward: 0.9500,                 loss: nan
second_0:                 episode reward: -0.9500,                 loss: 0.0383
Episode: 3241/50000 (6.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 135.75s / 21842.25 s
first_0:                 episode reward: 0.8500,                 loss: nan
second_0:                 episode reward: -0.8500,                 loss: 0.0382
Episode: 3261/50000 (6.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.86s / 21979.11 s
first_0:                 episode reward: 0.9000,                 loss: nan
second_0:                 episode reward: -0.9000,                 loss: 0.0380
Episode: 3281/50000 (6.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 136.80s / 22115.91 s
first_0:                 episode reward: 0.8500,                 loss: nan
second_0:                 episode reward: -0.8500,                 loss: 0.0388
Episode: 3301/50000 (6.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.38s / 22252.29 s
first_0:                 episode reward: 1.0500,                 loss: nan
second_0:                 episode reward: -1.0500,                 loss: 0.0384
Episode: 3321/50000 (6.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 135.55s / 22387.84 s
first_0:                 episode reward: 1.1000,                 loss: nan
second_0:                 episode reward: -1.1000,                 loss: 0.0374
Episode: 3341/50000 (6.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.05s / 22523.89 s
first_0:                 episode reward: 0.3500,                 loss: nan
second_0:                 episode reward: -0.3500,                 loss: 0.0370
Episode: 3361/50000 (6.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 135.40s / 22659.29 s
first_0:                 episode reward: 0.8500,                 loss: nan
second_0:                 episode reward: -0.8500,                 loss: 0.0371
Episode: 3381/50000 (6.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 135.96s / 22795.25 s
first_0:                 episode reward: 1.1000,                 loss: nan
second_0:                 episode reward: -1.1000,                 loss: 0.0375
Episode: 3401/50000 (6.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 135.56s / 22930.82 s
first_0:                 episode reward: 0.7500,                 loss: nan
second_0:                 episode reward: -0.7500,                 loss: 0.0376
Episode: 3421/50000 (6.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.21s / 23067.03 s
first_0:                 episode reward: 1.2000,                 loss: nan
second_0:                 episode reward: -1.2000,                 loss: 0.0378
Episode: 3441/50000 (6.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.13s / 23203.16 s
first_0:                 episode reward: 0.7500,                 loss: nan
second_0:                 episode reward: -0.7500,                 loss: 0.0385
Episode: 3461/50000 (6.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.66s / 23339.82 s
first_0:                 episode reward: 1.2000,                 loss: nan
second_0:                 episode reward: -1.2000,                 loss: 0.0382
Episode: 3481/50000 (6.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 136.55s / 23476.38 s
first_0:                 episode reward: 0.7000,                 loss: nan
second_0:                 episode reward: -0.7000,                 loss: 0.0384
Episode: 3501/50000 (7.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 135.87s / 23612.25 s
first_0:                 episode reward: 0.9500,                 loss: nan
second_0:                 episode reward: -0.9500,                 loss: 0.0387
Episode: 3521/50000 (7.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.83s / 23749.08 s
first_0:                 episode reward: 0.8000,                 loss: nan
second_0:                 episode reward: -0.8000,                 loss: 0.0374
Episode: 3541/50000 (7.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.14s / 23885.22 s
first_0:                 episode reward: 0.4000,                 loss: nan
second_0:                 episode reward: -0.4000,                 loss: 0.0372
Episode: 3561/50000 (7.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.55s / 24021.77 s
first_0:                 episode reward: 0.9500,                 loss: nan
second_0:                 episode reward: -0.9500,                 loss: 0.0381
Episode: 3581/50000 (7.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 135.74s / 24157.51 s
first_0:                 episode reward: 1.0000,                 loss: nan
second_0:                 episode reward: -1.0000,                 loss: 0.0376
Episode: 3601/50000 (7.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.76s / 24294.27 s
first_0:                 episode reward: 0.7500,                 loss: nan
second_0:                 episode reward: -0.7500,                 loss: 0.0390
Episode: 3621/50000 (7.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.25s / 24430.52 s
first_0:                 episode reward: 0.8000,                 loss: nan
second_0:                 episode reward: -0.8000,                 loss: 0.0380
Episode: 3641/50000 (7.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 135.96s / 24566.48 s
first_0:                 episode reward: 1.3000,                 loss: nan
second_0:                 episode reward: -1.3000,                 loss: 0.0382
Episode: 3661/50000 (7.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 135.63s / 24702.10 s
first_0:                 episode reward: 0.6500,                 loss: nan
second_0:                 episode reward: -0.6500,                 loss: 0.0381
Episode: 3681/50000 (7.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 135.49s / 24837.59 s
first_0:                 episode reward: 0.6500,                 loss: nan
second_0:                 episode reward: -0.6500,                 loss: 0.0387
Episode: 3701/50000 (7.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 137.09s / 24974.68 s
first_0:                 episode reward: 1.0500,                 loss: nan
second_0:                 episode reward: -1.0500,                 loss: 0.0388
Episode: 3721/50000 (7.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 135.78s / 25110.46 s
first_0:                 episode reward: 0.4000,                 loss: nan
second_0:                 episode reward: -0.4000,                 loss: 0.0395
Episode: 3741/50000 (7.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.93s / 25247.39 s
first_0:                 episode reward: 0.3000,                 loss: nan
second_0:                 episode reward: -0.3000,                 loss: 0.0391
Episode: 3761/50000 (7.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.72s / 25384.11 s
first_0:                 episode reward: 0.7000,                 loss: nan
second_0:                 episode reward: -0.7000,                 loss: 0.0390
Episode: 3781/50000 (7.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 136.58s / 25520.69 s
first_0:                 episode reward: 1.1000,                 loss: nan
second_0:                 episode reward: -1.1000,                 loss: 0.0388
Episode: 3801/50000 (7.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.26s / 25656.95 s
first_0:                 episode reward: 1.0000,                 loss: nan
second_0:                 episode reward: -1.0000,                 loss: 0.0388
Episode: 3821/50000 (7.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 135.97s / 25792.92 s
first_0:                 episode reward: 0.5500,                 loss: nan
second_0:                 episode reward: -0.5500,                 loss: 0.0383
Episode: 3841/50000 (7.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.00s / 25928.92 s
first_0:                 episode reward: 0.4500,                 loss: nan
second_0:                 episode reward: -0.4500,                 loss: 0.0376
Episode: 3861/50000 (7.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 137.21s / 26066.13 s
first_0:                 episode reward: 1.1000,                 loss: nan
second_0:                 episode reward: -1.1000,                 loss: 0.0377
Episode: 3881/50000 (7.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 136.18s / 26202.31 s
first_0:                 episode reward: 0.4000,                 loss: nan
second_0:                 episode reward: -0.4000,                 loss: 0.0371
Episode: 3901/50000 (7.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.45s / 26338.76 s
first_0:                 episode reward: 0.2000,                 loss: nan
second_0:                 episode reward: -0.2000,                 loss: 0.0361
Episode: 3921/50000 (7.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.10s / 26474.86 s
first_0:                 episode reward: 0.5000,                 loss: nan
second_0:                 episode reward: -0.5000,                 loss: 0.0366
Episode: 3941/50000 (7.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 135.67s / 26610.53 s
first_0:                 episode reward: 0.2500,                 loss: nan
second_0:                 episode reward: -0.2500,                 loss: 0.0370
Episode: 3961/50000 (7.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.65s / 26747.18 s
first_0:                 episode reward: 0.0000,                 loss: nan
second_0:                 episode reward: 0.0000,                 loss: 0.0366
Episode: 3981/50000 (7.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 135.96s / 26883.14 s
first_0:                 episode reward: 0.2500,                 loss: nan
second_0:                 episode reward: -0.2500,                 loss: 0.0381
Episode: 4001/50000 (8.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.41s / 27019.55 s
first_0:                 episode reward: 0.5500,                 loss: nan
second_0:                 episode reward: -0.5500,                 loss: 0.0374
Episode: 4021/50000 (8.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.70s / 27156.25 s
first_0:                 episode reward: 0.6000,                 loss: nan
second_0:                 episode reward: -0.6000,                 loss: 0.0373
Episode: 4041/50000 (8.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 135.79s / 27292.03 s
first_0:                 episode reward: 0.7000,                 loss: nan
second_0:                 episode reward: -0.7000,                 loss: 0.0380
Episode: 4061/50000 (8.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 135.75s / 27427.79 s
first_0:                 episode reward: 0.8500,                 loss: nan
second_0:                 episode reward: -0.8500,                 loss: 0.0389
Episode: 4081/50000 (8.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 136.04s / 27563.83 s
first_0:                 episode reward: 1.0000,                 loss: nan
second_0:                 episode reward: -1.0000,                 loss: 0.0401
Episode: 4101/50000 (8.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.51s / 27700.33 s
first_0:                 episode reward: 0.7000,                 loss: nan
second_0:                 episode reward: -0.7000,                 loss: 0.0410
Episode: 4121/50000 (8.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.77s / 27837.10 s
first_0:                 episode reward: 0.9000,                 loss: nan
second_0:                 episode reward: -0.9000,                 loss: 0.0412
Episode: 4141/50000 (8.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 135.66s / 27972.76 s
first_0:                 episode reward: 0.6500,                 loss: nan
second_0:                 episode reward: -0.6500,                 loss: 0.0408
Episode: 4161/50000 (8.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 135.85s / 28108.61 s
first_0:                 episode reward: 0.9000,                 loss: nan
second_0:                 episode reward: -0.9000,                 loss: 0.0402
Episode: 4181/50000 (8.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 136.77s / 28245.38 s
first_0:                 episode reward: 1.3000,                 loss: nan
second_0:                 episode reward: -1.3000,                 loss: 0.0408
Episode: 4201/50000 (8.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 135.49s / 28380.87 s
first_0:                 episode reward: 0.5500,                 loss: nan
second_0:                 episode reward: -0.5500,                 loss: 0.0393
Episode: 4221/50000 (8.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.19s / 28517.06 s
first_0:                 episode reward: 0.9500,                 loss: nan
second_0:                 episode reward: -0.9500,                 loss: 0.0394
Episode: 4241/50000 (8.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 135.19s / 28652.25 s
first_0:                 episode reward: 1.0500,                 loss: nan
second_0:                 episode reward: -1.0500,                 loss: 0.0406
Episode: 4261/50000 (8.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 135.78s / 28788.02 s
first_0:                 episode reward: 0.7500,                 loss: nan
second_0:                 episode reward: -0.7500,                 loss: 0.0405
Episode: 4281/50000 (8.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 136.01s / 28924.04 s
first_0:                 episode reward: 0.3000,                 loss: nan
second_0:                 episode reward: -0.3000,                 loss: 0.0399
Episode: 4301/50000 (8.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 135.94s / 29059.98 s
first_0:                 episode reward: 1.3500,                 loss: nan
second_0:                 episode reward: -1.3500,                 loss: 0.0407
Episode: 4321/50000 (8.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 135.45s / 29195.43 s
first_0:                 episode reward: 0.7500,                 loss: nan
second_0:                 episode reward: -0.7500,                 loss: 0.0414
Episode: 4341/50000 (8.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.60s / 29332.02 s
first_0:                 episode reward: 0.8000,                 loss: nan
second_0:                 episode reward: -0.8000,                 loss: 0.0423
Episode: 4361/50000 (8.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.12s / 29468.14 s
first_0:                 episode reward: 0.6000,                 loss: nan
second_0:                 episode reward: -0.6000,                 loss: 0.0396
Episode: 4381/50000 (8.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 135.09s / 29603.23 s
first_0:                 episode reward: 0.3500,                 loss: nan
second_0:                 episode reward: -0.3500,                 loss: 0.0387
Episode: 4401/50000 (8.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.16s / 29739.39 s
first_0:                 episode reward: 1.5000,                 loss: nan
second_0:                 episode reward: -1.5000,                 loss: 0.0391
Episode: 4421/50000 (8.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.93s / 29876.33 s
first_0:                 episode reward: 0.6000,                 loss: nan
second_0:                 episode reward: -0.6000,                 loss: 0.0389
Episode: 4441/50000 (8.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 135.74s / 30012.07 s
first_0:                 episode reward: 0.4000,                 loss: nan
second_0:                 episode reward: -0.4000,                 loss: 0.0395
Episode: 4461/50000 (8.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 135.05s / 30147.12 s
first_0:                 episode reward: 1.1500,                 loss: nan
second_0:                 episode reward: -1.1500,                 loss: 0.0390
Episode: 4481/50000 (8.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 136.21s / 30283.32 s
first_0:                 episode reward: 0.5000,                 loss: nan
second_0:                 episode reward: -0.5000,                 loss: 0.0389
Episode: 4501/50000 (9.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.02s / 30419.34 s
first_0:                 episode reward: 0.6000,                 loss: nan
second_0:                 episode reward: -0.6000,                 loss: 0.0395
Episode: 4521/50000 (9.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 135.93s / 30555.27 s
first_0:                 episode reward: 0.8000,                 loss: nan
second_0:                 episode reward: -0.8000,                 loss: 0.0410
Episode: 4541/50000 (9.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.81s / 30692.08 s
first_0:                 episode reward: 1.0500,                 loss: nan
second_0:                 episode reward: -1.0500,                 loss: 0.0409
Episode: 4561/50000 (9.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 137.63s / 30829.72 s
first_0:                 episode reward: 0.8500,                 loss: nan
second_0:                 episode reward: -0.8500,                 loss: 0.0409
Episode: 4581/50000 (9.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 135.53s / 30965.25 s
first_0:                 episode reward: 0.8500,                 loss: nan
second_0:                 episode reward: -0.8500,                 loss: 0.0405
Episode: 4601/50000 (9.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 135.44s / 31100.69 s
first_0:                 episode reward: 0.9500,                 loss: nan
second_0:                 episode reward: -0.9500,                 loss: 0.0411
Episode: 4621/50000 (9.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.03s / 31236.71 s
first_0:                 episode reward: 1.1000,                 loss: nan
second_0:                 episode reward: -1.1000,                 loss: 0.0409
Episode: 4641/50000 (9.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.25s / 31372.96 s
first_0:                 episode reward: 0.5500,                 loss: nan
second_0:                 episode reward: -0.5500,                 loss: 0.0401
Episode: 4661/50000 (9.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.38s / 31509.34 s
first_0:                 episode reward: 0.9000,                 loss: nan
second_0:                 episode reward: -0.9000,                 loss: 0.0390
Episode: 4681/50000 (9.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 135.53s / 31644.87 s
first_0:                 episode reward: 1.0000,                 loss: nan
second_0:                 episode reward: -1.0000,                 loss: 0.0389
Episode: 4701/50000 (9.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.33s / 31781.20 s
first_0:                 episode reward: 1.2000,                 loss: nan
second_0:                 episode reward: -1.2000,                 loss: 0.0389
Episode: 4721/50000 (9.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.26s / 31917.46 s
first_0:                 episode reward: 0.4000,                 loss: nan
second_0:                 episode reward: -0.4000,                 loss: 0.0389
Episode: 4741/50000 (9.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.16s / 32053.61 s
first_0:                 episode reward: 0.9000,                 loss: nan
second_0:                 episode reward: -0.9000,                 loss: 0.0378
Episode: 4761/50000 (9.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 135.86s / 32189.47 s
first_0:                 episode reward: 0.7500,                 loss: nan
second_0:                 episode reward: -0.7500,                 loss: 0.0374
Episode: 4781/50000 (9.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 135.87s / 32325.34 s
first_0:                 episode reward: 0.7500,                 loss: nan
second_0:                 episode reward: -0.7500,                 loss: 0.0381
Episode: 4801/50000 (9.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 135.87s / 32461.21 s
first_0:                 episode reward: 1.5000,                 loss: nan
second_0:                 episode reward: -1.5000,                 loss: 0.0376
Episode: 4821/50000 (9.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.58s / 32597.78 s
first_0:                 episode reward: 0.6000,                 loss: nan
second_0:                 episode reward: -0.6000,                 loss: 0.0368
Episode: 4841/50000 (9.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 135.76s / 32733.55 s
first_0:                 episode reward: 1.2000,                 loss: nan
second_0:                 episode reward: -1.2000,                 loss: 0.0372
Episode: 4861/50000 (9.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 135.85s / 32869.40 s
first_0:                 episode reward: 0.0000,                 loss: nan
second_0:                 episode reward: 0.0000,                 loss: 0.0362
Episode: 4881/50000 (9.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 137.35s / 33006.75 s
first_0:                 episode reward: 0.6000,                 loss: nan
second_0:                 episode reward: -0.6000,                 loss: 0.0355
Episode: 4901/50000 (9.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 137.01s / 33143.75 s
first_0:                 episode reward: 0.8000,                 loss: nan
second_0:                 episode reward: -0.8000,                 loss: 0.0364
Episode: 4921/50000 (9.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.82s / 33280.57 s
first_0:                 episode reward: 1.2500,                 loss: nan
second_0:                 episode reward: -1.2500,                 loss: 0.0367
Episode: 4941/50000 (9.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.72s / 33417.29 s
first_0:                 episode reward: 1.0500,                 loss: nan
second_0:                 episode reward: -1.0500,                 loss: 0.0376
Episode: 4961/50000 (9.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 135.98s / 33553.27 s
first_0:                 episode reward: 0.6500,                 loss: nan
second_0:                 episode reward: -0.6500,                 loss: 0.0376
Episode: 4981/50000 (9.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 135.61s / 33688.89 s
first_0:                 episode reward: 0.3500,                 loss: nan
second_0:                 episode reward: -0.3500,                 loss: 0.0378
Episode: 5001/50000 (10.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.12s / 33825.00 s
first_0:                 episode reward: 0.9000,                 loss: nan
second_0:                 episode reward: -0.9000,                 loss: 0.0380
Episode: 5021/50000 (10.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 137.30s / 33962.31 s
first_0:                 episode reward: 0.6000,                 loss: nan
second_0:                 episode reward: -0.6000,                 loss: 0.0385
Episode: 5041/50000 (10.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.35s / 34098.66 s
first_0:                 episode reward: 0.7500,                 loss: nan
second_0:                 episode reward: -0.7500,                 loss: 0.0383
Episode: 5061/50000 (10.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 135.88s / 34234.54 s
first_0:                 episode reward: 0.8000,                 loss: nan
second_0:                 episode reward: -0.8000,                 loss: 0.0381
Episode: 5081/50000 (10.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 136.31s / 34370.84 s
first_0:                 episode reward: 0.8000,                 loss: nan
second_0:                 episode reward: -0.8000,                 loss: 0.0377
Episode: 5101/50000 (10.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.63s / 34507.48 s
first_0:                 episode reward: 0.4500,                 loss: nan
second_0:                 episode reward: -0.4500,                 loss: 0.0387
Episode: 5121/50000 (10.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.58s / 34644.06 s
first_0:                 episode reward: 1.0000,                 loss: nan
second_0:                 episode reward: -1.0000,                 loss: 0.0391
Episode: 5141/50000 (10.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.25s / 34780.30 s
first_0:                 episode reward: 1.1000,                 loss: nan
second_0:                 episode reward: -1.1000,                 loss: 0.0379
Episode: 5161/50000 (10.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.14s / 34916.45 s
first_0:                 episode reward: 0.4500,                 loss: nan
second_0:                 episode reward: -0.4500,                 loss: 0.0382
Episode: 5181/50000 (10.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 135.44s / 35051.89 s
first_0:                 episode reward: 1.0000,                 loss: nan
second_0:                 episode reward: -1.0000,                 loss: 0.0392
Episode: 5201/50000 (10.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.60s / 35188.48 s
first_0:                 episode reward: 0.9000,                 loss: nan
second_0:                 episode reward: -0.9000,                 loss: 0.0402
Episode: 5221/50000 (10.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 137.28s / 35325.76 s
first_0:                 episode reward: 0.7500,                 loss: nan
second_0:                 episode reward: -0.7500,                 loss: 0.0397
Episode: 5241/50000 (10.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.06s / 35461.82 s
first_0:                 episode reward: 1.2500,                 loss: nan
second_0:                 episode reward: -1.2500,                 loss: 0.0375
Episode: 5261/50000 (10.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 135.88s / 35597.70 s
first_0:                 episode reward: 0.5000,                 loss: nan
second_0:                 episode reward: -0.5000,                 loss: 0.0372
Episode: 5281/50000 (10.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 135.96s / 35733.66 s
first_0:                 episode reward: 1.2000,                 loss: nan
second_0:                 episode reward: -1.2000,                 loss: 0.0377
Episode: 5301/50000 (10.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.13s / 35869.79 s
first_0:                 episode reward: 0.8000,                 loss: nan
second_0:                 episode reward: -0.8000,                 loss: 0.0375
Episode: 5321/50000 (10.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 135.32s / 36005.11 s
first_0:                 episode reward: 0.9000,                 loss: nan
second_0:                 episode reward: -0.9000,                 loss: 0.0379
Episode: 5341/50000 (10.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 135.77s / 36140.87 s
first_0:                 episode reward: 1.0000,                 loss: nan
second_0:                 episode reward: -1.0000,                 loss: 0.0394
Episode: 5361/50000 (10.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 137.03s / 36277.90 s
first_0:                 episode reward: 1.0500,                 loss: nan
second_0:                 episode reward: -1.0500,                 loss: 0.0392
Episode: 5381/50000 (10.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 135.28s / 36413.18 s
first_0:                 episode reward: 0.7000,                 loss: nan
second_0:                 episode reward: -0.7000,                 loss: 0.0376
Episode: 5401/50000 (10.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.05s / 36549.23 s
first_0:                 episode reward: 0.1500,                 loss: nan
second_0:                 episode reward: -0.1500,                 loss: 0.0379
Episode: 5421/50000 (10.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.75s / 36685.98 s
first_0:                 episode reward: 1.0500,                 loss: nan
second_0:                 episode reward: -1.0500,                 loss: 0.0380
Episode: 5441/50000 (10.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 135.96s / 36821.94 s
first_0:                 episode reward: 0.9000,                 loss: nan
second_0:                 episode reward: -0.9000,                 loss: 0.0390
Episode: 5461/50000 (10.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 137.05s / 36958.99 s
first_0:                 episode reward: 1.2500,                 loss: nan
second_0:                 episode reward: -1.2500,                 loss: 0.0394
Episode: 5481/50000 (10.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 135.98s / 37094.97 s
first_0:                 episode reward: 0.9500,                 loss: nan
second_0:                 episode reward: -0.9500,                 loss: 0.0385
Episode: 5501/50000 (11.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.15s / 37231.12 s
first_0:                 episode reward: 0.5500,                 loss: nan
second_0:                 episode reward: -0.5500,                 loss: 0.0383
Episode: 5521/50000 (11.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.43s / 37367.55 s
first_0:                 episode reward: 0.5000,                 loss: nan
second_0:                 episode reward: -0.5000,                 loss: 0.0381
Episode: 5541/50000 (11.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.10s / 37503.65 s
first_0:                 episode reward: 0.9500,                 loss: nan
second_0:                 episode reward: -0.9500,                 loss: 0.0385
Episode: 5561/50000 (11.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 135.83s / 37639.47 s
first_0:                 episode reward: 1.3500,                 loss: nan
second_0:                 episode reward: -1.3500,                 loss: 0.0388
Episode: 5581/50000 (11.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 137.00s / 37776.47 s
first_0:                 episode reward: 0.0000,                 loss: nan
second_0:                 episode reward: 0.0000,                 loss: 0.0392
Episode: 5601/50000 (11.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.47s / 37912.94 s
first_0:                 episode reward: 1.4000,                 loss: nan
second_0:                 episode reward: -1.4000,                 loss: 0.0394
Episode: 5621/50000 (11.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.05s / 38048.99 s
first_0:                 episode reward: 0.1500,                 loss: nan
second_0:                 episode reward: -0.1500,                 loss: 0.0402
Episode: 5641/50000 (11.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 135.74s / 38184.73 s
first_0:                 episode reward: 0.7500,                 loss: nan
second_0:                 episode reward: -0.7500,                 loss: 0.0394
Episode: 5661/50000 (11.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.36s / 38321.10 s
first_0:                 episode reward: 0.9000,                 loss: nan
second_0:                 episode reward: -0.9000,                 loss: 0.0396
Episode: 5681/50000 (11.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 135.94s / 38457.04 s
first_0:                 episode reward: 1.3000,                 loss: nan
second_0:                 episode reward: -1.3000,                 loss: 0.0395
Episode: 5701/50000 (11.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.80s / 38593.84 s
first_0:                 episode reward: 1.1000,                 loss: nan
second_0:                 episode reward: -1.1000,                 loss: 0.0400
Episode: 5721/50000 (11.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.98s / 38730.82 s
first_0:                 episode reward: 0.7000,                 loss: nan
second_0:                 episode reward: -0.7000,                 loss: 0.0400
Episode: 5741/50000 (11.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.51s / 38867.33 s
first_0:                 episode reward: 1.3000,                 loss: nan
second_0:                 episode reward: -1.3000,                 loss: 0.0397
Episode: 5761/50000 (11.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 135.65s / 39002.98 s
first_0:                 episode reward: 1.3000,                 loss: nan
second_0:                 episode reward: -1.3000,                 loss: 0.0403
Episode: 5781/50000 (11.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 135.70s / 39138.69 s
first_0:                 episode reward: 0.9000,                 loss: nan
second_0:                 episode reward: -0.9000,                 loss: 0.0406
Episode: 5801/50000 (11.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.26s / 39274.95 s
first_0:                 episode reward: 0.4000,                 loss: nan
second_0:                 episode reward: -0.4000,                 loss: 0.0403
Episode: 5821/50000 (11.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.75s / 39411.70 s
first_0:                 episode reward: 1.1000,                 loss: nan
second_0:                 episode reward: -1.1000,                 loss: 0.0404
Episode: 5841/50000 (11.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 135.74s / 39547.44 s
first_0:                 episode reward: 0.9000,                 loss: nan
second_0:                 episode reward: -0.9000,                 loss: 0.0406
Episode: 5861/50000 (11.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.46s / 39683.91 s
first_0:                 episode reward: 0.8000,                 loss: nan
second_0:                 episode reward: -0.8000,                 loss: 0.0405
Episode: 5881/50000 (11.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 136.80s / 39820.70 s
first_0:                 episode reward: 0.8500,                 loss: nan
second_0:                 episode reward: -0.8500,                 loss: 0.0409
Episode: 5901/50000 (11.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 137.11s / 39957.82 s
first_0:                 episode reward: 1.0500,                 loss: nan
second_0:                 episode reward: -1.0500,                 loss: 0.0405
Episode: 5921/50000 (11.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 135.98s / 40093.80 s
first_0:                 episode reward: 0.3000,                 loss: nan
second_0:                 episode reward: -0.3000,                 loss: 0.0409
Episode: 5941/50000 (11.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 135.31s / 40229.11 s
first_0:                 episode reward: 1.1500,                 loss: nan
second_0:                 episode reward: -1.1500,                 loss: 0.0395
Episode: 5961/50000 (11.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.25s / 40365.36 s
first_0:                 episode reward: 0.9500,                 loss: nan
second_0:                 episode reward: -0.9500,                 loss: 0.0386
Episode: 5981/50000 (11.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 135.97s / 40501.33 s
first_0:                 episode reward: 0.6000,                 loss: nan
second_0:                 episode reward: -0.6000,                 loss: 0.0397
Episode: 6001/50000 (12.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.98s / 40638.31 s
first_0:                 episode reward: 0.2000,                 loss: nan
second_0:                 episode reward: -0.2000,                 loss: 0.0392
Episode: 6021/50000 (12.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.63s / 40774.94 s
first_0:                 episode reward: 1.1000,                 loss: nan
second_0:                 episode reward: -1.1000,                 loss: 0.0409
Episode: 6041/50000 (12.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 137.07s / 40912.01 s
first_0:                 episode reward: 0.7500,                 loss: nan
second_0:                 episode reward: -0.7500,                 loss: 0.0395
Episode: 6061/50000 (12.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 135.42s / 41047.43 s
first_0:                 episode reward: 1.0000,                 loss: nan
second_0:                 episode reward: -1.0000,                 loss: 0.0404
Episode: 6081/50000 (12.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 136.03s / 41183.46 s
first_0:                 episode reward: 0.9500,                 loss: nan
second_0:                 episode reward: -0.9500,                 loss: 0.0401
Episode: 6101/50000 (12.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.43s / 41319.89 s
first_0:                 episode reward: 1.1500,                 loss: nan
second_0:                 episode reward: -1.1500,                 loss: 0.0412
Episode: 6121/50000 (12.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.30s / 41456.19 s
first_0:                 episode reward: 0.9000,                 loss: nan
second_0:                 episode reward: -0.9000,                 loss: 0.0418
Episode: 6141/50000 (12.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.60s / 41592.79 s
first_0:                 episode reward: 0.8500,                 loss: nan
second_0:                 episode reward: -0.8500,                 loss: 0.0419
Episode: 6161/50000 (12.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 135.58s / 41728.37 s
first_0:                 episode reward: 1.0000,                 loss: nan
second_0:                 episode reward: -1.0000,                 loss: 0.0424
Episode: 6181/50000 (12.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 136.75s / 41865.12 s
first_0:                 episode reward: 0.9000,                 loss: nan
second_0:                 episode reward: -0.9000,                 loss: 0.0408
Episode: 6201/50000 (12.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.22s / 42001.34 s
first_0:                 episode reward: 0.7000,                 loss: nan
second_0:                 episode reward: -0.7000,                 loss: 0.0413
Episode: 6221/50000 (12.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 137.32s / 42138.65 s
first_0:                 episode reward: 0.8000,                 loss: nan
second_0:                 episode reward: -0.8000,                 loss: 0.0423
Episode: 6241/50000 (12.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 137.54s / 42276.19 s
first_0:                 episode reward: 0.9000,                 loss: nan
second_0:                 episode reward: -0.9000,                 loss: 0.0424
Episode: 6261/50000 (12.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 135.81s / 42412.00 s
first_0:                 episode reward: 0.2500,                 loss: nan
second_0:                 episode reward: -0.2500,                 loss: 0.0418
Episode: 6281/50000 (12.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 136.47s / 42548.46 s
first_0:                 episode reward: 0.8000,                 loss: nan
second_0:                 episode reward: -0.8000,                 loss: 0.0422
Episode: 6301/50000 (12.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.60s / 42685.06 s
first_0:                 episode reward: 1.0000,                 loss: nan
second_0:                 episode reward: -1.0000,                 loss: 0.0431
Episode: 6321/50000 (12.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.01s / 42821.08 s
first_0:                 episode reward: -0.2000,                 loss: nan
second_0:                 episode reward: 0.2000,                 loss: 0.0431
Episode: 6341/50000 (12.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.00s / 42957.08 s
first_0:                 episode reward: 0.2000,                 loss: nan
second_0:                 episode reward: -0.2000,                 loss: 0.0448
Episode: 6361/50000 (12.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.48s / 43093.56 s
first_0:                 episode reward: 1.1000,                 loss: nan
second_0:                 episode reward: -1.1000,                 loss: 0.0441
Episode: 6381/50000 (12.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 137.37s / 43230.93 s
first_0:                 episode reward: 0.0500,                 loss: nan
second_0:                 episode reward: -0.0500,                 loss: 0.0441
Episode: 6401/50000 (12.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 137.00s / 43367.93 s
first_0:                 episode reward: 1.4000,                 loss: nan
second_0:                 episode reward: -1.4000,                 loss: 0.0458
Episode: 6421/50000 (12.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 135.79s / 43503.73 s
first_0:                 episode reward: 0.6500,                 loss: nan
second_0:                 episode reward: -0.6500,                 loss: 0.0462
Episode: 6441/50000 (12.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 135.94s / 43639.66 s
first_0:                 episode reward: 0.9500,                 loss: nan
second_0:                 episode reward: -0.9500,                 loss: 0.0467
Episode: 6461/50000 (12.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.45s / 43776.11 s
first_0:                 episode reward: 0.7500,                 loss: nan
second_0:                 episode reward: -0.7500,                 loss: 0.0470
Episode: 6481/50000 (12.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 136.63s / 43912.74 s
first_0:                 episode reward: 0.7500,                 loss: nan
second_0:                 episode reward: -0.7500,                 loss: 0.0462
Episode: 6501/50000 (13.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.22s / 44048.96 s
first_0:                 episode reward: 0.3500,                 loss: nan
second_0:                 episode reward: -0.3500,                 loss: 0.0469
Episode: 6521/50000 (13.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.50s / 44185.46 s
first_0:                 episode reward: 1.0000,                 loss: nan
second_0:                 episode reward: -1.0000,                 loss: 0.0450
Episode: 6541/50000 (13.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 135.65s / 44321.11 s
first_0:                 episode reward: 0.5000,                 loss: nan
second_0:                 episode reward: -0.5000,                 loss: 0.0444
Episode: 6561/50000 (13.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.80s / 44457.92 s
first_0:                 episode reward: 1.3000,                 loss: nan
second_0:                 episode reward: -1.3000,                 loss: 0.0432
Episode: 6581/50000 (13.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 136.48s / 44594.40 s
first_0:                 episode reward: 0.7000,                 loss: nan
second_0:                 episode reward: -0.7000,                 loss: 0.0427
Episode: 6601/50000 (13.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.21s / 44730.61 s
first_0:                 episode reward: 0.6000,                 loss: nan
second_0:                 episode reward: -0.6000,                 loss: 0.0441
Episode: 6621/50000 (13.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 135.68s / 44866.28 s
first_0:                 episode reward: 1.4500,                 loss: nan
second_0:                 episode reward: -1.4500,                 loss: 0.0432
Episode: 6641/50000 (13.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 135.82s / 45002.10 s
first_0:                 episode reward: 0.8500,                 loss: nan
second_0:                 episode reward: -0.8500,                 loss: 0.0429
Episode: 6661/50000 (13.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.77s / 45138.87 s
first_0:                 episode reward: 0.7500,                 loss: nan
second_0:                 episode reward: -0.7500,                 loss: 0.0439
Episode: 6681/50000 (13.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 136.74s / 45275.61 s
first_0:                 episode reward: 1.1000,                 loss: nan
second_0:                 episode reward: -1.1000,                 loss: 0.0434
Episode: 6701/50000 (13.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 135.85s / 45411.46 s
first_0:                 episode reward: 1.3500,                 loss: nan
second_0:                 episode reward: -1.3500,                 loss: 0.0448
Episode: 6721/50000 (13.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.42s / 45547.88 s
first_0:                 episode reward: 0.3000,                 loss: nan
second_0:                 episode reward: -0.3000,                 loss: 0.0439
Episode: 6741/50000 (13.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.31s / 45684.19 s
first_0:                 episode reward: 0.4000,                 loss: nan
second_0:                 episode reward: -0.4000,                 loss: 0.0425
Episode: 6761/50000 (13.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.69s / 45820.87 s
first_0:                 episode reward: 1.2500,                 loss: nan
second_0:                 episode reward: -1.2500,                 loss: 0.0439
Episode: 6781/50000 (13.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 136.46s / 45957.33 s
first_0:                 episode reward: 0.6500,                 loss: nan
second_0:                 episode reward: -0.6500,                 loss: 0.0434
Episode: 6801/50000 (13.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.62s / 46093.96 s
first_0:                 episode reward: 0.5500,                 loss: nan
second_0:                 episode reward: -0.5500,                 loss: 0.0428
Episode: 6821/50000 (13.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 135.97s / 46229.92 s
first_0:                 episode reward: 1.2000,                 loss: nan
second_0:                 episode reward: -1.2000,                 loss: 0.0414
Episode: 6841/50000 (13.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 137.48s / 46367.40 s
first_0:                 episode reward: 1.0000,                 loss: nan
second_0:                 episode reward: -1.0000,                 loss: 0.0401
Episode: 6861/50000 (13.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.25s / 46503.65 s
first_0:                 episode reward: 0.5000,                 loss: nan
second_0:                 episode reward: -0.5000,                 loss: 0.0401
Episode: 6881/50000 (13.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 136.85s / 46640.50 s
first_0:                 episode reward: 1.0500,                 loss: nan
second_0:                 episode reward: -1.0500,                 loss: 0.0392
Episode: 6901/50000 (13.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 137.03s / 46777.53 s
first_0:                 episode reward: 0.6000,                 loss: nan
second_0:                 episode reward: -0.6000,                 loss: 0.0391
Episode: 6921/50000 (13.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.38s / 46913.91 s
first_0:                 episode reward: 0.8000,                 loss: nan
second_0:                 episode reward: -0.8000,                 loss: 0.0398
Episode: 6941/50000 (13.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 137.36s / 47051.27 s
first_0:                 episode reward: 0.9000,                 loss: nan
second_0:                 episode reward: -0.9000,                 loss: 0.0393
Episode: 6961/50000 (13.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.80s / 47188.07 s
first_0:                 episode reward: 0.8500,                 loss: nan
second_0:                 episode reward: -0.8500,                 loss: 0.0392
Episode: 6981/50000 (13.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 137.12s / 47325.19 s
first_0:                 episode reward: 1.7000,                 loss: nan
second_0:                 episode reward: -1.7000,                 loss: 0.0384
Episode: 7001/50000 (14.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.05s / 47461.24 s
first_0:                 episode reward: 0.8500,                 loss: nan
second_0:                 episode reward: -0.8500,                 loss: 0.0391
Episode: 7021/50000 (14.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.15s / 47597.39 s
first_0:                 episode reward: 1.1500,                 loss: nan
second_0:                 episode reward: -1.1500,                 loss: 0.0391
Episode: 7041/50000 (14.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.14s / 47733.53 s
first_0:                 episode reward: 0.2500,                 loss: nan
second_0:                 episode reward: -0.2500,                 loss: 0.0382
Episode: 7061/50000 (14.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.45s / 47869.99 s
first_0:                 episode reward: 1.0500,                 loss: nan
second_0:                 episode reward: -1.0500,                 loss: 0.0381
Episode: 7081/50000 (14.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 135.64s / 48005.62 s
first_0:                 episode reward: 0.7000,                 loss: nan
second_0:                 episode reward: -0.7000,                 loss: 0.0377
Episode: 7101/50000 (14.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.07s / 48141.69 s
first_0:                 episode reward: 0.8500,                 loss: nan
second_0:                 episode reward: -0.8500,                 loss: 0.0378
Episode: 7121/50000 (14.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 137.01s / 48278.71 s
first_0:                 episode reward: 0.5000,                 loss: nan
second_0:                 episode reward: -0.5000,                 loss: 0.0386
Episode: 7141/50000 (14.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 137.29s / 48415.99 s
first_0:                 episode reward: 0.2000,                 loss: nan
second_0:                 episode reward: -0.2000,                 loss: 0.0399
Episode: 7161/50000 (14.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.41s / 48552.40 s
first_0:                 episode reward: 0.1500,                 loss: nan
second_0:                 episode reward: -0.1500,                 loss: 0.0392
Episode: 7181/50000 (14.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 135.94s / 48688.34 s
first_0:                 episode reward: 0.7500,                 loss: nan
second_0:                 episode reward: -0.7500,                 loss: 0.0398
Episode: 7201/50000 (14.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.30s / 48824.64 s
first_0:                 episode reward: 0.9500,                 loss: nan
second_0:                 episode reward: -0.9500,                 loss: 0.0403
Episode: 7221/50000 (14.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 135.57s / 48960.21 s
first_0:                 episode reward: 1.1000,                 loss: nan
second_0:                 episode reward: -1.1000,                 loss: 0.0406
Episode: 7241/50000 (14.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.17s / 49096.38 s
first_0:                 episode reward: 0.6500,                 loss: nan
second_0:                 episode reward: -0.6500,                 loss: 0.0400
Episode: 7261/50000 (14.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.00s / 49232.37 s
first_0:                 episode reward: 0.8000,                 loss: nan
second_0:                 episode reward: -0.8000,                 loss: 0.0410
Episode: 7281/50000 (14.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 135.79s / 49368.16 s
first_0:                 episode reward: 1.1500,                 loss: nan
second_0:                 episode reward: -1.1500,                 loss: 0.0406
Episode: 7301/50000 (14.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 135.97s / 49504.13 s
first_0:                 episode reward: 1.2000,                 loss: nan
second_0:                 episode reward: -1.2000,                 loss: 0.0408
Episode: 7321/50000 (14.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.68s / 49640.81 s
first_0:                 episode reward: 0.8500,                 loss: nan
second_0:                 episode reward: -0.8500,                 loss: 0.0426
Episode: 7341/50000 (14.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 135.90s / 49776.71 s
first_0:                 episode reward: 0.5500,                 loss: nan
second_0:                 episode reward: -0.5500,                 loss: 0.0424
Episode: 7361/50000 (14.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.51s / 49913.22 s
first_0:                 episode reward: 1.0000,                 loss: nan
second_0:                 episode reward: -1.0000,                 loss: 0.0409
Episode: 7381/50000 (14.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 136.41s / 50049.63 s
first_0:                 episode reward: 0.8000,                 loss: nan
second_0:                 episode reward: -0.8000,                 loss: 0.0406
Episode: 7401/50000 (14.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.49s / 50186.11 s
first_0:                 episode reward: 1.1000,                 loss: nan
second_0:                 episode reward: -1.1000,                 loss: 0.0409
Episode: 7421/50000 (14.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 137.04s / 50323.15 s
first_0:                 episode reward: 1.5500,                 loss: nan
second_0:                 episode reward: -1.5500,                 loss: 0.0406
Episode: 7441/50000 (14.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.85s / 50460.01 s
first_0:                 episode reward: 1.0000,                 loss: nan
second_0:                 episode reward: -1.0000,                 loss: 0.0419
Episode: 7461/50000 (14.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.63s / 50596.64 s
first_0:                 episode reward: 1.3000,                 loss: nan
second_0:                 episode reward: -1.3000,                 loss: 0.0422
Episode: 7481/50000 (14.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 137.79s / 50734.43 s
first_0:                 episode reward: 0.7000,                 loss: nan
second_0:                 episode reward: -0.7000,                 loss: 0.0417
Episode: 7501/50000 (15.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 135.87s / 50870.30 s
first_0:                 episode reward: 1.2000,                 loss: nan
second_0:                 episode reward: -1.2000,                 loss: 0.0425
Episode: 7521/50000 (15.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.17s / 51006.47 s
first_0:                 episode reward: 0.9500,                 loss: nan
second_0:                 episode reward: -0.9500,                 loss: 0.0427
Episode: 7541/50000 (15.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.81s / 51143.28 s
first_0:                 episode reward: 0.6000,                 loss: nan
second_0:                 episode reward: -0.6000,                 loss: 0.0421
Episode: 7561/50000 (15.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 137.12s / 51280.40 s
first_0:                 episode reward: 1.2000,                 loss: nan
second_0:                 episode reward: -1.2000,                 loss: 0.0420
Episode: 7581/50000 (15.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 136.03s / 51416.43 s
first_0:                 episode reward: 1.4000,                 loss: nan
second_0:                 episode reward: -1.4000,                 loss: 0.0415
Episode: 7601/50000 (15.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 137.39s / 51553.81 s
first_0:                 episode reward: 1.0000,                 loss: nan
second_0:                 episode reward: -1.0000,                 loss: 0.0413
Episode: 7621/50000 (15.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 137.05s / 51690.87 s
first_0:                 episode reward: 1.3000,                 loss: nan
second_0:                 episode reward: -1.3000,                 loss: 0.0407
Episode: 7641/50000 (15.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.42s / 51827.28 s
first_0:                 episode reward: 0.9000,                 loss: nan
second_0:                 episode reward: -0.9000,                 loss: 0.0413
Episode: 7661/50000 (15.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 135.77s / 51963.05 s
first_0:                 episode reward: 1.5500,                 loss: nan
second_0:                 episode reward: -1.5500,                 loss: 0.0423
Episode: 7681/50000 (15.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 136.39s / 52099.45 s
first_0:                 episode reward: 1.3000,                 loss: nan
second_0:                 episode reward: -1.3000,                 loss: 0.0415
Episode: 7701/50000 (15.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.01s / 52235.46 s
first_0:                 episode reward: 1.2000,                 loss: nan
second_0:                 episode reward: -1.2000,                 loss: 0.0407
Episode: 7721/50000 (15.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.14s / 52371.60 s
first_0:                 episode reward: 0.9500,                 loss: nan
second_0:                 episode reward: -0.9500,                 loss: 0.0411
Episode: 7741/50000 (15.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 137.01s / 52508.61 s
first_0:                 episode reward: 1.4500,                 loss: nan
second_0:                 episode reward: -1.4500,                 loss: 0.0406
Episode: 7761/50000 (15.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.74s / 52645.35 s
first_0:                 episode reward: 1.2000,                 loss: nan
second_0:                 episode reward: -1.2000,                 loss: 0.0397
Episode: 7781/50000 (15.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 137.02s / 52782.37 s
first_0:                 episode reward: 1.1500,                 loss: nan
second_0:                 episode reward: -1.1500,                 loss: 0.0407
Episode: 7801/50000 (15.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.48s / 52918.85 s
first_0:                 episode reward: 1.3000,                 loss: nan
second_0:                 episode reward: -1.3000,                 loss: 0.0393
Episode: 7821/50000 (15.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 135.94s / 53054.79 s
first_0:                 episode reward: 0.6500,                 loss: nan
second_0:                 episode reward: -0.6500,                 loss: 0.0399
Episode: 7841/50000 (15.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.86s / 53191.65 s
first_0:                 episode reward: 2.0000,                 loss: nan
second_0:                 episode reward: -2.0000,                 loss: 0.0398
Episode: 7861/50000 (15.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.52s / 53328.17 s
first_0:                 episode reward: 1.3500,                 loss: nan
second_0:                 episode reward: -1.3500,                 loss: 0.0402
Episode: 7881/50000 (15.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 135.83s / 53464.01 s
first_0:                 episode reward: 1.3500,                 loss: nan
second_0:                 episode reward: -1.3500,                 loss: 0.0402
Episode: 7901/50000 (15.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.84s / 53600.84 s
first_0:                 episode reward: 1.0000,                 loss: nan
second_0:                 episode reward: -1.0000,                 loss: 0.0404
Episode: 7921/50000 (15.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 137.70s / 53738.54 s
first_0:                 episode reward: 1.6500,                 loss: nan
second_0:                 episode reward: -1.6500,                 loss: 0.0411
Episode: 7941/50000 (15.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.67s / 53875.21 s
first_0:                 episode reward: 1.4500,                 loss: nan
second_0:                 episode reward: -1.4500,                 loss: 0.0401
Episode: 7961/50000 (15.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 135.57s / 54010.79 s
first_0:                 episode reward: 1.5500,                 loss: nan
second_0:                 episode reward: -1.5500,                 loss: 0.0409
Episode: 7981/50000 (15.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 136.73s / 54147.52 s
first_0:                 episode reward: 1.3000,                 loss: nan
second_0:                 episode reward: -1.3000,                 loss: 0.0404
Episode: 8001/50000 (16.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 135.84s / 54283.36 s
first_0:                 episode reward: 0.9500,                 loss: nan
second_0:                 episode reward: -0.9500,                 loss: 0.0401
Episode: 8021/50000 (16.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 135.80s / 54419.16 s
first_0:                 episode reward: 1.3500,                 loss: nan
second_0:                 episode reward: -1.3500,                 loss: 0.0392
Episode: 8041/50000 (16.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 137.55s / 54556.71 s
first_0:                 episode reward: 1.2000,                 loss: nan
second_0:                 episode reward: -1.2000,                 loss: 0.0408
Episode: 8061/50000 (16.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.23s / 54692.94 s
first_0:                 episode reward: 1.3000,                 loss: nan
second_0:                 episode reward: -1.3000,                 loss: 0.0410
Episode: 8081/50000 (16.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 136.77s / 54829.72 s
first_0:                 episode reward: 0.8500,                 loss: nan
second_0:                 episode reward: -0.8500,                 loss: 0.0396
Episode: 8101/50000 (16.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.81s / 54966.53 s
first_0:                 episode reward: 0.9500,                 loss: nan
second_0:                 episode reward: -0.9500,                 loss: 0.0401
Episode: 8121/50000 (16.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 135.60s / 55102.13 s
first_0:                 episode reward: 1.5000,                 loss: nan
second_0:                 episode reward: -1.5000,                 loss: 0.0402
Episode: 8141/50000 (16.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.25s / 55238.38 s
first_0:                 episode reward: 0.3500,                 loss: nan
second_0:                 episode reward: -0.3500,                 loss: 0.0398
Episode: 8161/50000 (16.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.35s / 55374.73 s
first_0:                 episode reward: 0.3500,                 loss: nan
second_0:                 episode reward: -0.3500,                 loss: 0.0395
Episode: 8181/50000 (16.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 136.64s / 55511.37 s
first_0:                 episode reward: 1.3000,                 loss: nan
second_0:                 episode reward: -1.3000,                 loss: 0.0399
Episode: 8201/50000 (16.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 135.93s / 55647.30 s
first_0:                 episode reward: 0.5500,                 loss: nan
second_0:                 episode reward: -0.5500,                 loss: 0.0398
Episode: 8221/50000 (16.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.01s / 55783.30 s
first_0:                 episode reward: 1.6000,                 loss: nan
second_0:                 episode reward: -1.6000,                 loss: 0.0401
Episode: 8241/50000 (16.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.30s / 55919.60 s
first_0:                 episode reward: 1.9000,                 loss: nan
second_0:                 episode reward: -1.9000,                 loss: 0.0388
Episode: 8261/50000 (16.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.47s / 56056.07 s
first_0:                 episode reward: 1.0000,                 loss: nan
second_0:                 episode reward: -1.0000,                 loss: 0.0374
Episode: 8281/50000 (16.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 136.33s / 56192.40 s
first_0:                 episode reward: 1.0000,                 loss: nan
second_0:                 episode reward: -1.0000,                 loss: 0.0387
Episode: 8301/50000 (16.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.84s / 56329.24 s
first_0:                 episode reward: 1.2500,                 loss: nan
second_0:                 episode reward: -1.2500,                 loss: 0.0383
Episode: 8321/50000 (16.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.24s / 56465.48 s
first_0:                 episode reward: 1.3500,                 loss: nan
second_0:                 episode reward: -1.3500,                 loss: 0.0394
Episode: 8341/50000 (16.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.76s / 56602.24 s
first_0:                 episode reward: 0.5000,                 loss: nan
second_0:                 episode reward: -0.5000,                 loss: 0.0391
Episode: 8361/50000 (16.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.68s / 56738.92 s
first_0:                 episode reward: 1.2000,                 loss: nan
second_0:                 episode reward: -1.2000,                 loss: 0.0372
Episode: 8381/50000 (16.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 135.52s / 56874.44 s
first_0:                 episode reward: 1.7500,                 loss: nan
second_0:                 episode reward: -1.7500,                 loss: 0.0385
Episode: 8401/50000 (16.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.45s / 57010.90 s
first_0:                 episode reward: 0.8000,                 loss: nan
second_0:                 episode reward: -0.8000,                 loss: 0.0385
Episode: 8421/50000 (16.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.35s / 57147.25 s
first_0:                 episode reward: 1.5000,                 loss: nan
second_0:                 episode reward: -1.5000,                 loss: 0.0390
Episode: 8441/50000 (16.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.09s / 57283.34 s
first_0:                 episode reward: 1.5500,                 loss: nan
second_0:                 episode reward: -1.5500,                 loss: 0.0387
Episode: 8461/50000 (16.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.23s / 57419.57 s
first_0:                 episode reward: 0.7500,                 loss: nan
second_0:                 episode reward: -0.7500,                 loss: 0.0394
Episode: 8481/50000 (16.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 136.19s / 57555.76 s
first_0:                 episode reward: 1.5000,                 loss: nan
second_0:                 episode reward: -1.5000,                 loss: 0.0406
Episode: 8501/50000 (17.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 135.54s / 57691.31 s
first_0:                 episode reward: 1.7500,                 loss: nan
second_0:                 episode reward: -1.7500,                 loss: 0.0399
Episode: 8521/50000 (17.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 135.78s / 57827.08 s
first_0:                 episode reward: 1.1000,                 loss: nan
second_0:                 episode reward: -1.1000,                 loss: 0.0404
Episode: 8541/50000 (17.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.19s / 57963.28 s
first_0:                 episode reward: 1.3000,                 loss: nan
second_0:                 episode reward: -1.3000,                 loss: 0.0397
Episode: 8561/50000 (17.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.14s / 58099.42 s
first_0:                 episode reward: 1.3000,                 loss: nan
second_0:                 episode reward: -1.3000,                 loss: 0.0397
Episode: 8581/50000 (17.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 135.92s / 58235.34 s
first_0:                 episode reward: 1.0500,                 loss: nan
second_0:                 episode reward: -1.0500,                 loss: 0.0413
Episode: 8601/50000 (17.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 135.79s / 58371.12 s
first_0:                 episode reward: 1.3000,                 loss: nan
second_0:                 episode reward: -1.3000,                 loss: 0.0425
Episode: 8621/50000 (17.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.10s / 58507.22 s
first_0:                 episode reward: 1.4000,                 loss: nan
second_0:                 episode reward: -1.4000,                 loss: 0.0410
Episode: 8641/50000 (17.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.10s / 58643.32 s
first_0:                 episode reward: 1.2000,                 loss: nan
second_0:                 episode reward: -1.2000,                 loss: 0.0409
Episode: 8661/50000 (17.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.12s / 58779.44 s
first_0:                 episode reward: 1.3000,                 loss: nan
second_0:                 episode reward: -1.3000,                 loss: 0.0411
Episode: 8681/50000 (17.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 135.82s / 58915.26 s
first_0:                 episode reward: 1.4000,                 loss: nan
second_0:                 episode reward: -1.4000,                 loss: 0.0413
Episode: 8701/50000 (17.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 135.66s / 59050.92 s
first_0:                 episode reward: 0.8000,                 loss: nan
second_0:                 episode reward: -0.8000,                 loss: 0.0406
Episode: 8721/50000 (17.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.90s / 59187.82 s
first_0:                 episode reward: 1.1500,                 loss: nan
second_0:                 episode reward: -1.1500,                 loss: 0.0421
Episode: 8741/50000 (17.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.50s / 59324.32 s
first_0:                 episode reward: 1.4000,                 loss: nan
second_0:                 episode reward: -1.4000,                 loss: 0.0420
Episode: 8761/50000 (17.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 137.41s / 59461.72 s
first_0:                 episode reward: 1.2000,                 loss: nan
second_0:                 episode reward: -1.2000,                 loss: 0.0421
Episode: 8781/50000 (17.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 136.77s / 59598.49 s
first_0:                 episode reward: 0.7000,                 loss: nan
second_0:                 episode reward: -0.7000,                 loss: 0.0435
Episode: 8801/50000 (17.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 135.83s / 59734.32 s
first_0:                 episode reward: 1.6000,                 loss: nan
second_0:                 episode reward: -1.6000,                 loss: 0.0433
Episode: 8821/50000 (17.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.00s / 59870.32 s
first_0:                 episode reward: 1.0500,                 loss: nan
second_0:                 episode reward: -1.0500,                 loss: 0.0433
Episode: 8841/50000 (17.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.65s / 60006.97 s
first_0:                 episode reward: 1.2000,                 loss: nan
second_0:                 episode reward: -1.2000,                 loss: 0.0425
Episode: 8861/50000 (17.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.21s / 60143.18 s
first_0:                 episode reward: 1.1500,                 loss: nan
second_0:                 episode reward: -1.1500,                 loss: 0.0422
Episode: 8881/50000 (17.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 135.66s / 60278.84 s
first_0:                 episode reward: 1.4000,                 loss: nan
second_0:                 episode reward: -1.4000,                 loss: 0.0430
Episode: 8901/50000 (17.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 135.69s / 60414.54 s
first_0:                 episode reward: 0.9500,                 loss: nan
second_0:                 episode reward: -0.9500,                 loss: 0.0420
Episode: 8921/50000 (17.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.97s / 60551.50 s
first_0:                 episode reward: 1.4000,                 loss: nan
second_0:                 episode reward: -1.4000,                 loss: 0.0408
Episode: 8941/50000 (17.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 135.81s / 60687.31 s
first_0:                 episode reward: 1.2000,                 loss: nan
second_0:                 episode reward: -1.2000,                 loss: 0.0409
Episode: 8961/50000 (17.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.08s / 60823.39 s
first_0:                 episode reward: 1.1000,                 loss: nan
second_0:                 episode reward: -1.1000,                 loss: 0.0421
Episode: 8981/50000 (17.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 136.35s / 60959.74 s
first_0:                 episode reward: 0.9500,                 loss: nan
second_0:                 episode reward: -0.9500,                 loss: 0.0408
Episode: 9001/50000 (18.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.45s / 61096.20 s
first_0:                 episode reward: 1.3000,                 loss: nan
second_0:                 episode reward: -1.3000,                 loss: 0.0405
Episode: 9021/50000 (18.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.64s / 61232.84 s
first_0:                 episode reward: 1.0000,                 loss: nan
second_0:                 episode reward: -1.0000,                 loss: 0.0413
Episode: 9041/50000 (18.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 137.49s / 61370.33 s
first_0:                 episode reward: 1.1000,                 loss: nan
second_0:                 episode reward: -1.1000,                 loss: 0.0398
Episode: 9061/50000 (18.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.40s / 61506.73 s
first_0:                 episode reward: 1.5000,                 loss: nan
second_0:                 episode reward: -1.5000,                 loss: 0.0389
Episode: 9081/50000 (18.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 136.03s / 61642.76 s
first_0:                 episode reward: 1.4500,                 loss: nan
second_0:                 episode reward: -1.4500,                 loss: 0.0373
Episode: 9101/50000 (18.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.75s / 61779.51 s
first_0:                 episode reward: 0.9000,                 loss: nan
second_0:                 episode reward: -0.9000,                 loss: 0.0391
Episode: 9121/50000 (18.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 137.25s / 61916.76 s
first_0:                 episode reward: 0.8500,                 loss: nan
second_0:                 episode reward: -0.8500,                 loss: 0.0403
Episode: 9141/50000 (18.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.43s / 62053.19 s
first_0:                 episode reward: 1.7000,                 loss: nan
second_0:                 episode reward: -1.7000,                 loss: 0.0387
Episode: 9161/50000 (18.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.12s / 62189.32 s
first_0:                 episode reward: 1.2000,                 loss: nan
second_0:                 episode reward: -1.2000,                 loss: 0.0390
Episode: 9181/50000 (18.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 136.71s / 62326.02 s
first_0:                 episode reward: 1.2500,                 loss: nan
second_0:                 episode reward: -1.2500,                 loss: 0.0398
Episode: 9201/50000 (18.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 137.27s / 62463.29 s
first_0:                 episode reward: 1.2000,                 loss: nan
second_0:                 episode reward: -1.2000,                 loss: 0.0392
Episode: 9221/50000 (18.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.73s / 62600.02 s
first_0:                 episode reward: 1.0500,                 loss: nan
second_0:                 episode reward: -1.0500,                 loss: 0.0394
Episode: 9241/50000 (18.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 137.09s / 62737.10 s
first_0:                 episode reward: 1.2000,                 loss: nan
second_0:                 episode reward: -1.2000,                 loss: 0.0390
Episode: 9261/50000 (18.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 137.71s / 62874.82 s
first_0:                 episode reward: 1.3000,                 loss: nan
second_0:                 episode reward: -1.3000,                 loss: 0.0396
Episode: 9281/50000 (18.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 137.09s / 63011.91 s
first_0:                 episode reward: 0.9500,                 loss: nan
second_0:                 episode reward: -0.9500,                 loss: 0.0397
Episode: 9301/50000 (18.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.96s / 63148.87 s
first_0:                 episode reward: 0.8500,                 loss: nan
second_0:                 episode reward: -0.8500,                 loss: 0.0399
Episode: 9321/50000 (18.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.26s / 63285.13 s
first_0:                 episode reward: 1.1000,                 loss: nan
second_0:                 episode reward: -1.1000,                 loss: 0.0394
Episode: 9341/50000 (18.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.48s / 63421.61 s
first_0:                 episode reward: 1.1500,                 loss: nan
second_0:                 episode reward: -1.1500,                 loss: 0.0395
Episode: 9361/50000 (18.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.06s / 63557.67 s
first_0:                 episode reward: 1.2000,                 loss: nan
second_0:                 episode reward: -1.2000,                 loss: 0.0393
Episode: 9381/50000 (18.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 135.98s / 63693.66 s
first_0:                 episode reward: 1.3500,                 loss: nan
second_0:                 episode reward: -1.3500,                 loss: 0.0388
Episode: 9401/50000 (18.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.82s / 63830.47 s
first_0:                 episode reward: 1.1500,                 loss: nan
second_0:                 episode reward: -1.1500,                 loss: 0.0386
Episode: 9421/50000 (18.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 137.57s / 63968.04 s
first_0:                 episode reward: 0.7500,                 loss: nan
second_0:                 episode reward: -0.7500,                 loss: 0.0385
Episode: 9441/50000 (18.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.95s / 64104.99 s
first_0:                 episode reward: 1.3000,                 loss: nan
second_0:                 episode reward: -1.3000,                 loss: 0.0395
Episode: 9461/50000 (18.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.89s / 64241.88 s
first_0:                 episode reward: 1.5500,                 loss: nan
second_0:                 episode reward: -1.5500,                 loss: 0.0398
Episode: 9481/50000 (18.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 135.98s / 64377.86 s
first_0:                 episode reward: 1.9500,                 loss: nan
second_0:                 episode reward: -1.9500,                 loss: 0.0411
Episode: 9501/50000 (19.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.67s / 64514.54 s
first_0:                 episode reward: 1.0500,                 loss: nan
second_0:                 episode reward: -1.0500,                 loss: 0.0411
Episode: 9521/50000 (19.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.97s / 64651.51 s
first_0:                 episode reward: 1.1000,                 loss: nan
second_0:                 episode reward: -1.1000,                 loss: 0.0418
Episode: 9541/50000 (19.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.73s / 64788.23 s
first_0:                 episode reward: 1.2000,                 loss: nan
second_0:                 episode reward: -1.2000,                 loss: 0.0410
Episode: 9561/50000 (19.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 137.26s / 64925.49 s
first_0:                 episode reward: 1.2000,                 loss: nan
second_0:                 episode reward: -1.2000,                 loss: 0.0413
Episode: 9581/50000 (19.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 136.88s / 65062.37 s
first_0:                 episode reward: 1.1500,                 loss: nan
second_0:                 episode reward: -1.1500,                 loss: 0.0418
Episode: 9601/50000 (19.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.13s / 65198.50 s
first_0:                 episode reward: 0.6000,                 loss: nan
second_0:                 episode reward: -0.6000,                 loss: 0.0406
Episode: 9621/50000 (19.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.57s / 65335.07 s
first_0:                 episode reward: 1.1000,                 loss: nan
second_0:                 episode reward: -1.1000,                 loss: 0.0392
Episode: 9641/50000 (19.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.73s / 65471.80 s
first_0:                 episode reward: 1.3500,                 loss: nan
second_0:                 episode reward: -1.3500,                 loss: 0.0386
Episode: 9661/50000 (19.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 137.70s / 65609.50 s
first_0:                 episode reward: 0.7000,                 loss: nan
second_0:                 episode reward: -0.7000,                 loss: 0.0381
Episode: 9681/50000 (19.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 136.38s / 65745.87 s
first_0:                 episode reward: 1.1000,                 loss: nan
second_0:                 episode reward: -1.1000,                 loss: 0.0395
Episode: 9701/50000 (19.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 137.32s / 65883.20 s
first_0:                 episode reward: 1.3500,                 loss: nan
second_0:                 episode reward: -1.3500,                 loss: 0.0397
Episode: 9721/50000 (19.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.39s / 66019.59 s
first_0:                 episode reward: 1.0500,                 loss: nan
second_0:                 episode reward: -1.0500,                 loss: 0.0403
Episode: 9741/50000 (19.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.46s / 66156.04 s
first_0:                 episode reward: 1.1500,                 loss: nan
second_0:                 episode reward: -1.1500,                 loss: 0.0409
Episode: 9761/50000 (19.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.93s / 66292.98 s
first_0:                 episode reward: 1.2000,                 loss: nan
second_0:                 episode reward: -1.2000,                 loss: 0.0405
Episode: 9781/50000 (19.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 137.61s / 66430.58 s
first_0:                 episode reward: 0.8000,                 loss: nan
second_0:                 episode reward: -0.8000,                 loss: 0.0400
Episode: 9801/50000 (19.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.30s / 66566.88 s
first_0:                 episode reward: 1.1500,                 loss: nan
second_0:                 episode reward: -1.1500,                 loss: 0.0396
Episode: 9821/50000 (19.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.61s / 66703.49 s
first_0:                 episode reward: 1.0500,                 loss: nan
second_0:                 episode reward: -1.0500,                 loss: 0.0398
Episode: 9841/50000 (19.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.30s / 66839.79 s
first_0:                 episode reward: 1.3500,                 loss: nan
second_0:                 episode reward: -1.3500,                 loss: 0.0396
Episode: 9861/50000 (19.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.32s / 66976.11 s
first_0:                 episode reward: 2.1500,                 loss: nan
second_0:                 episode reward: -2.1500,                 loss: 0.0404
Episode: 9881/50000 (19.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 135.91s / 67112.03 s
first_0:                 episode reward: 1.3500,                 loss: nan
second_0:                 episode reward: -1.3500,                 loss: 0.0410
Episode: 9901/50000 (19.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.61s / 67248.64 s
first_0:                 episode reward: 0.9000,                 loss: nan
second_0:                 episode reward: -0.9000,                 loss: 0.0396
Episode: 9921/50000 (19.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.58s / 67385.22 s
first_0:                 episode reward: 1.5000,                 loss: nan
second_0:                 episode reward: -1.5000,                 loss: 0.0395
Episode: 9941/50000 (19.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.71s / 67521.93 s
first_0:                 episode reward: 1.4000,                 loss: nan
second_0:                 episode reward: -1.4000,                 loss: 0.0392
Episode: 9961/50000 (19.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 137.04s / 67658.97 s
first_0:                 episode reward: 1.4500,                 loss: nan
second_0:                 episode reward: -1.4500,                 loss: 0.0388
Episode: 9981/50000 (19.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 136.18s / 67795.15 s
first_0:                 episode reward: 1.6000,                 loss: nan
second_0:                 episode reward: -1.6000,                 loss: 0.0407
Episode: 10001/50000 (20.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 135.99s / 67931.14 s
first_0:                 episode reward: 1.2500,                 loss: nan
second_0:                 episode reward: -1.2500,                 loss: 0.0415
Episode: 10021/50000 (20.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 135.98s / 68067.12 s
first_0:                 episode reward: 0.5000,                 loss: nan
second_0:                 episode reward: -0.5000,                 loss: 0.0416
Episode: 10041/50000 (20.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.70s / 68203.82 s
first_0:                 episode reward: 1.6000,                 loss: nan
second_0:                 episode reward: -1.6000,                 loss: 0.0409
Episode: 10061/50000 (20.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 137.40s / 68341.22 s
first_0:                 episode reward: 0.9500,                 loss: nan
second_0:                 episode reward: -0.9500,                 loss: 0.0388
Episode: 10081/50000 (20.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 136.60s / 68477.82 s
first_0:                 episode reward: 0.8500,                 loss: nan
second_0:                 episode reward: -0.8500,                 loss: 0.0399
Episode: 10101/50000 (20.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 137.49s / 68615.31 s
first_0:                 episode reward: 1.6000,                 loss: nan
second_0:                 episode reward: -1.6000,                 loss: 0.0404
Episode: 10121/50000 (20.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.31s / 68751.62 s
first_0:                 episode reward: 0.4500,                 loss: nan
second_0:                 episode reward: -0.4500,                 loss: 0.0402
Episode: 10141/50000 (20.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.58s / 68888.21 s
first_0:                 episode reward: 1.2500,                 loss: nan
second_0:                 episode reward: -1.2500,                 loss: 0.0397
Episode: 10161/50000 (20.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.80s / 69025.01 s
first_0:                 episode reward: 1.1000,                 loss: nan
second_0:                 episode reward: -1.1000,                 loss: 0.0392
Episode: 10181/50000 (20.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 136.84s / 69161.85 s
first_0:                 episode reward: 1.2000,                 loss: nan
second_0:                 episode reward: -1.2000,                 loss: 0.0381
Episode: 10201/50000 (20.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.88s / 69298.73 s
first_0:                 episode reward: 1.5500,                 loss: nan
second_0:                 episode reward: -1.5500,                 loss: 0.0381
Episode: 10221/50000 (20.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.08s / 69434.81 s
first_0:                 episode reward: 0.4000,                 loss: nan
second_0:                 episode reward: -0.4000,                 loss: 0.0382
Episode: 10241/50000 (20.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.12s / 69570.93 s
first_0:                 episode reward: 1.0000,                 loss: nan
second_0:                 episode reward: -1.0000,                 loss: 0.0380
Episode: 10261/50000 (20.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.82s / 69707.74 s
first_0:                 episode reward: 1.1500,                 loss: nan
second_0:                 episode reward: -1.1500,                 loss: 0.0387
Episode: 10281/50000 (20.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 136.02s / 69843.76 s
first_0:                 episode reward: 0.4500,                 loss: nan
second_0:                 episode reward: -0.4500,                 loss: 0.0383
Episode: 10301/50000 (20.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 135.67s / 69979.43 s
first_0:                 episode reward: 1.3500,                 loss: nan
second_0:                 episode reward: -1.3500,                 loss: 0.0382
Episode: 10321/50000 (20.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 137.16s / 70116.59 s
first_0:                 episode reward: 1.5000,                 loss: nan
second_0:                 episode reward: -1.5000,                 loss: 0.0389
Episode: 10341/50000 (20.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 135.91s / 70252.50 s
first_0:                 episode reward: 1.5000,                 loss: nan
second_0:                 episode reward: -1.5000,                 loss: 0.0386
Episode: 10361/50000 (20.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.57s / 70389.06 s
first_0:                 episode reward: 1.7000,                 loss: nan
second_0:                 episode reward: -1.7000,                 loss: 0.0379
Episode: 10381/50000 (20.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 136.53s / 70525.59 s
first_0:                 episode reward: 1.6000,                 loss: nan
second_0:                 episode reward: -1.6000,                 loss: 0.0376
Episode: 10401/50000 (20.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.36s / 70661.95 s
first_0:                 episode reward: 1.2500,                 loss: nan
second_0:                 episode reward: -1.2500,                 loss: 0.0377
Episode: 10421/50000 (20.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.99s / 70798.94 s
first_0:                 episode reward: 0.9000,                 loss: nan
second_0:                 episode reward: -0.9000,                 loss: 0.0384
Episode: 10441/50000 (20.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.43s / 70935.37 s
first_0:                 episode reward: 1.0500,                 loss: nan
second_0:                 episode reward: -1.0500,                 loss: 0.0392
Episode: 10461/50000 (20.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.67s / 71072.04 s
first_0:                 episode reward: 0.8000,                 loss: nan
second_0:                 episode reward: -0.8000,                 loss: 0.0391
Episode: 10481/50000 (20.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 136.51s / 71208.55 s
first_0:                 episode reward: 1.1000,                 loss: nan
second_0:                 episode reward: -1.1000,                 loss: 0.0390
Episode: 10501/50000 (21.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.80s / 71345.35 s
first_0:                 episode reward: 1.2000,                 loss: nan
second_0:                 episode reward: -1.2000,                 loss: 0.0387
Episode: 10521/50000 (21.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 137.50s / 71482.85 s
first_0:                 episode reward: 1.2500,                 loss: nan
second_0:                 episode reward: -1.2500,                 loss: 0.0392
Episode: 10541/50000 (21.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.78s / 71619.63 s
first_0:                 episode reward: 0.8000,                 loss: nan
second_0:                 episode reward: -0.8000,                 loss: 0.0397
Episode: 10561/50000 (21.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.62s / 71756.26 s
first_0:                 episode reward: 0.8000,                 loss: nan
second_0:                 episode reward: -0.8000,                 loss: 0.0407
Episode: 10581/50000 (21.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 136.22s / 71892.48 s
first_0:                 episode reward: 1.1000,                 loss: nan
second_0:                 episode reward: -1.1000,                 loss: 0.0404
Episode: 10601/50000 (21.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.47s / 72028.95 s
first_0:                 episode reward: 1.1500,                 loss: nan
second_0:                 episode reward: -1.1500,                 loss: 0.0395
Episode: 10621/50000 (21.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.34s / 72165.29 s
first_0:                 episode reward: 0.9000,                 loss: nan
second_0:                 episode reward: -0.9000,                 loss: 0.0412
Episode: 10641/50000 (21.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.52s / 72301.81 s
first_0:                 episode reward: 1.2500,                 loss: nan
second_0:                 episode reward: -1.2500,                 loss: 0.0404
Episode: 10661/50000 (21.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 137.18s / 72438.98 s
first_0:                 episode reward: 1.1500,                 loss: nan
second_0:                 episode reward: -1.1500,                 loss: 0.0411
Episode: 10681/50000 (21.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 136.04s / 72575.02 s
first_0:                 episode reward: 0.9000,                 loss: nan
second_0:                 episode reward: -0.9000,                 loss: 0.0415
Episode: 10701/50000 (21.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.06s / 72711.08 s
first_0:                 episode reward: 1.1000,                 loss: nan
second_0:                 episode reward: -1.1000,                 loss: 0.0411
Episode: 10721/50000 (21.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.93s / 72848.01 s
first_0:                 episode reward: 0.4000,                 loss: nan
second_0:                 episode reward: -0.4000,                 loss: 0.0422
Episode: 10741/50000 (21.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.87s / 72984.88 s
first_0:                 episode reward: 0.9500,                 loss: nan
second_0:                 episode reward: -0.9500,                 loss: 0.0425
Episode: 10761/50000 (21.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.46s / 73121.35 s
first_0:                 episode reward: 0.9000,                 loss: nan
second_0:                 episode reward: -0.9000,                 loss: 0.0419
Episode: 10781/50000 (21.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 137.55s / 73258.90 s
first_0:                 episode reward: 1.0500,                 loss: nan
second_0:                 episode reward: -1.0500,                 loss: 0.0424
Episode: 10801/50000 (21.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.39s / 73395.29 s
first_0:                 episode reward: 0.5000,                 loss: nan
second_0:                 episode reward: -0.5000,                 loss: 0.0417
Episode: 10821/50000 (21.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.87s / 73532.16 s
first_0:                 episode reward: 1.5500,                 loss: nan
second_0:                 episode reward: -1.5500,                 loss: 0.0395
Episode: 10841/50000 (21.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.74s / 73668.90 s
first_0:                 episode reward: 0.7000,                 loss: nan
second_0:                 episode reward: -0.7000,                 loss: 0.0384
Episode: 10861/50000 (21.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.63s / 73805.53 s
first_0:                 episode reward: 0.8000,                 loss: nan
second_0:                 episode reward: -0.8000,                 loss: 0.0387
Episode: 10881/50000 (21.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 136.47s / 73942.00 s
first_0:                 episode reward: 1.4500,                 loss: nan
second_0:                 episode reward: -1.4500,                 loss: 0.0389
Episode: 10901/50000 (21.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 137.15s / 74079.15 s
first_0:                 episode reward: 1.0500,                 loss: nan
second_0:                 episode reward: -1.0500,                 loss: 0.0386
Episode: 10921/50000 (21.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.14s / 74215.29 s
first_0:                 episode reward: 1.6000,                 loss: nan
second_0:                 episode reward: -1.6000,                 loss: 0.0392
Episode: 10941/50000 (21.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.60s / 74351.89 s
first_0:                 episode reward: 1.1000,                 loss: nan
second_0:                 episode reward: -1.1000,                 loss: 0.0406
Episode: 10961/50000 (21.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 138.13s / 74490.02 s
first_0:                 episode reward: 1.5500,                 loss: nan
second_0:                 episode reward: -1.5500,                 loss: 0.0410
Episode: 10981/50000 (21.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 136.22s / 74626.25 s
first_0:                 episode reward: 0.9500,                 loss: nan
second_0:                 episode reward: -0.9500,                 loss: 0.0404
Episode: 11001/50000 (22.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.84s / 74763.09 s
first_0:                 episode reward: 1.0000,                 loss: nan
second_0:                 episode reward: -1.0000,                 loss: 0.0414
Episode: 11021/50000 (22.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 137.01s / 74900.10 s
first_0:                 episode reward: 1.5500,                 loss: nan
second_0:                 episode reward: -1.5500,                 loss: 0.0409
Episode: 11041/50000 (22.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.45s / 75036.55 s
first_0:                 episode reward: 1.0000,                 loss: nan
second_0:                 episode reward: -1.0000,                 loss: 0.0399
Episode: 11061/50000 (22.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.11s / 75172.66 s
first_0:                 episode reward: 1.1000,                 loss: nan
second_0:                 episode reward: -1.1000,                 loss: 0.0401
Episode: 11081/50000 (22.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 136.74s / 75309.40 s
first_0:                 episode reward: 1.3500,                 loss: nan
second_0:                 episode reward: -1.3500,                 loss: 0.0404
Episode: 11101/50000 (22.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.10s / 75445.49 s
first_0:                 episode reward: 1.2500,                 loss: nan
second_0:                 episode reward: -1.2500,                 loss: 0.0408
Episode: 11121/50000 (22.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.20s / 75581.70 s
first_0:                 episode reward: 1.0500,                 loss: nan
second_0:                 episode reward: -1.0500,                 loss: 0.0395
Episode: 11141/50000 (22.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.14s / 75717.84 s
first_0:                 episode reward: 1.4000,                 loss: nan
second_0:                 episode reward: -1.4000,                 loss: 0.0413
Episode: 11161/50000 (22.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 135.64s / 75853.48 s
first_0:                 episode reward: 1.4000,                 loss: nan
second_0:                 episode reward: -1.4000,                 loss: 0.0405
Episode: 11181/50000 (22.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 137.37s / 75990.85 s
first_0:                 episode reward: 1.1500,                 loss: nan
second_0:                 episode reward: -1.1500,                 loss: 0.0416
Episode: 11201/50000 (22.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 137.23s / 76128.08 s
first_0:                 episode reward: 1.2500,                 loss: nan
second_0:                 episode reward: -1.2500,                 loss: 0.0414
Episode: 11221/50000 (22.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 137.02s / 76265.10 s
first_0:                 episode reward: 0.7500,                 loss: nan
second_0:                 episode reward: -0.7500,                 loss: 0.0403
Episode: 11241/50000 (22.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.76s / 76401.86 s
first_0:                 episode reward: 0.9500,                 loss: nan
second_0:                 episode reward: -0.9500,                 loss: 0.0397
Episode: 11261/50000 (22.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.60s / 76538.45 s
first_0:                 episode reward: 0.8500,                 loss: nan
second_0:                 episode reward: -0.8500,                 loss: 0.0410
Episode: 11281/50000 (22.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 136.82s / 76675.27 s
first_0:                 episode reward: 1.6500,                 loss: nan
second_0:                 episode reward: -1.6500,                 loss: 0.0403
Episode: 11301/50000 (22.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.75s / 76812.03 s
first_0:                 episode reward: 1.3500,                 loss: nan
second_0:                 episode reward: -1.3500,                 loss: 0.0421
Episode: 11321/50000 (22.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.06s / 76948.08 s
first_0:                 episode reward: 0.9000,                 loss: nan
second_0:                 episode reward: -0.9000,                 loss: 0.0414
Episode: 11341/50000 (22.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.59s / 77084.68 s
first_0:                 episode reward: 0.9500,                 loss: nan
second_0:                 episode reward: -0.9500,                 loss: 0.0409
Episode: 11361/50000 (22.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.96s / 77221.63 s
first_0:                 episode reward: 1.1000,                 loss: nan
second_0:                 episode reward: -1.1000,                 loss: 0.0408
Episode: 11381/50000 (22.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 137.12s / 77358.76 s
first_0:                 episode reward: 1.1000,                 loss: nan
second_0:                 episode reward: -1.1000,                 loss: 0.0401
Episode: 11401/50000 (22.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 137.10s / 77495.85 s
first_0:                 episode reward: 1.8500,                 loss: nan
second_0:                 episode reward: -1.8500,                 loss: 0.0374
Episode: 11421/50000 (22.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 137.13s / 77632.99 s
first_0:                 episode reward: 1.1000,                 loss: nan
second_0:                 episode reward: -1.1000,                 loss: 0.0393
Episode: 11441/50000 (22.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.30s / 77769.28 s
first_0:                 episode reward: 1.3500,                 loss: nan
second_0:                 episode reward: -1.3500,                 loss: 0.0399
Episode: 11461/50000 (22.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.94s / 77906.22 s
first_0:                 episode reward: 1.3000,                 loss: nan
second_0:                 episode reward: -1.3000,                 loss: 0.0391
Episode: 11481/50000 (22.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 137.13s / 78043.35 s
first_0:                 episode reward: 1.2000,                 loss: nan
second_0:                 episode reward: -1.2000,                 loss: 0.0411
Episode: 11501/50000 (23.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.53s / 78179.88 s
first_0:                 episode reward: 1.5000,                 loss: nan
second_0:                 episode reward: -1.5000,                 loss: 0.0421
Episode: 11521/50000 (23.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 137.05s / 78316.92 s
first_0:                 episode reward: 1.5500,                 loss: nan
second_0:                 episode reward: -1.5500,                 loss: 0.0410
Episode: 11541/50000 (23.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.99s / 78453.91 s
first_0:                 episode reward: 0.9500,                 loss: nan
second_0:                 episode reward: -0.9500,                 loss: 0.0401
Episode: 11561/50000 (23.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.03s / 78589.94 s
first_0:                 episode reward: 1.2000,                 loss: nan
second_0:                 episode reward: -1.2000,                 loss: 0.0409
Episode: 11581/50000 (23.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 136.48s / 78726.43 s
first_0:                 episode reward: 1.4000,                 loss: nan
second_0:                 episode reward: -1.4000,                 loss: 0.0416
Episode: 11601/50000 (23.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.68s / 78863.11 s
first_0:                 episode reward: 0.9000,                 loss: nan
second_0:                 episode reward: -0.9000,                 loss: 0.0429
Episode: 11621/50000 (23.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 137.73s / 79000.84 s
first_0:                 episode reward: 1.0500,                 loss: nan
second_0:                 episode reward: -1.0500,                 loss: 0.0412
Episode: 11641/50000 (23.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.18s / 79137.01 s
first_0:                 episode reward: 0.8500,                 loss: nan
second_0:                 episode reward: -0.8500,                 loss: 0.0425
Episode: 11661/50000 (23.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.49s / 79273.50 s
first_0:                 episode reward: 0.9000,                 loss: nan
second_0:                 episode reward: -0.9000,                 loss: 0.0425
Episode: 11681/50000 (23.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 137.83s / 79411.33 s
first_0:                 episode reward: 1.6000,                 loss: nan
second_0:                 episode reward: -1.6000,                 loss: 0.0424
Episode: 11701/50000 (23.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 137.65s / 79548.99 s
first_0:                 episode reward: 0.5500,                 loss: nan
second_0:                 episode reward: -0.5500,                 loss: 0.0424
Episode: 11721/50000 (23.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 137.30s / 79686.28 s
first_0:                 episode reward: 1.2500,                 loss: nan
second_0:                 episode reward: -1.2500,                 loss: 0.0425
Episode: 11741/50000 (23.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.10s / 79822.38 s
first_0:                 episode reward: 0.9500,                 loss: nan
second_0:                 episode reward: -0.9500,                 loss: 0.0435
Episode: 11761/50000 (23.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.46s / 79958.84 s
first_0:                 episode reward: 1.1500,                 loss: nan
second_0:                 episode reward: -1.1500,                 loss: 0.0442
Episode: 11781/50000 (23.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 137.51s / 80096.35 s
first_0:                 episode reward: 0.8000,                 loss: nan
second_0:                 episode reward: -0.8000,                 loss: 0.0428
Episode: 11801/50000 (23.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.03s / 80232.39 s
first_0:                 episode reward: 1.0000,                 loss: nan
second_0:                 episode reward: -1.0000,                 loss: 0.0419
Episode: 11821/50000 (23.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.62s / 80369.01 s
first_0:                 episode reward: 1.6000,                 loss: nan
second_0:                 episode reward: -1.6000,                 loss: 0.0428
Episode: 11841/50000 (23.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.32s / 80505.32 s
first_0:                 episode reward: 1.1000,                 loss: nan
second_0:                 episode reward: -1.1000,                 loss: 0.0423
Episode: 11861/50000 (23.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.93s / 80642.25 s
first_0:                 episode reward: 1.2500,                 loss: nan
second_0:                 episode reward: -1.2500,                 loss: 0.0436
Episode: 11881/50000 (23.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 136.08s / 80778.33 s
first_0:                 episode reward: 1.0500,                 loss: nan
second_0:                 episode reward: -1.0500,                 loss: 0.0439
Episode: 11901/50000 (23.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 137.77s / 80916.10 s
first_0:                 episode reward: 1.1500,                 loss: nan
second_0:                 episode reward: -1.1500,                 loss: 0.0432
Episode: 11921/50000 (23.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.92s / 81053.02 s
first_0:                 episode reward: 1.1000,                 loss: nan
second_0:                 episode reward: -1.1000,                 loss: 0.0425
Episode: 11941/50000 (23.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.63s / 81189.65 s
first_0:                 episode reward: 0.9500,                 loss: nan
second_0:                 episode reward: -0.9500,                 loss: 0.0416
Episode: 11961/50000 (23.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 137.16s / 81326.82 s
first_0:                 episode reward: 1.0500,                 loss: nan
second_0:                 episode reward: -1.0500,                 loss: 0.0411
Episode: 11981/50000 (23.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 137.02s / 81463.84 s
first_0:                 episode reward: 1.3500,                 loss: nan
second_0:                 episode reward: -1.3500,                 loss: 0.0405
Episode: 12001/50000 (24.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.99s / 81600.83 s
first_0:                 episode reward: 1.1500,                 loss: nan
second_0:                 episode reward: -1.1500,                 loss: 0.0402
Episode: 12021/50000 (24.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.89s / 81737.72 s
first_0:                 episode reward: 1.4500,                 loss: nan
second_0:                 episode reward: -1.4500,                 loss: 0.0408
Episode: 12041/50000 (24.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 137.31s / 81875.03 s
first_0:                 episode reward: 1.9500,                 loss: nan
second_0:                 episode reward: -1.9500,                 loss: 0.0419
Episode: 12061/50000 (24.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.38s / 82011.41 s
first_0:                 episode reward: 0.6000,                 loss: nan
second_0:                 episode reward: -0.6000,                 loss: 0.0432
Episode: 12081/50000 (24.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 136.55s / 82147.95 s
first_0:                 episode reward: 1.5000,                 loss: nan
second_0:                 episode reward: -1.5000,                 loss: 0.0398
Episode: 12101/50000 (24.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.70s / 82284.66 s
first_0:                 episode reward: 0.7000,                 loss: nan
second_0:                 episode reward: -0.7000,                 loss: 0.0400
Episode: 12121/50000 (24.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.81s / 82421.47 s
first_0:                 episode reward: 1.3000,                 loss: nan
second_0:                 episode reward: -1.3000,                 loss: 0.0389
Episode: 12141/50000 (24.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.26s / 82557.73 s
first_0:                 episode reward: 0.9000,                 loss: nan
second_0:                 episode reward: -0.9000,                 loss: 0.0393
Episode: 12161/50000 (24.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.88s / 82694.61 s
first_0:                 episode reward: 1.4500,                 loss: nan
second_0:                 episode reward: -1.4500,                 loss: 0.0401
Episode: 12181/50000 (24.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 136.86s / 82831.46 s
first_0:                 episode reward: 0.8500,                 loss: nan
second_0:                 episode reward: -0.8500,                 loss: 0.0406
Episode: 12201/50000 (24.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 137.22s / 82968.69 s
first_0:                 episode reward: 1.4000,                 loss: nan
second_0:                 episode reward: -1.4000,                 loss: 0.0397
Episode: 12221/50000 (24.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.62s / 83105.31 s
first_0:                 episode reward: 1.4000,                 loss: nan
second_0:                 episode reward: -1.4000,                 loss: 0.0409
Episode: 12241/50000 (24.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.45s / 83241.75 s
first_0:                 episode reward: 0.7500,                 loss: nan
second_0:                 episode reward: -0.7500,                 loss: 0.0396
Episode: 12261/50000 (24.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.25s / 83378.01 s
first_0:                 episode reward: 1.2500,                 loss: nan
second_0:                 episode reward: -1.2500,                 loss: 0.0400
Episode: 12281/50000 (24.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 137.03s / 83515.04 s
first_0:                 episode reward: 1.1000,                 loss: nan
second_0:                 episode reward: -1.1000,                 loss: 0.0399
Episode: 12301/50000 (24.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.51s / 83651.55 s
first_0:                 episode reward: 1.0500,                 loss: nan
second_0:                 episode reward: -1.0500,                 loss: 0.0398
Episode: 12321/50000 (24.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 135.74s / 83787.29 s
first_0:                 episode reward: 0.9500,                 loss: nan
second_0:                 episode reward: -0.9500,                 loss: 0.0400
Episode: 12341/50000 (24.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.36s / 83923.66 s
first_0:                 episode reward: 1.9000,                 loss: nan
second_0:                 episode reward: -1.9000,                 loss: 0.0396
Episode: 12361/50000 (24.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 136.57s / 84060.23 s
first_0:                 episode reward: 1.8500,                 loss: nan
second_0:                 episode reward: -1.8500,                 loss: 0.0404
Episode: 12381/50000 (24.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 136.43s / 84196.65 s
first_0:                 episode reward: 1.6500,                 loss: nan
second_0:                 episode reward: -1.6500,                 loss: 0.0400
Episode: 12401/50000 (24.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.37s / 84333.02 s
first_0:                 episode reward: 1.0000,                 loss: nan
second_0:                 episode reward: -1.0000,                 loss: 0.0397
Episode: 12421/50000 (24.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.99s / 84470.01 s
first_0:                 episode reward: 1.4000,                 loss: nan
second_0:                 episode reward: -1.4000,                 loss: 0.0390
Episode: 12441/50000 (24.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.93s / 84606.94 s
first_0:                 episode reward: 1.3500,                 loss: nan
second_0:                 episode reward: -1.3500,                 loss: 0.0391
Episode: 12461/50000 (24.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 137.12s / 84744.06 s
first_0:                 episode reward: 1.6000,                 loss: nan
second_0:                 episode reward: -1.6000,                 loss: 0.0381
Episode: 12481/50000 (24.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 137.49s / 84881.55 s
first_0:                 episode reward: 1.7500,                 loss: nan
second_0:                 episode reward: -1.7500,                 loss: 0.0388
Episode: 12501/50000 (25.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 136.27s / 85017.82 s
first_0:                 episode reward: 1.3500,                 loss: nan
second_0:                 episode reward: -1.3500,                 loss: 0.0382
Episode: 12521/50000 (25.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 137.04s / 85154.86 s
first_0:                 episode reward: 1.7500,                 loss: nan
second_0:                 episode reward: -1.7500,                 loss: 0.0380
Episode: 12541/50000 (25.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.58s / 85291.44 s
first_0:                 episode reward: 1.6000,                 loss: nan
second_0:                 episode reward: -1.6000,                 loss: 0.0393
Episode: 12561/50000 (25.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 137.54s / 85428.98 s
first_0:                 episode reward: 1.0000,                 loss: nan
second_0:                 episode reward: -1.0000,                 loss: 0.0395
Episode: 12581/50000 (25.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 137.43s / 85566.41 s
first_0:                 episode reward: 1.2000,                 loss: nan
second_0:                 episode reward: -1.2000,                 loss: 0.0394
Episode: 12601/50000 (25.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 137.25s / 85703.65 s
first_0:                 episode reward: 1.3000,                 loss: nan
second_0:                 episode reward: -1.3000,                 loss: 0.0396
Episode: 12621/50000 (25.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.20s / 85839.85 s
first_0:                 episode reward: 0.5500,                 loss: nan
second_0:                 episode reward: -0.5500,                 loss: 0.0394
Episode: 12641/50000 (25.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.38s / 85976.23 s
first_0:                 episode reward: 0.9000,                 loss: nan
second_0:                 episode reward: -0.9000,                 loss: 0.0397
Episode: 12661/50000 (25.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 135.97s / 86112.20 s
first_0:                 episode reward: 1.3500,                 loss: nan
second_0:                 episode reward: -1.3500,                 loss: 0.0402
Episode: 12681/50000 (25.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 137.91s / 86250.10 s
first_0:                 episode reward: 1.1000,                 loss: nan
second_0:                 episode reward: -1.1000,                 loss: 0.0404
Episode: 12701/50000 (25.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 137.18s / 86387.29 s
first_0:                 episode reward: 1.3000,                 loss: nan
second_0:                 episode reward: -1.3000,                 loss: 0.0418
Episode: 12721/50000 (25.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 136.97s / 86524.26 s
first_0:                 episode reward: 1.3500,                 loss: nan
second_0:                 episode reward: -1.3500,                 loss: 0.0409
Episode: 12741/50000 (25.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 136.28s / 86660.54 s
first_0:                 episode reward: 1.1000,                 loss: nan
second_0:                 episode reward: -1.1000,                 loss: 0.0421
Episode: 12761/50000 (25.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 138.31s / 86798.85 s
first_0:                 episode reward: 1.1500,                 loss: nan