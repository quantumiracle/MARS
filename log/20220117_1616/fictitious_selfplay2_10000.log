pygame 2.0.0 (SDL 2.0.12, python 3.7.10)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 12.0, (1,), float32) action space: Discrete(3)
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7f488f09fb90>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
Agents No. [0] (index starting from 0) are not learnable.
Load meta strategy:  [[0.2 0.2 0.2 0.2 0.2]
 [0.2 0.2 0.2 0.2 0.2]]
Load checkpoints (policy family):  [['50' '5253' '7615' '8835' '9107']
 ['193' '5289' '7712' '9011' '9134']]
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': 1, 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000, 'update_itr': 1}, 'batch_size': 640, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'cpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220117153310/epi_10000/', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'fictitious_selfplay2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'selfplay_score_delta': 1.5, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'against_baseline': False}
Save models to : /home/zihan/research/MARS/data/model/20220117153310_exploit_10000/mdp_arbitrary_mdp_fictitious_selfplay2. 
 Save logs to: /home/zihan/research/MARS/data/log/20220117153310_exploit_10000/mdp_arbitrary_mdp_fictitious_selfplay2.
Episode: 1/30000 (0.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 5.8183s / 5.8183 s
agent0:                 episode reward: 1.8170,                 loss: nan
agent1:                 episode reward: -1.8170,                 loss: nan
Episode: 21/30000 (0.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 6.7170s / 12.5353 s
agent0:                 episode reward: 0.1497,                 loss: nan
agent1:                 episode reward: -0.1497,                 loss: nan
Episode: 41/30000 (0.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 7.0414s / 19.5766 s
agent0:                 episode reward: -0.3376,                 loss: nan
agent1:                 episode reward: 0.3376,                 loss: nan
Episode: 61/30000 (0.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 6.5117s / 26.0884 s
agent0:                 episode reward: -0.1772,                 loss: nan
agent1:                 episode reward: 0.1772,                 loss: nan
Episode: 81/30000 (0.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 7.0605s / 33.1488 s
agent0:                 episode reward: -0.0070,                 loss: nan
agent1:                 episode reward: 0.0070,                 loss: nan
Episode: 101/30000 (0.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 6.7655s / 39.9144 s
agent0:                 episode reward: -0.3308,                 loss: nan
agent1:                 episode reward: 0.3308,                 loss: nan
Episode: 121/30000 (0.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 6.4658s / 46.3802 s
agent0:                 episode reward: 0.4399,                 loss: nan
agent1:                 episode reward: -0.4399,                 loss: nan
Episode: 141/30000 (0.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 7.0633s / 53.4435 s
agent0:                 episode reward: 0.2257,                 loss: nan
agent1:                 episode reward: -0.2257,                 loss: nan
Episode: 161/30000 (0.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 7.2724s / 60.7159 s
agent0:                 episode reward: 0.0890,                 loss: nan
agent1:                 episode reward: -0.0890,                 loss: nan
Episode: 181/30000 (0.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 7.7631s / 68.4790 s
agent0:                 episode reward: -0.0480,                 loss: nan
agent1:                 episode reward: 0.0480,                 loss: nan
Episode: 201/30000 (0.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 7.0985s / 75.5776 s
agent0:                 episode reward: 0.0510,                 loss: nan
agent1:                 episode reward: -0.0510,                 loss: nan
Episode: 221/30000 (0.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 97.1968s / 172.7744 s
agent0:                 episode reward: -0.2606,                 loss: nan
agent1:                 episode reward: 0.2606,                 loss: 0.1964
Episode: 241/30000 (0.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.2654s / 414.0398 s
agent0:                 episode reward: -0.1490,                 loss: nan
agent1:                 episode reward: 0.1490,                 loss: 0.1843
Episode: 261/30000 (0.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.0752s / 657.1150 s
agent0:                 episode reward: -0.1006,                 loss: nan
agent1:                 episode reward: 0.1006,                 loss: 0.1753
Episode: 281/30000 (0.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 239.3007s / 896.4157 s
agent0:                 episode reward: -0.0356,                 loss: nan
agent1:                 episode reward: 0.0356,                 loss: 0.1696
Episode: 301/30000 (1.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 237.9460s / 1134.3617 s
agent0:                 episode reward: 0.3441,                 loss: nan
agent1:                 episode reward: -0.3441,                 loss: 0.1658
Episode: 321/30000 (1.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.2520s / 1379.6136 s
agent0:                 episode reward: 0.2270,                 loss: nan
agent1:                 episode reward: -0.2270,                 loss: 0.1606
Episode: 341/30000 (1.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 240.3450s / 1619.9587 s
agent0:                 episode reward: 0.0892,                 loss: nan
agent1:                 episode reward: -0.0892,                 loss: 0.1577
Episode: 361/30000 (1.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.5816s / 1866.5403 s
agent0:                 episode reward: 0.0143,                 loss: nan
agent1:                 episode reward: -0.0143,                 loss: 0.1551
Episode: 381/30000 (1.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.9057s / 2114.4460 s
agent0:                 episode reward: 0.0696,                 loss: nan
agent1:                 episode reward: -0.0696,                 loss: 0.1509
Episode: 401/30000 (1.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.3577s / 2357.8037 s
agent0:                 episode reward: 0.1323,                 loss: nan
agent1:                 episode reward: -0.1323,                 loss: 0.1478
Episode: 421/30000 (1.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.1212s / 2601.9250 s
agent0:                 episode reward: -0.1550,                 loss: nan
agent1:                 episode reward: 0.1550,                 loss: 0.1451
Episode: 441/30000 (1.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.7543s / 2848.6792 s
agent0:                 episode reward: -0.2385,                 loss: nan
agent1:                 episode reward: 0.2385,                 loss: 0.1433
Episode: 461/30000 (1.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.6870s / 3092.3663 s
agent0:                 episode reward: 0.2453,                 loss: nan
agent1:                 episode reward: -0.2453,                 loss: 0.1418
Episode: 481/30000 (1.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 239.8688s / 3332.2351 s
agent0:                 episode reward: -0.1116,                 loss: nan
agent1:                 episode reward: 0.1116,                 loss: 0.1401
Episode: 501/30000 (1.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.9441s / 3579.1792 s
agent0:                 episode reward: -0.0660,                 loss: nan
agent1:                 episode reward: 0.0660,                 loss: 0.1386
Episode: 521/30000 (1.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 240.8562s / 3820.0354 s
agent0:                 episode reward: -0.0985,                 loss: nan
agent1:                 episode reward: 0.0985,                 loss: 0.1375
Episode: 541/30000 (1.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.3894s / 4069.4248 s
agent0:                 episode reward: 0.3460,                 loss: nan
agent1:                 episode reward: -0.3460,                 loss: 0.1392
Episode: 561/30000 (1.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.3414s / 4316.7662 s
agent0:                 episode reward: 0.0617,                 loss: nan
agent1:                 episode reward: -0.0617,                 loss: 0.1474
Episode: 581/30000 (1.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.1859s / 4561.9520 s
agent0:                 episode reward: 0.1309,                 loss: nan
agent1:                 episode reward: -0.1309,                 loss: 0.1441
Episode: 601/30000 (2.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.5697s / 4804.5217 s
agent0:                 episode reward: -0.2641,                 loss: nan
agent1:                 episode reward: 0.2641,                 loss: 0.1443
Episode: 621/30000 (2.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.2966s / 5051.8183 s
agent0:                 episode reward: 0.1908,                 loss: nan
agent1:                 episode reward: -0.1908,                 loss: 0.1412
Episode: 641/30000 (2.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.8971s / 5294.7155 s
agent0:                 episode reward: 0.0647,                 loss: nan
agent1:                 episode reward: -0.0647,                 loss: 0.1423
Episode: 661/30000 (2.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.8427s / 5537.5582 s
agent0:                 episode reward: -0.1530,                 loss: nan
agent1:                 episode reward: 0.1530,                 loss: 0.1453
Episode: 681/30000 (2.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.0969s / 5785.6550 s
agent0:                 episode reward: 0.3378,                 loss: nan
agent1:                 episode reward: -0.3378,                 loss: 0.1449
Episode: 701/30000 (2.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 253.3638s / 6039.0188 s
agent0:                 episode reward: -0.0346,                 loss: nan
agent1:                 episode reward: 0.0346,                 loss: 0.1437
Episode: 721/30000 (2.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 258.8807s / 6297.8995 s
agent0:                 episode reward: -0.0634,                 loss: nan
agent1:                 episode reward: 0.0634,                 loss: 0.1417
Episode: 741/30000 (2.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.8959s / 6545.7954 s
agent0:                 episode reward: -0.4749,                 loss: nan
agent1:                 episode reward: 0.4749,                 loss: 0.1421
Episode: 761/30000 (2.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 239.1124s / 6784.9078 s
agent0:                 episode reward: 0.4277,                 loss: nan
agent1:                 episode reward: -0.4277,                 loss: 0.1422
Episode: 781/30000 (2.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.9582s / 7031.8660 s
agent0:                 episode reward: 0.0525,                 loss: nan
agent1:                 episode reward: -0.0525,                 loss: 0.1421
Episode: 801/30000 (2.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.9050s / 7276.7710 s
agent0:                 episode reward: -0.0802,                 loss: nan
agent1:                 episode reward: 0.0802,                 loss: 0.1411
Episode: 821/30000 (2.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.5376s / 7526.3086 s
agent0:                 episode reward: -0.0375,                 loss: nan
agent1:                 episode reward: 0.0375,                 loss: 0.1413
Episode: 841/30000 (2.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 240.1438s / 7766.4524 s
agent0:                 episode reward: 0.0272,                 loss: nan
agent1:                 episode reward: -0.0272,                 loss: 0.1382
Episode: 861/30000 (2.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.9980s / 8018.4504 s
agent0:                 episode reward: -0.2664,                 loss: nan
agent1:                 episode reward: 0.2664,                 loss: 0.1407
Episode: 881/30000 (2.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.6741s / 8266.1245 s
agent0:                 episode reward: -0.4465,                 loss: nan
agent1:                 episode reward: 0.4465,                 loss: 0.1409
Episode: 901/30000 (3.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 254.6669s / 8520.7914 s
agent0:                 episode reward: -0.0612,                 loss: nan
agent1:                 episode reward: 0.0612,                 loss: 0.1458
Episode: 921/30000 (3.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.2683s / 8765.0597 s
agent0:                 episode reward: 0.0116,                 loss: nan
agent1:                 episode reward: -0.0116,                 loss: 0.1475
Episode: 941/30000 (3.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.8930s / 9017.9527 s
agent0:                 episode reward: 0.1091,                 loss: nan
agent1:                 episode reward: -0.1091,                 loss: 0.1460
Episode: 961/30000 (3.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 236.8526s / 9254.8054 s
agent0:                 episode reward: -0.1183,                 loss: nan
agent1:                 episode reward: 0.1183,                 loss: 0.1466
Episode: 981/30000 (3.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 254.6986s / 9509.5039 s
agent0:                 episode reward: 0.0505,                 loss: nan
agent1:                 episode reward: -0.0505,                 loss: 0.1460
Episode: 1001/30000 (3.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.5628s / 9760.0667 s
agent0:                 episode reward: -0.1795,                 loss: nan
agent1:                 episode reward: 0.1795,                 loss: 0.1488
Episode: 1021/30000 (3.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 237.9520s / 9998.0187 s
agent0:                 episode reward: 0.2836,                 loss: nan
agent1:                 episode reward: -0.2836,                 loss: 0.1468
Episode: 1041/30000 (3.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.4010s / 10250.4197 s
agent0:                 episode reward: 0.0372,                 loss: nan
agent1:                 episode reward: -0.0372,                 loss: 0.1459
Episode: 1061/30000 (3.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.0142s / 10494.4339 s
agent0:                 episode reward: 0.1953,                 loss: nan
agent1:                 episode reward: -0.1953,                 loss: 0.1450
Episode: 1081/30000 (3.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.6557s / 10737.0896 s
agent0:                 episode reward: 0.1986,                 loss: nan
agent1:                 episode reward: -0.1986,                 loss: 0.1454
Episode: 1101/30000 (3.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.1459s / 10988.2355 s
agent0:                 episode reward: 0.1522,                 loss: nan
agent1:                 episode reward: -0.1522,                 loss: 0.1462
Episode: 1121/30000 (3.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 254.9331s / 11243.1687 s
agent0:                 episode reward: 0.0814,                 loss: nan
agent1:                 episode reward: -0.0814,                 loss: 0.1460
Episode: 1141/30000 (3.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.6603s / 11488.8290 s
agent0:                 episode reward: 0.2114,                 loss: nan
agent1:                 episode reward: -0.2114,                 loss: 0.1467
Episode: 1161/30000 (3.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 256.1358s / 11744.9648 s
agent0:                 episode reward: -0.0832,                 loss: nan
agent1:                 episode reward: 0.0832,                 loss: 0.1449
Episode: 1181/30000 (3.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.3677s / 11991.3325 s
agent0:                 episode reward: -0.3725,                 loss: nan
agent1:                 episode reward: 0.3725,                 loss: 0.1454
Episode: 1201/30000 (4.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.2432s / 12232.5757 s
agent0:                 episode reward: -0.1339,                 loss: nan
agent1:                 episode reward: 0.1339,                 loss: 0.1451
Episode: 1221/30000 (4.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.3281s / 12477.9037 s
agent0:                 episode reward: -0.0534,                 loss: nan
agent1:                 episode reward: 0.0534,                 loss: 0.1478
Episode: 1241/30000 (4.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.2516s / 12724.1553 s
agent0:                 episode reward: -0.0453,                 loss: nan
agent1:                 episode reward: 0.0453,                 loss: 0.1482
Episode: 1261/30000 (4.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 240.8924s / 12965.0476 s
agent0:                 episode reward: -0.2130,                 loss: nan
agent1:                 episode reward: 0.2130,                 loss: 0.1493
Episode: 1281/30000 (4.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.8690s / 13211.9167 s
agent0:                 episode reward: -0.2727,                 loss: nan
agent1:                 episode reward: 0.2727,                 loss: 0.1491
Episode: 1301/30000 (4.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.0234s / 13453.9401 s
agent0:                 episode reward: 0.0629,                 loss: nan
agent1:                 episode reward: -0.0629,                 loss: 0.1510
Episode: 1321/30000 (4.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 240.3993s / 13694.3394 s
agent0:                 episode reward: -0.4483,                 loss: nan
agent1:                 episode reward: 0.4483,                 loss: 0.1500
Episode: 1341/30000 (4.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.8798s / 13937.2191 s
agent0:                 episode reward: -0.1340,                 loss: nan
agent1:                 episode reward: 0.1340,                 loss: 0.1498
Episode: 1361/30000 (4.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.0085s / 14187.2276 s
agent0:                 episode reward: -0.1429,                 loss: nan
agent1:                 episode reward: 0.1429,                 loss: 0.1484
Episode: 1381/30000 (4.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.1483s / 14433.3759 s
agent0:                 episode reward: -0.1362,                 loss: nan
agent1:                 episode reward: 0.1362,                 loss: 0.1482
Episode: 1401/30000 (4.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 255.4822s / 14688.8581 s
agent0:                 episode reward: 0.0317,                 loss: nan
agent1:                 episode reward: -0.0317,                 loss: 0.1489
Episode: 1421/30000 (4.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.0746s / 14938.9327 s
agent0:                 episode reward: -0.2314,                 loss: nan
agent1:                 episode reward: 0.2314,                 loss: 0.1476
Episode: 1441/30000 (4.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.8595s / 15184.7921 s
agent0:                 episode reward: -0.2806,                 loss: nan
agent1:                 episode reward: 0.2806,                 loss: 0.1485
Episode: 1461/30000 (4.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.7384s / 15432.5305 s
agent0:                 episode reward: -0.2531,                 loss: nan
agent1:                 episode reward: 0.2531,                 loss: 0.1499
Episode: 1481/30000 (4.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.2847s / 15676.8152 s
agent0:                 episode reward: -0.0472,                 loss: nan
agent1:                 episode reward: 0.0472,                 loss: 0.1494
Episode: 1501/30000 (5.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.9062s / 15928.7214 s
agent0:                 episode reward: -0.2826,                 loss: nan
agent1:                 episode reward: 0.2826,                 loss: 0.1472
Episode: 1521/30000 (5.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.6011s / 16171.3225 s
agent0:                 episode reward: 0.1283,                 loss: nan
agent1:                 episode reward: -0.1283,                 loss: 0.1477
Episode: 1541/30000 (5.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.0128s / 16420.3353 s
agent0:                 episode reward: -0.5088,                 loss: nan
agent1:                 episode reward: 0.5088,                 loss: 0.1502
Episode: 1561/30000 (5.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.7189s / 16667.0542 s
agent0:                 episode reward: -0.3414,                 loss: nan
agent1:                 episode reward: 0.3414,                 loss: 0.1465
Episode: 1581/30000 (5.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.3125s / 16911.3667 s
agent0:                 episode reward: -0.0156,                 loss: nan
agent1:                 episode reward: 0.0156,                 loss: 0.1481
Episode: 1601/30000 (5.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 237.2083s / 17148.5750 s
agent0:                 episode reward: -0.0983,                 loss: nan
agent1:                 episode reward: 0.0983,                 loss: 0.1484
Episode: 1621/30000 (5.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 240.9216s / 17389.4966 s
agent0:                 episode reward: -0.2084,                 loss: nan
agent1:                 episode reward: 0.2084,                 loss: 0.1475
Episode: 1641/30000 (5.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.2150s / 17637.7116 s
agent0:                 episode reward: -0.4180,                 loss: nan
agent1:                 episode reward: 0.4180,                 loss: 0.1484
Episode: 1661/30000 (5.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 241.6642s / 17879.3758 s
agent0:                 episode reward: 0.0500,                 loss: nan
agent1:                 episode reward: -0.0500,                 loss: 0.1464
Episode: 1681/30000 (5.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.7413s / 18126.1171 s
agent0:                 episode reward: -0.4198,                 loss: nan
agent1:                 episode reward: 0.4198,                 loss: 0.1457
Episode: 1701/30000 (5.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.5674s / 18375.6845 s
agent0:                 episode reward: 0.0287,                 loss: nan
agent1:                 episode reward: -0.0287,                 loss: 0.1460
Episode: 1721/30000 (5.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.1661s / 18624.8507 s
agent0:                 episode reward: -0.5915,                 loss: nan
agent1:                 episode reward: 0.5915,                 loss: 0.1472
Episode: 1741/30000 (5.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.5709s / 18867.4215 s
agent0:                 episode reward: -0.1123,                 loss: nan
agent1:                 episode reward: 0.1123,                 loss: 0.1480
Episode: 1761/30000 (5.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.1405s / 19118.5620 s
agent0:                 episode reward: -0.2076,                 loss: nan
agent1:                 episode reward: 0.2076,                 loss: 0.1484
Episode: 1781/30000 (5.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.4721s / 19368.0342 s
agent0:                 episode reward: 0.1903,                 loss: nan
agent1:                 episode reward: -0.1903,                 loss: 0.1457
Episode: 1801/30000 (6.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.8199s / 19611.8541 s
agent0:                 episode reward: -0.1930,                 loss: nan
agent1:                 episode reward: 0.1930,                 loss: 0.1473
Episode: 1821/30000 (6.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.6726s / 19855.5266 s
agent0:                 episode reward: 0.1265,                 loss: nan
agent1:                 episode reward: -0.1265,                 loss: 0.1491
Episode: 1841/30000 (6.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.5950s / 20098.1216 s
agent0:                 episode reward: 0.3388,                 loss: nan
agent1:                 episode reward: -0.3388,                 loss: 0.1486
Episode: 1861/30000 (6.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.5219s / 20343.6436 s
agent0:                 episode reward: -0.0144,                 loss: nan
agent1:                 episode reward: 0.0144,                 loss: 0.1492
Episode: 1881/30000 (6.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.0312s / 20590.6747 s
agent0:                 episode reward: 0.1800,                 loss: nan
agent1:                 episode reward: -0.1800,                 loss: 0.1466
Episode: 1901/30000 (6.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.1038s / 20834.7785 s
agent0:                 episode reward: -0.3677,                 loss: nan
agent1:                 episode reward: 0.3677,                 loss: 0.1492
Episode: 1921/30000 (6.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.6931s / 21078.4716 s
agent0:                 episode reward: 0.2371,                 loss: nan
agent1:                 episode reward: -0.2371,                 loss: 0.1474
Episode: 1941/30000 (6.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.6053s / 21330.0769 s
agent0:                 episode reward: -0.0227,                 loss: nan
agent1:                 episode reward: 0.0227,                 loss: 0.1472
Episode: 1961/30000 (6.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.6928s / 21575.7697 s
agent0:                 episode reward: -0.3160,                 loss: nan
agent1:                 episode reward: 0.3160,                 loss: 0.1480
Episode: 1981/30000 (6.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.9449s / 21822.7146 s
agent0:                 episode reward: -0.3703,                 loss: nan
agent1:                 episode reward: 0.3703,                 loss: 0.1452
Episode: 2001/30000 (6.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 254.6089s / 22077.3235 s
agent0:                 episode reward: -0.0363,                 loss: nan
agent1:                 episode reward: 0.0363,                 loss: 0.1454
Episode: 2021/30000 (6.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 236.0157s / 22313.3392 s
agent0:                 episode reward: 0.0641,                 loss: nan
agent1:                 episode reward: -0.0641,                 loss: 0.1475
Episode: 2041/30000 (6.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.7958s / 22557.1351 s
agent0:                 episode reward: -0.2339,                 loss: nan
agent1:                 episode reward: 0.2339,                 loss: 0.1461
Episode: 2061/30000 (6.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.2636s / 22806.3987 s
agent0:                 episode reward: -0.0955,                 loss: nan
agent1:                 episode reward: 0.0955,                 loss: 0.1466
Episode: 2081/30000 (6.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.4341s / 23051.8329 s
agent0:                 episode reward: 0.2645,                 loss: nan
agent1:                 episode reward: -0.2645,                 loss: 0.1456
Episode: 2101/30000 (7.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.5840s / 23295.4169 s
agent0:                 episode reward: -0.1777,                 loss: nan
agent1:                 episode reward: 0.1777,                 loss: 0.1470
Episode: 2121/30000 (7.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.3811s / 23539.7980 s
agent0:                 episode reward: 0.1265,                 loss: nan
agent1:                 episode reward: -0.1265,                 loss: 0.1467
Episode: 2141/30000 (7.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.8428s / 23790.6408 s
agent0:                 episode reward: -0.3283,                 loss: nan
agent1:                 episode reward: 0.3283,                 loss: 0.1462
Episode: 2161/30000 (7.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.1826s / 24040.8233 s
agent0:                 episode reward: -0.1899,                 loss: nan
agent1:                 episode reward: 0.1899,                 loss: 0.1469
Episode: 2181/30000 (7.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.8720s / 24282.6953 s
agent0:                 episode reward: 0.2462,                 loss: nan
agent1:                 episode reward: -0.2462,                 loss: 0.1455
Episode: 2201/30000 (7.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.6272s / 24526.3226 s
agent0:                 episode reward: 0.0294,                 loss: nan
agent1:                 episode reward: -0.0294,                 loss: 0.1460
Episode: 2221/30000 (7.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.4003s / 24769.7229 s
agent0:                 episode reward: -0.1179,                 loss: nan
agent1:                 episode reward: 0.1179,                 loss: 0.1462
Episode: 2241/30000 (7.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.4321s / 25019.1550 s
agent0:                 episode reward: -0.1311,                 loss: nan
agent1:                 episode reward: 0.1311,                 loss: 0.1493
Episode: 2261/30000 (7.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 236.7043s / 25255.8593 s
agent0:                 episode reward: -0.1805,                 loss: nan
agent1:                 episode reward: 0.1805,                 loss: 0.1485
Episode: 2281/30000 (7.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.0433s / 25507.9026 s
agent0:                 episode reward: 0.1209,                 loss: nan
agent1:                 episode reward: -0.1209,                 loss: 0.1473
Episode: 2301/30000 (7.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 240.9719s / 25748.8744 s
agent0:                 episode reward: 0.1568,                 loss: nan
agent1:                 episode reward: -0.1568,                 loss: 0.1477
Episode: 2321/30000 (7.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 236.8845s / 25985.7589 s
agent0:                 episode reward: -0.0630,                 loss: nan
agent1:                 episode reward: 0.0630,                 loss: 0.1471
Episode: 2341/30000 (7.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.1779s / 26231.9368 s
agent0:                 episode reward: 0.1918,                 loss: nan
agent1:                 episode reward: -0.1918,                 loss: 0.1478
Episode: 2361/30000 (7.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.6849s / 26481.6217 s
agent0:                 episode reward: -0.0421,                 loss: nan
agent1:                 episode reward: 0.0421,                 loss: 0.1483
Episode: 2381/30000 (7.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 240.9769s / 26722.5986 s
agent0:                 episode reward: 0.0138,                 loss: nan
agent1:                 episode reward: -0.0138,                 loss: 0.1477
Episode: 2401/30000 (8.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.4039s / 26970.0025 s
agent0:                 episode reward: -0.1690,                 loss: nan
agent1:                 episode reward: 0.1690,                 loss: 0.1461
Episode: 2421/30000 (8.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.0282s / 27219.0307 s
agent0:                 episode reward: -0.2327,                 loss: nan
agent1:                 episode reward: 0.2327,                 loss: 0.1466
Episode: 2441/30000 (8.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 238.4163s / 27457.4470 s
agent0:                 episode reward: -0.1702,                 loss: nan
agent1:                 episode reward: 0.1702,                 loss: 0.1466
Episode: 2461/30000 (8.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.9357s / 27702.3827 s
agent0:                 episode reward: -0.0577,                 loss: nan
agent1:                 episode reward: 0.0577,                 loss: 0.1458
Episode: 2481/30000 (8.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.8809s / 27954.2636 s
agent0:                 episode reward: -0.1931,                 loss: nan
agent1:                 episode reward: 0.1931,                 loss: 0.1487
Episode: 2501/30000 (8.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.0091s / 28198.2727 s
agent0:                 episode reward: -0.2615,                 loss: nan
agent1:                 episode reward: 0.2615,                 loss: 0.1456
Episode: 2521/30000 (8.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.9957s / 28440.2684 s
agent0:                 episode reward: -0.1261,                 loss: nan
agent1:                 episode reward: 0.1261,                 loss: 0.1458
Episode: 2541/30000 (8.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.3716s / 28681.6400 s
agent0:                 episode reward: -0.0063,                 loss: nan
agent1:                 episode reward: 0.0063,                 loss: 0.1472
Episode: 2561/30000 (8.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.9244s / 28928.5644 s
agent0:                 episode reward: -0.0772,                 loss: nan
agent1:                 episode reward: 0.0772,                 loss: 0.1464
Episode: 2581/30000 (8.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.0845s / 29173.6489 s
agent0:                 episode reward: 0.1096,                 loss: nan
agent1:                 episode reward: -0.1096,                 loss: 0.1471
Episode: 2601/30000 (8.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.6185s / 29423.2674 s
agent0:                 episode reward: 0.0306,                 loss: nan
agent1:                 episode reward: -0.0306,                 loss: 0.1458
Episode: 2621/30000 (8.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.0667s / 29669.3342 s
agent0:                 episode reward: -0.2444,                 loss: nan
agent1:                 episode reward: 0.2444,                 loss: 0.1469
Episode: 2641/30000 (8.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.5106s / 29914.8447 s
agent0:                 episode reward: -0.3307,                 loss: nan
agent1:                 episode reward: 0.3307,                 loss: 0.1453
Episode: 2661/30000 (8.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.1543s / 30165.9990 s
agent0:                 episode reward: -0.3287,                 loss: nan
agent1:                 episode reward: 0.3287,                 loss: 0.1455
Episode: 2681/30000 (8.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.8488s / 30409.8478 s
agent0:                 episode reward: 0.0635,                 loss: nan
agent1:                 episode reward: -0.0635,                 loss: 0.1448
Episode: 2701/30000 (9.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.8244s / 30658.6723 s
agent0:                 episode reward: -0.1660,                 loss: nan
agent1:                 episode reward: 0.1660,                 loss: 0.1460
Episode: 2721/30000 (9.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.0292s / 30905.7015 s
agent0:                 episode reward: -0.5515,                 loss: nan
agent1:                 episode reward: 0.5515,                 loss: 0.1460
Episode: 2741/30000 (9.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.1362s / 31154.8377 s
agent0:                 episode reward: 0.1528,                 loss: nan
agent1:                 episode reward: -0.1528,                 loss: 0.1461
Episode: 2761/30000 (9.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.3016s / 31401.1394 s
agent0:                 episode reward: -0.0131,                 loss: nan
agent1:                 episode reward: 0.0131,                 loss: 0.1463
Episode: 2781/30000 (9.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.0023s / 31645.1417 s
agent0:                 episode reward: -0.2322,                 loss: nan
agent1:                 episode reward: 0.2322,                 loss: 0.1463
Episode: 2801/30000 (9.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.8461s / 31890.9877 s
agent0:                 episode reward: -0.0452,                 loss: nan
agent1:                 episode reward: 0.0452,                 loss: 0.1466
Episode: 2821/30000 (9.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.6259s / 32140.6136 s
agent0:                 episode reward: 0.0476,                 loss: nan
agent1:                 episode reward: -0.0476,                 loss: 0.1471
Episode: 2841/30000 (9.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.0886s / 32382.7022 s
agent0:                 episode reward: -0.4823,                 loss: nan
agent1:                 episode reward: 0.4823,                 loss: 0.1457
Episode: 2861/30000 (9.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 241.3604s / 32624.0626 s
agent0:                 episode reward: -0.2901,                 loss: nan
agent1:                 episode reward: 0.2901,                 loss: 0.1455
Episode: 2881/30000 (9.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.4095s / 32871.4722 s
agent0:                 episode reward: -0.1648,                 loss: nan
agent1:                 episode reward: 0.1648,                 loss: 0.1470
Episode: 2901/30000 (9.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.7931s / 33117.2653 s
agent0:                 episode reward: 0.1359,                 loss: nan
agent1:                 episode reward: -0.1359,                 loss: 0.1495
Episode: 2921/30000 (9.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.7225s / 33366.9878 s
agent0:                 episode reward: -0.1876,                 loss: nan
agent1:                 episode reward: 0.1876,                 loss: 0.1491
Episode: 2941/30000 (9.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.0338s / 33618.0216 s
agent0:                 episode reward: -0.0403,                 loss: nan
agent1:                 episode reward: 0.0403,                 loss: 0.1500
Episode: 2961/30000 (9.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 234.6755s / 33852.6971 s
agent0:                 episode reward: -0.3051,                 loss: nan
agent1:                 episode reward: 0.3051,                 loss: 0.1507
Episode: 2981/30000 (9.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.2266s / 34100.9237 s
agent0:                 episode reward: -0.3487,                 loss: nan
agent1:                 episode reward: 0.3487,                 loss: 0.1517
Episode: 3001/30000 (10.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.6271s / 34346.5508 s
agent0:                 episode reward: -0.0580,                 loss: nan
agent1:                 episode reward: 0.0580,                 loss: 0.1488
Episode: 3021/30000 (10.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.2118s / 34595.7626 s
agent0:                 episode reward: -0.0824,                 loss: nan
agent1:                 episode reward: 0.0824,                 loss: 0.1507
Episode: 3041/30000 (10.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 238.3344s / 34834.0970 s
agent0:                 episode reward: 0.0508,                 loss: nan
agent1:                 episode reward: -0.0508,                 loss: 0.1485
Episode: 3061/30000 (10.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.7373s / 35081.8343 s
agent0:                 episode reward: -0.1666,                 loss: nan
agent1:                 episode reward: 0.1666,                 loss: 0.1487
Episode: 3081/30000 (10.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.7634s / 35329.5977 s
agent0:                 episode reward: -0.0211,                 loss: nan
agent1:                 episode reward: 0.0211,                 loss: 0.1491
Episode: 3101/30000 (10.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.4253s / 35572.0230 s
agent0:                 episode reward: -0.2287,                 loss: nan
agent1:                 episode reward: 0.2287,                 loss: 0.1490
Episode: 3121/30000 (10.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 234.1440s / 35806.1670 s
agent0:                 episode reward: -0.0418,                 loss: nan
agent1:                 episode reward: 0.0418,                 loss: 0.1496
Episode: 3141/30000 (10.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 239.2442s / 36045.4112 s
agent0:                 episode reward: -0.6395,                 loss: nan
agent1:                 episode reward: 0.6395,                 loss: 0.1495
Episode: 3161/30000 (10.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.9390s / 36291.3502 s
agent0:                 episode reward: -0.3511,                 loss: nan
agent1:                 episode reward: 0.3511,                 loss: 0.1474
Episode: 3181/30000 (10.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.8878s / 36540.2380 s
agent0:                 episode reward: -0.4395,                 loss: nan
agent1:                 episode reward: 0.4395,                 loss: 0.1489
Episode: 3201/30000 (10.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.6413s / 36783.8793 s
agent0:                 episode reward: -0.1965,                 loss: nan
agent1:                 episode reward: 0.1965,                 loss: 0.1495
Episode: 3221/30000 (10.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.7541s / 37026.6334 s
agent0:                 episode reward: -0.4632,                 loss: nan
agent1:                 episode reward: 0.4632,                 loss: 0.1502
Episode: 3241/30000 (10.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.2675s / 37272.9009 s
agent0:                 episode reward: -0.4177,                 loss: nan
agent1:                 episode reward: 0.4177,                 loss: 0.1514
Episode: 3261/30000 (10.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.7339s / 37520.6348 s
agent0:                 episode reward: 0.4025,                 loss: nan
agent1:                 episode reward: -0.4025,                 loss: 0.1520
Episode: 3281/30000 (10.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 255.4329s / 37776.0677 s
agent0:                 episode reward: -0.1712,                 loss: nan
agent1:                 episode reward: 0.1712,                 loss: 0.1515
Episode: 3301/30000 (11.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 229.8179s / 38005.8857 s
agent0:                 episode reward: -0.5051,                 loss: nan
agent1:                 episode reward: 0.5051,                 loss: 0.1525
Episode: 3321/30000 (11.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.9195s / 38254.8051 s
agent0:                 episode reward: -0.3574,                 loss: nan
agent1:                 episode reward: 0.3574,                 loss: 0.1501
Episode: 3341/30000 (11.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.0931s / 38500.8982 s
agent0:                 episode reward: -0.2983,                 loss: nan
agent1:                 episode reward: 0.2983,                 loss: 0.1523
Episode: 3361/30000 (11.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 240.5072s / 38741.4055 s
agent0:                 episode reward: -0.1839,                 loss: nan
agent1:                 episode reward: 0.1839,                 loss: 0.1515
Episode: 3381/30000 (11.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.5819s / 38983.9873 s
agent0:                 episode reward: -0.2600,                 loss: nan
agent1:                 episode reward: 0.2600,                 loss: 0.1489
Episode: 3401/30000 (11.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.5946s / 39234.5819 s
agent0:                 episode reward: -0.2961,                 loss: nan
agent1:                 episode reward: 0.2961,                 loss: 0.1522
Episode: 3421/30000 (11.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.2308s / 39475.8127 s
agent0:                 episode reward: -0.3357,                 loss: nan
agent1:                 episode reward: 0.3357,                 loss: 0.1502
Episode: 3441/30000 (11.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 240.3646s / 39716.1773 s
agent0:                 episode reward: -0.1372,                 loss: nan
agent1:                 episode reward: 0.1372,                 loss: 0.1523
Episode: 3461/30000 (11.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.0625s / 39958.2397 s
agent0:                 episode reward: -0.3889,                 loss: nan
agent1:                 episode reward: 0.3889,                 loss: 0.1510
Episode: 3481/30000 (11.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.2626s / 40203.5023 s
agent0:                 episode reward: -0.2007,                 loss: nan
agent1:                 episode reward: 0.2007,                 loss: 0.1510
Episode: 3501/30000 (11.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.8828s / 40447.3851 s
agent0:                 episode reward: -0.2626,                 loss: nan
agent1:                 episode reward: 0.2626,                 loss: 0.1505
Episode: 3521/30000 (11.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 236.5452s / 40683.9303 s
agent0:                 episode reward: -0.4616,                 loss: nan
agent1:                 episode reward: 0.4616,                 loss: 0.1492
Episode: 3541/30000 (11.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.3531s / 40926.2834 s
agent0:                 episode reward: -0.2259,                 loss: nan
agent1:                 episode reward: 0.2259,                 loss: 0.1517
Episode: 3561/30000 (11.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 239.6885s / 41165.9719 s
agent0:                 episode reward: -0.1518,                 loss: nan
agent1:                 episode reward: 0.1518,                 loss: 0.1497
Episode: 3581/30000 (11.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.7991s / 41413.7709 s
agent0:                 episode reward: -0.4786,                 loss: nan
agent1:                 episode reward: 0.4786,                 loss: 0.1483
Episode: 3601/30000 (12.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.5012s / 41662.2721 s
agent0:                 episode reward: -0.0493,                 loss: nan
agent1:                 episode reward: 0.0493,                 loss: 0.1472
Episode: 3621/30000 (12.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.9411s / 41910.2132 s
agent0:                 episode reward: 0.0051,                 loss: nan
agent1:                 episode reward: -0.0051,                 loss: 0.1491
Episode: 3641/30000 (12.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.2275s / 42157.4407 s
agent0:                 episode reward: -0.2006,                 loss: nan
agent1:                 episode reward: 0.2006,                 loss: 0.1465
Episode: 3661/30000 (12.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.6990s / 42402.1397 s
agent0:                 episode reward: -0.2348,                 loss: nan
agent1:                 episode reward: 0.2348,                 loss: 0.1481
Episode: 3681/30000 (12.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.5492s / 42650.6889 s
agent0:                 episode reward: -0.1380,                 loss: nan
agent1:                 episode reward: 0.1380,                 loss: 0.1478
Episode: 3701/30000 (12.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.1933s / 42895.8822 s
agent0:                 episode reward: -0.1447,                 loss: nan
agent1:                 episode reward: 0.1447,                 loss: 0.1483
Episode: 3721/30000 (12.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.1352s / 43147.0173 s
agent0:                 episode reward: -0.0665,                 loss: nan
agent1:                 episode reward: 0.0665,                 loss: 0.1486
Episode: 3741/30000 (12.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.2995s / 43395.3168 s
agent0:                 episode reward: -0.4438,                 loss: nan
agent1:                 episode reward: 0.4438,                 loss: 0.1476
Episode: 3761/30000 (12.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 255.6707s / 43650.9875 s
agent0:                 episode reward: -0.3713,                 loss: nan
agent1:                 episode reward: 0.3713,                 loss: 0.1477
Episode: 3781/30000 (12.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.7090s / 43895.6966 s
agent0:                 episode reward: -0.4635,                 loss: nan
agent1:                 episode reward: 0.4635,                 loss: 0.1476
Episode: 3801/30000 (12.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.3951s / 44137.0917 s
agent0:                 episode reward: -0.2633,                 loss: nan
agent1:                 episode reward: 0.2633,                 loss: 0.1477
Episode: 3821/30000 (12.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.5202s / 44388.6119 s
agent0:                 episode reward: -0.3250,                 loss: nan
agent1:                 episode reward: 0.3250,                 loss: 0.1492
Episode: 3841/30000 (12.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 239.6111s / 44628.2230 s
agent0:                 episode reward: -0.2054,                 loss: nan
agent1:                 episode reward: 0.2054,                 loss: 0.1463
Episode: 3861/30000 (12.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.9362s / 44875.1592 s
agent0:                 episode reward: -0.3307,                 loss: nan
agent1:                 episode reward: 0.3307,                 loss: 0.1490
Episode: 3881/30000 (12.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.0924s / 45120.2516 s
agent0:                 episode reward: 0.0580,                 loss: nan
agent1:                 episode reward: -0.0580,                 loss: 0.1474
Episode: 3901/30000 (13.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.8475s / 45373.0991 s
agent0:                 episode reward: -0.0204,                 loss: nan
agent1:                 episode reward: 0.0204,                 loss: 0.1450
Episode: 3921/30000 (13.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 237.6796s / 45610.7786 s
agent0:                 episode reward: -0.4188,                 loss: nan
agent1:                 episode reward: 0.4188,                 loss: 0.1455
Episode: 3941/30000 (13.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.9763s / 45863.7549 s
agent0:                 episode reward: -0.4467,                 loss: nan
agent1:                 episode reward: 0.4467,                 loss: 0.1437
Episode: 3961/30000 (13.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.1303s / 46109.8852 s
agent0:                 episode reward: 0.1069,                 loss: nan
agent1:                 episode reward: -0.1069,                 loss: 0.1429
Episode: 3981/30000 (13.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.0410s / 46354.9262 s
agent0:                 episode reward: -0.2405,                 loss: nan
agent1:                 episode reward: 0.2405,                 loss: 0.1430
Episode: 4001/30000 (13.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 255.2235s / 46610.1497 s
agent0:                 episode reward: -0.3119,                 loss: nan
agent1:                 episode reward: 0.3119,                 loss: 0.1453
Episode: 4021/30000 (13.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.4249s / 46860.5746 s
agent0:                 episode reward: -0.2077,                 loss: nan
agent1:                 episode reward: 0.2077,                 loss: 0.1445
Episode: 4041/30000 (13.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.7660s / 47113.3406 s
agent0:                 episode reward: -0.9029,                 loss: nan
agent1:                 episode reward: 0.9029,                 loss: 0.1442
Episode: 4061/30000 (13.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 256.9752s / 47370.3158 s
agent0:                 episode reward: -0.2974,                 loss: nan
agent1:                 episode reward: 0.2974,                 loss: 0.1427
Episode: 4081/30000 (13.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.7023s / 47620.0181 s
agent0:                 episode reward: -0.3303,                 loss: nan
agent1:                 episode reward: 0.3303,                 loss: 0.1448
Episode: 4101/30000 (13.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 240.6045s / 47860.6225 s
agent0:                 episode reward: -0.1108,                 loss: nan
agent1:                 episode reward: 0.1108,                 loss: 0.1431
Episode: 4121/30000 (13.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 240.9934s / 48101.6160 s
agent0:                 episode reward: 0.0018,                 loss: nan
agent1:                 episode reward: -0.0018,                 loss: 0.1445
Episode: 4141/30000 (13.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.6347s / 48353.2506 s
agent0:                 episode reward: -0.6308,                 loss: nan
agent1:                 episode reward: 0.6308,                 loss: 0.1441
Episode: 4161/30000 (13.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.2532s / 48596.5038 s
agent0:                 episode reward: -0.1821,                 loss: nan
agent1:                 episode reward: 0.1821,                 loss: 0.1442
Episode: 4181/30000 (13.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.5635s / 48844.0673 s
agent0:                 episode reward: -0.3779,                 loss: nan
agent1:                 episode reward: 0.3779,                 loss: 0.1435
Episode: 4201/30000 (14.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.3906s / 49089.4579 s
agent0:                 episode reward: -0.0499,                 loss: nan
agent1:                 episode reward: 0.0499,                 loss: 0.1441
Episode: 4221/30000 (14.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.5506s / 49333.0085 s
agent0:                 episode reward: -0.4740,                 loss: nan
agent1:                 episode reward: 0.4740,                 loss: 0.1432
Episode: 4241/30000 (14.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.6423s / 49579.6508 s
agent0:                 episode reward: -0.3618,                 loss: nan
agent1:                 episode reward: 0.3618,                 loss: 0.1408
Episode: 4261/30000 (14.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 258.6449s / 49838.2957 s
agent0:                 episode reward: -0.2624,                 loss: nan
agent1:                 episode reward: 0.2624,                 loss: 0.1439
Episode: 4281/30000 (14.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.4651s / 50089.7609 s
agent0:                 episode reward: -0.6592,                 loss: nan
agent1:                 episode reward: 0.6592,                 loss: 0.1425
Episode: 4301/30000 (14.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.0729s / 50333.8338 s
agent0:                 episode reward: -0.6520,                 loss: nan
agent1:                 episode reward: 0.6520,                 loss: 0.1434
Episode: 4321/30000 (14.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.1868s / 50577.0206 s
agent0:                 episode reward: -0.6169,                 loss: nan
agent1:                 episode reward: 0.6169,                 loss: 0.1432
Episode: 4341/30000 (14.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.1416s / 50824.1622 s
agent0:                 episode reward: 0.4870,                 loss: nan
agent1:                 episode reward: -0.4870,                 loss: 0.1429
Episode: 4361/30000 (14.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 241.7321s / 51065.8943 s
agent0:                 episode reward: 0.1847,                 loss: nan
agent1:                 episode reward: -0.1847,                 loss: 0.1438
Episode: 4381/30000 (14.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.7209s / 51310.6152 s
agent0:                 episode reward: -0.3970,                 loss: nan
agent1:                 episode reward: 0.3970,                 loss: 0.1439
Episode: 4401/30000 (14.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 237.9501s / 51548.5652 s
agent0:                 episode reward: -0.2390,                 loss: nan
agent1:                 episode reward: 0.2390,                 loss: 0.1438
Episode: 4421/30000 (14.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 255.4404s / 51804.0056 s
agent0:                 episode reward: -0.3909,                 loss: nan
agent1:                 episode reward: 0.3909,                 loss: 0.1455
Episode: 4441/30000 (14.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.4129s / 52047.4185 s
agent0:                 episode reward: -0.2723,                 loss: nan
agent1:                 episode reward: 0.2723,                 loss: 0.1444
Episode: 4461/30000 (14.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.9258s / 52299.3443 s
agent0:                 episode reward: -0.9780,                 loss: nan
agent1:                 episode reward: 0.9780,                 loss: 0.1440
Episode: 4481/30000 (14.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.2159s / 52551.5602 s
agent0:                 episode reward: -0.2494,                 loss: nan
agent1:                 episode reward: 0.2494,                 loss: 0.1431
Episode: 4501/30000 (15.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.4150s / 52803.9752 s
agent0:                 episode reward: -0.3552,                 loss: nan
agent1:                 episode reward: 0.3552,                 loss: 0.1438
Episode: 4521/30000 (15.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.5480s / 53050.5232 s
agent0:                 episode reward: -0.3307,                 loss: nan
agent1:                 episode reward: 0.3307,                 loss: 0.1431
Episode: 4541/30000 (15.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.5361s / 53295.0592 s
agent0:                 episode reward: -0.0102,                 loss: nan
agent1:                 episode reward: 0.0102,                 loss: 0.1430
Episode: 4561/30000 (15.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 240.2604s / 53535.3196 s
agent0:                 episode reward: 0.1367,                 loss: nan
agent1:                 episode reward: -0.1367,                 loss: 0.1435
Episode: 4581/30000 (15.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.2515s / 53783.5711 s
agent0:                 episode reward: -0.3943,                 loss: nan
agent1:                 episode reward: 0.3943,                 loss: 0.1448
Episode: 4601/30000 (15.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.9779s / 54028.5490 s
agent0:                 episode reward: -0.7987,                 loss: nan
agent1:                 episode reward: 0.7987,                 loss: 0.1436
Episode: 4621/30000 (15.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.2489s / 54272.7979 s
agent0:                 episode reward: 0.2852,                 loss: nan
agent1:                 episode reward: -0.2852,                 loss: 0.1412
Episode: 4641/30000 (15.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.8266s / 54524.6245 s
agent0:                 episode reward: -0.3594,                 loss: nan
agent1:                 episode reward: 0.3594,                 loss: 0.1424
Episode: 4661/30000 (15.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.0998s / 54770.7243 s
agent0:                 episode reward: -0.9132,                 loss: nan
agent1:                 episode reward: 0.9132,                 loss: 0.1439
Episode: 4681/30000 (15.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.2903s / 55020.0145 s
agent0:                 episode reward: -0.5548,                 loss: nan
agent1:                 episode reward: 0.5548,                 loss: 0.1434
Episode: 4701/30000 (15.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 240.4677s / 55260.4822 s
agent0:                 episode reward: -0.0453,                 loss: nan
agent1:                 episode reward: 0.0453,                 loss: 0.1417
Episode: 4721/30000 (15.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 241.9296s / 55502.4119 s
agent0:                 episode reward: -0.2660,                 loss: nan
agent1:                 episode reward: 0.2660,                 loss: 0.1426
Episode: 4741/30000 (15.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.8560s / 55747.2678 s
agent0:                 episode reward: -0.5297,                 loss: nan
agent1:                 episode reward: 0.5297,                 loss: 0.1434
Episode: 4761/30000 (15.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.5297s / 55997.7975 s
agent0:                 episode reward: -0.3745,                 loss: nan
agent1:                 episode reward: 0.3745,                 loss: 0.1441
Episode: 4781/30000 (15.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.8428s / 56245.6404 s
agent0:                 episode reward: -0.1172,                 loss: nan
agent1:                 episode reward: 0.1172,                 loss: 0.1434
Episode: 4801/30000 (16.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.4224s / 56490.0627 s
agent0:                 episode reward: -0.3907,                 loss: nan
agent1:                 episode reward: 0.3907,                 loss: 0.1435
Episode: 4821/30000 (16.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 240.2807s / 56730.3434 s
agent0:                 episode reward: -0.4148,                 loss: nan
agent1:                 episode reward: 0.4148,                 loss: 0.1408
Episode: 4841/30000 (16.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.9097s / 56976.2531 s
agent0:                 episode reward: -0.4696,                 loss: nan
agent1:                 episode reward: 0.4696,                 loss: 0.1416
Episode: 4861/30000 (16.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.7158s / 57225.9689 s
agent0:                 episode reward: -0.3855,                 loss: nan
agent1:                 episode reward: 0.3855,                 loss: 0.1428
Episode: 4881/30000 (16.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.2240s / 57476.1929 s
agent0:                 episode reward: 0.0095,                 loss: nan
agent1:                 episode reward: -0.0095,                 loss: 0.1440
Episode: 4901/30000 (16.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.6825s / 57725.8754 s
agent0:                 episode reward: -0.7254,                 loss: nan
agent1:                 episode reward: 0.7254,                 loss: 0.1409
Episode: 4921/30000 (16.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.0971s / 57966.9725 s
agent0:                 episode reward: -0.4435,                 loss: nan
agent1:                 episode reward: 0.4435,                 loss: 0.1417
Episode: 4941/30000 (16.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 239.9627s / 58206.9352 s
agent0:                 episode reward: -0.1971,                 loss: nan
agent1:                 episode reward: 0.1971,                 loss: 0.1416
Episode: 4961/30000 (16.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.4696s / 58457.4048 s
agent0:                 episode reward: -0.1669,                 loss: nan
agent1:                 episode reward: 0.1669,                 loss: 0.1438
Episode: 4981/30000 (16.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.7680s / 58710.1727 s
agent0:                 episode reward: -0.3574,                 loss: nan
agent1:                 episode reward: 0.3574,                 loss: 0.1411
Episode: 5001/30000 (16.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.1123s / 58956.2850 s
agent0:                 episode reward: -0.4838,                 loss: nan
agent1:                 episode reward: 0.4838,                 loss: 0.1419
Episode: 5021/30000 (16.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.1694s / 59201.4544 s
agent0:                 episode reward: -0.3773,                 loss: nan
agent1:                 episode reward: 0.3773,                 loss: 0.1450
Episode: 5041/30000 (16.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 239.8444s / 59441.2988 s
agent0:                 episode reward: -0.4093,                 loss: nan
agent1:                 episode reward: 0.4093,                 loss: 0.1428
Episode: 5061/30000 (16.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.6741s / 59684.9729 s
agent0:                 episode reward: -0.3814,                 loss: nan
agent1:                 episode reward: 0.3814,                 loss: 0.1428
Episode: 5081/30000 (16.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.2231s / 59934.1960 s
agent0:                 episode reward: -0.1112,                 loss: nan
agent1:                 episode reward: 0.1112,                 loss: 0.1418
Episode: 5101/30000 (17.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.1007s / 60181.2967 s
agent0:                 episode reward: -0.7927,                 loss: nan
agent1:                 episode reward: 0.7927,                 loss: 0.1416
Episode: 5121/30000 (17.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 238.5750s / 60419.8717 s
agent0:                 episode reward: -0.5989,                 loss: nan
agent1:                 episode reward: 0.5989,                 loss: 0.1426
Episode: 5141/30000 (17.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.9929s / 60666.8646 s
agent0:                 episode reward: 0.0799,                 loss: nan
agent1:                 episode reward: -0.0799,                 loss: 0.1441
Episode: 5161/30000 (17.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.6741s / 60910.5388 s
agent0:                 episode reward: -0.0427,                 loss: nan
agent1:                 episode reward: 0.0427,                 loss: 0.1434
Episode: 5181/30000 (17.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.3186s / 61154.8573 s
agent0:                 episode reward: -0.2279,                 loss: nan
agent1:                 episode reward: 0.2279,                 loss: 0.1432
Episode: 5201/30000 (17.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 241.4271s / 61396.2844 s
agent0:                 episode reward: -0.3343,                 loss: nan
agent1:                 episode reward: 0.3343,                 loss: 0.1419
Episode: 5221/30000 (17.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.9602s / 61638.2446 s
agent0:                 episode reward: -0.6947,                 loss: nan
agent1:                 episode reward: 0.6947,                 loss: 0.1426
Episode: 5241/30000 (17.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.9781s / 61880.2227 s
agent0:                 episode reward: -0.1295,                 loss: nan
agent1:                 episode reward: 0.1295,                 loss: 0.1416
Episode: 5261/30000 (17.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.4368s / 62125.6595 s
agent0:                 episode reward: 0.1000,                 loss: nan
agent1:                 episode reward: -0.1000,                 loss: 0.1417
Episode: 5281/30000 (17.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.9508s / 62376.6103 s
agent0:                 episode reward: -0.2956,                 loss: nan
agent1:                 episode reward: 0.2956,                 loss: 0.1408
Episode: 5301/30000 (17.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 257.2944s / 62633.9047 s
agent0:                 episode reward: -0.3958,                 loss: nan
agent1:                 episode reward: 0.3958,                 loss: 0.1435
Episode: 5321/30000 (17.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.6807s / 62880.5854 s
agent0:                 episode reward: -0.2422,                 loss: nan
agent1:                 episode reward: 0.2422,                 loss: 0.1411
Episode: 5341/30000 (17.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.4485s / 63133.0339 s
agent0:                 episode reward: -0.0849,                 loss: nan
agent1:                 episode reward: 0.0849,                 loss: 0.1422
Episode: 5361/30000 (17.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.2011s / 63385.2350 s
agent0:                 episode reward: -0.0916,                 loss: nan
agent1:                 episode reward: 0.0916,                 loss: 0.1418
Episode: 5381/30000 (17.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.0367s / 63637.2717 s
agent0:                 episode reward: -0.1235,                 loss: nan
agent1:                 episode reward: 0.1235,                 loss: 0.1407
Episode: 5401/30000 (18.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.4058s / 63886.6775 s
agent0:                 episode reward: -0.0948,                 loss: nan
agent1:                 episode reward: 0.0948,                 loss: 0.1421
Episode: 5421/30000 (18.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.5107s / 64135.1882 s
agent0:                 episode reward: -0.3214,                 loss: nan
agent1:                 episode reward: 0.3214,                 loss: 0.1430
Episode: 5441/30000 (18.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 238.5414s / 64373.7295 s
agent0:                 episode reward: -0.0149,                 loss: nan
agent1:                 episode reward: 0.0149,                 loss: 0.1425
Episode: 5461/30000 (18.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.9061s / 64626.6356 s
agent0:                 episode reward: -0.0080,                 loss: nan
agent1:                 episode reward: 0.0080,                 loss: 0.1409
Episode: 5481/30000 (18.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.2877s / 64871.9233 s
agent0:                 episode reward: -0.3531,                 loss: nan
agent1:                 episode reward: 0.3531,                 loss: 0.1404
Episode: 5501/30000 (18.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.8395s / 65115.7629 s
agent0:                 episode reward: -0.3585,                 loss: nan
agent1:                 episode reward: 0.3585,                 loss: 0.1411
Episode: 5521/30000 (18.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.6240s / 65364.3869 s
agent0:                 episode reward: -0.4555,                 loss: nan
agent1:                 episode reward: 0.4555,                 loss: 0.1423
Episode: 5541/30000 (18.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.5196s / 65616.9065 s
agent0:                 episode reward: -0.5104,                 loss: nan
agent1:                 episode reward: 0.5104,                 loss: 0.1407
Episode: 5561/30000 (18.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.4597s / 65861.3662 s
agent0:                 episode reward: -0.6008,                 loss: nan
agent1:                 episode reward: 0.6008,                 loss: 0.1417
Episode: 5581/30000 (18.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.1823s / 66105.5485 s
agent0:                 episode reward: -0.4870,                 loss: nan
agent1:                 episode reward: 0.4870,                 loss: 0.1429
Episode: 5601/30000 (18.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.6921s / 66354.2406 s
agent0:                 episode reward: -0.2997,                 loss: nan
agent1:                 episode reward: 0.2997,                 loss: 0.1420
Episode: 5621/30000 (18.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.9023s / 66602.1428 s
agent0:                 episode reward: -0.4067,                 loss: nan
agent1:                 episode reward: 0.4067,                 loss: 0.1440
Episode: 5641/30000 (18.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.0351s / 66847.1779 s
agent0:                 episode reward: -0.0541,                 loss: nan
agent1:                 episode reward: 0.0541,                 loss: 0.1420
Episode: 5661/30000 (18.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.7783s / 67095.9563 s
agent0:                 episode reward: -0.0963,                 loss: nan
agent1:                 episode reward: 0.0963,                 loss: 0.1443
Episode: 5681/30000 (18.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.0406s / 67341.9968 s
agent0:                 episode reward: 0.0320,                 loss: nan
agent1:                 episode reward: -0.0320,                 loss: 0.1421
Episode: 5701/30000 (19.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.6401s / 67587.6370 s
agent0:                 episode reward: -0.2020,                 loss: nan
agent1:                 episode reward: 0.2020,                 loss: 0.1418
Episode: 5721/30000 (19.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.1670s / 67833.8039 s
agent0:                 episode reward: -0.1450,                 loss: nan
agent1:                 episode reward: 0.1450,                 loss: 0.1406
Episode: 5741/30000 (19.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 239.5629s / 68073.3668 s
agent0:                 episode reward: -0.3880,                 loss: nan
agent1:                 episode reward: 0.3880,                 loss: 0.1423
Episode: 5761/30000 (19.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.9585s / 68317.3253 s
agent0:                 episode reward: 0.1013,                 loss: nan
agent1:                 episode reward: -0.1013,                 loss: 0.1433
Episode: 5781/30000 (19.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.7715s / 68564.0968 s
agent0:                 episode reward: 0.0383,                 loss: nan
agent1:                 episode reward: -0.0383,                 loss: 0.1414
Episode: 5801/30000 (19.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 255.6066s / 68819.7034 s
agent0:                 episode reward: -0.1271,                 loss: nan
agent1:                 episode reward: 0.1271,                 loss: 0.1420
Episode: 5821/30000 (19.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.8602s / 69065.5636 s
agent0:                 episode reward: -0.1919,                 loss: nan
agent1:                 episode reward: 0.1919,                 loss: 0.1419
Episode: 5841/30000 (19.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 253.7229s / 69319.2865 s
agent0:                 episode reward: -0.4093,                 loss: nan
agent1:                 episode reward: 0.4093,                 loss: 0.1414
Episode: 5861/30000 (19.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.9684s / 69570.2549 s
agent0:                 episode reward: -0.1017,                 loss: nan
agent1:                 episode reward: 0.1017,                 loss: 0.1415
Episode: 5881/30000 (19.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.6753s / 69819.9302 s
agent0:                 episode reward: -0.4690,                 loss: nan
agent1:                 episode reward: 0.4690,                 loss: 0.1431
Episode: 5901/30000 (19.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 240.5425s / 70060.4727 s
agent0:                 episode reward: 0.0430,                 loss: nan
agent1:                 episode reward: -0.0430,                 loss: 0.1425
Episode: 5921/30000 (19.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 262.1409s / 70322.6136 s
agent0:                 episode reward: -0.5140,                 loss: nan
agent1:                 episode reward: 0.5140,                 loss: 0.1409
Episode: 5941/30000 (19.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 239.7483s / 70562.3620 s
agent0:                 episode reward: -0.1870,                 loss: nan
agent1:                 episode reward: 0.1870,                 loss: 0.1389
Episode: 5961/30000 (19.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.8895s / 70806.2515 s
agent0:                 episode reward: -0.0425,                 loss: nan
agent1:                 episode reward: 0.0425,                 loss: 0.1426
Episode: 5981/30000 (19.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.5375s / 71049.7890 s
agent0:                 episode reward: -0.5187,                 loss: nan
agent1:                 episode reward: 0.5187,                 loss: 0.1421
Episode: 6001/30000 (20.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.5366s / 71298.3256 s
agent0:                 episode reward: -0.0977,                 loss: nan
agent1:                 episode reward: 0.0977,                 loss: 0.1420
Episode: 6021/30000 (20.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.2029s / 71540.5285 s
agent0:                 episode reward: -0.1369,                 loss: nan
agent1:                 episode reward: 0.1369,                 loss: 0.1416
Episode: 6041/30000 (20.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.9028s / 71783.4312 s
agent0:                 episode reward: -0.0579,                 loss: nan
agent1:                 episode reward: 0.0579,                 loss: 0.1402
Episode: 6061/30000 (20.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.3929s / 72029.8241 s
agent0:                 episode reward: -0.4056,                 loss: nan
agent1:                 episode reward: 0.4056,                 loss: 0.1424
Episode: 6081/30000 (20.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.5298s / 72281.3539 s
agent0:                 episode reward: -0.1952,                 loss: nan
agent1:                 episode reward: 0.1952,                 loss: 0.1409
Episode: 6101/30000 (20.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 253.2686s / 72534.6225 s
agent0:                 episode reward: -0.2557,                 loss: nan
agent1:                 episode reward: 0.2557,                 loss: 0.1419
Episode: 6121/30000 (20.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.3299s / 72784.9524 s
agent0:                 episode reward: -0.0475,                 loss: nan
agent1:                 episode reward: 0.0475,                 loss: 0.1413
Episode: 6141/30000 (20.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 256.2002s / 73041.1526 s
agent0:                 episode reward: -0.6390,                 loss: nan
agent1:                 episode reward: 0.6390,                 loss: 0.1430
Episode: 6161/30000 (20.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.4705s / 73289.6231 s
agent0:                 episode reward: -0.2680,                 loss: nan
agent1:                 episode reward: 0.2680,                 loss: 0.1401
Episode: 6181/30000 (20.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.0722s / 73531.6953 s
agent0:                 episode reward: -0.3165,                 loss: nan
agent1:                 episode reward: 0.3165,                 loss: 0.1416
Episode: 6201/30000 (20.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.7315s / 73780.4269 s
agent0:                 episode reward: -0.1969,                 loss: nan
agent1:                 episode reward: 0.1969,                 loss: 0.1410
Episode: 6221/30000 (20.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.0183s / 74027.4452 s
agent0:                 episode reward: -0.4342,                 loss: nan
agent1:                 episode reward: 0.4342,                 loss: 0.1422
Episode: 6241/30000 (20.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.5844s / 74272.0296 s
agent0:                 episode reward: -0.2076,                 loss: nan
agent1:                 episode reward: 0.2076,                 loss: 0.1433
Episode: 6261/30000 (20.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.6629s / 74521.6925 s
agent0:                 episode reward: -0.4324,                 loss: nan
agent1:                 episode reward: 0.4324,                 loss: 0.1421
Episode: 6281/30000 (20.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 256.3127s / 74778.0053 s
agent0:                 episode reward: -0.5081,                 loss: nan
agent1:                 episode reward: 0.5081,                 loss: 0.1409
Episode: 6301/30000 (21.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.2678s / 75025.2731 s
agent0:                 episode reward: -0.1305,                 loss: nan
agent1:                 episode reward: 0.1305,                 loss: 0.1427
Episode: 6321/30000 (21.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.4134s / 75276.6865 s
agent0:                 episode reward: -0.1463,                 loss: nan
agent1:                 episode reward: 0.1463,                 loss: 0.1405
Episode: 6341/30000 (21.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.4008s / 75522.0872 s
agent0:                 episode reward: 0.1047,                 loss: nan
agent1:                 episode reward: -0.1047,                 loss: 0.1419
Episode: 6361/30000 (21.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 254.0256s / 75776.1129 s
agent0:                 episode reward: -0.2747,                 loss: nan
agent1:                 episode reward: 0.2747,                 loss: 0.1397
Episode: 6381/30000 (21.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.1049s / 76019.2177 s
agent0:                 episode reward: -0.3115,                 loss: nan
agent1:                 episode reward: 0.3115,                 loss: 0.1416
Episode: 6401/30000 (21.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.0054s / 76267.2231 s
agent0:                 episode reward: -0.3127,                 loss: nan
agent1:                 episode reward: 0.3127,                 loss: 0.1399
Episode: 6421/30000 (21.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.2986s / 76515.5216 s
agent0:                 episode reward: -0.2980,                 loss: nan
agent1:                 episode reward: 0.2980,                 loss: 0.1418
Episode: 6441/30000 (21.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 253.5884s / 76769.1100 s
agent0:                 episode reward: -0.3325,                 loss: nan
agent1:                 episode reward: 0.3325,                 loss: 0.1409
Episode: 6461/30000 (21.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 257.1961s / 77026.3061 s
agent0:                 episode reward: -0.3486,                 loss: nan
agent1:                 episode reward: 0.3486,                 loss: 0.1412
Episode: 6481/30000 (21.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.0553s / 77270.3613 s
agent0:                 episode reward: -0.3706,                 loss: nan
agent1:                 episode reward: 0.3706,                 loss: 0.1419
Episode: 6501/30000 (21.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.1685s / 77512.5299 s
agent0:                 episode reward: -0.4666,                 loss: nan
agent1:                 episode reward: 0.4666,                 loss: 0.1411
Episode: 6521/30000 (21.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.4233s / 77764.9531 s
agent0:                 episode reward: -0.0843,                 loss: nan
agent1:                 episode reward: 0.0843,                 loss: 0.1396
Episode: 6541/30000 (21.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.4439s / 78010.3970 s
agent0:                 episode reward: -0.4990,                 loss: nan
agent1:                 episode reward: 0.4990,                 loss: 0.1434
Episode: 6561/30000 (21.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.4745s / 78261.8716 s
agent0:                 episode reward: -0.4308,                 loss: nan
agent1:                 episode reward: 0.4308,                 loss: 0.1404
Episode: 6581/30000 (21.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.9784s / 78512.8499 s
agent0:                 episode reward: -0.0959,                 loss: nan
agent1:                 episode reward: 0.0959,                 loss: 0.1386
Episode: 6601/30000 (22.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.5131s / 78755.3631 s
agent0:                 episode reward: -0.4200,                 loss: nan
agent1:                 episode reward: 0.4200,                 loss: 0.1397
Episode: 6621/30000 (22.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 240.7150s / 78996.0780 s
agent0:                 episode reward: -0.2659,                 loss: nan
agent1:                 episode reward: 0.2659,                 loss: 0.1380
Episode: 6641/30000 (22.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.0458s / 79248.1239 s
agent0:                 episode reward: -0.7649,                 loss: nan
agent1:                 episode reward: 0.7649,                 loss: 0.1407
Episode: 6661/30000 (22.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.6638s / 79497.7877 s
agent0:                 episode reward: -0.2523,                 loss: nan
agent1:                 episode reward: 0.2523,                 loss: 0.1404
Episode: 6681/30000 (22.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.4777s / 79746.2654 s
agent0:                 episode reward: -0.3698,                 loss: nan
agent1:                 episode reward: 0.3698,                 loss: 0.1394
Episode: 6701/30000 (22.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.8113s / 79993.0767 s
agent0:                 episode reward: -0.1773,                 loss: nan
agent1:                 episode reward: 0.1773,                 loss: 0.1408
Episode: 6721/30000 (22.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.0733s / 80240.1500 s
agent0:                 episode reward: -0.2449,                 loss: nan
agent1:                 episode reward: 0.2449,                 loss: 0.1406
Episode: 6741/30000 (22.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.2885s / 80487.4384 s
agent0:                 episode reward: -0.6706,                 loss: nan
agent1:                 episode reward: 0.6706,                 loss: 0.1398
Episode: 6761/30000 (22.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.5112s / 80730.9497 s
agent0:                 episode reward: -0.2341,                 loss: nan
agent1:                 episode reward: 0.2341,                 loss: 0.1411
Episode: 6781/30000 (22.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 254.2913s / 80985.2410 s
agent0:                 episode reward: -0.1336,                 loss: nan
agent1:                 episode reward: 0.1336,                 loss: 0.1395
Episode: 6801/30000 (22.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.4306s / 81237.6715 s
agent0:                 episode reward: -0.1758,                 loss: nan
agent1:                 episode reward: 0.1758,                 loss: 0.1414
Episode: 6821/30000 (22.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.0871s / 81479.7587 s
agent0:                 episode reward: -0.1369,                 loss: nan
agent1:                 episode reward: 0.1369,                 loss: 0.1407
Episode: 6841/30000 (22.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.3551s / 81730.1137 s
agent0:                 episode reward: -0.7145,                 loss: nan
agent1:                 episode reward: 0.7145,                 loss: 0.1400
Episode: 6861/30000 (22.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.7133s / 81980.8270 s
agent0:                 episode reward: -0.1952,                 loss: nan
agent1:                 episode reward: 0.1952,                 loss: 0.1403
Episode: 6881/30000 (22.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.9667s / 82228.7937 s
agent0:                 episode reward: -0.2041,                 loss: nan
agent1:                 episode reward: 0.2041,                 loss: 0.1421
Episode: 6901/30000 (23.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.9580s / 82472.7518 s
agent0:                 episode reward: -0.6289,                 loss: nan
agent1:                 episode reward: 0.6289,                 loss: 0.1397
Episode: 6921/30000 (23.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 238.0162s / 82710.7680 s
agent0:                 episode reward: -0.4625,                 loss: nan
agent1:                 episode reward: 0.4625,                 loss: 0.1415
Episode: 6941/30000 (23.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 254.9214s / 82965.6893 s
agent0:                 episode reward: -1.0012,                 loss: nan
agent1:                 episode reward: 1.0012,                 loss: 0.1391
Episode: 6961/30000 (23.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 239.0932s / 83204.7826 s
agent0:                 episode reward: 0.1024,                 loss: nan
agent1:                 episode reward: -0.1024,                 loss: 0.1400
Episode: 6981/30000 (23.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.8242s / 83456.6068 s
agent0:                 episode reward: -0.6543,                 loss: nan
agent1:                 episode reward: 0.6543,                 loss: 0.1399
Episode: 7001/30000 (23.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.3798s / 83701.9866 s
agent0:                 episode reward: -0.4287,                 loss: nan
agent1:                 episode reward: 0.4287,                 loss: 0.1393
Episode: 7021/30000 (23.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 257.3275s / 83959.3141 s
agent0:                 episode reward: -0.3311,                 loss: nan
agent1:                 episode reward: 0.3311,                 loss: 0.1399
Episode: 7041/30000 (23.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.9021s / 84208.2162 s
agent0:                 episode reward: -0.7662,                 loss: nan
agent1:                 episode reward: 0.7662,                 loss: 0.1393
Episode: 7061/30000 (23.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 238.7148s / 84446.9310 s
agent0:                 episode reward: -0.5469,                 loss: nan
agent1:                 episode reward: 0.5469,                 loss: 0.1400
Episode: 7081/30000 (23.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 233.7057s / 84680.6367 s
agent0:                 episode reward: -0.0519,                 loss: nan
agent1:                 episode reward: 0.0519,                 loss: 0.1405
Episode: 7101/30000 (23.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.3173s / 84921.9541 s
agent0:                 episode reward: -0.3430,                 loss: nan
agent1:                 episode reward: 0.3430,                 loss: 0.1413
Episode: 7121/30000 (23.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.6441s / 85170.5981 s
agent0:                 episode reward: -0.9151,                 loss: nan
agent1:                 episode reward: 0.9151,                 loss: 0.1407
Episode: 7141/30000 (23.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.3327s / 85416.9309 s
agent0:                 episode reward: -0.7184,                 loss: nan
agent1:                 episode reward: 0.7184,                 loss: 0.1405
Episode: 7161/30000 (23.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.3081s / 85660.2390 s
agent0:                 episode reward: -0.4959,                 loss: nan
agent1:                 episode reward: 0.4959,                 loss: 0.1411
Episode: 7181/30000 (23.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.9381s / 85908.1770 s
agent0:                 episode reward: -0.3151,                 loss: nan
agent1:                 episode reward: 0.3151,                 loss: 0.1392
Episode: 7201/30000 (24.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.2121s / 86155.3891 s
agent0:                 episode reward: -0.6448,                 loss: nan
agent1:                 episode reward: 0.6448,                 loss: 0.1401
Episode: 7221/30000 (24.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.0027s / 86405.3918 s
agent0:                 episode reward: -0.4517,                 loss: nan
agent1:                 episode reward: 0.4517,                 loss: 0.1388
Episode: 7241/30000 (24.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.4887s / 86648.8806 s
agent0:                 episode reward: -0.3975,                 loss: nan
agent1:                 episode reward: 0.3975,                 loss: 0.1378
Episode: 7261/30000 (24.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.1078s / 86890.9884 s
agent0:                 episode reward: -0.2826,                 loss: nan
agent1:                 episode reward: 0.2826,                 loss: 0.1393
Episode: 7281/30000 (24.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.7491s / 87135.7375 s
agent0:                 episode reward: -0.3678,                 loss: nan
agent1:                 episode reward: 0.3678,                 loss: 0.1395
Episode: 7301/30000 (24.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.3630s / 87386.1005 s
agent0:                 episode reward: -0.4781,                 loss: nan
agent1:                 episode reward: 0.4781,                 loss: 0.1397
Episode: 7321/30000 (24.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.0430s / 87634.1435 s
agent0:                 episode reward: -0.5937,                 loss: nan
agent1:                 episode reward: 0.5937,                 loss: 0.1403
Episode: 7341/30000 (24.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.1409s / 87877.2844 s
agent0:                 episode reward: -0.1718,                 loss: nan
agent1:                 episode reward: 0.1718,                 loss: 0.1390
Episode: 7361/30000 (24.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.2881s / 88121.5724 s
agent0:                 episode reward: -0.5318,                 loss: nan
agent1:                 episode reward: 0.5318,                 loss: 0.1378
Episode: 7381/30000 (24.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.1439s / 88366.7163 s
agent0:                 episode reward: -0.2758,                 loss: nan
agent1:                 episode reward: 0.2758,                 loss: 0.1388
Episode: 7401/30000 (24.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.4589s / 88615.1752 s
agent0:                 episode reward: -0.8380,                 loss: nan
agent1:                 episode reward: 0.8380,                 loss: 0.1384
Episode: 7421/30000 (24.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.2896s / 88867.4648 s
agent0:                 episode reward: -0.5453,                 loss: nan
agent1:                 episode reward: 0.5453,                 loss: 0.1377
Episode: 7441/30000 (24.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 257.7575s / 89125.2223 s
agent0:                 episode reward: -0.3136,                 loss: nan
agent1:                 episode reward: 0.3136,                 loss: 0.1381
Episode: 7461/30000 (24.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.5021s / 89373.7244 s
agent0:                 episode reward: -0.2001,                 loss: nan
agent1:                 episode reward: 0.2001,                 loss: 0.1381
Episode: 7481/30000 (24.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 236.8581s / 89610.5824 s