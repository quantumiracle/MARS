pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 12.0, (1,), float32) action space: Discrete(3)
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7f322cf454a8>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
Agents No. [0] (index starting from 0) are not learnable.
Load meta strategy:  [array([0.013, 0.013, 0.013, ..., 0.013, 0.013, 0.013]) array([0.013, 0.013, 0.013, ..., 0.013, 0.013, 0.013])]
Load checkpoints (policy family):  [list(['50', '5253', '7615', '8835', '9107', '9703', '11990', '12159', '12524', '13308', '13498', '13724', '14178', '14316', '14615', '15091', '15175', '15419', '15750', '16939', '17375', '17843', '17917', '18353', '18640', '19318', '19446', '19648', '20384', '20683', '20884', '21272', '21672', '22747', '23030', '23310', '24520', '24853', '26681', '26940', '28709', '29740', '29846', '30462', '30651', '30760', '31416', '31603', '32106', '32698', '33332', '33767', '33881', '36744', '37270', '38685', '39143', '41292', '42031', '42615', '42749', '43319', '44780', '45269', '45498', '45743', '45999', '46193', '46771', '46952', '47200', '48030', '48564', '48855', '49288', '49557'])
 list(['193', '5289', '7712', '9011', '9134', '9750', '12072', '12183', '12551', '13372', '13527', '13900', '14248', '14538', '14753', '15114', '15219', '15590', '15822', '16961', '17442', '17874', '17965', '18390', '18710', '19358', '19474', '19725', '20485', '20727', '20925', '21436', '21759', '22805', '23082', '23363', '24633', '24918', '26747', '26990', '28804', '29797', '29890', '30570', '30697', '30815', '31505', '31652', '32168', '32769', '33481', '33828', '33952', '36804', '37326', '38773', '39204', '41367', '42118', '42678', '42883', '43395', '44845', '45356', '45577', '45810', '46067', '46269', '46865', '47038', '47292', '48138', '48748', '49098', '49412'])]
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': 1, 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'batch_size': 640, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220117153310/epi_50000/', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'fictitious_selfplay2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'selfplay_score_delta': 1.5, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'against_baseline': False}
Save models to : /home/quantumiracle/research/MARS/data/model/20220117153310_exploit_50000/mdp_arbitrary_mdp_fictitious_selfplay2. 
 Save logs to: /home/quantumiracle/research/MARS/data/log/20220117153310_exploit_50000/mdp_arbitrary_mdp_fictitious_selfplay2.
Episode: 1/30000 (0.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0270s / 0.0270 s
agent0:                 episode reward: -0.1492,                 loss: nan
agent1:                 episode reward: 0.1492,                 loss: nan
Episode: 21/30000 (0.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0568s / 0.0838 s
agent0:                 episode reward: 0.4838,                 loss: nan
agent1:                 episode reward: -0.4838,                 loss: nan
Episode: 41/30000 (0.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0515s / 0.1352 s
agent0:                 episode reward: -0.1507,                 loss: nan
agent1:                 episode reward: 0.1507,                 loss: nan
Episode: 61/30000 (0.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0470s / 0.1823 s
agent0:                 episode reward: 0.2448,                 loss: nan
agent1:                 episode reward: -0.2448,                 loss: nan
Episode: 81/30000 (0.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0458s / 0.2280 s
agent0:                 episode reward: 0.4583,                 loss: nan
agent1:                 episode reward: -0.4583,                 loss: nan
Episode: 101/30000 (0.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0451s / 0.2732 s
agent0:                 episode reward: 0.0332,                 loss: nan
agent1:                 episode reward: -0.0332,                 loss: nan
Episode: 121/30000 (0.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0439s / 0.3170 s
agent0:                 episode reward: 0.0409,                 loss: nan
agent1:                 episode reward: -0.0409,                 loss: nan
Episode: 141/30000 (0.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0458s / 0.3629 s
agent0:                 episode reward: -0.2809,                 loss: nan
agent1:                 episode reward: 0.2809,                 loss: nan
Episode: 161/30000 (0.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0434s / 0.4062 s
agent0:                 episode reward: -0.0144,                 loss: nan
agent1:                 episode reward: 0.0144,                 loss: nan
Episode: 181/30000 (0.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0426s / 0.4488 s
agent0:                 episode reward: -0.4147,                 loss: nan
agent1:                 episode reward: 0.4147,                 loss: nan
Episode: 201/30000 (0.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0435s / 0.4923 s
agent0:                 episode reward: -0.0023,                 loss: nan
agent1:                 episode reward: 0.0023,                 loss: nan
Episode: 221/30000 (0.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1106s / 0.6029 s
agent0:                 episode reward: 0.0073,                 loss: nan
agent1:                 episode reward: -0.0073,                 loss: 0.2082
Episode: 241/30000 (0.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1566s / 0.7595 s
agent0:                 episode reward: 0.0677,                 loss: nan
agent1:                 episode reward: -0.0677,                 loss: 0.1904
Episode: 261/30000 (0.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1561s / 0.9156 s
agent0:                 episode reward: 0.3129,                 loss: nan
agent1:                 episode reward: -0.3129,                 loss: 0.1759
Episode: 281/30000 (0.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1595s / 1.0751 s
agent0:                 episode reward: 0.1639,                 loss: nan
agent1:                 episode reward: -0.1639,                 loss: 0.1697
Episode: 301/30000 (1.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1648s / 1.2400 s
agent0:                 episode reward: -0.0768,                 loss: nan
agent1:                 episode reward: 0.0768,                 loss: 0.1648
Episode: 321/30000 (1.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1656s / 1.4055 s
agent0:                 episode reward: 0.2582,                 loss: nan
agent1:                 episode reward: -0.2582,                 loss: 0.1612
Episode: 341/30000 (1.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1637s / 1.5692 s
agent0:                 episode reward: 0.0913,                 loss: nan
agent1:                 episode reward: -0.0913,                 loss: 0.1569
Episode: 361/30000 (1.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1586s / 1.7278 s
agent0:                 episode reward: 0.2381,                 loss: nan
agent1:                 episode reward: -0.2381,                 loss: 0.1539
Episode: 381/30000 (1.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1668s / 1.8946 s
agent0:                 episode reward: -0.2284,                 loss: nan
agent1:                 episode reward: 0.2284,                 loss: 0.1533
Episode: 401/30000 (1.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1932s / 2.0878 s
agent0:                 episode reward: 0.1198,                 loss: nan
agent1:                 episode reward: -0.1198,                 loss: 0.1500
Episode: 421/30000 (1.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1702s / 2.2580 s
agent0:                 episode reward: -0.1158,                 loss: nan
agent1:                 episode reward: 0.1158,                 loss: 0.1478
Episode: 441/30000 (1.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1597s / 2.4177 s
agent0:                 episode reward: 0.2612,                 loss: nan
agent1:                 episode reward: -0.2612,                 loss: 0.1478
Episode: 461/30000 (1.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1599s / 2.5777 s
agent0:                 episode reward: 0.2732,                 loss: nan
agent1:                 episode reward: -0.2732,                 loss: 0.1450
Episode: 481/30000 (1.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1827s / 2.7604 s
agent0:                 episode reward: 0.0411,                 loss: nan
agent1:                 episode reward: -0.0411,                 loss: 0.1414
Episode: 501/30000 (1.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2001s / 2.9605 s
agent0:                 episode reward: -0.3509,                 loss: nan
agent1:                 episode reward: 0.3509,                 loss: 0.1409
Episode: 521/30000 (1.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1580s / 3.1185 s
agent0:                 episode reward: -0.4061,                 loss: nan
agent1:                 episode reward: 0.4061,                 loss: 0.1400
Episode: 541/30000 (1.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1675s / 3.2861 s
agent0:                 episode reward: -0.1660,                 loss: nan
agent1:                 episode reward: 0.1660,                 loss: 0.1390
Episode: 561/30000 (1.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1672s / 3.4533 s
agent0:                 episode reward: 0.4485,                 loss: nan
agent1:                 episode reward: -0.4485,                 loss: 0.1462
Episode: 581/30000 (1.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1643s / 3.6176 s
agent0:                 episode reward: -0.1017,                 loss: nan
agent1:                 episode reward: 0.1017,                 loss: 0.1437
Episode: 601/30000 (2.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1634s / 3.7810 s
agent0:                 episode reward: -0.1304,                 loss: nan
agent1:                 episode reward: 0.1304,                 loss: 0.1426
Episode: 621/30000 (2.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1628s / 3.9439 s
agent0:                 episode reward: -0.2490,                 loss: nan
agent1:                 episode reward: 0.2490,                 loss: 0.1408
Episode: 641/30000 (2.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1591s / 4.1030 s
agent0:                 episode reward: 0.0497,                 loss: nan
agent1:                 episode reward: -0.0497,                 loss: 0.1392
Episode: 661/30000 (2.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1625s / 4.2656 s
agent0:                 episode reward: -0.1667,                 loss: nan
agent1:                 episode reward: 0.1667,                 loss: 0.1377
Episode: 681/30000 (2.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1634s / 4.4290 s
agent0:                 episode reward: -0.0331,                 loss: nan
agent1:                 episode reward: 0.0331,                 loss: 0.1385
Episode: 701/30000 (2.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1710s / 4.6000 s
agent0:                 episode reward: 0.1351,                 loss: nan
agent1:                 episode reward: -0.1351,                 loss: 0.1377
Episode: 721/30000 (2.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1594s / 4.7594 s
agent0:                 episode reward: -0.2518,                 loss: nan
agent1:                 episode reward: 0.2518,                 loss: 0.1368
Episode: 741/30000 (2.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1579s / 4.9173 s
agent0:                 episode reward: 0.2295,                 loss: nan
agent1:                 episode reward: -0.2295,                 loss: 0.1378
Episode: 761/30000 (2.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1694s / 5.0866 s
agent0:                 episode reward: 0.0029,                 loss: nan
agent1:                 episode reward: -0.0029,                 loss: 0.1372
Episode: 781/30000 (2.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1638s / 5.2504 s
agent0:                 episode reward: -0.0041,                 loss: nan
agent1:                 episode reward: 0.0041,                 loss: 0.1376
Episode: 801/30000 (2.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1547s / 5.4051 s
agent0:                 episode reward: 0.3562,                 loss: nan
agent1:                 episode reward: -0.3562,                 loss: 0.1360
Episode: 821/30000 (2.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1609s / 5.5661 s
agent0:                 episode reward: -0.1285,                 loss: nan
agent1:                 episode reward: 0.1285,                 loss: 0.1362
Episode: 841/30000 (2.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1629s / 5.7290 s
agent0:                 episode reward: -0.1497,                 loss: nan
agent1:                 episode reward: 0.1497,                 loss: 0.1369
Episode: 861/30000 (2.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1649s / 5.8939 s
agent0:                 episode reward: -0.3618,                 loss: nan
agent1:                 episode reward: 0.3618,                 loss: 0.1378
Episode: 881/30000 (2.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1616s / 6.0555 s
agent0:                 episode reward: -0.3966,                 loss: nan
agent1:                 episode reward: 0.3966,                 loss: 0.1383
Episode: 901/30000 (3.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1632s / 6.2188 s
agent0:                 episode reward: -0.2809,                 loss: nan
agent1:                 episode reward: 0.2809,                 loss: 0.1405
Episode: 921/30000 (3.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1669s / 6.3857 s
agent0:                 episode reward: 0.1687,                 loss: nan
agent1:                 episode reward: -0.1687,                 loss: 0.1396
Episode: 941/30000 (3.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1687s / 6.5544 s
agent0:                 episode reward: 0.2132,                 loss: nan
agent1:                 episode reward: -0.2132,                 loss: 0.1396
Episode: 961/30000 (3.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1685s / 6.7229 s
agent0:                 episode reward: -0.2076,                 loss: nan
agent1:                 episode reward: 0.2076,                 loss: 0.1387
Episode: 981/30000 (3.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1657s / 6.8886 s
agent0:                 episode reward: 0.1398,                 loss: nan
agent1:                 episode reward: -0.1398,                 loss: 0.1399
Episode: 1001/30000 (3.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1647s / 7.0533 s
agent0:                 episode reward: 0.2619,                 loss: nan
agent1:                 episode reward: -0.2619,                 loss: 0.1383
Episode: 1021/30000 (3.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1605s / 7.2138 s
agent0:                 episode reward: -0.2220,                 loss: nan
agent1:                 episode reward: 0.2220,                 loss: 0.1405
Episode: 1041/30000 (3.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1639s / 7.3776 s
agent0:                 episode reward: -0.4964,                 loss: nan
agent1:                 episode reward: 0.4964,                 loss: 0.1395
Episode: 1061/30000 (3.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1720s / 7.5496 s
agent0:                 episode reward: -0.0726,                 loss: nan
agent1:                 episode reward: 0.0726,                 loss: 0.1397
Episode: 1081/30000 (3.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1677s / 7.7173 s
agent0:                 episode reward: -0.2521,                 loss: nan
agent1:                 episode reward: 0.2521,                 loss: 0.1380
Episode: 1101/30000 (3.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1668s / 7.8840 s
agent0:                 episode reward: 0.1814,                 loss: nan
agent1:                 episode reward: -0.1814,                 loss: 0.1381
Episode: 1121/30000 (3.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1761s / 8.0602 s
agent0:                 episode reward: 0.3158,                 loss: nan
agent1:                 episode reward: -0.3158,                 loss: 0.1364
Episode: 1141/30000 (3.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1893s / 8.2494 s
agent0:                 episode reward: -0.0847,                 loss: nan
agent1:                 episode reward: 0.0847,                 loss: 0.1361
Episode: 1161/30000 (3.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1688s / 8.4182 s
agent0:                 episode reward: 0.1750,                 loss: nan
agent1:                 episode reward: -0.1750,                 loss: 0.1348
Episode: 1181/30000 (3.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1685s / 8.5867 s
agent0:                 episode reward: -0.0791,                 loss: nan
agent1:                 episode reward: 0.0791,                 loss: 0.1353
Episode: 1201/30000 (4.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1727s / 8.7594 s
agent0:                 episode reward: 0.2433,                 loss: nan
agent1:                 episode reward: -0.2433,                 loss: 0.1355
Episode: 1221/30000 (4.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1669s / 8.9263 s
agent0:                 episode reward: 0.1042,                 loss: nan
agent1:                 episode reward: -0.1042,                 loss: 0.1358
Episode: 1241/30000 (4.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1567s / 9.0830 s
agent0:                 episode reward: -0.1785,                 loss: nan
agent1:                 episode reward: 0.1785,                 loss: 0.1349
Episode: 1261/30000 (4.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1606s / 9.2436 s
agent0:                 episode reward: 0.0971,                 loss: nan
agent1:                 episode reward: -0.0971,                 loss: 0.1355
Episode: 1281/30000 (4.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1581s / 9.4017 s
agent0:                 episode reward: 0.4084,                 loss: nan
agent1:                 episode reward: -0.4084,                 loss: 0.1339
Episode: 1301/30000 (4.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1624s / 9.5640 s
agent0:                 episode reward: 0.2182,                 loss: nan
agent1:                 episode reward: -0.2182,                 loss: 0.1336
Episode: 1321/30000 (4.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1615s / 9.7255 s
agent0:                 episode reward: -0.3801,                 loss: nan
agent1:                 episode reward: 0.3801,                 loss: 0.1340
Episode: 1341/30000 (4.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1603s / 9.8858 s
agent0:                 episode reward: 0.2736,                 loss: nan
agent1:                 episode reward: -0.2736,                 loss: 0.1342
Episode: 1361/30000 (4.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1609s / 10.0468 s
agent0:                 episode reward: -0.3626,                 loss: nan
agent1:                 episode reward: 0.3626,                 loss: 0.1339
Episode: 1381/30000 (4.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1621s / 10.2088 s
agent0:                 episode reward: -0.4999,                 loss: nan
agent1:                 episode reward: 0.4999,                 loss: 0.1333
Episode: 1401/30000 (4.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1642s / 10.3730 s
agent0:                 episode reward: 0.2862,                 loss: nan
agent1:                 episode reward: -0.2862,                 loss: 0.1349
Episode: 1421/30000 (4.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1656s / 10.5386 s
agent0:                 episode reward: -0.2597,                 loss: nan
agent1:                 episode reward: 0.2597,                 loss: 0.1340
Episode: 1441/30000 (4.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1656s / 10.7042 s
agent0:                 episode reward: 0.2167,                 loss: nan
agent1:                 episode reward: -0.2167,                 loss: 0.1330
Episode: 1461/30000 (4.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1638s / 10.8680 s
agent0:                 episode reward: -0.2726,                 loss: nan
agent1:                 episode reward: 0.2726,                 loss: 0.1325
Episode: 1481/30000 (4.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1705s / 11.0385 s
agent0:                 episode reward: -0.0448,                 loss: nan
agent1:                 episode reward: 0.0448,                 loss: 0.1316
Episode: 1501/30000 (5.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1975s / 11.2360 s
agent0:                 episode reward: -0.4358,                 loss: nan
agent1:                 episode reward: 0.4358,                 loss: 0.1324
Episode: 1521/30000 (5.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1756s / 11.4115 s
agent0:                 episode reward: -0.3166,                 loss: nan
agent1:                 episode reward: 0.3166,                 loss: 0.1321
Episode: 1541/30000 (5.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1646s / 11.5761 s
agent0:                 episode reward: 0.0404,                 loss: nan
agent1:                 episode reward: -0.0404,                 loss: 0.1299
Episode: 1561/30000 (5.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1601s / 11.7362 s
agent0:                 episode reward: 0.2470,                 loss: nan
agent1:                 episode reward: -0.2470,                 loss: 0.1307
Episode: 1581/30000 (5.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1689s / 11.9051 s
agent0:                 episode reward: 0.2967,                 loss: nan
agent1:                 episode reward: -0.2967,                 loss: 0.1302
Episode: 1601/30000 (5.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1717s / 12.0768 s
agent0:                 episode reward: 0.4518,                 loss: nan
agent1:                 episode reward: -0.4518,                 loss: 0.1302
Episode: 1621/30000 (5.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1673s / 12.2441 s
agent0:                 episode reward: 0.0816,                 loss: nan
agent1:                 episode reward: -0.0816,                 loss: 0.1293
Episode: 1641/30000 (5.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1640s / 12.4082 s
agent0:                 episode reward: -0.0464,                 loss: nan
agent1:                 episode reward: 0.0464,                 loss: 0.1292
Episode: 1661/30000 (5.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1646s / 12.5727 s
agent0:                 episode reward: -0.1798,                 loss: nan
agent1:                 episode reward: 0.1798,                 loss: 0.1290
Episode: 1681/30000 (5.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1649s / 12.7377 s
agent0:                 episode reward: -0.0230,                 loss: nan
agent1:                 episode reward: 0.0230,                 loss: 0.1278
Episode: 1701/30000 (5.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1917s / 12.9293 s
agent0:                 episode reward: 0.1768,                 loss: nan
agent1:                 episode reward: -0.1768,                 loss: 0.1296
Episode: 1721/30000 (5.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1716s / 13.1009 s
agent0:                 episode reward: 0.0737,                 loss: nan
agent1:                 episode reward: -0.0737,                 loss: 0.1288
Episode: 1741/30000 (5.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1962s / 13.2971 s
agent0:                 episode reward: -0.1094,                 loss: nan
agent1:                 episode reward: 0.1094,                 loss: 0.1293
Episode: 1761/30000 (5.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1834s / 13.4805 s
agent0:                 episode reward: -0.2178,                 loss: nan
agent1:                 episode reward: 0.2178,                 loss: 0.1301
Episode: 1781/30000 (5.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1678s / 13.6483 s
agent0:                 episode reward: 0.0296,                 loss: nan
agent1:                 episode reward: -0.0296,                 loss: 0.1298
Episode: 1801/30000 (6.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1655s / 13.8137 s
agent0:                 episode reward: -0.3039,                 loss: nan
agent1:                 episode reward: 0.3039,                 loss: 0.1308
Episode: 1821/30000 (6.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1759s / 13.9896 s
agent0:                 episode reward: -0.2767,                 loss: nan
agent1:                 episode reward: 0.2767,                 loss: 0.1282
Episode: 1841/30000 (6.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2350s / 14.2247 s
agent0:                 episode reward: 0.0982,                 loss: nan
agent1:                 episode reward: -0.0982,                 loss: 0.1285
Episode: 1861/30000 (6.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1854s / 14.4101 s
agent0:                 episode reward: 0.2953,                 loss: nan
agent1:                 episode reward: -0.2953,                 loss: 0.1267
Episode: 1881/30000 (6.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1716s / 14.5817 s
agent0:                 episode reward: 0.2550,                 loss: nan
agent1:                 episode reward: -0.2550,                 loss: 0.1294
Episode: 1901/30000 (6.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1731s / 14.7549 s
agent0:                 episode reward: -0.1060,                 loss: nan
agent1:                 episode reward: 0.1060,                 loss: 0.1308
Episode: 1921/30000 (6.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2045s / 14.9593 s
agent0:                 episode reward: -0.3240,                 loss: nan
agent1:                 episode reward: 0.3240,                 loss: 0.1311
Episode: 1941/30000 (6.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1919s / 15.1513 s
agent0:                 episode reward: -0.4687,                 loss: nan
agent1:                 episode reward: 0.4687,                 loss: 0.1314
Episode: 1961/30000 (6.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1643s / 15.3155 s
agent0:                 episode reward: 0.1881,                 loss: nan
agent1:                 episode reward: -0.1881,                 loss: 0.1309
Episode: 1981/30000 (6.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1643s / 15.4798 s
agent0:                 episode reward: 0.0461,                 loss: nan
agent1:                 episode reward: -0.0461,                 loss: 0.1305
Episode: 2001/30000 (6.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1653s / 15.6451 s
agent0:                 episode reward: 0.0322,                 loss: nan
agent1:                 episode reward: -0.0322,                 loss: 0.1301
Episode: 2021/30000 (6.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1652s / 15.8102 s
agent0:                 episode reward: 0.2192,                 loss: nan
agent1:                 episode reward: -0.2192,                 loss: 0.1307
Episode: 2041/30000 (6.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1655s / 15.9757 s
agent0:                 episode reward: 0.0729,                 loss: nan
agent1:                 episode reward: -0.0729,                 loss: 0.1297
Episode: 2061/30000 (6.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1661s / 16.1418 s
agent0:                 episode reward: -0.0865,                 loss: nan
agent1:                 episode reward: 0.0865,                 loss: 0.1304
Episode: 2081/30000 (6.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1732s / 16.3149 s
agent0:                 episode reward: 0.0950,                 loss: nan
agent1:                 episode reward: -0.0950,                 loss: 0.1289
Episode: 2101/30000 (7.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1717s / 16.4866 s
agent0:                 episode reward: -0.4145,                 loss: nan
agent1:                 episode reward: 0.4145,                 loss: 0.1289
Episode: 2121/30000 (7.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1693s / 16.6559 s
agent0:                 episode reward: -0.1226,                 loss: nan
agent1:                 episode reward: 0.1226,                 loss: 0.1305
Episode: 2141/30000 (7.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1693s / 16.8253 s
agent0:                 episode reward: 0.1608,                 loss: nan
agent1:                 episode reward: -0.1608,                 loss: 0.1289
Episode: 2161/30000 (7.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1701s / 16.9954 s
agent0:                 episode reward: 0.2071,                 loss: nan
agent1:                 episode reward: -0.2071,                 loss: 0.1285
Episode: 2181/30000 (7.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1787s / 17.1741 s
agent0:                 episode reward: 0.1304,                 loss: nan
agent1:                 episode reward: -0.1304,                 loss: 0.1296
Episode: 2201/30000 (7.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1891s / 17.3632 s
agent0:                 episode reward: 0.0270,                 loss: nan
agent1:                 episode reward: -0.0270,                 loss: 0.1298
Episode: 2221/30000 (7.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1815s / 17.5447 s
agent0:                 episode reward: -0.3028,                 loss: nan
agent1:                 episode reward: 0.3028,                 loss: 0.1277
Episode: 2241/30000 (7.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1743s / 17.7190 s
agent0:                 episode reward: -0.0470,                 loss: nan
agent1:                 episode reward: 0.0470,                 loss: 0.1259
Episode: 2261/30000 (7.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1750s / 17.8940 s
agent0:                 episode reward: -0.3647,                 loss: nan
agent1:                 episode reward: 0.3647,                 loss: 0.1277
Episode: 2281/30000 (7.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1720s / 18.0661 s
agent0:                 episode reward: 0.2737,                 loss: nan
agent1:                 episode reward: -0.2737,                 loss: 0.1279
Episode: 2301/30000 (7.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1720s / 18.2381 s
agent0:                 episode reward: -0.3932,                 loss: nan
agent1:                 episode reward: 0.3932,                 loss: 0.1267
Episode: 2321/30000 (7.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1730s / 18.4110 s
agent0:                 episode reward: 0.1399,                 loss: nan
agent1:                 episode reward: -0.1399,                 loss: 0.1264
Episode: 2341/30000 (7.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1745s / 18.5855 s
agent0:                 episode reward: 0.0374,                 loss: nan
agent1:                 episode reward: -0.0374,                 loss: 0.1256
Episode: 2361/30000 (7.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1710s / 18.7565 s
agent0:                 episode reward: 0.0308,                 loss: nan
agent1:                 episode reward: -0.0308,                 loss: 0.1244
Episode: 2381/30000 (7.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1767s / 18.9333 s
agent0:                 episode reward: 0.2802,                 loss: nan
agent1:                 episode reward: -0.2802,                 loss: 0.1266
Episode: 2401/30000 (8.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1766s / 19.1098 s
agent0:                 episode reward: -0.0947,                 loss: nan
agent1:                 episode reward: 0.0947,                 loss: 0.1266
Episode: 2421/30000 (8.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1695s / 19.2793 s
agent0:                 episode reward: 0.0382,                 loss: nan
agent1:                 episode reward: -0.0382,                 loss: 0.1253
Episode: 2441/30000 (8.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1733s / 19.4526 s
agent0:                 episode reward: -0.6043,                 loss: nan
agent1:                 episode reward: 0.6043,                 loss: 0.1254
Episode: 2461/30000 (8.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1738s / 19.6264 s
agent0:                 episode reward: -0.3877,                 loss: nan
agent1:                 episode reward: 0.3877,                 loss: 0.1252
Episode: 2481/30000 (8.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1721s / 19.7985 s
agent0:                 episode reward: -0.1081,                 loss: nan
agent1:                 episode reward: 0.1081,                 loss: 0.1267
Episode: 2501/30000 (8.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1752s / 19.9737 s
agent0:                 episode reward: -0.0478,                 loss: nan
agent1:                 episode reward: 0.0478,                 loss: 0.1253
Episode: 2521/30000 (8.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1692s / 20.1429 s
agent0:                 episode reward: 0.1067,                 loss: nan
agent1:                 episode reward: -0.1067,                 loss: 0.1259
Episode: 2541/30000 (8.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1877s / 20.3307 s
agent0:                 episode reward: -0.2162,                 loss: nan
agent1:                 episode reward: 0.2162,                 loss: 0.1253
Episode: 2561/30000 (8.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1888s / 20.5195 s
agent0:                 episode reward: 0.0816,                 loss: nan
agent1:                 episode reward: -0.0816,                 loss: 0.1312
Episode: 2581/30000 (8.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1728s / 20.6923 s
agent0:                 episode reward: -0.5720,                 loss: nan
agent1:                 episode reward: 0.5720,                 loss: 0.1319
Episode: 2601/30000 (8.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1696s / 20.8619 s
agent0:                 episode reward: -0.4157,                 loss: nan
agent1:                 episode reward: 0.4157,                 loss: 0.1329
Episode: 2621/30000 (8.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1701s / 21.0320 s
agent0:                 episode reward: -0.2430,                 loss: nan
agent1:                 episode reward: 0.2430,                 loss: 0.1326
Episode: 2641/30000 (8.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1859s / 21.2178 s
agent0:                 episode reward: 0.0561,                 loss: nan
agent1:                 episode reward: -0.0561,                 loss: 0.1325
Episode: 2661/30000 (8.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1769s / 21.3947 s
agent0:                 episode reward: 0.2339,                 loss: nan
agent1:                 episode reward: -0.2339,                 loss: 0.1327
Episode: 2681/30000 (8.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1763s / 21.5710 s
agent0:                 episode reward: -0.2242,                 loss: nan
agent1:                 episode reward: 0.2242,                 loss: 0.1305
Episode: 2701/30000 (9.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1755s / 21.7465 s
agent0:                 episode reward: -0.2120,                 loss: nan
agent1:                 episode reward: 0.2120,                 loss: 0.1333
Episode: 2721/30000 (9.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1744s / 21.9209 s
agent0:                 episode reward: -0.3599,                 loss: nan
agent1:                 episode reward: 0.3599,                 loss: 0.1316
Episode: 2741/30000 (9.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1768s / 22.0977 s
agent0:                 episode reward: -0.2096,                 loss: nan
agent1:                 episode reward: 0.2096,                 loss: 0.1323
Episode: 2761/30000 (9.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1752s / 22.2729 s
agent0:                 episode reward: 0.0048,                 loss: nan
agent1:                 episode reward: -0.0048,                 loss: 0.1331
Episode: 2781/30000 (9.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1796s / 22.4525 s
agent0:                 episode reward: -0.1350,                 loss: nan
agent1:                 episode reward: 0.1350,                 loss: 0.1323
Episode: 2801/30000 (9.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2088s / 22.6613 s
agent0:                 episode reward: -0.4351,                 loss: nan
agent1:                 episode reward: 0.4351,                 loss: 0.1334
Episode: 2821/30000 (9.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1745s / 22.8358 s
agent0:                 episode reward: -0.3377,                 loss: nan
agent1:                 episode reward: 0.3377,                 loss: 0.1332
Episode: 2841/30000 (9.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1881s / 23.0239 s
agent0:                 episode reward: 0.2937,                 loss: nan
agent1:                 episode reward: -0.2937,                 loss: 0.1319
Episode: 2861/30000 (9.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1798s / 23.2037 s
agent0:                 episode reward: 0.0914,                 loss: nan
agent1:                 episode reward: -0.0914,                 loss: 0.1313
Episode: 2881/30000 (9.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1936s / 23.3973 s
agent0:                 episode reward: -0.3219,                 loss: nan
agent1:                 episode reward: 0.3219,                 loss: 0.1320
Episode: 2901/30000 (9.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1936s / 23.5910 s
agent0:                 episode reward: -0.4233,                 loss: nan
agent1:                 episode reward: 0.4233,                 loss: 0.1241
Episode: 2921/30000 (9.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1822s / 23.7732 s
agent0:                 episode reward: -0.0532,                 loss: nan
agent1:                 episode reward: 0.0532,                 loss: 0.1268
Episode: 2941/30000 (9.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1828s / 23.9559 s
agent0:                 episode reward: 0.0567,                 loss: nan
agent1:                 episode reward: -0.0567,                 loss: 0.1251
Episode: 2961/30000 (9.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1819s / 24.1379 s
agent0:                 episode reward: -0.2118,                 loss: nan
agent1:                 episode reward: 0.2118,                 loss: 0.1248
Episode: 2981/30000 (9.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1792s / 24.3170 s
agent0:                 episode reward: -0.2931,                 loss: nan
agent1:                 episode reward: 0.2931,                 loss: 0.1249
Episode: 3001/30000 (10.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1811s / 24.4981 s
agent0:                 episode reward: 0.1923,                 loss: nan
agent1:                 episode reward: -0.1923,                 loss: 0.1250
Episode: 3021/30000 (10.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1834s / 24.6815 s
agent0:                 episode reward: 0.0308,                 loss: nan
agent1:                 episode reward: -0.0308,                 loss: 0.1243
Episode: 3041/30000 (10.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1732s / 24.8547 s
agent0:                 episode reward: -0.1622,                 loss: nan
agent1:                 episode reward: 0.1622,                 loss: 0.1255
Episode: 3061/30000 (10.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1782s / 25.0329 s
agent0:                 episode reward: -0.0778,                 loss: nan
agent1:                 episode reward: 0.0778,                 loss: 0.1254
Episode: 3081/30000 (10.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1794s / 25.2123 s
agent0:                 episode reward: -0.2485,                 loss: nan
agent1:                 episode reward: 0.2485,                 loss: 0.1253
Episode: 3101/30000 (10.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1786s / 25.3909 s
agent0:                 episode reward: -0.2791,                 loss: nan
agent1:                 episode reward: 0.2791,                 loss: 0.1242
Episode: 3121/30000 (10.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1756s / 25.5665 s
agent0:                 episode reward: 0.1708,                 loss: nan
agent1:                 episode reward: -0.1708,                 loss: 0.1248
Episode: 3141/30000 (10.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1758s / 25.7422 s
agent0:                 episode reward: -0.1402,                 loss: nan
agent1:                 episode reward: 0.1402,                 loss: 0.1259
Episode: 3161/30000 (10.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1778s / 25.9201 s
agent0:                 episode reward: -0.0543,                 loss: nan
agent1:                 episode reward: 0.0543,                 loss: 0.1241
Episode: 3181/30000 (10.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1778s / 26.0979 s
agent0:                 episode reward: -0.0524,                 loss: nan
agent1:                 episode reward: 0.0524,                 loss: 0.1267
Episode: 3201/30000 (10.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1778s / 26.2757 s
agent0:                 episode reward: 0.0617,                 loss: nan
agent1:                 episode reward: -0.0617,                 loss: 0.1258
Episode: 3221/30000 (10.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1943s / 26.4700 s
agent0:                 episode reward: -0.1830,                 loss: nan
agent1:                 episode reward: 0.1830,                 loss: 0.1261
Episode: 3241/30000 (10.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1972s / 26.6672 s
agent0:                 episode reward: -0.5998,                 loss: nan
agent1:                 episode reward: 0.5998,                 loss: 0.1305
Episode: 3261/30000 (10.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1813s / 26.8484 s
agent0:                 episode reward: -0.3024,                 loss: nan
agent1:                 episode reward: 0.3024,                 loss: 0.1293
Episode: 3281/30000 (10.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1816s / 27.0300 s
agent0:                 episode reward: -0.1212,                 loss: nan
agent1:                 episode reward: 0.1212,                 loss: 0.1293
Episode: 3301/30000 (11.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1852s / 27.2153 s
agent0:                 episode reward: 0.4166,                 loss: nan
agent1:                 episode reward: -0.4166,                 loss: 0.1292
Episode: 3321/30000 (11.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1834s / 27.3986 s
agent0:                 episode reward: -0.5439,                 loss: nan
agent1:                 episode reward: 0.5439,                 loss: 0.1279
Episode: 3341/30000 (11.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1812s / 27.5798 s
agent0:                 episode reward: -0.3586,                 loss: nan
agent1:                 episode reward: 0.3586,                 loss: 0.1303
Episode: 3361/30000 (11.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1789s / 27.7587 s
agent0:                 episode reward: 0.0391,                 loss: nan
agent1:                 episode reward: -0.0391,                 loss: 0.1315
Episode: 3381/30000 (11.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1782s / 27.9369 s
agent0:                 episode reward: -0.4311,                 loss: nan
agent1:                 episode reward: 0.4311,                 loss: 0.1289
Episode: 3401/30000 (11.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1807s / 28.1176 s
agent0:                 episode reward: -0.5273,                 loss: nan
agent1:                 episode reward: 0.5273,                 loss: 0.1286
Episode: 3421/30000 (11.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1765s / 28.2941 s
agent0:                 episode reward: 0.0733,                 loss: nan
agent1:                 episode reward: -0.0733,                 loss: 0.1292
Episode: 3441/30000 (11.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1746s / 28.4687 s
agent0:                 episode reward: -0.1214,                 loss: nan
agent1:                 episode reward: 0.1214,                 loss: 0.1285
Episode: 3461/30000 (11.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1939s / 28.6626 s
agent0:                 episode reward: 0.2110,                 loss: nan
agent1:                 episode reward: -0.2110,                 loss: 0.1291
Episode: 3481/30000 (11.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1796s / 28.8422 s
agent0:                 episode reward: -0.3124,                 loss: nan
agent1:                 episode reward: 0.3124,                 loss: 0.1289
Episode: 3501/30000 (11.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1803s / 29.0226 s
agent0:                 episode reward: -0.3521,                 loss: nan
agent1:                 episode reward: 0.3521,                 loss: 0.1283
Episode: 3521/30000 (11.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1817s / 29.2043 s
agent0:                 episode reward: 0.1009,                 loss: nan
agent1:                 episode reward: -0.1009,                 loss: 0.1284
Episode: 3541/30000 (11.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1816s / 29.3859 s
agent0:                 episode reward: -0.3428,                 loss: nan
agent1:                 episode reward: 0.3428,                 loss: 0.1290
Episode: 3561/30000 (11.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2290s / 29.6149 s
agent0:                 episode reward: 0.2481,                 loss: nan
agent1:                 episode reward: -0.2481,                 loss: 0.1273
Episode: 3581/30000 (11.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2028s / 29.8178 s
agent0:                 episode reward: -0.2629,                 loss: nan
agent1:                 episode reward: 0.2629,                 loss: 0.1253
Episode: 3601/30000 (12.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1790s / 29.9967 s
agent0:                 episode reward: 0.2297,                 loss: nan
agent1:                 episode reward: -0.2297,                 loss: 0.1243
Episode: 3621/30000 (12.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1783s / 30.1750 s
agent0:                 episode reward: -0.3675,                 loss: nan
agent1:                 episode reward: 0.3675,                 loss: 0.1244
Episode: 3641/30000 (12.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1781s / 30.3531 s
agent0:                 episode reward: 0.0078,                 loss: nan
agent1:                 episode reward: -0.0078,                 loss: 0.1246
Episode: 3661/30000 (12.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1806s / 30.5338 s
agent0:                 episode reward: -0.2420,                 loss: nan
agent1:                 episode reward: 0.2420,                 loss: 0.1242
Episode: 3681/30000 (12.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1844s / 30.7182 s
agent0:                 episode reward: 0.0290,                 loss: nan
agent1:                 episode reward: -0.0290,                 loss: 0.1260
Episode: 3701/30000 (12.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1857s / 30.9039 s
agent0:                 episode reward: -0.1993,                 loss: nan
agent1:                 episode reward: 0.1993,                 loss: 0.1238
Episode: 3721/30000 (12.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1895s / 31.0934 s
agent0:                 episode reward: -0.0279,                 loss: nan
agent1:                 episode reward: 0.0279,                 loss: 0.1247
Episode: 3741/30000 (12.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1898s / 31.2832 s
agent0:                 episode reward: -0.1646,                 loss: nan
agent1:                 episode reward: 0.1646,                 loss: 0.1235
Episode: 3761/30000 (12.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1883s / 31.4714 s
agent0:                 episode reward: -0.2398,                 loss: nan
agent1:                 episode reward: 0.2398,                 loss: 0.1242
Episode: 3781/30000 (12.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1880s / 31.6594 s
agent0:                 episode reward: 0.1349,                 loss: nan
agent1:                 episode reward: -0.1349,                 loss: 0.1256
Episode: 3801/30000 (12.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1901s / 31.8496 s
agent0:                 episode reward: -0.2823,                 loss: nan
agent1:                 episode reward: 0.2823,                 loss: 0.1253
Episode: 3821/30000 (12.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1902s / 32.0397 s
agent0:                 episode reward: -0.1607,                 loss: nan
agent1:                 episode reward: 0.1607,                 loss: 0.1245
Episode: 3841/30000 (12.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1884s / 32.2281 s
agent0:                 episode reward: -0.2721,                 loss: nan
agent1:                 episode reward: 0.2721,                 loss: 0.1242
Episode: 3861/30000 (12.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1894s / 32.4175 s
agent0:                 episode reward: -0.3577,                 loss: nan
agent1:                 episode reward: 0.3577,                 loss: 0.1250
Episode: 3881/30000 (12.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2137s / 32.6312 s
agent0:                 episode reward: -0.3278,                 loss: nan
agent1:                 episode reward: 0.3278,                 loss: 0.1268
Episode: 3901/30000 (13.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2010s / 32.8322 s
agent0:                 episode reward: -0.1180,                 loss: nan
agent1:                 episode reward: 0.1180,                 loss: 0.1253
Episode: 3921/30000 (13.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1860s / 33.0182 s
agent0:                 episode reward: -0.1500,                 loss: nan
agent1:                 episode reward: 0.1500,                 loss: 0.1248
Episode: 3941/30000 (13.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1837s / 33.2019 s
agent0:                 episode reward: -0.0334,                 loss: nan
agent1:                 episode reward: 0.0334,                 loss: 0.1252
Episode: 3961/30000 (13.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1880s / 33.3900 s
agent0:                 episode reward: 0.1660,                 loss: nan
agent1:                 episode reward: -0.1660,                 loss: 0.1254
Episode: 3981/30000 (13.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1891s / 33.5790 s
agent0:                 episode reward: 0.1305,                 loss: nan
agent1:                 episode reward: -0.1305,                 loss: 0.1264
Episode: 4001/30000 (13.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1914s / 33.7705 s
agent0:                 episode reward: 0.0981,                 loss: nan
agent1:                 episode reward: -0.0981,                 loss: 0.1261
Episode: 4021/30000 (13.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1869s / 33.9574 s
agent0:                 episode reward: -0.5700,                 loss: nan
agent1:                 episode reward: 0.5700,                 loss: 0.1264
Episode: 4041/30000 (13.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1890s / 34.1464 s
agent0:                 episode reward: -0.4562,                 loss: nan
agent1:                 episode reward: 0.4562,                 loss: 0.1268
Episode: 4061/30000 (13.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1891s / 34.3355 s
agent0:                 episode reward: -0.2386,                 loss: nan
agent1:                 episode reward: 0.2386,                 loss: 0.1276
Episode: 4081/30000 (13.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1842s / 34.5197 s
agent0:                 episode reward: -0.4046,                 loss: nan
agent1:                 episode reward: 0.4046,                 loss: 0.1267
Episode: 4101/30000 (13.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1833s / 34.7030 s
agent0:                 episode reward: -0.1459,                 loss: nan
agent1:                 episode reward: 0.1459,                 loss: 0.1265
Episode: 4121/30000 (13.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1849s / 34.8880 s
agent0:                 episode reward: -0.0149,                 loss: nan
agent1:                 episode reward: 0.0149,                 loss: 0.1267
Episode: 4141/30000 (13.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1839s / 35.0719 s
agent0:                 episode reward: -0.1494,                 loss: nan
agent1:                 episode reward: 0.1494,                 loss: 0.1266
Episode: 4161/30000 (13.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1841s / 35.2560 s
agent0:                 episode reward: -0.2084,                 loss: nan
agent1:                 episode reward: 0.2084,                 loss: 0.1256
Episode: 4181/30000 (13.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1790s / 35.4351 s
agent0:                 episode reward: -0.2319,                 loss: nan
agent1:                 episode reward: 0.2319,                 loss: 0.1260
Episode: 4201/30000 (14.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1951s / 35.6302 s
agent0:                 episode reward: -0.2887,                 loss: nan
agent1:                 episode reward: 0.2887,                 loss: 0.1274
Episode: 4221/30000 (14.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1965s / 35.8266 s
agent0:                 episode reward: -0.2857,                 loss: nan
agent1:                 episode reward: 0.2857,                 loss: 0.1263
Episode: 4241/30000 (14.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1763s / 36.0029 s
agent0:                 episode reward: -0.0414,                 loss: nan
agent1:                 episode reward: 0.0414,                 loss: 0.1249
Episode: 4261/30000 (14.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1795s / 36.1825 s
agent0:                 episode reward: -0.3197,                 loss: nan
agent1:                 episode reward: 0.3197,                 loss: 0.1220
Episode: 4281/30000 (14.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1824s / 36.3649 s
agent0:                 episode reward: -0.1282,                 loss: nan
agent1:                 episode reward: 0.1282,                 loss: 0.1223
Episode: 4301/30000 (14.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1856s / 36.5505 s
agent0:                 episode reward: -0.2934,                 loss: nan
agent1:                 episode reward: 0.2934,                 loss: 0.1223
Episode: 4321/30000 (14.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1849s / 36.7354 s
agent0:                 episode reward: -0.3099,                 loss: nan
agent1:                 episode reward: 0.3099,                 loss: 0.1228
Episode: 4341/30000 (14.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1837s / 36.9191 s
agent0:                 episode reward: 0.0271,                 loss: nan
agent1:                 episode reward: -0.0271,                 loss: 0.1238
Episode: 4361/30000 (14.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1862s / 37.1053 s
agent0:                 episode reward: -0.3110,                 loss: nan
agent1:                 episode reward: 0.3110,                 loss: 0.1233
Episode: 4381/30000 (14.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1850s / 37.2902 s
agent0:                 episode reward: -0.3753,                 loss: nan
agent1:                 episode reward: 0.3753,                 loss: 0.1243
Episode: 4401/30000 (14.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1820s / 37.4723 s
agent0:                 episode reward: -0.2320,                 loss: nan
agent1:                 episode reward: 0.2320,                 loss: 0.1236
Episode: 4421/30000 (14.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1857s / 37.6580 s
agent0:                 episode reward: -0.1007,                 loss: nan
agent1:                 episode reward: 0.1007,                 loss: 0.1213
Episode: 4441/30000 (14.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2063s / 37.8643 s
agent0:                 episode reward: 0.0804,                 loss: nan
agent1:                 episode reward: -0.0804,                 loss: 0.1239
Episode: 4461/30000 (14.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1849s / 38.0492 s
agent0:                 episode reward: -0.3889,                 loss: nan
agent1:                 episode reward: 0.3889,                 loss: 0.1228
Episode: 4481/30000 (14.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1815s / 38.2307 s
agent0:                 episode reward: -0.4031,                 loss: nan
agent1:                 episode reward: 0.4031,                 loss: 0.1222
Episode: 4501/30000 (15.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1843s / 38.4150 s
agent0:                 episode reward: -0.2790,                 loss: nan
agent1:                 episode reward: 0.2790,                 loss: 0.1235
Episode: 4521/30000 (15.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1851s / 38.6001 s
agent0:                 episode reward: -0.0832,                 loss: nan
agent1:                 episode reward: 0.0832,                 loss: 0.1216
Episode: 4541/30000 (15.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2165s / 38.8166 s
agent0:                 episode reward: 0.0775,                 loss: nan
agent1:                 episode reward: -0.0775,                 loss: 0.1228
Episode: 4561/30000 (15.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2044s / 39.0210 s
agent0:                 episode reward: -0.1536,                 loss: nan
agent1:                 episode reward: 0.1536,                 loss: 0.1243
Episode: 4581/30000 (15.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1932s / 39.2142 s
agent0:                 episode reward: -0.4209,                 loss: nan
agent1:                 episode reward: 0.4209,                 loss: 0.1267
Episode: 4601/30000 (15.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1862s / 39.4004 s
agent0:                 episode reward: -0.3261,                 loss: nan
agent1:                 episode reward: 0.3261,                 loss: 0.1262
Episode: 4621/30000 (15.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1749s / 39.5753 s
agent0:                 episode reward: 0.2365,                 loss: nan
agent1:                 episode reward: -0.2365,                 loss: 0.1260
Episode: 4641/30000 (15.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1778s / 39.7530 s
agent0:                 episode reward: -0.1061,                 loss: nan
agent1:                 episode reward: 0.1061,                 loss: 0.1251
Episode: 4661/30000 (15.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1783s / 39.9314 s
agent0:                 episode reward: -0.3727,                 loss: nan
agent1:                 episode reward: 0.3727,                 loss: 0.1242
Episode: 4681/30000 (15.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1787s / 40.1100 s
agent0:                 episode reward: -0.0457,                 loss: nan
agent1:                 episode reward: 0.0457,                 loss: 0.1238
Episode: 4701/30000 (15.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1803s / 40.2903 s
agent0:                 episode reward: -0.1503,                 loss: nan
agent1:                 episode reward: 0.1503,                 loss: 0.1250
Episode: 4721/30000 (15.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1796s / 40.4699 s
agent0:                 episode reward: -0.3097,                 loss: nan
agent1:                 episode reward: 0.3097,                 loss: 0.1246
Episode: 4741/30000 (15.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1779s / 40.6478 s
agent0:                 episode reward: -0.2456,                 loss: nan
agent1:                 episode reward: 0.2456,                 loss: 0.1252
Episode: 4761/30000 (15.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1778s / 40.8257 s
agent0:                 episode reward: -0.4260,                 loss: nan
agent1:                 episode reward: 0.4260,                 loss: 0.1243
Episode: 4781/30000 (15.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1781s / 41.0038 s
agent0:                 episode reward: -0.4422,                 loss: nan
agent1:                 episode reward: 0.4422,                 loss: 0.1268
Episode: 4801/30000 (16.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1831s / 41.1869 s
agent0:                 episode reward: 0.1235,                 loss: nan
agent1:                 episode reward: -0.1235,                 loss: 0.1271
Episode: 4821/30000 (16.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1833s / 41.3702 s
agent0:                 episode reward: -0.0969,                 loss: nan
agent1:                 episode reward: 0.0969,                 loss: 0.1246
Episode: 4841/30000 (16.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1855s / 41.5557 s
agent0:                 episode reward: -0.0931,                 loss: nan
agent1:                 episode reward: 0.0931,                 loss: 0.1266
Episode: 4861/30000 (16.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1954s / 41.7510 s
agent0:                 episode reward: -0.2387,                 loss: nan
agent1:                 episode reward: 0.2387,                 loss: 0.1263
Episode: 4881/30000 (16.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1993s / 41.9503 s
agent0:                 episode reward: -0.1947,                 loss: nan
agent1:                 episode reward: 0.1947,                 loss: 0.1251
Episode: 4901/30000 (16.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1864s / 42.1367 s
agent0:                 episode reward: -0.2800,                 loss: nan
agent1:                 episode reward: 0.2800,                 loss: 0.1253
Episode: 4921/30000 (16.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1869s / 42.3236 s
agent0:                 episode reward: 0.0129,                 loss: nan
agent1:                 episode reward: -0.0129,                 loss: 0.1255
Episode: 4941/30000 (16.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1896s / 42.5131 s
agent0:                 episode reward: -0.0701,                 loss: nan
agent1:                 episode reward: 0.0701,                 loss: 0.1258
Episode: 4961/30000 (16.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1988s / 42.7120 s
agent0:                 episode reward: -0.2985,                 loss: nan
agent1:                 episode reward: 0.2985,                 loss: 0.1244
Episode: 4981/30000 (16.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1868s / 42.8988 s
agent0:                 episode reward: -0.2918,                 loss: nan
agent1:                 episode reward: 0.2918,                 loss: 0.1257
Episode: 5001/30000 (16.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1905s / 43.0893 s
agent0:                 episode reward: -0.6678,                 loss: nan
agent1:                 episode reward: 0.6678,                 loss: 0.1251
Episode: 5021/30000 (16.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1863s / 43.2756 s
agent0:                 episode reward: -0.0636,                 loss: nan
agent1:                 episode reward: 0.0636,                 loss: 0.1238
Episode: 5041/30000 (16.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1892s / 43.4648 s
agent0:                 episode reward: -0.2521,                 loss: nan
agent1:                 episode reward: 0.2521,                 loss: 0.1248
Episode: 5061/30000 (16.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1883s / 43.6531 s
agent0:                 episode reward: 0.2900,                 loss: nan
agent1:                 episode reward: -0.2900,                 loss: 0.1232
Episode: 5081/30000 (16.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1972s / 43.8503 s
agent0:                 episode reward: -0.1937,                 loss: nan
agent1:                 episode reward: 0.1937,                 loss: 0.1246
Episode: 5101/30000 (17.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1917s / 44.0420 s
agent0:                 episode reward: -0.0400,                 loss: nan
agent1:                 episode reward: 0.0400,                 loss: 0.1245
Episode: 5121/30000 (17.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1916s / 44.2337 s
agent0:                 episode reward: -0.3347,                 loss: nan
agent1:                 episode reward: 0.3347,                 loss: 0.1237
Episode: 5141/30000 (17.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1922s / 44.4258 s
agent0:                 episode reward: -0.6699,                 loss: nan
agent1:                 episode reward: 0.6699,                 loss: 0.1242
Episode: 5161/30000 (17.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1895s / 44.6154 s
agent0:                 episode reward: -0.3437,                 loss: nan
agent1:                 episode reward: 0.3437,                 loss: 0.1238
Episode: 5181/30000 (17.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2085s / 44.8239 s
agent0:                 episode reward: -0.5408,                 loss: nan
agent1:                 episode reward: 0.5408,                 loss: 0.1240
Episode: 5201/30000 (17.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2137s / 45.0376 s
agent0:                 episode reward: -0.3848,                 loss: nan
agent1:                 episode reward: 0.3848,                 loss: 0.1245
Episode: 5221/30000 (17.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1889s / 45.2265 s
agent0:                 episode reward: -0.2600,                 loss: nan
agent1:                 episode reward: 0.2600,                 loss: 0.1231
Episode: 5241/30000 (17.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1856s / 45.4121 s
agent0:                 episode reward: -0.3537,                 loss: nan
agent1:                 episode reward: 0.3537,                 loss: 0.1227
Episode: 5261/30000 (17.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1849s / 45.5970 s
agent0:                 episode reward: -0.3671,                 loss: nan
agent1:                 episode reward: 0.3671,                 loss: 0.1223
Episode: 5281/30000 (17.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1822s / 45.7792 s
agent0:                 episode reward: -0.0895,                 loss: nan
agent1:                 episode reward: 0.0895,                 loss: 0.1212
Episode: 5301/30000 (17.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1809s / 45.9601 s
agent0:                 episode reward: -0.3099,                 loss: nan
agent1:                 episode reward: 0.3099,                 loss: 0.1224
Episode: 5321/30000 (17.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1880s / 46.1481 s
agent0:                 episode reward: 0.0708,                 loss: nan
agent1:                 episode reward: -0.0708,                 loss: 0.1231
Episode: 5341/30000 (17.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2025s / 46.3506 s
agent0:                 episode reward: -0.3381,                 loss: nan
agent1:                 episode reward: 0.3381,                 loss: 0.1227
Episode: 5361/30000 (17.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1868s / 46.5374 s
agent0:                 episode reward: -0.0041,                 loss: nan
agent1:                 episode reward: 0.0041,                 loss: 0.1233
Episode: 5381/30000 (17.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1830s / 46.7204 s
agent0:                 episode reward: -0.3141,                 loss: nan
agent1:                 episode reward: 0.3141,                 loss: 0.1208
Episode: 5401/30000 (18.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1888s / 46.9092 s
agent0:                 episode reward: -0.2273,                 loss: nan
agent1:                 episode reward: 0.2273,                 loss: 0.1205
Episode: 5421/30000 (18.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1886s / 47.0978 s
agent0:                 episode reward: -0.2933,                 loss: nan
agent1:                 episode reward: 0.2933,                 loss: 0.1238
Episode: 5441/30000 (18.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1850s / 47.2829 s
agent0:                 episode reward: -0.1291,                 loss: nan
agent1:                 episode reward: 0.1291,                 loss: 0.1214
Episode: 5461/30000 (18.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1848s / 47.4677 s
agent0:                 episode reward: -0.1692,                 loss: nan
agent1:                 episode reward: 0.1692,                 loss: 0.1221
Episode: 5481/30000 (18.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1901s / 47.6577 s
agent0:                 episode reward: -0.1033,                 loss: nan
agent1:                 episode reward: 0.1033,                 loss: 0.1212
Episode: 5501/30000 (18.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1981s / 47.8559 s
agent0:                 episode reward: -0.5026,                 loss: nan
agent1:                 episode reward: 0.5026,                 loss: 0.1225
Episode: 5521/30000 (18.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2618s / 48.1177 s
agent0:                 episode reward: 0.0625,                 loss: nan
agent1:                 episode reward: -0.0625,                 loss: 0.1241
Episode: 5541/30000 (18.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2012s / 48.3189 s
agent0:                 episode reward: -0.5745,                 loss: nan
agent1:                 episode reward: 0.5745,                 loss: 0.1219
Episode: 5561/30000 (18.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1960s / 48.5148 s
agent0:                 episode reward: -0.5623,                 loss: nan
agent1:                 episode reward: 0.5623,                 loss: 0.1207
Episode: 5581/30000 (18.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1969s / 48.7118 s
agent0:                 episode reward: -0.3063,                 loss: nan
agent1:                 episode reward: 0.3063,                 loss: 0.1207
Episode: 5601/30000 (18.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2023s / 48.9141 s
agent0:                 episode reward: -0.3130,                 loss: nan
agent1:                 episode reward: 0.3130,                 loss: 0.1213
Episode: 5621/30000 (18.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1959s / 49.1099 s
agent0:                 episode reward: -0.2872,                 loss: nan
agent1:                 episode reward: 0.2872,                 loss: 0.1216
Episode: 5641/30000 (18.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1981s / 49.3080 s
agent0:                 episode reward: -0.6888,                 loss: nan
agent1:                 episode reward: 0.6888,                 loss: 0.1216
Episode: 5661/30000 (18.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1927s / 49.5007 s
agent0:                 episode reward: -0.8274,                 loss: nan
agent1:                 episode reward: 0.8274,                 loss: 0.1207
Episode: 5681/30000 (18.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1927s / 49.6935 s
agent0:                 episode reward: -0.5677,                 loss: nan
agent1:                 episode reward: 0.5677,                 loss: 0.1199
Episode: 5701/30000 (19.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2016s / 49.8951 s
agent0:                 episode reward: -0.2372,                 loss: nan
agent1:                 episode reward: 0.2372,                 loss: 0.1206
Episode: 5721/30000 (19.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1982s / 50.0933 s
agent0:                 episode reward: -0.5501,                 loss: nan
agent1:                 episode reward: 0.5501,                 loss: 0.1198
Episode: 5741/30000 (19.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1976s / 50.2909 s
agent0:                 episode reward: 0.0168,                 loss: nan
agent1:                 episode reward: -0.0168,                 loss: 0.1221
Episode: 5761/30000 (19.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2001s / 50.4910 s
agent0:                 episode reward: -0.6175,                 loss: nan
agent1:                 episode reward: 0.6175,                 loss: 0.1212
Episode: 5781/30000 (19.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1973s / 50.6883 s
agent0:                 episode reward: 0.0809,                 loss: nan
agent1:                 episode reward: -0.0809,                 loss: 0.1215
Episode: 5801/30000 (19.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2159s / 50.9042 s
agent0:                 episode reward: -0.3231,                 loss: nan
agent1:                 episode reward: 0.3231,                 loss: 0.1218
Episode: 5821/30000 (19.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2248s / 51.1290 s
agent0:                 episode reward: -0.2975,                 loss: nan
agent1:                 episode reward: 0.2975,                 loss: 0.1190
Episode: 5841/30000 (19.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2062s / 51.3352 s
agent0:                 episode reward: -0.2760,                 loss: nan
agent1:                 episode reward: 0.2760,                 loss: 0.1208
Episode: 5861/30000 (19.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2016s / 51.5368 s
agent0:                 episode reward: -0.3983,                 loss: nan
agent1:                 episode reward: 0.3983,                 loss: 0.1206
Episode: 5881/30000 (19.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1989s / 51.7357 s
agent0:                 episode reward: -0.2055,                 loss: nan
agent1:                 episode reward: 0.2055,                 loss: 0.1217
Episode: 5901/30000 (19.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1983s / 51.9340 s
agent0:                 episode reward: -0.6223,                 loss: nan
agent1:                 episode reward: 0.6223,                 loss: 0.1226
Episode: 5921/30000 (19.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2019s / 52.1359 s
agent0:                 episode reward: -0.4664,                 loss: nan
agent1:                 episode reward: 0.4664,                 loss: 0.1227
Episode: 5941/30000 (19.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2007s / 52.3367 s
agent0:                 episode reward: -0.1364,                 loss: nan
agent1:                 episode reward: 0.1364,                 loss: 0.1233
Episode: 5961/30000 (19.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1997s / 52.5364 s
agent0:                 episode reward: -0.4337,                 loss: nan
agent1:                 episode reward: 0.4337,                 loss: 0.1221
Episode: 5981/30000 (19.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2046s / 52.7410 s
agent0:                 episode reward: -0.0001,                 loss: nan
agent1:                 episode reward: 0.0001,                 loss: 0.1227
Episode: 6001/30000 (20.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2083s / 52.9493 s
agent0:                 episode reward: 0.0107,                 loss: nan
agent1:                 episode reward: -0.0107,                 loss: 0.1230
Episode: 6021/30000 (20.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1984s / 53.1476 s
agent0:                 episode reward: -0.1610,                 loss: nan
agent1:                 episode reward: 0.1610,                 loss: 0.1224
Episode: 6041/30000 (20.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2027s / 53.3503 s
agent0:                 episode reward: -0.1728,                 loss: nan
agent1:                 episode reward: 0.1728,                 loss: 0.1222
Episode: 6061/30000 (20.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2021s / 53.5524 s
agent0:                 episode reward: -0.3342,                 loss: nan
agent1:                 episode reward: 0.3342,                 loss: 0.1215
Episode: 6081/30000 (20.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1977s / 53.7501 s
agent0:                 episode reward: -0.2427,                 loss: nan
agent1:                 episode reward: 0.2427,                 loss: 0.1209
Episode: 6101/30000 (20.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2394s / 53.9895 s
agent0:                 episode reward: -0.5001,                 loss: nan
agent1:                 episode reward: 0.5001,                 loss: 0.1221
Episode: 6121/30000 (20.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2278s / 54.2173 s
agent0:                 episode reward: -0.2279,                 loss: nan
agent1:                 episode reward: 0.2279,                 loss: 0.1226
Episode: 6141/30000 (20.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2036s / 54.4209 s
agent0:                 episode reward: -0.3474,                 loss: nan
agent1:                 episode reward: 0.3474,                 loss: 0.1205
Episode: 6161/30000 (20.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2208s / 54.6417 s
agent0:                 episode reward: -0.5407,                 loss: nan
agent1:                 episode reward: 0.5407,                 loss: 0.1220
Episode: 6181/30000 (20.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1990s / 54.8407 s
agent0:                 episode reward: -0.3049,                 loss: nan
agent1:                 episode reward: 0.3049,                 loss: 0.1236
Episode: 6201/30000 (20.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1964s / 55.0371 s
agent0:                 episode reward: -0.4475,                 loss: nan
agent1:                 episode reward: 0.4475,                 loss: 0.1228
Episode: 6221/30000 (20.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1929s / 55.2300 s
agent0:                 episode reward: -0.4015,                 loss: nan
agent1:                 episode reward: 0.4015,                 loss: 0.1223
Episode: 6241/30000 (20.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1989s / 55.4290 s
agent0:                 episode reward: -0.0692,                 loss: nan
agent1:                 episode reward: 0.0692,                 loss: 0.1230
Episode: 6261/30000 (20.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1931s / 55.6221 s
agent0:                 episode reward: -0.0438,                 loss: nan
agent1:                 episode reward: 0.0438,                 loss: 0.1215
Episode: 6281/30000 (20.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1934s / 55.8155 s
agent0:                 episode reward: 0.1171,                 loss: nan
agent1:                 episode reward: -0.1171,                 loss: 0.1220
Episode: 6301/30000 (21.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1956s / 56.0111 s
agent0:                 episode reward: -0.1977,                 loss: nan
agent1:                 episode reward: 0.1977,                 loss: 0.1190
Episode: 6321/30000 (21.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1961s / 56.2072 s
agent0:                 episode reward: -0.2270,                 loss: nan
agent1:                 episode reward: 0.2270,                 loss: 0.1206
Episode: 6341/30000 (21.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1977s / 56.4049 s
agent0:                 episode reward: -0.2472,                 loss: nan
agent1:                 episode reward: 0.2472,                 loss: 0.1215
Episode: 6361/30000 (21.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1972s / 56.6022 s
agent0:                 episode reward: -0.2565,                 loss: nan
agent1:                 episode reward: 0.2565,                 loss: 0.1220
Episode: 6381/30000 (21.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1957s / 56.7979 s
agent0:                 episode reward: -0.1782,                 loss: nan
agent1:                 episode reward: 0.1782,                 loss: 0.1204
Episode: 6401/30000 (21.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2143s / 57.0122 s
agent0:                 episode reward: -0.4891,                 loss: nan
agent1:                 episode reward: 0.4891,                 loss: 0.1207
Episode: 6421/30000 (21.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2331s / 57.2453 s
agent0:                 episode reward: 0.0115,                 loss: nan
agent1:                 episode reward: -0.0115,                 loss: 0.1190
Episode: 6441/30000 (21.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2067s / 57.4520 s
agent0:                 episode reward: -0.4204,                 loss: nan
agent1:                 episode reward: 0.4204,                 loss: 0.1217
Episode: 6461/30000 (21.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1945s / 57.6465 s
agent0:                 episode reward: -0.1455,                 loss: nan
agent1:                 episode reward: 0.1455,                 loss: 0.1213
Episode: 6481/30000 (21.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1988s / 57.8453 s
agent0:                 episode reward: -0.1604,                 loss: nan
agent1:                 episode reward: 0.1604,                 loss: 0.1216
Episode: 6501/30000 (21.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1997s / 58.0450 s
agent0:                 episode reward: 0.0323,                 loss: nan
agent1:                 episode reward: -0.0323,                 loss: 0.1210
Episode: 6521/30000 (21.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1976s / 58.2425 s
agent0:                 episode reward: -0.5602,                 loss: nan
agent1:                 episode reward: 0.5602,                 loss: 0.1195
Episode: 6541/30000 (21.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1977s / 58.4402 s
agent0:                 episode reward: -0.3698,                 loss: nan
agent1:                 episode reward: 0.3698,                 loss: 0.1214
Episode: 6561/30000 (21.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1986s / 58.6388 s
agent0:                 episode reward: -0.6366,                 loss: nan
agent1:                 episode reward: 0.6366,                 loss: 0.1188
Episode: 6581/30000 (21.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2103s / 58.8491 s
agent0:                 episode reward: -0.4201,                 loss: nan
agent1:                 episode reward: 0.4201,                 loss: 0.1181
Episode: 6601/30000 (22.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1994s / 59.0484 s
agent0:                 episode reward: -0.2914,                 loss: nan
agent1:                 episode reward: 0.2914,                 loss: 0.1221
Episode: 6621/30000 (22.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2004s / 59.2488 s
agent0:                 episode reward: -0.4829,                 loss: nan
agent1:                 episode reward: 0.4829,                 loss: 0.1204
Episode: 6641/30000 (22.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2091s / 59.4579 s
agent0:                 episode reward: -0.3562,                 loss: nan
agent1:                 episode reward: 0.3562,                 loss: 0.1188
Episode: 6661/30000 (22.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2036s / 59.6615 s
agent0:                 episode reward: -0.2349,                 loss: nan
agent1:                 episode reward: 0.2349,                 loss: 0.1199
Episode: 6681/30000 (22.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2055s / 59.8669 s
agent0:                 episode reward: -0.3045,                 loss: nan
agent1:                 episode reward: 0.3045,                 loss: 0.1199
Episode: 6701/30000 (22.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2132s / 60.0801 s
agent0:                 episode reward: -0.2905,                 loss: nan
agent1:                 episode reward: 0.2905,                 loss: 0.1212
Episode: 6721/30000 (22.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2253s / 60.3054 s
agent0:                 episode reward: -0.3951,                 loss: nan
agent1:                 episode reward: 0.3951,                 loss: 0.1190
Episode: 6741/30000 (22.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2056s / 60.5110 s
agent0:                 episode reward: 0.0312,                 loss: nan
agent1:                 episode reward: -0.0312,                 loss: 0.1200
Episode: 6761/30000 (22.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2042s / 60.7151 s
agent0:                 episode reward: 0.0994,                 loss: nan
agent1:                 episode reward: -0.0994,                 loss: 0.1192
Episode: 6781/30000 (22.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2047s / 60.9198 s
agent0:                 episode reward: -0.3265,                 loss: nan
agent1:                 episode reward: 0.3265,                 loss: 0.1206
Episode: 6801/30000 (22.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2029s / 61.1228 s
agent0:                 episode reward: -0.0383,                 loss: nan
agent1:                 episode reward: 0.0383,                 loss: 0.1197
Episode: 6821/30000 (22.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2024s / 61.3252 s
agent0:                 episode reward: -0.6902,                 loss: nan
agent1:                 episode reward: 0.6902,                 loss: 0.1198
Episode: 6841/30000 (22.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2242s / 61.5494 s
agent0:                 episode reward: -0.4634,                 loss: nan
agent1:                 episode reward: 0.4634,                 loss: 0.1192
Episode: 6861/30000 (22.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2085s / 61.7579 s
agent0:                 episode reward: -0.1766,                 loss: nan
agent1:                 episode reward: 0.1766,                 loss: 0.1185
Episode: 6881/30000 (22.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2126s / 61.9705 s
agent0:                 episode reward: -0.1772,                 loss: nan
agent1:                 episode reward: 0.1772,                 loss: 0.1196
Episode: 6901/30000 (23.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2126s / 62.1831 s
agent0:                 episode reward: -0.1221,                 loss: nan
agent1:                 episode reward: 0.1221,                 loss: 0.1188
Episode: 6921/30000 (23.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1961s / 62.3792 s
agent0:                 episode reward: -0.2904,                 loss: nan
agent1:                 episode reward: 0.2904,                 loss: 0.1194
Episode: 6941/30000 (23.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2038s / 62.5830 s
agent0:                 episode reward: -0.6195,                 loss: nan
agent1:                 episode reward: 0.6195,                 loss: 0.1205
Episode: 6961/30000 (23.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2094s / 62.7924 s
agent0:                 episode reward: -0.4185,                 loss: nan
agent1:                 episode reward: 0.4185,                 loss: 0.1189
Episode: 6981/30000 (23.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2407s / 63.0331 s
agent0:                 episode reward: -0.1472,                 loss: nan
agent1:                 episode reward: 0.1472,                 loss: 0.1193
Episode: 7001/30000 (23.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2290s / 63.2621 s
agent0:                 episode reward: -0.1850,                 loss: nan
agent1:                 episode reward: 0.1850,                 loss: 0.1182
Episode: 7021/30000 (23.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2089s / 63.4710 s
agent0:                 episode reward: -0.4236,                 loss: nan
agent1:                 episode reward: 0.4236,                 loss: 0.1204
Episode: 7041/30000 (23.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1955s / 63.6664 s
agent0:                 episode reward: -0.0588,                 loss: nan
agent1:                 episode reward: 0.0588,                 loss: 0.1181
Episode: 7061/30000 (23.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2023s / 63.8687 s
agent0:                 episode reward: -0.2043,                 loss: nan
agent1:                 episode reward: 0.2043,                 loss: 0.1188
Episode: 7081/30000 (23.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1980s / 64.0667 s
agent0:                 episode reward: -0.3977,                 loss: nan
agent1:                 episode reward: 0.3977,                 loss: 0.1194
Episode: 7101/30000 (23.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1991s / 64.2657 s
agent0:                 episode reward: -0.5182,                 loss: nan
agent1:                 episode reward: 0.5182,                 loss: 0.1191
Episode: 7121/30000 (23.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1984s / 64.4641 s
agent0:                 episode reward: -0.2215,                 loss: nan
agent1:                 episode reward: 0.2215,                 loss: 0.1197
Episode: 7141/30000 (23.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1975s / 64.6616 s
agent0:                 episode reward: -0.3136,                 loss: nan
agent1:                 episode reward: 0.3136,                 loss: 0.1187
Episode: 7161/30000 (23.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1978s / 64.8594 s
agent0:                 episode reward: 0.0535,                 loss: nan
agent1:                 episode reward: -0.0535,                 loss: 0.1185
Episode: 7181/30000 (23.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1997s / 65.0591 s
agent0:                 episode reward: -0.3565,                 loss: nan
agent1:                 episode reward: 0.3565,                 loss: 0.1190
Episode: 7201/30000 (24.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1928s / 65.2519 s
agent0:                 episode reward: 0.1413,                 loss: nan
agent1:                 episode reward: -0.1413,                 loss: 0.1199
Episode: 7221/30000 (24.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1954s / 65.4472 s
agent0:                 episode reward: -0.3994,                 loss: nan
agent1:                 episode reward: 0.3994,                 loss: 0.1190
Episode: 7241/30000 (24.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1981s / 65.6453 s
agent0:                 episode reward: -0.4548,                 loss: nan
agent1:                 episode reward: 0.4548,                 loss: 0.1199
Episode: 7261/30000 (24.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2014s / 65.8467 s
agent0:                 episode reward: -0.2917,                 loss: nan
agent1:                 episode reward: 0.2917,                 loss: 0.1206
Episode: 7281/30000 (24.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1965s / 66.0432 s
agent0:                 episode reward: -0.2849,                 loss: nan
agent1:                 episode reward: 0.2849,                 loss: 0.1190
Episode: 7301/30000 (24.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2157s / 66.2590 s
agent0:                 episode reward: -0.2144,                 loss: nan
agent1:                 episode reward: 0.2144,                 loss: 0.1197
Episode: 7321/30000 (24.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2252s / 66.4842 s
agent0:                 episode reward: -0.1895,                 loss: nan
agent1:                 episode reward: 0.1895,                 loss: 0.1199
Episode: 7341/30000 (24.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2135s / 66.6976 s
agent0:                 episode reward: -0.1894,                 loss: nan
agent1:                 episode reward: 0.1894,                 loss: 0.1180
Episode: 7361/30000 (24.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2055s / 66.9032 s
agent0:                 episode reward: -0.2241,                 loss: nan
agent1:                 episode reward: 0.2241,                 loss: 0.1184
Episode: 7381/30000 (24.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2094s / 67.1125 s
agent0:                 episode reward: -0.2409,                 loss: nan
agent1:                 episode reward: 0.2409,                 loss: 0.1179
Episode: 7401/30000 (24.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2280s / 67.3405 s
agent0:                 episode reward: -0.4031,                 loss: nan
agent1:                 episode reward: 0.4031,                 loss: 0.1188
Episode: 7421/30000 (24.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2023s / 67.5429 s
agent0:                 episode reward: -0.3159,                 loss: nan
agent1:                 episode reward: 0.3159,                 loss: 0.1184
Episode: 7441/30000 (24.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2071s / 67.7500 s
agent0:                 episode reward: -0.3436,                 loss: nan
agent1:                 episode reward: 0.3436,                 loss: 0.1205
Episode: 7461/30000 (24.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2093s / 67.9593 s
agent0:                 episode reward: -0.0352,                 loss: nan
agent1:                 episode reward: 0.0352,                 loss: 0.1178
Episode: 7481/30000 (24.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2071s / 68.1664 s
agent0:                 episode reward: -0.5104,                 loss: nan
agent1:                 episode reward: 0.5104,                 loss: 0.1188
Episode: 7501/30000 (25.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2101s / 68.3765 s
agent0:                 episode reward: -0.4215,                 loss: nan
agent1:                 episode reward: 0.4215,                 loss: 0.1192
Episode: 7521/30000 (25.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2085s / 68.5850 s
agent0:                 episode reward: -0.4242,                 loss: nan
agent1:                 episode reward: 0.4242,                 loss: 0.1206
Episode: 7541/30000 (25.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2066s / 68.7916 s
agent0:                 episode reward: -0.3884,                 loss: nan
agent1:                 episode reward: 0.3884,                 loss: 0.1200
Episode: 7561/30000 (25.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2181s / 69.0097 s
agent0:                 episode reward: -0.2917,                 loss: nan
agent1:                 episode reward: 0.2917,                 loss: 0.1188
Episode: 7581/30000 (25.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2240s / 69.2337 s
agent0:                 episode reward: -0.3840,                 loss: nan
agent1:                 episode reward: 0.3840,                 loss: 0.1187
Episode: 7601/30000 (25.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2270s / 69.4607 s
agent0:                 episode reward: -0.4518,                 loss: nan
agent1:                 episode reward: 0.4518,                 loss: 0.1183
Episode: 7621/30000 (25.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2107s / 69.6714 s
agent0:                 episode reward: -0.6649,                 loss: nan
agent1:                 episode reward: 0.6649,                 loss: 0.1213
Episode: 7641/30000 (25.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2078s / 69.8791 s
agent0:                 episode reward: -0.0610,                 loss: nan
agent1:                 episode reward: 0.0610,                 loss: 0.1197
Episode: 7661/30000 (25.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2144s / 70.0936 s
agent0:                 episode reward: -0.3011,                 loss: nan
agent1:                 episode reward: 0.3011,                 loss: 0.1191
Episode: 7681/30000 (25.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2094s / 70.3030 s
agent0:                 episode reward: -0.3160,                 loss: nan
agent1:                 episode reward: 0.3160,                 loss: 0.1212
Episode: 7701/30000 (25.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2059s / 70.5089 s
agent0:                 episode reward: -0.1785,                 loss: nan
agent1:                 episode reward: 0.1785,                 loss: 0.1183
Episode: 7721/30000 (25.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2046s / 70.7135 s
agent0:                 episode reward: -0.3424,                 loss: nan
agent1:                 episode reward: 0.3424,                 loss: 0.1192
Episode: 7741/30000 (25.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2007s / 70.9142 s
agent0:                 episode reward: -0.1606,                 loss: nan
agent1:                 episode reward: 0.1606,                 loss: 0.1194
Episode: 7761/30000 (25.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1981s / 71.1123 s
agent0:                 episode reward: -0.8156,                 loss: nan
agent1:                 episode reward: 0.8156,                 loss: 0.1202
Episode: 7781/30000 (25.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2263s / 71.3387 s
agent0:                 episode reward: -0.2358,                 loss: nan
agent1:                 episode reward: 0.2358,                 loss: 0.1196
Episode: 7801/30000 (26.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2105s / 71.5492 s
agent0:                 episode reward: -0.5058,                 loss: nan
agent1:                 episode reward: 0.5058,                 loss: 0.1190
Episode: 7821/30000 (26.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2048s / 71.7540 s
agent0:                 episode reward: -0.3355,                 loss: nan
agent1:                 episode reward: 0.3355,                 loss: 0.1202
Episode: 7841/30000 (26.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2035s / 71.9575 s
agent0:                 episode reward: -0.3675,                 loss: nan
agent1:                 episode reward: 0.3675,                 loss: 0.1194
Episode: 7861/30000 (26.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2032s / 72.1607 s
agent0:                 episode reward: -0.6785,                 loss: nan
agent1:                 episode reward: 0.6785,                 loss: 0.1188
Episode: 7881/30000 (26.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2215s / 72.3821 s
agent0:                 episode reward: -0.2457,                 loss: nan
agent1:                 episode reward: 0.2457,                 loss: 0.1177
Episode: 7901/30000 (26.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2218s / 72.6039 s
agent0:                 episode reward: -0.0277,                 loss: nan
agent1:                 episode reward: 0.0277,                 loss: 0.1188
Episode: 7921/30000 (26.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2069s / 72.8109 s
agent0:                 episode reward: -0.4687,                 loss: nan
agent1:                 episode reward: 0.4687,                 loss: 0.1189
Episode: 7941/30000 (26.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2197s / 73.0305 s
agent0:                 episode reward: -0.6200,                 loss: nan
agent1:                 episode reward: 0.6200,                 loss: 0.1191
Episode: 7961/30000 (26.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2110s / 73.2415 s
agent0:                 episode reward: -0.2261,                 loss: nan
agent1:                 episode reward: 0.2261,                 loss: 0.1191
Episode: 7981/30000 (26.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2093s / 73.4508 s
agent0:                 episode reward: -0.4725,                 loss: nan
agent1:                 episode reward: 0.4725,                 loss: 0.1198
Episode: 8001/30000 (26.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2122s / 73.6630 s
agent0:                 episode reward: -0.1410,                 loss: nan
agent1:                 episode reward: 0.1410,                 loss: 0.1172
Episode: 8021/30000 (26.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2133s / 73.8762 s
agent0:                 episode reward: -0.5068,                 loss: nan
agent1:                 episode reward: 0.5068,                 loss: 0.1181
Episode: 8041/30000 (26.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2178s / 74.0940 s
agent0:                 episode reward: -0.4503,                 loss: nan
agent1:                 episode reward: 0.4503,                 loss: 0.1194
Episode: 8061/30000 (26.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2240s / 74.3180 s
agent0:                 episode reward: -0.1631,                 loss: nan
agent1:                 episode reward: 0.1631,                 loss: 0.1172
Episode: 8081/30000 (26.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2304s / 74.5484 s
agent0:                 episode reward: -0.3498,                 loss: nan
agent1:                 episode reward: 0.3498,                 loss: 0.1159
Episode: 8101/30000 (27.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2439s / 74.7923 s
agent0:                 episode reward: 0.1922,                 loss: nan
agent1:                 episode reward: -0.1922,                 loss: 0.1178
Episode: 8121/30000 (27.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2226s / 75.0149 s
agent0:                 episode reward: -0.5954,                 loss: nan
agent1:                 episode reward: 0.5954,                 loss: 0.1180
Episode: 8141/30000 (27.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2192s / 75.2341 s
agent0:                 episode reward: -0.7016,                 loss: nan
agent1:                 episode reward: 0.7016,                 loss: 0.1195
Episode: 8161/30000 (27.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2657s / 75.4998 s
agent0:                 episode reward: -0.3019,                 loss: nan
agent1:                 episode reward: 0.3019,                 loss: 0.1182
Episode: 8181/30000 (27.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2437s / 75.7436 s
agent0:                 episode reward: -0.6812,                 loss: nan
agent1:                 episode reward: 0.6812,                 loss: 0.1193
Episode: 8201/30000 (27.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2084s / 75.9520 s
agent0:                 episode reward: -0.2393,                 loss: nan
agent1:                 episode reward: 0.2393,                 loss: 0.1201
Episode: 8221/30000 (27.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2088s / 76.1608 s
agent0:                 episode reward: -0.5124,                 loss: nan
agent1:                 episode reward: 0.5124,                 loss: 0.1191
Episode: 8241/30000 (27.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2168s / 76.3776 s
agent0:                 episode reward: -0.4263,                 loss: nan
agent1:                 episode reward: 0.4263,                 loss: 0.1177
Episode: 8261/30000 (27.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2162s / 76.5938 s
agent0:                 episode reward: -0.1845,                 loss: nan
agent1:                 episode reward: 0.1845,                 loss: 0.1180
Episode: 8281/30000 (27.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2136s / 76.8075 s
agent0:                 episode reward: -0.2050,                 loss: nan
agent1:                 episode reward: 0.2050,                 loss: 0.1192
Episode: 8301/30000 (27.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2036s / 77.0111 s
agent0:                 episode reward: -0.3326,                 loss: nan
agent1:                 episode reward: 0.3326,                 loss: 0.1172
Episode: 8321/30000 (27.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2073s / 77.2184 s
agent0:                 episode reward: -0.0911,                 loss: nan
agent1:                 episode reward: 0.0911,                 loss: 0.1185
Episode: 8341/30000 (27.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2083s / 77.4267 s
agent0:                 episode reward: -0.7348,                 loss: nan
agent1:                 episode reward: 0.7348,                 loss: 0.1191
Episode: 8361/30000 (27.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2077s / 77.6344 s
agent0:                 episode reward: -0.1409,                 loss: nan
agent1:                 episode reward: 0.1409,                 loss: 0.1187
Episode: 8381/30000 (27.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2086s / 77.8431 s
agent0:                 episode reward: -0.2039,                 loss: nan
agent1:                 episode reward: 0.2039,                 loss: 0.1177
Episode: 8401/30000 (28.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2132s / 78.0562 s
agent0:                 episode reward: -0.1271,                 loss: nan
agent1:                 episode reward: 0.1271,                 loss: 0.1174
Episode: 8421/30000 (28.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2109s / 78.2671 s
agent0:                 episode reward: -0.1716,                 loss: nan
agent1:                 episode reward: 0.1716,                 loss: 0.1152
Episode: 8441/30000 (28.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2258s / 78.4929 s
agent0:                 episode reward: -0.6190,                 loss: nan
agent1:                 episode reward: 0.6190,                 loss: 0.1180
Episode: 8461/30000 (28.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2407s / 78.7336 s
agent0:                 episode reward: -0.6634,                 loss: nan
agent1:                 episode reward: 0.6634,                 loss: 0.1190
Episode: 8481/30000 (28.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2630s / 78.9966 s
agent0:                 episode reward: -0.4501,                 loss: nan
agent1:                 episode reward: 0.4501,                 loss: 0.1188
Episode: 8501/30000 (28.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2164s / 79.2130 s
agent0:                 episode reward: -0.2540,                 loss: nan
agent1:                 episode reward: 0.2540,                 loss: 0.1180
Episode: 8521/30000 (28.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2154s / 79.4285 s
agent0:                 episode reward: -0.2358,                 loss: nan
agent1:                 episode reward: 0.2358,                 loss: 0.1180
Episode: 8541/30000 (28.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2346s / 79.6631 s
agent0:                 episode reward: -0.5922,                 loss: nan
agent1:                 episode reward: 0.5922,                 loss: 0.1176
Episode: 8561/30000 (28.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2072s / 79.8703 s
agent0:                 episode reward: -0.6103,                 loss: nan
agent1:                 episode reward: 0.6103,                 loss: 0.1191
Episode: 8581/30000 (28.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2069s / 80.0772 s
agent0:                 episode reward: -0.4368,                 loss: nan
agent1:                 episode reward: 0.4368,                 loss: 0.1184
Episode: 8601/30000 (28.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2139s / 80.2911 s
agent0:                 episode reward: 0.1845,                 loss: nan
agent1:                 episode reward: -0.1845,                 loss: 0.1179
Episode: 8621/30000 (28.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2150s / 80.5061 s
agent0:                 episode reward: -0.6174,                 loss: nan
agent1:                 episode reward: 0.6174,                 loss: 0.1193
Episode: 8641/30000 (28.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2155s / 80.7216 s
agent0:                 episode reward: -0.2597,                 loss: nan
agent1:                 episode reward: 0.2597,                 loss: 0.1193
Episode: 8661/30000 (28.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2154s / 80.9371 s
agent0:                 episode reward: 0.1868,                 loss: nan
agent1:                 episode reward: -0.1868,                 loss: 0.1174
Episode: 8681/30000 (28.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2170s / 81.1541 s
agent0:                 episode reward: -0.0229,                 loss: nan
agent1:                 episode reward: 0.0229,                 loss: 0.1172
Episode: 8701/30000 (29.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2162s / 81.3702 s
agent0:                 episode reward: -0.1352,                 loss: nan
agent1:                 episode reward: 0.1352,                 loss: 0.1195
Episode: 8721/30000 (29.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2309s / 81.6011 s
agent0:                 episode reward: -0.5705,                 loss: nan
agent1:                 episode reward: 0.5705,                 loss: 0.1190
Episode: 8741/30000 (29.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2322s / 81.8333 s
agent0:                 episode reward: -0.4860,                 loss: nan
agent1:                 episode reward: 0.4860,                 loss: 0.1170
Episode: 8761/30000 (29.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2151s / 82.0485 s
agent0:                 episode reward: -0.4445,                 loss: nan
agent1:                 episode reward: 0.4445,                 loss: 0.1182
Episode: 8781/30000 (29.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2155s / 82.2639 s
agent0:                 episode reward: -0.5891,                 loss: nan
agent1:                 episode reward: 0.5891,                 loss: 0.1169
Episode: 8801/30000 (29.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2237s / 82.4876 s
agent0:                 episode reward: -0.4601,                 loss: nan
agent1:                 episode reward: 0.4601,                 loss: 0.1160
Episode: 8821/30000 (29.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2254s / 82.7130 s
agent0:                 episode reward: -0.4357,                 loss: nan
agent1:                 episode reward: 0.4357,                 loss: 0.1189
Episode: 8841/30000 (29.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2223s / 82.9354 s
agent0:                 episode reward: -0.3424,                 loss: nan
agent1:                 episode reward: 0.3424,                 loss: 0.1176
Episode: 8861/30000 (29.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2051s / 83.1404 s
agent0:                 episode reward: -0.8605,                 loss: nan
agent1:                 episode reward: 0.8605,                 loss: 0.1168
Episode: 8881/30000 (29.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2096s / 83.3500 s
agent0:                 episode reward: -0.2766,                 loss: nan
agent1:                 episode reward: 0.2766,                 loss: 0.1182
Episode: 8901/30000 (29.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2119s / 83.5619 s
agent0:                 episode reward: -0.2705,                 loss: nan
agent1:                 episode reward: 0.2705,                 loss: 0.1166
Episode: 8921/30000 (29.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2204s / 83.7823 s
agent0:                 episode reward: -0.4270,                 loss: nan
agent1:                 episode reward: 0.4270,                 loss: 0.1165
Episode: 8941/30000 (29.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2248s / 84.0071 s
agent0:                 episode reward: -0.4852,                 loss: nan
agent1:                 episode reward: 0.4852,                 loss: 0.1162
Episode: 8961/30000 (29.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2215s / 84.2286 s
agent0:                 episode reward: 0.1960,                 loss: nan
agent1:                 episode reward: -0.1960,                 loss: 0.1159
Episode: 8981/30000 (29.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2161s / 84.4447 s
agent0:                 episode reward: -0.4166,                 loss: nan
agent1:                 episode reward: 0.4166,                 loss: 0.1167
Episode: 9001/30000 (30.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2426s / 84.6873 s
agent0:                 episode reward: -0.5010,                 loss: nan
agent1:                 episode reward: 0.5010,                 loss: 0.1157
Episode: 9021/30000 (30.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2292s / 84.9165 s
agent0:                 episode reward: -0.4203,                 loss: nan
agent1:                 episode reward: 0.4203,                 loss: 0.1175
Episode: 9041/30000 (30.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2184s / 85.1349 s
agent0:                 episode reward: -0.6467,                 loss: nan
agent1:                 episode reward: 0.6467,                 loss: 0.1166
Episode: 9061/30000 (30.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2134s / 85.3483 s
agent0:                 episode reward: -0.3529,                 loss: nan
agent1:                 episode reward: 0.3529,                 loss: 0.1169
Episode: 9081/30000 (30.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2137s / 85.5620 s
agent0:                 episode reward: -0.5080,                 loss: nan
agent1:                 episode reward: 0.5080,                 loss: 0.1160
Episode: 9101/30000 (30.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2190s / 85.7809 s
agent0:                 episode reward: -0.3270,                 loss: nan
agent1:                 episode reward: 0.3270,                 loss: 0.1156
Episode: 9121/30000 (30.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2184s / 85.9993 s
agent0:                 episode reward: -0.0888,                 loss: nan
agent1:                 episode reward: 0.0888,                 loss: 0.1162
Episode: 9141/30000 (30.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2167s / 86.2160 s
agent0:                 episode reward: -0.3771,                 loss: nan
agent1:                 episode reward: 0.3771,                 loss: 0.1156
Episode: 9161/30000 (30.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2176s / 86.4336 s
agent0:                 episode reward: -0.0057,                 loss: nan
agent1:                 episode reward: 0.0057,                 loss: 0.1164
Episode: 9181/30000 (30.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2156s / 86.6492 s
agent0:                 episode reward: -0.2793,                 loss: nan
agent1:                 episode reward: 0.2793,                 loss: 0.1153
Episode: 9201/30000 (30.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2205s / 86.8697 s
agent0:                 episode reward: -0.2203,                 loss: nan
agent1:                 episode reward: 0.2203,                 loss: 0.1158
Episode: 9221/30000 (30.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2211s / 87.0908 s
agent0:                 episode reward: -0.1885,                 loss: nan
agent1:                 episode reward: 0.1885,                 loss: 0.1166
Episode: 9241/30000 (30.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2221s / 87.3129 s
agent0:                 episode reward: -0.2374,                 loss: nan
agent1:                 episode reward: 0.2374,                 loss: 0.1141
Episode: 9261/30000 (30.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2217s / 87.5347 s
agent0:                 episode reward: -0.5900,                 loss: nan
agent1:                 episode reward: 0.5900,                 loss: 0.1164
Episode: 9281/30000 (30.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2356s / 87.7703 s
agent0:                 episode reward: -0.2118,                 loss: nan
agent1:                 episode reward: 0.2118,                 loss: 0.1153
Episode: 9301/30000 (31.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2432s / 88.0136 s
agent0:                 episode reward: -0.6073,                 loss: nan
agent1:                 episode reward: 0.6073,                 loss: 0.1164
Episode: 9321/30000 (31.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2222s / 88.2357 s
agent0:                 episode reward: -0.2410,                 loss: nan
agent1:                 episode reward: 0.2410,                 loss: 0.1148
Episode: 9341/30000 (31.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2220s / 88.4577 s
agent0:                 episode reward: -0.4474,                 loss: nan
agent1:                 episode reward: 0.4474,                 loss: 0.1158
Episode: 9361/30000 (31.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2196s / 88.6773 s
agent0:                 episode reward: -0.5546,                 loss: nan
agent1:                 episode reward: 0.5546,                 loss: 0.1170
Episode: 9381/30000 (31.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2217s / 88.8990 s
agent0:                 episode reward: -0.1194,                 loss: nan
agent1:                 episode reward: 0.1194,                 loss: 0.1145
Episode: 9401/30000 (31.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2159s / 89.1149 s
agent0:                 episode reward: -0.3150,                 loss: nan
agent1:                 episode reward: 0.3150,                 loss: 0.1153
Episode: 9421/30000 (31.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2104s / 89.3253 s
agent0:                 episode reward: -0.5146,                 loss: nan
agent1:                 episode reward: 0.5146,                 loss: 0.1156
Episode: 9441/30000 (31.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2072s / 89.5326 s
agent0:                 episode reward: -0.4393,                 loss: nan
agent1:                 episode reward: 0.4393,                 loss: 0.1155
Episode: 9461/30000 (31.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2064s / 89.7389 s
agent0:                 episode reward: -0.3783,                 loss: nan
agent1:                 episode reward: 0.3783,                 loss: 0.1148
Episode: 9481/30000 (31.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2074s / 89.9463 s
agent0:                 episode reward: -0.5452,                 loss: nan
agent1:                 episode reward: 0.5452,                 loss: 0.1162
Episode: 9501/30000 (31.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2069s / 90.1532 s
agent0:                 episode reward: -0.1557,                 loss: nan
agent1:                 episode reward: 0.1557,                 loss: 0.1147
Episode: 9521/30000 (31.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2315s / 90.3847 s
agent0:                 episode reward: -0.4992,                 loss: nan
agent1:                 episode reward: 0.4992,                 loss: 0.1154
Episode: 9541/30000 (31.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2306s / 90.6154 s
agent0:                 episode reward: -0.3377,                 loss: nan
agent1:                 episode reward: 0.3377,                 loss: 0.1160
Episode: 9561/30000 (31.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2506s / 90.8660 s
agent0:                 episode reward: -0.1443,                 loss: nan
agent1:                 episode reward: 0.1443,                 loss: 0.1160
Episode: 9581/30000 (31.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2211s / 91.0872 s
agent0:                 episode reward: -0.2140,                 loss: nan
agent1:                 episode reward: 0.2140,                 loss: 0.1166
Episode: 9601/30000 (32.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2158s / 91.3030 s
agent0:                 episode reward: 0.1800,                 loss: nan
agent1:                 episode reward: -0.1800,                 loss: 0.1158
Episode: 9621/30000 (32.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2159s / 91.5189 s
agent0:                 episode reward: -0.0793,                 loss: nan
agent1:                 episode reward: 0.0793,                 loss: 0.1158
Episode: 9641/30000 (32.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2161s / 91.7350 s
agent0:                 episode reward: -0.4056,                 loss: nan
agent1:                 episode reward: 0.4056,                 loss: 0.1168
Episode: 9661/30000 (32.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2165s / 91.9515 s
agent0:                 episode reward: -0.4061,                 loss: nan
agent1:                 episode reward: 0.4061,                 loss: 0.1159
Episode: 9681/30000 (32.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2177s / 92.1692 s
agent0:                 episode reward: -0.4788,                 loss: nan
agent1:                 episode reward: 0.4788,                 loss: 0.1157
Episode: 9701/30000 (32.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2223s / 92.3914 s
agent0:                 episode reward: -0.6380,                 loss: nan
agent1:                 episode reward: 0.6380,                 loss: 0.1163
Episode: 9721/30000 (32.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2234s / 92.6149 s
agent0:                 episode reward: -0.0530,                 loss: nan
agent1:                 episode reward: 0.0530,                 loss: 0.1162
Episode: 9741/30000 (32.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2211s / 92.8360 s
agent0:                 episode reward: -0.3310,                 loss: nan
agent1:                 episode reward: 0.3310,                 loss: 0.1141
Episode: 9761/30000 (32.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2304s / 93.0664 s
agent0:                 episode reward: -0.2268,                 loss: nan
agent1:                 episode reward: 0.2268,                 loss: 0.1151
Episode: 9781/30000 (32.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2186s / 93.2850 s
agent0:                 episode reward: -0.6913,                 loss: nan
agent1:                 episode reward: 0.6913,                 loss: 0.1161
Episode: 9801/30000 (32.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2185s / 93.5035 s
agent0:                 episode reward: -0.2602,                 loss: nan
agent1:                 episode reward: 0.2602,                 loss: 0.1168
Episode: 9821/30000 (32.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2262s / 93.7298 s
agent0:                 episode reward: -0.3792,                 loss: nan
agent1:                 episode reward: 0.3792,                 loss: 0.1156
Episode: 9841/30000 (32.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2616s / 93.9913 s
agent0:                 episode reward: -0.4809,                 loss: nan
agent1:                 episode reward: 0.4809,                 loss: 0.1147
Episode: 9861/30000 (32.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2283s / 94.2197 s
agent0:                 episode reward: 0.1772,                 loss: nan
agent1:                 episode reward: -0.1772,                 loss: 0.1169
Episode: 9881/30000 (32.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2195s / 94.4391 s
agent0:                 episode reward: -0.5925,                 loss: nan
agent1:                 episode reward: 0.5925,                 loss: 0.1178
Episode: 9901/30000 (33.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2212s / 94.6604 s
agent0:                 episode reward: -0.5020,                 loss: nan
agent1:                 episode reward: 0.5020,                 loss: 0.1169
Episode: 9921/30000 (33.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2239s / 94.8843 s
agent0:                 episode reward: -0.7987,                 loss: nan
agent1:                 episode reward: 0.7987,                 loss: 0.1169
Episode: 9941/30000 (33.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2216s / 95.1058 s
agent0:                 episode reward: -0.5372,                 loss: nan
agent1:                 episode reward: 0.5372,                 loss: 0.1172
Episode: 9961/30000 (33.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2238s / 95.3296 s
agent0:                 episode reward: -0.5138,                 loss: nan
agent1:                 episode reward: 0.5138,                 loss: 0.1168
Episode: 9981/30000 (33.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2187s / 95.5484 s
agent0:                 episode reward: -0.3659,                 loss: nan
agent1:                 episode reward: 0.3659,                 loss: 0.1182
Episode: 10001/30000 (33.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2203s / 95.7687 s
agent0:                 episode reward: -0.5421,                 loss: nan
agent1:                 episode reward: 0.5421,                 loss: 0.1180
Episode: 10021/30000 (33.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2221s / 95.9908 s
agent0:                 episode reward: -0.4163,                 loss: nan
agent1:                 episode reward: 0.4163,                 loss: 0.1173
Episode: 10041/30000 (33.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2401s / 96.2308 s
agent0:                 episode reward: -0.2748,                 loss: nan
agent1:                 episode reward: 0.2748,                 loss: 0.1160
Episode: 10061/30000 (33.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2243s / 96.4551 s
agent0:                 episode reward: -0.3953,                 loss: nan
agent1:                 episode reward: 0.3953,                 loss: 0.1163
Episode: 10081/30000 (33.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2208s / 96.6759 s
agent0:                 episode reward: -0.0604,                 loss: nan
agent1:                 episode reward: 0.0604,                 loss: 0.1154
Episode: 10101/30000 (33.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2634s / 96.9393 s
agent0:                 episode reward: -0.2322,                 loss: nan
agent1:                 episode reward: 0.2322,                 loss: 0.1167
Episode: 10121/30000 (33.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2281s / 97.1674 s
agent0:                 episode reward: -0.2454,                 loss: nan
agent1:                 episode reward: 0.2454,                 loss: 0.1155
Episode: 10141/30000 (33.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2160s / 97.3834 s
agent0:                 episode reward: -0.3297,                 loss: nan
agent1:                 episode reward: 0.3297,                 loss: 0.1176
Episode: 10161/30000 (33.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2143s / 97.5977 s
agent0:                 episode reward: -0.2212,                 loss: nan
agent1:                 episode reward: 0.2212,                 loss: 0.1182
Episode: 10181/30000 (33.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2209s / 97.8186 s
agent0:                 episode reward: -0.2300,                 loss: nan
agent1:                 episode reward: 0.2300,                 loss: 0.1167
Episode: 10201/30000 (34.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2227s / 98.0413 s
agent0:                 episode reward: -0.4891,                 loss: nan
agent1:                 episode reward: 0.4891,                 loss: 0.1161
Episode: 10221/30000 (34.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2240s / 98.2652 s
agent0:                 episode reward: -0.2735,                 loss: nan
agent1:                 episode reward: 0.2735,                 loss: 0.1155
Episode: 10241/30000 (34.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2230s / 98.4882 s
agent0:                 episode reward: -0.4433,                 loss: nan
agent1:                 episode reward: 0.4433,                 loss: 0.1168
Episode: 10261/30000 (34.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2179s / 98.7061 s
agent0:                 episode reward: -0.3245,                 loss: nan
agent1:                 episode reward: 0.3245,                 loss: 0.1155
Episode: 10281/30000 (34.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2281s / 98.9342 s
agent0:                 episode reward: -0.1681,                 loss: nan
agent1:                 episode reward: 0.1681,                 loss: 0.1167
Episode: 10301/30000 (34.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2357s / 99.1699 s
agent0:                 episode reward: -0.6167,                 loss: nan
agent1:                 episode reward: 0.6167,                 loss: 0.1166
Episode: 10321/30000 (34.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2202s / 99.3901 s
agent0:                 episode reward: -0.0671,                 loss: nan
agent1:                 episode reward: 0.0671,                 loss: 0.1180
Episode: 10341/30000 (34.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2254s / 99.6155 s
agent0:                 episode reward: -0.7993,                 loss: nan
agent1:                 episode reward: 0.7993,                 loss: 0.1165
Episode: 10361/30000 (34.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2298s / 99.8454 s
agent0:                 episode reward: -0.3654,                 loss: nan
agent1:                 episode reward: 0.3654,                 loss: 0.1160
Episode: 10381/30000 (34.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2508s / 100.0961 s
agent0:                 episode reward: -0.1366,                 loss: nan
agent1:                 episode reward: 0.1366,                 loss: 0.1163
Episode: 10401/30000 (34.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2240s / 100.3202 s
agent0:                 episode reward: -0.2026,                 loss: nan
agent1:                 episode reward: 0.2026,                 loss: 0.1165
Episode: 10421/30000 (34.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2210s / 100.5411 s
agent0:                 episode reward: -0.5034,                 loss: nan
agent1:                 episode reward: 0.5034,                 loss: 0.1153
Episode: 10441/30000 (34.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2190s / 100.7601 s
agent0:                 episode reward: -0.3209,                 loss: nan
agent1:                 episode reward: 0.3209,                 loss: 0.1157
Episode: 10461/30000 (34.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2213s / 100.9814 s
agent0:                 episode reward: -0.0711,                 loss: nan
agent1:                 episode reward: 0.0711,                 loss: 0.1161
Episode: 10481/30000 (34.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2237s / 101.2051 s
agent0:                 episode reward: -0.2043,                 loss: nan
agent1:                 episode reward: 0.2043,                 loss: 0.1164
Episode: 10501/30000 (35.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2234s / 101.4285 s
agent0:                 episode reward: -0.3550,                 loss: nan
agent1:                 episode reward: 0.3550,                 loss: 0.1162
Episode: 10521/30000 (35.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2207s / 101.6492 s
agent0:                 episode reward: -0.4317,                 loss: nan
agent1:                 episode reward: 0.4317,                 loss: 0.1144
Episode: 10541/30000 (35.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2205s / 101.8696 s
agent0:                 episode reward: -0.4136,                 loss: nan
agent1:                 episode reward: 0.4136,                 loss: 0.1153
Episode: 10561/30000 (35.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2265s / 102.0961 s
agent0:                 episode reward: -0.5537,                 loss: nan
agent1:                 episode reward: 0.5537,                 loss: 0.1149
Episode: 10581/30000 (35.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2257s / 102.3218 s
agent0:                 episode reward: -0.4703,                 loss: nan
agent1:                 episode reward: 0.4703,                 loss: 0.1165
Episode: 10601/30000 (35.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2392s / 102.5610 s
agent0:                 episode reward: -0.5466,                 loss: nan
agent1:                 episode reward: 0.5466,                 loss: 0.1159
Episode: 10621/30000 (35.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2321s / 102.7931 s
agent0:                 episode reward: -0.5832,                 loss: nan
agent1:                 episode reward: 0.5832,                 loss: 0.1154
Episode: 10641/30000 (35.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2505s / 103.0436 s
agent0:                 episode reward: -0.7392,                 loss: nan
agent1:                 episode reward: 0.7392,                 loss: 0.1143
Episode: 10661/30000 (35.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2541s / 103.2977 s
agent0:                 episode reward: -0.5030,                 loss: nan
agent1:                 episode reward: 0.5030,                 loss: 0.1150
Episode: 10681/30000 (35.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2281s / 103.5258 s
agent0:                 episode reward: -0.6280,                 loss: nan
agent1:                 episode reward: 0.6280,                 loss: 0.1155
Episode: 10701/30000 (35.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2258s / 103.7516 s
agent0:                 episode reward: -0.6703,                 loss: nan
agent1:                 episode reward: 0.6703,                 loss: 0.1146
Episode: 10721/30000 (35.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2370s / 103.9886 s
agent0:                 episode reward: -0.4620,                 loss: nan
agent1:                 episode reward: 0.4620,                 loss: 0.1155
Episode: 10741/30000 (35.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2280s / 104.2166 s
agent0:                 episode reward: -0.6993,                 loss: nan
agent1:                 episode reward: 0.6993,                 loss: 0.1144
Episode: 10761/30000 (35.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2283s / 104.4449 s
agent0:                 episode reward: -0.2019,                 loss: nan
agent1:                 episode reward: 0.2019,                 loss: 0.1146
Episode: 10781/30000 (35.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2530s / 104.6979 s
agent0:                 episode reward: -0.4416,                 loss: nan
agent1:                 episode reward: 0.4416,                 loss: 0.1150
Episode: 10801/30000 (36.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2255s / 104.9234 s
agent0:                 episode reward: -0.2392,                 loss: nan
agent1:                 episode reward: 0.2392,                 loss: 0.1138
Episode: 10821/30000 (36.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2242s / 105.1476 s
agent0:                 episode reward: -0.5328,                 loss: nan
agent1:                 episode reward: 0.5328,                 loss: 0.1156
Episode: 10841/30000 (36.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2435s / 105.3911 s
agent0:                 episode reward: -0.0370,                 loss: nan
agent1:                 episode reward: 0.0370,                 loss: 0.1157
Episode: 10861/30000 (36.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2429s / 105.6340 s
agent0:                 episode reward: -0.4621,                 loss: nan
agent1:                 episode reward: 0.4621,                 loss: 0.1158
Episode: 10881/30000 (36.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2196s / 105.8535 s
agent0:                 episode reward: -0.4347,                 loss: nan
agent1:                 episode reward: 0.4347,                 loss: 0.1145
Episode: 10901/30000 (36.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2618s / 106.1153 s
agent0:                 episode reward: -0.3753,                 loss: nan
agent1:                 episode reward: 0.3753,                 loss: 0.1160
Episode: 10921/30000 (36.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2395s / 106.3548 s
agent0:                 episode reward: -0.7059,                 loss: nan
agent1:                 episode reward: 0.7059,                 loss: 0.1152
Episode: 10941/30000 (36.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2260s / 106.5808 s
agent0:                 episode reward: -0.3121,                 loss: nan
agent1:                 episode reward: 0.3121,                 loss: 0.1154
Episode: 10961/30000 (36.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2215s / 106.8023 s
agent0:                 episode reward: -0.3091,                 loss: nan
agent1:                 episode reward: 0.3091,                 loss: 0.1152
Episode: 10981/30000 (36.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2192s / 107.0215 s
agent0:                 episode reward: -0.6082,                 loss: nan
agent1:                 episode reward: 0.6082,                 loss: 0.1142
Episode: 11001/30000 (36.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2176s / 107.2392 s
agent0:                 episode reward: -0.3813,                 loss: nan
agent1:                 episode reward: 0.3813,                 loss: 0.1146
Episode: 11021/30000 (36.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2264s / 107.4656 s
agent0:                 episode reward: -0.5234,                 loss: nan
agent1:                 episode reward: 0.5234,                 loss: 0.1157
Episode: 11041/30000 (36.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2314s / 107.6970 s
agent0:                 episode reward: -0.6144,                 loss: nan
agent1:                 episode reward: 0.6144,                 loss: 0.1147
Episode: 11061/30000 (36.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2314s / 107.9284 s
agent0:                 episode reward: -0.3161,                 loss: nan
agent1:                 episode reward: 0.3161,                 loss: 0.1152
Episode: 11081/30000 (36.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2255s / 108.1539 s
agent0:                 episode reward: -0.2321,                 loss: nan
agent1:                 episode reward: 0.2321,                 loss: 0.1158
Episode: 11101/30000 (37.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2293s / 108.3832 s
agent0:                 episode reward: -0.1476,                 loss: nan
agent1:                 episode reward: 0.1476,                 loss: 0.1157
Episode: 11121/30000 (37.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2302s / 108.6134 s
agent0:                 episode reward: -0.3977,                 loss: nan
agent1:                 episode reward: 0.3977,                 loss: 0.1160
Episode: 11141/30000 (37.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2512s / 108.8646 s
agent0:                 episode reward: -0.3026,                 loss: nan
agent1:                 episode reward: 0.3026,                 loss: 0.1171
Episode: 11161/30000 (37.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2640s / 109.1286 s
agent0:                 episode reward: -0.7675,                 loss: nan
agent1:                 episode reward: 0.7675,                 loss: 0.1151
Episode: 11181/30000 (37.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2726s / 109.4012 s
agent0:                 episode reward: -0.3835,                 loss: nan
agent1:                 episode reward: 0.3835,                 loss: 0.1157
Episode: 11201/30000 (37.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2400s / 109.6412 s
agent0:                 episode reward: -0.2098,                 loss: nan
agent1:                 episode reward: 0.2098,                 loss: 0.1139
Episode: 11221/30000 (37.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2380s / 109.8792 s
agent0:                 episode reward: -0.4982,                 loss: nan
agent1:                 episode reward: 0.4982,                 loss: 0.1151
Episode: 11241/30000 (37.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2329s / 110.1121 s
agent0:                 episode reward: -0.4168,                 loss: nan
agent1:                 episode reward: 0.4168,                 loss: 0.1137
Episode: 11261/30000 (37.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2269s / 110.3390 s
agent0:                 episode reward: -0.5605,                 loss: nan
agent1:                 episode reward: 0.5605,                 loss: 0.1134
Episode: 11281/30000 (37.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2272s / 110.5662 s
agent0:                 episode reward: -0.3004,                 loss: nan
agent1:                 episode reward: 0.3004,                 loss: 0.1141
Episode: 11301/30000 (37.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2253s / 110.7916 s
agent0:                 episode reward: -0.5633,                 loss: nan
agent1:                 episode reward: 0.5633,                 loss: 0.1149
Episode: 11321/30000 (37.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2343s / 111.0259 s
agent0:                 episode reward: -0.3966,                 loss: nan
agent1:                 episode reward: 0.3966,                 loss: 0.1156
Episode: 11341/30000 (37.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2282s / 111.2541 s
agent0:                 episode reward: -0.2955,                 loss: nan
agent1:                 episode reward: 0.2955,                 loss: 0.1146
Episode: 11361/30000 (37.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2350s / 111.4891 s
agent0:                 episode reward: -0.4809,                 loss: nan
agent1:                 episode reward: 0.4809,                 loss: 0.1141
Episode: 11381/30000 (37.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2289s / 111.7180 s
agent0:                 episode reward: -0.5075,                 loss: nan
agent1:                 episode reward: 0.5075,                 loss: 0.1140
Episode: 11401/30000 (38.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2345s / 111.9524 s
agent0:                 episode reward: -0.4643,                 loss: nan
agent1:                 episode reward: 0.4643,                 loss: 0.1125
Episode: 11421/30000 (38.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2487s / 112.2012 s
agent0:                 episode reward: -0.6805,                 loss: nan
agent1:                 episode reward: 0.6805,                 loss: 0.1135
Episode: 11441/30000 (38.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2569s / 112.4581 s
agent0:                 episode reward: -0.4302,                 loss: nan
agent1:                 episode reward: 0.4302,                 loss: 0.1151
Episode: 11461/30000 (38.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2361s / 112.6942 s
agent0:                 episode reward: -0.4417,                 loss: nan
agent1:                 episode reward: 0.4417,                 loss: 0.1134
Episode: 11481/30000 (38.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2502s / 112.9444 s
agent0:                 episode reward: -0.7201,                 loss: nan
agent1:                 episode reward: 0.7201,                 loss: 0.1149
Episode: 11501/30000 (38.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2369s / 113.1813 s
agent0:                 episode reward: -0.6040,                 loss: nan
agent1:                 episode reward: 0.6040,                 loss: 0.1116
Episode: 11521/30000 (38.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2288s / 113.4102 s
agent0:                 episode reward: -0.1677,                 loss: nan
agent1:                 episode reward: 0.1677,                 loss: 0.1143
Episode: 11541/30000 (38.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2283s / 113.6385 s
agent0:                 episode reward: -0.3954,                 loss: nan
agent1:                 episode reward: 0.3954,                 loss: 0.1149
Episode: 11561/30000 (38.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2315s / 113.8700 s
agent0:                 episode reward: -0.5546,                 loss: nan
agent1:                 episode reward: 0.5546,                 loss: 0.1134
Episode: 11581/30000 (38.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2355s / 114.1055 s
agent0:                 episode reward: -0.8087,                 loss: nan
agent1:                 episode reward: 0.8087,                 loss: 0.1130
Episode: 11601/30000 (38.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2307s / 114.3363 s
agent0:                 episode reward: -0.5861,                 loss: nan
agent1:                 episode reward: 0.5861,                 loss: 0.1120
Episode: 11621/30000 (38.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2323s / 114.5686 s
agent0:                 episode reward: -0.6258,                 loss: nan
agent1:                 episode reward: 0.6258,                 loss: 0.1131
Episode: 11641/30000 (38.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2255s / 114.7941 s
agent0:                 episode reward: -0.5578,                 loss: nan
agent1:                 episode reward: 0.5578,                 loss: 0.1117
Episode: 11661/30000 (38.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2304s / 115.0245 s
agent0:                 episode reward: -0.6539,                 loss: nan
agent1:                 episode reward: 0.6539,                 loss: 0.1140
Episode: 11681/30000 (38.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2446s / 115.2692 s
agent0:                 episode reward: -0.3887,                 loss: nan
agent1:                 episode reward: 0.3887,                 loss: 0.1129
Episode: 11701/30000 (39.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2435s / 115.5127 s
agent0:                 episode reward: -0.5000,                 loss: nan
agent1:                 episode reward: 0.5000,                 loss: 0.1123
Episode: 11721/30000 (39.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2333s / 115.7460 s
agent0:                 episode reward: -0.1913,                 loss: nan
agent1:                 episode reward: 0.1913,                 loss: 0.1131
Episode: 11741/30000 (39.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2261s / 115.9721 s
agent0:                 episode reward: -0.3093,                 loss: nan
agent1:                 episode reward: 0.3093,                 loss: 0.1113
Episode: 11761/30000 (39.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2295s / 116.2016 s
agent0:                 episode reward: -0.4419,                 loss: nan
agent1:                 episode reward: 0.4419,                 loss: 0.1122
Episode: 11781/30000 (39.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2337s / 116.4353 s
agent0:                 episode reward: -0.4612,                 loss: nan
agent1:                 episode reward: 0.4612,                 loss: 0.1122
Episode: 11801/30000 (39.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2391s / 116.6744 s
agent0:                 episode reward: -0.5826,                 loss: nan
agent1:                 episode reward: 0.5826,                 loss: 0.1119
Episode: 11821/30000 (39.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2355s / 116.9099 s
agent0:                 episode reward: -0.7659,                 loss: nan
agent1:                 episode reward: 0.7659,                 loss: 0.1127
Episode: 11841/30000 (39.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2847s / 117.1946 s
agent0:                 episode reward: -0.7712,                 loss: nan
agent1:                 episode reward: 0.7712,                 loss: 0.1124
Episode: 11861/30000 (39.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2393s / 117.4339 s
agent0:                 episode reward: -0.5691,                 loss: nan
agent1:                 episode reward: 0.5691,                 loss: 0.1132
Episode: 11881/30000 (39.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2373s / 117.6712 s
agent0:                 episode reward: -0.4279,                 loss: nan
agent1:                 episode reward: 0.4279,                 loss: 0.1136
Episode: 11901/30000 (39.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2361s / 117.9073 s
agent0:                 episode reward: -0.3769,                 loss: nan
agent1:                 episode reward: 0.3769,                 loss: 0.1144
Episode: 11921/30000 (39.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2452s / 118.1525 s
agent0:                 episode reward: -0.8535,                 loss: nan
agent1:                 episode reward: 0.8535,                 loss: 0.1116
Episode: 11941/30000 (39.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2523s / 118.4048 s
agent0:                 episode reward: -0.5999,                 loss: nan
agent1:                 episode reward: 0.5999,                 loss: 0.1123
Episode: 11961/30000 (39.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2405s / 118.6453 s
agent0:                 episode reward: -0.6365,                 loss: nan
agent1:                 episode reward: 0.6365,                 loss: 0.1130
Episode: 11981/30000 (39.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2334s / 118.8787 s
agent0:                 episode reward: -0.5440,                 loss: nan
agent1:                 episode reward: 0.5440,                 loss: 0.1126
Episode: 12001/30000 (40.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2408s / 119.1195 s
agent0:                 episode reward: -0.4158,                 loss: nan
agent1:                 episode reward: 0.4158,                 loss: 0.1131
Episode: 12021/30000 (40.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2359s / 119.3554 s
agent0:                 episode reward: -0.3810,                 loss: nan
agent1:                 episode reward: 0.3810,                 loss: 0.1125
Episode: 12041/30000 (40.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2375s / 119.5929 s
agent0:                 episode reward: -0.4204,                 loss: nan
agent1:                 episode reward: 0.4204,                 loss: 0.1146
Episode: 12061/30000 (40.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2362s / 119.8291 s
agent0:                 episode reward: -0.6731,                 loss: nan
agent1:                 episode reward: 0.6731,                 loss: 0.1128
Episode: 12081/30000 (40.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2429s / 120.0720 s
agent0:                 episode reward: -0.3657,                 loss: nan
agent1:                 episode reward: 0.3657,                 loss: 0.1119
Episode: 12101/30000 (40.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2371s / 120.3091 s
agent0:                 episode reward: -0.5164,                 loss: nan
agent1:                 episode reward: 0.5164,                 loss: 0.1116
Episode: 12121/30000 (40.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2385s / 120.5476 s
agent0:                 episode reward: -0.7548,                 loss: nan
agent1:                 episode reward: 0.7548,                 loss: 0.1139
Episode: 12141/30000 (40.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2348s / 120.7824 s
agent0:                 episode reward: -0.5913,                 loss: nan
agent1:                 episode reward: 0.5913,                 loss: 0.1128
Episode: 12161/30000 (40.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2416s / 121.0240 s
agent0:                 episode reward: -0.3374,                 loss: nan
agent1:                 episode reward: 0.3374,                 loss: 0.1125
Episode: 12181/30000 (40.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2641s / 121.2881 s
agent0:                 episode reward: -0.5006,                 loss: nan
agent1:                 episode reward: 0.5006,                 loss: 0.1127
Episode: 12201/30000 (40.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2713s / 121.5594 s
agent0:                 episode reward: -0.3789,                 loss: nan
agent1:                 episode reward: 0.3789,                 loss: 0.1123
Episode: 12221/30000 (40.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2455s / 121.8049 s
agent0:                 episode reward: -0.5568,                 loss: nan
agent1:                 episode reward: 0.5568,                 loss: 0.1123
Episode: 12241/30000 (40.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2383s / 122.0432 s
agent0:                 episode reward: -0.4140,                 loss: nan
agent1:                 episode reward: 0.4140,                 loss: 0.1126
Episode: 12261/30000 (40.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2383s / 122.2815 s
agent0:                 episode reward: -0.4436,                 loss: nan
agent1:                 episode reward: 0.4436,                 loss: 0.1138
Episode: 12281/30000 (40.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2410s / 122.5225 s
agent0:                 episode reward: -0.4915,                 loss: nan
agent1:                 episode reward: 0.4915,                 loss: 0.1122
Episode: 12301/30000 (41.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2430s / 122.7654 s
agent0:                 episode reward: -0.5505,                 loss: nan
agent1:                 episode reward: 0.5505,                 loss: 0.1133
Episode: 12321/30000 (41.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2386s / 123.0040 s
agent0:                 episode reward: -0.6170,                 loss: nan
agent1:                 episode reward: 0.6170,                 loss: 0.1119
Episode: 12341/30000 (41.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2398s / 123.2439 s
agent0:                 episode reward: -0.5734,                 loss: nan
agent1:                 episode reward: 0.5734,                 loss: 0.1135
Episode: 12361/30000 (41.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2413s / 123.4852 s
agent0:                 episode reward: -0.2773,                 loss: nan
agent1:                 episode reward: 0.2773,                 loss: 0.1134
Episode: 12381/30000 (41.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2407s / 123.7259 s
agent0:                 episode reward: -0.3976,                 loss: nan
agent1:                 episode reward: 0.3976,                 loss: 0.1125
Episode: 12401/30000 (41.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2420s / 123.9679 s
agent0:                 episode reward: -0.3646,                 loss: nan
agent1:                 episode reward: 0.3646,                 loss: 0.1116
Episode: 12421/30000 (41.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2393s / 124.2072 s
agent0:                 episode reward: -0.4287,                 loss: nan
agent1:                 episode reward: 0.4287,                 loss: 0.1129
Episode: 12441/30000 (41.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2618s / 124.4690 s
agent0:                 episode reward: -0.3965,                 loss: nan
agent1:                 episode reward: 0.3965,                 loss: 0.1130
Episode: 12461/30000 (41.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2495s / 124.7185 s
agent0:                 episode reward: -0.5256,                 loss: nan
agent1:                 episode reward: 0.5256,                 loss: 0.1129
Episode: 12481/30000 (41.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2293s / 124.9478 s
agent0:                 episode reward: -0.6834,                 loss: nan
agent1:                 episode reward: 0.6834,                 loss: 0.1128
Episode: 12501/30000 (41.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2365s / 125.1843 s
agent0:                 episode reward: -0.2785,                 loss: nan
agent1:                 episode reward: 0.2785,                 loss: 0.1137
Episode: 12521/30000 (41.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2342s / 125.4185 s
agent0:                 episode reward: -0.8462,                 loss: nan
agent1:                 episode reward: 0.8462,                 loss: 0.1124
Episode: 12541/30000 (41.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2260s / 125.6445 s
agent0:                 episode reward: -0.7550,                 loss: nan
agent1:                 episode reward: 0.7550,                 loss: 0.1120
Episode: 12561/30000 (41.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2264s / 125.8709 s
agent0:                 episode reward: -0.7711,                 loss: nan
agent1:                 episode reward: 0.7711,                 loss: 0.1122
Episode: 12581/30000 (41.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2291s / 126.1000 s
agent0:                 episode reward: -0.5234,                 loss: nan
agent1:                 episode reward: 0.5234,                 loss: 0.1111
Episode: 12601/30000 (42.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2310s / 126.3310 s
agent0:                 episode reward: -0.2845,                 loss: nan
agent1:                 episode reward: 0.2845,                 loss: 0.1113
Episode: 12621/30000 (42.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2335s / 126.5645 s
agent0:                 episode reward: -0.2736,                 loss: nan
agent1:                 episode reward: 0.2736,                 loss: 0.1096
Episode: 12641/30000 (42.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2302s / 126.7948 s
agent0:                 episode reward: -0.4993,                 loss: nan
agent1:                 episode reward: 0.4993,                 loss: 0.1123
Episode: 12661/30000 (42.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2336s / 127.0284 s
agent0:                 episode reward: -0.6331,                 loss: nan
agent1:                 episode reward: 0.6331,                 loss: 0.1095
Episode: 12681/30000 (42.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2452s / 127.2736 s
agent0:                 episode reward: -0.0507,                 loss: nan
agent1:                 episode reward: 0.0507,                 loss: 0.1104
Episode: 12701/30000 (42.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2757s / 127.5493 s
agent0:                 episode reward: -0.5021,                 loss: nan
agent1:                 episode reward: 0.5021,                 loss: 0.1115
Episode: 12721/30000 (42.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2660s / 127.8153 s
agent0:                 episode reward: -0.3523,                 loss: nan
agent1:                 episode reward: 0.3523,                 loss: 0.1107
Episode: 12741/30000 (42.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2445s / 128.0598 s
agent0:                 episode reward: -0.2808,                 loss: nan
agent1:                 episode reward: 0.2808,                 loss: 0.1110
Episode: 12761/30000 (42.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2441s / 128.3039 s
agent0:                 episode reward: -0.6461,                 loss: nan
agent1:                 episode reward: 0.6461,                 loss: 0.1097
Episode: 12781/30000 (42.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2394s / 128.5433 s
agent0:                 episode reward: -0.6389,                 loss: nan
agent1:                 episode reward: 0.6389,                 loss: 0.1107
Episode: 12801/30000 (42.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2463s / 128.7896 s
agent0:                 episode reward: -0.2580,                 loss: nan
agent1:                 episode reward: 0.2580,                 loss: 0.1099
Episode: 12821/30000 (42.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2391s / 129.0287 s
agent0:                 episode reward: -0.5031,                 loss: nan
agent1:                 episode reward: 0.5031,                 loss: 0.1117
Episode: 12841/30000 (42.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2447s / 129.2734 s
agent0:                 episode reward: -0.0953,                 loss: nan
agent1:                 episode reward: 0.0953,                 loss: 0.1097
Episode: 12861/30000 (42.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2598s / 129.5332 s
agent0:                 episode reward: -0.2666,                 loss: nan
agent1:                 episode reward: 0.2666,                 loss: 0.1103
Episode: 12881/30000 (42.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2503s / 129.7835 s
agent0:                 episode reward: -0.6571,                 loss: nan
agent1:                 episode reward: 0.6571,                 loss: 0.1116
Episode: 12901/30000 (43.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2422s / 130.0258 s
agent0:                 episode reward: -0.5747,                 loss: nan
agent1:                 episode reward: 0.5747,                 loss: 0.1146
Episode: 12921/30000 (43.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2448s / 130.2705 s
agent0:                 episode reward: -0.3296,                 loss: nan
agent1:                 episode reward: 0.3296,                 loss: 0.1147
Episode: 12941/30000 (43.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2511s / 130.5217 s
agent0:                 episode reward: -0.4023,                 loss: nan
agent1:                 episode reward: 0.4023,                 loss: 0.1154
Episode: 12961/30000 (43.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2554s / 130.7771 s
agent0:                 episode reward: -0.4796,                 loss: nan
agent1:                 episode reward: 0.4796,                 loss: 0.1141
Episode: 12981/30000 (43.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2374s / 131.0145 s
agent0:                 episode reward: -0.5166,                 loss: nan
agent1:                 episode reward: 0.5166,                 loss: 0.1155
Episode: 13001/30000 (43.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2318s / 131.2463 s
agent0:                 episode reward: -0.2500,                 loss: nan
agent1:                 episode reward: 0.2500,                 loss: 0.1143
Episode: 13021/30000 (43.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2390s / 131.4853 s
agent0:                 episode reward: -0.2509,                 loss: nan
agent1:                 episode reward: 0.2509,                 loss: 0.1142
Episode: 13041/30000 (43.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2371s / 131.7224 s
agent0:                 episode reward: -0.6805,                 loss: nan
agent1:                 episode reward: 0.6805,                 loss: 0.1150
Episode: 13061/30000 (43.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2352s / 131.9576 s
agent0:                 episode reward: -0.4196,                 loss: nan
agent1:                 episode reward: 0.4196,                 loss: 0.1142
Episode: 13081/30000 (43.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2384s / 132.1960 s
agent0:                 episode reward: -0.1193,                 loss: nan
agent1:                 episode reward: 0.1193,                 loss: 0.1150
Episode: 13101/30000 (43.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2359s / 132.4319 s
agent0:                 episode reward: -0.4808,                 loss: nan
agent1:                 episode reward: 0.4808,                 loss: 0.1148
Episode: 13121/30000 (43.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2416s / 132.6735 s
agent0:                 episode reward: -0.7096,                 loss: nan
agent1:                 episode reward: 0.7096,                 loss: 0.1142
Episode: 13141/30000 (43.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2410s / 132.9146 s
agent0:                 episode reward: -0.2052,                 loss: nan
agent1:                 episode reward: 0.2052,                 loss: 0.1152
Episode: 13161/30000 (43.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2369s / 133.1514 s
agent0:                 episode reward: -0.3973,                 loss: nan
agent1:                 episode reward: 0.3973,                 loss: 0.1128
Episode: 13181/30000 (43.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2387s / 133.3902 s
agent0:                 episode reward: -0.5762,                 loss: nan
agent1:                 episode reward: 0.5762,                 loss: 0.1143
Episode: 13201/30000 (44.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2613s / 133.6515 s
agent0:                 episode reward: -0.4107,                 loss: nan
agent1:                 episode reward: 0.4107,                 loss: 0.1135
Episode: 13221/30000 (44.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2586s / 133.9101 s
agent0:                 episode reward: -0.2892,                 loss: nan
agent1:                 episode reward: 0.2892,                 loss: 0.1124
Episode: 13241/30000 (44.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2455s / 134.1555 s
agent0:                 episode reward: -0.4048,                 loss: nan
agent1:                 episode reward: 0.4048,                 loss: 0.1117
Episode: 13261/30000 (44.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2379s / 134.3934 s
agent0:                 episode reward: -0.3958,                 loss: nan
agent1:                 episode reward: 0.3958,                 loss: 0.1114
Episode: 13281/30000 (44.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2420s / 134.6354 s
agent0:                 episode reward: -0.2205,                 loss: nan
agent1:                 episode reward: 0.2205,                 loss: 0.1120
Episode: 13301/30000 (44.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2378s / 134.8733 s
agent0:                 episode reward: -0.5968,                 loss: nan
agent1:                 episode reward: 0.5968,                 loss: 0.1103
Episode: 13321/30000 (44.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2399s / 135.1131 s
agent0:                 episode reward: -0.4498,                 loss: nan
agent1:                 episode reward: 0.4498,                 loss: 0.1101
Episode: 13341/30000 (44.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2534s / 135.3665 s
agent0:                 episode reward: -0.4378,                 loss: nan
agent1:                 episode reward: 0.4378,                 loss: 0.1115
Episode: 13361/30000 (44.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2520s / 135.6185 s
agent0:                 episode reward: -0.5970,                 loss: nan
agent1:                 episode reward: 0.5970,                 loss: 0.1098
Episode: 13381/30000 (44.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2744s / 135.8929 s
agent0:                 episode reward: -0.4508,                 loss: nan
agent1:                 episode reward: 0.4508,                 loss: 0.1115
Episode: 13401/30000 (44.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2593s / 136.1522 s
agent0:                 episode reward: -0.4045,                 loss: nan
agent1:                 episode reward: 0.4045,                 loss: 0.1107
Episode: 13421/30000 (44.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2640s / 136.4161 s
agent0:                 episode reward: -0.5511,                 loss: nan
agent1:                 episode reward: 0.5511,                 loss: 0.1110
Episode: 13441/30000 (44.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2547s / 136.6709 s
agent0:                 episode reward: -0.4201,                 loss: nan
agent1:                 episode reward: 0.4201,                 loss: 0.1098
Episode: 13461/30000 (44.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2637s / 136.9346 s
agent0:                 episode reward: -0.4708,                 loss: nan
agent1:                 episode reward: 0.4708,                 loss: 0.1105
Episode: 13481/30000 (44.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2647s / 137.1993 s
agent0:                 episode reward: -0.9209,                 loss: nan
agent1:                 episode reward: 0.9209,                 loss: 0.1115
Episode: 13501/30000 (45.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2579s / 137.4571 s
agent0:                 episode reward: -0.4126,                 loss: nan
agent1:                 episode reward: 0.4126,                 loss: 0.1106
Episode: 13521/30000 (45.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2550s / 137.7121 s
agent0:                 episode reward: -0.3454,                 loss: nan
agent1:                 episode reward: 0.3454,                 loss: 0.1102
Episode: 13541/30000 (45.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2598s / 137.9719 s
agent0:                 episode reward: -0.6467,                 loss: nan
agent1:                 episode reward: 0.6467,                 loss: 0.1105
Episode: 13561/30000 (45.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2467s / 138.2186 s
agent0:                 episode reward: -0.5303,                 loss: nan
agent1:                 episode reward: 0.5303,                 loss: 0.1100
Episode: 13581/30000 (45.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2478s / 138.4664 s
agent0:                 episode reward: -0.7869,                 loss: nan
agent1:                 episode reward: 0.7869,                 loss: 0.1117
Episode: 13601/30000 (45.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2503s / 138.7167 s
agent0:                 episode reward: -0.4759,                 loss: nan
agent1:                 episode reward: 0.4759,                 loss: 0.1110
Episode: 13621/30000 (45.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2523s / 138.9690 s
agent0:                 episode reward: -0.7801,                 loss: nan
agent1:                 episode reward: 0.7801,                 loss: 0.1100
Episode: 13641/30000 (45.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2514s / 139.2204 s
agent0:                 episode reward: -0.4460,                 loss: nan
agent1:                 episode reward: 0.4460,                 loss: 0.1111
Episode: 13661/30000 (45.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2505s / 139.4709 s
agent0:                 episode reward: -0.3816,                 loss: nan
agent1:                 episode reward: 0.3816,                 loss: 0.1116
Episode: 13681/30000 (45.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2669s / 139.7377 s
agent0:                 episode reward: -0.2936,                 loss: nan
agent1:                 episode reward: 0.2936,                 loss: 0.1126
Episode: 13701/30000 (45.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2750s / 140.0127 s
agent0:                 episode reward: -0.4213,                 loss: nan
agent1:                 episode reward: 0.4213,                 loss: 0.1105
Episode: 13721/30000 (45.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2587s / 140.2714 s
agent0:                 episode reward: -0.2520,                 loss: nan
agent1:                 episode reward: 0.2520,                 loss: 0.1110
Episode: 13741/30000 (45.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2449s / 140.5163 s
agent0:                 episode reward: -0.0891,                 loss: nan
agent1:                 episode reward: 0.0891,                 loss: 0.1113
Episode: 13761/30000 (45.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2510s / 140.7673 s
agent0:                 episode reward: -0.4971,                 loss: nan
agent1:                 episode reward: 0.4971,                 loss: 0.1094
Episode: 13781/30000 (45.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2696s / 141.0370 s
agent0:                 episode reward: -0.9401,                 loss: nan
agent1:                 episode reward: 0.9401,                 loss: 0.1114
Episode: 13801/30000 (46.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2687s / 141.3057 s
agent0:                 episode reward: -0.4842,                 loss: nan
agent1:                 episode reward: 0.4842,                 loss: 0.1105
Episode: 13821/30000 (46.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2577s / 141.5634 s
agent0:                 episode reward: -0.3548,                 loss: nan
agent1:                 episode reward: 0.3548,                 loss: 0.1107
Episode: 13841/30000 (46.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2589s / 141.8223 s
agent0:                 episode reward: -0.3910,                 loss: nan
agent1:                 episode reward: 0.3910,                 loss: 0.1102
Episode: 13861/30000 (46.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2565s / 142.0788 s
agent0:                 episode reward: -0.5154,                 loss: nan
agent1:                 episode reward: 0.5154,                 loss: 0.1104
Episode: 13881/30000 (46.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2550s / 142.3338 s
agent0:                 episode reward: -0.3931,                 loss: nan
agent1:                 episode reward: 0.3931,                 loss: 0.1118
Episode: 13901/30000 (46.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2576s / 142.5913 s
agent0:                 episode reward: -0.4511,                 loss: nan
agent1:                 episode reward: 0.4511,                 loss: 0.1100
Episode: 13921/30000 (46.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2826s / 142.8739 s
agent0:                 episode reward: -0.7757,                 loss: nan
agent1:                 episode reward: 0.7757,                 loss: 0.1103
Episode: 13941/30000 (46.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2615s / 143.1354 s
agent0:                 episode reward: -0.6118,                 loss: nan
agent1:                 episode reward: 0.6118,                 loss: 0.1102
Episode: 13961/30000 (46.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2530s / 143.3885 s
agent0:                 episode reward: -0.1186,                 loss: nan
agent1:                 episode reward: 0.1186,                 loss: 0.1112
Episode: 13981/30000 (46.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2451s / 143.6335 s
agent0:                 episode reward: -0.4160,                 loss: nan
agent1:                 episode reward: 0.4160,                 loss: 0.1102
Episode: 14001/30000 (46.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2453s / 143.8789 s
agent0:                 episode reward: -0.3719,                 loss: nan
agent1:                 episode reward: 0.3719,                 loss: 0.1100
Episode: 14021/30000 (46.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2495s / 144.1284 s
agent0:                 episode reward: -0.2153,                 loss: nan
agent1:                 episode reward: 0.2153,                 loss: 0.1101
Episode: 14041/30000 (46.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2485s / 144.3769 s
agent0:                 episode reward: -0.3702,                 loss: nan
agent1:                 episode reward: 0.3702,                 loss: 0.1096
Episode: 14061/30000 (46.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2532s / 144.6301 s
agent0:                 episode reward: -0.5609,                 loss: nan
agent1:                 episode reward: 0.5609,                 loss: 0.1107
Episode: 14081/30000 (46.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2460s / 144.8760 s
agent0:                 episode reward: -0.6943,                 loss: nan
agent1:                 episode reward: 0.6943,                 loss: 0.1101
Episode: 14101/30000 (47.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2446s / 145.1206 s
agent0:                 episode reward: -0.3856,                 loss: nan
agent1:                 episode reward: 0.3856,                 loss: 0.1101
Episode: 14121/30000 (47.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2366s / 145.3573 s
agent0:                 episode reward: -0.4479,                 loss: nan
agent1:                 episode reward: 0.4479,                 loss: 0.1100
Episode: 14141/30000 (47.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2397s / 145.5970 s
agent0:                 episode reward: -0.2432,                 loss: nan
agent1:                 episode reward: 0.2432,                 loss: 0.1090
Episode: 14161/30000 (47.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2588s / 145.8558 s
agent0:                 episode reward: -0.7269,                 loss: nan
agent1:                 episode reward: 0.7269,                 loss: 0.1099
Episode: 14181/30000 (47.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2688s / 146.1246 s
agent0:                 episode reward: -0.4987,                 loss: nan
agent1:                 episode reward: 0.4987,                 loss: 0.1107
Episode: 14201/30000 (47.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2518s / 146.3764 s
agent0:                 episode reward: -0.3172,                 loss: nan
agent1:                 episode reward: 0.3172,                 loss: 0.1111
Episode: 14221/30000 (47.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2495s / 146.6259 s
agent0:                 episode reward: -0.5332,                 loss: nan
agent1:                 episode reward: 0.5332,                 loss: 0.1098
Episode: 14241/30000 (47.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2533s / 146.8791 s
agent0:                 episode reward: -0.3567,                 loss: nan
agent1:                 episode reward: 0.3567,                 loss: 0.1096
Episode: 14261/30000 (47.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2539s / 147.1330 s
agent0:                 episode reward: -0.0311,                 loss: nan
agent1:                 episode reward: 0.0311,                 loss: 0.1091
Episode: 14281/30000 (47.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2545s / 147.3875 s
agent0:                 episode reward: -0.2686,                 loss: nan
agent1:                 episode reward: 0.2686,                 loss: 0.1104
Episode: 14301/30000 (47.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2532s / 147.6407 s
agent0:                 episode reward: -0.7260,                 loss: nan
agent1:                 episode reward: 0.7260,                 loss: 0.1087
Episode: 14321/30000 (47.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2506s / 147.8912 s
agent0:                 episode reward: -0.3278,                 loss: nan
agent1:                 episode reward: 0.3278,                 loss: 0.1104
Episode: 14341/30000 (47.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2538s / 148.1451 s
agent0:                 episode reward: -0.3439,                 loss: nan
agent1:                 episode reward: 0.3439,                 loss: 0.1100
Episode: 14361/30000 (47.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2572s / 148.4022 s
agent0:                 episode reward: -0.5987,                 loss: nan
agent1:                 episode reward: 0.5987,                 loss: 0.1097
Episode: 14381/30000 (47.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2573s / 148.6595 s
agent0:                 episode reward: -0.6790,                 loss: nan
agent1:                 episode reward: 0.6790,                 loss: 0.1100
Episode: 14401/30000 (48.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2801s / 148.9396 s
agent0:                 episode reward: -0.4391,                 loss: nan
agent1:                 episode reward: 0.4391,                 loss: 0.1099
Episode: 14421/30000 (48.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2801s / 149.2197 s
agent0:                 episode reward: -0.7296,                 loss: nan
agent1:                 episode reward: 0.7296,                 loss: 0.1082
Episode: 14441/30000 (48.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2544s / 149.4740 s
agent0:                 episode reward: -0.1626,                 loss: nan
agent1:                 episode reward: 0.1626,                 loss: 0.1090
Episode: 14461/30000 (48.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2563s / 149.7304 s
agent0:                 episode reward: -0.6626,                 loss: nan
agent1:                 episode reward: 0.6626,                 loss: 0.1091
Episode: 14481/30000 (48.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2504s / 149.9807 s
agent0:                 episode reward: -0.5714,                 loss: nan
agent1:                 episode reward: 0.5714,                 loss: 0.1103
Episode: 14501/30000 (48.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2505s / 150.2312 s
agent0:                 episode reward: -0.4199,                 loss: nan
agent1:                 episode reward: 0.4199,                 loss: 0.1108
Episode: 14521/30000 (48.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2503s / 150.4815 s
agent0:                 episode reward: -0.4795,                 loss: nan
agent1:                 episode reward: 0.4795,                 loss: 0.1115
Episode: 14541/30000 (48.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2548s / 150.7363 s
agent0:                 episode reward: -0.6366,                 loss: nan
agent1:                 episode reward: 0.6366,                 loss: 0.1101
Episode: 14561/30000 (48.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2550s / 150.9913 s
agent0:                 episode reward: -0.0374,                 loss: nan
agent1:                 episode reward: 0.0374,                 loss: 0.1090
Episode: 14581/30000 (48.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2541s / 151.2454 s
agent0:                 episode reward: -0.6508,                 loss: nan
agent1:                 episode reward: 0.6508,                 loss: 0.1098
Episode: 14601/30000 (48.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2538s / 151.4992 s
agent0:                 episode reward: -0.5082,                 loss: nan
agent1:                 episode reward: 0.5082,                 loss: 0.1119
Episode: 14621/30000 (48.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2447s / 151.7439 s
agent0:                 episode reward: -0.5951,                 loss: nan
agent1:                 episode reward: 0.5951,                 loss: 0.1089
Episode: 14641/30000 (48.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2632s / 152.0071 s
agent0:                 episode reward: -0.4172,                 loss: nan
agent1:                 episode reward: 0.4172,                 loss: 0.1101
Episode: 14661/30000 (48.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2595s / 152.2666 s
agent0:                 episode reward: -0.5773,                 loss: nan
agent1:                 episode reward: 0.5773,                 loss: 0.1099
Episode: 14681/30000 (48.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2508s / 152.5174 s
agent0:                 episode reward: -0.4951,                 loss: nan
agent1:                 episode reward: 0.4951,                 loss: 0.1109
Episode: 14701/30000 (49.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2456s / 152.7630 s
agent0:                 episode reward: -0.4974,                 loss: nan
agent1:                 episode reward: 0.4974,                 loss: 0.1096
Episode: 14721/30000 (49.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2553s / 153.0182 s
agent0:                 episode reward: -0.2587,                 loss: nan
agent1:                 episode reward: 0.2587,                 loss: 0.1094
Episode: 14741/30000 (49.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2551s / 153.2733 s
agent0:                 episode reward: -0.4194,                 loss: nan
agent1:                 episode reward: 0.4194,                 loss: 0.1099
Episode: 14761/30000 (49.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2520s / 153.5252 s
agent0:                 episode reward: -0.6717,                 loss: nan
agent1:                 episode reward: 0.6717,                 loss: 0.1099
Episode: 14781/30000 (49.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2572s / 153.7824 s
agent0:                 episode reward: -0.5258,                 loss: nan
agent1:                 episode reward: 0.5258,                 loss: 0.1109
Episode: 14801/30000 (49.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2536s / 154.0360 s
agent0:                 episode reward: -0.6239,                 loss: nan
agent1:                 episode reward: 0.6239,                 loss: 0.1085
Episode: 14821/30000 (49.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2643s / 154.3003 s
agent0:                 episode reward: -0.4808,                 loss: nan
agent1:                 episode reward: 0.4808,                 loss: 0.1094
Episode: 14841/30000 (49.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2887s / 154.5890 s
agent0:                 episode reward: -0.3051,                 loss: nan
agent1:                 episode reward: 0.3051,                 loss: 0.1091
Episode: 14861/30000 (49.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2656s / 154.8546 s
agent0:                 episode reward: -0.3051,                 loss: nan
agent1:                 episode reward: 0.3051,                 loss: 0.1097
Episode: 14881/30000 (49.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2822s / 155.1368 s
agent0:                 episode reward: -0.4938,                 loss: nan
agent1:                 episode reward: 0.4938,                 loss: 0.1092
Episode: 14901/30000 (49.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2786s / 155.4154 s
agent0:                 episode reward: -0.6187,                 loss: nan
agent1:                 episode reward: 0.6187,                 loss: 0.1104
Episode: 14921/30000 (49.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2658s / 155.6812 s
agent0:                 episode reward: -0.4028,                 loss: nan
agent1:                 episode reward: 0.4028,                 loss: 0.1085
Episode: 14941/30000 (49.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2572s / 155.9384 s
agent0:                 episode reward: -0.7039,                 loss: nan
agent1:                 episode reward: 0.7039,                 loss: 0.1100
Episode: 14961/30000 (49.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2568s / 156.1952 s
agent0:                 episode reward: -0.7743,                 loss: nan
agent1:                 episode reward: 0.7743,                 loss: 0.1091
Episode: 14981/30000 (49.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2660s / 156.4613 s
agent0:                 episode reward: -0.3937,                 loss: nan
agent1:                 episode reward: 0.3937,                 loss: 0.1094
Episode: 15001/30000 (50.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2591s / 156.7204 s
agent0:                 episode reward: -0.4720,                 loss: nan
agent1:                 episode reward: 0.4720,                 loss: 0.1100
Episode: 15021/30000 (50.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2624s / 156.9827 s
agent0:                 episode reward: -0.6167,                 loss: nan
agent1:                 episode reward: 0.6167,                 loss: 0.1106
Episode: 15041/30000 (50.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2674s / 157.2501 s
agent0:                 episode reward: -0.3164,                 loss: nan
agent1:                 episode reward: 0.3164,                 loss: 0.1095
Episode: 15061/30000 (50.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2514s / 157.5015 s
agent0:                 episode reward: -0.3936,                 loss: nan
agent1:                 episode reward: 0.3936,                 loss: 0.1086
Episode: 15081/30000 (50.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2531s / 157.7546 s
agent0:                 episode reward: -0.7116,                 loss: nan
agent1:                 episode reward: 0.7116,                 loss: 0.1089
Episode: 15101/30000 (50.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2519s / 158.0065 s
agent0:                 episode reward: -0.4560,                 loss: nan
agent1:                 episode reward: 0.4560,                 loss: 0.1095
Episode: 15121/30000 (50.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2829s / 158.2894 s
agent0:                 episode reward: -0.3183,                 loss: nan
agent1:                 episode reward: 0.3183,                 loss: 0.1092
Episode: 15141/30000 (50.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2588s / 158.5483 s
agent0:                 episode reward: -0.7414,                 loss: nan
agent1:                 episode reward: 0.7414,                 loss: 0.1091
Episode: 15161/30000 (50.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2566s / 158.8049 s
agent0:                 episode reward: -0.3434,                 loss: nan
agent1:                 episode reward: 0.3434,                 loss: 0.1098
Episode: 15181/30000 (50.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2546s / 159.0595 s
agent0:                 episode reward: -0.3591,                 loss: nan
agent1:                 episode reward: 0.3591,                 loss: 0.1099
Episode: 15201/30000 (50.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2518s / 159.3113 s
agent0:                 episode reward: -0.2619,                 loss: nan
agent1:                 episode reward: 0.2619,                 loss: 0.1092
Episode: 15221/30000 (50.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2578s / 159.5691 s
agent0:                 episode reward: -0.4919,                 loss: nan
agent1:                 episode reward: 0.4919,                 loss: 0.1105
Episode: 15241/30000 (50.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2526s / 159.8217 s
agent0:                 episode reward: -0.7074,                 loss: nan
agent1:                 episode reward: 0.7074,                 loss: 0.1087
Episode: 15261/30000 (50.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2506s / 160.0723 s
agent0:                 episode reward: -0.6279,                 loss: nan
agent1:                 episode reward: 0.6279,                 loss: 0.1095
Episode: 15281/30000 (50.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2514s / 160.3238 s
agent0:                 episode reward: -0.4509,                 loss: nan
agent1:                 episode reward: 0.4509,                 loss: 0.1105
Episode: 15301/30000 (51.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2543s / 160.5780 s
agent0:                 episode reward: -0.7840,                 loss: nan
agent1:                 episode reward: 0.7840,                 loss: 0.1087
Episode: 15321/30000 (51.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2518s / 160.8298 s
agent0:                 episode reward: -0.2743,                 loss: nan
agent1:                 episode reward: 0.2743,                 loss: 0.1100
Episode: 15341/30000 (51.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2635s / 161.0933 s
agent0:                 episode reward: -0.3047,                 loss: nan
agent1:                 episode reward: 0.3047,                 loss: 0.1079
Episode: 15361/30000 (51.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2807s / 161.3740 s
agent0:                 episode reward: -0.3820,                 loss: nan
agent1:                 episode reward: 0.3820,                 loss: 0.1092
Episode: 15381/30000 (51.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2533s / 161.6273 s
agent0:                 episode reward: -0.4465,                 loss: nan
agent1:                 episode reward: 0.4465,                 loss: 0.1097
Episode: 15401/30000 (51.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2538s / 161.8811 s
agent0:                 episode reward: -0.3697,                 loss: nan
agent1:                 episode reward: 0.3697,                 loss: 0.1091
Episode: 15421/30000 (51.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2568s / 162.1379 s
agent0:                 episode reward: -0.6378,                 loss: nan
agent1:                 episode reward: 0.6378,                 loss: 0.1088
Episode: 15441/30000 (51.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2579s / 162.3958 s
agent0:                 episode reward: -0.4087,                 loss: nan
agent1:                 episode reward: 0.4087,                 loss: 0.1102
Episode: 15461/30000 (51.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2583s / 162.6541 s
agent0:                 episode reward: -0.4521,                 loss: nan
agent1:                 episode reward: 0.4521,                 loss: 0.1098
Episode: 15481/30000 (51.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2732s / 162.9272 s
agent0:                 episode reward: -0.3394,                 loss: nan
agent1:                 episode reward: 0.3394,                 loss: 0.1109
Episode: 15501/30000 (51.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2594s / 163.1866 s
agent0:                 episode reward: -0.6928,                 loss: nan
agent1:                 episode reward: 0.6928,                 loss: 0.1086
Episode: 15521/30000 (51.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2597s / 163.4463 s
agent0:                 episode reward: -0.3555,                 loss: nan
agent1:                 episode reward: 0.3555,                 loss: 0.1091
Episode: 15541/30000 (51.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2538s / 163.7001 s
agent0:                 episode reward: -0.5585,                 loss: nan
agent1:                 episode reward: 0.5585,                 loss: 0.1099
Episode: 15561/30000 (51.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2661s / 163.9662 s
agent0:                 episode reward: -0.6824,                 loss: nan
agent1:                 episode reward: 0.6824,                 loss: 0.1109
Episode: 15581/30000 (51.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2749s / 164.2411 s
agent0:                 episode reward: -0.2574,                 loss: nan
agent1:                 episode reward: 0.2574,                 loss: 0.1104
Episode: 15601/30000 (52.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3143s / 164.5554 s
agent0:                 episode reward: -0.5168,                 loss: nan
agent1:                 episode reward: 0.5168,                 loss: 0.1106
Episode: 15621/30000 (52.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2588s / 164.8142 s
agent0:                 episode reward: -0.3802,                 loss: nan
agent1:                 episode reward: 0.3802,                 loss: 0.1112
Episode: 15641/30000 (52.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2577s / 165.0719 s
agent0:                 episode reward: -0.6202,                 loss: nan
agent1:                 episode reward: 0.6202,                 loss: 0.1102
Episode: 15661/30000 (52.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2589s / 165.3308 s
agent0:                 episode reward: -0.3754,                 loss: nan
agent1:                 episode reward: 0.3754,                 loss: 0.1105
Episode: 15681/30000 (52.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2581s / 165.5889 s
agent0:                 episode reward: -0.5019,                 loss: nan
agent1:                 episode reward: 0.5019,                 loss: 0.1100
Episode: 15701/30000 (52.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2540s / 165.8429 s
agent0:                 episode reward: -0.0230,                 loss: nan
agent1:                 episode reward: 0.0230,                 loss: 0.1117
Episode: 15721/30000 (52.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2541s / 166.0969 s
agent0:                 episode reward: -0.3888,                 loss: nan
agent1:                 episode reward: 0.3888,                 loss: 0.1105
Episode: 15741/30000 (52.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2608s / 166.3577 s
agent0:                 episode reward: -0.4756,                 loss: nan
agent1:                 episode reward: 0.4756,                 loss: 0.1098
Episode: 15761/30000 (52.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2594s / 166.6171 s
agent0:                 episode reward: -0.3947,                 loss: nan
agent1:                 episode reward: 0.3947,                 loss: 0.1115
Episode: 15781/30000 (52.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2582s / 166.8753 s
agent0:                 episode reward: -0.8528,                 loss: nan
agent1:                 episode reward: 0.8528,                 loss: 0.1112
Episode: 15801/30000 (52.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2562s / 167.1315 s
agent0:                 episode reward: -0.2201,                 loss: nan
agent1:                 episode reward: 0.2201,                 loss: 0.1107
Episode: 15821/30000 (52.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2778s / 167.4093 s
agent0:                 episode reward: -0.6974,                 loss: nan
agent1:                 episode reward: 0.6974,                 loss: 0.1092
Episode: 15841/30000 (52.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2585s / 167.6678 s
agent0:                 episode reward: -0.5411,                 loss: nan
agent1:                 episode reward: 0.5411,                 loss: 0.1109
Episode: 15861/30000 (52.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2514s / 167.9192 s
agent0:                 episode reward: -0.6455,                 loss: nan
agent1:                 episode reward: 0.6455,                 loss: 0.1104
Episode: 15881/30000 (52.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2551s / 168.1742 s
agent0:                 episode reward: -0.3943,                 loss: nan
agent1:                 episode reward: 0.3943,                 loss: 0.1099
Episode: 15901/30000 (53.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2486s / 168.4228 s
agent0:                 episode reward: -0.4623,                 loss: nan
agent1:                 episode reward: 0.4623,                 loss: 0.1104
Episode: 15921/30000 (53.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2529s / 168.6758 s
agent0:                 episode reward: -0.3188,                 loss: nan
agent1:                 episode reward: 0.3188,                 loss: 0.1108
Episode: 15941/30000 (53.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2496s / 168.9254 s
agent0:                 episode reward: -0.3965,                 loss: nan
agent1:                 episode reward: 0.3965,                 loss: 0.1099
Episode: 15961/30000 (53.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2611s / 169.1865 s
agent0:                 episode reward: -0.1422,                 loss: nan
agent1:                 episode reward: 0.1422,                 loss: 0.1100
Episode: 15981/30000 (53.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2449s / 169.4314 s
agent0:                 episode reward: -0.3801,                 loss: nan
agent1:                 episode reward: 0.3801,                 loss: 0.1101
Episode: 16001/30000 (53.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2505s / 169.6819 s
agent0:                 episode reward: -0.9929,                 loss: nan
agent1:                 episode reward: 0.9929,                 loss: 0.1099
Episode: 16021/30000 (53.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2576s / 169.9395 s
agent0:                 episode reward: -0.6593,                 loss: nan
agent1:                 episode reward: 0.6593,                 loss: 0.1097
Episode: 16041/30000 (53.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2596s / 170.1991 s
agent0:                 episode reward: -0.5256,                 loss: nan
agent1:                 episode reward: 0.5256,                 loss: 0.1085
Episode: 16061/30000 (53.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2600s / 170.4591 s
agent0:                 episode reward: -0.6741,                 loss: nan
agent1:                 episode reward: 0.6741,                 loss: 0.1095
Episode: 16081/30000 (53.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2562s / 170.7154 s
agent0:                 episode reward: -0.7093,                 loss: nan
agent1:                 episode reward: 0.7093,                 loss: 0.1099
Episode: 16101/30000 (53.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2568s / 170.9722 s
agent0:                 episode reward: -0.9393,                 loss: nan
agent1:                 episode reward: 0.9393,                 loss: 0.1093
Episode: 16121/30000 (53.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2670s / 171.2392 s
agent0:                 episode reward: -0.6902,                 loss: nan
agent1:                 episode reward: 0.6902,                 loss: 0.1096
Episode: 16141/30000 (53.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2569s / 171.4960 s
agent0:                 episode reward: -0.3010,                 loss: nan
agent1:                 episode reward: 0.3010,                 loss: 0.1095
Episode: 16161/30000 (53.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2517s / 171.7477 s
agent0:                 episode reward: -0.6625,                 loss: nan
agent1:                 episode reward: 0.6625,                 loss: 0.1087
Episode: 16181/30000 (53.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2480s / 171.9957 s
agent0:                 episode reward: -1.1086,                 loss: nan
agent1:                 episode reward: 1.1086,                 loss: 0.1086
Episode: 16201/30000 (54.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2515s / 172.2472 s
agent0:                 episode reward: -0.2556,                 loss: nan
agent1:                 episode reward: 0.2556,                 loss: 0.1101
Episode: 16221/30000 (54.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2518s / 172.4990 s
agent0:                 episode reward: -0.7084,                 loss: nan
agent1:                 episode reward: 0.7084,                 loss: 0.1079
Episode: 16241/30000 (54.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2534s / 172.7524 s
agent0:                 episode reward: -0.4687,                 loss: nan
agent1:                 episode reward: 0.4687,                 loss: 0.1109
Episode: 16261/30000 (54.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2611s / 173.0135 s
agent0:                 episode reward: -0.4055,                 loss: nan
agent1:                 episode reward: 0.4055,                 loss: 0.1095
Episode: 16281/30000 (54.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2730s / 173.2866 s
agent0:                 episode reward: -0.7566,                 loss: nan
agent1:                 episode reward: 0.7566,                 loss: 0.1096
Episode: 16301/30000 (54.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2559s / 173.5424 s
agent0:                 episode reward: -0.3196,                 loss: nan
agent1:                 episode reward: 0.3196,                 loss: 0.1100
Episode: 16321/30000 (54.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2564s / 173.7989 s
agent0:                 episode reward: -0.7818,                 loss: nan
agent1:                 episode reward: 0.7818,                 loss: 0.1096
Episode: 16341/30000 (54.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2545s / 174.0534 s
agent0:                 episode reward: -0.6248,                 loss: nan
agent1:                 episode reward: 0.6248,                 loss: 0.1080
Episode: 16361/30000 (54.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2565s / 174.3099 s
agent0:                 episode reward: -0.6614,                 loss: nan
agent1:                 episode reward: 0.6614,                 loss: 0.1097
Episode: 16381/30000 (54.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2566s / 174.5665 s
agent0:                 episode reward: -0.5439,                 loss: nan
agent1:                 episode reward: 0.5439,                 loss: 0.1105
Episode: 16401/30000 (54.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2561s / 174.8227 s
agent0:                 episode reward: -0.7048,                 loss: nan
agent1:                 episode reward: 0.7048,                 loss: 0.1098
Episode: 16421/30000 (54.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2542s / 175.0769 s
agent0:                 episode reward: -0.3006,                 loss: nan
agent1:                 episode reward: 0.3006,                 loss: 0.1091
Episode: 16441/30000 (54.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2551s / 175.3320 s
agent0:                 episode reward: -0.5274,                 loss: nan
agent1:                 episode reward: 0.5274,                 loss: 0.1080
Episode: 16461/30000 (54.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2500s / 175.5820 s
agent0:                 episode reward: -0.5729,                 loss: nan
agent1:                 episode reward: 0.5729,                 loss: 0.1092
Episode: 16481/30000 (54.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2546s / 175.8366 s
agent0:                 episode reward: -0.4923,                 loss: nan
agent1:                 episode reward: 0.4923,                 loss: 0.1107
Episode: 16501/30000 (55.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2719s / 176.1084 s
agent0:                 episode reward: -0.4613,                 loss: nan
agent1:                 episode reward: 0.4613,                 loss: 0.1097
Episode: 16521/30000 (55.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3008s / 176.4092 s
agent0:                 episode reward: -0.0726,                 loss: nan
agent1:                 episode reward: 0.0726,                 loss: 0.1098
Episode: 16541/30000 (55.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2754s / 176.6846 s
agent0:                 episode reward: -0.6948,                 loss: nan
agent1:                 episode reward: 0.6948,                 loss: 0.1095
Episode: 16561/30000 (55.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2725s / 176.9570 s
agent0:                 episode reward: -0.6883,                 loss: nan
agent1:                 episode reward: 0.6883,                 loss: 0.1105
Episode: 16581/30000 (55.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2727s / 177.2297 s
agent0:                 episode reward: -0.3857,                 loss: nan
agent1:                 episode reward: 0.3857,                 loss: 0.1125
Episode: 16601/30000 (55.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2698s / 177.4995 s
agent0:                 episode reward: -0.4965,                 loss: nan
agent1:                 episode reward: 0.4965,                 loss: 0.1123
Episode: 16621/30000 (55.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2670s / 177.7664 s
agent0:                 episode reward: -0.4135,                 loss: nan
agent1:                 episode reward: 0.4135,                 loss: 0.1118
Episode: 16641/30000 (55.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2636s / 178.0301 s
agent0:                 episode reward: -0.6681,                 loss: nan
agent1:                 episode reward: 0.6681,                 loss: 0.1117
Episode: 16661/30000 (55.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2611s / 178.2911 s
agent0:                 episode reward: -0.6327,                 loss: nan
agent1:                 episode reward: 0.6327,                 loss: 0.1116
Episode: 16681/30000 (55.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2610s / 178.5521 s
agent0:                 episode reward: -0.7708,                 loss: nan
agent1:                 episode reward: 0.7708,                 loss: 0.1128
Episode: 16701/30000 (55.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2647s / 178.8169 s
agent0:                 episode reward: -0.6170,                 loss: nan
agent1:                 episode reward: 0.6170,                 loss: 0.1125
Episode: 16721/30000 (55.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2624s / 179.0793 s
agent0:                 episode reward: -0.3421,                 loss: nan
agent1:                 episode reward: 0.3421,                 loss: 0.1113
Episode: 16741/30000 (55.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2978s / 179.3771 s
agent0:                 episode reward: -0.5725,                 loss: nan
agent1:                 episode reward: 0.5725,                 loss: 0.1120
Episode: 16761/30000 (55.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2980s / 179.6751 s
agent0:                 episode reward: -0.6026,                 loss: nan
agent1:                 episode reward: 0.6026,                 loss: 0.1120
Episode: 16781/30000 (55.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2669s / 179.9420 s
agent0:                 episode reward: -0.7235,                 loss: nan
agent1:                 episode reward: 0.7235,                 loss: 0.1116
Episode: 16801/30000 (56.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2662s / 180.2082 s
agent0:                 episode reward: -0.1850,                 loss: nan
agent1:                 episode reward: 0.1850,                 loss: 0.1118
Episode: 16821/30000 (56.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2643s / 180.4725 s
agent0:                 episode reward: -0.6053,                 loss: nan
agent1:                 episode reward: 0.6053,                 loss: 0.1110
Episode: 16841/30000 (56.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2695s / 180.7420 s
agent0:                 episode reward: -0.4590,                 loss: nan
agent1:                 episode reward: 0.4590,                 loss: 0.1115
Episode: 16861/30000 (56.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2664s / 181.0084 s
agent0:                 episode reward: -0.5951,                 loss: nan
agent1:                 episode reward: 0.5951,                 loss: 0.1114
Episode: 16881/30000 (56.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2730s / 181.2814 s
agent0:                 episode reward: -0.5615,                 loss: nan
agent1:                 episode reward: 0.5615,                 loss: 0.1122
Episode: 16901/30000 (56.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2734s / 181.5548 s
agent0:                 episode reward: -0.7214,                 loss: nan
agent1:                 episode reward: 0.7214,                 loss: 0.1081
Episode: 16921/30000 (56.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2762s / 181.8310 s
agent0:                 episode reward: -0.7029,                 loss: nan
agent1:                 episode reward: 0.7029,                 loss: 0.1091
Episode: 16941/30000 (56.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2729s / 182.1040 s
agent0:                 episode reward: -0.3428,                 loss: nan
agent1:                 episode reward: 0.3428,                 loss: 0.1092
Episode: 16961/30000 (56.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2895s / 182.3934 s
agent0:                 episode reward: -0.4209,                 loss: nan
agent1:                 episode reward: 0.4209,                 loss: 0.1088
Episode: 16981/30000 (56.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2764s / 182.6699 s
agent0:                 episode reward: -0.4887,                 loss: nan
agent1:                 episode reward: 0.4887,                 loss: 0.1099
Episode: 17001/30000 (56.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2707s / 182.9405 s
agent0:                 episode reward: -0.4820,                 loss: nan
agent1:                 episode reward: 0.4820,                 loss: 0.1082
Episode: 17021/30000 (56.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2678s / 183.2083 s
agent0:                 episode reward: -0.2421,                 loss: nan
agent1:                 episode reward: 0.2421,                 loss: 0.1088
Episode: 17041/30000 (56.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2546s / 183.4629 s
agent0:                 episode reward: -0.5564,                 loss: nan
agent1:                 episode reward: 0.5564,                 loss: 0.1077
Episode: 17061/30000 (56.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2642s / 183.7271 s
agent0:                 episode reward: -0.7111,                 loss: nan
agent1:                 episode reward: 0.7111,                 loss: 0.1075
Episode: 17081/30000 (56.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2688s / 183.9959 s
agent0:                 episode reward: -0.9375,                 loss: nan
agent1:                 episode reward: 0.9375,                 loss: 0.1076
Episode: 17101/30000 (57.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2714s / 184.2673 s
agent0:                 episode reward: -0.3450,                 loss: nan
agent1:                 episode reward: 0.3450,                 loss: 0.1100
Episode: 17121/30000 (57.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2744s / 184.5417 s
agent0:                 episode reward: -0.5535,                 loss: nan
agent1:                 episode reward: 0.5535,                 loss: 0.1089
Episode: 17141/30000 (57.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2720s / 184.8138 s
agent0:                 episode reward: -0.5975,                 loss: nan
agent1:                 episode reward: 0.5975,                 loss: 0.1085
Episode: 17161/30000 (57.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2714s / 185.0852 s
agent0:                 episode reward: -0.7502,                 loss: nan
agent1:                 episode reward: 0.7502,                 loss: 0.1090
Episode: 17181/30000 (57.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2887s / 185.3739 s
agent0:                 episode reward: -0.7666,                 loss: nan
agent1:                 episode reward: 0.7666,                 loss: 0.1082
Episode: 17201/30000 (57.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2829s / 185.6568 s
agent0:                 episode reward: -0.5966,                 loss: nan
agent1:                 episode reward: 0.5966,                 loss: 0.1072
Episode: 17221/30000 (57.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2569s / 185.9137 s
agent0:                 episode reward: -0.5012,                 loss: nan
agent1:                 episode reward: 0.5012,                 loss: 0.1080
Episode: 17241/30000 (57.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2597s / 186.1734 s
agent0:                 episode reward: -0.3715,                 loss: nan
agent1:                 episode reward: 0.3715,                 loss: 0.1051
Episode: 17261/30000 (57.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2634s / 186.4368 s
agent0:                 episode reward: -0.1351,                 loss: nan
agent1:                 episode reward: 0.1351,                 loss: 0.1067
Episode: 17281/30000 (57.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2613s / 186.6981 s
agent0:                 episode reward: -0.9790,                 loss: nan
agent1:                 episode reward: 0.9790,                 loss: 0.1057
Episode: 17301/30000 (57.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2631s / 186.9612 s
agent0:                 episode reward: -0.3452,                 loss: nan
agent1:                 episode reward: 0.3452,                 loss: 0.1070
Episode: 17321/30000 (57.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2514s / 187.2126 s
agent0:                 episode reward: -0.6000,                 loss: nan
agent1:                 episode reward: 0.6000,                 loss: 0.1061
Episode: 17341/30000 (57.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2658s / 187.4784 s
agent0:                 episode reward: -0.4030,                 loss: nan
agent1:                 episode reward: 0.4030,                 loss: 0.1062
Episode: 17361/30000 (57.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2677s / 187.7461 s
agent0:                 episode reward: -0.7342,                 loss: nan
agent1:                 episode reward: 0.7342,                 loss: 0.1077
Episode: 17381/30000 (57.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2779s / 188.0240 s
agent0:                 episode reward: -0.7337,                 loss: nan
agent1:                 episode reward: 0.7337,                 loss: 0.1069
Episode: 17401/30000 (58.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2687s / 188.2926 s
agent0:                 episode reward: -0.3473,                 loss: nan
agent1:                 episode reward: 0.3473,                 loss: 0.1070
Episode: 17421/30000 (58.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2979s / 188.5905 s
agent0:                 episode reward: -0.8568,                 loss: nan
agent1:                 episode reward: 0.8568,                 loss: 0.1081
Episode: 17441/30000 (58.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2686s / 188.8591 s
agent0:                 episode reward: -0.8904,                 loss: nan
agent1:                 episode reward: 0.8904,                 loss: 0.1054
Episode: 17461/30000 (58.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2670s / 189.1261 s
agent0:                 episode reward: -0.5454,                 loss: nan
agent1:                 episode reward: 0.5454,                 loss: 0.1072
Episode: 17481/30000 (58.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2633s / 189.3894 s
agent0:                 episode reward: -0.2910,                 loss: nan
agent1:                 episode reward: 0.2910,                 loss: 0.1086
Episode: 17501/30000 (58.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2585s / 189.6479 s
agent0:                 episode reward: -0.9922,                 loss: nan
agent1:                 episode reward: 0.9922,                 loss: 0.1071
Episode: 17521/30000 (58.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2583s / 189.9062 s
agent0:                 episode reward: -1.1757,                 loss: nan
agent1:                 episode reward: 1.1757,                 loss: 0.1057
Episode: 17541/30000 (58.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2573s / 190.1635 s
agent0:                 episode reward: -0.3362,                 loss: nan
agent1:                 episode reward: 0.3362,                 loss: 0.1066
Episode: 17561/30000 (58.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2585s / 190.4220 s
agent0:                 episode reward: -0.8179,                 loss: nan
agent1:                 episode reward: 0.8179,                 loss: 0.1079
Episode: 17581/30000 (58.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2613s / 190.6833 s
agent0:                 episode reward: -0.8068,                 loss: nan
agent1:                 episode reward: 0.8068,                 loss: 0.1080
Episode: 17601/30000 (58.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2571s / 190.9404 s
agent0:                 episode reward: -0.4299,                 loss: nan
agent1:                 episode reward: 0.4299,                 loss: 0.1076
Episode: 17621/30000 (58.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2573s / 191.1977 s
agent0:                 episode reward: -0.4156,                 loss: nan
agent1:                 episode reward: 0.4156,                 loss: 0.1092
Episode: 17641/30000 (58.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2674s / 191.4651 s
agent0:                 episode reward: -0.4610,                 loss: nan
agent1:                 episode reward: 0.4610,                 loss: 0.1094
Episode: 17661/30000 (58.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2757s / 191.7408 s
agent0:                 episode reward: -0.4007,                 loss: nan
agent1:                 episode reward: 0.4007,                 loss: 0.1078
Episode: 17681/30000 (58.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2618s / 192.0026 s
agent0:                 episode reward: -0.4008,                 loss: nan
agent1:                 episode reward: 0.4008,                 loss: 0.1074
Episode: 17701/30000 (59.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2583s / 192.2609 s
agent0:                 episode reward: -0.5108,                 loss: nan
agent1:                 episode reward: 0.5108,                 loss: 0.1079
Episode: 17721/30000 (59.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2579s / 192.5188 s
agent0:                 episode reward: -0.2095,                 loss: nan
agent1:                 episode reward: 0.2095,                 loss: 0.1071
Episode: 17741/30000 (59.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2631s / 192.7819 s
agent0:                 episode reward: -0.3725,                 loss: nan
agent1:                 episode reward: 0.3725,                 loss: 0.1079
Episode: 17761/30000 (59.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2602s / 193.0421 s
agent0:                 episode reward: -0.7469,                 loss: nan
agent1:                 episode reward: 0.7469,                 loss: 0.1079
Episode: 17781/30000 (59.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2601s / 193.3022 s
agent0:                 episode reward: -0.4792,                 loss: nan
agent1:                 episode reward: 0.4792,                 loss: 0.1085
Episode: 17801/30000 (59.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2639s / 193.5661 s
agent0:                 episode reward: -0.5696,                 loss: nan
agent1:                 episode reward: 0.5696,                 loss: 0.1072
Episode: 17821/30000 (59.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2744s / 193.8404 s
agent0:                 episode reward: -0.5598,                 loss: nan
agent1:                 episode reward: 0.5598,                 loss: 0.1070
Episode: 17841/30000 (59.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2764s / 194.1169 s
agent0:                 episode reward: -0.9986,                 loss: nan
agent1:                 episode reward: 0.9986,                 loss: 0.1077
Episode: 17861/30000 (59.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2784s / 194.3952 s
agent0:                 episode reward: -0.6356,                 loss: nan
agent1:                 episode reward: 0.6356,                 loss: 0.1083
Episode: 17881/30000 (59.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3041s / 194.6993 s
agent0:                 episode reward: -1.1039,                 loss: nan
agent1:                 episode reward: 1.1039,                 loss: 0.1082
Episode: 17901/30000 (59.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2827s / 194.9819 s
agent0:                 episode reward: -0.7382,                 loss: nan
agent1:                 episode reward: 0.7382,                 loss: 0.1084
Episode: 17921/30000 (59.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2891s / 195.2711 s
agent0:                 episode reward: -0.4836,                 loss: nan
agent1:                 episode reward: 0.4836,                 loss: 0.1087
Episode: 17941/30000 (59.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2756s / 195.5466 s
agent0:                 episode reward: -0.5762,                 loss: nan
agent1:                 episode reward: 0.5762,                 loss: 0.1081
Episode: 17961/30000 (59.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2721s / 195.8187 s
agent0:                 episode reward: -0.7276,                 loss: nan
agent1:                 episode reward: 0.7276,                 loss: 0.1107
Episode: 17981/30000 (59.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2712s / 196.0898 s
agent0:                 episode reward: -0.6648,                 loss: nan
agent1:                 episode reward: 0.6648,                 loss: 0.1103
Episode: 18001/30000 (60.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2929s / 196.3827 s
agent0:                 episode reward: -0.3422,                 loss: nan
agent1:                 episode reward: 0.3422,                 loss: 0.1090
Episode: 18021/30000 (60.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2758s / 196.6586 s
agent0:                 episode reward: -0.3397,                 loss: nan
agent1:                 episode reward: 0.3397,                 loss: 0.1084
Episode: 18041/30000 (60.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2691s / 196.9276 s
agent0:                 episode reward: -0.5051,                 loss: nan
agent1:                 episode reward: 0.5051,                 loss: 0.1072
Episode: 18061/30000 (60.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2760s / 197.2037 s
agent0:                 episode reward: -0.5692,                 loss: nan
agent1:                 episode reward: 0.5692,                 loss: 0.1084
Episode: 18081/30000 (60.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2694s / 197.4730 s
agent0:                 episode reward: -0.4258,                 loss: nan
agent1:                 episode reward: 0.4258,                 loss: 0.1090
Episode: 18101/30000 (60.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3264s / 197.7994 s
agent0:                 episode reward: -0.4740,                 loss: nan
agent1:                 episode reward: 0.4740,                 loss: 0.1090
Episode: 18121/30000 (60.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2779s / 198.0773 s
agent0:                 episode reward: -0.9619,                 loss: nan
agent1:                 episode reward: 0.9619,                 loss: 0.1092
Episode: 18141/30000 (60.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2695s / 198.3468 s
agent0:                 episode reward: -0.2200,                 loss: nan
agent1:                 episode reward: 0.2200,                 loss: 0.1074
Episode: 18161/30000 (60.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2704s / 198.6172 s
agent0:                 episode reward: -0.4476,                 loss: nan
agent1:                 episode reward: 0.4476,                 loss: 0.1090
Episode: 18181/30000 (60.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2801s / 198.8973 s
agent0:                 episode reward: -0.3871,                 loss: nan
agent1:                 episode reward: 0.3871,                 loss: 0.1087
Episode: 18201/30000 (60.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2700s / 199.1673 s
agent0:                 episode reward: -0.6202,                 loss: nan
agent1:                 episode reward: 0.6202,                 loss: 0.1088
Episode: 18221/30000 (60.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2742s / 199.4415 s
agent0:                 episode reward: -0.4196,                 loss: nan
agent1:                 episode reward: 0.4196,                 loss: 0.1082
Episode: 18241/30000 (60.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2706s / 199.7121 s
agent0:                 episode reward: -0.7028,                 loss: nan
agent1:                 episode reward: 0.7028,                 loss: 0.1072
Episode: 18261/30000 (60.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2709s / 199.9830 s
agent0:                 episode reward: -0.5603,                 loss: nan
agent1:                 episode reward: 0.5603,                 loss: 0.1089
Episode: 18281/30000 (60.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2757s / 200.2588 s
agent0:                 episode reward: -0.7652,                 loss: nan
agent1:                 episode reward: 0.7652,                 loss: 0.1074
Episode: 18301/30000 (61.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2803s / 200.5390 s
agent0:                 episode reward: -0.5042,                 loss: nan
agent1:                 episode reward: 0.5042,                 loss: 0.1086
Episode: 18321/30000 (61.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2935s / 200.8326 s
agent0:                 episode reward: -0.2645,                 loss: nan
agent1:                 episode reward: 0.2645,                 loss: 0.1071
Episode: 18341/30000 (61.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2761s / 201.1087 s
agent0:                 episode reward: -0.8349,                 loss: nan
agent1:                 episode reward: 0.8349,                 loss: 0.1073
Episode: 18361/30000 (61.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2737s / 201.3824 s
agent0:                 episode reward: -0.1702,                 loss: nan
agent1:                 episode reward: 0.1702,                 loss: 0.1087
Episode: 18381/30000 (61.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2708s / 201.6531 s
agent0:                 episode reward: -0.6655,                 loss: nan
agent1:                 episode reward: 0.6655,                 loss: 0.1075
Episode: 18401/30000 (61.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2721s / 201.9253 s
agent0:                 episode reward: -0.7882,                 loss: nan
agent1:                 episode reward: 0.7882,                 loss: 0.1081
Episode: 18421/30000 (61.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2766s / 202.2018 s
agent0:                 episode reward: -0.6169,                 loss: nan
agent1:                 episode reward: 0.6169,                 loss: 0.1076
Episode: 18441/30000 (61.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2758s / 202.4776 s
agent0:                 episode reward: -0.7267,                 loss: nan
agent1:                 episode reward: 0.7267,                 loss: 0.1083
Episode: 18461/30000 (61.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2835s / 202.7612 s
agent0:                 episode reward: -0.9669,                 loss: nan
agent1:                 episode reward: 0.9669,                 loss: 0.1061
Episode: 18481/30000 (61.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2789s / 203.0401 s
agent0:                 episode reward: -0.5172,                 loss: nan
agent1:                 episode reward: 0.5172,                 loss: 0.1093
Episode: 18501/30000 (61.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2749s / 203.3149 s
agent0:                 episode reward: -0.6431,                 loss: nan
agent1:                 episode reward: 0.6431,                 loss: 0.1072
Episode: 18521/30000 (61.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2837s / 203.5987 s
agent0:                 episode reward: -0.5471,                 loss: nan
agent1:                 episode reward: 0.5471,                 loss: 0.1065
Episode: 18541/30000 (61.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2897s / 203.8883 s
agent0:                 episode reward: -0.6424,                 loss: nan
agent1:                 episode reward: 0.6424,                 loss: 0.1084
Episode: 18561/30000 (61.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2648s / 204.1532 s
agent0:                 episode reward: -0.2615,                 loss: nan
agent1:                 episode reward: 0.2615,                 loss: 0.1056
Episode: 18581/30000 (61.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2703s / 204.4235 s
agent0:                 episode reward: -0.6536,                 loss: nan
agent1:                 episode reward: 0.6536,                 loss: 0.1083
Episode: 18601/30000 (62.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2911s / 204.7146 s
agent0:                 episode reward: -0.3288,                 loss: nan
agent1:                 episode reward: 0.3288,                 loss: 0.1079
Episode: 18621/30000 (62.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2896s / 205.0042 s
agent0:                 episode reward: -0.9273,                 loss: nan
agent1:                 episode reward: 0.9273,                 loss: 0.1075
Episode: 18641/30000 (62.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2814s / 205.2856 s
agent0:                 episode reward: -0.3076,                 loss: nan
agent1:                 episode reward: 0.3076,                 loss: 0.1064
Episode: 18661/30000 (62.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2843s / 205.5699 s
agent0:                 episode reward: -0.3757,                 loss: nan
agent1:                 episode reward: 0.3757,                 loss: 0.1076
Episode: 18681/30000 (62.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2849s / 205.8548 s
agent0:                 episode reward: -0.6953,                 loss: nan
agent1:                 episode reward: 0.6953,                 loss: 0.1090
Episode: 18701/30000 (62.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2871s / 206.1419 s
agent0:                 episode reward: -0.7059,                 loss: nan
agent1:                 episode reward: 0.7059,                 loss: 0.1075
Episode: 18721/30000 (62.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2836s / 206.4255 s
agent0:                 episode reward: -0.1086,                 loss: nan
agent1:                 episode reward: 0.1086,                 loss: 0.1088
Episode: 18741/30000 (62.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2822s / 206.7077 s
agent0:                 episode reward: -0.5993,                 loss: nan
agent1:                 episode reward: 0.5993,                 loss: 0.1078
Episode: 18761/30000 (62.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3078s / 207.0155 s
agent0:                 episode reward: -0.6219,                 loss: nan
agent1:                 episode reward: 0.6219,                 loss: 0.1070
Episode: 18781/30000 (62.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2728s / 207.2883 s
agent0:                 episode reward: -0.6215,                 loss: nan
agent1:                 episode reward: 0.6215,                 loss: 0.1078
Episode: 18801/30000 (62.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2764s / 207.5647 s
agent0:                 episode reward: -0.7646,                 loss: nan
agent1:                 episode reward: 0.7646,                 loss: 0.1083
Episode: 18821/30000 (62.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2886s / 207.8533 s
agent0:                 episode reward: -0.6392,                 loss: nan
agent1:                 episode reward: 0.6392,                 loss: 0.1068
Episode: 18841/30000 (62.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2862s / 208.1395 s
agent0:                 episode reward: -0.4797,                 loss: nan
agent1:                 episode reward: 0.4797,                 loss: 0.1084
Episode: 18861/30000 (62.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2901s / 208.4296 s
agent0:                 episode reward: -0.6215,                 loss: nan
agent1:                 episode reward: 0.6215,                 loss: 0.1055
Episode: 18881/30000 (62.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2761s / 208.7057 s
agent0:                 episode reward: -0.3873,                 loss: nan
agent1:                 episode reward: 0.3873,                 loss: 0.1073
Episode: 18901/30000 (63.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2822s / 208.9879 s
agent0:                 episode reward: -0.6203,                 loss: nan
agent1:                 episode reward: 0.6203,                 loss: 0.1071
Episode: 18921/30000 (63.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2728s / 209.2607 s
agent0:                 episode reward: -0.6537,                 loss: nan
agent1:                 episode reward: 0.6537,                 loss: 0.1079
Episode: 18941/30000 (63.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2794s / 209.5401 s
agent0:                 episode reward: -0.7107,                 loss: nan
agent1:                 episode reward: 0.7107,                 loss: 0.1074
Episode: 18961/30000 (63.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2809s / 209.8210 s
agent0:                 episode reward: -0.3441,                 loss: nan
agent1:                 episode reward: 0.3441,                 loss: 0.1066
Episode: 18981/30000 (63.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2935s / 210.1145 s
agent0:                 episode reward: -0.7350,                 loss: nan
agent1:                 episode reward: 0.7350,                 loss: 0.1076
Episode: 19001/30000 (63.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2729s / 210.3874 s
agent0:                 episode reward: -0.3695,                 loss: nan
agent1:                 episode reward: 0.3695,                 loss: 0.1061
Episode: 19021/30000 (63.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2788s / 210.6661 s
agent0:                 episode reward: -0.6658,                 loss: nan
agent1:                 episode reward: 0.6658,                 loss: 0.1062
Episode: 19041/30000 (63.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2788s / 210.9449 s
agent0:                 episode reward: -0.7564,                 loss: nan
agent1:                 episode reward: 0.7564,                 loss: 0.1072
Episode: 19061/30000 (63.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2811s / 211.2260 s
agent0:                 episode reward: -0.5744,                 loss: nan
agent1:                 episode reward: 0.5744,                 loss: 0.1072
Episode: 19081/30000 (63.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2900s / 211.5159 s
agent0:                 episode reward: -0.5162,                 loss: nan
agent1:                 episode reward: 0.5162,                 loss: 0.1056
Episode: 19101/30000 (63.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2828s / 211.7988 s
agent0:                 episode reward: -0.8578,                 loss: nan
agent1:                 episode reward: 0.8578,                 loss: 0.1079
Episode: 19121/30000 (63.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2851s / 212.0839 s
agent0:                 episode reward: -0.3166,                 loss: nan
agent1:                 episode reward: 0.3166,                 loss: 0.1085
Episode: 19141/30000 (63.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2822s / 212.3661 s
agent0:                 episode reward: -0.5707,                 loss: nan
agent1:                 episode reward: 0.5707,                 loss: 0.1069
Episode: 19161/30000 (63.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2765s / 212.6426 s
agent0:                 episode reward: -0.5337,                 loss: nan
agent1:                 episode reward: 0.5337,                 loss: 0.1069
Episode: 19181/30000 (63.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3168s / 212.9594 s
agent0:                 episode reward: -0.7128,                 loss: nan
agent1:                 episode reward: 0.7128,                 loss: 0.1066
Episode: 19201/30000 (64.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3053s / 213.2647 s
agent0:                 episode reward: -0.5033,                 loss: nan
agent1:                 episode reward: 0.5033,                 loss: 0.1072
Episode: 19221/30000 (64.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2685s / 213.5332 s
agent0:                 episode reward: -0.6178,                 loss: nan
agent1:                 episode reward: 0.6178,                 loss: 0.1082
Episode: 19241/30000 (64.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2704s / 213.8036 s
agent0:                 episode reward: -0.6705,                 loss: nan
agent1:                 episode reward: 0.6705,                 loss: 0.1078
Episode: 19261/30000 (64.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2707s / 214.0744 s
agent0:                 episode reward: -0.6525,                 loss: nan
agent1:                 episode reward: 0.6525,                 loss: 0.1085
Episode: 19281/30000 (64.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2694s / 214.3438 s
agent0:                 episode reward: -0.6767,                 loss: nan
agent1:                 episode reward: 0.6767,                 loss: 0.1083
Episode: 19301/30000 (64.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2655s / 214.6093 s
agent0:                 episode reward: -0.8250,                 loss: nan
agent1:                 episode reward: 0.8250,                 loss: 0.1066
Episode: 19321/30000 (64.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2670s / 214.8763 s
agent0:                 episode reward: -0.8033,                 loss: nan
agent1:                 episode reward: 0.8033,                 loss: 0.1080
Episode: 19341/30000 (64.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2689s / 215.1453 s
agent0:                 episode reward: -0.5634,                 loss: nan
agent1:                 episode reward: 0.5634,                 loss: 0.1076
Episode: 19361/30000 (64.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2700s / 215.4152 s
agent0:                 episode reward: -0.6925,                 loss: nan
agent1:                 episode reward: 0.6925,                 loss: 0.1086
Episode: 19381/30000 (64.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2666s / 215.6818 s
agent0:                 episode reward: -0.4315,                 loss: nan
agent1:                 episode reward: 0.4315,                 loss: 0.1076
Episode: 19401/30000 (64.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2796s / 215.9613 s
agent0:                 episode reward: -0.8150,                 loss: nan
agent1:                 episode reward: 0.8150,                 loss: 0.1081
Episode: 19421/30000 (64.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2977s / 216.2590 s
agent0:                 episode reward: -0.8797,                 loss: nan
agent1:                 episode reward: 0.8797,                 loss: 0.1091
Episode: 19441/30000 (64.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2973s / 216.5563 s
agent0:                 episode reward: -0.8622,                 loss: nan
agent1:                 episode reward: 0.8622,                 loss: 0.1075
Episode: 19461/30000 (64.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2739s / 216.8302 s
agent0:                 episode reward: -0.4287,                 loss: nan
agent1:                 episode reward: 0.4287,                 loss: 0.1087
Episode: 19481/30000 (64.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2762s / 217.1064 s
agent0:                 episode reward: -0.4496,                 loss: nan
agent1:                 episode reward: 0.4496,                 loss: 0.1082
Episode: 19501/30000 (65.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2766s / 217.3830 s
agent0:                 episode reward: -0.7446,                 loss: nan
agent1:                 episode reward: 0.7446,                 loss: 0.1095
Episode: 19521/30000 (65.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2799s / 217.6628 s
agent0:                 episode reward: -0.7767,                 loss: nan
agent1:                 episode reward: 0.7767,                 loss: 0.1078
Episode: 19541/30000 (65.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2809s / 217.9437 s
agent0:                 episode reward: -0.4877,                 loss: nan
agent1:                 episode reward: 0.4877,                 loss: 0.1064
Episode: 19561/30000 (65.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2801s / 218.2238 s
agent0:                 episode reward: -0.7533,                 loss: nan
agent1:                 episode reward: 0.7533,                 loss: 0.1083
Episode: 19581/30000 (65.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2795s / 218.5033 s
agent0:                 episode reward: -0.5891,                 loss: nan
agent1:                 episode reward: 0.5891,                 loss: 0.1096
Episode: 19601/30000 (65.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2839s / 218.7872 s
agent0:                 episode reward: -0.5586,                 loss: nan
agent1:                 episode reward: 0.5586,                 loss: 0.1075
Episode: 19621/30000 (65.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2780s / 219.0653 s
agent0:                 episode reward: -0.7083,                 loss: nan
agent1:                 episode reward: 0.7083,                 loss: 0.1082
Episode: 19641/30000 (65.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2719s / 219.3372 s
agent0:                 episode reward: -0.4454,                 loss: nan
agent1:                 episode reward: 0.4454,                 loss: 0.1080
Episode: 19661/30000 (65.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2704s / 219.6075 s
agent0:                 episode reward: -0.7564,                 loss: nan
agent1:                 episode reward: 0.7564,                 loss: 0.1078
Episode: 19681/30000 (65.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2725s / 219.8800 s
agent0:                 episode reward: -0.7333,                 loss: nan
agent1:                 episode reward: 0.7333,                 loss: 0.1084
Episode: 19701/30000 (65.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2699s / 220.1499 s
agent0:                 episode reward: -0.6872,                 loss: nan
agent1:                 episode reward: 0.6872,                 loss: 0.1063
Episode: 19721/30000 (65.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2735s / 220.4234 s
agent0:                 episode reward: -0.7606,                 loss: nan
agent1:                 episode reward: 0.7606,                 loss: 0.1069
Episode: 19741/30000 (65.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2820s / 220.7054 s
agent0:                 episode reward: -0.4959,                 loss: nan
agent1:                 episode reward: 0.4959,                 loss: 0.1084
Episode: 19761/30000 (65.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3297s / 221.0351 s
agent0:                 episode reward: -0.3318,                 loss: nan
agent1:                 episode reward: 0.3318,                 loss: 0.1074
Episode: 19781/30000 (65.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3014s / 221.3365 s
agent0:                 episode reward: -0.3276,                 loss: nan
agent1:                 episode reward: 0.3276,                 loss: 0.1092
Episode: 19801/30000 (66.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3313s / 221.6679 s
agent0:                 episode reward: -0.8859,                 loss: nan
agent1:                 episode reward: 0.8859,                 loss: 0.1086
Episode: 19821/30000 (66.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3036s / 221.9714 s
agent0:                 episode reward: -0.6827,                 loss: nan
agent1:                 episode reward: 0.6827,                 loss: 0.1079
Episode: 19841/30000 (66.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2895s / 222.2609 s
agent0:                 episode reward: -0.5983,                 loss: nan
agent1:                 episode reward: 0.5983,                 loss: 0.1079
Episode: 19861/30000 (66.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2827s / 222.5436 s
agent0:                 episode reward: -0.5842,                 loss: nan
agent1:                 episode reward: 0.5842,                 loss: 0.1071
Episode: 19881/30000 (66.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2876s / 222.8312 s
agent0:                 episode reward: -0.7510,                 loss: nan
agent1:                 episode reward: 0.7510,                 loss: 0.1078
Episode: 19901/30000 (66.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2879s / 223.1191 s
agent0:                 episode reward: -0.6836,                 loss: nan
agent1:                 episode reward: 0.6836,                 loss: 0.1075
Episode: 19921/30000 (66.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2827s / 223.4019 s
agent0:                 episode reward: -0.8332,                 loss: nan
agent1:                 episode reward: 0.8332,                 loss: 0.1081
Episode: 19941/30000 (66.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2867s / 223.6886 s
agent0:                 episode reward: -0.6054,                 loss: nan
agent1:                 episode reward: 0.6054,                 loss: 0.1090
Episode: 19961/30000 (66.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2885s / 223.9771 s
agent0:                 episode reward: -0.6456,                 loss: nan
agent1:                 episode reward: 0.6456,                 loss: 0.1084
Episode: 19981/30000 (66.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2953s / 224.2724 s
agent0:                 episode reward: -0.2964,                 loss: nan
agent1:                 episode reward: 0.2964,                 loss: 0.1086
Episode: 20001/30000 (66.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2860s / 224.5584 s
agent0:                 episode reward: -0.6546,                 loss: nan
agent1:                 episode reward: 0.6546,                 loss: 0.1076
Episode: 20021/30000 (66.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2965s / 224.8549 s
agent0:                 episode reward: -0.4882,                 loss: nan
agent1:                 episode reward: 0.4882,                 loss: 0.1071
Episode: 20041/30000 (66.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2916s / 225.1465 s
agent0:                 episode reward: -0.7552,                 loss: nan
agent1:                 episode reward: 0.7552,                 loss: 0.1066
Episode: 20061/30000 (66.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2759s / 225.4224 s
agent0:                 episode reward: -0.4897,                 loss: nan
agent1:                 episode reward: 0.4897,                 loss: 0.1091
Episode: 20081/30000 (66.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2717s / 225.6941 s
agent0:                 episode reward: -0.6336,                 loss: nan
agent1:                 episode reward: 0.6336,                 loss: 0.1085
Episode: 20101/30000 (67.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2722s / 225.9663 s
agent0:                 episode reward: -0.2150,                 loss: nan
agent1:                 episode reward: 0.2150,                 loss: 0.1079
Episode: 20121/30000 (67.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2760s / 226.2423 s
agent0:                 episode reward: -0.6928,                 loss: nan
agent1:                 episode reward: 0.6928,                 loss: 0.1091
Episode: 20141/30000 (67.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2729s / 226.5152 s
agent0:                 episode reward: -0.7357,                 loss: nan
agent1:                 episode reward: 0.7357,                 loss: 0.1085
Episode: 20161/30000 (67.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2741s / 226.7894 s
agent0:                 episode reward: -0.5401,                 loss: nan
agent1:                 episode reward: 0.5401,                 loss: 0.1069
Episode: 20181/30000 (67.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2746s / 227.0640 s
agent0:                 episode reward: -0.9148,                 loss: nan
agent1:                 episode reward: 0.9148,                 loss: 0.1071
Episode: 20201/30000 (67.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2767s / 227.3407 s
agent0:                 episode reward: -0.4668,                 loss: nan
agent1:                 episode reward: 0.4668,                 loss: 0.1076
Episode: 20221/30000 (67.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2762s / 227.6169 s
agent0:                 episode reward: -0.3294,                 loss: nan
agent1:                 episode reward: 0.3294,                 loss: 0.1060
Episode: 20241/30000 (67.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2929s / 227.9098 s
agent0:                 episode reward: -0.4209,                 loss: nan
agent1:                 episode reward: 0.4209,                 loss: 0.1046
Episode: 20261/30000 (67.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2860s / 228.1958 s
agent0:                 episode reward: -0.4079,                 loss: nan
agent1:                 episode reward: 0.4079,                 loss: 0.1054
Episode: 20281/30000 (67.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2808s / 228.4767 s
agent0:                 episode reward: -0.7285,                 loss: nan
agent1:                 episode reward: 0.7285,                 loss: 0.1038
Episode: 20301/30000 (67.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2812s / 228.7579 s
agent0:                 episode reward: -0.9015,                 loss: nan
agent1:                 episode reward: 0.9015,                 loss: 0.1056
Episode: 20321/30000 (67.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2779s / 229.0358 s
agent0:                 episode reward: -0.5365,                 loss: nan
agent1:                 episode reward: 0.5365,                 loss: 0.1055
Episode: 20341/30000 (67.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2758s / 229.3115 s
agent0:                 episode reward: -0.8682,                 loss: nan
agent1:                 episode reward: 0.8682,                 loss: 0.1045
Episode: 20361/30000 (67.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2744s / 229.5859 s
agent0:                 episode reward: -0.7097,                 loss: nan
agent1:                 episode reward: 0.7097,                 loss: 0.1056
Episode: 20381/30000 (67.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3121s / 229.8980 s
agent0:                 episode reward: -0.5717,                 loss: nan
agent1:                 episode reward: 0.5717,                 loss: 0.1045
Episode: 20401/30000 (68.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2936s / 230.1916 s
agent0:                 episode reward: -0.4841,                 loss: nan
agent1:                 episode reward: 0.4841,                 loss: 0.1061
Episode: 20421/30000 (68.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2928s / 230.4844 s
agent0:                 episode reward: -0.5155,                 loss: nan
agent1:                 episode reward: 0.5155,                 loss: 0.1045
Episode: 20441/30000 (68.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3015s / 230.7858 s
agent0:                 episode reward: -0.7836,                 loss: nan
agent1:                 episode reward: 0.7836,                 loss: 0.1046
Episode: 20461/30000 (68.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3308s / 231.1166 s
agent0:                 episode reward: -0.6720,                 loss: nan
agent1:                 episode reward: 0.6720,                 loss: 0.1034
Episode: 20481/30000 (68.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2937s / 231.4103 s
agent0:                 episode reward: -0.7179,                 loss: nan
agent1:                 episode reward: 0.7179,                 loss: 0.1056
Episode: 20501/30000 (68.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2892s / 231.6995 s
agent0:                 episode reward: -0.6046,                 loss: nan
agent1:                 episode reward: 0.6046,                 loss: 0.1055
Episode: 20521/30000 (68.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2942s / 231.9938 s
agent0:                 episode reward: -0.7147,                 loss: nan
agent1:                 episode reward: 0.7147,                 loss: 0.1059
Episode: 20541/30000 (68.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2921s / 232.2858 s
agent0:                 episode reward: -0.9595,                 loss: nan
agent1:                 episode reward: 0.9595,                 loss: 0.1052
Episode: 20561/30000 (68.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2913s / 232.5771 s
agent0:                 episode reward: -0.8277,                 loss: nan
agent1:                 episode reward: 0.8277,                 loss: 0.1070
Episode: 20581/30000 (68.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3065s / 232.8836 s
agent0:                 episode reward: -0.4229,                 loss: nan
agent1:                 episode reward: 0.4229,                 loss: 0.1068
Episode: 20601/30000 (68.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2873s / 233.1709 s
agent0:                 episode reward: -0.5987,                 loss: nan
agent1:                 episode reward: 0.5987,                 loss: 0.1072
Episode: 20621/30000 (68.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2911s / 233.4620 s
agent0:                 episode reward: -1.0828,                 loss: nan
agent1:                 episode reward: 1.0828,                 loss: 0.1052
Episode: 20641/30000 (68.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2891s / 233.7511 s
agent0:                 episode reward: -1.0061,                 loss: nan
agent1:                 episode reward: 1.0061,                 loss: 0.1069
Episode: 20661/30000 (68.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3143s / 234.0654 s
agent0:                 episode reward: -0.3376,                 loss: nan
agent1:                 episode reward: 0.3376,                 loss: 0.1068
Episode: 20681/30000 (68.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2854s / 234.3508 s
agent0:                 episode reward: -0.3937,                 loss: nan
agent1:                 episode reward: 0.3937,                 loss: 0.1059
Episode: 20701/30000 (69.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2860s / 234.6367 s
agent0:                 episode reward: -0.6027,                 loss: nan
agent1:                 episode reward: 0.6027,                 loss: 0.1083
Episode: 20721/30000 (69.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2851s / 234.9218 s
agent0:                 episode reward: -0.8004,                 loss: nan
agent1:                 episode reward: 0.8004,                 loss: 0.1062
Episode: 20741/30000 (69.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2955s / 235.2173 s
agent0:                 episode reward: -0.7204,                 loss: nan
agent1:                 episode reward: 0.7204,                 loss: 0.1065
Episode: 20761/30000 (69.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2942s / 235.5115 s
agent0:                 episode reward: -0.7799,                 loss: nan
agent1:                 episode reward: 0.7799,                 loss: 0.1055
Episode: 20781/30000 (69.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3111s / 235.8227 s
agent0:                 episode reward: -0.6453,                 loss: nan
agent1:                 episode reward: 0.6453,                 loss: 0.1079
Episode: 20801/30000 (69.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3146s / 236.1372 s
agent0:                 episode reward: -0.6636,                 loss: nan
agent1:                 episode reward: 0.6636,                 loss: 0.1062
Episode: 20821/30000 (69.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3023s / 236.4396 s
agent0:                 episode reward: -0.7092,                 loss: nan
agent1:                 episode reward: 0.7092,                 loss: 0.1070
Episode: 20841/30000 (69.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2919s / 236.7315 s
agent0:                 episode reward: -0.8176,                 loss: nan
agent1:                 episode reward: 0.8176,                 loss: 0.1063
Episode: 20861/30000 (69.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3087s / 237.0401 s
agent0:                 episode reward: -0.6668,                 loss: nan
agent1:                 episode reward: 0.6668,                 loss: 0.1067
Episode: 20881/30000 (69.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3016s / 237.3417 s
agent0:                 episode reward: -0.6478,                 loss: nan
agent1:                 episode reward: 0.6478,                 loss: 0.1076
Episode: 20901/30000 (69.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2852s / 237.6269 s
agent0:                 episode reward: -0.6538,                 loss: nan
agent1:                 episode reward: 0.6538,                 loss: 0.1077
Episode: 20921/30000 (69.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3047s / 237.9317 s
agent0:                 episode reward: -0.5890,                 loss: nan
agent1:                 episode reward: 0.5890,                 loss: 0.1053
Episode: 20941/30000 (69.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3055s / 238.2371 s
agent0:                 episode reward: -0.4771,                 loss: nan
agent1:                 episode reward: 0.4771,                 loss: 0.1063
Episode: 20961/30000 (69.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3026s / 238.5397 s
agent0:                 episode reward: -0.4817,                 loss: nan
agent1:                 episode reward: 0.4817,                 loss: 0.1064
Episode: 20981/30000 (69.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3058s / 238.8455 s
agent0:                 episode reward: -0.6182,                 loss: nan
agent1:                 episode reward: 0.6182,                 loss: 0.1068
Episode: 21001/30000 (70.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3087s / 239.1542 s
agent0:                 episode reward: -0.8946,                 loss: nan
agent1:                 episode reward: 0.8946,                 loss: 0.1054
Episode: 21021/30000 (70.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2773s / 239.4315 s
agent0:                 episode reward: -0.6754,                 loss: nan
agent1:                 episode reward: 0.6754,                 loss: 0.1061
Episode: 21041/30000 (70.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2789s / 239.7105 s
agent0:                 episode reward: -0.7299,                 loss: nan
agent1:                 episode reward: 0.7299,                 loss: 0.1077
Episode: 21061/30000 (70.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2782s / 239.9886 s
agent0:                 episode reward: -0.2179,                 loss: nan
agent1:                 episode reward: 0.2179,                 loss: 0.1069
Episode: 21081/30000 (70.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2832s / 240.2718 s
agent0:                 episode reward: -0.6022,                 loss: nan
agent1:                 episode reward: 0.6022,                 loss: 0.1063
Episode: 21101/30000 (70.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2904s / 240.5622 s
agent0:                 episode reward: -0.8199,                 loss: nan
agent1:                 episode reward: 0.8199,                 loss: 0.1070
Episode: 21121/30000 (70.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2937s / 240.8559 s
agent0:                 episode reward: -0.3605,                 loss: nan
agent1:                 episode reward: 0.3605,                 loss: 0.1078
Episode: 21141/30000 (70.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2924s / 241.1483 s
agent0:                 episode reward: -0.5811,                 loss: nan
agent1:                 episode reward: 0.5811,                 loss: 0.1078
Episode: 21161/30000 (70.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2913s / 241.4396 s
agent0:                 episode reward: -0.7167,                 loss: nan
agent1:                 episode reward: 0.7167,                 loss: 0.1073
Episode: 21181/30000 (70.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2905s / 241.7301 s
agent0:                 episode reward: -0.7376,                 loss: nan
agent1:                 episode reward: 0.7376,                 loss: 0.1063
Episode: 21201/30000 (70.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2929s / 242.0230 s
agent0:                 episode reward: -0.6280,                 loss: nan
agent1:                 episode reward: 0.6280,                 loss: 0.1050
Episode: 21221/30000 (70.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2937s / 242.3168 s
agent0:                 episode reward: -0.9492,                 loss: nan
agent1:                 episode reward: 0.9492,                 loss: 0.1058
Episode: 21241/30000 (70.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3159s / 242.6327 s
agent0:                 episode reward: -0.3588,                 loss: nan
agent1:                 episode reward: 0.3588,                 loss: 0.1067
Episode: 21261/30000 (70.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3107s / 242.9434 s
agent0:                 episode reward: -0.5807,                 loss: nan
agent1:                 episode reward: 0.5807,                 loss: 0.1052
Episode: 21281/30000 (70.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2923s / 243.2357 s
agent0:                 episode reward: -0.5967,                 loss: nan
agent1:                 episode reward: 0.5967,                 loss: 0.1055
Episode: 21301/30000 (71.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2924s / 243.5281 s
agent0:                 episode reward: -0.9113,                 loss: nan
agent1:                 episode reward: 0.9113,                 loss: 0.1051
Episode: 21321/30000 (71.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2987s / 243.8268 s
agent0:                 episode reward: -0.5966,                 loss: nan
agent1:                 episode reward: 0.5966,                 loss: 0.1052
Episode: 21341/30000 (71.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2940s / 244.1208 s
agent0:                 episode reward: -0.7050,                 loss: nan
agent1:                 episode reward: 0.7050,                 loss: 0.1048
Episode: 21361/30000 (71.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2942s / 244.4150 s
agent0:                 episode reward: -0.9308,                 loss: nan
agent1:                 episode reward: 0.9308,                 loss: 0.1058
Episode: 21381/30000 (71.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2938s / 244.7088 s
agent0:                 episode reward: -0.7803,                 loss: nan
agent1:                 episode reward: 0.7803,                 loss: 0.1054
Episode: 21401/30000 (71.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2921s / 245.0008 s
agent0:                 episode reward: -0.7102,                 loss: nan
agent1:                 episode reward: 0.7102,                 loss: 0.1056
Episode: 21421/30000 (71.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2963s / 245.2972 s
agent0:                 episode reward: -0.8861,                 loss: nan
agent1:                 episode reward: 0.8861,                 loss: 0.1072
Episode: 21441/30000 (71.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2990s / 245.5961 s
agent0:                 episode reward: -0.3125,                 loss: nan
agent1:                 episode reward: 0.3125,                 loss: 0.1073
Episode: 21461/30000 (71.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3192s / 245.9153 s
agent0:                 episode reward: -0.7042,                 loss: nan
agent1:                 episode reward: 0.7042,                 loss: 0.1067
Episode: 21481/30000 (71.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3171s / 246.2324 s
agent0:                 episode reward: -0.5172,                 loss: nan
agent1:                 episode reward: 0.5172,                 loss: 0.1057
Episode: 21501/30000 (71.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2842s / 246.5166 s
agent0:                 episode reward: -0.8068,                 loss: nan
agent1:                 episode reward: 0.8068,                 loss: 0.1046
Episode: 21521/30000 (71.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2850s / 246.8017 s
agent0:                 episode reward: -0.6226,                 loss: nan
agent1:                 episode reward: 0.6226,                 loss: 0.1056
Episode: 21541/30000 (71.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2785s / 247.0802 s
agent0:                 episode reward: -0.8341,                 loss: nan
agent1:                 episode reward: 0.8341,                 loss: 0.1058
Episode: 21561/30000 (71.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2796s / 247.3598 s
agent0:                 episode reward: -0.4857,                 loss: nan
agent1:                 episode reward: 0.4857,                 loss: 0.1065
Episode: 21581/30000 (71.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2798s / 247.6397 s
agent0:                 episode reward: -0.6413,                 loss: nan
agent1:                 episode reward: 0.6413,                 loss: 0.1055
Episode: 21601/30000 (72.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2792s / 247.9189 s
agent0:                 episode reward: -0.4791,                 loss: nan
agent1:                 episode reward: 0.4791,                 loss: 0.1062
Episode: 21621/30000 (72.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2831s / 248.2020 s
agent0:                 episode reward: -0.8510,                 loss: nan
agent1:                 episode reward: 0.8510,                 loss: 0.1067
Episode: 21641/30000 (72.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2857s / 248.4877 s
agent0:                 episode reward: -0.8841,                 loss: nan
agent1:                 episode reward: 0.8841,                 loss: 0.1058
Episode: 21661/30000 (72.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3011s / 248.7888 s
agent0:                 episode reward: -0.7114,                 loss: nan
agent1:                 episode reward: 0.7114,                 loss: 0.1065
Episode: 21681/30000 (72.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3010s / 249.0898 s
agent0:                 episode reward: -0.5652,                 loss: nan
agent1:                 episode reward: 0.5652,                 loss: 0.1069
Episode: 21701/30000 (72.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2895s / 249.3793 s
agent0:                 episode reward: -0.5833,                 loss: nan
agent1:                 episode reward: 0.5833,                 loss: 0.1064
Episode: 21721/30000 (72.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2877s / 249.6670 s
agent0:                 episode reward: -0.7039,                 loss: nan
agent1:                 episode reward: 0.7039,                 loss: 0.1046
Episode: 21741/30000 (72.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3022s / 249.9693 s
agent0:                 episode reward: -0.5954,                 loss: nan
agent1:                 episode reward: 0.5954,                 loss: 0.1056
Episode: 21761/30000 (72.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3026s / 250.2719 s
agent0:                 episode reward: -0.4236,                 loss: nan
agent1:                 episode reward: 0.4236,                 loss: 0.1065
Episode: 21781/30000 (72.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3003s / 250.5721 s
agent0:                 episode reward: -0.6190,                 loss: nan
agent1:                 episode reward: 0.6190,                 loss: 0.1060
Episode: 21801/30000 (72.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3013s / 250.8734 s
agent0:                 episode reward: -0.7094,                 loss: nan
agent1:                 episode reward: 0.7094,                 loss: 0.1054
Episode: 21821/30000 (72.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2864s / 251.1598 s
agent0:                 episode reward: -0.6014,                 loss: nan
agent1:                 episode reward: 0.6014,                 loss: 0.1062
Episode: 21841/30000 (72.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2858s / 251.4456 s
agent0:                 episode reward: -0.6832,                 loss: nan
agent1:                 episode reward: 0.6832,                 loss: 0.1061
Episode: 21861/30000 (72.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2858s / 251.7313 s
agent0:                 episode reward: -0.6618,                 loss: nan
agent1:                 episode reward: 0.6618,                 loss: 0.1063
Episode: 21881/30000 (72.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3059s / 252.0372 s
agent0:                 episode reward: -0.7670,                 loss: nan
agent1:                 episode reward: 0.7670,                 loss: 0.1054
Episode: 21901/30000 (73.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2894s / 252.3267 s
agent0:                 episode reward: -0.4798,                 loss: nan
agent1:                 episode reward: 0.4798,                 loss: 0.1083
Episode: 21921/30000 (73.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2882s / 252.6148 s
agent0:                 episode reward: -0.5563,                 loss: nan
agent1:                 episode reward: 0.5563,                 loss: 0.1082
Episode: 21941/30000 (73.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3031s / 252.9180 s
agent0:                 episode reward: -0.5580,                 loss: nan
agent1:                 episode reward: 0.5580,                 loss: 0.1075
Episode: 21961/30000 (73.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3080s / 253.2260 s
agent0:                 episode reward: -0.5675,                 loss: nan
agent1:                 episode reward: 0.5675,                 loss: 0.1074
Episode: 21981/30000 (73.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3081s / 253.5341 s
agent0:                 episode reward: -0.7268,                 loss: nan
agent1:                 episode reward: 0.7268,                 loss: 0.1070
Episode: 22001/30000 (73.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3167s / 253.8509 s
agent0:                 episode reward: -0.7986,                 loss: nan
agent1:                 episode reward: 0.7986,                 loss: 0.1061
Episode: 22021/30000 (73.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3048s / 254.1556 s
agent0:                 episode reward: -0.5402,                 loss: nan
agent1:                 episode reward: 0.5402,                 loss: 0.1074
Episode: 22041/30000 (73.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3026s / 254.4582 s
agent0:                 episode reward: -0.6453,                 loss: nan
agent1:                 episode reward: 0.6453,                 loss: 0.1054
Episode: 22061/30000 (73.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3286s / 254.7868 s
agent0:                 episode reward: -0.4540,                 loss: nan
agent1:                 episode reward: 0.4540,                 loss: 0.1069
Episode: 22081/30000 (73.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3281s / 255.1149 s
agent0:                 episode reward: -0.9777,                 loss: nan
agent1:                 episode reward: 0.9777,                 loss: 0.1060
Episode: 22101/30000 (73.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3040s / 255.4189 s
agent0:                 episode reward: -0.5297,                 loss: nan
agent1:                 episode reward: 0.5297,                 loss: 0.1068
Episode: 22121/30000 (73.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3082s / 255.7270 s
agent0:                 episode reward: -0.5857,                 loss: nan
agent1:                 episode reward: 0.5857,                 loss: 0.1065
Episode: 22141/30000 (73.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3063s / 256.0333 s
agent0:                 episode reward: -0.8752,                 loss: nan
agent1:                 episode reward: 0.8752,                 loss: 0.1055
Episode: 22161/30000 (73.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3078s / 256.3412 s
agent0:                 episode reward: -1.1348,                 loss: nan
agent1:                 episode reward: 1.1348,                 loss: 0.1074
Episode: 22181/30000 (73.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3021s / 256.6433 s
agent0:                 episode reward: -0.8395,                 loss: nan
agent1:                 episode reward: 0.8395,                 loss: 0.1063
Episode: 22201/30000 (74.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2995s / 256.9428 s
agent0:                 episode reward: -0.6271,                 loss: nan
agent1:                 episode reward: 0.6271,                 loss: 0.1082
Episode: 22221/30000 (74.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3012s / 257.2440 s
agent0:                 episode reward: -0.7157,                 loss: nan
agent1:                 episode reward: 0.7157,                 loss: 0.1066
Episode: 22241/30000 (74.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3067s / 257.5507 s
agent0:                 episode reward: -0.5381,                 loss: nan
agent1:                 episode reward: 0.5381,                 loss: 0.1046
Episode: 22261/30000 (74.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3119s / 257.8626 s
agent0:                 episode reward: -0.4301,                 loss: nan
agent1:                 episode reward: 0.4301,                 loss: 0.1071
Episode: 22281/30000 (74.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3311s / 258.1937 s
agent0:                 episode reward: -0.5215,                 loss: nan
agent1:                 episode reward: 0.5215,                 loss: 0.1048
Episode: 22301/30000 (74.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3102s / 258.5039 s
agent0:                 episode reward: -0.5114,                 loss: nan
agent1:                 episode reward: 0.5114,                 loss: 0.1057
Episode: 22321/30000 (74.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3062s / 258.8101 s
agent0:                 episode reward: -0.5793,                 loss: nan
agent1:                 episode reward: 0.5793,                 loss: 0.1052
Episode: 22341/30000 (74.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3044s / 259.1145 s
agent0:                 episode reward: -0.4868,                 loss: nan
agent1:                 episode reward: 0.4868,                 loss: 0.1057
Episode: 22361/30000 (74.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3074s / 259.4218 s
agent0:                 episode reward: -0.5612,                 loss: nan
agent1:                 episode reward: 0.5612,                 loss: 0.1053
Episode: 22381/30000 (74.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3053s / 259.7272 s
agent0:                 episode reward: -0.7885,                 loss: nan
agent1:                 episode reward: 0.7885,                 loss: 0.1047
Episode: 22401/30000 (74.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3062s / 260.0333 s
agent0:                 episode reward: -0.5531,                 loss: nan
agent1:                 episode reward: 0.5531,                 loss: 0.1055
Episode: 22421/30000 (74.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3020s / 260.3353 s
agent0:                 episode reward: -0.4056,                 loss: nan
agent1:                 episode reward: 0.4056,                 loss: 0.1065
Episode: 22441/30000 (74.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3038s / 260.6391 s
agent0:                 episode reward: -0.5898,                 loss: nan
agent1:                 episode reward: 0.5898,                 loss: 0.1060
Episode: 22461/30000 (74.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3166s / 260.9557 s
agent0:                 episode reward: -0.7972,                 loss: nan
agent1:                 episode reward: 0.7972,                 loss: 0.1040
Episode: 22481/30000 (74.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3236s / 261.2793 s
agent0:                 episode reward: -0.7405,                 loss: nan
agent1:                 episode reward: 0.7405,                 loss: 0.1068
Episode: 22501/30000 (75.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3108s / 261.5901 s
agent0:                 episode reward: -0.9465,                 loss: nan
agent1:                 episode reward: 0.9465,                 loss: 0.1048
Episode: 22521/30000 (75.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3040s / 261.8941 s
agent0:                 episode reward: -0.3517,                 loss: nan
agent1:                 episode reward: 0.3517,                 loss: 0.1045
Episode: 22541/30000 (75.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3064s / 262.2006 s
agent0:                 episode reward: -0.2847,                 loss: nan
agent1:                 episode reward: 0.2847,                 loss: 0.1064
Episode: 22561/30000 (75.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3065s / 262.5071 s
agent0:                 episode reward: -0.5146,                 loss: nan
agent1:                 episode reward: 0.5146,                 loss: 0.1060
Episode: 22581/30000 (75.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3045s / 262.8116 s
agent0:                 episode reward: -0.7570,                 loss: nan
agent1:                 episode reward: 0.7570,                 loss: 0.1050
Episode: 22601/30000 (75.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3234s / 263.1349 s
agent0:                 episode reward: -0.2467,                 loss: nan
agent1:                 episode reward: 0.2467,                 loss: 0.1064
Episode: 22621/30000 (75.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3001s / 263.4350 s
agent0:                 episode reward: -0.6569,                 loss: nan
agent1:                 episode reward: 0.6569,                 loss: 0.1064
Episode: 22641/30000 (75.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3070s / 263.7420 s
agent0:                 episode reward: -0.3192,                 loss: nan
agent1:                 episode reward: 0.3192,                 loss: 0.1047
Episode: 22661/30000 (75.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3099s / 264.0520 s
agent0:                 episode reward: -0.5891,                 loss: nan
agent1:                 episode reward: 0.5891,                 loss: 0.1062
Episode: 22681/30000 (75.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3056s / 264.3575 s
agent0:                 episode reward: -0.1413,                 loss: nan
agent1:                 episode reward: 0.1413,                 loss: 0.1068
Episode: 22701/30000 (75.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3071s / 264.6646 s
agent0:                 episode reward: -0.9457,                 loss: nan
agent1:                 episode reward: 0.9457,                 loss: 0.1069
Episode: 22721/30000 (75.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3038s / 264.9685 s
agent0:                 episode reward: -0.7672,                 loss: nan
agent1:                 episode reward: 0.7672,                 loss: 0.1063
Episode: 22741/30000 (75.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3056s / 265.2741 s
agent0:                 episode reward: -0.6031,                 loss: nan
agent1:                 episode reward: 0.6031,                 loss: 0.1057
Episode: 22761/30000 (75.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2877s / 265.5618 s
agent0:                 episode reward: -0.7438,                 loss: nan
agent1:                 episode reward: 0.7438,                 loss: 0.1051
Episode: 22781/30000 (75.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2926s / 265.8544 s
agent0:                 episode reward: -0.5565,                 loss: nan
agent1:                 episode reward: 0.5565,                 loss: 0.1055
Episode: 22801/30000 (76.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2926s / 266.1470 s
agent0:                 episode reward: -0.4942,                 loss: nan
agent1:                 episode reward: 0.4942,                 loss: 0.1059
Episode: 22821/30000 (76.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2964s / 266.4434 s
agent0:                 episode reward: -0.9819,                 loss: nan
agent1:                 episode reward: 0.9819,                 loss: 0.1052
Episode: 22841/30000 (76.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3010s / 266.7445 s
agent0:                 episode reward: -0.3344,                 loss: nan
agent1:                 episode reward: 0.3344,                 loss: 0.1066
Episode: 22861/30000 (76.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3128s / 267.0573 s
agent0:                 episode reward: -0.6905,                 loss: nan
agent1:                 episode reward: 0.6905,                 loss: 0.1045
Episode: 22881/30000 (76.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2954s / 267.3527 s
agent0:                 episode reward: -0.3966,                 loss: nan
agent1:                 episode reward: 0.3966,                 loss: 0.1054
Episode: 22901/30000 (76.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2945s / 267.6472 s
agent0:                 episode reward: -0.2482,                 loss: nan
agent1:                 episode reward: 0.2482,                 loss: 0.1047
Episode: 22921/30000 (76.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2965s / 267.9438 s
agent0:                 episode reward: -0.5369,                 loss: nan
agent1:                 episode reward: 0.5369,                 loss: 0.1060
Episode: 22941/30000 (76.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2920s / 268.2357 s
agent0:                 episode reward: -0.8862,                 loss: nan
agent1:                 episode reward: 0.8862,                 loss: 0.1049
Episode: 22961/30000 (76.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2956s / 268.5313 s
agent0:                 episode reward: -0.9995,                 loss: nan
agent1:                 episode reward: 0.9995,                 loss: 0.1039
Episode: 22981/30000 (76.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3002s / 268.8315 s
agent0:                 episode reward: -0.6963,                 loss: nan
agent1:                 episode reward: 0.6963,                 loss: 0.1038
Episode: 23001/30000 (76.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2981s / 269.1296 s
agent0:                 episode reward: -0.7435,                 loss: nan
agent1:                 episode reward: 0.7435,                 loss: 0.1048
Episode: 23021/30000 (76.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3042s / 269.4339 s
agent0:                 episode reward: -0.7892,                 loss: nan
agent1:                 episode reward: 0.7892,                 loss: 0.1039
Episode: 23041/30000 (76.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3003s / 269.7341 s
agent0:                 episode reward: -0.5761,                 loss: nan
agent1:                 episode reward: 0.5761,                 loss: 0.1044
Episode: 23061/30000 (76.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3375s / 270.0716 s
agent0:                 episode reward: -0.4908,                 loss: nan
agent1:                 episode reward: 0.4908,                 loss: 0.1046
Episode: 23081/30000 (76.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3305s / 270.4021 s
agent0:                 episode reward: -0.4224,                 loss: nan
agent1:                 episode reward: 0.4224,                 loss: 0.1039
Episode: 23101/30000 (77.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3138s / 270.7159 s
agent0:                 episode reward: -0.5711,                 loss: nan
agent1:                 episode reward: 0.5711,                 loss: 0.1042
Episode: 23121/30000 (77.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3092s / 271.0251 s
agent0:                 episode reward: -0.5413,                 loss: nan
agent1:                 episode reward: 0.5413,                 loss: 0.1046
Episode: 23141/30000 (77.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3236s / 271.3487 s
agent0:                 episode reward: -0.0684,                 loss: nan
agent1:                 episode reward: 0.0684,                 loss: 0.1046
Episode: 23161/30000 (77.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3036s / 271.6522 s
agent0:                 episode reward: -0.4533,                 loss: nan
agent1:                 episode reward: 0.4533,                 loss: 0.1040
Episode: 23181/30000 (77.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3014s / 271.9536 s
agent0:                 episode reward: -0.6331,                 loss: nan
agent1:                 episode reward: 0.6331,                 loss: 0.1049
Episode: 23201/30000 (77.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2972s / 272.2508 s
agent0:                 episode reward: -0.8643,                 loss: nan
agent1:                 episode reward: 0.8643,                 loss: 0.1049
Episode: 23221/30000 (77.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2928s / 272.5436 s
agent0:                 episode reward: -0.7122,                 loss: nan
agent1:                 episode reward: 0.7122,                 loss: 0.1024
Episode: 23241/30000 (77.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2970s / 272.8406 s
agent0:                 episode reward: -0.6384,                 loss: nan
agent1:                 episode reward: 0.6384,                 loss: 0.1068
Episode: 23261/30000 (77.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3209s / 273.1616 s
agent0:                 episode reward: -0.6189,                 loss: nan
agent1:                 episode reward: 0.6189,                 loss: 0.1042
Episode: 23281/30000 (77.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3018s / 273.4634 s
agent0:                 episode reward: -0.5958,                 loss: nan
agent1:                 episode reward: 0.5958,                 loss: 0.1051
Episode: 23301/30000 (77.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3007s / 273.7641 s
agent0:                 episode reward: -0.8212,                 loss: nan
agent1:                 episode reward: 0.8212,                 loss: 0.1054
Episode: 23321/30000 (77.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2960s / 274.0601 s
agent0:                 episode reward: -0.5945,                 loss: nan
agent1:                 episode reward: 0.5945,                 loss: 0.1065
Episode: 23341/30000 (77.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3038s / 274.3640 s
agent0:                 episode reward: -0.7240,                 loss: nan
agent1:                 episode reward: 0.7240,                 loss: 0.1052
Episode: 23361/30000 (77.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3231s / 274.6871 s
agent0:                 episode reward: -0.5532,                 loss: nan
agent1:                 episode reward: 0.5532,                 loss: 0.1054
Episode: 23381/30000 (77.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3166s / 275.0038 s
agent0:                 episode reward: -0.4748,                 loss: nan
agent1:                 episode reward: 0.4748,                 loss: 0.1069
Episode: 23401/30000 (78.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3302s / 275.3340 s
agent0:                 episode reward: -0.6958,                 loss: nan
agent1:                 episode reward: 0.6958,                 loss: 0.1064
Episode: 23421/30000 (78.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3138s / 275.6478 s
agent0:                 episode reward: -1.0786,                 loss: nan
agent1:                 episode reward: 1.0786,                 loss: 0.1053
Episode: 23441/30000 (78.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3199s / 275.9677 s
agent0:                 episode reward: -0.6015,                 loss: nan
agent1:                 episode reward: 0.6015,                 loss: 0.1050
Episode: 23461/30000 (78.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3336s / 276.3014 s
agent0:                 episode reward: -0.7291,                 loss: nan
agent1:                 episode reward: 0.7291,                 loss: 0.1043
Episode: 23481/30000 (78.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3155s / 276.6169 s
agent0:                 episode reward: -0.5573,                 loss: nan
agent1:                 episode reward: 0.5573,                 loss: 0.1058
Episode: 23501/30000 (78.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3082s / 276.9251 s
agent0:                 episode reward: -0.6101,                 loss: nan
agent1:                 episode reward: 0.6101,                 loss: 0.1046
Episode: 23521/30000 (78.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2994s / 277.2244 s
agent0:                 episode reward: -0.4970,                 loss: nan
agent1:                 episode reward: 0.4970,                 loss: 0.1062
Episode: 23541/30000 (78.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3013s / 277.5258 s
agent0:                 episode reward: -0.7413,                 loss: nan
agent1:                 episode reward: 0.7413,                 loss: 0.1046
Episode: 23561/30000 (78.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3004s / 277.8262 s
agent0:                 episode reward: -0.5903,                 loss: nan
agent1:                 episode reward: 0.5903,                 loss: 0.1048
Episode: 23581/30000 (78.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2940s / 278.1202 s
agent0:                 episode reward: -0.4780,                 loss: nan
agent1:                 episode reward: 0.4780,                 loss: 0.1048
Episode: 23601/30000 (78.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2968s / 278.4169 s
agent0:                 episode reward: -0.6016,                 loss: nan
agent1:                 episode reward: 0.6016,                 loss: 0.1047
Episode: 23621/30000 (78.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3016s / 278.7185 s
agent0:                 episode reward: -1.0119,                 loss: nan
agent1:                 episode reward: 1.0119,                 loss: 0.1045
Episode: 23641/30000 (78.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3105s / 279.0290 s
agent0:                 episode reward: -0.8934,                 loss: nan
agent1:                 episode reward: 0.8934,                 loss: 0.1050
Episode: 23661/30000 (78.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3314s / 279.3604 s
agent0:                 episode reward: -0.8097,                 loss: nan
agent1:                 episode reward: 0.8097,                 loss: 0.1040
Episode: 23681/30000 (78.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3273s / 279.6877 s
agent0:                 episode reward: -0.7167,                 loss: nan
agent1:                 episode reward: 0.7167,                 loss: 0.1040
Episode: 23701/30000 (79.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3074s / 279.9951 s
agent0:                 episode reward: -0.8255,                 loss: nan
agent1:                 episode reward: 0.8255,                 loss: 0.1041
Episode: 23721/30000 (79.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3042s / 280.2994 s
agent0:                 episode reward: -0.7147,                 loss: nan
agent1:                 episode reward: 0.7147,                 loss: 0.1036
Episode: 23741/30000 (79.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3109s / 280.6103 s
agent0:                 episode reward: -0.6799,                 loss: nan
agent1:                 episode reward: 0.6799,                 loss: 0.1038
Episode: 23761/30000 (79.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3106s / 280.9208 s
agent0:                 episode reward: -0.3057,                 loss: nan
agent1:                 episode reward: 0.3057,                 loss: 0.1048
Episode: 23781/30000 (79.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3105s / 281.2313 s
agent0:                 episode reward: -0.6178,                 loss: nan
agent1:                 episode reward: 0.6178,                 loss: 0.1047
Episode: 23801/30000 (79.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3119s / 281.5432 s
agent0:                 episode reward: -0.3369,                 loss: nan
agent1:                 episode reward: 0.3369,                 loss: 0.1053
Episode: 23821/30000 (79.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3103s / 281.8535 s
agent0:                 episode reward: -0.7969,                 loss: nan
agent1:                 episode reward: 0.7969,                 loss: 0.1045
Episode: 23841/30000 (79.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3234s / 282.1769 s
agent0:                 episode reward: -0.6533,                 loss: nan
agent1:                 episode reward: 0.6533,                 loss: 0.1041
Episode: 23861/30000 (79.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3148s / 282.4916 s
agent0:                 episode reward: -0.3647,                 loss: nan
agent1:                 episode reward: 0.3647,                 loss: 0.1029
Episode: 23881/30000 (79.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3105s / 282.8021 s
agent0:                 episode reward: -0.5881,                 loss: nan
agent1:                 episode reward: 0.5881,                 loss: 0.1034
Episode: 23901/30000 (79.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3123s / 283.1144 s
agent0:                 episode reward: -0.7283,                 loss: nan
agent1:                 episode reward: 0.7283,                 loss: 0.1041
Episode: 23921/30000 (79.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3114s / 283.4259 s
agent0:                 episode reward: -0.4754,                 loss: nan
agent1:                 episode reward: 0.4754,                 loss: 0.1052
Episode: 23941/30000 (79.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3240s / 283.7499 s
agent0:                 episode reward: -1.1156,                 loss: nan
agent1:                 episode reward: 1.1156,                 loss: 0.1057
Episode: 23961/30000 (79.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3173s / 284.0671 s
agent0:                 episode reward: -0.6498,                 loss: nan
agent1:                 episode reward: 0.6498,                 loss: 0.1058
Episode: 23981/30000 (79.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3120s / 284.3791 s
agent0:                 episode reward: -0.3955,                 loss: nan
agent1:                 episode reward: 0.3955,                 loss: 0.1033
Episode: 24001/30000 (80.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3140s / 284.6931 s
agent0:                 episode reward: -0.5988,                 loss: nan
agent1:                 episode reward: 0.5988,                 loss: 0.1047
Episode: 24021/30000 (80.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3133s / 285.0064 s
agent0:                 episode reward: -0.4630,                 loss: nan
agent1:                 episode reward: 0.4630,                 loss: 0.1053
Episode: 24041/30000 (80.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3612s / 285.3677 s
agent0:                 episode reward: -0.6808,                 loss: nan
agent1:                 episode reward: 0.6808,                 loss: 0.1052
Episode: 24061/30000 (80.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3231s / 285.6907 s
agent0:                 episode reward: -0.4263,                 loss: nan
agent1:                 episode reward: 0.4263,                 loss: 0.1045
Episode: 24081/30000 (80.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3120s / 286.0027 s
agent0:                 episode reward: -0.4263,                 loss: nan
agent1:                 episode reward: 0.4263,                 loss: 0.1049
Episode: 24101/30000 (80.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3113s / 286.3140 s
agent0:                 episode reward: -0.5353,                 loss: nan
agent1:                 episode reward: 0.5353,                 loss: 0.1043
Episode: 24121/30000 (80.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3133s / 286.6274 s
agent0:                 episode reward: -0.7775,                 loss: nan
agent1:                 episode reward: 0.7775,                 loss: 0.1040
Episode: 24141/30000 (80.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3107s / 286.9381 s
agent0:                 episode reward: -0.6629,                 loss: nan
agent1:                 episode reward: 0.6629,                 loss: 0.1035
Episode: 24161/30000 (80.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3143s / 287.2523 s
agent0:                 episode reward: -0.7634,                 loss: nan
agent1:                 episode reward: 0.7634,                 loss: 0.1045
Episode: 24181/30000 (80.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3140s / 287.5664 s
agent0:                 episode reward: -0.4987,                 loss: nan
agent1:                 episode reward: 0.4987,                 loss: 0.1038
Episode: 24201/30000 (80.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3396s / 287.9059 s
agent0:                 episode reward: -0.0384,                 loss: nan
agent1:                 episode reward: 0.0384,                 loss: 0.1042
Episode: 24221/30000 (80.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3302s / 288.2361 s
agent0:                 episode reward: -0.7085,                 loss: nan
agent1:                 episode reward: 0.7085,                 loss: 0.1057
Episode: 24241/30000 (80.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3415s / 288.5777 s
agent0:                 episode reward: -0.5555,                 loss: nan
agent1:                 episode reward: 0.5555,                 loss: 0.1040
Episode: 24261/30000 (80.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3245s / 288.9022 s
agent0:                 episode reward: -0.0968,                 loss: nan
agent1:                 episode reward: 0.0968,                 loss: 0.1037
Episode: 24281/30000 (80.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3261s / 289.2283 s
agent0:                 episode reward: -0.4464,                 loss: nan
agent1:                 episode reward: 0.4464,                 loss: 0.1054
Episode: 24301/30000 (81.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3266s / 289.5549 s
agent0:                 episode reward: -0.7072,                 loss: nan
agent1:                 episode reward: 0.7072,                 loss: 0.1048
Episode: 24321/30000 (81.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3312s / 289.8861 s
agent0:                 episode reward: -0.7055,                 loss: nan
agent1:                 episode reward: 0.7055,                 loss: 0.1050
Episode: 24341/30000 (81.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3238s / 290.2099 s
agent0:                 episode reward: -0.7066,                 loss: nan
agent1:                 episode reward: 0.7066,                 loss: 0.1053
Episode: 24361/30000 (81.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3226s / 290.5325 s
agent0:                 episode reward: -0.5553,                 loss: nan
agent1:                 episode reward: 0.5553,                 loss: 0.1034
Episode: 24381/30000 (81.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3074s / 290.8399 s
agent0:                 episode reward: -0.6992,                 loss: nan
agent1:                 episode reward: 0.6992,                 loss: 0.1052
Episode: 24401/30000 (81.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3612s / 291.2011 s
agent0:                 episode reward: -0.5078,                 loss: nan
agent1:                 episode reward: 0.5078,                 loss: 0.1042
Episode: 24421/30000 (81.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3341s / 291.5352 s
agent0:                 episode reward: -0.6688,                 loss: nan
agent1:                 episode reward: 0.6688,                 loss: 0.1040
Episode: 24441/30000 (81.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3216s / 291.8568 s
agent0:                 episode reward: -0.6959,                 loss: nan
agent1:                 episode reward: 0.6959,                 loss: 0.1048
Episode: 24461/30000 (81.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3243s / 292.1811 s
agent0:                 episode reward: -0.6438,                 loss: nan
agent1:                 episode reward: 0.6438,                 loss: 0.1035
Episode: 24481/30000 (81.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3197s / 292.5008 s
agent0:                 episode reward: -0.5601,                 loss: nan
agent1:                 episode reward: 0.5601,                 loss: 0.1046
Episode: 24501/30000 (81.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3260s / 292.8267 s
agent0:                 episode reward: -0.3585,                 loss: nan
agent1:                 episode reward: 0.3585,                 loss: 0.1042
Episode: 24521/30000 (81.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3251s / 293.1518 s
agent0:                 episode reward: -0.3606,                 loss: nan
agent1:                 episode reward: 0.3606,                 loss: 0.1043
Episode: 24541/30000 (81.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3113s / 293.4631 s
agent0:                 episode reward: -0.7595,                 loss: nan
agent1:                 episode reward: 0.7595,                 loss: 0.1043
Episode: 24561/30000 (81.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3192s / 293.7823 s
agent0:                 episode reward: -0.4739,                 loss: nan
agent1:                 episode reward: 0.4739,                 loss: 0.1040
Episode: 24581/30000 (81.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3142s / 294.0965 s
agent0:                 episode reward: -0.8033,                 loss: nan
agent1:                 episode reward: 0.8033,                 loss: 0.1043
Episode: 24601/30000 (82.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3233s / 294.4198 s
agent0:                 episode reward: -0.4761,                 loss: nan
agent1:                 episode reward: 0.4761,                 loss: 0.1042
Episode: 24621/30000 (82.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3270s / 294.7468 s
agent0:                 episode reward: -0.2935,                 loss: nan
agent1:                 episode reward: 0.2935,                 loss: 0.1042
Episode: 24641/30000 (82.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3135s / 295.0603 s
agent0:                 episode reward: -0.3352,                 loss: nan
agent1:                 episode reward: 0.3352,                 loss: 0.1039
Episode: 24661/30000 (82.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3149s / 295.3752 s
agent0:                 episode reward: -0.6537,                 loss: nan
agent1:                 episode reward: 0.6537,                 loss: 0.1034
Episode: 24681/30000 (82.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3315s / 295.7067 s
agent0:                 episode reward: -0.4715,                 loss: nan
agent1:                 episode reward: 0.4715,                 loss: 0.1044
Episode: 24701/30000 (82.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3052s / 296.0119 s
agent0:                 episode reward: -0.5597,                 loss: nan
agent1:                 episode reward: 0.5597,                 loss: 0.1036
Episode: 24721/30000 (82.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3304s / 296.3422 s
agent0:                 episode reward: -0.3306,                 loss: nan
agent1:                 episode reward: 0.3306,                 loss: 0.1042
Episode: 24741/30000 (82.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3264s / 296.6687 s
agent0:                 episode reward: -1.0110,                 loss: nan
agent1:                 episode reward: 1.0110,                 loss: 0.1038
Episode: 24761/30000 (82.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3307s / 296.9994 s
agent0:                 episode reward: -0.6023,                 loss: nan
agent1:                 episode reward: 0.6023,                 loss: 0.1040
Episode: 24781/30000 (82.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3363s / 297.3357 s
agent0:                 episode reward: -0.6646,                 loss: nan
agent1:                 episode reward: 0.6646,                 loss: 0.1044
Episode: 24801/30000 (82.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3606s / 297.6963 s
agent0:                 episode reward: -0.5120,                 loss: nan
agent1:                 episode reward: 0.5120,                 loss: 0.1041
Episode: 24821/30000 (82.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3260s / 298.0223 s
agent0:                 episode reward: -1.0859,                 loss: nan
agent1:                 episode reward: 1.0859,                 loss: 0.1043
Episode: 24841/30000 (82.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3225s / 298.3448 s
agent0:                 episode reward: -0.6071,                 loss: nan
agent1:                 episode reward: 0.6071,                 loss: 0.1043
Episode: 24861/30000 (82.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3182s / 298.6630 s
agent0:                 episode reward: -0.5670,                 loss: nan
agent1:                 episode reward: 0.5670,                 loss: 0.1030
Episode: 24881/30000 (82.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3195s / 298.9826 s
agent0:                 episode reward: -0.5894,                 loss: nan
agent1:                 episode reward: 0.5894,                 loss: 0.1041
Episode: 24901/30000 (83.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3169s / 299.2995 s
agent0:                 episode reward: -0.8100,                 loss: nan
agent1:                 episode reward: 0.8100,                 loss: 0.1038
Episode: 24921/30000 (83.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3318s / 299.6313 s
agent0:                 episode reward: -0.5853,                 loss: nan
agent1:                 episode reward: 0.5853,                 loss: 0.1055
Episode: 24941/30000 (83.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3234s / 299.9547 s
agent0:                 episode reward: -0.6096,                 loss: nan
agent1:                 episode reward: 0.6096,                 loss: 0.1054
Episode: 24961/30000 (83.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3208s / 300.2755 s
agent0:                 episode reward: -0.5199,                 loss: nan
agent1:                 episode reward: 0.5199,                 loss: 0.1026
Episode: 24981/30000 (83.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3443s / 300.6197 s
agent0:                 episode reward: -0.9607,                 loss: nan
agent1:                 episode reward: 0.9607,                 loss: 0.1037
Episode: 25001/30000 (83.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3227s / 300.9424 s
agent0:                 episode reward: -0.6018,                 loss: nan
agent1:                 episode reward: 0.6018,                 loss: 0.1038
Episode: 25021/30000 (83.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3275s / 301.2699 s
agent0:                 episode reward: -0.7954,                 loss: nan
agent1:                 episode reward: 0.7954,                 loss: 0.1045
Episode: 25041/30000 (83.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3207s / 301.5906 s
agent0:                 episode reward: -0.6238,                 loss: nan
agent1:                 episode reward: 0.6238,                 loss: 0.1036
Episode: 25061/30000 (83.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3216s / 301.9122 s
agent0:                 episode reward: -0.6627,                 loss: nan
agent1:                 episode reward: 0.6627,                 loss: 0.1032
Episode: 25081/30000 (83.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3203s / 302.2325 s
agent0:                 episode reward: -0.9170,                 loss: nan
agent1:                 episode reward: 0.9170,                 loss: 0.1053
Episode: 25101/30000 (83.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3361s / 302.5686 s
agent0:                 episode reward: -0.9232,                 loss: nan
agent1:                 episode reward: 0.9232,                 loss: 0.1047
Episode: 25121/30000 (83.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3210s / 302.8896 s
agent0:                 episode reward: -0.2936,                 loss: nan
agent1:                 episode reward: 0.2936,                 loss: 0.1038
Episode: 25141/30000 (83.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3216s / 303.2112 s
agent0:                 episode reward: -0.6003,                 loss: nan
agent1:                 episode reward: 0.6003,                 loss: 0.1037
Episode: 25161/30000 (83.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3307s / 303.5418 s
agent0:                 episode reward: -0.5234,                 loss: nan
agent1:                 episode reward: 0.5234,                 loss: 0.1033
Episode: 25181/30000 (83.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3482s / 303.8900 s
agent0:                 episode reward: -0.7834,                 loss: nan
agent1:                 episode reward: 0.7834,                 loss: 0.1035
Episode: 25201/30000 (84.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3242s / 304.2142 s
agent0:                 episode reward: -0.7439,                 loss: nan
agent1:                 episode reward: 0.7439,                 loss: 0.1039
Episode: 25221/30000 (84.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3238s / 304.5380 s
agent0:                 episode reward: -0.3573,                 loss: nan
agent1:                 episode reward: 0.3573,                 loss: 0.1043
Episode: 25241/30000 (84.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3213s / 304.8593 s
agent0:                 episode reward: -0.3128,                 loss: nan
agent1:                 episode reward: 0.3128,                 loss: 0.1041
Episode: 25261/30000 (84.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3220s / 305.1812 s
agent0:                 episode reward: -0.8001,                 loss: nan
agent1:                 episode reward: 0.8001,                 loss: 0.1041
Episode: 25281/30000 (84.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3226s / 305.5038 s
agent0:                 episode reward: -0.7726,                 loss: nan
agent1:                 episode reward: 0.7726,                 loss: 0.1035
Episode: 25301/30000 (84.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3229s / 305.8267 s
agent0:                 episode reward: -0.6703,                 loss: nan
agent1:                 episode reward: 0.6703,                 loss: 0.1038
Episode: 25321/30000 (84.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3203s / 306.1471 s
agent0:                 episode reward: -0.6735,                 loss: nan
agent1:                 episode reward: 0.6735,                 loss: 0.1033
Episode: 25341/30000 (84.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3219s / 306.4689 s
agent0:                 episode reward: -0.3988,                 loss: nan
agent1:                 episode reward: 0.3988,                 loss: 0.1035
Episode: 25361/30000 (84.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3474s / 306.8163 s
agent0:                 episode reward: -0.8895,                 loss: nan
agent1:                 episode reward: 0.8895,                 loss: 0.1038
Episode: 25381/30000 (84.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3266s / 307.1429 s
agent0:                 episode reward: -0.9101,                 loss: nan
agent1:                 episode reward: 0.9101,                 loss: 0.1041
Episode: 25401/30000 (84.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3208s / 307.4636 s
agent0:                 episode reward: -0.5562,                 loss: nan
agent1:                 episode reward: 0.5562,                 loss: 0.1034
Episode: 25421/30000 (84.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3240s / 307.7877 s
agent0:                 episode reward: -0.9502,                 loss: nan
agent1:                 episode reward: 0.9502,                 loss: 0.1044
Episode: 25441/30000 (84.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3252s / 308.1129 s
agent0:                 episode reward: -0.6582,                 loss: nan
agent1:                 episode reward: 0.6582,                 loss: 0.1036
Episode: 25461/30000 (84.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3179s / 308.4307 s
agent0:                 episode reward: -0.8165,                 loss: nan
agent1:                 episode reward: 0.8165,                 loss: 0.1038
Episode: 25481/30000 (84.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3247s / 308.7554 s
agent0:                 episode reward: -1.0327,                 loss: nan
agent1:                 episode reward: 1.0327,                 loss: 0.1030
Episode: 25501/30000 (85.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3246s / 309.0800 s
agent0:                 episode reward: -0.5926,                 loss: nan
agent1:                 episode reward: 0.5926,                 loss: 0.1032
Episode: 25521/30000 (85.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3251s / 309.4051 s
agent0:                 episode reward: -0.8820,                 loss: nan
agent1:                 episode reward: 0.8820,                 loss: 0.1037
Episode: 25541/30000 (85.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3310s / 309.7361 s
agent0:                 episode reward: -0.5730,                 loss: nan
agent1:                 episode reward: 0.5730,                 loss: 0.1032
Episode: 25561/30000 (85.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3203s / 310.0564 s
agent0:                 episode reward: -0.6380,                 loss: nan
agent1:                 episode reward: 0.6380,                 loss: 0.1038
Episode: 25581/30000 (85.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3263s / 310.3827 s
agent0:                 episode reward: -0.7426,                 loss: nan
agent1:                 episode reward: 0.7426,                 loss: 0.1036
Episode: 25601/30000 (85.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3215s / 310.7041 s
agent0:                 episode reward: -0.7261,                 loss: nan
agent1:                 episode reward: 0.7261,                 loss: 0.1046
Episode: 25621/30000 (85.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3176s / 311.0217 s
agent0:                 episode reward: -0.4665,                 loss: nan
agent1:                 episode reward: 0.4665,                 loss: 0.1038
Episode: 25641/30000 (85.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3217s / 311.3434 s
agent0:                 episode reward: -0.8422,                 loss: nan
agent1:                 episode reward: 0.8422,                 loss: 0.1029
Episode: 25661/30000 (85.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3271s / 311.6705 s
agent0:                 episode reward: -0.6973,                 loss: nan
agent1:                 episode reward: 0.6973,                 loss: 0.1043
Episode: 25681/30000 (85.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3248s / 311.9953 s
agent0:                 episode reward: -0.8451,                 loss: nan
agent1:                 episode reward: 0.8451,                 loss: 0.1032
Episode: 25701/30000 (85.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3222s / 312.3175 s
agent0:                 episode reward: -0.6457,                 loss: nan
agent1:                 episode reward: 0.6457,                 loss: 0.1045
Episode: 25721/30000 (85.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3411s / 312.6587 s
agent0:                 episode reward: -0.8332,                 loss: nan
agent1:                 episode reward: 0.8332,                 loss: 0.1039
Episode: 25741/30000 (85.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3524s / 313.0111 s
agent0:                 episode reward: -0.2867,                 loss: nan
agent1:                 episode reward: 0.2867,                 loss: 0.1032
Episode: 25761/30000 (85.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3288s / 313.3398 s
agent0:                 episode reward: -0.5819,                 loss: nan
agent1:                 episode reward: 0.5819,                 loss: 0.1034
Episode: 25781/30000 (85.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3493s / 313.6891 s
agent0:                 episode reward: -0.7523,                 loss: nan
agent1:                 episode reward: 0.7523,                 loss: 0.1051
Episode: 25801/30000 (86.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3344s / 314.0235 s
agent0:                 episode reward: -1.3410,                 loss: nan
agent1:                 episode reward: 1.3410,                 loss: 0.1029
Episode: 25821/30000 (86.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3249s / 314.3485 s
agent0:                 episode reward: -0.3049,                 loss: nan
agent1:                 episode reward: 0.3049,                 loss: 0.1037
Episode: 25841/30000 (86.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3259s / 314.6744 s
agent0:                 episode reward: -0.6776,                 loss: nan
agent1:                 episode reward: 0.6776,                 loss: 0.1048
Episode: 25861/30000 (86.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3250s / 314.9993 s
agent0:                 episode reward: -0.5390,                 loss: nan
agent1:                 episode reward: 0.5390,                 loss: 0.1034
Episode: 25881/30000 (86.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3430s / 315.3423 s
agent0:                 episode reward: -0.5434,                 loss: nan
agent1:                 episode reward: 0.5434,                 loss: 0.1045
Episode: 25901/30000 (86.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3472s / 315.6896 s
agent0:                 episode reward: -0.5791,                 loss: nan
agent1:                 episode reward: 0.5791,                 loss: 0.1042
Episode: 25921/30000 (86.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3320s / 316.0216 s
agent0:                 episode reward: -0.7702,                 loss: nan
agent1:                 episode reward: 0.7702,                 loss: 0.1023
Episode: 25941/30000 (86.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3242s / 316.3457 s
agent0:                 episode reward: -0.4927,                 loss: nan
agent1:                 episode reward: 0.4927,                 loss: 0.1048
Episode: 25961/30000 (86.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3237s / 316.6694 s
agent0:                 episode reward: -0.6806,                 loss: nan
agent1:                 episode reward: 0.6806,                 loss: 0.1035
Episode: 25981/30000 (86.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3291s / 316.9986 s
agent0:                 episode reward: -0.5857,                 loss: nan
agent1:                 episode reward: 0.5857,                 loss: 0.1044
Episode: 26001/30000 (86.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3239s / 317.3225 s
agent0:                 episode reward: -0.7535,                 loss: nan
agent1:                 episode reward: 0.7535,                 loss: 0.1051
Episode: 26021/30000 (86.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3263s / 317.6488 s
agent0:                 episode reward: -0.5948,                 loss: nan
agent1:                 episode reward: 0.5948,                 loss: 0.1028
Episode: 26041/30000 (86.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3313s / 317.9800 s
agent0:                 episode reward: -0.3625,                 loss: nan
agent1:                 episode reward: 0.3625,                 loss: 0.1044
Episode: 26061/30000 (86.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3287s / 318.3087 s
agent0:                 episode reward: -0.7358,                 loss: nan
agent1:                 episode reward: 0.7358,                 loss: 0.1054
Episode: 26081/30000 (86.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3489s / 318.6576 s
agent0:                 episode reward: -0.8582,                 loss: nan
agent1:                 episode reward: 0.8582,                 loss: 0.1052
Episode: 26101/30000 (87.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3559s / 319.0135 s
agent0:                 episode reward: -0.6465,                 loss: nan
agent1:                 episode reward: 0.6465,                 loss: 0.1035
Episode: 26121/30000 (87.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3359s / 319.3494 s
agent0:                 episode reward: -0.6135,                 loss: nan
agent1:                 episode reward: 0.6135,                 loss: 0.1032
Episode: 26141/30000 (87.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3176s / 319.6670 s
agent0:                 episode reward: -0.2427,                 loss: nan
agent1:                 episode reward: 0.2427,                 loss: 0.1035
Episode: 26161/30000 (87.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3245s / 319.9916 s
agent0:                 episode reward: -0.5937,                 loss: nan
agent1:                 episode reward: 0.5937,                 loss: 0.1042
Episode: 26181/30000 (87.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3425s / 320.3340 s
agent0:                 episode reward: -0.6315,                 loss: nan
agent1:                 episode reward: 0.6315,                 loss: 0.1031
Episode: 26201/30000 (87.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3134s / 320.6475 s
agent0:                 episode reward: -0.5788,                 loss: nan
agent1:                 episode reward: 0.5788,                 loss: 0.1033
Episode: 26221/30000 (87.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3150s / 320.9625 s
agent0:                 episode reward: -0.4914,                 loss: nan
agent1:                 episode reward: 0.4914,                 loss: 0.1030
Episode: 26241/30000 (87.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3422s / 321.3047 s
agent0:                 episode reward: -0.5989,                 loss: nan
agent1:                 episode reward: 0.5989,                 loss: 0.1028
Episode: 26261/30000 (87.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3366s / 321.6413 s
agent0:                 episode reward: -0.6854,                 loss: nan
agent1:                 episode reward: 0.6854,                 loss: 0.1029
Episode: 26281/30000 (87.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3326s / 321.9739 s
agent0:                 episode reward: -0.5416,                 loss: nan
agent1:                 episode reward: 0.5416,                 loss: 0.1040
Episode: 26301/30000 (87.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3256s / 322.2995 s
agent0:                 episode reward: -0.5414,                 loss: nan
agent1:                 episode reward: 0.5414,                 loss: 0.1020
Episode: 26321/30000 (87.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3358s / 322.6353 s
agent0:                 episode reward: -0.6743,                 loss: nan
agent1:                 episode reward: 0.6743,                 loss: 0.1032
Episode: 26341/30000 (87.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3263s / 322.9615 s
agent0:                 episode reward: -0.7747,                 loss: nan
agent1:                 episode reward: 0.7747,                 loss: 0.1038
Episode: 26361/30000 (87.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3258s / 323.2874 s
agent0:                 episode reward: -0.3965,                 loss: nan
agent1:                 episode reward: 0.3965,                 loss: 0.1038
Episode: 26381/30000 (87.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3300s / 323.6173 s
agent0:                 episode reward: -0.6950,                 loss: nan
agent1:                 episode reward: 0.6950,                 loss: 0.1038
Episode: 26401/30000 (88.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3297s / 323.9470 s
agent0:                 episode reward: -0.3887,                 loss: nan
agent1:                 episode reward: 0.3887,                 loss: 0.1025
Episode: 26421/30000 (88.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3293s / 324.2763 s
agent0:                 episode reward: -0.6436,                 loss: nan
agent1:                 episode reward: 0.6436,                 loss: 0.1025
Episode: 26441/30000 (88.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3146s / 324.5909 s
agent0:                 episode reward: -0.7318,                 loss: nan
agent1:                 episode reward: 0.7318,                 loss: 0.1045
Episode: 26461/30000 (88.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3350s / 324.9260 s
agent0:                 episode reward: -0.6404,                 loss: nan
agent1:                 episode reward: 0.6404,                 loss: 0.1040
Episode: 26481/30000 (88.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3323s / 325.2583 s
agent0:                 episode reward: -0.4410,                 loss: nan
agent1:                 episode reward: 0.4410,                 loss: 0.1032
Episode: 26501/30000 (88.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3349s / 325.5931 s
agent0:                 episode reward: -1.0744,                 loss: nan
agent1:                 episode reward: 1.0744,                 loss: 0.1019
Episode: 26521/30000 (88.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3364s / 325.9295 s
agent0:                 episode reward: -0.5435,                 loss: nan
agent1:                 episode reward: 0.5435,                 loss: 0.1046
Episode: 26541/30000 (88.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3275s / 326.2570 s
agent0:                 episode reward: -0.7182,                 loss: nan
agent1:                 episode reward: 0.7182,                 loss: 0.1030
Episode: 26561/30000 (88.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3310s / 326.5880 s
agent0:                 episode reward: -0.7540,                 loss: nan
agent1:                 episode reward: 0.7540,                 loss: 0.1036
Episode: 26581/30000 (88.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3230s / 326.9110 s
agent0:                 episode reward: -0.5815,                 loss: nan
agent1:                 episode reward: 0.5815,                 loss: 0.1018
Episode: 26601/30000 (88.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3306s / 327.2415 s
agent0:                 episode reward: -0.5261,                 loss: nan
agent1:                 episode reward: 0.5261,                 loss: 0.1026
Episode: 26621/30000 (88.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3240s / 327.5656 s
agent0:                 episode reward: -0.6865,                 loss: nan
agent1:                 episode reward: 0.6865,                 loss: 0.1032
Episode: 26641/30000 (88.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3468s / 327.9124 s
agent0:                 episode reward: -0.6632,                 loss: nan
agent1:                 episode reward: 0.6632,                 loss: 0.1038
Episode: 26661/30000 (88.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3333s / 328.2457 s
agent0:                 episode reward: -0.3914,                 loss: nan
agent1:                 episode reward: 0.3914,                 loss: 0.1040
Episode: 26681/30000 (88.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3238s / 328.5694 s
agent0:                 episode reward: -0.4763,                 loss: nan
agent1:                 episode reward: 0.4763,                 loss: 0.1031
Episode: 26701/30000 (89.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3421s / 328.9115 s
agent0:                 episode reward: -0.5279,                 loss: nan
agent1:                 episode reward: 0.5279,                 loss: 0.1034
Episode: 26721/30000 (89.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3302s / 329.2417 s
agent0:                 episode reward: -0.6168,                 loss: nan
agent1:                 episode reward: 0.6168,                 loss: 0.1028
Episode: 26741/30000 (89.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3432s / 329.5849 s
agent0:                 episode reward: -0.7863,                 loss: nan
agent1:                 episode reward: 0.7863,                 loss: 0.1028
Episode: 26761/30000 (89.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3367s / 329.9216 s
agent0:                 episode reward: -0.7731,                 loss: nan
agent1:                 episode reward: 0.7731,                 loss: 0.1022
Episode: 26781/30000 (89.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3360s / 330.2577 s
agent0:                 episode reward: -0.5606,                 loss: nan
agent1:                 episode reward: 0.5606,                 loss: 0.1027
Episode: 26801/30000 (89.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3174s / 330.5751 s
agent0:                 episode reward: -0.5817,                 loss: nan
agent1:                 episode reward: 0.5817,                 loss: 0.1030
Episode: 26821/30000 (89.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3577s / 330.9328 s
agent0:                 episode reward: -0.4173,                 loss: nan
agent1:                 episode reward: 0.4173,                 loss: 0.1037
Episode: 26841/30000 (89.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3297s / 331.2625 s
agent0:                 episode reward: -0.6348,                 loss: nan
agent1:                 episode reward: 0.6348,                 loss: 0.1021
Episode: 26861/30000 (89.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3201s / 331.5825 s
agent0:                 episode reward: -0.6822,                 loss: nan
agent1:                 episode reward: 0.6822,                 loss: 0.1031
Episode: 26881/30000 (89.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3338s / 331.9164 s
agent0:                 episode reward: -0.6517,                 loss: nan
agent1:                 episode reward: 0.6517,                 loss: 0.1039
Episode: 26901/30000 (89.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3333s / 332.2497 s
agent0:                 episode reward: -0.2524,                 loss: nan
agent1:                 episode reward: 0.2524,                 loss: 0.1024
Episode: 26921/30000 (89.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3336s / 332.5833 s
agent0:                 episode reward: -0.5015,                 loss: nan
agent1:                 episode reward: 0.5015,                 loss: 0.1040
Episode: 26941/30000 (89.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3353s / 332.9186 s
agent0:                 episode reward: -0.8686,                 loss: nan
agent1:                 episode reward: 0.8686,                 loss: 0.1033
Episode: 26961/30000 (89.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3393s / 333.2579 s
agent0:                 episode reward: -0.5606,                 loss: nan
agent1:                 episode reward: 0.5606,                 loss: 0.1035
Episode: 26981/30000 (89.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3389s / 333.5968 s
agent0:                 episode reward: -0.6014,                 loss: nan
agent1:                 episode reward: 0.6014,                 loss: 0.1047
Episode: 27001/30000 (90.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3552s / 333.9520 s
agent0:                 episode reward: -0.8490,                 loss: nan
agent1:                 episode reward: 0.8490,                 loss: 0.1028
Episode: 27021/30000 (90.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3228s / 334.2748 s
agent0:                 episode reward: -0.6638,                 loss: nan
agent1:                 episode reward: 0.6638,                 loss: 0.1048
Episode: 27041/30000 (90.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3227s / 334.5975 s
agent0:                 episode reward: -0.4806,                 loss: nan
agent1:                 episode reward: 0.4806,                 loss: 0.1024
Episode: 27061/30000 (90.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3231s / 334.9206 s
agent0:                 episode reward: -0.7914,                 loss: nan
agent1:                 episode reward: 0.7914,                 loss: 0.1029
Episode: 27081/30000 (90.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3181s / 335.2387 s
agent0:                 episode reward: -0.7290,                 loss: nan
agent1:                 episode reward: 0.7290,                 loss: 0.1029
Episode: 27101/30000 (90.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3181s / 335.5568 s
agent0:                 episode reward: -0.3535,                 loss: nan
agent1:                 episode reward: 0.3535,                 loss: 0.1044
Episode: 27121/30000 (90.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3223s / 335.8791 s
agent0:                 episode reward: -0.8714,                 loss: nan
agent1:                 episode reward: 0.8714,                 loss: 0.1053
Episode: 27141/30000 (90.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3286s / 336.2077 s
agent0:                 episode reward: -0.6694,                 loss: nan
agent1:                 episode reward: 0.6694,                 loss: 0.1035
Episode: 27161/30000 (90.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3290s / 336.5367 s
agent0:                 episode reward: -0.5055,                 loss: nan
agent1:                 episode reward: 0.5055,                 loss: 0.1040
Episode: 27181/30000 (90.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3241s / 336.8608 s
agent0:                 episode reward: -0.9271,                 loss: nan
agent1:                 episode reward: 0.9271,                 loss: 0.1042
Episode: 27201/30000 (90.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3670s / 337.2278 s
agent0:                 episode reward: -0.2929,                 loss: nan
agent1:                 episode reward: 0.2929,                 loss: 0.1029
Episode: 27221/30000 (90.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3269s / 337.5547 s
agent0:                 episode reward: -0.5624,                 loss: nan
agent1:                 episode reward: 0.5624,                 loss: 0.1035
Episode: 27241/30000 (90.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3359s / 337.8906 s
agent0:                 episode reward: -0.8295,                 loss: nan
agent1:                 episode reward: 0.8295,                 loss: 0.1037
Episode: 27261/30000 (90.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3194s / 338.2100 s
agent0:                 episode reward: -0.7475,                 loss: nan
agent1:                 episode reward: 0.7475,                 loss: 0.1043
Episode: 27281/30000 (90.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3265s / 338.5365 s
agent0:                 episode reward: -0.7245,                 loss: nan
agent1:                 episode reward: 0.7245,                 loss: 0.1032
Episode: 27301/30000 (91.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3380s / 338.8745 s
agent0:                 episode reward: -0.6778,                 loss: nan
agent1:                 episode reward: 0.6778,                 loss: 0.1041
Episode: 27321/30000 (91.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3392s / 339.2137 s
agent0:                 episode reward: -0.4441,                 loss: nan
agent1:                 episode reward: 0.4441,                 loss: 0.1029
Episode: 27341/30000 (91.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3324s / 339.5461 s
agent0:                 episode reward: -0.9189,                 loss: nan
agent1:                 episode reward: 0.9189,                 loss: 0.1045
Episode: 27361/30000 (91.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3308s / 339.8769 s
agent0:                 episode reward: -0.2701,                 loss: nan
agent1:                 episode reward: 0.2701,                 loss: 0.1038
Episode: 27381/30000 (91.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3591s / 340.2360 s
agent0:                 episode reward: -0.7258,                 loss: nan
agent1:                 episode reward: 0.7258,                 loss: 0.1039
Episode: 27401/30000 (91.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3341s / 340.5700 s
agent0:                 episode reward: -0.8425,                 loss: nan
agent1:                 episode reward: 0.8425,                 loss: 0.1051
Episode: 27421/30000 (91.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3330s / 340.9031 s
agent0:                 episode reward: -0.6507,                 loss: nan
agent1:                 episode reward: 0.6507,                 loss: 0.1037
Episode: 27441/30000 (91.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3357s / 341.2388 s
agent0:                 episode reward: -0.5506,                 loss: nan
agent1:                 episode reward: 0.5506,                 loss: 0.1035
Episode: 27461/30000 (91.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3394s / 341.5783 s
agent0:                 episode reward: -0.7907,                 loss: nan
agent1:                 episode reward: 0.7907,                 loss: 0.1026
Episode: 27481/30000 (91.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3426s / 341.9208 s
agent0:                 episode reward: -0.7583,                 loss: nan
agent1:                 episode reward: 0.7583,                 loss: 0.1043
Episode: 27501/30000 (91.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3512s / 342.2721 s
agent0:                 episode reward: -0.9257,                 loss: nan
agent1:                 episode reward: 0.9257,                 loss: 0.1026
Episode: 27521/30000 (91.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3554s / 342.6275 s
agent0:                 episode reward: -0.9972,                 loss: nan
agent1:                 episode reward: 0.9972,                 loss: 0.1038
Episode: 27541/30000 (91.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3351s / 342.9626 s
agent0:                 episode reward: -0.7387,                 loss: nan
agent1:                 episode reward: 0.7387,                 loss: 0.1040
Episode: 27561/30000 (91.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3637s / 343.3262 s
agent0:                 episode reward: -0.7984,                 loss: nan
agent1:                 episode reward: 0.7984,                 loss: 0.1036
Episode: 27581/30000 (91.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3393s / 343.6656 s
agent0:                 episode reward: -0.8730,                 loss: nan
agent1:                 episode reward: 0.8730,                 loss: 0.1036
Episode: 27601/30000 (92.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3441s / 344.0096 s
agent0:                 episode reward: -0.9570,                 loss: nan
agent1:                 episode reward: 0.9570,                 loss: 0.1024
Episode: 27621/30000 (92.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3410s / 344.3506 s
agent0:                 episode reward: -0.7637,                 loss: nan
agent1:                 episode reward: 0.7637,                 loss: 0.1034
Episode: 27641/30000 (92.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3471s / 344.6978 s
agent0:                 episode reward: -0.8186,                 loss: nan
agent1:                 episode reward: 0.8186,                 loss: 0.1038
Episode: 27661/30000 (92.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3353s / 345.0331 s
agent0:                 episode reward: -0.5224,                 loss: nan
agent1:                 episode reward: 0.5224,                 loss: 0.1033
Episode: 27681/30000 (92.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3638s / 345.3969 s
agent0:                 episode reward: -0.8757,                 loss: nan
agent1:                 episode reward: 0.8757,                 loss: 0.1028
Episode: 27701/30000 (92.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3606s / 345.7575 s
agent0:                 episode reward: -0.6928,                 loss: nan
agent1:                 episode reward: 0.6928,                 loss: 0.1033
Episode: 27721/30000 (92.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3720s / 346.1294 s
agent0:                 episode reward: -0.6358,                 loss: nan
agent1:                 episode reward: 0.6358,                 loss: 0.1035
Episode: 27741/30000 (92.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3601s / 346.4895 s
agent0:                 episode reward: -0.9551,                 loss: nan
agent1:                 episode reward: 0.9551,                 loss: 0.1039
Episode: 27761/30000 (92.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3397s / 346.8293 s
agent0:                 episode reward: -0.5320,                 loss: nan
agent1:                 episode reward: 0.5320,                 loss: 0.1018
Episode: 27781/30000 (92.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3372s / 347.1665 s
agent0:                 episode reward: -0.7259,                 loss: nan
agent1:                 episode reward: 0.7259,                 loss: 0.1034
Episode: 27801/30000 (92.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3396s / 347.5061 s
agent0:                 episode reward: -0.7011,                 loss: nan
agent1:                 episode reward: 0.7011,                 loss: 0.1029
Episode: 27821/30000 (92.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3401s / 347.8462 s
agent0:                 episode reward: -0.8482,                 loss: nan
agent1:                 episode reward: 0.8482,                 loss: 0.1025
Episode: 27841/30000 (92.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3379s / 348.1841 s
agent0:                 episode reward: -0.5676,                 loss: nan
agent1:                 episode reward: 0.5676,                 loss: 0.1045
Episode: 27861/30000 (92.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3363s / 348.5204 s
agent0:                 episode reward: -0.7581,                 loss: nan
agent1:                 episode reward: 0.7581,                 loss: 0.1038
Episode: 27881/30000 (92.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3418s / 348.8622 s
agent0:                 episode reward: -0.5655,                 loss: nan
agent1:                 episode reward: 0.5655,                 loss: 0.1027
Episode: 27901/30000 (93.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3519s / 349.2141 s
agent0:                 episode reward: -0.7417,                 loss: nan
agent1:                 episode reward: 0.7417,                 loss: 0.1022
Episode: 27921/30000 (93.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3578s / 349.5719 s
agent0:                 episode reward: -0.8580,                 loss: nan
agent1:                 episode reward: 0.8580,                 loss: 0.1007
Episode: 27941/30000 (93.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3449s / 349.9168 s
agent0:                 episode reward: -0.7372,                 loss: nan
agent1:                 episode reward: 0.7372,                 loss: 0.1028
Episode: 27961/30000 (93.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3438s / 350.2606 s
agent0:                 episode reward: -0.3933,                 loss: nan
agent1:                 episode reward: 0.3933,                 loss: 0.1032
Episode: 27981/30000 (93.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3376s / 350.5982 s
agent0:                 episode reward: -0.5433,                 loss: nan
agent1:                 episode reward: 0.5433,                 loss: 0.1011
Episode: 28001/30000 (93.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3349s / 350.9332 s
agent0:                 episode reward: -0.4313,                 loss: nan
agent1:                 episode reward: 0.4313,                 loss: 0.1018
Episode: 28021/30000 (93.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3382s / 351.2714 s
agent0:                 episode reward: -0.6651,                 loss: nan
agent1:                 episode reward: 0.6651,                 loss: 0.1021
Episode: 28041/30000 (93.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3399s / 351.6113 s
agent0:                 episode reward: -0.3381,                 loss: nan
agent1:                 episode reward: 0.3381,                 loss: 0.1018
Episode: 28061/30000 (93.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3426s / 351.9539 s
agent0:                 episode reward: -0.6022,                 loss: nan
agent1:                 episode reward: 0.6022,                 loss: 0.1032
Episode: 28081/30000 (93.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3439s / 352.2978 s
agent0:                 episode reward: -0.5332,                 loss: nan
agent1:                 episode reward: 0.5332,                 loss: 0.1023
Episode: 28101/30000 (93.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3358s / 352.6336 s
agent0:                 episode reward: -0.1854,                 loss: nan
agent1:                 episode reward: 0.1854,                 loss: 0.1024
Episode: 28121/30000 (93.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3281s / 352.9617 s
agent0:                 episode reward: -0.6325,                 loss: nan
agent1:                 episode reward: 0.6325,                 loss: 0.1014
Episode: 28141/30000 (93.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3228s / 353.2845 s
agent0:                 episode reward: -0.6957,                 loss: nan
agent1:                 episode reward: 0.6957,                 loss: 0.1024
Episode: 28161/30000 (93.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3257s / 353.6102 s
agent0:                 episode reward: -0.6972,                 loss: nan
agent1:                 episode reward: 0.6972,                 loss: 0.1021
Episode: 28181/30000 (93.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3265s / 353.9368 s
agent0:                 episode reward: -0.9314,                 loss: nan
agent1:                 episode reward: 0.9314,                 loss: 0.1025
Episode: 28201/30000 (94.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3318s / 354.2686 s
agent0:                 episode reward: -0.5906,                 loss: nan
agent1:                 episode reward: 0.5906,                 loss: 0.1030
Episode: 28221/30000 (94.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3456s / 354.6142 s
agent0:                 episode reward: -0.8063,                 loss: nan
agent1:                 episode reward: 0.8063,                 loss: 0.1011
Episode: 28241/30000 (94.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3411s / 354.9553 s
agent0:                 episode reward: -0.7745,                 loss: nan
agent1:                 episode reward: 0.7745,                 loss: 0.1027
Episode: 28261/30000 (94.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3629s / 355.3181 s
agent0:                 episode reward: -0.6142,                 loss: nan
agent1:                 episode reward: 0.6142,                 loss: 0.1027
Episode: 28281/30000 (94.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3429s / 355.6611 s
agent0:                 episode reward: -0.4113,                 loss: nan
agent1:                 episode reward: 0.4113,                 loss: 0.1021
Episode: 28301/30000 (94.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3357s / 355.9967 s
agent0:                 episode reward: -0.6281,                 loss: nan
agent1:                 episode reward: 0.6281,                 loss: 0.1036
Episode: 28321/30000 (94.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3418s / 356.3386 s
agent0:                 episode reward: -0.5964,                 loss: nan
agent1:                 episode reward: 0.5964,                 loss: 0.1038
Episode: 28341/30000 (94.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3397s / 356.6783 s
agent0:                 episode reward: -0.7991,                 loss: nan
agent1:                 episode reward: 0.7991,                 loss: 0.1018
Episode: 28361/30000 (94.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3417s / 357.0200 s
agent0:                 episode reward: -0.6486,                 loss: nan
agent1:                 episode reward: 0.6486,                 loss: 0.1030
Episode: 28381/30000 (94.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3433s / 357.3633 s
agent0:                 episode reward: -0.8602,                 loss: nan
agent1:                 episode reward: 0.8602,                 loss: 0.1021
Episode: 28401/30000 (94.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3461s / 357.7093 s
agent0:                 episode reward: -0.8255,                 loss: nan
agent1:                 episode reward: 0.8255,                 loss: 0.1017
Episode: 28421/30000 (94.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3466s / 358.0559 s
agent0:                 episode reward: -0.4517,                 loss: nan
agent1:                 episode reward: 0.4517,                 loss: 0.1023
Episode: 28441/30000 (94.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3673s / 358.4232 s
agent0:                 episode reward: -0.5116,                 loss: nan
agent1:                 episode reward: 0.5116,                 loss: 0.1034
Episode: 28461/30000 (94.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3497s / 358.7729 s
agent0:                 episode reward: -0.9330,                 loss: nan
agent1:                 episode reward: 0.9330,                 loss: 0.1020
Episode: 28481/30000 (94.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3521s / 359.1251 s
agent0:                 episode reward: -0.5950,                 loss: nan
agent1:                 episode reward: 0.5950,                 loss: 0.1021
Episode: 28501/30000 (95.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3516s / 359.4766 s
agent0:                 episode reward: -0.8190,                 loss: nan
agent1:                 episode reward: 0.8190,                 loss: 0.1031
Episode: 28521/30000 (95.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3478s / 359.8244 s
agent0:                 episode reward: -0.6367,                 loss: nan
agent1:                 episode reward: 0.6367,                 loss: 0.1018
Episode: 28541/30000 (95.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3357s / 360.1601 s
agent0:                 episode reward: -0.6531,                 loss: nan
agent1:                 episode reward: 0.6531,                 loss: 0.1036
Episode: 28561/30000 (95.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3452s / 360.5053 s
agent0:                 episode reward: -0.4426,                 loss: nan
agent1:                 episode reward: 0.4426,                 loss: 0.1010
Episode: 28581/30000 (95.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3464s / 360.8518 s
agent0:                 episode reward: -0.4437,                 loss: nan
agent1:                 episode reward: 0.4437,                 loss: 0.1018
Episode: 28601/30000 (95.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3814s / 361.2332 s
agent0:                 episode reward: -0.8993,                 loss: nan
agent1:                 episode reward: 0.8993,                 loss: 0.1016
Episode: 28621/30000 (95.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3311s / 361.5643 s
agent0:                 episode reward: -0.5712,                 loss: nan
agent1:                 episode reward: 0.5712,                 loss: 0.1016
Episode: 28641/30000 (95.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3274s / 361.8917 s
agent0:                 episode reward: -0.4158,                 loss: nan
agent1:                 episode reward: 0.4158,                 loss: 0.1016
Episode: 28661/30000 (95.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3329s / 362.2246 s
agent0:                 episode reward: -0.6341,                 loss: nan
agent1:                 episode reward: 0.6341,                 loss: 0.1008
Episode: 28681/30000 (95.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3307s / 362.5553 s
agent0:                 episode reward: -0.7741,                 loss: nan
agent1:                 episode reward: 0.7741,                 loss: 0.1011
Episode: 28701/30000 (95.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3478s / 362.9031 s
agent0:                 episode reward: -0.9565,                 loss: nan
agent1:                 episode reward: 0.9565,                 loss: 0.1011
Episode: 28721/30000 (95.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3304s / 363.2335 s
agent0:                 episode reward: -0.4687,                 loss: nan
agent1:                 episode reward: 0.4687,                 loss: 0.1014
Episode: 28741/30000 (95.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3282s / 363.5616 s
agent0:                 episode reward: -1.0640,                 loss: nan
agent1:                 episode reward: 1.0640,                 loss: 0.1010
Episode: 28761/30000 (95.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3311s / 363.8927 s
agent0:                 episode reward: -0.4970,                 loss: nan
agent1:                 episode reward: 0.4970,                 loss: 0.1017
Episode: 28781/30000 (95.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3393s / 364.2320 s
agent0:                 episode reward: -0.5693,                 loss: nan
agent1:                 episode reward: 0.5693,                 loss: 0.1016
Episode: 28801/30000 (96.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3440s / 364.5760 s
agent0:                 episode reward: -0.5792,                 loss: nan
agent1:                 episode reward: 0.5792,                 loss: 0.1024
Episode: 28821/30000 (96.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3517s / 364.9277 s
agent0:                 episode reward: -0.6037,                 loss: nan
agent1:                 episode reward: 0.6037,                 loss: 0.1020
Episode: 28841/30000 (96.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3469s / 365.2746 s
agent0:                 episode reward: -0.7877,                 loss: nan
agent1:                 episode reward: 0.7877,                 loss: 0.1005
Episode: 28861/30000 (96.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3456s / 365.6202 s
agent0:                 episode reward: -0.8008,                 loss: nan
agent1:                 episode reward: 0.8008,                 loss: 0.1009
Episode: 28881/30000 (96.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3396s / 365.9598 s
agent0:                 episode reward: -0.5659,                 loss: nan
agent1:                 episode reward: 0.5659,                 loss: 0.1003
Episode: 28901/30000 (96.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3418s / 366.3016 s
agent0:                 episode reward: -0.6677,                 loss: nan
agent1:                 episode reward: 0.6677,                 loss: 0.1018
Episode: 28921/30000 (96.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3447s / 366.6463 s
agent0:                 episode reward: -0.9077,                 loss: nan
agent1:                 episode reward: 0.9077,                 loss: 0.1016
Episode: 28941/30000 (96.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3430s / 366.9892 s
agent0:                 episode reward: -0.5727,                 loss: nan
agent1:                 episode reward: 0.5727,                 loss: 0.1006
Episode: 28961/30000 (96.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3660s / 367.3553 s
agent0:                 episode reward: -0.7170,                 loss: nan
agent1:                 episode reward: 0.7170,                 loss: 0.1013
Episode: 28981/30000 (96.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3612s / 367.7164 s
agent0:                 episode reward: -0.6053,                 loss: nan
agent1:                 episode reward: 0.6053,                 loss: 0.1007
Episode: 29001/30000 (96.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3291s / 368.0455 s
agent0:                 episode reward: -0.5495,                 loss: nan
agent1:                 episode reward: 0.5495,                 loss: 0.1009
Episode: 29021/30000 (96.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3319s / 368.3774 s
agent0:                 episode reward: -0.7441,                 loss: nan
agent1:                 episode reward: 0.7441,                 loss: 0.1015
Episode: 29041/30000 (96.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3300s / 368.7075 s
agent0:                 episode reward: -0.7546,                 loss: nan
agent1:                 episode reward: 0.7546,                 loss: 0.0995
Episode: 29061/30000 (96.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3373s / 369.0448 s
agent0:                 episode reward: -0.5634,                 loss: nan
agent1:                 episode reward: 0.5634,                 loss: 0.1020
Episode: 29081/30000 (96.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3349s / 369.3797 s
agent0:                 episode reward: -0.6396,                 loss: nan
agent1:                 episode reward: 0.6396,                 loss: 0.1003
Episode: 29101/30000 (97.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3320s / 369.7117 s
agent0:                 episode reward: -0.6325,                 loss: nan
agent1:                 episode reward: 0.6325,                 loss: 0.1004
Episode: 29121/30000 (97.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3245s / 370.0361 s
agent0:                 episode reward: -0.7284,                 loss: nan
agent1:                 episode reward: 0.7284,                 loss: 0.1015
Episode: 29141/30000 (97.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3376s / 370.3737 s
agent0:                 episode reward: -0.5573,                 loss: nan
agent1:                 episode reward: 0.5573,                 loss: 0.1015
Episode: 29161/30000 (97.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3406s / 370.7143 s
agent0:                 episode reward: -0.6236,                 loss: nan
agent1:                 episode reward: 0.6236,                 loss: 0.1016
Episode: 29181/30000 (97.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3266s / 371.0409 s
agent0:                 episode reward: -0.5648,                 loss: nan
agent1:                 episode reward: 0.5648,                 loss: 0.1005
Episode: 29201/30000 (97.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3497s / 371.3906 s
agent0:                 episode reward: -0.6735,                 loss: nan
agent1:                 episode reward: 0.6735,                 loss: 0.1018
Episode: 29221/30000 (97.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3283s / 371.7189 s
agent0:                 episode reward: -0.4684,                 loss: nan
agent1:                 episode reward: 0.4684,                 loss: 0.1022
Episode: 29241/30000 (97.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3313s / 372.0502 s
agent0:                 episode reward: -0.8805,                 loss: nan
agent1:                 episode reward: 0.8805,                 loss: 0.1003
Episode: 29261/30000 (97.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3291s / 372.3794 s
agent0:                 episode reward: -0.4882,                 loss: nan
agent1:                 episode reward: 0.4882,                 loss: 0.1012
Episode: 29281/30000 (97.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3246s / 372.7040 s
agent0:                 episode reward: -0.7881,                 loss: nan
agent1:                 episode reward: 0.7881,                 loss: 0.1009
Episode: 29301/30000 (97.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3311s / 373.0352 s
agent0:                 episode reward: -0.6937,                 loss: nan
agent1:                 episode reward: 0.6937,                 loss: 0.1020
Episode: 29321/30000 (97.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3372s / 373.3724 s
agent0:                 episode reward: -0.7858,                 loss: nan
agent1:                 episode reward: 0.7858,                 loss: 0.1017
Episode: 29341/30000 (97.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3533s / 373.7257 s
agent0:                 episode reward: -0.4556,                 loss: nan
agent1:                 episode reward: 0.4556,                 loss: 0.1027
Episode: 29361/30000 (97.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3445s / 374.0702 s
agent0:                 episode reward: -0.6171,                 loss: nan
agent1:                 episode reward: 0.6171,                 loss: 0.1011
Episode: 29381/30000 (97.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3477s / 374.4179 s
agent0:                 episode reward: -0.7487,                 loss: nan
agent1:                 episode reward: 0.7487,                 loss: 0.1027
Episode: 29401/30000 (98.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3484s / 374.7663 s
agent0:                 episode reward: -0.9040,                 loss: nan
agent1:                 episode reward: 0.9040,                 loss: 0.1010
Episode: 29421/30000 (98.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3403s / 375.1066 s
agent0:                 episode reward: -0.8308,                 loss: nan
agent1:                 episode reward: 0.8308,                 loss: 0.1022
Episode: 29441/30000 (98.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3447s / 375.4513 s
agent0:                 episode reward: -0.7138,                 loss: nan
agent1:                 episode reward: 0.7138,                 loss: 0.1012
Episode: 29461/30000 (98.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3466s / 375.7979 s
agent0:                 episode reward: -0.7890,                 loss: nan
agent1:                 episode reward: 0.7890,                 loss: 0.1019
Episode: 29481/30000 (98.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3461s / 376.1441 s
agent0:                 episode reward: -0.7120,                 loss: nan
agent1:                 episode reward: 0.7120,                 loss: 0.1023
Episode: 29501/30000 (98.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3558s / 376.4998 s
agent0:                 episode reward: -0.6976,                 loss: nan
agent1:                 episode reward: 0.6976,                 loss: 0.1024
Episode: 29521/30000 (98.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3519s / 376.8517 s
agent0:                 episode reward: -0.5299,                 loss: nan
agent1:                 episode reward: 0.5299,                 loss: 0.1004
Episode: 29541/30000 (98.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3351s / 377.1868 s
agent0:                 episode reward: -0.3928,                 loss: nan
agent1:                 episode reward: 0.3928,                 loss: 0.1022
Episode: 29561/30000 (98.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3359s / 377.5227 s
agent0:                 episode reward: -0.6899,                 loss: nan
agent1:                 episode reward: 0.6899,                 loss: 0.1023
Episode: 29581/30000 (98.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3367s / 377.8594 s
agent0:                 episode reward: -0.6368,                 loss: nan
agent1:                 episode reward: 0.6368,                 loss: 0.1014
Episode: 29601/30000 (98.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3992s / 378.2586 s
agent0:                 episode reward: -1.0346,                 loss: nan
agent1:                 episode reward: 1.0346,                 loss: 0.1005/home/quantumiracle/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/quantumiracle/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

Episode: 29621/30000 (98.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3383s / 378.5969 s
agent0:                 episode reward: -0.5371,                 loss: nan
agent1:                 episode reward: 0.5371,                 loss: 0.1024
Episode: 29641/30000 (98.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3373s / 378.9342 s
agent0:                 episode reward: -0.7373,                 loss: nan
agent1:                 episode reward: 0.7373,                 loss: 0.1023
Episode: 29661/30000 (98.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3335s / 379.2676 s
agent0:                 episode reward: -0.7310,                 loss: nan
agent1:                 episode reward: 0.7310,                 loss: 0.1026
Episode: 29681/30000 (98.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3724s / 379.6400 s
agent0:                 episode reward: -0.7795,                 loss: nan
agent1:                 episode reward: 0.7795,                 loss: 0.1025
Episode: 29701/30000 (99.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3493s / 379.9892 s
agent0:                 episode reward: -0.6239,                 loss: nan
agent1:                 episode reward: 0.6239,                 loss: 0.1016
Episode: 29721/30000 (99.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3523s / 380.3415 s
agent0:                 episode reward: -0.7410,                 loss: nan
agent1:                 episode reward: 0.7410,                 loss: 0.1018
Episode: 29741/30000 (99.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3508s / 380.6923 s
agent0:                 episode reward: -0.6966,                 loss: nan
agent1:                 episode reward: 0.6966,                 loss: 0.1027
Episode: 29761/30000 (99.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3449s / 381.0372 s
agent0:                 episode reward: -0.4452,                 loss: nan
agent1:                 episode reward: 0.4452,                 loss: 0.1022
Episode: 29781/30000 (99.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3530s / 381.3903 s
agent0:                 episode reward: -0.7223,                 loss: nan
agent1:                 episode reward: 0.7223,                 loss: 0.1026
Episode: 29801/30000 (99.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3522s / 381.7424 s
agent0:                 episode reward: -0.9481,                 loss: nan
agent1:                 episode reward: 0.9481,                 loss: 0.1013
Episode: 29821/30000 (99.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3490s / 382.0915 s
agent0:                 episode reward: -0.2464,                 loss: nan
agent1:                 episode reward: 0.2464,                 loss: 0.1042
Episode: 29841/30000 (99.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3509s / 382.4424 s
agent0:                 episode reward: -1.0643,                 loss: nan
agent1:                 episode reward: 1.0643,                 loss: 0.1021
Episode: 29861/30000 (99.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3742s / 382.8166 s
agent0:                 episode reward: -0.3753,                 loss: nan
agent1:                 episode reward: 0.3753,                 loss: 0.1024
Episode: 29881/30000 (99.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3501s / 383.1667 s
agent0:                 episode reward: -0.6362,                 loss: nan
agent1:                 episode reward: 0.6362,                 loss: 0.1018
Episode: 29901/30000 (99.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3538s / 383.5204 s
agent0:                 episode reward: -0.8527,                 loss: nan
agent1:                 episode reward: 0.8527,                 loss: 0.1005
Episode: 29921/30000 (99.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3682s / 383.8886 s
agent0:                 episode reward: -0.8294,                 loss: nan
agent1:                 episode reward: 0.8294,                 loss: 0.1014
Episode: 29941/30000 (99.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3523s / 384.2409 s
agent0:                 episode reward: -0.8021,                 loss: nan
agent1:                 episode reward: 0.8021,                 loss: 0.1021
Episode: 29961/30000 (99.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3484s / 384.5894 s
agent0:                 episode reward: -0.5322,                 loss: nan
agent1:                 episode reward: 0.5322,                 loss: 0.1017
Episode: 29981/30000 (99.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3539s / 384.9433 s
agent0:                 episode reward: -0.5412,                 loss: nan
agent1:                 episode reward: 0.5412,                 loss: 0.1002
