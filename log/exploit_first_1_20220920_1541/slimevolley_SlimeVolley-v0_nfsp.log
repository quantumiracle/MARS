/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
slimevolley_SlimeVolley-v0
default:  {'env_name': 'SlimeVolley-v0', 'env_type': 'slimevolley', 'num_envs': 5, 'ram': True, 'seed': 'random', 'record_video': False, 'against_baseline': False, 'algorithm': 'NFSP', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 300, 'train_start_frame': 10000, 'save_id': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'wandb_activate': False, 'wandb_entity': '', 'wandb_project': '', 'wandb_group': '', 'wandb_name': '', 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False, 'policy': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': 'Softmax'}}, 'marl_method': 'nfsp', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'eta': 0.1}}
{'env_name': 'SlimeVolley-v0', 'env_type': 'slimevolley', 'num_envs': 5, 'ram': True, 'seed': 'random', 'record_video': False, 'against_baseline': False, 'algorithm': 'NFSP', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 300, 'train_start_frame': 10000, 'save_id': 202209252250, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'wandb_activate': False, 'wandb_entity': '', 'wandb_project': '', 'wandb_group': '', 'wandb_name': '', 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False, 'policy': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': 'Softmax'}}, 'marl_method': 'nfsp', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'eta': 0.1}, 'load_id': 202209201541, 'to_exploit': 'first_1'}
SlimeVolley-v0 slimevolley
record video: interval 100, length 300
Load SlimeVolley-v0 environment in type slimevolley.
Env observation space: Box(-3.4028235e+38, 3.4028235e+38, (12,), float32) action space: Discrete(6)
random seed: 559
<mars.env.wrappers.mars_wrappers.Dict2TupleWrapper object at 0x7f1c4f1cbe10>
discrete_policy 6 Discrete(6)
discrete_policy 6 Discrete(6)
Traceback (most recent call last):
  File "general_exploit.py", line 48, in <module>
    launch()
  File "general_exploit.py", line 30, in launch
    trained_model = eval(args.algorithm)(env, args)
  File "/data/zihan/research/MARS/mars/rl/agents/nfsp.py", line 18, in __init__
    self._init_model(env, args)
  File "/data/zihan/research/MARS/mars/rl/agents/nfsp.py", line 37, in _init_model
    self.rl_agent = DQN(env, args)  # TODO can also use other RL agents
  File "/data/zihan/research/MARS/mars/rl/agents/dqn.py", line 19, in __init__
    self._init_model(env, args)
  File "/data/zihan/research/MARS/mars/rl/agents/dqn.py", line 38, in _init_model
    self.model = self._select_type(env, args).to(self.device)
  File "/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
slimevolley_SlimeVolley-v0
default:  {'env_name': 'SlimeVolley-v0', 'env_type': 'slimevolley', 'num_envs': 5, 'ram': True, 'seed': 'random', 'record_video': False, 'against_baseline': False, 'algorithm': 'NFSP', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 300, 'train_start_frame': 10000, 'save_id': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'wandb_activate': False, 'wandb_entity': '', 'wandb_project': '', 'wandb_group': '', 'wandb_name': '', 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False, 'policy': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': 'Softmax'}}, 'marl_method': 'nfsp', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'eta': 0.1}}
{'env_name': 'SlimeVolley-v0', 'env_type': 'slimevolley', 'num_envs': 5, 'ram': True, 'seed': 'random', 'record_video': False, 'against_baseline': False, 'algorithm': 'NFSP', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 300, 'train_start_frame': 10000, 'save_id': 202209252254, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'wandb_activate': False, 'wandb_entity': '', 'wandb_project': '', 'wandb_group': '', 'wandb_name': '', 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False, 'policy': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': 'Softmax'}}, 'marl_method': 'nfsp', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'eta': 0.1}, 'load_id': 202209201541, 'to_exploit': 'first_1'}
SlimeVolley-v0 slimevolley
record video: interval 100, length 300
Load SlimeVolley-v0 environment in type slimevolley.
Env observation space: Box(-3.4028235e+38, 3.4028235e+38, (12,), float32) action space: Discrete(6)
random seed: 953
<mars.env.wrappers.mars_wrappers.Dict2TupleWrapper object at 0x7fe3c3dd5b70>
discrete_policy 6 Discrete(6)
discrete_policy 6 Discrete(6)
discrete_policy 6 Discrete(6)
discrete_policy 6 Discrete(6)
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  ./data/model/202209201541/slimevolley_SlimeVolley-v0_nfsp/8000_0
Arguments:  {'env_name': 'SlimeVolley-v0', 'env_type': 'slimevolley', 'num_envs': 1, 'ram': True, 'seed': 'random', 'record_video': False, 'against_baseline': False, 'algorithm': 'NFSP', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 50000, 'max_steps_per_episode': 300, 'train_start_frame': 10000, 'save_id': 202209252254, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': './data/model/202209201541/slimevolley_SlimeVolley-v0_nfsp/8000_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'wandb_activate': False, 'wandb_entity': '', 'wandb_project': '', 'wandb_group': '', 'wandb_name': '', 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False, 'policy': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': 'Softmax'}}, 'marl_method': 'nfsp', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'eta': 0.1}, 'load_id': 202209201541, 'to_exploit': 'first_1', 'idx_exploited_model': 0}
Save models to : /data/zihan/research/MARS/data/model/202209201541_exploit_first/slimevolley_SlimeVolley-v0_nfsp. 
 Save logs to: /data/zihan/research/MARS/data/log/202209201541_exploit_first/slimevolley_SlimeVolley-v0_nfsp.
Traceback (most recent call last):
  File "general_exploit.py", line 48, in <module>
    launch()
  File "general_exploit.py", line 45, in launch
    rollout(env, model, exploitation_args, save_id = str(args.load_id)+f'_exploit_{to_exploit}') # save results of exploitation in a separate folder
  File "/data/zihan/research/MARS/mars/rollout.py", line 21, in rollout
    rollout_normal(env, model, save_id, args)
  File "/data/zihan/research/MARS/mars/rollout.py", line 128, in rollout_normal
    obs_, reward, done, info = env.step(action)  # required action shape: (envs, agents, dim)
  File "/data/zihan/research/MARS/mars/env/wrappers/mars_wrappers.py", line 535, in step
    obs, rewards, dones, infos = self.env.step(actions)
  File "/data/zihan/research/MARS/mars/env/wrappers/mars_wrappers.py", line 475, in step
    obs0, reward, done, info = self.env.step(*actions_)  # gym!=0.18 will break this line
TypeError: step() takes 2 positional arguments but 3 were given
slimevolley_SlimeVolley-v0
default:  {'env_name': 'SlimeVolley-v0', 'env_type': 'slimevolley', 'num_envs': 5, 'ram': True, 'seed': 'random', 'record_video': False, 'against_baseline': False, 'algorithm': 'NFSP', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 300, 'train_start_frame': 10000, 'save_id': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'wandb_activate': False, 'wandb_entity': '', 'wandb_project': '', 'wandb_group': '', 'wandb_name': '', 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False, 'policy': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': 'Softmax'}}, 'marl_method': 'nfsp', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'eta': 0.1}}
{'env_name': 'SlimeVolley-v0', 'env_type': 'slimevolley', 'num_envs': 5, 'ram': True, 'seed': 'random', 'record_video': False, 'against_baseline': False, 'algorithm': 'NFSP', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 300, 'train_start_frame': 10000, 'save_id': 202209252301, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'wandb_activate': False, 'wandb_entity': '', 'wandb_project': '', 'wandb_group': '', 'wandb_name': '', 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False, 'policy': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': 'Softmax'}}, 'marl_method': 'nfsp', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'eta': 0.1}, 'load_id': 202209201541, 'to_exploit': 'first_1'}
SlimeVolley-v0 slimevolley
record video: interval 100, length 300
Load SlimeVolley-v0 environment in type slimevolley.
Env observation space: Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (12,), float32) action space: Discrete(6)
random seed: 530
<mars.env.wrappers.mars_wrappers.Dict2TupleWrapper object at 0x7f0725184ac8>
discrete_policy 6 Discrete(6)
discrete_policy 6 Discrete(6)
discrete_policy 6 Discrete(6)
discrete_policy 6 Discrete(6)
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  ./data/model/202209201541/slimevolley_SlimeVolley-v0_nfsp/8000_0
Arguments:  {'env_name': 'SlimeVolley-v0', 'env_type': 'slimevolley', 'num_envs': 1, 'ram': True, 'seed': 'random', 'record_video': False, 'against_baseline': False, 'algorithm': 'NFSP', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 50000, 'max_steps_per_episode': 300, 'train_start_frame': 10000, 'save_id': 202209252301, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': './data/model/202209201541/slimevolley_SlimeVolley-v0_nfsp/8000_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'wandb_activate': False, 'wandb_entity': '', 'wandb_project': '', 'wandb_group': '', 'wandb_name': '', 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False, 'policy': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': 'Softmax'}}, 'marl_method': 'nfsp', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'eta': 0.1}, 'load_id': 202209201541, 'to_exploit': 'first_1', 'idx_exploited_model': 0}
Save models to : /data/zihan/research/MARS/data/model/202209201541_exploit_first/slimevolley_SlimeVolley-v0_nfsp. 
 Save logs to: /data/zihan/research/MARS/data/log/202209201541_exploit_first/slimevolley_SlimeVolley-v0_nfsp.
Episode: 1/50000 (0.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 6.62s / 6.62 s
first_0:                 episode reward: -1.0000,                 loss: nan
second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 21/50000 (0.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 58.58s / 65.20 s
first_0:                 episode reward: 0.1000,                 loss: nan
second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 41/50000 (0.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 93.12s / 158.32 s
first_0:                 episode reward: 0.3500,                 loss: nan
second_0:                 episode reward: -0.3500,                 loss: 0.4439
Episode: 61/50000 (0.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 148.96s / 307.27 s
first_0:                 episode reward: -0.2000,                 loss: nan
second_0:                 episode reward: 0.2000,                 loss: 0.0660
Episode: 81/50000 (0.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 149.05s / 456.33 s
first_0:                 episode reward: 0.2000,                 loss: nan
second_0:                 episode reward: -0.2000,                 loss: 0.0454
Episode: 101/50000 (0.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 148.95s / 605.28 s
first_0:                 episode reward: 0.1000,                 loss: nan
second_0:                 episode reward: -0.1000,                 loss: 0.0432
Episode: 121/50000 (0.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 149.62s / 754.90 s
first_0:                 episode reward: 0.2500,                 loss: nan
second_0:                 episode reward: -0.2500,                 loss: 0.0429
Episode: 141/50000 (0.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 151.31s / 906.21 s
first_0:                 episode reward: 0.3500,                 loss: nan
second_0:                 episode reward: -0.3500,                 loss: 0.0468
Episode: 161/50000 (0.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 151.26s / 1057.47 s
first_0:                 episode reward: 0.0500,                 loss: nan
second_0:                 episode reward: -0.0500,                 loss: 0.0466
Episode: 181/50000 (0.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 152.04s / 1209.51 s
first_0:                 episode reward: -0.1000,                 loss: nan
second_0:                 episode reward: 0.1000,                 loss: 0.0438
Episode: 201/50000 (0.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 151.53s / 1361.04 s
first_0:                 episode reward: 0.4000,                 loss: nan
second_0:                 episode reward: -0.4000,                 loss: 0.0433
Episode: 221/50000 (0.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 152.62s / 1513.66 s
first_0:                 episode reward: 0.0500,                 loss: nan
second_0:                 episode reward: -0.0500,                 loss: 0.0441
Episode: 241/50000 (0.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 153.02s / 1666.69 s
first_0:                 episode reward: 1.0500,                 loss: nan
second_0:                 episode reward: -1.0500,                 loss: 0.0444
Episode: 261/50000 (0.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 153.83s / 1820.51 s
first_0:                 episode reward: 0.2500,                 loss: nan
second_0:                 episode reward: -0.2500,                 loss: 0.0439
Episode: 281/50000 (0.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 153.23s / 1973.74 s
first_0:                 episode reward: -0.0500,                 loss: nan
second_0:                 episode reward: 0.0500,                 loss: 0.0418
Episode: 301/50000 (0.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 153.82s / 2127.56 s
first_0:                 episode reward: 0.8000,                 loss: nan
second_0:                 episode reward: -0.8000,                 loss: 0.0423
Episode: 321/50000 (0.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 154.21s / 2281.77 s
first_0:                 episode reward: 0.0000,                 loss: nan
second_0:                 episode reward: 0.0000,                 loss: 0.0414
Episode: 341/50000 (0.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 154.33s / 2436.10 s
first_0:                 episode reward: -0.5500,                 loss: nan
second_0:                 episode reward: 0.5500,                 loss: 0.0413
Episode: 361/50000 (0.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 154.43s / 2590.53 s
first_0:                 episode reward: -0.2500,                 loss: nan
second_0:                 episode reward: 0.2500,                 loss: 0.0418
Episode: 381/50000 (0.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 155.27s / 2745.80 s
first_0:                 episode reward: -0.2500,                 loss: nan
second_0:                 episode reward: 0.2500,                 loss: 0.0423
Episode: 401/50000 (0.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 155.21s / 2901.02 s
first_0:                 episode reward: 0.2500,                 loss: nan
second_0:                 episode reward: -0.2500,                 loss: 0.0417
Episode: 421/50000 (0.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 156.00s / 3057.02 s
first_0:                 episode reward: -0.4500,                 loss: nan
second_0:                 episode reward: 0.4500,                 loss: 0.0420
Episode: 441/50000 (0.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 156.17s / 3213.19 s
first_0:                 episode reward: -0.4500,                 loss: nan
second_0:                 episode reward: 0.4500,                 loss: 0.0404
Episode: 461/50000 (0.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 156.96s / 3370.15 s
first_0:                 episode reward: 0.2500,                 loss: nan
second_0:                 episode reward: -0.2500,                 loss: 0.0407
Episode: 481/50000 (0.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 157.64s / 3527.78 s
first_0:                 episode reward: 0.7000,                 loss: nan
second_0:                 episode reward: -0.7000,                 loss: 0.0404
Episode: 501/50000 (1.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 157.76s / 3685.54 s
first_0:                 episode reward: 0.7000,                 loss: nan
second_0:                 episode reward: -0.7000,                 loss: 0.0422
Episode: 521/50000 (1.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 158.18s / 3843.72 s
first_0:                 episode reward: -0.1000,                 loss: nan
second_0:                 episode reward: 0.1000,                 loss: 0.0449
Episode: 541/50000 (1.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 158.35s / 4002.07 s
first_0:                 episode reward: 0.3000,                 loss: nan
second_0:                 episode reward: -0.3000,                 loss: 0.0451
Episode: 561/50000 (1.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 159.40s / 4161.47 s
first_0:                 episode reward: 0.4500,                 loss: nan
second_0:                 episode reward: -0.4500,                 loss: 0.0450
Episode: 581/50000 (1.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 158.97s / 4320.44 s
first_0:                 episode reward: 0.3000,                 loss: nan
second_0:                 episode reward: -0.3000,                 loss: 0.0441
Episode: 601/50000 (1.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 159.35s / 4479.78 s
first_0:                 episode reward: 0.6000,                 loss: nan
second_0:                 episode reward: -0.6000,                 loss: 0.0433
Episode: 621/50000 (1.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 159.32s / 4639.10 s
first_0:                 episode reward: 0.2000,                 loss: nan
second_0:                 episode reward: -0.2000,                 loss: 0.0421
Episode: 641/50000 (1.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 159.71s / 4798.82 s
first_0:                 episode reward: 0.2500,                 loss: nan
second_0:                 episode reward: -0.2500,                 loss: 0.0412
Episode: 661/50000 (1.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 158.44s / 4957.26 s
first_0:                 episode reward: 0.4500,                 loss: nan
second_0:                 episode reward: -0.4500,                 loss: 0.0426
Episode: 681/50000 (1.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 159.96s / 5117.22 s
first_0:                 episode reward: -0.1500,                 loss: nan
second_0:                 episode reward: 0.1500,                 loss: 0.0411
Episode: 701/50000 (1.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 159.42s / 5276.65 s
first_0:                 episode reward: 0.0500,                 loss: nan
second_0:                 episode reward: -0.0500,                 loss: 0.0431
Episode: 721/50000 (1.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 160.17s / 5436.82 s
first_0:                 episode reward: -0.5000,                 loss: nan
second_0:                 episode reward: 0.5000,                 loss: 0.0436
Episode: 741/50000 (1.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 160.15s / 5596.97 s
first_0:                 episode reward: 0.4500,                 loss: nan
second_0:                 episode reward: -0.4500,                 loss: 0.0422
Episode: 761/50000 (1.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 160.38s / 5757.34 s
first_0:                 episode reward: -0.1500,                 loss: nan
second_0:                 episode reward: 0.1500,                 loss: 0.0403
Episode: 781/50000 (1.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 159.45s / 5916.80 s
first_0:                 episode reward: 0.7000,                 loss: nan
second_0:                 episode reward: -0.7000,                 loss: 0.0409
Episode: 801/50000 (1.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 159.28s / 6076.08 s
first_0:                 episode reward: 0.0500,                 loss: nan
second_0:                 episode reward: -0.0500,                 loss: 0.0405
Episode: 821/50000 (1.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 159.73s / 6235.81 s
first_0:                 episode reward: 0.7500,                 loss: nan
second_0:                 episode reward: -0.7500,                 loss: 0.0388
Episode: 841/50000 (1.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 160.14s / 6395.95 s
first_0:                 episode reward: 0.0500,                 loss: nan
second_0:                 episode reward: -0.0500,                 loss: 0.0406
Episode: 861/50000 (1.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 159.56s / 6555.51 s
first_0:                 episode reward: 0.1000,                 loss: nan
second_0:                 episode reward: -0.1000,                 loss: 0.0388
Episode: 881/50000 (1.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 160.70s / 6716.20 s
first_0:                 episode reward: 0.0500,                 loss: nan
second_0:                 episode reward: -0.0500,                 loss: 0.0399
Episode: 901/50000 (1.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 160.39s / 6876.60 s
first_0:                 episode reward: -0.1000,                 loss: nan
second_0:                 episode reward: 0.1000,                 loss: 0.0391
Episode: 921/50000 (1.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 160.54s / 7037.14 s
first_0:                 episode reward: 0.2000,                 loss: nan
second_0:                 episode reward: -0.2000,                 loss: 0.0375
Episode: 941/50000 (1.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 160.87s / 7198.00 s
first_0:                 episode reward: 0.2000,                 loss: nan
second_0:                 episode reward: -0.2000,                 loss: 0.0382
Episode: 961/50000 (1.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.09s / 7359.09 s
first_0:                 episode reward: 0.4500,                 loss: nan
second_0:                 episode reward: -0.4500,                 loss: 0.0383
Episode: 981/50000 (1.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 160.54s / 7519.64 s
first_0:                 episode reward: 0.5000,                 loss: nan
second_0:                 episode reward: -0.5000,                 loss: 0.0393
Episode: 1001/50000 (2.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 160.74s / 7680.38 s
first_0:                 episode reward: -0.1000,                 loss: nan
second_0:                 episode reward: 0.1000,                 loss: 0.0394
Episode: 1021/50000 (2.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 160.53s / 7840.91 s
first_0:                 episode reward: 0.5500,                 loss: nan
second_0:                 episode reward: -0.5500,                 loss: 0.0409
Episode: 1041/50000 (2.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 160.38s / 8001.29 s
first_0:                 episode reward: 0.4000,                 loss: nan
second_0:                 episode reward: -0.4000,                 loss: 0.0386
Episode: 1061/50000 (2.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.08s / 8162.37 s
first_0:                 episode reward: -0.1500,                 loss: nan
second_0:                 episode reward: 0.1500,                 loss: 0.0386
Episode: 1081/50000 (2.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 160.71s / 8323.08 s
first_0:                 episode reward: 0.0000,                 loss: nan
second_0:                 episode reward: 0.0000,                 loss: 0.0388
Episode: 1101/50000 (2.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.10s / 8484.19 s
first_0:                 episode reward: 0.1500,                 loss: nan
second_0:                 episode reward: -0.1500,                 loss: 0.0381
Episode: 1121/50000 (2.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.06s / 8645.25 s
first_0:                 episode reward: 0.2000,                 loss: nan
second_0:                 episode reward: -0.2000,                 loss: 0.0391
Episode: 1141/50000 (2.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 160.40s / 8805.65 s
first_0:                 episode reward: -0.0500,                 loss: nan
second_0:                 episode reward: 0.0500,                 loss: 0.0383
Episode: 1161/50000 (2.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.03s / 8966.68 s
first_0:                 episode reward: -0.1000,                 loss: nan
second_0:                 episode reward: 0.1000,                 loss: 0.0387
Episode: 1181/50000 (2.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 160.57s / 9127.25 s
first_0:                 episode reward: 0.5000,                 loss: nan
second_0:                 episode reward: -0.5000,                 loss: 0.0381
Episode: 1201/50000 (2.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 160.44s / 9287.69 s
first_0:                 episode reward: 0.4000,                 loss: nan
second_0:                 episode reward: -0.4000,                 loss: 0.0387
Episode: 1221/50000 (2.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 160.98s / 9448.67 s
first_0:                 episode reward: -0.8000,                 loss: nan
second_0:                 episode reward: 0.8000,                 loss: 0.0380
Episode: 1241/50000 (2.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.97s / 9610.64 s
first_0:                 episode reward: 0.0500,                 loss: nan
second_0:                 episode reward: -0.0500,                 loss: 0.0370
Episode: 1261/50000 (2.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.23s / 9771.86 s
first_0:                 episode reward: 0.0000,                 loss: nan
second_0:                 episode reward: 0.0000,                 loss: 0.0379
Episode: 1281/50000 (2.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.38s / 9933.25 s
first_0:                 episode reward: 0.4000,                 loss: nan
second_0:                 episode reward: -0.4000,                 loss: 0.0382
Episode: 1301/50000 (2.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.00s / 10094.25 s
first_0:                 episode reward: -0.5500,                 loss: nan
second_0:                 episode reward: 0.5500,                 loss: 0.0380
Episode: 1321/50000 (2.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 160.57s / 10254.82 s
first_0:                 episode reward: 0.3000,                 loss: nan
second_0:                 episode reward: -0.3000,                 loss: 0.0388
Episode: 1341/50000 (2.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.05s / 10415.87 s
first_0:                 episode reward: 0.1000,                 loss: nan
second_0:                 episode reward: -0.1000,                 loss: 0.0375
Episode: 1361/50000 (2.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.11s / 10576.97 s
first_0:                 episode reward: 0.4500,                 loss: nan
second_0:                 episode reward: -0.4500,                 loss: 0.0377
Episode: 1381/50000 (2.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 160.98s / 10737.95 s
first_0:                 episode reward: 0.4500,                 loss: nan
second_0:                 episode reward: -0.4500,                 loss: 0.0374
Episode: 1401/50000 (2.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.29s / 10899.24 s
first_0:                 episode reward: 0.1000,                 loss: nan
second_0:                 episode reward: -0.1000,                 loss: 0.0369
Episode: 1421/50000 (2.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.17s / 11060.40 s
first_0:                 episode reward: 0.2500,                 loss: nan
second_0:                 episode reward: -0.2500,                 loss: 0.0372
Episode: 1441/50000 (2.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.86s / 11222.26 s
first_0:                 episode reward: -0.0500,                 loss: nan
second_0:                 episode reward: 0.0500,                 loss: 0.0377
Episode: 1461/50000 (2.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 160.51s / 11382.78 s
first_0:                 episode reward: -0.2000,                 loss: nan
second_0:                 episode reward: 0.2000,                 loss: 0.0382
Episode: 1481/50000 (2.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.26s / 11544.04 s
first_0:                 episode reward: 0.3500,                 loss: nan
second_0:                 episode reward: -0.3500,                 loss: 0.0381
Episode: 1501/50000 (3.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.60s / 11705.64 s
first_0:                 episode reward: 0.2500,                 loss: nan
second_0:                 episode reward: -0.2500,                 loss: 0.0382
Episode: 1521/50000 (3.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.47s / 11867.11 s
first_0:                 episode reward: -0.2500,                 loss: nan
second_0:                 episode reward: 0.2500,                 loss: 0.0383
Episode: 1541/50000 (3.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.86s / 12028.96 s
first_0:                 episode reward: 0.1000,                 loss: nan
second_0:                 episode reward: -0.1000,                 loss: 0.0374
Episode: 1561/50000 (3.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.98s / 12190.94 s
first_0:                 episode reward: 0.7000,                 loss: nan
second_0:                 episode reward: -0.7000,                 loss: 0.0382
Episode: 1581/50000 (3.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.54s / 12352.49 s
first_0:                 episode reward: -0.4500,                 loss: nan
second_0:                 episode reward: 0.4500,                 loss: 0.0383
Episode: 1601/50000 (3.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.33s / 12513.82 s
first_0:                 episode reward: 0.1500,                 loss: nan
second_0:                 episode reward: -0.1500,                 loss: 0.0394
Episode: 1621/50000 (3.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.24s / 12675.05 s
first_0:                 episode reward: -0.1500,                 loss: nan
second_0:                 episode reward: 0.1500,                 loss: 0.0389
Episode: 1641/50000 (3.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 160.78s / 12835.83 s
first_0:                 episode reward: -0.4000,                 loss: nan
second_0:                 episode reward: 0.4000,                 loss: 0.0384
Episode: 1661/50000 (3.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 160.92s / 12996.75 s
first_0:                 episode reward: -0.5000,                 loss: nan
second_0:                 episode reward: 0.5000,                 loss: 0.0388
Episode: 1681/50000 (3.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 160.91s / 13157.66 s
first_0:                 episode reward: 0.0000,                 loss: nan
second_0:                 episode reward: 0.0000,                 loss: 0.0383
Episode: 1701/50000 (3.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.38s / 13319.04 s
first_0:                 episode reward: 0.4500,                 loss: nan
second_0:                 episode reward: -0.4500,                 loss: 0.0386
Episode: 1721/50000 (3.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.92s / 13480.97 s
first_0:                 episode reward: -0.0500,                 loss: nan
second_0:                 episode reward: 0.0500,                 loss: 0.0384
Episode: 1741/50000 (3.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.00s / 13641.96 s
first_0:                 episode reward: 0.3000,                 loss: nan
second_0:                 episode reward: -0.3000,                 loss: 0.0391
Episode: 1761/50000 (3.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.50s / 13803.46 s
first_0:                 episode reward: -0.2000,                 loss: nan
second_0:                 episode reward: 0.2000,                 loss: 0.0397
Episode: 1781/50000 (3.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.21s / 13964.67 s
first_0:                 episode reward: -0.7000,                 loss: nan
second_0:                 episode reward: 0.7000,                 loss: 0.0410
Episode: 1801/50000 (3.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.92s / 14126.59 s
first_0:                 episode reward: 0.2000,                 loss: nan
second_0:                 episode reward: -0.2000,                 loss: 0.0398
Episode: 1821/50000 (3.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 162.86s / 14289.45 s
first_0:                 episode reward: 0.4000,                 loss: nan
second_0:                 episode reward: -0.4000,                 loss: 0.0392
Episode: 1841/50000 (3.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 162.28s / 14451.73 s
first_0:                 episode reward: 0.0000,                 loss: nan
second_0:                 episode reward: 0.0000,                 loss: 0.0389
Episode: 1861/50000 (3.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.16s / 14612.89 s
first_0:                 episode reward: 0.2000,                 loss: nan
second_0:                 episode reward: -0.2000,                 loss: 0.0390
Episode: 1881/50000 (3.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.35s / 14774.24 s
first_0:                 episode reward: 0.0000,                 loss: nan
second_0:                 episode reward: 0.0000,                 loss: 0.0390
Episode: 1901/50000 (3.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.26s / 14935.50 s
first_0:                 episode reward: 0.5500,                 loss: nan
second_0:                 episode reward: -0.5500,                 loss: 0.0405
Episode: 1921/50000 (3.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.53s / 15097.03 s
first_0:                 episode reward: 0.0500,                 loss: nan
second_0:                 episode reward: -0.0500,                 loss: 0.0398
Episode: 1941/50000 (3.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.72s / 15258.76 s
first_0:                 episode reward: -0.3000,                 loss: nan
second_0:                 episode reward: 0.3000,                 loss: 0.0388
Episode: 1961/50000 (3.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.27s / 15420.03 s
first_0:                 episode reward: 0.1000,                 loss: nan
second_0:                 episode reward: -0.1000,                 loss: 0.0388
Episode: 1981/50000 (3.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.81s / 15581.83 s
first_0:                 episode reward: 0.3500,                 loss: nan
second_0:                 episode reward: -0.3500,                 loss: 0.0378
Episode: 2001/50000 (4.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.03s / 15742.86 s
first_0:                 episode reward: 0.2500,                 loss: nan
second_0:                 episode reward: -0.2500,                 loss: 0.0379
Episode: 2021/50000 (4.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.72s / 15904.58 s
first_0:                 episode reward: 0.5500,                 loss: nan
second_0:                 episode reward: -0.5500,                 loss: 0.0378
Episode: 2041/50000 (4.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 162.27s / 16066.85 s
first_0:                 episode reward: 0.0500,                 loss: nan
second_0:                 episode reward: -0.0500,                 loss: 0.0382
Episode: 2061/50000 (4.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 162.74s / 16229.59 s
first_0:                 episode reward: 0.5000,                 loss: nan
second_0:                 episode reward: -0.5000,                 loss: 0.0377
Episode: 2081/50000 (4.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 162.80s / 16392.39 s
first_0:                 episode reward: 0.0500,                 loss: nan
second_0:                 episode reward: -0.0500,                 loss: 0.0387
Episode: 2101/50000 (4.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 163.06s / 16555.45 s
first_0:                 episode reward: 0.0500,                 loss: nan
second_0:                 episode reward: -0.0500,                 loss: 0.0374
Episode: 2121/50000 (4.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 160.50s / 16715.95 s
first_0:                 episode reward: 0.1500,                 loss: nan
second_0:                 episode reward: -0.1500,                 loss: 0.0369
Episode: 2141/50000 (4.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.84s / 16877.80 s
first_0:                 episode reward: -0.4000,                 loss: nan
second_0:                 episode reward: 0.4000,                 loss: 0.0376
Episode: 2161/50000 (4.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 160.75s / 17038.54 s
first_0:                 episode reward: 0.2000,                 loss: nan
second_0:                 episode reward: -0.2000,                 loss: 0.0376
Episode: 2181/50000 (4.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.13s / 17199.67 s
first_0:                 episode reward: -0.0500,                 loss: nan
second_0:                 episode reward: 0.0500,                 loss: 0.0370
Episode: 2201/50000 (4.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.46s / 17361.14 s
first_0:                 episode reward: -0.2000,                 loss: nan
second_0:                 episode reward: 0.2000,                 loss: 0.0367
Episode: 2221/50000 (4.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.06s / 17522.19 s
first_0:                 episode reward: 0.2000,                 loss: nan
second_0:                 episode reward: -0.2000,                 loss: 0.0364
Episode: 2241/50000 (4.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 162.01s / 17684.20 s
first_0:                 episode reward: -0.3000,                 loss: nan
second_0:                 episode reward: 0.3000,                 loss: 0.0363
Episode: 2261/50000 (4.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.35s / 17845.55 s
first_0:                 episode reward: 0.7500,                 loss: nan
second_0:                 episode reward: -0.7500,                 loss: 0.0366
Episode: 2281/50000 (4.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.64s / 18007.18 s
first_0:                 episode reward: 0.3000,                 loss: nan
second_0:                 episode reward: -0.3000,                 loss: 0.0373
Episode: 2301/50000 (4.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 160.94s / 18168.12 s
first_0:                 episode reward: -0.2500,                 loss: nan
second_0:                 episode reward: 0.2500,                 loss: 0.0364
Episode: 2321/50000 (4.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.84s / 18329.96 s
first_0:                 episode reward: 0.7500,                 loss: nan
second_0:                 episode reward: -0.7500,                 loss: 0.0368
Episode: 2341/50000 (4.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 162.38s / 18492.34 s
first_0:                 episode reward: -0.0500,                 loss: nan
second_0:                 episode reward: 0.0500,                 loss: 0.0366
Episode: 2361/50000 (4.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 162.64s / 18654.99 s
first_0:                 episode reward: 0.5500,                 loss: nan
second_0:                 episode reward: -0.5500,                 loss: 0.0357
Episode: 2381/50000 (4.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 162.06s / 18817.05 s
first_0:                 episode reward: -0.5000,                 loss: nan
second_0:                 episode reward: 0.5000,                 loss: 0.0366
Episode: 2401/50000 (4.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 162.24s / 18979.29 s
first_0:                 episode reward: 0.1500,                 loss: nan
second_0:                 episode reward: -0.1500,                 loss: 0.0360
Episode: 2421/50000 (4.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.03s / 19140.32 s
first_0:                 episode reward: 0.2000,                 loss: nan
second_0:                 episode reward: -0.2000,                 loss: 0.0372
Episode: 2441/50000 (4.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.76s / 19302.08 s
first_0:                 episode reward: 0.3500,                 loss: nan
second_0:                 episode reward: -0.3500,                 loss: 0.0382
Episode: 2461/50000 (4.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 160.95s / 19463.02 s
first_0:                 episode reward: -0.2500,                 loss: nan
second_0:                 episode reward: 0.2500,                 loss: 0.0379
Episode: 2481/50000 (4.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 160.99s / 19624.01 s
first_0:                 episode reward: -0.5500,                 loss: nan
second_0:                 episode reward: 0.5500,                 loss: 0.0381
Episode: 2501/50000 (5.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 160.71s / 19784.72 s
first_0:                 episode reward: 0.1000,                 loss: nan
second_0:                 episode reward: -0.1000,                 loss: 0.0367
Episode: 2521/50000 (5.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.13s / 19945.85 s
first_0:                 episode reward: -0.4500,                 loss: nan
second_0:                 episode reward: 0.4500,                 loss: 0.0366
Episode: 2541/50000 (5.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.28s / 20107.13 s
first_0:                 episode reward: 0.9500,                 loss: nan
second_0:                 episode reward: -0.9500,                 loss: 0.0366
Episode: 2561/50000 (5.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 163.06s / 20270.19 s
first_0:                 episode reward: 0.1500,                 loss: nan
second_0:                 episode reward: -0.1500,                 loss: 0.0376
Episode: 2581/50000 (5.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 162.67s / 20432.87 s
first_0:                 episode reward: 0.1000,                 loss: nan
second_0:                 episode reward: -0.1000,                 loss: 0.0371
Episode: 2601/50000 (5.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.80s / 20594.67 s
first_0:                 episode reward: 0.2500,                 loss: nan
second_0:                 episode reward: -0.2500,                 loss: 0.0367
Episode: 2621/50000 (5.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.63s / 20756.30 s
first_0:                 episode reward: -0.1500,                 loss: nan
second_0:                 episode reward: 0.1500,                 loss: 0.0375
Episode: 2641/50000 (5.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 162.41s / 20918.71 s
first_0:                 episode reward: 0.0500,                 loss: nan
second_0:                 episode reward: -0.0500,                 loss: 0.0370
Episode: 2661/50000 (5.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 162.80s / 21081.51 s
first_0:                 episode reward: -0.3000,                 loss: nan
second_0:                 episode reward: 0.3000,                 loss: 0.0372
Episode: 2681/50000 (5.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.54s / 21243.05 s
first_0:                 episode reward: 0.5500,                 loss: nan
second_0:                 episode reward: -0.5500,                 loss: 0.0386
Episode: 2701/50000 (5.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.35s / 21404.40 s
first_0:                 episode reward: -0.3000,                 loss: nan
second_0:                 episode reward: 0.3000,                 loss: 0.0377
Episode: 2721/50000 (5.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 162.66s / 21567.06 s
first_0:                 episode reward: 0.3000,                 loss: nan
second_0:                 episode reward: -0.3000,                 loss: 0.0385
Episode: 2741/50000 (5.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.68s / 21728.75 s
first_0:                 episode reward: 0.0000,                 loss: nan
second_0:                 episode reward: 0.0000,                 loss: 0.0377
Episode: 2761/50000 (5.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 162.27s / 21891.02 s
first_0:                 episode reward: -0.0500,                 loss: nan
second_0:                 episode reward: 0.0500,                 loss: 0.0377
Episode: 2781/50000 (5.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 162.23s / 22053.25 s
first_0:                 episode reward: 0.4000,                 loss: nan
second_0:                 episode reward: -0.4000,                 loss: 0.0368
Episode: 2801/50000 (5.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.10s / 22214.35 s
first_0:                 episode reward: -0.1000,                 loss: nan
second_0:                 episode reward: 0.1000,                 loss: 0.0369
Episode: 2821/50000 (5.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.75s / 22376.10 s
first_0:                 episode reward: -1.0000,                 loss: nan
second_0:                 episode reward: 1.0000,                 loss: 0.0366
Episode: 2841/50000 (5.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.37s / 22537.47 s
first_0:                 episode reward: 0.2500,                 loss: nan
second_0:                 episode reward: -0.2500,                 loss: 0.0366
Episode: 2861/50000 (5.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 162.33s / 22699.80 s
first_0:                 episode reward: -0.0500,                 loss: nan
second_0:                 episode reward: 0.0500,                 loss: 0.0376
Episode: 2881/50000 (5.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.16s / 22860.96 s
first_0:                 episode reward: -0.0500,                 loss: nan
second_0:                 episode reward: 0.0500,                 loss: 0.0379
Episode: 2901/50000 (5.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.99s / 23022.95 s
first_0:                 episode reward: -0.1000,                 loss: nan
second_0:                 episode reward: 0.1000,                 loss: 0.0378
Episode: 2921/50000 (5.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 162.28s / 23185.23 s
first_0:                 episode reward: 0.3000,                 loss: nan
second_0:                 episode reward: -0.3000,                 loss: 0.0382
Episode: 2941/50000 (5.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.26s / 23346.49 s
first_0:                 episode reward: -0.5000,                 loss: nan
second_0:                 episode reward: 0.5000,                 loss: 0.0372
Episode: 2961/50000 (5.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.24s / 23507.73 s
first_0:                 episode reward: -0.6500,                 loss: nan
second_0:                 episode reward: 0.6500,                 loss: 0.0381
Episode: 2981/50000 (5.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.06s / 23668.79 s
first_0:                 episode reward: -0.2000,                 loss: nan
second_0:                 episode reward: 0.2000,                 loss: 0.0380
Episode: 3001/50000 (6.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.68s / 23830.47 s
first_0:                 episode reward: -0.0500,                 loss: nan
second_0:                 episode reward: 0.0500,                 loss: 0.0373
Episode: 3021/50000 (6.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 162.07s / 23992.54 s
first_0:                 episode reward: 0.0000,                 loss: nan
second_0:                 episode reward: 0.0000,                 loss: 0.0385
Episode: 3041/50000 (6.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 160.92s / 24153.46 s
first_0:                 episode reward: -0.0500,                 loss: nan
second_0:                 episode reward: 0.0500,                 loss: 0.0388
Episode: 3061/50000 (6.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.61s / 24315.06 s
first_0:                 episode reward: -0.1500,                 loss: nan
second_0:                 episode reward: 0.1500,                 loss: 0.0375
Episode: 3081/50000 (6.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.31s / 24476.37 s
first_0:                 episode reward: 0.1000,                 loss: nan
second_0:                 episode reward: -0.1000,                 loss: 0.0384
Episode: 3101/50000 (6.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.69s / 24638.06 s
first_0:                 episode reward: -0.1000,                 loss: nan
second_0:                 episode reward: 0.1000,                 loss: 0.0384
Episode: 3121/50000 (6.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 160.97s / 24799.03 s
first_0:                 episode reward: -0.2500,                 loss: nan
second_0:                 episode reward: 0.2500,                 loss: 0.0381
Episode: 3141/50000 (6.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 160.97s / 24960.00 s
first_0:                 episode reward: 0.0000,                 loss: nan
second_0:                 episode reward: 0.0000,                 loss: 0.0383
Episode: 3161/50000 (6.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 162.72s / 25122.72 s
first_0:                 episode reward: -0.2500,                 loss: nan
second_0:                 episode reward: 0.2500,                 loss: 0.0389
Episode: 3181/50000 (6.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.66s / 25284.38 s
first_0:                 episode reward: 0.0500,                 loss: nan
second_0:                 episode reward: -0.0500,                 loss: 0.0389
Episode: 3201/50000 (6.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.95s / 25446.32 s
first_0:                 episode reward: 0.1000,                 loss: nan
second_0:                 episode reward: -0.1000,                 loss: 0.0389
Episode: 3221/50000 (6.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.33s / 25607.65 s
first_0:                 episode reward: 0.1000,                 loss: nan
second_0:                 episode reward: -0.1000,                 loss: 0.0377
Episode: 3241/50000 (6.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.68s / 25769.33 s
first_0:                 episode reward: -0.4500,                 loss: nan
second_0:                 episode reward: 0.4500,                 loss: 0.0381
Episode: 3261/50000 (6.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.27s / 25930.60 s
first_0:                 episode reward: 0.0000,                 loss: nan
second_0:                 episode reward: 0.0000,                 loss: 0.0384
Episode: 3281/50000 (6.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.08s / 26091.69 s
first_0:                 episode reward: 0.6000,                 loss: nan
second_0:                 episode reward: -0.6000,                 loss: 0.0392
Episode: 3301/50000 (6.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.53s / 26253.22 s
first_0:                 episode reward: 0.3000,                 loss: nan
second_0:                 episode reward: -0.3000,                 loss: 0.0390
Episode: 3321/50000 (6.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.49s / 26414.70 s
first_0:                 episode reward: -0.1500,                 loss: nan
second_0:                 episode reward: 0.1500,                 loss: 0.0395
Episode: 3341/50000 (6.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.04s / 26575.75 s
first_0:                 episode reward: 0.0000,                 loss: nan
second_0:                 episode reward: 0.0000,                 loss: 0.0386
Episode: 3361/50000 (6.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.07s / 26736.82 s
first_0:                 episode reward: 0.1000,                 loss: nan
second_0:                 episode reward: -0.1000,                 loss: 0.0390
Episode: 3381/50000 (6.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.24s / 26898.06 s
first_0:                 episode reward: 0.1000,                 loss: nan
second_0:                 episode reward: -0.1000,                 loss: 0.0380
Episode: 3401/50000 (6.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 160.88s / 27058.93 s
first_0:                 episode reward: -0.1000,                 loss: nan
second_0:                 episode reward: 0.1000,                 loss: 0.0380
Episode: 3421/50000 (6.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 160.88s / 27219.81 s
first_0:                 episode reward: 0.2500,                 loss: nan
second_0:                 episode reward: -0.2500,                 loss: 0.0387
Episode: 3441/50000 (6.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.43s / 27381.24 s
first_0:                 episode reward: 0.0000,                 loss: nan
second_0:                 episode reward: 0.0000,                 loss: 0.0390
Episode: 3461/50000 (6.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.97s / 27543.21 s
first_0:                 episode reward: -0.5500,                 loss: nan
second_0:                 episode reward: 0.5500,                 loss: 0.0376
Episode: 3481/50000 (6.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.56s / 27704.77 s
first_0:                 episode reward: -0.4000,                 loss: nan
second_0:                 episode reward: 0.4000,                 loss: 0.0375
Episode: 3501/50000 (7.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.34s / 27866.11 s
first_0:                 episode reward: -0.3000,                 loss: nan
second_0:                 episode reward: 0.3000,                 loss: 0.0378
Episode: 3521/50000 (7.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.59s / 28027.70 s
first_0:                 episode reward: 0.0500,                 loss: nan
second_0:                 episode reward: -0.0500,                 loss: 0.0376
Episode: 3541/50000 (7.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.32s / 28189.03 s
first_0:                 episode reward: -0.6500,                 loss: nan
second_0:                 episode reward: 0.6500,                 loss: 0.0367
Episode: 3561/50000 (7.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.66s / 28350.69 s
first_0:                 episode reward: -0.1000,                 loss: nan
second_0:                 episode reward: 0.1000,                 loss: 0.0373
Episode: 3581/50000 (7.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.52s / 28512.21 s
first_0:                 episode reward: -0.3500,                 loss: nan
second_0:                 episode reward: 0.3500,                 loss: 0.0376
Episode: 3601/50000 (7.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.37s / 28673.58 s
first_0:                 episode reward: -0.1000,                 loss: nan
second_0:                 episode reward: 0.1000,                 loss: 0.0361
Episode: 3621/50000 (7.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.99s / 28835.57 s
first_0:                 episode reward: -0.1000,                 loss: nan
second_0:                 episode reward: 0.1000,                 loss: 0.0368
Episode: 3641/50000 (7.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.26s / 28996.83 s
first_0:                 episode reward: -0.3000,                 loss: nan
second_0:                 episode reward: 0.3000,                 loss: 0.0368
Episode: 3661/50000 (7.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.58s / 29158.40 s
first_0:                 episode reward: 0.1000,                 loss: nan
second_0:                 episode reward: -0.1000,                 loss: 0.0365
Episode: 3681/50000 (7.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 160.92s / 29319.32 s
first_0:                 episode reward: -0.2500,                 loss: nan
second_0:                 episode reward: 0.2500,                 loss: 0.0375
Episode: 3701/50000 (7.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 160.94s / 29480.26 s
first_0:                 episode reward: 0.0500,                 loss: nan
second_0:                 episode reward: -0.0500,                 loss: 0.0375
Episode: 3721/50000 (7.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 162.01s / 29642.26 s
first_0:                 episode reward: -0.6000,                 loss: nan
second_0:                 episode reward: 0.6000,                 loss: 0.0385
Episode: 3741/50000 (7.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.51s / 29803.77 s
first_0:                 episode reward: 0.3000,                 loss: nan
second_0:                 episode reward: -0.3000,                 loss: 0.0381
Episode: 3761/50000 (7.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.64s / 29965.41 s
first_0:                 episode reward: -0.1000,                 loss: nan
second_0:                 episode reward: 0.1000,                 loss: 0.0378
Episode: 3781/50000 (7.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 162.11s / 30127.52 s
first_0:                 episode reward: -0.1000,                 loss: nan
second_0:                 episode reward: 0.1000,                 loss: 0.0377
Episode: 3801/50000 (7.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.29s / 30288.81 s
first_0:                 episode reward: -0.3500,                 loss: nan
second_0:                 episode reward: 0.3500,                 loss: 0.0377
Episode: 3821/50000 (7.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.06s / 30449.87 s
first_0:                 episode reward: 0.1000,                 loss: nan
second_0:                 episode reward: -0.1000,                 loss: 0.0367
Episode: 3841/50000 (7.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.31s / 30611.18 s
first_0:                 episode reward: -0.1500,                 loss: nan
second_0:                 episode reward: 0.1500,                 loss: 0.0376
Episode: 3861/50000 (7.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 160.97s / 30772.15 s
first_0:                 episode reward: -0.3000,                 loss: nan
second_0:                 episode reward: 0.3000,                 loss: 0.0372
Episode: 3881/50000 (7.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.04s / 30933.19 s
first_0:                 episode reward: -0.0500,                 loss: nan
second_0:                 episode reward: 0.0500,                 loss: 0.0371
Episode: 3901/50000 (7.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.70s / 31094.89 s
first_0:                 episode reward: 0.0000,                 loss: nan
second_0:                 episode reward: 0.0000,                 loss: 0.0372
Episode: 3921/50000 (7.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.71s / 31256.60 s
first_0:                 episode reward: -0.1500,                 loss: nan
second_0:                 episode reward: 0.1500,                 loss: 0.0392
Episode: 3941/50000 (7.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 162.03s / 31418.63 s
first_0:                 episode reward: -0.2500,                 loss: nan
second_0:                 episode reward: 0.2500,                 loss: 0.0380
Episode: 3961/50000 (7.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 162.46s / 31581.09 s
first_0:                 episode reward: 0.4000,                 loss: nan
second_0:                 episode reward: -0.4000,                 loss: 0.0379
Episode: 3981/50000 (7.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.84s / 31742.93 s
first_0:                 episode reward: 0.2000,                 loss: nan
second_0:                 episode reward: -0.2000,                 loss: 0.0385
Episode: 4001/50000 (8.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.95s / 31904.87 s
first_0:                 episode reward: -0.2000,                 loss: nan
second_0:                 episode reward: 0.2000,                 loss: 0.0383
Episode: 4021/50000 (8.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 162.30s / 32067.17 s
first_0:                 episode reward: 0.0000,                 loss: nan
second_0:                 episode reward: 0.0000,                 loss: 0.0392
Episode: 4041/50000 (8.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.24s / 32228.42 s
first_0:                 episode reward: 0.0000,                 loss: nan
second_0:                 episode reward: 0.0000,                 loss: 0.0391
Episode: 4061/50000 (8.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 162.24s / 32390.65 s
first_0:                 episode reward: 0.3500,                 loss: nan
second_0:                 episode reward: -0.3500,                 loss: 0.0390
Episode: 4081/50000 (8.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.57s / 32552.22 s
first_0:                 episode reward: -0.4500,                 loss: nan
second_0:                 episode reward: 0.4500,                 loss: 0.0388
Episode: 4101/50000 (8.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.60s / 32713.82 s
first_0:                 episode reward: 0.0500,                 loss: nan
second_0:                 episode reward: -0.0500,                 loss: 0.0388
Episode: 4121/50000 (8.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.68s / 32875.50 s
first_0:                 episode reward: 0.0500,                 loss: nan
second_0:                 episode reward: -0.0500,                 loss: 0.0392
Episode: 4141/50000 (8.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.13s / 33036.63 s
first_0:                 episode reward: 0.0000,                 loss: nan
second_0:                 episode reward: 0.0000,                 loss: 0.0377
Episode: 4161/50000 (8.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.29s / 33197.92 s
first_0:                 episode reward: 0.2500,                 loss: nan
second_0:                 episode reward: -0.2500,                 loss: 0.0371
Episode: 4181/50000 (8.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.05s / 33358.97 s
first_0:                 episode reward: -0.1500,                 loss: nan
second_0:                 episode reward: 0.1500,                 loss: 0.0373
Episode: 4201/50000 (8.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.20s / 33520.16 s
first_0:                 episode reward: 0.2000,                 loss: nan
second_0:                 episode reward: -0.2000,                 loss: 0.0378
Episode: 4221/50000 (8.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.82s / 33681.99 s
first_0:                 episode reward: -0.5000,                 loss: nan
second_0:                 episode reward: 0.5000,                 loss: 0.0373
Episode: 4241/50000 (8.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.55s / 33843.54 s
first_0:                 episode reward: 0.4000,                 loss: nan
second_0:                 episode reward: -0.4000,                 loss: 0.0370
Episode: 4261/50000 (8.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.15s / 34004.68 s
first_0:                 episode reward: -0.3500,                 loss: nan
second_0:                 episode reward: 0.3500,                 loss: 0.0386
Episode: 4281/50000 (8.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 162.00s / 34166.69 s
first_0:                 episode reward: -0.1500,                 loss: nan
second_0:                 episode reward: 0.1500,                 loss: 0.0381
Episode: 4301/50000 (8.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.47s / 34328.16 s
first_0:                 episode reward: 0.4000,                 loss: nan
second_0:                 episode reward: -0.4000,                 loss: 0.0389
Episode: 4321/50000 (8.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.33s / 34489.49 s
first_0:                 episode reward: 0.3500,                 loss: nan
second_0:                 episode reward: -0.3500,                 loss: 0.0392
Episode: 4341/50000 (8.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.17s / 34650.66 s
first_0:                 episode reward: 0.3500,                 loss: nan
second_0:                 episode reward: -0.3500,                 loss: 0.0388
Episode: 4361/50000 (8.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 162.01s / 34812.68 s
first_0:                 episode reward: -0.7000,                 loss: nan
second_0:                 episode reward: 0.7000,                 loss: 0.0374
Episode: 4381/50000 (8.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.75s / 34974.43 s
first_0:                 episode reward: -0.1500,                 loss: nan
second_0:                 episode reward: 0.1500,                 loss: 0.0374
Episode: 4401/50000 (8.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.49s / 35135.92 s
first_0:                 episode reward: -0.9000,                 loss: nan
second_0:                 episode reward: 0.9000,                 loss: 0.0378
Episode: 4421/50000 (8.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.75s / 35297.67 s
first_0:                 episode reward: 0.1500,                 loss: nan
second_0:                 episode reward: -0.1500,                 loss: 0.0380
Episode: 4441/50000 (8.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.66s / 35459.33 s
first_0:                 episode reward: 0.1500,                 loss: nan
second_0:                 episode reward: -0.1500,                 loss: 0.0385
Episode: 4461/50000 (8.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.65s / 35620.98 s
first_0:                 episode reward: 0.0500,                 loss: nan
second_0:                 episode reward: -0.0500,                 loss: 0.0376
Episode: 4481/50000 (8.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.20s / 35782.18 s
first_0:                 episode reward: -0.2000,                 loss: nan
second_0:                 episode reward: 0.2000,                 loss: 0.0382
Episode: 4501/50000 (9.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.58s / 35943.77 s
first_0:                 episode reward: 0.0500,                 loss: nan
second_0:                 episode reward: -0.0500,                 loss: 0.0371
Episode: 4521/50000 (9.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.41s / 36105.18 s
first_0:                 episode reward: -0.7000,                 loss: nan
second_0:                 episode reward: 0.7000,                 loss: 0.0371
Episode: 4541/50000 (9.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.88s / 36267.06 s
first_0:                 episode reward: 0.3500,                 loss: nan
second_0:                 episode reward: -0.3500,                 loss: 0.0368
Episode: 4561/50000 (9.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.83s / 36428.89 s
first_0:                 episode reward: -0.3000,                 loss: nan
second_0:                 episode reward: 0.3000,                 loss: 0.0370
Episode: 4581/50000 (9.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.59s / 36590.48 s
first_0:                 episode reward: -0.2000,                 loss: nan
second_0:                 episode reward: 0.2000,                 loss: 0.0366
Episode: 4601/50000 (9.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 162.25s / 36752.73 s
first_0:                 episode reward: 0.4500,                 loss: nan
second_0:                 episode reward: -0.4500,                 loss: 0.0367
Episode: 4621/50000 (9.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 162.11s / 36914.84 s
first_0:                 episode reward: 0.1000,                 loss: nan
second_0:                 episode reward: -0.1000,                 loss: 0.0375
Episode: 4641/50000 (9.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.21s / 37076.05 s
first_0:                 episode reward: -0.1000,                 loss: nan
second_0:                 episode reward: 0.1000,                 loss: 0.0381
Episode: 4661/50000 (9.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 162.01s / 37238.05 s
first_0:                 episode reward: 0.5500,                 loss: nan
second_0:                 episode reward: -0.5500,                 loss: 0.0385
Episode: 4681/50000 (9.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.47s / 37399.53 s
first_0:                 episode reward: 0.3500,                 loss: nan
second_0:                 episode reward: -0.3500,                 loss: 0.0380
Episode: 4701/50000 (9.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 160.79s / 37560.32 s
first_0:                 episode reward: 0.4000,                 loss: nan
second_0:                 episode reward: -0.4000,                 loss: 0.0373
Episode: 4721/50000 (9.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.73s / 37722.06 s
first_0:                 episode reward: -0.4500,                 loss: nan
second_0:                 episode reward: 0.4500,                 loss: 0.0371
Episode: 4741/50000 (9.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.22s / 37883.28 s
first_0:                 episode reward: 0.3500,                 loss: nan
second_0:                 episode reward: -0.3500,                 loss: 0.0366
Episode: 4761/50000 (9.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.76s / 38045.04 s
first_0:                 episode reward: -0.3000,                 loss: nan
second_0:                 episode reward: 0.3000,                 loss: 0.0373
Episode: 4781/50000 (9.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.11s / 38206.15 s
first_0:                 episode reward: 0.5000,                 loss: nan
second_0:                 episode reward: -0.5000,                 loss: 0.0366
Episode: 4801/50000 (9.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.82s / 38367.97 s
first_0:                 episode reward: 0.2000,                 loss: nan
second_0:                 episode reward: -0.2000,                 loss: 0.0371
Episode: 4821/50000 (9.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.68s / 38529.65 s
first_0:                 episode reward: 0.0000,                 loss: nan
second_0:                 episode reward: 0.0000,                 loss: 0.0369
Episode: 4841/50000 (9.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.33s / 38690.98 s
first_0:                 episode reward: 0.6000,                 loss: nan
second_0:                 episode reward: -0.6000,                 loss: 0.0355
Episode: 4861/50000 (9.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 162.12s / 38853.10 s
first_0:                 episode reward: 0.1000,                 loss: nan
second_0:                 episode reward: -0.1000,                 loss: 0.0358
Episode: 4881/50000 (9.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 162.07s / 39015.16 s
first_0:                 episode reward: -0.1000,                 loss: nan
second_0:                 episode reward: 0.1000,                 loss: 0.0367
Episode: 4901/50000 (9.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 162.27s / 39177.44 s
first_0:                 episode reward: 0.3000,                 loss: nan
second_0:                 episode reward: -0.3000,                 loss: 0.0364
Episode: 4921/50000 (9.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.29s / 39338.73 s
first_0:                 episode reward: 0.0000,                 loss: nan
second_0:                 episode reward: 0.0000,                 loss: 0.0376
Episode: 4941/50000 (9.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.56s / 39500.29 s
first_0:                 episode reward: 0.0500,                 loss: nan
second_0:                 episode reward: -0.0500,                 loss: 0.0380
Episode: 4961/50000 (9.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.18s / 39661.46 s
first_0:                 episode reward: -0.0500,                 loss: nan
second_0:                 episode reward: 0.0500,                 loss: 0.0375
Episode: 4981/50000 (9.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.89s / 39823.36 s
first_0:                 episode reward: 0.2500,                 loss: nan
second_0:                 episode reward: -0.2500,                 loss: 0.0366
Episode: 5001/50000 (10.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.84s / 39985.20 s
first_0:                 episode reward: 0.2000,                 loss: nan
second_0:                 episode reward: -0.2000,                 loss: 0.0385
Episode: 5021/50000 (10.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 162.40s / 40147.60 s
first_0:                 episode reward: 0.1000,                 loss: nan
second_0:                 episode reward: -0.1000,                 loss: 0.0394
Episode: 5041/50000 (10.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 162.30s / 40309.90 s
first_0:                 episode reward: -0.1500,                 loss: nan
second_0:                 episode reward: 0.1500,                 loss: 0.0384
Episode: 5061/50000 (10.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 162.42s / 40472.32 s
first_0:                 episode reward: 0.1000,                 loss: nan
second_0:                 episode reward: -0.1000,                 loss: 0.0373
Episode: 5081/50000 (10.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.57s / 40633.89 s
first_0:                 episode reward: -1.2000,                 loss: nan
second_0:                 episode reward: 1.2000,                 loss: 0.0366
Episode: 5101/50000 (10.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 162.11s / 40796.00 s
first_0:                 episode reward: 0.0000,                 loss: nan
second_0:                 episode reward: 0.0000,                 loss: 0.0369
Episode: 5121/50000 (10.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.94s / 40957.94 s
first_0:                 episode reward: 0.3000,                 loss: nan
second_0:                 episode reward: -0.3000,                 loss: 0.0379
Episode: 5141/50000 (10.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.24s / 41119.18 s
first_0:                 episode reward: -0.2000,                 loss: nan
second_0:                 episode reward: 0.2000,                 loss: 0.0385
Episode: 5161/50000 (10.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.77s / 41280.95 s
first_0:                 episode reward: 0.0500,                 loss: nan
second_0:                 episode reward: -0.0500,                 loss: 0.0386
Episode: 5181/50000 (10.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 162.32s / 41443.27 s
first_0:                 episode reward: -0.2500,                 loss: nan
second_0:                 episode reward: 0.2500,                 loss: 0.0376
Episode: 5201/50000 (10.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 162.34s / 41605.60 s
first_0:                 episode reward: 0.1000,                 loss: nan
second_0:                 episode reward: -0.1000,                 loss: 0.0385
Episode: 5221/50000 (10.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.83s / 41767.43 s
first_0:                 episode reward: -0.2000,                 loss: nan
second_0:                 episode reward: 0.2000,                 loss: 0.0376
Episode: 5241/50000 (10.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.99s / 41929.42 s
first_0:                 episode reward: 0.2500,                 loss: nan
second_0:                 episode reward: -0.2500,                 loss: 0.0387
Episode: 5261/50000 (10.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.76s / 42091.18 s
first_0:                 episode reward: 0.5000,                 loss: nan
second_0:                 episode reward: -0.5000,                 loss: 0.0376
Episode: 5281/50000 (10.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.06s / 42252.24 s
first_0:                 episode reward: -0.0500,                 loss: nan
second_0:                 episode reward: 0.0500,                 loss: 0.0379
Episode: 5301/50000 (10.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.14s / 42413.38 s
first_0:                 episode reward: 0.4000,                 loss: nan
second_0:                 episode reward: -0.4000,                 loss: 0.0374
Episode: 5321/50000 (10.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.48s / 42574.86 s
first_0:                 episode reward: 0.0000,                 loss: nan
second_0:                 episode reward: 0.0000,                 loss: 0.0387
Episode: 5341/50000 (10.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.32s / 42736.18 s
first_0:                 episode reward: -0.2500,                 loss: nan
second_0:                 episode reward: 0.2500,                 loss: 0.0382
Episode: 5361/50000 (10.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.82s / 42898.00 s
first_0:                 episode reward: -0.7000,                 loss: nan
second_0:                 episode reward: 0.7000,                 loss: 0.0373
Episode: 5381/50000 (10.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.56s / 43059.55 s
first_0:                 episode reward: 0.2500,                 loss: nan
second_0:                 episode reward: -0.2500,                 loss: 0.0377
Episode: 5401/50000 (10.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.54s / 43221.09 s
first_0:                 episode reward: 0.0500,                 loss: nan
second_0:                 episode reward: -0.0500,                 loss: 0.0374
Episode: 5421/50000 (10.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 160.95s / 43382.05 s
first_0:                 episode reward: 0.4500,                 loss: nan
second_0:                 episode reward: -0.4500,                 loss: 0.0368
Episode: 5441/50000 (10.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 160.86s / 43542.91 s
first_0:                 episode reward: 0.1500,                 loss: nan
second_0:                 episode reward: -0.1500,                 loss: 0.0367
Episode: 5461/50000 (10.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.64s / 43704.55 s
first_0:                 episode reward: -0.2000,                 loss: nan
second_0:                 episode reward: 0.2000,                 loss: 0.0367
Episode: 5481/50000 (10.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.42s / 43865.97 s
first_0:                 episode reward: 0.5000,                 loss: nan
second_0:                 episode reward: -0.5000,                 loss: 0.0365
Episode: 5501/50000 (11.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.78s / 44027.75 s
first_0:                 episode reward: 0.2500,                 loss: nan
second_0:                 episode reward: -0.2500,                 loss: 0.0356
Episode: 5521/50000 (11.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.94s / 44189.69 s
first_0:                 episode reward: -0.3500,                 loss: nan
second_0:                 episode reward: 0.3500,                 loss: 0.0367
Episode: 5541/50000 (11.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 162.28s / 44351.97 s
first_0:                 episode reward: -0.9000,                 loss: nan
second_0:                 episode reward: 0.9000,                 loss: 0.0364
Episode: 5561/50000 (11.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 162.29s / 44514.27 s
first_0:                 episode reward: -0.0500,                 loss: nan
second_0:                 episode reward: 0.0500,                 loss: 0.0369
Episode: 5581/50000 (11.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 162.11s / 44676.38 s
first_0:                 episode reward: 0.0500,                 loss: nan
second_0:                 episode reward: -0.0500,                 loss: 0.0382
Episode: 5601/50000 (11.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 162.75s / 44839.13 s
first_0:                 episode reward: -0.5000,                 loss: nan
second_0:                 episode reward: 0.5000,                 loss: 0.0386
Episode: 5621/50000 (11.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 162.30s / 45001.43 s
first_0:                 episode reward: -0.1500,                 loss: nan
second_0:                 episode reward: 0.1500,                 loss: 0.0384
Episode: 5641/50000 (11.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.64s / 45163.07 s
first_0:                 episode reward: -0.4500,                 loss: nan
second_0:                 episode reward: 0.4500,                 loss: 0.0380
Episode: 5661/50000 (11.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.21s / 45324.28 s
first_0:                 episode reward: 0.3000,                 loss: nan
second_0:                 episode reward: -0.3000,                 loss: 0.0376
Episode: 5681/50000 (11.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.86s / 45486.14 s
first_0:                 episode reward: -0.1000,                 loss: nan
second_0:                 episode reward: 0.1000,                 loss: 0.0391
Episode: 5701/50000 (11.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.90s / 45648.03 s
first_0:                 episode reward: 0.3000,                 loss: nan
second_0:                 episode reward: -0.3000,                 loss: 0.0382
Episode: 5721/50000 (11.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.73s / 45809.77 s
first_0:                 episode reward: 0.0500,                 loss: nan
second_0:                 episode reward: -0.0500,                 loss: 0.0386
Episode: 5741/50000 (11.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 162.02s / 45971.79 s
first_0:                 episode reward: -0.2500,                 loss: nan
second_0:                 episode reward: 0.2500,                 loss: 0.0385
Episode: 5761/50000 (11.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.75s / 46133.55 s
first_0:                 episode reward: -0.1500,                 loss: nan
second_0:                 episode reward: 0.1500,                 loss: 0.0374
Episode: 5781/50000 (11.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.57s / 46295.11 s
first_0:                 episode reward: -0.0500,                 loss: nan
second_0:                 episode reward: 0.0500,                 loss: 0.0385
Episode: 5801/50000 (11.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.89s / 46457.00 s
first_0:                 episode reward: 0.3000,                 loss: nan
second_0:                 episode reward: -0.3000,                 loss: 0.0391
Episode: 5821/50000 (11.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 162.16s / 46619.16 s
first_0:                 episode reward: 0.0000,                 loss: nan
second_0:                 episode reward: 0.0000,                 loss: 0.0384
Episode: 5841/50000 (11.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.29s / 46780.45 s
first_0:                 episode reward: 0.3500,                 loss: nan
second_0:                 episode reward: -0.3500,                 loss: 0.0388
Episode: 5861/50000 (11.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.80s / 46942.25 s
first_0:                 episode reward: 0.1000,                 loss: nan
second_0:                 episode reward: -0.1000,                 loss: 0.0390
Episode: 5881/50000 (11.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.16s / 47103.40 s
first_0:                 episode reward: -0.4500,                 loss: nan
second_0:                 episode reward: 0.4500,                 loss: 0.0388
Episode: 5901/50000 (11.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.84s / 47265.24 s
first_0:                 episode reward: 0.4000,                 loss: nan
second_0:                 episode reward: -0.4000,                 loss: 0.0386
Episode: 5921/50000 (11.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 162.24s / 47427.48 s
first_0:                 episode reward: 0.1000,                 loss: nan
second_0:                 episode reward: -0.1000,                 loss: 0.0385
Episode: 5941/50000 (11.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.66s / 47589.15 s
first_0:                 episode reward: -0.1000,                 loss: nan
second_0:                 episode reward: 0.1000,                 loss: 0.0389
Episode: 5961/50000 (11.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 162.11s / 47751.26 s
first_0:                 episode reward: 0.4500,                 loss: nan
second_0:                 episode reward: -0.4500,                 loss: 0.0384
Episode: 5981/50000 (11.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.83s / 47913.09 s
first_0:                 episode reward: 0.2000,                 loss: nan
second_0:                 episode reward: -0.2000,                 loss: 0.0378
Episode: 6001/50000 (12.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.19s / 48074.28 s
first_0:                 episode reward: 0.3000,                 loss: nan
second_0:                 episode reward: -0.3000,                 loss: 0.0385
Episode: 6021/50000 (12.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 162.37s / 48236.65 s
first_0:                 episode reward: 0.3500,                 loss: nan
second_0:                 episode reward: -0.3500,                 loss: 0.0384
Episode: 6041/50000 (12.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.74s / 48398.38 s
first_0:                 episode reward: -0.6500,                 loss: nan
second_0:                 episode reward: 0.6500,                 loss: 0.0387
Episode: 6061/50000 (12.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.60s / 48559.98 s
first_0:                 episode reward: 0.2500,                 loss: nan
second_0:                 episode reward: -0.2500,                 loss: 0.0375
Episode: 6081/50000 (12.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 160.64s / 48720.63 s
first_0:                 episode reward: 0.4000,                 loss: nan
second_0:                 episode reward: -0.4000,                 loss: 0.0386
Episode: 6101/50000 (12.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.65s / 48882.28 s
first_0:                 episode reward: 0.0500,                 loss: nan
second_0:                 episode reward: -0.0500,                 loss: 0.0387
Episode: 6121/50000 (12.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 162.01s / 49044.30 s
first_0:                 episode reward: -0.4000,                 loss: nan
second_0:                 episode reward: 0.4000,                 loss: 0.0390
Episode: 6141/50000 (12.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.53s / 49205.82 s
first_0:                 episode reward: -0.1000,                 loss: nan
second_0:                 episode reward: 0.1000,                 loss: 0.0401
Episode: 6161/50000 (12.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 162.43s / 49368.26 s
first_0:                 episode reward: -0.4000,                 loss: nan
second_0:                 episode reward: 0.4000,                 loss: 0.0396
Episode: 6181/50000 (12.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.71s / 49529.97 s
first_0:                 episode reward: -0.3000,                 loss: nan
second_0:                 episode reward: 0.3000,                 loss: 0.0394
Episode: 6201/50000 (12.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.31s / 49691.27 s
first_0:                 episode reward: 0.4500,                 loss: nan
second_0:                 episode reward: -0.4500,                 loss: 0.0397
Episode: 6221/50000 (12.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.16s / 49852.44 s
first_0:                 episode reward: -0.4000,                 loss: nan
second_0:                 episode reward: 0.4000,                 loss: 0.0385
Episode: 6241/50000 (12.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.35s / 50013.78 s
first_0:                 episode reward: -0.3000,                 loss: nan
second_0:                 episode reward: 0.3000,                 loss: 0.0395
Episode: 6261/50000 (12.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.71s / 50175.49 s
first_0:                 episode reward: -0.3000,                 loss: nan
second_0:                 episode reward: 0.3000,                 loss: 0.0392
Episode: 6281/50000 (12.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.58s / 50337.07 s
first_0:                 episode reward: 0.0000,                 loss: nan
second_0:                 episode reward: 0.0000,                 loss: 0.0385
Episode: 6301/50000 (12.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.96s / 50499.03 s
first_0:                 episode reward: -0.3500,                 loss: nan
second_0:                 episode reward: 0.3500,                 loss: 0.0377
Episode: 6321/50000 (12.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.56s / 50660.59 s
first_0:                 episode reward: 0.0500,                 loss: nan
second_0:                 episode reward: -0.0500,                 loss: 0.0378
Episode: 6341/50000 (12.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 160.74s / 50821.33 s
first_0:                 episode reward: -0.1000,                 loss: nan
second_0:                 episode reward: 0.1000,                 loss: 0.0387
Episode: 6361/50000 (12.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 162.14s / 50983.47 s
first_0:                 episode reward: -0.6000,                 loss: nan
second_0:                 episode reward: 0.6000,                 loss: 0.0393
Episode: 6381/50000 (12.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.03s / 51144.50 s
first_0:                 episode reward: -0.1000,                 loss: nan
second_0:                 episode reward: 0.1000,                 loss: 0.0384
Episode: 6401/50000 (12.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.08s / 51305.58 s
first_0:                 episode reward: 0.0500,                 loss: nan
second_0:                 episode reward: -0.0500,                 loss: 0.0380
Episode: 6421/50000 (12.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.43s / 51467.01 s
first_0:                 episode reward: -0.2000,                 loss: nan
second_0:                 episode reward: 0.2000,                 loss: 0.0374
Episode: 6441/50000 (12.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.31s / 51628.32 s
first_0:                 episode reward: 0.1000,                 loss: nan
second_0:                 episode reward: -0.1000,                 loss: 0.0363
Episode: 6461/50000 (12.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.03s / 51789.35 s
first_0:                 episode reward: 0.1000,                 loss: nan
second_0:                 episode reward: -0.1000,                 loss: 0.0372
Episode: 6481/50000 (12.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.44s / 51950.79 s
first_0:                 episode reward: -0.2500,                 loss: nan
second_0:                 episode reward: 0.2500,                 loss: 0.0376
Episode: 6501/50000 (13.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 162.61s / 52113.40 s
first_0:                 episode reward: 0.0000,                 loss: nan
second_0:                 episode reward: 0.0000,                 loss: 0.0362
Episode: 6521/50000 (13.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.86s / 52275.26 s
first_0:                 episode reward: 0.2000,                 loss: nan
second_0:                 episode reward: -0.2000,                 loss: 0.0374
Episode: 6541/50000 (13.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.40s / 52436.67 s
first_0:                 episode reward: -0.0500,                 loss: nan
second_0:                 episode reward: 0.0500,                 loss: 0.0374
Episode: 6561/50000 (13.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.17s / 52597.83 s
first_0:                 episode reward: -0.1000,                 loss: nan
second_0:                 episode reward: 0.1000,                 loss: 0.0371
Episode: 6581/50000 (13.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.91s / 52759.74 s
first_0:                 episode reward: 0.2000,                 loss: nan
second_0:                 episode reward: -0.2000,                 loss: 0.0370
Episode: 6601/50000 (13.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.69s / 52921.43 s
first_0:                 episode reward: 0.5000,                 loss: nan
second_0:                 episode reward: -0.5000,                 loss: 0.0379
Episode: 6621/50000 (13.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.26s / 53082.69 s
first_0:                 episode reward: 0.5000,                 loss: nan
second_0:                 episode reward: -0.5000,                 loss: 0.0380
Episode: 6641/50000 (13.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 162.44s / 53245.13 s
first_0:                 episode reward: -0.0500,                 loss: nan
second_0:                 episode reward: 0.0500,                 loss: 0.0381
Episode: 6661/50000 (13.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.22s / 53406.35 s
first_0:                 episode reward: -0.1000,                 loss: nan
second_0:                 episode reward: 0.1000,                 loss: 0.0377
Episode: 6681/50000 (13.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.20s / 53567.55 s
first_0:                 episode reward: -0.1000,                 loss: nan
second_0:                 episode reward: 0.1000,                 loss: 0.0387
Episode: 6701/50000 (13.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.02s / 53728.57 s
first_0:                 episode reward: 0.0500,                 loss: nan
second_0:                 episode reward: -0.0500,                 loss: 0.0377
Episode: 6721/50000 (13.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.46s / 53890.04 s
first_0:                 episode reward: -0.1000,                 loss: nan
second_0:                 episode reward: 0.1000,                 loss: 0.0374
Episode: 6741/50000 (13.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 162.10s / 54052.13 s
first_0:                 episode reward: -0.2000,                 loss: nan
second_0:                 episode reward: 0.2000,                 loss: 0.0377
Episode: 6761/50000 (13.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.55s / 54213.68 s
first_0:                 episode reward: -0.1000,                 loss: nan
second_0:                 episode reward: 0.1000,                 loss: 0.0367
Episode: 6781/50000 (13.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.17s / 54374.86 s
first_0:                 episode reward: 0.6500,                 loss: nan
second_0:                 episode reward: -0.6500,                 loss: 0.0368
Episode: 6801/50000 (13.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.77s / 54536.62 s
first_0:                 episode reward: -0.0500,                 loss: nan
second_0:                 episode reward: 0.0500,                 loss: 0.0381
Episode: 6821/50000 (13.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.75s / 54698.37 s
first_0:                 episode reward: -0.3500,                 loss: nan
second_0:                 episode reward: 0.3500,                 loss: 0.0375
Episode: 6841/50000 (13.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.04s / 54859.41 s
first_0:                 episode reward: 0.7500,                 loss: nan
second_0:                 episode reward: -0.7500,                 loss: 0.0383
Episode: 6861/50000 (13.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 162.11s / 55021.52 s
first_0:                 episode reward: -0.1500,                 loss: nan
second_0:                 episode reward: 0.1500,                 loss: 0.0402
Episode: 6881/50000 (13.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 162.63s / 55184.16 s
first_0:                 episode reward: 0.7500,                 loss: nan
second_0:                 episode reward: -0.7500,                 loss: 0.0405
Episode: 6901/50000 (13.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 162.09s / 55346.25 s
first_0:                 episode reward: 0.1500,                 loss: nan
second_0:                 episode reward: -0.1500,                 loss: 0.0386
Episode: 6921/50000 (13.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 162.44s / 55508.68 s
first_0:                 episode reward: 0.4000,                 loss: nan
second_0:                 episode reward: -0.4000,                 loss: 0.0382
Episode: 6941/50000 (13.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.58s / 55670.26 s
first_0:                 episode reward: 0.2500,                 loss: nan
second_0:                 episode reward: -0.2500,                 loss: 0.0394
Episode: 6961/50000 (13.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.38s / 55831.64 s
first_0:                 episode reward: 0.4000,                 loss: nan
second_0:                 episode reward: -0.4000,                 loss: 0.0406
Episode: 6981/50000 (13.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 162.58s / 55994.22 s
first_0:                 episode reward: -0.5000,                 loss: nan
second_0:                 episode reward: 0.5000,                 loss: 0.0402
Episode: 7001/50000 (14.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 162.37s / 56156.59 s
first_0:                 episode reward: 0.6500,                 loss: nan
second_0:                 episode reward: -0.6500,                 loss: 0.0392
Episode: 7021/50000 (14.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.79s / 56318.38 s
first_0:                 episode reward: 0.7000,                 loss: nan
second_0:                 episode reward: -0.7000,                 loss: 0.0394
Episode: 7041/50000 (14.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.67s / 56480.05 s
first_0:                 episode reward: -0.3500,                 loss: nan
second_0:                 episode reward: 0.3500,                 loss: 0.0391
Episode: 7061/50000 (14.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 162.12s / 56642.17 s
first_0:                 episode reward: -0.2500,                 loss: nan
second_0:                 episode reward: 0.2500,                 loss: 0.0394
Episode: 7081/50000 (14.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 162.69s / 56804.86 s
first_0:                 episode reward: 0.6000,                 loss: nan
second_0:                 episode reward: -0.6000,                 loss: 0.0384
Episode: 7101/50000 (14.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 162.55s / 56967.41 s
first_0:                 episode reward: 0.0000,                 loss: nan
second_0:                 episode reward: 0.0000,                 loss: 0.0389
Episode: 7121/50000 (14.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 162.38s / 57129.78 s
first_0:                 episode reward: 0.4000,                 loss: nan
second_0:                 episode reward: -0.4000,                 loss: 0.0382
Episode: 7141/50000 (14.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.47s / 57291.26 s
first_0:                 episode reward: 0.4500,                 loss: nan
second_0:                 episode reward: -0.4500,                 loss: 0.0390
Episode: 7161/50000 (14.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 162.03s / 57453.29 s
first_0:                 episode reward: 0.2000,                 loss: nan
second_0:                 episode reward: -0.2000,                 loss: 0.0389
Episode: 7181/50000 (14.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 162.59s / 57615.88 s
first_0:                 episode reward: -0.0500,                 loss: nan
second_0:                 episode reward: 0.0500,                 loss: 0.0376
Episode: 7201/50000 (14.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.96s / 57777.84 s
first_0:                 episode reward: 0.3000,                 loss: nan
second_0:                 episode reward: -0.3000,                 loss: 0.0377
Episode: 7221/50000 (14.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 162.32s / 57940.15 s
first_0:                 episode reward: -0.4500,                 loss: nan
second_0:                 episode reward: 0.4500,                 loss: 0.0374
Episode: 7241/50000 (14.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.01s / 58101.17 s
first_0:                 episode reward: 0.3500,                 loss: nan
second_0:                 episode reward: -0.3500,                 loss: 0.0382
Episode: 7261/50000 (14.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.97s / 58263.14 s
first_0:                 episode reward: 0.2500,                 loss: nan
second_0:                 episode reward: -0.2500,                 loss: 0.0378
Episode: 7281/50000 (14.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.67s / 58424.81 s
first_0:                 episode reward: -0.3500,                 loss: nan
second_0:                 episode reward: 0.3500,                 loss: 0.0373
Episode: 7301/50000 (14.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.43s / 58586.23 s
first_0:                 episode reward: 0.0500,                 loss: nan
second_0:                 episode reward: -0.0500,                 loss: 0.0383
Episode: 7321/50000 (14.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.11s / 58747.35 s
first_0:                 episode reward: -0.1500,                 loss: nan
second_0:                 episode reward: 0.1500,                 loss: 0.0388
Episode: 7341/50000 (14.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.20s / 58908.55 s
first_0:                 episode reward: 0.5500,                 loss: nan
second_0:                 episode reward: -0.5500,                 loss: 0.0395
Episode: 7361/50000 (14.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.65s / 59070.20 s
first_0:                 episode reward: 0.3000,                 loss: nan
second_0:                 episode reward: -0.3000,                 loss: 0.0391
Episode: 7381/50000 (14.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.47s / 59231.67 s
first_0:                 episode reward: 0.0000,                 loss: nan
second_0:                 episode reward: 0.0000,                 loss: 0.0384
Episode: 7401/50000 (14.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.56s / 59393.23 s
first_0:                 episode reward: -0.8500,                 loss: nan
second_0:                 episode reward: 0.8500,                 loss: 0.0389
Episode: 7421/50000 (14.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.81s / 59555.04 s
first_0:                 episode reward: -0.0500,                 loss: nan
second_0:                 episode reward: 0.0500,                 loss: 0.0394
Episode: 7441/50000 (14.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 162.64s / 59717.68 s
first_0:                 episode reward: 0.2500,                 loss: nan
second_0:                 episode reward: -0.2500,                 loss: 0.0390
Episode: 7461/50000 (14.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.80s / 59879.48 s
first_0:                 episode reward: -0.0500,                 loss: nan
second_0:                 episode reward: 0.0500,                 loss: 0.0393
Episode: 7481/50000 (14.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 162.40s / 60041.89 s
first_0:                 episode reward: 0.2000,                 loss: nan
second_0:                 episode reward: -0.2000,                 loss: 0.0384
Episode: 7501/50000 (15.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.09s / 60202.97 s
first_0:                 episode reward: 0.3500,                 loss: nan
second_0:                 episode reward: -0.3500,                 loss: 0.0392
Episode: 7521/50000 (15.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 162.11s / 60365.09 s
first_0:                 episode reward: 0.7000,                 loss: nan
second_0:                 episode reward: -0.7000,                 loss: 0.0375
Episode: 7541/50000 (15.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.51s / 60526.60 s
first_0:                 episode reward: 0.0000,                 loss: nan
second_0:                 episode reward: 0.0000,                 loss: 0.0391
Episode: 7561/50000 (15.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.51s / 60688.11 s
first_0:                 episode reward: -0.0500,                 loss: nan
second_0:                 episode reward: 0.0500,                 loss: 0.0388
Episode: 7581/50000 (15.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.45s / 60849.57 s
first_0:                 episode reward: -0.3000,                 loss: nan
second_0:                 episode reward: 0.3000,                 loss: 0.0385
Episode: 7601/50000 (15.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.83s / 61011.39 s
first_0:                 episode reward: 0.3000,                 loss: nan
second_0:                 episode reward: -0.3000,                 loss: 0.0385
Episode: 7621/50000 (15.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.54s / 61172.93 s
first_0:                 episode reward: 0.7000,                 loss: nan
second_0:                 episode reward: -0.7000,                 loss: 0.0390
Episode: 7641/50000 (15.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.24s / 61334.17 s
first_0:                 episode reward: -0.8000,                 loss: nan
second_0:                 episode reward: 0.8000,                 loss: 0.0389
Episode: 7661/50000 (15.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.96s / 61496.13 s
first_0:                 episode reward: 0.1000,                 loss: nan
second_0:                 episode reward: -0.1000,                 loss: 0.0403
Episode: 7681/50000 (15.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 160.97s / 61657.10 s
first_0:                 episode reward: 0.4000,                 loss: nan
second_0:                 episode reward: -0.4000,                 loss: 0.0398
Episode: 7701/50000 (15.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 162.44s / 61819.54 s
first_0:                 episode reward: 0.0500,                 loss: nan
second_0:                 episode reward: -0.0500,                 loss: 0.0402
Episode: 7721/50000 (15.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.48s / 61981.02 s
first_0:                 episode reward: 0.0500,                 loss: nan
second_0:                 episode reward: -0.0500,                 loss: 0.0392
Episode: 7741/50000 (15.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 162.20s / 62143.23 s
first_0:                 episode reward: 0.4000,                 loss: nan
second_0:                 episode reward: -0.4000,                 loss: 0.0389
Episode: 7761/50000 (15.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.99s / 62305.21 s
first_0:                 episode reward: 0.4000,                 loss: nan
second_0:                 episode reward: -0.4000,                 loss: 0.0386
Episode: 7781/50000 (15.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.02s / 62466.24 s
first_0:                 episode reward: 0.3500,                 loss: nan
second_0:                 episode reward: -0.3500,                 loss: 0.0382
Episode: 7801/50000 (15.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 162.11s / 62628.35 s
first_0:                 episode reward: 0.1000,                 loss: nan
second_0:                 episode reward: -0.1000,                 loss: 0.0385
Episode: 7821/50000 (15.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.96s / 62790.31 s
first_0:                 episode reward: 0.5000,                 loss: nan
second_0:                 episode reward: -0.5000,                 loss: 0.0387
Episode: 7841/50000 (15.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 160.99s / 62951.30 s
first_0:                 episode reward: -0.3000,                 loss: nan
second_0:                 episode reward: 0.3000,                 loss: 0.0390
Episode: 7861/50000 (15.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.01s / 63112.31 s
first_0:                 episode reward: -0.2000,                 loss: nan
second_0:                 episode reward: 0.2000,                 loss: 0.0379
Episode: 7881/50000 (15.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.73s / 63274.04 s
first_0:                 episode reward: 0.1000,                 loss: nan
second_0:                 episode reward: -0.1000,                 loss: 0.0397
Episode: 7901/50000 (15.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.22s / 63435.26 s
first_0:                 episode reward: -0.4500,                 loss: nan
second_0:                 episode reward: 0.4500,                 loss: 0.0394
Episode: 7921/50000 (15.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 162.02s / 63597.28 s
first_0:                 episode reward: 0.1000,                 loss: nan
second_0:                 episode reward: -0.1000,                 loss: 0.0407
Episode: 7941/50000 (15.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.51s / 63758.79 s
first_0:                 episode reward: -0.3000,                 loss: nan
second_0:                 episode reward: 0.3000,                 loss: 0.0397
Episode: 7961/50000 (15.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 160.92s / 63919.71 s
first_0:                 episode reward: 0.2500,                 loss: nan
second_0:                 episode reward: -0.2500,                 loss: 0.0391
Episode: 7981/50000 (15.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 162.61s / 64082.33 s
first_0:                 episode reward: 0.0000,                 loss: nan
second_0:                 episode reward: 0.0000,                 loss: 0.0397
Episode: 8001/50000 (16.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.75s / 64244.08 s
first_0:                 episode reward: 0.2500,                 loss: nan
second_0:                 episode reward: -0.2500,                 loss: 0.0397
Episode: 8021/50000 (16.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.81s / 64405.88 s
first_0:                 episode reward: 0.2000,                 loss: nan
second_0:                 episode reward: -0.2000,                 loss: 0.0389
Episode: 8041/50000 (16.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 162.17s / 64568.05 s
first_0:                 episode reward: -0.7000,                 loss: nan
second_0:                 episode reward: 0.7000,                 loss: 0.0388
Episode: 8061/50000 (16.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 162.40s / 64730.46 s
first_0:                 episode reward: 0.0000,                 loss: nan
second_0:                 episode reward: 0.0000,                 loss: 0.0393
Episode: 8081/50000 (16.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 162.04s / 64892.50 s
first_0:                 episode reward: 0.1500,                 loss: nan
second_0:                 episode reward: -0.1500,                 loss: 0.0399
Episode: 8101/50000 (16.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 162.00s / 65054.49 s
first_0:                 episode reward: -0.3000,                 loss: nan
second_0:                 episode reward: 0.3000,                 loss: 0.0409
Episode: 8121/50000 (16.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.45s / 65215.95 s
first_0:                 episode reward: -0.3000,                 loss: nan
second_0:                 episode reward: 0.3000,                 loss: 0.0395
Episode: 8141/50000 (16.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 162.42s / 65378.36 s
first_0:                 episode reward: -0.2500,                 loss: nan
second_0:                 episode reward: 0.2500,                 loss: 0.0391
Episode: 8161/50000 (16.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.45s / 65539.81 s
first_0:                 episode reward: -0.3000,                 loss: nan
second_0:                 episode reward: 0.3000,                 loss: 0.0392
Episode: 8181/50000 (16.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.31s / 65701.12 s
first_0:                 episode reward: 0.1500,                 loss: nan
second_0:                 episode reward: -0.1500,                 loss: 0.0394
Episode: 8201/50000 (16.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 162.03s / 65863.16 s
first_0:                 episode reward: -0.3500,                 loss: nan
second_0:                 episode reward: 0.3500,                 loss: 0.0408
Episode: 8221/50000 (16.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.63s / 66024.78 s
first_0:                 episode reward: 0.1000,                 loss: nan
second_0:                 episode reward: -0.1000,                 loss: 0.0409
Episode: 8241/50000 (16.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 162.41s / 66187.20 s
first_0:                 episode reward: 0.4500,                 loss: nan
second_0:                 episode reward: -0.4500,                 loss: 0.0400
Episode: 8261/50000 (16.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.33s / 66348.52 s
first_0:                 episode reward: 0.3000,                 loss: nan
second_0:                 episode reward: -0.3000,                 loss: 0.0399
Episode: 8281/50000 (16.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.48s / 66510.00 s
first_0:                 episode reward: -0.7500,                 loss: nan
second_0:                 episode reward: 0.7500,                 loss: 0.0411
Episode: 8301/50000 (16.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.24s / 66671.24 s
first_0:                 episode reward: -0.2000,                 loss: nan
second_0:                 episode reward: 0.2000,                 loss: 0.0419
Episode: 8321/50000 (16.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.57s / 66832.81 s
first_0:                 episode reward: 0.3000,                 loss: nan
second_0:                 episode reward: -0.3000,                 loss: 0.0410
Episode: 8341/50000 (16.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.68s / 66994.49 s
first_0:                 episode reward: 0.3000,                 loss: nan
second_0:                 episode reward: -0.3000,                 loss: 0.0407
Episode: 8361/50000 (16.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.95s / 67156.45 s
first_0:                 episode reward: 0.3000,                 loss: nan
second_0:                 episode reward: -0.3000,                 loss: 0.0401
Episode: 8381/50000 (16.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.64s / 67318.08 s
first_0:                 episode reward: -0.0500,                 loss: nan
second_0:                 episode reward: 0.0500,                 loss: 0.0393
Episode: 8401/50000 (16.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.20s / 67479.28 s
first_0:                 episode reward: 0.5000,                 loss: nan
second_0:                 episode reward: -0.5000,                 loss: 0.0402
Episode: 8421/50000 (16.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.44s / 67640.72 s
first_0:                 episode reward: 0.3000,                 loss: nan
second_0:                 episode reward: -0.3000,                 loss: 0.0394
Episode: 8441/50000 (16.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.16s / 67801.88 s
first_0:                 episode reward: -0.3000,                 loss: nan
second_0:                 episode reward: 0.3000,                 loss: 0.0395
Episode: 8461/50000 (16.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.26s / 67963.14 s
first_0:                 episode reward: -0.0500,                 loss: nan
second_0:                 episode reward: 0.0500,                 loss: 0.0394
Episode: 8481/50000 (16.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.15s / 68124.29 s
first_0:                 episode reward: -0.5000,                 loss: nan
second_0:                 episode reward: 0.5000,                 loss: 0.0397
Episode: 8501/50000 (17.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.81s / 68286.10 s
first_0:                 episode reward: 0.5000,                 loss: nan
second_0:                 episode reward: -0.5000,                 loss: 0.0381
Episode: 8521/50000 (17.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.36s / 68447.46 s
first_0:                 episode reward: -0.0500,                 loss: nan
second_0:                 episode reward: 0.0500,                 loss: 0.0384
Episode: 8541/50000 (17.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.57s / 68609.02 s
first_0:                 episode reward: 0.4000,                 loss: nan
second_0:                 episode reward: -0.4000,                 loss: 0.0384
Episode: 8561/50000 (17.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.50s / 68770.52 s
first_0:                 episode reward: -0.6000,                 loss: nan
second_0:                 episode reward: 0.6000,                 loss: 0.0375
Episode: 8581/50000 (17.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.54s / 68932.06 s
first_0:                 episode reward: 0.2500,                 loss: nan
second_0:                 episode reward: -0.2500,                 loss: 0.0377
Episode: 8601/50000 (17.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 162.21s / 69094.27 s
first_0:                 episode reward: 0.0500,                 loss: nan
second_0:                 episode reward: -0.0500,                 loss: 0.0394
Episode: 8621/50000 (17.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 162.00s / 69256.28 s
first_0:                 episode reward: 0.2000,                 loss: nan
second_0:                 episode reward: -0.2000,                 loss: 0.0393
Episode: 8641/50000 (17.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.88s / 69418.16 s
first_0:                 episode reward: 0.3500,                 loss: nan
second_0:                 episode reward: -0.3500,                 loss: 0.0372
Episode: 8661/50000 (17.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.27s / 69579.43 s
first_0:                 episode reward: -0.3500,                 loss: nan
second_0:                 episode reward: 0.3500,                 loss: 0.0382
Episode: 8681/50000 (17.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 162.24s / 69741.67 s
first_0:                 episode reward: 0.4000,                 loss: nan
second_0:                 episode reward: -0.4000,                 loss: 0.0381
Episode: 8701/50000 (17.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.72s / 69903.40 s
first_0:                 episode reward: -0.5000,                 loss: nan
second_0:                 episode reward: 0.5000,                 loss: 0.0387
Episode: 8721/50000 (17.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.63s / 70065.03 s
first_0:                 episode reward: 0.2500,                 loss: nan
second_0:                 episode reward: -0.2500,                 loss: 0.0391
Episode: 8741/50000 (17.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 160.88s / 70225.91 s
first_0:                 episode reward: 0.4500,                 loss: nan
second_0:                 episode reward: -0.4500,                 loss: 0.0398
Episode: 8761/50000 (17.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.42s / 70387.33 s
first_0:                 episode reward: 0.1000,                 loss: nan
second_0:                 episode reward: -0.1000,                 loss: 0.0395
Episode: 8781/50000 (17.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.59s / 70548.92 s
first_0:                 episode reward: -0.1500,                 loss: nan
second_0:                 episode reward: 0.1500,                 loss: 0.0393
Episode: 8801/50000 (17.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.47s / 70710.39 s
first_0:                 episode reward: 0.4500,                 loss: nan
second_0:                 episode reward: -0.4500,                 loss: 0.0401
Episode: 8821/50000 (17.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.31s / 70871.70 s
first_0:                 episode reward: -0.2500,                 loss: nan
second_0:                 episode reward: 0.2500,                 loss: 0.0398
Episode: 8841/50000 (17.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.58s / 71033.28 s
first_0:                 episode reward: -0.6000,                 loss: nan
second_0:                 episode reward: 0.6000,                 loss: 0.0407
Episode: 8861/50000 (17.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.57s / 71194.85 s
first_0:                 episode reward: -0.5000,                 loss: nan
second_0:                 episode reward: 0.5000,                 loss: 0.0392
Episode: 8881/50000 (17.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 160.99s / 71355.84 s
first_0:                 episode reward: -0.0500,                 loss: nan
second_0:                 episode reward: 0.0500,                 loss: 0.0416
Episode: 8901/50000 (17.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.18s / 71517.02 s
first_0:                 episode reward: 0.1000,                 loss: nan
second_0:                 episode reward: -0.1000,                 loss: 0.0414
Episode: 8921/50000 (17.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.73s / 71678.75 s
first_0:                 episode reward: 0.0500,                 loss: nan
second_0:                 episode reward: -0.0500,                 loss: 0.0392
Episode: 8941/50000 (17.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 162.37s / 71841.12 s
first_0:                 episode reward: -0.2500,                 loss: nan
second_0:                 episode reward: 0.2500,                 loss: 0.0392
Episode: 8961/50000 (17.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.10s / 72002.22 s
first_0:                 episode reward: -0.2000,                 loss: nan
second_0:                 episode reward: 0.2000,                 loss: 0.0405
Episode: 8981/50000 (17.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 162.20s / 72164.42 s
first_0:                 episode reward: 0.3000,                 loss: nan
second_0:                 episode reward: -0.3000,                 loss: 0.0407
Episode: 9001/50000 (18.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.56s / 72325.98 s
first_0:                 episode reward: -0.2000,                 loss: nan
second_0:                 episode reward: 0.2000,                 loss: 0.0412
Episode: 9021/50000 (18.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.23s / 72487.21 s
first_0:                 episode reward: 0.1000,                 loss: nan
second_0:                 episode reward: -0.1000,                 loss: 0.0407
Episode: 9041/50000 (18.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.42s / 72648.63 s
first_0:                 episode reward: -0.2500,                 loss: nan
second_0:                 episode reward: 0.2500,                 loss: 0.0409
Episode: 9061/50000 (18.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.87s / 72810.50 s
first_0:                 episode reward: 0.5000,                 loss: nan
second_0:                 episode reward: -0.5000,                 loss: 0.0398
Episode: 9081/50000 (18.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.48s / 72971.98 s
first_0:                 episode reward: -0.4500,                 loss: nan
second_0:                 episode reward: 0.4500,                 loss: 0.0390
Episode: 9101/50000 (18.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.09s / 73133.07 s
first_0:                 episode reward: 0.8000,                 loss: nan
second_0:                 episode reward: -0.8000,                 loss: 0.0387
Episode: 9121/50000 (18.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.60s / 73294.67 s
first_0:                 episode reward: 0.1500,                 loss: nan
second_0:                 episode reward: -0.1500,                 loss: 0.0395
Episode: 9141/50000 (18.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.80s / 73456.47 s
first_0:                 episode reward: 0.0500,                 loss: nan
second_0:                 episode reward: -0.0500,                 loss: 0.0381
Episode: 9161/50000 (18.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.76s / 73618.23 s
first_0:                 episode reward: 0.1000,                 loss: nan
second_0:                 episode reward: -0.1000,                 loss: 0.0391
Episode: 9181/50000 (18.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 162.19s / 73780.42 s
first_0:                 episode reward: -0.3500,                 loss: nan
second_0:                 episode reward: 0.3500,                 loss: 0.0375
Episode: 9201/50000 (18.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 162.16s / 73942.57 s
first_0:                 episode reward: -0.1000,                 loss: nan
second_0:                 episode reward: 0.1000,                 loss: 0.0386
Episode: 9221/50000 (18.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 162.08s / 74104.65 s
first_0:                 episode reward: -0.6000,                 loss: nan
second_0:                 episode reward: 0.6000,                 loss: 0.0393
Episode: 9241/50000 (18.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.98s / 74266.63 s
first_0:                 episode reward: 0.1500,                 loss: nan
second_0:                 episode reward: -0.1500,                 loss: 0.0397
Episode: 9261/50000 (18.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 162.18s / 74428.81 s
first_0:                 episode reward: 0.6000,                 loss: nan
second_0:                 episode reward: -0.6000,                 loss: 0.0400
Episode: 9281/50000 (18.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 160.85s / 74589.66 s
first_0:                 episode reward: -0.4000,                 loss: nan
second_0:                 episode reward: 0.4000,                 loss: 0.0404
Episode: 9301/50000 (18.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.38s / 74751.04 s
first_0:                 episode reward: -0.2500,                 loss: nan
second_0:                 episode reward: 0.2500,                 loss: 0.0397
Episode: 9321/50000 (18.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.98s / 74913.02 s
first_0:                 episode reward: -0.1000,                 loss: nan
second_0:                 episode reward: 0.1000,                 loss: 0.0395
Episode: 9341/50000 (18.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.90s / 75074.92 s
first_0:                 episode reward: 0.1000,                 loss: nan
second_0:                 episode reward: -0.1000,                 loss: 0.0393
Episode: 9361/50000 (18.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 162.23s / 75237.14 s
first_0:                 episode reward: 0.2500,                 loss: nan
second_0:                 episode reward: -0.2500,                 loss: 0.0390
Episode: 9381/50000 (18.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.39s / 75398.53 s
first_0:                 episode reward: -0.2500,                 loss: nan
second_0:                 episode reward: 0.2500,                 loss: 0.0406
Episode: 9401/50000 (18.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.70s / 75560.23 s
first_0:                 episode reward: 0.1000,                 loss: nan
second_0:                 episode reward: -0.1000,                 loss: 0.0391
Episode: 9421/50000 (18.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 162.14s / 75722.38 s
first_0:                 episode reward: -0.3000,                 loss: nan
second_0:                 episode reward: 0.3000,                 loss: 0.0393
Episode: 9441/50000 (18.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 162.62s / 75884.99 s
first_0:                 episode reward: -0.0500,                 loss: nan
second_0:                 episode reward: 0.0500,                 loss: 0.0390
Episode: 9461/50000 (18.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.60s / 76046.59 s
first_0:                 episode reward: 0.3500,                 loss: nan
second_0:                 episode reward: -0.3500,                 loss: 0.0387
Episode: 9481/50000 (18.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.16s / 76207.75 s
first_0:                 episode reward: 0.1000,                 loss: nan
second_0:                 episode reward: -0.1000,                 loss: 0.0386
Episode: 9501/50000 (19.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.55s / 76369.30 s
first_0:                 episode reward: 0.5500,                 loss: nan
second_0:                 episode reward: -0.5500,                 loss: 0.0384
Episode: 9521/50000 (19.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.66s / 76530.96 s
first_0:                 episode reward: 0.2500,                 loss: nan
second_0:                 episode reward: -0.2500,                 loss: 0.0379
Episode: 9541/50000 (19.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.89s / 76692.85 s
first_0:                 episode reward: 0.1000,                 loss: nan
second_0:                 episode reward: -0.1000,                 loss: 0.0392
Episode: 9561/50000 (19.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.56s / 76854.42 s
first_0:                 episode reward: -0.3000,                 loss: nan
second_0:                 episode reward: 0.3000,                 loss: 0.0393
Episode: 9581/50000 (19.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 162.08s / 77016.50 s
first_0:                 episode reward: -0.3000,                 loss: nan
second_0:                 episode reward: 0.3000,                 loss: 0.0393
Episode: 9601/50000 (19.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 162.21s / 77178.70 s
first_0:                 episode reward: -0.2000,                 loss: nan
second_0:                 episode reward: 0.2000,                 loss: 0.0389
Episode: 9621/50000 (19.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.57s / 77340.27 s
first_0:                 episode reward: 0.3000,                 loss: nan
second_0:                 episode reward: -0.3000,                 loss: 0.0397
Episode: 9641/50000 (19.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.70s / 77501.97 s
first_0:                 episode reward: 0.1000,                 loss: nan
second_0:                 episode reward: -0.1000,                 loss: 0.0399
Episode: 9661/50000 (19.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.90s / 77663.87 s
first_0:                 episode reward: 0.2500,                 loss: nan
second_0:                 episode reward: -0.2500,                 loss: 0.0411
Episode: 9681/50000 (19.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 162.33s / 77826.21 s
first_0:                 episode reward: 0.2500,                 loss: nan
second_0:                 episode reward: -0.2500,                 loss: 0.0408
Episode: 9701/50000 (19.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 162.07s / 77988.27 s
first_0:                 episode reward: 0.2500,                 loss: nan
second_0:                 episode reward: -0.2500,                 loss: 0.0413
Episode: 9721/50000 (19.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.49s / 78149.76 s
first_0:                 episode reward: -0.1500,                 loss: nan
second_0:                 episode reward: 0.1500,                 loss: 0.0410
Episode: 9741/50000 (19.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.92s / 78311.68 s
first_0:                 episode reward: -0.1000,                 loss: nan
second_0:                 episode reward: 0.1000,                 loss: 0.0409
Episode: 9761/50000 (19.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.48s / 78473.16 s
first_0:                 episode reward: 0.2000,                 loss: nan
second_0:                 episode reward: -0.2000,                 loss: 0.0408
Episode: 9781/50000 (19.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.71s / 78634.87 s
first_0:                 episode reward: 0.4500,                 loss: nan
second_0:                 episode reward: -0.4500,                 loss: 0.0409
Episode: 9801/50000 (19.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.34s / 78796.21 s
first_0:                 episode reward: 0.1500,                 loss: nan
second_0:                 episode reward: -0.1500,                 loss: 0.0417
Episode: 9821/50000 (19.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.54s / 78957.75 s
first_0:                 episode reward: -0.1000,                 loss: nan
second_0:                 episode reward: 0.1000,                 loss: 0.0405
Episode: 9841/50000 (19.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.72s / 79119.47 s
first_0:                 episode reward: 0.4500,                 loss: nan
second_0:                 episode reward: -0.4500,                 loss: 0.0395
Episode: 9861/50000 (19.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.61s / 79281.08 s
first_0:                 episode reward: 0.0000,                 loss: nan
second_0:                 episode reward: 0.0000,                 loss: 0.0397
Episode: 9881/50000 (19.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.23s / 79442.31 s
first_0:                 episode reward: -0.3000,                 loss: nan
second_0:                 episode reward: 0.3000,                 loss: 0.0398
Episode: 9901/50000 (19.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 162.03s / 79604.33 s
first_0:                 episode reward: -0.2500,                 loss: nan
second_0:                 episode reward: 0.2500,                 loss: 0.0386
Episode: 9921/50000 (19.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.26s / 79765.60 s
first_0:                 episode reward: 0.1500,                 loss: nan
second_0:                 episode reward: -0.1500,                 loss: 0.0401
Episode: 9941/50000 (19.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.01s / 79926.61 s
first_0:                 episode reward: -0.1000,                 loss: nan
second_0:                 episode reward: 0.1000,                 loss: 0.0389
Episode: 9961/50000 (19.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.77s / 80088.37 s
first_0:                 episode reward: -0.6000,                 loss: nan
second_0:                 episode reward: 0.6000,                 loss: 0.0397
Episode: 9981/50000 (19.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.26s / 80249.63 s
first_0:                 episode reward: 0.0000,                 loss: nan
second_0:                 episode reward: 0.0000,                 loss: 0.0392
Episode: 10001/50000 (20.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.25s / 80410.89 s
first_0:                 episode reward: 0.2500,                 loss: nan
second_0:                 episode reward: -0.2500,                 loss: 0.0402
Episode: 10021/50000 (20.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.47s / 80572.35 s
first_0:                 episode reward: 0.5000,                 loss: nan
second_0:                 episode reward: -0.5000,                 loss: 0.0391
Episode: 10041/50000 (20.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 160.85s / 80733.20 s
first_0:                 episode reward: 0.1500,                 loss: nan
second_0:                 episode reward: -0.1500,                 loss: 0.0399
Episode: 10061/50000 (20.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.52s / 80894.72 s
first_0:                 episode reward: -0.1000,                 loss: nan
second_0:                 episode reward: 0.1000,                 loss: 0.0398
Episode: 10081/50000 (20.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.30s / 81056.02 s
first_0:                 episode reward: 0.5000,                 loss: nan
second_0:                 episode reward: -0.5000,                 loss: 0.0408
Episode: 10101/50000 (20.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.92s / 81217.94 s
first_0:                 episode reward: -0.2000,                 loss: nan
second_0:                 episode reward: 0.2000,                 loss: 0.0398
Episode: 10121/50000 (20.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.78s / 81379.72 s
first_0:                 episode reward: 0.0500,                 loss: nan
second_0:                 episode reward: -0.0500,                 loss: 0.0401
Episode: 10141/50000 (20.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.31s / 81541.03 s
first_0:                 episode reward: 0.5500,                 loss: nan
second_0:                 episode reward: -0.5500,                 loss: 0.0400
Episode: 10161/50000 (20.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.28s / 81702.31 s
first_0:                 episode reward: -0.2000,                 loss: nan
second_0:                 episode reward: 0.2000,                 loss: 0.0408
Episode: 10181/50000 (20.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.30s / 81863.60 s
first_0:                 episode reward: -1.0000,                 loss: nan
second_0:                 episode reward: 1.0000,                 loss: 0.0405
Episode: 10201/50000 (20.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.98s / 82025.58 s
first_0:                 episode reward: -0.0500,                 loss: nan
second_0:                 episode reward: 0.0500,                 loss: 0.0399
Episode: 10221/50000 (20.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 162.50s / 82188.08 s
first_0:                 episode reward: 0.2000,                 loss: nan
second_0:                 episode reward: -0.2000,                 loss: 0.0399
Episode: 10241/50000 (20.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.75s / 82349.84 s
first_0:                 episode reward: 0.3500,                 loss: nan
second_0:                 episode reward: -0.3500,                 loss: 0.0396
Episode: 10261/50000 (20.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.59s / 82511.43 s
first_0:                 episode reward: 0.0500,                 loss: nan
second_0:                 episode reward: -0.0500,                 loss: 0.0408
Episode: 10281/50000 (20.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.35s / 82672.78 s
first_0:                 episode reward: 0.2000,                 loss: nan
second_0:                 episode reward: -0.2000,                 loss: 0.0417
Episode: 10301/50000 (20.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.17s / 82833.95 s
first_0:                 episode reward: 0.0000,                 loss: nan
second_0:                 episode reward: 0.0000,                 loss: 0.0411
Episode: 10321/50000 (20.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.34s / 82995.29 s
first_0:                 episode reward: -0.3000,                 loss: nan
second_0:                 episode reward: 0.3000,                 loss: 0.0404
Episode: 10341/50000 (20.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.90s / 83157.18 s
first_0:                 episode reward: 0.3500,                 loss: nan
second_0:                 episode reward: -0.3500,                 loss: 0.0400
Episode: 10361/50000 (20.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 162.33s / 83319.51 s
first_0:                 episode reward: 0.0500,                 loss: nan
second_0:                 episode reward: -0.0500,                 loss: 0.0389
Episode: 10381/50000 (20.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.99s / 83481.50 s
first_0:                 episode reward: -0.3500,                 loss: nan
second_0:                 episode reward: 0.3500,                 loss: 0.0402
Episode: 10401/50000 (20.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 162.58s / 83644.08 s
first_0:                 episode reward: -0.1500,                 loss: nan
second_0:                 episode reward: 0.1500,                 loss: 0.0407
Episode: 10421/50000 (20.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.65s / 83805.73 s
first_0:                 episode reward: 0.3500,                 loss: nan
second_0:                 episode reward: -0.3500,                 loss: 0.0396
Episode: 10441/50000 (20.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.89s / 83967.62 s
first_0:                 episode reward: 0.4000,                 loss: nan
second_0:                 episode reward: -0.4000,                 loss: 0.0391
Episode: 10461/50000 (20.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 162.05s / 84129.67 s
first_0:                 episode reward: 0.9500,                 loss: nan
second_0:                 episode reward: -0.9500,                 loss: 0.0393
Episode: 10481/50000 (20.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 162.33s / 84292.00 s
first_0:                 episode reward: -0.4000,                 loss: nan
second_0:                 episode reward: 0.4000,                 loss: 0.0398
Episode: 10501/50000 (21.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.48s / 84453.48 s
first_0:                 episode reward: -0.8000,                 loss: nan
second_0:                 episode reward: 0.8000,                 loss: 0.0394
Episode: 10521/50000 (21.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.97s / 84615.46 s
first_0:                 episode reward: 0.0500,                 loss: nan
second_0:                 episode reward: -0.0500,                 loss: 0.0397
Episode: 10541/50000 (21.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.83s / 84777.29 s
first_0:                 episode reward: -0.3500,                 loss: nan
second_0:                 episode reward: 0.3500,                 loss: 0.0394
Episode: 10561/50000 (21.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 162.03s / 84939.31 s
first_0:                 episode reward: -0.1500,                 loss: nan
second_0:                 episode reward: 0.1500,                 loss: 0.0405
Episode: 10581/50000 (21.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.96s / 85101.27 s
first_0:                 episode reward: -0.8000,                 loss: nan
second_0:                 episode reward: 0.8000,                 loss: 0.0387
Episode: 10601/50000 (21.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.54s / 85262.82 s
first_0:                 episode reward: 0.0000,                 loss: nan
second_0:                 episode reward: 0.0000,                 loss: 0.0402
Episode: 10621/50000 (21.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.21s / 85424.03 s
first_0:                 episode reward: -0.4500,                 loss: nan
second_0:                 episode reward: 0.4500,                 loss: 0.0397
Episode: 10641/50000 (21.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 160.93s / 85584.97 s
first_0:                 episode reward: -0.0500,                 loss: nan
second_0:                 episode reward: 0.0500,                 loss: 0.0395
Episode: 10661/50000 (21.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 160.96s / 85745.93 s
first_0:                 episode reward: 0.5500,                 loss: nan
second_0:                 episode reward: -0.5500,                 loss: 0.0397
Episode: 10681/50000 (21.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.39s / 85907.32 s
first_0:                 episode reward: 0.2500,                 loss: nan
second_0:                 episode reward: -0.2500,                 loss: 0.0389
Episode: 10701/50000 (21.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 162.20s / 86069.52 s
first_0:                 episode reward: 0.2000,                 loss: nan
second_0:                 episode reward: -0.2000,                 loss: 0.0392
Episode: 10721/50000 (21.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 162.27s / 86231.80 s
first_0:                 episode reward: -0.2500,                 loss: nan
second_0:                 episode reward: 0.2500,                 loss: 0.0393
Episode: 10741/50000 (21.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 162.07s / 86393.86 s
first_0:                 episode reward: -0.3000,                 loss: nan
second_0:                 episode reward: 0.3000,                 loss: 0.0406
Episode: 10761/50000 (21.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.17s / 86555.04 s
first_0:                 episode reward: 0.5000,                 loss: nan
second_0:                 episode reward: -0.5000,                 loss: 0.0392
Episode: 10781/50000 (21.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.33s / 86716.37 s
first_0:                 episode reward: 0.0500,                 loss: nan
second_0:                 episode reward: -0.0500,                 loss: 0.0395
Episode: 10801/50000 (21.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.68s / 86878.05 s
first_0:                 episode reward: -0.3500,                 loss: nan
second_0:                 episode reward: 0.3500,                 loss: 0.0403
Episode: 10821/50000 (21.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 161.19s / 87039.24 s
first_0:                 episode reward: -0.5000,                 loss: nan
second_0:                 episode reward: 0.5000,                 loss: 0.0402
Episode: 10841/50000 (21.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.81s / 87201.05 s
first_0:                 episode reward: 0.3500,                 loss: nan
second_0:                 episode reward: -0.3500,                 loss: 0.0398
Episode: 10861/50000 (21.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.30s / 87362.36 s
first_0:                 episode reward: -0.2500,                 loss: nan
second_0:                 episode reward: 0.2500,                 loss: 0.0392
Episode: 10881/50000 (21.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 162.30s / 87524.66 s
first_0:                 episode reward: -0.5000,                 loss: nan
second_0:                 episode reward: 0.5000,                 loss: 0.0392
Episode: 10901/50000 (21.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.95s / 87686.61 s
first_0:                 episode reward: -0.3000,                 loss: nan
second_0:                 episode reward: 0.3000,                 loss: 0.0393
Episode: 10921/50000 (21.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 162.16s / 87848.77 s
first_0:                 episode reward: 0.3000,                 loss: nan
second_0:                 episode reward: -0.3000,                 loss: 0.0402
Episode: 10941/50000 (21.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.92s / 88010.69 s
first_0:                 episode reward: -0.1000,                 loss: nan
second_0:                 episode reward: 0.1000,                 loss: 0.0398
Episode: 10961/50000 (21.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 161.61s / 88172.30 s
first_0:                 episode reward: 0.7000,                 loss: nan
second_0:                 episode reward: -0.7000,                 loss: 0.0393
Episode: 10981/50000 (21.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 161.64s / 88333.94 s
first_0:                 episode reward: 0.5500,                 loss: nan
second_0:                 episode reward: -0.5500,                 loss: 0.0396
Episode: 11001/50000 (22.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 161.71s / 88495.65 s
first_0:                 episode reward: -0.2000,                 loss: nan
second_0:                 episode reward: 0.2000,                 loss: 0.0403
Episode: 11021/50000 (22.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 162.00s / 88657.65 s
first_0:                 episode reward: -0.5000,                 loss: nan
second_0:                 episode reward: 0.5000,                 loss: 0.0403
Episode: 11041/50000 (22.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.19s / 88818.84 s
first_0:                 episode reward: -0.1500,                 loss: nan
second_0:                 episode reward: 0.1500,                 loss: 0.0408
Episode: 11061/50000 (22.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 162.29s / 88981.13 s
first_0:                 episode reward: 0.3000,                 loss: nan
second_0:                 episode reward: -0.3000,                 loss: 0.0396
Episode: 11081/50000 (22.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 162.06s / 89143.19 s
first_0:                 episode reward: -0.1000,                 loss: nan
second_0:                 episode reward: 0.1000,                 loss: 0.0404
Episode: 11101/50000 (22.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 162.76s / 89305.96 s
first_0:                 episode reward: -0.5500,                 loss: nan
second_0:                 episode reward: 0.5500,                 loss: 0.0404
Episode: 11121/50000 (22.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 163.21s / 89469.17 s
first_0:                 episode reward: -0.0500,                 loss: nan
second_0:                 episode reward: 0.0500,                 loss: 0.0397
Episode: 11141/50000 (22.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 161.90s / 89631.06 s