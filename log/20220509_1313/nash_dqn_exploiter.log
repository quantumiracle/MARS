pygame 2.0.0 (SDL 2.0.12, python 3.7.10)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 33.0, (1,), float32) action space: Discrete(3)
random seed: 58
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7f902017ad10>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
Agents No. [1] (index starting from 0) are not learnable.
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': 'random', 'algorithm': 'NashDQNExploiter', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 1.0, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.0, 'eps_decay': 30000, 'exploiter_update_itr': 1}, 'num_process': 1, 'batch_size': 640, 'max_episodes': 50100, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 10, 'log_interval': 10, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 1000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn_exploiter', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True}}
Save models to : /home/zihan/research/MARS/data/model/20220509131350/mdp_arbitrary_mdp_nash_dqn_exploiter. 
 Save logs to: /home/zihan/research/MARS/data/log/20220509131350/mdp_arbitrary_mdp_nash_dqn_exploiter.
Episode: 1/50100 (0.0020%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1023s / 1.1023 s
agent0:                 episode reward: -0.4743,                 loss: nan
agent1:                 episode reward: 0.4743,                 loss: nan
Episode: 11/50100 (0.0220%),                 avg. length: 9.0,                last time consumption/overall running time: 0.0374s / 1.1396 s
agent0:                 episode reward: -0.1532,                 loss: nan
agent1:                 episode reward: 0.1532,                 loss: nan
Episode: 21/50100 (0.0419%),                 avg. length: 9.0,                last time consumption/overall running time: 0.0305s / 1.1701 s
agent0:                 episode reward: 0.5013,                 loss: nan
agent1:                 episode reward: -0.5013,                 loss: nan
Episode: 31/50100 (0.0619%),                 avg. length: 9.0,                last time consumption/overall running time: 0.0310s / 1.2011 s
agent0:                 episode reward: -0.1500,                 loss: nan
agent1:                 episode reward: 0.1500,                 loss: nan
Episode: 41/50100 (0.0818%),                 avg. length: 9.0,                last time consumption/overall running time: 0.0293s / 1.2304 s
agent0:                 episode reward: 0.0151,                 loss: nan
agent1:                 episode reward: -0.0151,                 loss: nan
Episode: 51/50100 (0.1018%),                 avg. length: 9.0,                last time consumption/overall running time: 0.0304s / 1.2608 s
agent0:                 episode reward: 0.3997,                 loss: nan
agent1:                 episode reward: -0.3997,                 loss: nan
Episode: 61/50100 (0.1218%),                 avg. length: 9.0,                last time consumption/overall running time: 0.0310s / 1.2918 s
agent0:                 episode reward: 1.0590,                 loss: nan
agent1:                 episode reward: -1.0590,                 loss: nan
Episode: 71/50100 (0.1417%),                 avg. length: 9.0,                last time consumption/overall running time: 28.4711s / 29.7629 s
agent0:                 episode reward: 0.7184,                 loss: 0.3390
agent1:                 episode reward: -0.7184,                 loss: nan
Episode: 81/50100 (0.1617%),                 avg. length: 9.0,                last time consumption/overall running time: 40.5448s / 70.3077 s
agent0:                 episode reward: -1.3737,                 loss: 0.3228
agent1:                 episode reward: 1.3737,                 loss: nan
Episode: 91/50100 (0.1816%),                 avg. length: 9.0,                last time consumption/overall running time: 40.5478s / 110.8556 s
agent0:                 episode reward: -0.2309,                 loss: 0.3187
agent1:                 episode reward: 0.2309,                 loss: nan
Episode: 101/50100 (0.2016%),                 avg. length: 9.0,                last time consumption/overall running time: 40.5866s / 151.4422 s
agent0:                 episode reward: 0.1194,                 loss: 0.3123
agent1:                 episode reward: -0.1194,                 loss: nan
Episode: 111/50100 (0.2216%),                 avg. length: 9.0,                last time consumption/overall running time: 40.5579s / 192.0001 s
agent0:                 episode reward: 0.1746,                 loss: 0.3091
agent1:                 episode reward: -0.1746,                 loss: nan
Episode: 121/50100 (0.2415%),                 avg. length: 9.0,                last time consumption/overall running time: 40.6630s / 232.6631 s
agent0:                 episode reward: -0.3809,                 loss: 0.3086
agent1:                 episode reward: 0.3809,                 loss: nan
Episode: 131/50100 (0.2615%),                 avg. length: 9.0,                last time consumption/overall running time: 40.4635s / 273.1266 s
agent0:                 episode reward: -0.1348,                 loss: 0.3088
agent1:                 episode reward: 0.1348,                 loss: nan
Episode: 141/50100 (0.2814%),                 avg. length: 9.0,                last time consumption/overall running time: 40.3772s / 313.5038 s
agent0:                 episode reward: 0.0017,                 loss: 0.3054
agent1:                 episode reward: -0.0017,                 loss: nan
Episode: 151/50100 (0.3014%),                 avg. length: 9.0,                last time consumption/overall running time: 40.3668s / 353.8706 s
agent0:                 episode reward: 1.4944,                 loss: 0.3072
agent1:                 episode reward: -1.4944,                 loss: nan
Episode: 161/50100 (0.3214%),                 avg. length: 9.0,                last time consumption/overall running time: 40.3765s / 394.2471 s
agent0:                 episode reward: 0.2288,                 loss: 0.3071
agent1:                 episode reward: -0.2288,                 loss: nan
Episode: 171/50100 (0.3413%),                 avg. length: 9.0,                last time consumption/overall running time: 40.5140s / 434.7611 s
agent0:                 episode reward: 0.8969,                 loss: 0.3029
agent1:                 episode reward: -0.8969,                 loss: nan
Episode: 181/50100 (0.3613%),                 avg. length: 9.0,                last time consumption/overall running time: 40.4417s / 475.2028 s
agent0:                 episode reward: 0.2997,                 loss: 0.3027
agent1:                 episode reward: -0.2997,                 loss: nan
Episode: 191/50100 (0.3812%),                 avg. length: 9.0,                last time consumption/overall running time: 40.4270s / 515.6298 s
agent0:                 episode reward: 0.0717,                 loss: 0.3005
agent1:                 episode reward: -0.0717,                 loss: nan
Episode: 201/50100 (0.4012%),                 avg. length: 9.0,                last time consumption/overall running time: 40.5514s / 556.1813 s
agent0:                 episode reward: -0.3823,                 loss: 0.3025
agent1:                 episode reward: 0.3823,                 loss: nan
Episode: 211/50100 (0.4212%),                 avg. length: 9.0,                last time consumption/overall running time: 40.4390s / 596.6202 s
agent0:                 episode reward: -0.3634,                 loss: 0.3015
agent1:                 episode reward: 0.3634,                 loss: nan
Episode: 221/50100 (0.4411%),                 avg. length: 9.0,                last time consumption/overall running time: 40.7885s / 637.4087 s
agent0:                 episode reward: -0.5203,                 loss: 0.3009
agent1:                 episode reward: 0.5203,                 loss: nan
Episode: 231/50100 (0.4611%),                 avg. length: 9.0,                last time consumption/overall running time: 40.6944s / 678.1031 s
agent0:                 episode reward: -0.3012,                 loss: 0.3021
agent1:                 episode reward: 0.3012,                 loss: nan
Episode: 241/50100 (0.4810%),                 avg. length: 9.0,                last time consumption/overall running time: 40.5948s / 718.6978 s
agent0:                 episode reward: 0.6919,                 loss: 0.2989
agent1:                 episode reward: -0.6919,                 loss: nan
Episode: 251/50100 (0.5010%),                 avg. length: 9.0,                last time consumption/overall running time: 40.5591s / 759.2569 s
agent0:                 episode reward: 0.9750,                 loss: 0.2992
agent1:                 episode reward: -0.9750,                 loss: nan
Episode: 261/50100 (0.5210%),                 avg. length: 9.0,                last time consumption/overall running time: 40.5759s / 799.8329 s
agent0:                 episode reward: 0.6035,                 loss: 0.2970
agent1:                 episode reward: -0.6035,                 loss: nan
Episode: 271/50100 (0.5409%),                 avg. length: 9.0,                last time consumption/overall running time: 40.5882s / 840.4211 s
agent0:                 episode reward: -0.4039,                 loss: 0.3006
agent1:                 episode reward: 0.4039,                 loss: nan
Episode: 281/50100 (0.5609%),                 avg. length: 9.0,                last time consumption/overall running time: 40.5620s / 880.9831 s
agent0:                 episode reward: -0.7309,                 loss: 0.3004
agent1:                 episode reward: 0.7309,                 loss: nan
Episode: 291/50100 (0.5808%),                 avg. length: 9.0,                last time consumption/overall running time: 40.6297s / 921.6128 s
agent0:                 episode reward: 0.0027,                 loss: 0.2995
agent1:                 episode reward: -0.0027,                 loss: nan
Episode: 301/50100 (0.6008%),                 avg. length: 9.0,                last time consumption/overall running time: 40.6234s / 962.2362 s
agent0:                 episode reward: -0.3806,                 loss: 0.2967
agent1:                 episode reward: 0.3806,                 loss: nan
Episode: 311/50100 (0.6208%),                 avg. length: 9.0,                last time consumption/overall running time: 40.8355s / 1003.0717 s
agent0:                 episode reward: 0.8140,                 loss: 0.2957
agent1:                 episode reward: -0.8140,                 loss: nan
Episode: 321/50100 (0.6407%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9549s / 1044.0266 s
agent0:                 episode reward: -0.5521,                 loss: 0.2955
agent1:                 episode reward: 0.5521,                 loss: nan
Episode: 331/50100 (0.6607%),                 avg. length: 9.0,                last time consumption/overall running time: 40.7496s / 1084.7761 s
agent0:                 episode reward: 0.9032,                 loss: 0.2938
agent1:                 episode reward: -0.9032,                 loss: nan
Episode: 341/50100 (0.6806%),                 avg. length: 9.0,                last time consumption/overall running time: 40.6860s / 1125.4621 s
agent0:                 episode reward: 0.6379,                 loss: 0.2930
agent1:                 episode reward: -0.6379,                 loss: nan
Episode: 351/50100 (0.7006%),                 avg. length: 9.0,                last time consumption/overall running time: 40.7649s / 1166.2270 s
agent0:                 episode reward: -0.1320,                 loss: 0.2924
agent1:                 episode reward: 0.1320,                 loss: nan
Episode: 361/50100 (0.7206%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9131s / 1207.1401 s
agent0:                 episode reward: 0.1437,                 loss: 0.2925
agent1:                 episode reward: -0.1437,                 loss: nan
Episode: 371/50100 (0.7405%),                 avg. length: 9.0,                last time consumption/overall running time: 41.0800s / 1248.2201 s
agent0:                 episode reward: -0.4638,                 loss: 0.2961
agent1:                 episode reward: 0.4638,                 loss: nan
Episode: 381/50100 (0.7605%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9621s / 1289.1822 s
agent0:                 episode reward: -0.5544,                 loss: 0.2952
agent1:                 episode reward: 0.5544,                 loss: nan
Episode: 391/50100 (0.7804%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9630s / 1330.1452 s
agent0:                 episode reward: 0.3022,                 loss: 0.2955
agent1:                 episode reward: -0.3022,                 loss: nan
Episode: 401/50100 (0.8004%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9220s / 1371.0672 s
agent0:                 episode reward: -1.5128,                 loss: 0.2936
agent1:                 episode reward: 1.5128,                 loss: nan
Episode: 411/50100 (0.8204%),                 avg. length: 9.0,                last time consumption/overall running time: 41.0455s / 1412.1127 s
agent0:                 episode reward: -0.4054,                 loss: 0.2955
agent1:                 episode reward: 0.4054,                 loss: nan
Episode: 421/50100 (0.8403%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9637s / 1453.0764 s
agent0:                 episode reward: -0.2214,                 loss: 0.2943
agent1:                 episode reward: 0.2214,                 loss: nan
Episode: 431/50100 (0.8603%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9613s / 1494.0377 s
agent0:                 episode reward: 0.3756,                 loss: 0.2902
agent1:                 episode reward: -0.3756,                 loss: nan
Episode: 441/50100 (0.8802%),                 avg. length: 9.0,                last time consumption/overall running time: 41.0048s / 1535.0425 s
agent0:                 episode reward: 0.0972,                 loss: 0.2924
agent1:                 episode reward: -0.0972,                 loss: nan
Episode: 451/50100 (0.9002%),                 avg. length: 9.0,                last time consumption/overall running time: 40.8354s / 1575.8780 s
agent0:                 episode reward: -1.1723,                 loss: 0.2916
agent1:                 episode reward: 1.1723,                 loss: nan
Episode: 461/50100 (0.9202%),                 avg. length: 9.0,                last time consumption/overall running time: 41.0474s / 1616.9253 s
agent0:                 episode reward: -1.4129,                 loss: 0.2960
agent1:                 episode reward: 1.4129,                 loss: nan
Episode: 471/50100 (0.9401%),                 avg. length: 9.0,                last time consumption/overall running time: 40.7472s / 1657.6726 s
agent0:                 episode reward: 0.1854,                 loss: 0.2952
agent1:                 episode reward: -0.1854,                 loss: nan
Episode: 481/50100 (0.9601%),                 avg. length: 9.0,                last time consumption/overall running time: 41.0609s / 1698.7334 s
agent0:                 episode reward: 0.7506,                 loss: 0.2961
agent1:                 episode reward: -0.7506,                 loss: nan
Episode: 491/50100 (0.9800%),                 avg. length: 9.0,                last time consumption/overall running time: 41.0352s / 1739.7687 s
agent0:                 episode reward: 0.4453,                 loss: 0.2972
agent1:                 episode reward: -0.4453,                 loss: nan
Episode: 501/50100 (1.0000%),                 avg. length: 9.0,                last time consumption/overall running time: 41.1107s / 1780.8793 s
agent0:                 episode reward: -0.8277,                 loss: 0.2939
agent1:                 episode reward: 0.8277,                 loss: nan
Episode: 511/50100 (1.0200%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9653s / 1821.8446 s
agent0:                 episode reward: 0.8179,                 loss: 0.2936
agent1:                 episode reward: -0.8179,                 loss: nan
Episode: 521/50100 (1.0399%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9851s / 1862.8297 s
agent0:                 episode reward: 0.1405,                 loss: 0.2964
agent1:                 episode reward: -0.1405,                 loss: nan
Episode: 531/50100 (1.0599%),                 avg. length: 9.0,                last time consumption/overall running time: 40.7678s / 1903.5976 s
agent0:                 episode reward: 0.7442,                 loss: 0.2947
agent1:                 episode reward: -0.7442,                 loss: nan
Episode: 541/50100 (1.0798%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9786s / 1944.5762 s
agent0:                 episode reward: -0.4161,                 loss: 0.2925
agent1:                 episode reward: 0.4161,                 loss: nan
Episode: 551/50100 (1.0998%),                 avg. length: 9.0,                last time consumption/overall running time: 40.7306s / 1985.3068 s
agent0:                 episode reward: 0.9232,                 loss: 0.2938
agent1:                 episode reward: -0.9232,                 loss: nan
Episode: 561/50100 (1.1198%),                 avg. length: 9.0,                last time consumption/overall running time: 40.8905s / 2026.1973 s
agent0:                 episode reward: 0.1355,                 loss: 0.2924
agent1:                 episode reward: -0.1355,                 loss: nan
Episode: 571/50100 (1.1397%),                 avg. length: 9.0,                last time consumption/overall running time: 40.7603s / 2066.9575 s
agent0:                 episode reward: -0.9319,                 loss: 0.2941
agent1:                 episode reward: 0.9319,                 loss: nan
Episode: 581/50100 (1.1597%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9137s / 2107.8713 s
agent0:                 episode reward: -0.0139,                 loss: 0.2960
agent1:                 episode reward: 0.0139,                 loss: nan
Episode: 591/50100 (1.1796%),                 avg. length: 9.0,                last time consumption/overall running time: 40.8466s / 2148.7179 s
agent0:                 episode reward: -0.3324,                 loss: 0.2969
agent1:                 episode reward: 0.3324,                 loss: nan
Episode: 601/50100 (1.1996%),                 avg. length: 9.0,                last time consumption/overall running time: 40.7492s / 2189.4671 s
agent0:                 episode reward: -0.1083,                 loss: 0.2964
agent1:                 episode reward: 0.1083,                 loss: nan
Episode: 611/50100 (1.2196%),                 avg. length: 9.0,                last time consumption/overall running time: 41.0579s / 2230.5250 s
agent0:                 episode reward: 0.3793,                 loss: 0.2979
agent1:                 episode reward: -0.3793,                 loss: nan
Episode: 621/50100 (1.2395%),                 avg. length: 9.0,                last time consumption/overall running time: 41.1328s / 2271.6578 s
agent0:                 episode reward: 0.4742,                 loss: 0.2956
agent1:                 episode reward: -0.4742,                 loss: nan
Episode: 631/50100 (1.2595%),                 avg. length: 9.0,                last time consumption/overall running time: 41.2832s / 2312.9411 s
agent0:                 episode reward: 0.1397,                 loss: 0.2938
agent1:                 episode reward: -0.1397,                 loss: nan
Episode: 641/50100 (1.2794%),                 avg. length: 9.0,                last time consumption/overall running time: 41.3490s / 2354.2901 s
agent0:                 episode reward: 0.1673,                 loss: 0.2953
agent1:                 episode reward: -0.1673,                 loss: nan
Episode: 651/50100 (1.2994%),                 avg. length: 9.0,                last time consumption/overall running time: 41.4750s / 2395.7650 s
agent0:                 episode reward: -0.2399,                 loss: 0.2945
agent1:                 episode reward: 0.2399,                 loss: nan
Episode: 661/50100 (1.3194%),                 avg. length: 9.0,                last time consumption/overall running time: 41.4511s / 2437.2162 s
agent0:                 episode reward: 0.2171,                 loss: 0.2927
agent1:                 episode reward: -0.2171,                 loss: nan
Episode: 671/50100 (1.3393%),                 avg. length: 9.0,                last time consumption/overall running time: 41.3074s / 2478.5235 s
agent0:                 episode reward: 1.2031,                 loss: 0.2955
agent1:                 episode reward: -1.2031,                 loss: nan
Episode: 681/50100 (1.3593%),                 avg. length: 9.0,                last time consumption/overall running time: 41.3360s / 2519.8595 s
agent0:                 episode reward: -0.6619,                 loss: 0.2931
agent1:                 episode reward: 0.6619,                 loss: nan
Episode: 691/50100 (1.3792%),                 avg. length: 9.0,                last time consumption/overall running time: 41.0725s / 2560.9320 s
agent0:                 episode reward: -0.1924,                 loss: 0.2958
agent1:                 episode reward: 0.1924,                 loss: nan
Episode: 701/50100 (1.3992%),                 avg. length: 9.0,                last time consumption/overall running time: 40.8835s / 2601.8155 s
agent0:                 episode reward: 0.2668,                 loss: 0.2937
agent1:                 episode reward: -0.2668,                 loss: nan
Episode: 711/50100 (1.4192%),                 avg. length: 9.0,                last time consumption/overall running time: 41.1858s / 2643.0013 s
agent0:                 episode reward: 0.8858,                 loss: 0.2951
agent1:                 episode reward: -0.8858,                 loss: nan
Episode: 721/50100 (1.4391%),                 avg. length: 9.0,                last time consumption/overall running time: 40.8448s / 2683.8461 s
agent0:                 episode reward: -0.1344,                 loss: 0.2917
agent1:                 episode reward: 0.1344,                 loss: nan
Episode: 731/50100 (1.4591%),                 avg. length: 9.0,                last time consumption/overall running time: 40.8494s / 2724.6955 s
agent0:                 episode reward: -0.2056,                 loss: 0.2936
agent1:                 episode reward: 0.2056,                 loss: nan
Episode: 741/50100 (1.4790%),                 avg. length: 9.0,                last time consumption/overall running time: 40.7509s / 2765.4464 s
agent0:                 episode reward: 0.1530,                 loss: 0.2925
agent1:                 episode reward: -0.1530,                 loss: nan
Episode: 751/50100 (1.4990%),                 avg. length: 9.0,                last time consumption/overall running time: 40.8255s / 2806.2719 s
agent0:                 episode reward: -0.7370,                 loss: 0.2924
agent1:                 episode reward: 0.7370,                 loss: nan
Episode: 761/50100 (1.5190%),                 avg. length: 9.0,                last time consumption/overall running time: 40.7500s / 2847.0219 s
agent0:                 episode reward: -1.0688,                 loss: 0.2929
agent1:                 episode reward: 1.0688,                 loss: nan
Episode: 771/50100 (1.5389%),                 avg. length: 9.0,                last time consumption/overall running time: 40.8253s / 2887.8472 s
agent0:                 episode reward: -0.9813,                 loss: 0.2909
agent1:                 episode reward: 0.9813,                 loss: nan
Episode: 781/50100 (1.5589%),                 avg. length: 9.0,                last time consumption/overall running time: 40.8737s / 2928.7208 s
agent0:                 episode reward: 0.5664,                 loss: 0.2937
agent1:                 episode reward: -0.5664,                 loss: nan
Episode: 791/50100 (1.5788%),                 avg. length: 9.0,                last time consumption/overall running time: 40.8569s / 2969.5777 s
agent0:                 episode reward: -0.2199,                 loss: 0.2956
agent1:                 episode reward: 0.2199,                 loss: nan
Episode: 801/50100 (1.5988%),                 avg. length: 9.0,                last time consumption/overall running time: 40.7646s / 3010.3424 s
agent0:                 episode reward: 0.0270,                 loss: 0.2938
agent1:                 episode reward: -0.0270,                 loss: nan
Episode: 811/50100 (1.6188%),                 avg. length: 9.0,                last time consumption/overall running time: 41.1692s / 3051.5116 s
agent0:                 episode reward: 0.2506,                 loss: 0.2921
agent1:                 episode reward: -0.2506,                 loss: nan
Episode: 821/50100 (1.6387%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9375s / 3092.4491 s
agent0:                 episode reward: -0.5107,                 loss: 0.2925
agent1:                 episode reward: 0.5107,                 loss: nan
Episode: 831/50100 (1.6587%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9944s / 3133.4435 s
agent0:                 episode reward: 1.2910,                 loss: 0.2946
agent1:                 episode reward: -1.2910,                 loss: nan
Episode: 841/50100 (1.6786%),                 avg. length: 9.0,                last time consumption/overall running time: 41.0730s / 3174.5165 s
agent0:                 episode reward: 0.3127,                 loss: 0.2899
agent1:                 episode reward: -0.3127,                 loss: nan
Episode: 851/50100 (1.6986%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9989s / 3215.5155 s
agent0:                 episode reward: -0.6325,                 loss: 0.2930
agent1:                 episode reward: 0.6325,                 loss: nan
Episode: 861/50100 (1.7186%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9997s / 3256.5151 s
agent0:                 episode reward: 1.0702,                 loss: 0.2923
agent1:                 episode reward: -1.0702,                 loss: nan
Episode: 871/50100 (1.7385%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9190s / 3297.4342 s
agent0:                 episode reward: 0.6463,                 loss: 0.2937
agent1:                 episode reward: -0.6463,                 loss: nan
Episode: 881/50100 (1.7585%),                 avg. length: 9.0,                last time consumption/overall running time: 40.8822s / 3338.3164 s
agent0:                 episode reward: -0.5525,                 loss: 0.2950
agent1:                 episode reward: 0.5525,                 loss: nan
Episode: 891/50100 (1.7784%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9105s / 3379.2268 s
agent0:                 episode reward: 0.1065,                 loss: 0.2927
agent1:                 episode reward: -0.1065,                 loss: nan
Episode: 901/50100 (1.7984%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9290s / 3420.1558 s
agent0:                 episode reward: 0.0899,                 loss: 0.2955
agent1:                 episode reward: -0.0899,                 loss: nan
Episode: 911/50100 (1.8184%),                 avg. length: 9.0,                last time consumption/overall running time: 41.0722s / 3461.2279 s
agent0:                 episode reward: -0.6586,                 loss: 0.2948
agent1:                 episode reward: 0.6586,                 loss: nan
Episode: 921/50100 (1.8383%),                 avg. length: 9.0,                last time consumption/overall running time: 40.8918s / 3502.1197 s
agent0:                 episode reward: 0.3629,                 loss: 0.2943
agent1:                 episode reward: -0.3629,                 loss: nan
Episode: 931/50100 (1.8583%),                 avg. length: 9.0,                last time consumption/overall running time: 41.0231s / 3543.1428 s
agent0:                 episode reward: -0.1691,                 loss: 0.2932
agent1:                 episode reward: 0.1691,                 loss: nan
Episode: 941/50100 (1.8782%),                 avg. length: 9.0,                last time consumption/overall running time: 40.8736s / 3584.0164 s
agent0:                 episode reward: 0.4365,                 loss: 0.2948
agent1:                 episode reward: -0.4365,                 loss: nan
Episode: 951/50100 (1.8982%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9939s / 3625.0104 s
agent0:                 episode reward: 0.4519,                 loss: 0.2915
agent1:                 episode reward: -0.4519,                 loss: nan
Episode: 961/50100 (1.9182%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9452s / 3665.9556 s
agent0:                 episode reward: 0.4676,                 loss: 0.2941
agent1:                 episode reward: -0.4676,                 loss: nan
Episode: 971/50100 (1.9381%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9393s / 3706.8949 s
agent0:                 episode reward: -0.4227,                 loss: 0.2917
agent1:                 episode reward: 0.4227,                 loss: nan
Episode: 981/50100 (1.9581%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9863s / 3747.8812 s
agent0:                 episode reward: 0.0460,                 loss: 0.2901
agent1:                 episode reward: -0.0460,                 loss: nan
Episode: 991/50100 (1.9780%),                 avg. length: 9.0,                last time consumption/overall running time: 41.0646s / 3788.9458 s
agent0:                 episode reward: -0.3298,                 loss: 0.2925
agent1:                 episode reward: 0.3298,                 loss: nan
Episode: 1001/50100 (1.9980%),                 avg. length: 9.0,                last time consumption/overall running time: 41.0118s / 3829.9576 s
agent0:                 episode reward: 0.1624,                 loss: 0.2912
agent1:                 episode reward: -0.1624,                 loss: nan
Episode: 1011/50100 (2.0180%),                 avg. length: 9.0,                last time consumption/overall running time: 41.0727s / 3871.0304 s
agent0:                 episode reward: 0.4365,                 loss: 0.2924
agent1:                 episode reward: -0.4365,                 loss: nan
Episode: 1021/50100 (2.0379%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9450s / 3911.9753 s
agent0:                 episode reward: 0.0072,                 loss: 0.2900
agent1:                 episode reward: -0.0072,                 loss: nan
Episode: 1031/50100 (2.0579%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9328s / 3952.9082 s
agent0:                 episode reward: -0.7376,                 loss: 0.2901
agent1:                 episode reward: 0.7376,                 loss: nan
Episode: 1041/50100 (2.0778%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9946s / 3993.9028 s
agent0:                 episode reward: -0.1065,                 loss: 0.2899
agent1:                 episode reward: 0.1065,                 loss: nan
Episode: 1051/50100 (2.0978%),                 avg. length: 9.0,                last time consumption/overall running time: 41.0016s / 4034.9043 s
agent0:                 episode reward: 0.7323,                 loss: 0.2873
agent1:                 episode reward: -0.7323,                 loss: nan
Episode: 1061/50100 (2.1178%),                 avg. length: 9.0,                last time consumption/overall running time: 40.8992s / 4075.8035 s
agent0:                 episode reward: 0.1491,                 loss: 0.2926
agent1:                 episode reward: -0.1491,                 loss: nan
Episode: 1071/50100 (2.1377%),                 avg. length: 9.0,                last time consumption/overall running time: 40.8429s / 4116.6464 s
agent0:                 episode reward: -0.6491,                 loss: 0.2921
agent1:                 episode reward: 0.6491,                 loss: nan
Episode: 1081/50100 (2.1577%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9407s / 4157.5871 s
agent0:                 episode reward: -0.2074,                 loss: 0.2910
agent1:                 episode reward: 0.2074,                 loss: nan
Episode: 1091/50100 (2.1776%),                 avg. length: 9.0,                last time consumption/overall running time: 40.7743s / 4198.3614 s
agent0:                 episode reward: -0.5249,                 loss: 0.2929
agent1:                 episode reward: 0.5249,                 loss: nan
Episode: 1101/50100 (2.1976%),                 avg. length: 9.0,                last time consumption/overall running time: 40.8349s / 4239.1963 s
agent0:                 episode reward: 0.3938,                 loss: 0.2923
agent1:                 episode reward: -0.3938,                 loss: nan
Episode: 1111/50100 (2.2176%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9122s / 4280.1085 s
agent0:                 episode reward: 0.0765,                 loss: 0.2908
agent1:                 episode reward: -0.0765,                 loss: nan
Episode: 1121/50100 (2.2375%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9112s / 4321.0197 s
agent0:                 episode reward: 0.5408,                 loss: 0.2906
agent1:                 episode reward: -0.5408,                 loss: nan
Episode: 1131/50100 (2.2575%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9617s / 4361.9813 s
agent0:                 episode reward: -0.3759,                 loss: 0.2904
agent1:                 episode reward: 0.3759,                 loss: nan
Episode: 1141/50100 (2.2774%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9332s / 4402.9145 s
agent0:                 episode reward: -0.2806,                 loss: 0.2911
agent1:                 episode reward: 0.2806,                 loss: nan
Episode: 1151/50100 (2.2974%),                 avg. length: 9.0,                last time consumption/overall running time: 40.8385s / 4443.7531 s
agent0:                 episode reward: 0.1975,                 loss: 0.2919
agent1:                 episode reward: -0.1975,                 loss: nan
Episode: 1161/50100 (2.3174%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9606s / 4484.7137 s
agent0:                 episode reward: 0.0423,                 loss: 0.2917
agent1:                 episode reward: -0.0423,                 loss: nan
Episode: 1171/50100 (2.3373%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9299s / 4525.6436 s
agent0:                 episode reward: 0.3416,                 loss: 0.2930
agent1:                 episode reward: -0.3416,                 loss: nan
Episode: 1181/50100 (2.3573%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9875s / 4566.6310 s
agent0:                 episode reward: 0.4552,                 loss: 0.2933
agent1:                 episode reward: -0.4552,                 loss: nan
Episode: 1191/50100 (2.3772%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9641s / 4607.5951 s
agent0:                 episode reward: -0.2518,                 loss: 0.2916
agent1:                 episode reward: 0.2518,                 loss: nan
Episode: 1201/50100 (2.3972%),                 avg. length: 9.0,                last time consumption/overall running time: 41.0201s / 4648.6152 s
agent0:                 episode reward: 0.9500,                 loss: 0.2904
agent1:                 episode reward: -0.9500,                 loss: nan
Episode: 1211/50100 (2.4172%),                 avg. length: 9.0,                last time consumption/overall running time: 41.0805s / 4689.6957 s
agent0:                 episode reward: 0.3893,                 loss: 0.2923
agent1:                 episode reward: -0.3893,                 loss: nan
Episode: 1221/50100 (2.4371%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9418s / 4730.6376 s
agent0:                 episode reward: 1.0042,                 loss: 0.2921
agent1:                 episode reward: -1.0042,                 loss: nan
Episode: 1231/50100 (2.4571%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9925s / 4771.6301 s
agent0:                 episode reward: 0.4313,                 loss: 0.2879
agent1:                 episode reward: -0.4313,                 loss: nan
Episode: 1241/50100 (2.4770%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9548s / 4812.5849 s
agent0:                 episode reward: 0.6972,                 loss: 0.2896
agent1:                 episode reward: -0.6972,                 loss: nan
Episode: 1251/50100 (2.4970%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9824s / 4853.5673 s
agent0:                 episode reward: 0.5937,                 loss: 0.2876
agent1:                 episode reward: -0.5937,                 loss: nan
Episode: 1261/50100 (2.5170%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9906s / 4894.5579 s
agent0:                 episode reward: -0.4341,                 loss: 0.2883
agent1:                 episode reward: 0.4341,                 loss: nan
Episode: 1271/50100 (2.5369%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9082s / 4935.4661 s
agent0:                 episode reward: -0.4897,                 loss: 0.2899
agent1:                 episode reward: 0.4897,                 loss: nan
Episode: 1281/50100 (2.5569%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9773s / 4976.4433 s
agent0:                 episode reward: 0.0709,                 loss: 0.2902
agent1:                 episode reward: -0.0709,                 loss: nan
Episode: 1291/50100 (2.5768%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9325s / 5017.3759 s
agent0:                 episode reward: -0.6891,                 loss: 0.2908
agent1:                 episode reward: 0.6891,                 loss: nan
Episode: 1301/50100 (2.5968%),                 avg. length: 9.0,                last time consumption/overall running time: 41.3119s / 5058.6878 s
agent0:                 episode reward: 1.0495,                 loss: 0.2907
agent1:                 episode reward: -1.0495,                 loss: nan
Episode: 1311/50100 (2.6168%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9498s / 5099.6376 s
agent0:                 episode reward: 1.2949,                 loss: 0.2888
agent1:                 episode reward: -1.2949,                 loss: nan
Episode: 1321/50100 (2.6367%),                 avg. length: 9.0,                last time consumption/overall running time: 41.1152s / 5140.7528 s
agent0:                 episode reward: -0.3795,                 loss: 0.2870
agent1:                 episode reward: 0.3795,                 loss: nan
Episode: 1331/50100 (2.6567%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9599s / 5181.7127 s
agent0:                 episode reward: 0.8190,                 loss: 0.2894
agent1:                 episode reward: -0.8190,                 loss: nan
Episode: 1341/50100 (2.6766%),                 avg. length: 9.0,                last time consumption/overall running time: 40.8071s / 5222.5198 s
agent0:                 episode reward: 0.7926,                 loss: 0.2895
agent1:                 episode reward: -0.7926,                 loss: nan
Episode: 1351/50100 (2.6966%),                 avg. length: 9.0,                last time consumption/overall running time: 40.8415s / 5263.3613 s
agent0:                 episode reward: 0.2690,                 loss: 0.2893
agent1:                 episode reward: -0.2690,                 loss: nan
Episode: 1361/50100 (2.7166%),                 avg. length: 9.0,                last time consumption/overall running time: 40.8536s / 5304.2149 s
agent0:                 episode reward: -0.2709,                 loss: 0.2867
agent1:                 episode reward: 0.2709,                 loss: nan
Episode: 1371/50100 (2.7365%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9129s / 5345.1278 s
agent0:                 episode reward: 0.2304,                 loss: 0.2890
agent1:                 episode reward: -0.2304,                 loss: nan
Episode: 1381/50100 (2.7565%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9689s / 5386.0967 s
agent0:                 episode reward: 0.2102,                 loss: 0.2864
agent1:                 episode reward: -0.2102,                 loss: nan
Episode: 1391/50100 (2.7764%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9398s / 5427.0365 s
agent0:                 episode reward: 0.4647,                 loss: 0.2872
agent1:                 episode reward: -0.4647,                 loss: nan
Episode: 1401/50100 (2.7964%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9009s / 5467.9374 s
agent0:                 episode reward: -0.3930,                 loss: 0.2859
agent1:                 episode reward: 0.3930,                 loss: nan
Episode: 1411/50100 (2.8164%),                 avg. length: 9.0,                last time consumption/overall running time: 41.0308s / 5508.9682 s
agent0:                 episode reward: -0.5301,                 loss: 0.2893
agent1:                 episode reward: 0.5301,                 loss: nan
Episode: 1421/50100 (2.8363%),                 avg. length: 9.0,                last time consumption/overall running time: 41.0415s / 5550.0097 s
agent0:                 episode reward: -0.5810,                 loss: 0.2892
agent1:                 episode reward: 0.5810,                 loss: nan
Episode: 1431/50100 (2.8563%),                 avg. length: 9.0,                last time consumption/overall running time: 41.0090s / 5591.0187 s
agent0:                 episode reward: 0.7506,                 loss: 0.2845
agent1:                 episode reward: -0.7506,                 loss: nan
Episode: 1441/50100 (2.8762%),                 avg. length: 9.0,                last time consumption/overall running time: 41.0649s / 5632.0836 s
agent0:                 episode reward: 0.1276,                 loss: 0.2868
agent1:                 episode reward: -0.1276,                 loss: nan
Episode: 1451/50100 (2.8962%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9748s / 5673.0583 s
agent0:                 episode reward: 0.6431,                 loss: 0.2853
agent1:                 episode reward: -0.6431,                 loss: nan
Episode: 1461/50100 (2.9162%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9802s / 5714.0385 s
agent0:                 episode reward: 0.3448,                 loss: 0.2846
agent1:                 episode reward: -0.3448,                 loss: nan
Episode: 1471/50100 (2.9361%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9789s / 5755.0174 s
agent0:                 episode reward: -0.5333,                 loss: 0.2906
agent1:                 episode reward: 0.5333,                 loss: nan
Episode: 1481/50100 (2.9561%),                 avg. length: 9.0,                last time consumption/overall running time: 41.1103s / 5796.1276 s
agent0:                 episode reward: -0.4910,                 loss: 0.2879
agent1:                 episode reward: 0.4910,                 loss: nan
Episode: 1491/50100 (2.9760%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9302s / 5837.0579 s
agent0:                 episode reward: -0.4444,                 loss: 0.2892
agent1:                 episode reward: 0.4444,                 loss: nan
Episode: 1501/50100 (2.9960%),                 avg. length: 9.0,                last time consumption/overall running time: 40.8535s / 5877.9114 s
agent0:                 episode reward: -0.0679,                 loss: 0.2888
agent1:                 episode reward: 0.0679,                 loss: nan
Episode: 1511/50100 (3.0160%),                 avg. length: 9.0,                last time consumption/overall running time: 40.8913s / 5918.8027 s
agent0:                 episode reward: -0.3542,                 loss: 0.2854
agent1:                 episode reward: 0.3542,                 loss: nan
Episode: 1521/50100 (3.0359%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9630s / 5959.7658 s
agent0:                 episode reward: 0.1518,                 loss: 0.2871
agent1:                 episode reward: -0.1518,                 loss: nan
Episode: 1531/50100 (3.0559%),                 avg. length: 9.0,                last time consumption/overall running time: 40.7675s / 6000.5333 s
agent0:                 episode reward: -0.0751,                 loss: 0.2867
agent1:                 episode reward: 0.0751,                 loss: nan
Episode: 1541/50100 (3.0758%),                 avg. length: 9.0,                last time consumption/overall running time: 40.8596s / 6041.3929 s
agent0:                 episode reward: 0.5382,                 loss: 0.2848
agent1:                 episode reward: -0.5382,                 loss: nan
Episode: 1551/50100 (3.0958%),                 avg. length: 9.0,                last time consumption/overall running time: 40.7856s / 6082.1784 s
agent0:                 episode reward: 0.1710,                 loss: 0.2838
agent1:                 episode reward: -0.1710,                 loss: nan
Episode: 1561/50100 (3.1158%),                 avg. length: 9.0,                last time consumption/overall running time: 40.7622s / 6122.9406 s
agent0:                 episode reward: 0.0714,                 loss: 0.2856
agent1:                 episode reward: -0.0714,                 loss: nan
Episode: 1571/50100 (3.1357%),                 avg. length: 9.0,                last time consumption/overall running time: 40.7998s / 6163.7404 s
agent0:                 episode reward: -0.2915,                 loss: 0.2864
agent1:                 episode reward: 0.2915,                 loss: nan
Episode: 1581/50100 (3.1557%),                 avg. length: 9.0,                last time consumption/overall running time: 40.8417s / 6204.5821 s
agent0:                 episode reward: 0.3708,                 loss: 0.2855
agent1:                 episode reward: -0.3708,                 loss: nan
Episode: 1591/50100 (3.1756%),                 avg. length: 9.0,                last time consumption/overall running time: 40.8155s / 6245.3976 s
agent0:                 episode reward: 0.4937,                 loss: 0.2864
agent1:                 episode reward: -0.4937,                 loss: nan
Episode: 1601/50100 (3.1956%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9449s / 6286.3425 s
agent0:                 episode reward: -0.8519,                 loss: 0.2848
agent1:                 episode reward: 0.8519,                 loss: nan
Episode: 1611/50100 (3.2156%),                 avg. length: 9.0,                last time consumption/overall running time: 40.8396s / 6327.1821 s
agent0:                 episode reward: 0.3423,                 loss: 0.2831
agent1:                 episode reward: -0.3423,                 loss: nan
Episode: 1621/50100 (3.2355%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9332s / 6368.1153 s
agent0:                 episode reward: -0.7645,                 loss: 0.2844
agent1:                 episode reward: 0.7645,                 loss: nan
Episode: 1631/50100 (3.2555%),                 avg. length: 9.0,                last time consumption/overall running time: 40.8635s / 6408.9788 s
agent0:                 episode reward: -0.1450,                 loss: 0.2849
agent1:                 episode reward: 0.1450,                 loss: nan
Episode: 1641/50100 (3.2754%),                 avg. length: 9.0,                last time consumption/overall running time: 40.8147s / 6449.7936 s
agent0:                 episode reward: 0.4765,                 loss: 0.2839
agent1:                 episode reward: -0.4765,                 loss: nan
Episode: 1651/50100 (3.2954%),                 avg. length: 9.0,                last time consumption/overall running time: 40.8160s / 6490.6095 s
agent0:                 episode reward: 0.3636,                 loss: 0.2858
agent1:                 episode reward: -0.3636,                 loss: nan
Episode: 1661/50100 (3.3154%),                 avg. length: 9.0,                last time consumption/overall running time: 40.8776s / 6531.4871 s
agent0:                 episode reward: -0.1068,                 loss: 0.2831
agent1:                 episode reward: 0.1068,                 loss: nan
Episode: 1671/50100 (3.3353%),                 avg. length: 9.0,                last time consumption/overall running time: 40.8603s / 6572.3474 s
agent0:                 episode reward: 0.4185,                 loss: 0.2844
agent1:                 episode reward: -0.4185,                 loss: nan
Episode: 1681/50100 (3.3553%),                 avg. length: 9.0,                last time consumption/overall running time: 40.8108s / 6613.1582 s
agent0:                 episode reward: 0.2072,                 loss: 0.2863
agent1:                 episode reward: -0.2072,                 loss: nan
Episode: 1691/50100 (3.3752%),                 avg. length: 9.0,                last time consumption/overall running time: 40.8339s / 6653.9922 s
agent0:                 episode reward: -1.1478,                 loss: 0.2836
agent1:                 episode reward: 1.1478,                 loss: nan
Episode: 1701/50100 (3.3952%),                 avg. length: 9.0,                last time consumption/overall running time: 40.8702s / 6694.8624 s
agent0:                 episode reward: 0.4732,                 loss: 0.2853
agent1:                 episode reward: -0.4732,                 loss: nan
Episode: 1711/50100 (3.4152%),                 avg. length: 9.0,                last time consumption/overall running time: 40.8442s / 6735.7066 s
agent0:                 episode reward: 0.6681,                 loss: 0.2850
agent1:                 episode reward: -0.6681,                 loss: nan
Episode: 1721/50100 (3.4351%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9314s / 6776.6380 s
agent0:                 episode reward: 0.4078,                 loss: 0.2827
agent1:                 episode reward: -0.4078,                 loss: nan
Episode: 1731/50100 (3.4551%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9711s / 6817.6091 s
agent0:                 episode reward: 0.7835,                 loss: 0.2831
agent1:                 episode reward: -0.7835,                 loss: nan
Episode: 1741/50100 (3.4750%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9198s / 6858.5289 s
agent0:                 episode reward: 1.2028,                 loss: 0.2815
agent1:                 episode reward: -1.2028,                 loss: nan
Episode: 1751/50100 (3.4950%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9848s / 6899.5137 s
agent0:                 episode reward: 0.1220,                 loss: 0.2805
agent1:                 episode reward: -0.1220,                 loss: nan
Episode: 1761/50100 (3.5150%),                 avg. length: 9.0,                last time consumption/overall running time: 40.8879s / 6940.4016 s
agent0:                 episode reward: 0.6470,                 loss: 0.2806
agent1:                 episode reward: -0.6470,                 loss: nan
Episode: 1771/50100 (3.5349%),                 avg. length: 9.0,                last time consumption/overall running time: 40.8993s / 6981.3009 s
agent0:                 episode reward: -0.1719,                 loss: 0.2798
agent1:                 episode reward: 0.1719,                 loss: nan
Episode: 1781/50100 (3.5549%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9496s / 7022.2505 s
agent0:                 episode reward: -0.0066,                 loss: 0.2768
agent1:                 episode reward: 0.0066,                 loss: nan
Episode: 1791/50100 (3.5749%),                 avg. length: 9.0,                last time consumption/overall running time: 41.0562s / 7063.3067 s
agent0:                 episode reward: 0.1398,                 loss: 0.2783
agent1:                 episode reward: -0.1398,                 loss: nan
Episode: 1801/50100 (3.5948%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9758s / 7104.2825 s
agent0:                 episode reward: 0.0824,                 loss: 0.2776
agent1:                 episode reward: -0.0824,                 loss: nan
Episode: 1811/50100 (3.6148%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9620s / 7145.2445 s
agent0:                 episode reward: -0.2107,                 loss: 0.2789
agent1:                 episode reward: 0.2107,                 loss: nan
Episode: 1821/50100 (3.6347%),                 avg. length: 9.0,                last time consumption/overall running time: 41.0332s / 7186.2777 s
agent0:                 episode reward: -0.3064,                 loss: 0.2787
agent1:                 episode reward: 0.3064,                 loss: nan
Episode: 1831/50100 (3.6547%),                 avg. length: 9.0,                last time consumption/overall running time: 41.1791s / 7227.4568 s
agent0:                 episode reward: -0.6432,                 loss: 0.2778
agent1:                 episode reward: 0.6432,                 loss: nan
Episode: 1841/50100 (3.6747%),                 avg. length: 9.0,                last time consumption/overall running time: 41.0746s / 7268.5314 s
agent0:                 episode reward: -0.4051,                 loss: 0.2765
agent1:                 episode reward: 0.4051,                 loss: nan
Episode: 1851/50100 (3.6946%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9783s / 7309.5097 s
agent0:                 episode reward: -1.1520,                 loss: 0.2779
agent1:                 episode reward: 1.1520,                 loss: nan
Episode: 1861/50100 (3.7146%),                 avg. length: 9.0,                last time consumption/overall running time: 41.0397s / 7350.5494 s
agent0:                 episode reward: 0.9403,                 loss: 0.2756
agent1:                 episode reward: -0.9403,                 loss: nan
Episode: 1871/50100 (3.7345%),                 avg. length: 9.0,                last time consumption/overall running time: 41.0096s / 7391.5590 s
agent0:                 episode reward: -0.1292,                 loss: 0.2799
agent1:                 episode reward: 0.1292,                 loss: nan
Episode: 1881/50100 (3.7545%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9882s / 7432.5472 s
agent0:                 episode reward: 0.0451,                 loss: 0.2767
agent1:                 episode reward: -0.0451,                 loss: nan
Episode: 1891/50100 (3.7745%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9118s / 7473.4590 s
agent0:                 episode reward: -0.2593,                 loss: 0.2766
agent1:                 episode reward: 0.2593,                 loss: nan
Episode: 1901/50100 (3.7944%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9209s / 7514.3799 s
agent0:                 episode reward: 0.2396,                 loss: 0.2785
agent1:                 episode reward: -0.2396,                 loss: nan
Episode: 1911/50100 (3.8144%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9469s / 7555.3268 s
agent0:                 episode reward: -0.0170,                 loss: 0.2785
agent1:                 episode reward: 0.0170,                 loss: nan
Episode: 1921/50100 (3.8343%),                 avg. length: 9.0,                last time consumption/overall running time: 40.8842s / 7596.2110 s
agent0:                 episode reward: -0.2142,                 loss: 0.2765
agent1:                 episode reward: 0.2142,                 loss: nan
Episode: 1931/50100 (3.8543%),                 avg. length: 9.0,                last time consumption/overall running time: 41.0308s / 7637.2418 s
agent0:                 episode reward: -0.5616,                 loss: 0.2750
agent1:                 episode reward: 0.5616,                 loss: nan
Episode: 1941/50100 (3.8743%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9814s / 7678.2232 s
agent0:                 episode reward: 1.2704,                 loss: 0.2778
agent1:                 episode reward: -1.2704,                 loss: nan
Episode: 1951/50100 (3.8942%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9421s / 7719.1653 s
agent0:                 episode reward: 0.7703,                 loss: 0.2765
agent1:                 episode reward: -0.7703,                 loss: nan
Episode: 1961/50100 (3.9142%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9504s / 7760.1157 s
agent0:                 episode reward: 0.2933,                 loss: 0.2755
agent1:                 episode reward: -0.2933,                 loss: nan
Episode: 1971/50100 (3.9341%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9061s / 7801.0217 s
agent0:                 episode reward: 0.6322,                 loss: 0.2757
agent1:                 episode reward: -0.6322,                 loss: nan
Episode: 1981/50100 (3.9541%),                 avg. length: 9.0,                last time consumption/overall running time: 40.8979s / 7841.9196 s
agent0:                 episode reward: 0.7528,                 loss: 0.2760
agent1:                 episode reward: -0.7528,                 loss: nan
Episode: 1991/50100 (3.9741%),                 avg. length: 9.0,                last time consumption/overall running time: 40.8814s / 7882.8011 s
agent0:                 episode reward: -0.1241,                 loss: 0.2752
agent1:                 episode reward: 0.1241,                 loss: nan
Episode: 2001/50100 (3.9940%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9422s / 7923.7433 s
agent0:                 episode reward: 0.4040,                 loss: 0.2755
agent1:                 episode reward: -0.4040,                 loss: nan
Episode: 2011/50100 (4.0140%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9230s / 7964.6663 s
agent0:                 episode reward: 0.5486,                 loss: 0.2707
agent1:                 episode reward: -0.5486,                 loss: nan
Episode: 2021/50100 (4.0339%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9374s / 8005.6037 s
agent0:                 episode reward: 0.5701,                 loss: 0.2730
agent1:                 episode reward: -0.5701,                 loss: nan
Episode: 2031/50100 (4.0539%),                 avg. length: 9.0,                last time consumption/overall running time: 41.0381s / 8046.6417 s
agent0:                 episode reward: -0.1879,                 loss: 0.2704
agent1:                 episode reward: 0.1879,                 loss: nan
Episode: 2041/50100 (4.0739%),                 avg. length: 9.0,                last time consumption/overall running time: 41.0521s / 8087.6938 s
agent0:                 episode reward: -1.4127,                 loss: 0.2726
agent1:                 episode reward: 1.4127,                 loss: nan
Episode: 2051/50100 (4.0938%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9879s / 8128.6817 s
agent0:                 episode reward: 0.2934,                 loss: 0.2720
agent1:                 episode reward: -0.2934,                 loss: nan
Episode: 2061/50100 (4.1138%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9173s / 8169.5990 s
agent0:                 episode reward: -1.1689,                 loss: 0.2729
agent1:                 episode reward: 1.1689,                 loss: nan
Episode: 2071/50100 (4.1337%),                 avg. length: 9.0,                last time consumption/overall running time: 41.0046s / 8210.6036 s
agent0:                 episode reward: 0.0746,                 loss: 0.2729
agent1:                 episode reward: -0.0746,                 loss: nan
Episode: 2081/50100 (4.1537%),                 avg. length: 9.0,                last time consumption/overall running time: 41.0061s / 8251.6097 s
agent0:                 episode reward: -1.0281,                 loss: 0.2722
agent1:                 episode reward: 1.0281,                 loss: nan
Episode: 2091/50100 (4.1737%),                 avg. length: 9.0,                last time consumption/overall running time: 40.9425s / 8292.5522 s
agent0:                 episode reward: -1.2582,                 loss: 0.2715
agent1:                 episode reward: 1.2582,                 loss: nan
Episode: 2101/50100 (4.1936%),                 avg. length: 9.0,                last time consumption/overall running time: 41.0043s / 8333.5566 s
agent0:                 episode reward: -0.1072,                 loss: 0.2693
agent1:                 episode reward: 0.1072,                 loss: nan
Episode: 2111/50100 (4.2136%),                 avg. length: 9.0,                last time consumption/overall running time: 41.0872s / 8374.6438 s
agent0:                 episode reward: -0.4258,                 loss: 0.2716
agent1:                 episode reward: 0.4258,                 loss: nan
Episode: 2121/50100 (4.2335%),                 avg. length: 9.0,                last time consumption/overall running time: 41.0084s / 8415.6522 s
agent0:                 episode reward: -0.2232,                 loss: 0.2715
agent1:                 episode reward: 0.2232,                 loss: nan