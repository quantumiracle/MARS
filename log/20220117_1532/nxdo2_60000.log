pygame 2.0.0 (SDL 2.0.12, python 3.7.10)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 12.0, (1,), float32) action space: Discrete(3)
random seed: 91
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7fd8a5789f50>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
Agents No. [0] (index starting from 0) are not learnable.
Load meta strategy:  [[0.249 0.11  0.088 ... 0.    0.    0.   ]
 [0.042 0.025 0.037 ... 0.    0.    0.   ]]
Load checkpoints (policy family):  [['83' '5753' '6419' ... '57305' '57555' '59346']
 ['121' '6342' '6627' ... '57352' '57708' '59367']]
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': 'random', 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000, 'update_itr': 1}, 'batch_size': 640, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'cpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220116204408/epi_60000/', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nxdo2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'selfplay_score_delta': 1.5, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'against_baseline': False}
Save models to : /home/zihan/research/MARS/data/model/20220116204408_exploit_60000/mdp_arbitrary_mdp_nxdo2. 
 Save logs to: /home/zihan/research/MARS/data/log/20220116204408_exploit_60000/mdp_arbitrary_mdp_nxdo2.
Episode: 1/30000 (0.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 1.3684s / 1.3684 s
agent0:                 episode reward: -1.1373,                 loss: nan
agent1:                 episode reward: 1.1373,                 loss: nan
Episode: 21/30000 (0.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3324s / 1.7008 s
agent0:                 episode reward: 0.0971,                 loss: nan
agent1:                 episode reward: -0.0971,                 loss: nan
Episode: 41/30000 (0.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1891s / 1.8898 s
agent0:                 episode reward: 0.0704,                 loss: nan
agent1:                 episode reward: -0.0704,                 loss: nan
Episode: 61/30000 (0.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0990s / 1.9888 s
agent0:                 episode reward: -0.3420,                 loss: nan
agent1:                 episode reward: 0.3420,                 loss: nan
Episode: 81/30000 (0.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2163s / 2.2051 s
agent0:                 episode reward: -0.3334,                 loss: nan
agent1:                 episode reward: 0.3334,                 loss: nan
Episode: 101/30000 (0.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6456s / 2.8507 s
agent0:                 episode reward: -0.1505,                 loss: nan
agent1:                 episode reward: 0.1505,                 loss: nan
Episode: 121/30000 (0.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6018s / 3.4524 s
agent0:                 episode reward: 0.1557,                 loss: nan
agent1:                 episode reward: -0.1557,                 loss: nan
Episode: 141/30000 (0.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2660s / 3.7185 s
agent0:                 episode reward: -0.4993,                 loss: nan
agent1:                 episode reward: 0.4993,                 loss: nan
Episode: 161/30000 (0.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5698s / 4.2883 s
agent0:                 episode reward: -0.0269,                 loss: nan
agent1:                 episode reward: 0.0269,                 loss: nan
Episode: 181/30000 (0.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 1.0731s / 5.3614 s
agent0:                 episode reward: 0.5043,                 loss: nan
agent1:                 episode reward: -0.5043,                 loss: nan
Episode: 201/30000 (0.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 1.4646s / 6.8260 s
agent0:                 episode reward: -0.1281,                 loss: nan
agent1:                 episode reward: 0.1281,                 loss: nan
Episode: 221/30000 (0.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 36.8299s / 43.6559 s
agent0:                 episode reward: -0.1006,                 loss: nan
agent1:                 episode reward: 0.1006,                 loss: 0.2391
Episode: 241/30000 (0.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 94.7651s / 138.4210 s
agent0:                 episode reward: -0.1866,                 loss: nan
agent1:                 episode reward: 0.1866,                 loss: 0.2104
Episode: 261/30000 (0.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 98.7724s / 237.1935 s
agent0:                 episode reward: -0.2444,                 loss: nan
agent1:                 episode reward: 0.2444,                 loss: 0.1838
Episode: 281/30000 (0.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 99.6763s / 336.8698 s
agent0:                 episode reward: 0.5944,                 loss: nan
agent1:                 episode reward: -0.5944,                 loss: 0.1688
Episode: 301/30000 (1.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 100.5768s / 437.4466 s
agent0:                 episode reward: 0.1129,                 loss: nan
agent1:                 episode reward: -0.1129,                 loss: 0.1655
Episode: 321/30000 (1.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 96.8641s / 534.3107 s
agent0:                 episode reward: 0.0642,                 loss: nan
agent1:                 episode reward: -0.0642,                 loss: 0.1641
Episode: 341/30000 (1.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 99.6752s / 633.9859 s
agent0:                 episode reward: -0.0052,                 loss: nan
agent1:                 episode reward: 0.0052,                 loss: 0.1637
Episode: 361/30000 (1.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 98.5040s / 732.4898 s
agent0:                 episode reward: 0.3750,                 loss: nan
agent1:                 episode reward: -0.3750,                 loss: 0.1629
Episode: 381/30000 (1.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 95.6532s / 828.1430 s
agent0:                 episode reward: 0.4842,                 loss: nan
agent1:                 episode reward: -0.4842,                 loss: 0.1610
Episode: 401/30000 (1.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 98.6298s / 926.7728 s
agent0:                 episode reward: 0.3516,                 loss: nan
agent1:                 episode reward: -0.3516,                 loss: 0.1602
Episode: 421/30000 (1.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 101.2534s / 1028.0262 s
agent0:                 episode reward: 0.1649,                 loss: nan
agent1:                 episode reward: -0.1649,                 loss: 0.1592
Episode: 441/30000 (1.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 102.4536s / 1130.4798 s
agent0:                 episode reward: 0.0541,                 loss: nan
agent1:                 episode reward: -0.0541,                 loss: 0.1565
Episode: 461/30000 (1.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 103.1436s / 1233.6234 s
agent0:                 episode reward: 0.1290,                 loss: nan
agent1:                 episode reward: -0.1290,                 loss: 0.1576
Episode: 481/30000 (1.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 110.8196s / 1344.4430 s
agent0:                 episode reward: -0.6373,                 loss: nan
agent1:                 episode reward: 0.6373,                 loss: 0.1576
Episode: 501/30000 (1.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 109.4462s / 1453.8893 s
agent0:                 episode reward: 0.1074,                 loss: nan
agent1:                 episode reward: -0.1074,                 loss: 0.1568
Episode: 521/30000 (1.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 105.2036s / 1559.0929 s
agent0:                 episode reward: 0.2977,                 loss: nan
agent1:                 episode reward: -0.2977,                 loss: 0.1570
Episode: 541/30000 (1.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 104.8636s / 1663.9565 s
agent0:                 episode reward: -0.1812,                 loss: nan
agent1:                 episode reward: 0.1812,                 loss: 0.1564
Episode: 561/30000 (1.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 108.4787s / 1772.4352 s
agent0:                 episode reward: -0.0444,                 loss: nan
agent1:                 episode reward: 0.0444,                 loss: 0.1744
Episode: 581/30000 (1.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 106.3418s / 1878.7769 s
agent0:                 episode reward: 0.0398,                 loss: nan
agent1:                 episode reward: -0.0398,                 loss: 0.1664
Episode: 601/30000 (2.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 108.6952s / 1987.4722 s
agent0:                 episode reward: 0.1533,                 loss: nan
agent1:                 episode reward: -0.1533,                 loss: 0.1629
Episode: 621/30000 (2.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 109.5471s / 2097.0193 s
agent0:                 episode reward: -0.2068,                 loss: nan
agent1:                 episode reward: 0.2068,                 loss: 0.1612
Episode: 641/30000 (2.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 108.6502s / 2205.6695 s
agent0:                 episode reward: 0.2120,                 loss: nan
agent1:                 episode reward: -0.2120,                 loss: 0.1598
Episode: 661/30000 (2.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 107.6494s / 2313.3189 s
agent0:                 episode reward: 0.0961,                 loss: nan
agent1:                 episode reward: -0.0961,                 loss: 0.1606
Episode: 681/30000 (2.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 108.2091s / 2421.5279 s
agent0:                 episode reward: 0.3292,                 loss: nan
agent1:                 episode reward: -0.3292,                 loss: 0.1606
Episode: 701/30000 (2.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 109.9387s / 2531.4666 s
agent0:                 episode reward: 0.1833,                 loss: nan
agent1:                 episode reward: -0.1833,                 loss: 0.1599
Episode: 721/30000 (2.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 107.8275s / 2639.2941 s
agent0:                 episode reward: 0.0680,                 loss: nan
agent1:                 episode reward: -0.0680,                 loss: 0.1603
Episode: 741/30000 (2.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.1863s / 2772.4804 s
agent0:                 episode reward: -0.3686,                 loss: nan
agent1:                 episode reward: 0.3686,                 loss: 0.1595
Episode: 761/30000 (2.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 236.4125s / 3008.8930 s
agent0:                 episode reward: 0.2993,                 loss: nan
agent1:                 episode reward: -0.2993,                 loss: 0.1580
Episode: 781/30000 (2.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.4330s / 3252.3260 s
agent0:                 episode reward: 0.0556,                 loss: nan
agent1:                 episode reward: -0.0556,                 loss: 0.1577
Episode: 801/30000 (2.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 235.3822s / 3487.7082 s
agent0:                 episode reward: 0.1025,                 loss: nan
agent1:                 episode reward: -0.1025,                 loss: 0.1592
Episode: 821/30000 (2.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 241.4822s / 3729.1904 s
agent0:                 episode reward: -0.2027,                 loss: nan
agent1:                 episode reward: 0.2027,                 loss: 0.1586
Episode: 841/30000 (2.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.1069s / 3975.2973 s
agent0:                 episode reward: -0.0093,                 loss: nan
agent1:                 episode reward: 0.0093,                 loss: 0.1588
Episode: 861/30000 (2.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 240.6082s / 4215.9055 s
agent0:                 episode reward: 0.2601,                 loss: nan
agent1:                 episode reward: -0.2601,                 loss: 0.1575
Episode: 881/30000 (2.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 239.0627s / 4454.9683 s
agent0:                 episode reward: 0.3590,                 loss: nan
agent1:                 episode reward: -0.3590,                 loss: 0.1592
Episode: 901/30000 (3.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 238.5692s / 4693.5375 s
agent0:                 episode reward: -0.1778,                 loss: nan
agent1:                 episode reward: 0.1778,                 loss: 0.1616
Episode: 921/30000 (3.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.8981s / 4939.4356 s
agent0:                 episode reward: 0.0474,                 loss: nan
agent1:                 episode reward: -0.0474,                 loss: 0.1590
Episode: 941/30000 (3.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 235.0386s / 5174.4742 s
agent0:                 episode reward: -0.2986,                 loss: nan
agent1:                 episode reward: 0.2986,                 loss: 0.1598
Episode: 961/30000 (3.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.6703s / 5419.1445 s
agent0:                 episode reward: -0.5917,                 loss: nan
agent1:                 episode reward: 0.5917,                 loss: 0.1595
Episode: 981/30000 (3.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 233.3643s / 5652.5088 s
agent0:                 episode reward: -0.1548,                 loss: nan
agent1:                 episode reward: 0.1548,                 loss: 0.1598
Episode: 1001/30000 (3.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.3841s / 5901.8929 s
agent0:                 episode reward: 0.3084,                 loss: nan
agent1:                 episode reward: -0.3084,                 loss: 0.1600
Episode: 1021/30000 (3.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 239.4885s / 6141.3814 s
agent0:                 episode reward: -0.0595,                 loss: nan
agent1:                 episode reward: 0.0595,                 loss: 0.1582
Episode: 1041/30000 (3.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 236.3274s / 6377.7088 s
agent0:                 episode reward: -0.3168,                 loss: nan
agent1:                 episode reward: 0.3168,                 loss: 0.1593
Episode: 1061/30000 (3.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.9899s / 6628.6987 s
agent0:                 episode reward: -0.2006,                 loss: nan
agent1:                 episode reward: 0.2006,                 loss: 0.1592
Episode: 1081/30000 (3.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.8345s / 6872.5332 s
agent0:                 episode reward: 0.5148,                 loss: nan
agent1:                 episode reward: -0.5148,                 loss: 0.1582
Episode: 1101/30000 (3.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 237.9767s / 7110.5099 s
agent0:                 episode reward: 0.1668,                 loss: nan
agent1:                 episode reward: -0.1668,                 loss: 0.1594
Episode: 1121/30000 (3.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.2862s / 7360.7961 s
agent0:                 episode reward: -0.0329,                 loss: nan
agent1:                 episode reward: 0.0329,                 loss: 0.1588
Episode: 1141/30000 (3.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 232.3455s / 7593.1416 s
agent0:                 episode reward: -0.0679,                 loss: nan
agent1:                 episode reward: 0.0679,                 loss: 0.1583
Episode: 1161/30000 (3.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.1988s / 7835.3404 s
agent0:                 episode reward: 0.1869,                 loss: nan
agent1:                 episode reward: -0.1869,                 loss: 0.1594
Episode: 1181/30000 (3.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.8037s / 8079.1440 s
agent0:                 episode reward: -0.0463,                 loss: nan
agent1:                 episode reward: 0.0463,                 loss: 0.1588
Episode: 1201/30000 (4.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.6349s / 8323.7790 s
agent0:                 episode reward: -0.1119,                 loss: nan
agent1:                 episode reward: 0.1119,                 loss: 0.1609
Episode: 1221/30000 (4.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 240.8502s / 8564.6292 s
agent0:                 episode reward: 0.3157,                 loss: nan
agent1:                 episode reward: -0.3157,                 loss: 0.1592
Episode: 1241/30000 (4.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 238.7593s / 8803.3884 s
agent0:                 episode reward: 0.1453,                 loss: nan
agent1:                 episode reward: -0.1453,                 loss: 0.1562
Episode: 1261/30000 (4.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.1274s / 9053.5158 s
agent0:                 episode reward: -0.0670,                 loss: nan
agent1:                 episode reward: 0.0670,                 loss: 0.1572
Episode: 1281/30000 (4.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 240.8252s / 9294.3410 s
agent0:                 episode reward: 0.0174,                 loss: nan
agent1:                 episode reward: -0.0174,                 loss: 0.1564
Episode: 1301/30000 (4.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 238.0388s / 9532.3799 s
agent0:                 episode reward: -0.2504,                 loss: nan
agent1:                 episode reward: 0.2504,                 loss: 0.1560
Episode: 1321/30000 (4.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 238.1118s / 9770.4917 s
agent0:                 episode reward: -0.4460,                 loss: nan
agent1:                 episode reward: 0.4460,                 loss: 0.1569
Episode: 1341/30000 (4.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.2645s / 10014.7561 s
agent0:                 episode reward: 0.0141,                 loss: nan
agent1:                 episode reward: -0.0141,                 loss: 0.1564
Episode: 1361/30000 (4.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 240.4306s / 10255.1867 s
agent0:                 episode reward: 0.1639,                 loss: nan
agent1:                 episode reward: -0.1639,                 loss: 0.1549
Episode: 1381/30000 (4.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 238.8411s / 10494.0278 s
agent0:                 episode reward: -0.2072,                 loss: nan
agent1:                 episode reward: 0.2072,                 loss: 0.1545
Episode: 1401/30000 (4.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.3568s / 10740.3846 s
agent0:                 episode reward: -0.0465,                 loss: nan
agent1:                 episode reward: 0.0465,                 loss: 0.1549
Episode: 1421/30000 (4.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 241.9093s / 10982.2938 s
agent0:                 episode reward: -0.1861,                 loss: nan
agent1:                 episode reward: 0.1861,                 loss: 0.1557
Episode: 1441/30000 (4.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.5830s / 11223.8769 s
agent0:                 episode reward: -0.1405,                 loss: nan
agent1:                 episode reward: 0.1405,                 loss: 0.1542
Episode: 1461/30000 (4.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.9067s / 11467.7835 s
agent0:                 episode reward: 0.1482,                 loss: nan
agent1:                 episode reward: -0.1482,                 loss: 0.1541
Episode: 1481/30000 (4.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.6055s / 11710.3890 s
agent0:                 episode reward: -0.2303,                 loss: nan
agent1:                 episode reward: 0.2303,                 loss: 0.1539
Episode: 1501/30000 (5.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.7455s / 11961.1346 s
agent0:                 episode reward: -0.2061,                 loss: nan
agent1:                 episode reward: 0.2061,                 loss: 0.1552
Episode: 1521/30000 (5.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 238.7532s / 12199.8878 s
agent0:                 episode reward: 0.3883,                 loss: nan
agent1:                 episode reward: -0.3883,                 loss: 0.1541
Episode: 1541/30000 (5.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.8238s / 12448.7116 s
agent0:                 episode reward: -0.3304,                 loss: nan
agent1:                 episode reward: 0.3304,                 loss: 0.1554
Episode: 1561/30000 (5.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.2188s / 12692.9304 s
agent0:                 episode reward: -0.1356,                 loss: nan
agent1:                 episode reward: 0.1356,                 loss: 0.1584
Episode: 1581/30000 (5.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 240.4353s / 12933.3657 s
agent0:                 episode reward: -0.4278,                 loss: nan
agent1:                 episode reward: 0.4278,                 loss: 0.1592
Episode: 1601/30000 (5.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 238.9616s / 13172.3273 s
agent0:                 episode reward: -0.0266,                 loss: nan
agent1:                 episode reward: 0.0266,                 loss: 0.1620
Episode: 1621/30000 (5.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.3421s / 13421.6694 s
agent0:                 episode reward: 0.1569,                 loss: nan
agent1:                 episode reward: -0.1569,                 loss: 0.1612
Episode: 1641/30000 (5.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 235.1374s / 13656.8068 s
agent0:                 episode reward: 0.1974,                 loss: nan
agent1:                 episode reward: -0.1974,                 loss: 0.1611
Episode: 1661/30000 (5.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 236.3284s / 13893.1352 s
agent0:                 episode reward: 0.0682,                 loss: nan
agent1:                 episode reward: -0.0682,                 loss: 0.1620
Episode: 1681/30000 (5.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.6391s / 14134.7743 s
agent0:                 episode reward: -0.0796,                 loss: nan
agent1:                 episode reward: 0.0796,                 loss: 0.1606
Episode: 1701/30000 (5.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.1141s / 14381.8884 s
agent0:                 episode reward: 0.1180,                 loss: nan
agent1:                 episode reward: -0.1180,                 loss: 0.1610
Episode: 1721/30000 (5.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 241.9209s / 14623.8092 s
agent0:                 episode reward: -0.4081,                 loss: nan
agent1:                 episode reward: 0.4081,                 loss: 0.1615
Episode: 1741/30000 (5.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 236.5628s / 14860.3720 s
agent0:                 episode reward: 0.2287,                 loss: nan
agent1:                 episode reward: -0.2287,                 loss: 0.1604
Episode: 1761/30000 (5.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 236.2075s / 15096.5795 s
agent0:                 episode reward: -0.3086,                 loss: nan
agent1:                 episode reward: 0.3086,                 loss: 0.1595
Episode: 1781/30000 (5.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.6902s / 15346.2697 s
agent0:                 episode reward: 0.1473,                 loss: nan
agent1:                 episode reward: -0.1473,                 loss: 0.1606
Episode: 1801/30000 (6.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 240.9662s / 15587.2359 s
agent0:                 episode reward: -0.2892,                 loss: nan
agent1:                 episode reward: 0.2892,                 loss: 0.1615
Episode: 1821/30000 (6.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 238.8789s / 15826.1148 s
agent0:                 episode reward: 0.2177,                 loss: nan
agent1:                 episode reward: -0.2177,                 loss: 0.1618
Episode: 1841/30000 (6.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.2014s / 16068.3162 s
agent0:                 episode reward: 0.1278,                 loss: nan
agent1:                 episode reward: -0.1278,                 loss: 0.1611
Episode: 1861/30000 (6.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.6029s / 16312.9191 s
agent0:                 episode reward: -0.1604,                 loss: nan
agent1:                 episode reward: 0.1604,                 loss: 0.1613
Episode: 1881/30000 (6.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.9032s / 16559.8223 s
agent0:                 episode reward: -0.2794,                 loss: nan
agent1:                 episode reward: 0.2794,                 loss: 0.1607
Episode: 1901/30000 (6.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.9731s / 16807.7954 s
agent0:                 episode reward: -0.1289,                 loss: nan
agent1:                 episode reward: 0.1289,                 loss: 0.1583
Episode: 1921/30000 (6.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.5372s / 17055.3326 s
agent0:                 episode reward: -0.0981,                 loss: nan
agent1:                 episode reward: 0.0981,                 loss: 0.1590
Episode: 1941/30000 (6.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.0721s / 17297.4047 s
agent0:                 episode reward: -0.3968,                 loss: nan
agent1:                 episode reward: 0.3968,                 loss: 0.1567
Episode: 1961/30000 (6.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 235.5398s / 17532.9445 s
agent0:                 episode reward: 0.0798,                 loss: nan
agent1:                 episode reward: -0.0798,                 loss: 0.1584
Episode: 1981/30000 (6.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.5137s / 17776.4582 s
agent0:                 episode reward: 0.1652,                 loss: nan
agent1:                 episode reward: -0.1652,                 loss: 0.1580
Episode: 2001/30000 (6.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.9316s / 18022.3898 s
agent0:                 episode reward: 0.4585,                 loss: nan
agent1:                 episode reward: -0.4585,                 loss: 0.1578
Episode: 2021/30000 (6.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.6416s / 18268.0314 s
agent0:                 episode reward: 0.4220,                 loss: nan
agent1:                 episode reward: -0.4220,                 loss: 0.1579
Episode: 2041/30000 (6.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 239.9216s / 18507.9530 s
agent0:                 episode reward: -0.1820,                 loss: nan
agent1:                 episode reward: 0.1820,                 loss: 0.1579
Episode: 2061/30000 (6.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 238.1522s / 18746.1052 s
agent0:                 episode reward: 0.4469,                 loss: nan
agent1:                 episode reward: -0.4469,                 loss: 0.1567
Episode: 2081/30000 (6.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.9030s / 18993.0082 s
agent0:                 episode reward: 0.0760,                 loss: nan
agent1:                 episode reward: -0.0760,                 loss: 0.1593
Episode: 2101/30000 (7.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.8312s / 19238.8394 s
agent0:                 episode reward: 0.1271,                 loss: nan
agent1:                 episode reward: -0.1271,                 loss: 0.1582
Episode: 2121/30000 (7.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.4405s / 19489.2799 s
agent0:                 episode reward: 0.4218,                 loss: nan
agent1:                 episode reward: -0.4218,                 loss: 0.1585
Episode: 2141/30000 (7.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 240.7823s / 19730.0622 s
agent0:                 episode reward: -0.3831,                 loss: nan
agent1:                 episode reward: 0.3831,                 loss: 0.1602
Episode: 2161/30000 (7.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.6737s / 19974.7359 s
agent0:                 episode reward: -0.0621,                 loss: nan
agent1:                 episode reward: 0.0621,                 loss: 0.1595
Episode: 2181/30000 (7.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.6038s / 20225.3396 s
agent0:                 episode reward: 0.0868,                 loss: nan
agent1:                 episode reward: -0.0868,                 loss: 0.1586
Episode: 2201/30000 (7.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.5083s / 20468.8479 s
agent0:                 episode reward: -0.1418,                 loss: nan
agent1:                 episode reward: 0.1418,                 loss: 0.1583
Episode: 2221/30000 (7.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 236.7703s / 20705.6182 s
agent0:                 episode reward: 0.3120,                 loss: nan
agent1:                 episode reward: -0.3120,                 loss: 0.1571
Episode: 2241/30000 (7.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.8001s / 20954.4183 s
agent0:                 episode reward: -0.2660,                 loss: nan
agent1:                 episode reward: 0.2660,                 loss: 0.1553
Episode: 2261/30000 (7.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 238.9467s / 21193.3650 s
agent0:                 episode reward: 0.0994,                 loss: nan
agent1:                 episode reward: -0.0994,                 loss: 0.1568
Episode: 2281/30000 (7.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.1176s / 21441.4826 s
agent0:                 episode reward: -0.2677,                 loss: nan
agent1:                 episode reward: 0.2677,                 loss: 0.1557
Episode: 2301/30000 (7.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 237.8093s / 21679.2919 s
agent0:                 episode reward: 0.0212,                 loss: nan
agent1:                 episode reward: -0.0212,                 loss: 0.1553
Episode: 2321/30000 (7.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 235.7834s / 21915.0753 s
agent0:                 episode reward: -0.0170,                 loss: nan
agent1:                 episode reward: 0.0170,                 loss: 0.1547
Episode: 2341/30000 (7.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.0426s / 22158.1180 s
agent0:                 episode reward: -0.2633,                 loss: nan
agent1:                 episode reward: 0.2633,                 loss: 0.1542
Episode: 2361/30000 (7.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.6992s / 22401.8171 s
agent0:                 episode reward: -0.0677,                 loss: nan
agent1:                 episode reward: 0.0677,                 loss: 0.1544
Episode: 2381/30000 (7.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.1991s / 22646.0162 s
agent0:                 episode reward: -0.3733,                 loss: nan
agent1:                 episode reward: 0.3733,                 loss: 0.1544
Episode: 2401/30000 (8.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 239.0506s / 22885.0668 s
agent0:                 episode reward: -0.2214,                 loss: nan
agent1:                 episode reward: 0.2214,                 loss: 0.1539
Episode: 2421/30000 (8.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.7106s / 23127.7773 s
agent0:                 episode reward: 0.1283,                 loss: nan
agent1:                 episode reward: -0.1283,                 loss: 0.1543
Episode: 2441/30000 (8.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 240.3233s / 23368.1006 s
agent0:                 episode reward: -0.1580,                 loss: nan
agent1:                 episode reward: 0.1580,                 loss: 0.1542
Episode: 2461/30000 (8.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.2540s / 23619.3546 s
agent0:                 episode reward: 0.2919,                 loss: nan
agent1:                 episode reward: -0.2919,                 loss: 0.1536
Episode: 2481/30000 (8.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.1847s / 23863.5393 s
agent0:                 episode reward: -0.5126,                 loss: nan
agent1:                 episode reward: 0.5126,                 loss: 0.1547
Episode: 2501/30000 (8.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.0362s / 24111.5755 s
agent0:                 episode reward: 0.2546,                 loss: nan
agent1:                 episode reward: -0.2546,                 loss: 0.1548
Episode: 2521/30000 (8.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.9875s / 24353.5630 s
agent0:                 episode reward: 0.2083,                 loss: nan
agent1:                 episode reward: -0.2083,                 loss: 0.1551
Episode: 2541/30000 (8.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 237.4365s / 24590.9995 s
agent0:                 episode reward: -0.1191,                 loss: nan
agent1:                 episode reward: 0.1191,                 loss: 0.1547
Episode: 2561/30000 (8.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.3848s / 24833.3843 s
agent0:                 episode reward: 0.1308,                 loss: nan
agent1:                 episode reward: -0.1308,                 loss: 0.1547
Episode: 2581/30000 (8.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 236.5988s / 25069.9832 s
agent0:                 episode reward: -0.2630,                 loss: nan
agent1:                 episode reward: 0.2630,                 loss: 0.1564
Episode: 2601/30000 (8.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.5928s / 25320.5759 s
agent0:                 episode reward: 0.1258,                 loss: nan
agent1:                 episode reward: -0.1258,                 loss: 0.1548
Episode: 2621/30000 (8.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.2883s / 25562.8642 s
agent0:                 episode reward: 0.1555,                 loss: nan
agent1:                 episode reward: -0.1555,                 loss: 0.1539
Episode: 2641/30000 (8.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.4573s / 25813.3215 s
agent0:                 episode reward: -0.0633,                 loss: nan
agent1:                 episode reward: 0.0633,                 loss: 0.1549
Episode: 2661/30000 (8.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.2986s / 26058.6201 s
agent0:                 episode reward: -0.0083,                 loss: nan
agent1:                 episode reward: 0.0083,                 loss: 0.1547
Episode: 2681/30000 (8.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.7857s / 26303.4058 s
agent0:                 episode reward: -0.1701,                 loss: nan
agent1:                 episode reward: 0.1701,                 loss: 0.1555
Episode: 2701/30000 (9.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.0318s / 26554.4376 s
agent0:                 episode reward: -0.3031,                 loss: nan
agent1:                 episode reward: 0.3031,                 loss: 0.1545
Episode: 2721/30000 (9.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 235.6880s / 26790.1256 s
agent0:                 episode reward: -0.1407,                 loss: nan
agent1:                 episode reward: 0.1407,                 loss: 0.1525
Episode: 2741/30000 (9.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.2509s / 27039.3766 s
agent0:                 episode reward: -0.0885,                 loss: nan
agent1:                 episode reward: 0.0885,                 loss: 0.1555
Episode: 2761/30000 (9.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.4003s / 27282.7769 s
agent0:                 episode reward: -0.1115,                 loss: nan
agent1:                 episode reward: 0.1115,                 loss: 0.1544
Episode: 2781/30000 (9.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.3697s / 27528.1466 s
agent0:                 episode reward: -0.0897,                 loss: nan
agent1:                 episode reward: 0.0897,                 loss: 0.1540
Episode: 2801/30000 (9.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.8621s / 27775.0086 s
agent0:                 episode reward: -0.1098,                 loss: nan
agent1:                 episode reward: 0.1098,                 loss: 0.1540
Episode: 2821/30000 (9.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 235.4085s / 28010.4171 s
agent0:                 episode reward: -0.2698,                 loss: nan
agent1:                 episode reward: 0.2698,                 loss: 0.1535
Episode: 2841/30000 (9.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.5377s / 28254.9549 s
agent0:                 episode reward: -0.1230,                 loss: nan
agent1:                 episode reward: 0.1230,                 loss: 0.1536
Episode: 2861/30000 (9.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 239.2866s / 28494.2415 s
agent0:                 episode reward: -0.3634,                 loss: nan
agent1:                 episode reward: 0.3634,                 loss: 0.1544
Episode: 2881/30000 (9.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.9438s / 28739.1853 s
agent0:                 episode reward: 0.3945,                 loss: nan
agent1:                 episode reward: -0.3945,                 loss: 0.1531
Episode: 2901/30000 (9.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.4675s / 28986.6528 s
agent0:                 episode reward: -0.0659,                 loss: nan
agent1:                 episode reward: 0.0659,                 loss: 0.1532
Episode: 2921/30000 (9.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.0400s / 29234.6928 s
agent0:                 episode reward: 0.2186,                 loss: nan
agent1:                 episode reward: -0.2186,                 loss: 0.1530
Episode: 2941/30000 (9.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 229.2444s / 29463.9372 s
agent0:                 episode reward: -0.2269,                 loss: nan
agent1:                 episode reward: 0.2269,                 loss: 0.1532
Episode: 2961/30000 (9.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.8924s / 29713.8296 s
agent0:                 episode reward: 0.0233,                 loss: nan
agent1:                 episode reward: -0.0233,                 loss: 0.1537
Episode: 2981/30000 (9.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.7827s / 29958.6123 s
agent0:                 episode reward: 0.2693,                 loss: nan
agent1:                 episode reward: -0.2693,                 loss: 0.1529
Episode: 3001/30000 (10.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.2970s / 30202.9093 s
agent0:                 episode reward: 0.3578,                 loss: nan
agent1:                 episode reward: -0.3578,                 loss: 0.1544
Episode: 3021/30000 (10.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.4912s / 30446.4006 s
agent0:                 episode reward: 0.5444,                 loss: nan
agent1:                 episode reward: -0.5444,                 loss: 0.1539
Episode: 3041/30000 (10.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.9191s / 30692.3196 s
agent0:                 episode reward: 0.0377,                 loss: nan
agent1:                 episode reward: -0.0377,                 loss: 0.1544
Episode: 3061/30000 (10.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 235.8172s / 30928.1369 s
agent0:                 episode reward: -0.0475,                 loss: nan
agent1:                 episode reward: 0.0475,                 loss: 0.1550
Episode: 3081/30000 (10.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.9856s / 31174.1225 s
agent0:                 episode reward: -0.2251,                 loss: nan
agent1:                 episode reward: 0.2251,                 loss: 0.1544
Episode: 3101/30000 (10.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 241.7267s / 31415.8491 s
agent0:                 episode reward: -0.0144,                 loss: nan
agent1:                 episode reward: 0.0144,                 loss: 0.1521
Episode: 3121/30000 (10.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 240.9033s / 31656.7525 s
agent0:                 episode reward: 0.2846,                 loss: nan
agent1:                 episode reward: -0.2846,                 loss: 0.1532
Episode: 3141/30000 (10.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.9211s / 31909.6736 s
agent0:                 episode reward: -0.2845,                 loss: nan
agent1:                 episode reward: 0.2845,                 loss: 0.1523
Episode: 3161/30000 (10.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.0750s / 32156.7485 s
agent0:                 episode reward: 0.0191,                 loss: nan
agent1:                 episode reward: -0.0191,                 loss: 0.1537
Episode: 3181/30000 (10.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.6726s / 32405.4211 s
agent0:                 episode reward: -0.5873,                 loss: nan
agent1:                 episode reward: 0.5873,                 loss: 0.1530
Episode: 3201/30000 (10.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 234.3791s / 32639.8002 s
agent0:                 episode reward: -0.1123,                 loss: nan
agent1:                 episode reward: 0.1123,                 loss: 0.1544
Episode: 3221/30000 (10.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.6808s / 32889.4810 s
agent0:                 episode reward: 0.0230,                 loss: nan
agent1:                 episode reward: -0.0230,                 loss: 0.1547
Episode: 3241/30000 (10.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 239.6952s / 33129.1762 s
agent0:                 episode reward: -0.2474,                 loss: nan
agent1:                 episode reward: 0.2474,                 loss: 0.1573
Episode: 3261/30000 (10.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.5240s / 33378.7002 s
agent0:                 episode reward: 0.1185,                 loss: nan
agent1:                 episode reward: -0.1185,                 loss: 0.1551
Episode: 3281/30000 (10.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.4615s / 33624.1616 s
agent0:                 episode reward: -0.2267,                 loss: nan
agent1:                 episode reward: 0.2267,                 loss: 0.1544
Episode: 3301/30000 (11.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.2514s / 33867.4130 s
agent0:                 episode reward: -0.2387,                 loss: nan
agent1:                 episode reward: 0.2387,                 loss: 0.1561
Episode: 3321/30000 (11.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.4982s / 34111.9111 s
agent0:                 episode reward: 0.0901,                 loss: nan
agent1:                 episode reward: -0.0901,                 loss: 0.1572
Episode: 3341/30000 (11.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 240.7789s / 34352.6901 s
agent0:                 episode reward: -0.1078,                 loss: nan
agent1:                 episode reward: 0.1078,                 loss: 0.1559
Episode: 3361/30000 (11.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.1633s / 34596.8534 s
agent0:                 episode reward: 0.1252,                 loss: nan
agent1:                 episode reward: -0.1252,                 loss: 0.1569
Episode: 3381/30000 (11.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 239.6300s / 34836.4833 s
agent0:                 episode reward: -0.2399,                 loss: nan
agent1:                 episode reward: 0.2399,                 loss: 0.1550
Episode: 3401/30000 (11.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.2454s / 35084.7288 s
agent0:                 episode reward: -0.2701,                 loss: nan
agent1:                 episode reward: 0.2701,                 loss: 0.1547
Episode: 3421/30000 (11.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 234.4365s / 35319.1653 s
agent0:                 episode reward: 0.0137,                 loss: nan
agent1:                 episode reward: -0.0137,                 loss: 0.1571
Episode: 3441/30000 (11.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.1877s / 35564.3529 s
agent0:                 episode reward: -0.1615,                 loss: nan
agent1:                 episode reward: 0.1615,                 loss: 0.1561
Episode: 3461/30000 (11.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.7414s / 35815.0944 s
agent0:                 episode reward: -0.1535,                 loss: nan
agent1:                 episode reward: 0.1535,                 loss: 0.1567
Episode: 3481/30000 (11.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.0106s / 36062.1049 s
agent0:                 episode reward: 0.0747,                 loss: nan
agent1:                 episode reward: -0.0747,                 loss: 0.1568
Episode: 3501/30000 (11.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 256.1248s / 36318.2297 s
agent0:                 episode reward: -0.0789,                 loss: nan
agent1:                 episode reward: 0.0789,                 loss: 0.1569
Episode: 3521/30000 (11.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.2167s / 36569.4464 s
agent0:                 episode reward: 0.0813,                 loss: nan
agent1:                 episode reward: -0.0813,                 loss: 0.1561
Episode: 3541/30000 (11.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.4622s / 36816.9086 s
agent0:                 episode reward: -0.1241,                 loss: nan
agent1:                 episode reward: 0.1241,                 loss: 0.1553
Episode: 3561/30000 (11.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.9171s / 37060.8257 s
agent0:                 episode reward: 0.0788,                 loss: nan
agent1:                 episode reward: -0.0788,                 loss: 0.1584
Episode: 3581/30000 (11.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 254.7779s / 37315.6036 s
agent0:                 episode reward: -0.2129,                 loss: nan
agent1:                 episode reward: 0.2129,                 loss: 0.1574
Episode: 3601/30000 (12.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.1798s / 37556.7833 s
agent0:                 episode reward: 0.0277,                 loss: nan
agent1:                 episode reward: -0.0277,                 loss: 0.1568
Episode: 3621/30000 (12.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 255.0065s / 37811.7898 s
agent0:                 episode reward: -0.5239,                 loss: nan
agent1:                 episode reward: 0.5239,                 loss: 0.1564
Episode: 3641/30000 (12.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 236.5864s / 38048.3762 s
agent0:                 episode reward: -0.1967,                 loss: nan
agent1:                 episode reward: 0.1967,                 loss: 0.1549
Episode: 3661/30000 (12.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 235.2469s / 38283.6231 s
agent0:                 episode reward: -0.0894,                 loss: nan
agent1:                 episode reward: 0.0894,                 loss: 0.1540
Episode: 3681/30000 (12.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.2596s / 38534.8828 s
agent0:                 episode reward: -0.1000,                 loss: nan
agent1:                 episode reward: 0.1000,                 loss: 0.1566
Episode: 3701/30000 (12.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 235.6795s / 38770.5623 s
agent0:                 episode reward: -0.0218,                 loss: nan
agent1:                 episode reward: 0.0218,                 loss: 0.1555
Episode: 3721/30000 (12.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.8414s / 39016.4036 s
agent0:                 episode reward: -0.2266,                 loss: nan
agent1:                 episode reward: 0.2266,                 loss: 0.1554
Episode: 3741/30000 (12.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.9777s / 39262.3813 s
agent0:                 episode reward: 0.3928,                 loss: nan
agent1:                 episode reward: -0.3928,                 loss: 0.1554
Episode: 3761/30000 (12.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.7036s / 39513.0849 s
agent0:                 episode reward: 0.1666,                 loss: nan
agent1:                 episode reward: -0.1666,                 loss: 0.1559
Episode: 3781/30000 (12.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 234.5371s / 39747.6221 s
agent0:                 episode reward: 0.2006,                 loss: nan
agent1:                 episode reward: -0.2006,                 loss: 0.1558
Episode: 3801/30000 (12.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.2437s / 39993.8658 s
agent0:                 episode reward: -0.1111,                 loss: nan
agent1:                 episode reward: 0.1111,                 loss: 0.1565
Episode: 3821/30000 (12.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.8554s / 40243.7212 s
agent0:                 episode reward: -0.3205,                 loss: nan
agent1:                 episode reward: 0.3205,                 loss: 0.1537
Episode: 3841/30000 (12.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.0605s / 40488.7817 s
agent0:                 episode reward: 0.2244,                 loss: nan
agent1:                 episode reward: -0.2244,                 loss: 0.1557
Episode: 3861/30000 (12.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.7832s / 40734.5649 s
agent0:                 episode reward: 0.2899,                 loss: nan
agent1:                 episode reward: -0.2899,                 loss: 0.1556
Episode: 3881/30000 (12.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 240.4389s / 40975.0038 s
agent0:                 episode reward: 0.1437,                 loss: nan
agent1:                 episode reward: -0.1437,                 loss: 0.1564
Episode: 3901/30000 (13.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.0882s / 41222.0919 s
agent0:                 episode reward: -0.4737,                 loss: nan
agent1:                 episode reward: 0.4737,                 loss: 0.1536
Episode: 3921/30000 (13.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.6901s / 41467.7820 s
agent0:                 episode reward: 0.0482,                 loss: nan
agent1:                 episode reward: -0.0482,                 loss: 0.1548
Episode: 3941/30000 (13.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.6104s / 41711.3925 s
agent0:                 episode reward: -0.0797,                 loss: nan
agent1:                 episode reward: 0.0797,                 loss: 0.1531
Episode: 3961/30000 (13.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.5410s / 41962.9335 s
agent0:                 episode reward: 0.0521,                 loss: nan
agent1:                 episode reward: -0.0521,                 loss: 0.1536
Episode: 3981/30000 (13.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.4675s / 42215.4010 s
agent0:                 episode reward: -0.2118,                 loss: nan
agent1:                 episode reward: 0.2118,                 loss: 0.1543
Episode: 4001/30000 (13.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.7845s / 42462.1855 s
agent0:                 episode reward: 0.2320,                 loss: nan
agent1:                 episode reward: -0.2320,                 loss: 0.1541
Episode: 4021/30000 (13.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 239.6623s / 42701.8477 s
agent0:                 episode reward: -0.5724,                 loss: nan
agent1:                 episode reward: 0.5724,                 loss: 0.1530
Episode: 4041/30000 (13.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 254.8236s / 42956.6713 s
agent0:                 episode reward: -0.2668,                 loss: nan
agent1:                 episode reward: 0.2668,                 loss: 0.1534
Episode: 4061/30000 (13.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 254.9329s / 43211.6042 s
agent0:                 episode reward: -0.1918,                 loss: nan
agent1:                 episode reward: 0.1918,                 loss: 0.1550
Episode: 4081/30000 (13.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.8574s / 43461.4616 s
agent0:                 episode reward: -0.2990,                 loss: nan
agent1:                 episode reward: 0.2990,                 loss: 0.1534
Episode: 4101/30000 (13.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.5339s / 43713.9955 s
agent0:                 episode reward: -0.2074,                 loss: nan
agent1:                 episode reward: 0.2074,                 loss: 0.1554
Episode: 4121/30000 (13.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 234.9341s / 43948.9297 s
agent0:                 episode reward: -0.2467,                 loss: nan
agent1:                 episode reward: 0.2467,                 loss: 0.1543
Episode: 4141/30000 (13.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.5042s / 44194.4338 s
agent0:                 episode reward: -0.3428,                 loss: nan
agent1:                 episode reward: 0.3428,                 loss: 0.1554
Episode: 4161/30000 (13.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 239.1595s / 44433.5933 s
agent0:                 episode reward: -0.2326,                 loss: nan
agent1:                 episode reward: 0.2326,                 loss: 0.1539
Episode: 4181/30000 (13.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 254.6164s / 44688.2097 s
agent0:                 episode reward: -0.2431,                 loss: nan
agent1:                 episode reward: 0.2431,                 loss: 0.1541
Episode: 4201/30000 (14.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 240.7763s / 44928.9860 s
agent0:                 episode reward: -0.1200,                 loss: nan
agent1:                 episode reward: 0.1200,                 loss: 0.1543
Episode: 4221/30000 (14.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 239.4486s / 45168.4346 s
agent0:                 episode reward: 0.1131,                 loss: nan
agent1:                 episode reward: -0.1131,                 loss: 0.1552
Episode: 4241/30000 (14.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.6822s / 45413.1168 s
agent0:                 episode reward: -0.0429,                 loss: nan
agent1:                 episode reward: 0.0429,                 loss: 0.1573
Episode: 4261/30000 (14.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 254.5675s / 45667.6843 s
agent0:                 episode reward: 0.1942,                 loss: nan
agent1:                 episode reward: -0.1942,                 loss: 0.1570
Episode: 4281/30000 (14.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.6609s / 45912.3451 s
agent0:                 episode reward: -0.2378,                 loss: nan
agent1:                 episode reward: 0.2378,                 loss: 0.1567
Episode: 4301/30000 (14.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.5611s / 46160.9063 s
agent0:                 episode reward: -0.1588,                 loss: nan
agent1:                 episode reward: 0.1588,                 loss: 0.1561
Episode: 4321/30000 (14.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 238.6977s / 46399.6039 s
agent0:                 episode reward: 0.1514,                 loss: nan
agent1:                 episode reward: -0.1514,                 loss: 0.1554
Episode: 4341/30000 (14.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 235.9321s / 46635.5361 s
agent0:                 episode reward: 0.3038,                 loss: nan
agent1:                 episode reward: -0.3038,                 loss: 0.1565
Episode: 4361/30000 (14.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.8008s / 46886.3368 s
agent0:                 episode reward: -0.3645,                 loss: nan
agent1:                 episode reward: 0.3645,                 loss: 0.1564
Episode: 4381/30000 (14.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.3256s / 47131.6624 s
agent0:                 episode reward: 0.1148,                 loss: nan
agent1:                 episode reward: -0.1148,                 loss: 0.1563
Episode: 4401/30000 (14.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 236.3157s / 47367.9781 s
agent0:                 episode reward: -0.2847,                 loss: nan
agent1:                 episode reward: 0.2847,                 loss: 0.1562
Episode: 4421/30000 (14.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.0067s / 47609.9848 s
agent0:                 episode reward: -0.3369,                 loss: nan
agent1:                 episode reward: 0.3369,                 loss: 0.1574
Episode: 4441/30000 (14.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.9522s / 47860.9370 s
agent0:                 episode reward: 0.0646,                 loss: nan
agent1:                 episode reward: -0.0646,                 loss: 0.1569
Episode: 4461/30000 (14.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.6392s / 48113.5762 s
agent0:                 episode reward: -0.3885,                 loss: nan
agent1:                 episode reward: 0.3885,                 loss: 0.1572
Episode: 4481/30000 (14.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.4648s / 48362.0410 s
agent0:                 episode reward: -0.0863,                 loss: nan
agent1:                 episode reward: 0.0863,                 loss: 0.1546
Episode: 4501/30000 (15.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.7723s / 48605.8133 s
agent0:                 episode reward: -0.3907,                 loss: nan
agent1:                 episode reward: 0.3907,                 loss: 0.1565
Episode: 4521/30000 (15.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.1989s / 48855.0122 s
agent0:                 episode reward: 0.1607,                 loss: nan
agent1:                 episode reward: -0.1607,                 loss: 0.1578
Episode: 4541/30000 (15.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.0415s / 49104.0538 s
agent0:                 episode reward: -0.1198,                 loss: nan
agent1:                 episode reward: 0.1198,                 loss: 0.1557
Episode: 4561/30000 (15.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 256.2930s / 49360.3468 s
agent0:                 episode reward: 0.3799,                 loss: nan
agent1:                 episode reward: -0.3799,                 loss: 0.1565
Episode: 4581/30000 (15.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.7250s / 49605.0717 s
agent0:                 episode reward: 0.0582,                 loss: nan
agent1:                 episode reward: -0.0582,                 loss: 0.1565
Episode: 4601/30000 (15.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.8524s / 49855.9241 s
agent0:                 episode reward: -0.2425,                 loss: nan
agent1:                 episode reward: 0.2425,                 loss: 0.1570
Episode: 4621/30000 (15.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 236.2818s / 50092.2059 s
agent0:                 episode reward: -0.1825,                 loss: nan
agent1:                 episode reward: 0.1825,                 loss: 0.1551
Episode: 4641/30000 (15.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.9200s / 50345.1259 s
agent0:                 episode reward: -0.3501,                 loss: nan
agent1:                 episode reward: 0.3501,                 loss: 0.1565
Episode: 4661/30000 (15.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 238.1520s / 50583.2779 s
agent0:                 episode reward: -0.3706,                 loss: nan
agent1:                 episode reward: 0.3706,                 loss: 0.1553
Episode: 4681/30000 (15.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.8032s / 50829.0811 s
agent0:                 episode reward: 0.3770,                 loss: nan
agent1:                 episode reward: -0.3770,                 loss: 0.1536
Episode: 4701/30000 (15.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.3506s / 51078.4317 s
agent0:                 episode reward: -0.0964,                 loss: nan
agent1:                 episode reward: 0.0964,                 loss: 0.1530
Episode: 4721/30000 (15.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 255.2727s / 51333.7044 s
agent0:                 episode reward: -0.4398,                 loss: nan
agent1:                 episode reward: 0.4398,                 loss: 0.1559
Episode: 4741/30000 (15.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.5650s / 51575.2694 s
agent0:                 episode reward: 0.2252,                 loss: nan
agent1:                 episode reward: -0.2252,                 loss: 0.1571
Episode: 4761/30000 (15.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.6388s / 51816.9083 s
agent0:                 episode reward: -0.0084,                 loss: nan
agent1:                 episode reward: 0.0084,                 loss: 0.1541
Episode: 4781/30000 (15.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.9664s / 52066.8747 s
agent0:                 episode reward: 0.0690,                 loss: nan
agent1:                 episode reward: -0.0690,                 loss: 0.1551
Episode: 4801/30000 (16.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 255.8337s / 52322.7084 s
agent0:                 episode reward: -0.4157,                 loss: nan
agent1:                 episode reward: 0.4157,                 loss: 0.1554
Episode: 4821/30000 (16.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.3241s / 52569.0325 s
agent0:                 episode reward: 0.2259,                 loss: nan
agent1:                 episode reward: -0.2259,                 loss: 0.1562
Episode: 4841/30000 (16.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.6235s / 52811.6560 s
agent0:                 episode reward: 0.2768,                 loss: nan
agent1:                 episode reward: -0.2768,                 loss: 0.1557
Episode: 4861/30000 (16.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.8375s / 53054.4935 s
agent0:                 episode reward: 0.0501,                 loss: nan
agent1:                 episode reward: -0.0501,                 loss: 0.1549
Episode: 4881/30000 (16.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.6389s / 53305.1325 s
agent0:                 episode reward: -0.4249,                 loss: nan
agent1:                 episode reward: 0.4249,                 loss: 0.1553
Episode: 4901/30000 (16.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.4218s / 53552.5543 s
agent0:                 episode reward: 0.1311,                 loss: nan
agent1:                 episode reward: -0.1311,                 loss: 0.1552
Episode: 4921/30000 (16.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.4499s / 53801.0042 s
agent0:                 episode reward: -0.7917,                 loss: nan
agent1:                 episode reward: 0.7917,                 loss: 0.1555
Episode: 4941/30000 (16.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.1741s / 54048.1783 s
agent0:                 episode reward: -0.1571,                 loss: nan
agent1:                 episode reward: 0.1571,                 loss: 0.1542
Episode: 4961/30000 (16.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.7052s / 54293.8835 s
agent0:                 episode reward: -0.1003,                 loss: nan
agent1:                 episode reward: 0.1003,                 loss: 0.1528
Episode: 4981/30000 (16.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 236.3744s / 54530.2579 s
agent0:                 episode reward: -0.1760,                 loss: nan
agent1:                 episode reward: 0.1760,                 loss: 0.1556
Episode: 5001/30000 (16.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.6142s / 54779.8722 s
agent0:                 episode reward: -0.3318,                 loss: nan
agent1:                 episode reward: 0.3318,                 loss: 0.1549
Episode: 5021/30000 (16.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.3807s / 55029.2529 s
agent0:                 episode reward: -0.3014,                 loss: nan
agent1:                 episode reward: 0.3014,                 loss: 0.1551
Episode: 5041/30000 (16.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.2599s / 55281.5128 s
agent0:                 episode reward: -0.1662,                 loss: nan
agent1:                 episode reward: 0.1662,                 loss: 0.1541
Episode: 5061/30000 (16.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.3657s / 55525.8786 s
agent0:                 episode reward: -0.2363,                 loss: nan
agent1:                 episode reward: 0.2363,                 loss: 0.1517
Episode: 5081/30000 (16.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 239.7097s / 55765.5882 s
agent0:                 episode reward: -0.2594,                 loss: nan
agent1:                 episode reward: 0.2594,                 loss: 0.1556
Episode: 5101/30000 (17.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.5040s / 56015.0922 s
agent0:                 episode reward: -0.3365,                 loss: nan
agent1:                 episode reward: 0.3365,                 loss: 0.1546
Episode: 5121/30000 (17.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 239.0007s / 56254.0929 s
agent0:                 episode reward: -0.2163,                 loss: nan
agent1:                 episode reward: 0.2163,                 loss: 0.1538
Episode: 5141/30000 (17.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.7972s / 56503.8902 s
agent0:                 episode reward: -0.0699,                 loss: nan
agent1:                 episode reward: 0.0699,                 loss: 0.1558
Episode: 5161/30000 (17.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.0777s / 56745.9679 s
agent0:                 episode reward: 0.2834,                 loss: nan
agent1:                 episode reward: -0.2834,                 loss: 0.1544
Episode: 5181/30000 (17.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.4841s / 56989.4520 s
agent0:                 episode reward: 0.2218,                 loss: nan
agent1:                 episode reward: -0.2218,                 loss: 0.1532
Episode: 5201/30000 (17.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.5987s / 57239.0507 s
agent0:                 episode reward: -0.2314,                 loss: nan
agent1:                 episode reward: 0.2314,                 loss: 0.1545
Episode: 5221/30000 (17.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.1702s / 57486.2208 s
agent0:                 episode reward: -0.7453,                 loss: nan
agent1:                 episode reward: 0.7453,                 loss: 0.1543
Episode: 5241/30000 (17.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.0666s / 57736.2874 s
agent0:                 episode reward: -0.1449,                 loss: nan
agent1:                 episode reward: 0.1449,                 loss: 0.1533
Episode: 5261/30000 (17.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 241.1385s / 57977.4260 s
agent0:                 episode reward: -0.0882,                 loss: nan
agent1:                 episode reward: 0.0882,                 loss: 0.1524
Episode: 5281/30000 (17.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.5248s / 58224.9507 s
agent0:                 episode reward: -0.0169,                 loss: nan
agent1:                 episode reward: 0.0169,                 loss: 0.1533
Episode: 5301/30000 (17.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.9256s / 58474.8763 s
agent0:                 episode reward: -0.1812,                 loss: nan
agent1:                 episode reward: 0.1812,                 loss: 0.1529
Episode: 5321/30000 (17.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.8475s / 58717.7238 s
agent0:                 episode reward: -0.3347,                 loss: nan
agent1:                 episode reward: 0.3347,                 loss: 0.1523
Episode: 5341/30000 (17.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.7347s / 58962.4585 s
agent0:                 episode reward: -0.3309,                 loss: nan
agent1:                 episode reward: 0.3309,                 loss: 0.1543
Episode: 5361/30000 (17.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.6626s / 59215.1211 s
agent0:                 episode reward: 0.1103,                 loss: nan
agent1:                 episode reward: -0.1103,                 loss: 0.1540
Episode: 5381/30000 (17.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.8205s / 59460.9416 s
agent0:                 episode reward: -0.2336,                 loss: nan
agent1:                 episode reward: 0.2336,                 loss: 0.1532
Episode: 5401/30000 (18.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.9238s / 59703.8655 s
agent0:                 episode reward: -0.2153,                 loss: nan
agent1:                 episode reward: 0.2153,                 loss: 0.1525
Episode: 5421/30000 (18.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.1874s / 59956.0529 s
agent0:                 episode reward: -0.4895,                 loss: nan
agent1:                 episode reward: 0.4895,                 loss: 0.1535
Episode: 5441/30000 (18.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.2906s / 60199.3435 s
agent0:                 episode reward: -0.3048,                 loss: nan
agent1:                 episode reward: 0.3048,                 loss: 0.1530
Episode: 5461/30000 (18.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.1082s / 60445.4517 s
agent0:                 episode reward: -0.1757,                 loss: nan
agent1:                 episode reward: 0.1757,                 loss: 0.1536
Episode: 5481/30000 (18.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.9544s / 60698.4061 s
agent0:                 episode reward: -0.5431,                 loss: nan
agent1:                 episode reward: 0.5431,                 loss: 0.1533
Episode: 5501/30000 (18.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 253.5806s / 60951.9867 s
agent0:                 episode reward: -0.0047,                 loss: nan
agent1:                 episode reward: 0.0047,                 loss: 0.1528
Episode: 5521/30000 (18.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.7123s / 61198.6990 s
agent0:                 episode reward: -0.0256,                 loss: nan
agent1:                 episode reward: 0.0256,                 loss: 0.1515
Episode: 5541/30000 (18.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.6305s / 61450.3295 s
agent0:                 episode reward: -0.0708,                 loss: nan
agent1:                 episode reward: 0.0708,                 loss: 0.1528
Episode: 5561/30000 (18.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 235.6574s / 61685.9869 s
agent0:                 episode reward: 0.0276,                 loss: nan
agent1:                 episode reward: -0.0276,                 loss: 0.1531
Episode: 5581/30000 (18.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.1103s / 61930.0972 s
agent0:                 episode reward: -0.3247,                 loss: nan
agent1:                 episode reward: 0.3247,                 loss: 0.1548
Episode: 5601/30000 (18.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.6656s / 62176.7628 s
agent0:                 episode reward: -0.0276,                 loss: nan
agent1:                 episode reward: 0.0276,                 loss: 0.1538
Episode: 5621/30000 (18.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 235.6745s / 62412.4373 s
agent0:                 episode reward: -0.2914,                 loss: nan
agent1:                 episode reward: 0.2914,                 loss: 0.1539
Episode: 5641/30000 (18.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.9396s / 62654.3769 s
agent0:                 episode reward: -0.0228,                 loss: nan
agent1:                 episode reward: 0.0228,                 loss: 0.1531
Episode: 5661/30000 (18.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.7356s / 62896.1126 s
agent0:                 episode reward: -0.3060,                 loss: nan
agent1:                 episode reward: 0.3060,                 loss: 0.1535
Episode: 5681/30000 (18.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.1178s / 63146.2303 s
agent0:                 episode reward: -0.3237,                 loss: nan
agent1:                 episode reward: 0.3237,                 loss: 0.1553
Episode: 5701/30000 (19.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.7634s / 63388.9937 s
agent0:                 episode reward: -0.2052,                 loss: nan
agent1:                 episode reward: 0.2052,                 loss: 0.1534
Episode: 5721/30000 (19.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.7641s / 63636.7578 s
agent0:                 episode reward: -0.3952,                 loss: nan
agent1:                 episode reward: 0.3952,                 loss: 0.1549
Episode: 5741/30000 (19.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 239.7373s / 63876.4951 s
agent0:                 episode reward: 0.2700,                 loss: nan
agent1:                 episode reward: -0.2700,                 loss: 0.1536
Episode: 5761/30000 (19.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.4832s / 64120.9784 s
agent0:                 episode reward: 0.1351,                 loss: nan
agent1:                 episode reward: -0.1351,                 loss: 0.1553
Episode: 5781/30000 (19.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.2631s / 64368.2415 s
agent0:                 episode reward: -0.0375,                 loss: nan
agent1:                 episode reward: 0.0375,                 loss: 0.1531
Episode: 5801/30000 (19.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.6721s / 64613.9136 s
agent0:                 episode reward: -0.0298,                 loss: nan
agent1:                 episode reward: 0.0298,                 loss: 0.1538
Episode: 5821/30000 (19.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.7112s / 64864.6248 s
agent0:                 episode reward: -0.1410,                 loss: nan
agent1:                 episode reward: 0.1410,                 loss: 0.1538
Episode: 5841/30000 (19.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.5116s / 65111.1364 s
agent0:                 episode reward: -0.2538,                 loss: nan
agent1:                 episode reward: 0.2538,                 loss: 0.1531
Episode: 5861/30000 (19.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 241.2756s / 65352.4121 s
agent0:                 episode reward: -0.2184,                 loss: nan
agent1:                 episode reward: 0.2184,                 loss: 0.1538
Episode: 5881/30000 (19.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 240.5959s / 65593.0079 s
agent0:                 episode reward: -0.4506,                 loss: nan
agent1:                 episode reward: 0.4506,                 loss: 0.1527
Episode: 5901/30000 (19.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.9614s / 65845.9693 s
agent0:                 episode reward: 0.3827,                 loss: nan
agent1:                 episode reward: -0.3827,                 loss: 0.1556
Episode: 5921/30000 (19.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.3599s / 66089.3293 s
agent0:                 episode reward: -0.3867,                 loss: nan
agent1:                 episode reward: 0.3867,                 loss: 0.1575
Episode: 5941/30000 (19.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.4143s / 66338.7435 s
agent0:                 episode reward: -0.0523,                 loss: nan
agent1:                 episode reward: 0.0523,                 loss: 0.1571
Episode: 5961/30000 (19.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 234.0119s / 66572.7555 s
agent0:                 episode reward: 0.0234,                 loss: nan
agent1:                 episode reward: -0.0234,                 loss: 0.1538
Episode: 5981/30000 (19.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.3198s / 66817.0752 s
agent0:                 episode reward: -0.2603,                 loss: nan
agent1:                 episode reward: 0.2603,                 loss: 0.1564
Episode: 6001/30000 (20.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 235.0606s / 67052.1359 s
agent0:                 episode reward: -0.4669,                 loss: nan
agent1:                 episode reward: 0.4669,                 loss: 0.1576
Episode: 6021/30000 (20.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 236.8174s / 67288.9532 s
agent0:                 episode reward: -0.4367,                 loss: nan
agent1:                 episode reward: 0.4367,                 loss: 0.1561
Episode: 6041/30000 (20.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.0866s / 67532.0399 s
agent0:                 episode reward: -0.1146,                 loss: nan
agent1:                 episode reward: 0.1146,                 loss: 0.1557
Episode: 6061/30000 (20.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.2663s / 67774.3062 s
agent0:                 episode reward: 0.1095,                 loss: nan
agent1:                 episode reward: -0.1095,                 loss: 0.1578
Episode: 6081/30000 (20.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.0577s / 68019.3639 s
agent0:                 episode reward: 0.1022,                 loss: nan
agent1:                 episode reward: -0.1022,                 loss: 0.1565
Episode: 6101/30000 (20.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.8226s / 68262.1865 s
agent0:                 episode reward: -0.1201,                 loss: nan
agent1:                 episode reward: 0.1201,                 loss: 0.1574
Episode: 6121/30000 (20.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 254.1599s / 68516.3464 s
agent0:                 episode reward: 0.2081,                 loss: nan
agent1:                 episode reward: -0.2081,                 loss: 0.1566
Episode: 6141/30000 (20.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.7947s / 68760.1411 s
agent0:                 episode reward: 0.2262,                 loss: nan
agent1:                 episode reward: -0.2262,                 loss: 0.1550
Episode: 6161/30000 (20.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.7534s / 69006.8945 s
agent0:                 episode reward: -0.0756,                 loss: nan
agent1:                 episode reward: 0.0756,                 loss: 0.1570
Episode: 6181/30000 (20.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.9921s / 69254.8865 s
agent0:                 episode reward: 0.1061,                 loss: nan
agent1:                 episode reward: -0.1061,                 loss: 0.1556
Episode: 6201/30000 (20.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.0857s / 69505.9722 s
agent0:                 episode reward: -0.5011,                 loss: nan
agent1:                 episode reward: 0.5011,                 loss: 0.1553
Episode: 6221/30000 (20.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.0011s / 69750.9732 s
agent0:                 episode reward: -0.2163,                 loss: nan
agent1:                 episode reward: 0.2163,                 loss: 0.1581
Episode: 6241/30000 (20.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 237.1564s / 69988.1297 s
agent0:                 episode reward: -0.2160,                 loss: nan
agent1:                 episode reward: 0.2160,                 loss: 0.1585
Episode: 6261/30000 (20.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 256.7609s / 70244.8906 s
agent0:                 episode reward: -0.3298,                 loss: nan
agent1:                 episode reward: 0.3298,                 loss: 0.1574
Episode: 6281/30000 (20.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.1004s / 70488.9910 s
agent0:                 episode reward: -0.1996,                 loss: nan
agent1:                 episode reward: 0.1996,                 loss: 0.1583
Episode: 6301/30000 (21.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.5156s / 70731.5066 s
agent0:                 episode reward: -0.0209,                 loss: nan
agent1:                 episode reward: 0.0209,                 loss: 0.1584
Episode: 6321/30000 (21.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.5672s / 70976.0738 s
agent0:                 episode reward: -0.0281,                 loss: nan
agent1:                 episode reward: 0.0281,                 loss: 0.1577
Episode: 6341/30000 (21.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.2690s / 71223.3427 s
agent0:                 episode reward: -0.3880,                 loss: nan
agent1:                 episode reward: 0.3880,                 loss: 0.1577
Episode: 6361/30000 (21.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.1164s / 71470.4591 s
agent0:                 episode reward: -0.6238,                 loss: nan
agent1:                 episode reward: 0.6238,                 loss: 0.1579
Episode: 6381/30000 (21.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.8831s / 71716.3422 s
agent0:                 episode reward: 0.1006,                 loss: nan
agent1:                 episode reward: -0.1006,                 loss: 0.1596
Episode: 6401/30000 (21.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.9692s / 71966.3113 s
agent0:                 episode reward: -0.2236,                 loss: nan
agent1:                 episode reward: 0.2236,                 loss: 0.1561
Episode: 6421/30000 (21.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 235.5479s / 72201.8593 s
agent0:                 episode reward: -0.1046,                 loss: nan
agent1:                 episode reward: 0.1046,                 loss: 0.1592
Episode: 6441/30000 (21.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.7284s / 72445.5877 s
agent0:                 episode reward: -0.2176,                 loss: nan
agent1:                 episode reward: 0.2176,                 loss: 0.1574
Episode: 6461/30000 (21.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 257.8608s / 72703.4485 s
agent0:                 episode reward: -0.1650,                 loss: nan
agent1:                 episode reward: 0.1650,                 loss: 0.1575
Episode: 6481/30000 (21.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.6766s / 72945.1251 s
agent0:                 episode reward: -0.4543,                 loss: nan
agent1:                 episode reward: 0.4543,                 loss: 0.1563
Episode: 6501/30000 (21.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.2171s / 73190.3422 s
agent0:                 episode reward: -0.4262,                 loss: nan
agent1:                 episode reward: 0.4262,                 loss: 0.1557
Episode: 6521/30000 (21.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 258.2519s / 73448.5941 s
agent0:                 episode reward: 0.1306,                 loss: nan
agent1:                 episode reward: -0.1306,                 loss: 0.1551
Episode: 6541/30000 (21.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.7294s / 73693.3235 s
agent0:                 episode reward: 0.0637,                 loss: nan
agent1:                 episode reward: -0.0637,                 loss: 0.1573
Episode: 6561/30000 (21.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.5697s / 73937.8932 s
agent0:                 episode reward: -0.3473,                 loss: nan
agent1:                 episode reward: 0.3473,                 loss: 0.1555
Episode: 6581/30000 (21.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.5716s / 74185.4649 s
agent0:                 episode reward: -0.6119,                 loss: nan
agent1:                 episode reward: 0.6119,                 loss: 0.1550
Episode: 6601/30000 (22.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.1497s / 74427.6145 s
agent0:                 episode reward: -0.5366,                 loss: nan
agent1:                 episode reward: 0.5366,                 loss: 0.1537
Episode: 6621/30000 (22.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.3469s / 74672.9614 s
agent0:                 episode reward: -0.5667,                 loss: nan
agent1:                 episode reward: 0.5667,                 loss: 0.1551
Episode: 6641/30000 (22.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 240.0953s / 74913.0568 s
agent0:                 episode reward: -0.0843,                 loss: nan
agent1:                 episode reward: 0.0843,                 loss: 0.1548
Episode: 6661/30000 (22.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 256.8247s / 75169.8815 s
agent0:                 episode reward: 0.1866,                 loss: nan
agent1:                 episode reward: -0.1866,                 loss: 0.1552
Episode: 6681/30000 (22.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.9773s / 75416.8588 s
agent0:                 episode reward: -0.5006,                 loss: nan
agent1:                 episode reward: 0.5006,                 loss: 0.1538
Episode: 6701/30000 (22.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.5171s / 75663.3759 s
agent0:                 episode reward: 0.1655,                 loss: nan
agent1:                 episode reward: -0.1655,                 loss: 0.1548
Episode: 6721/30000 (22.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.4348s / 75910.8107 s
agent0:                 episode reward: -0.3257,                 loss: nan
agent1:                 episode reward: 0.3257,                 loss: 0.1559
Episode: 6741/30000 (22.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 257.8165s / 76168.6272 s
agent0:                 episode reward: -0.3849,                 loss: nan
agent1:                 episode reward: 0.3849,                 loss: 0.1546
Episode: 6761/30000 (22.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.8098s / 76411.4369 s
agent0:                 episode reward: 0.2297,                 loss: nan
agent1:                 episode reward: -0.2297,                 loss: 0.1558
Episode: 6781/30000 (22.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.8292s / 76663.2662 s
agent0:                 episode reward: -0.3145,                 loss: nan
agent1:                 episode reward: 0.3145,                 loss: 0.1554
Episode: 6801/30000 (22.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.1460s / 76910.4122 s
agent0:                 episode reward: -0.4625,                 loss: nan
agent1:                 episode reward: 0.4625,                 loss: 0.1557
Episode: 6821/30000 (22.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.9754s / 77163.3875 s
agent0:                 episode reward: -0.0083,                 loss: nan
agent1:                 episode reward: 0.0083,                 loss: 0.1556
Episode: 6841/30000 (22.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.9339s / 77408.3215 s
agent0:                 episode reward: -0.3628,                 loss: nan
agent1:                 episode reward: 0.3628,                 loss: 0.1545
Episode: 6861/30000 (22.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.2366s / 77657.5581 s
agent0:                 episode reward: -0.0209,                 loss: nan
agent1:                 episode reward: 0.0209,                 loss: 0.1547
Episode: 6881/30000 (22.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 253.1314s / 77910.6895 s
agent0:                 episode reward: 0.2148,                 loss: nan
agent1:                 episode reward: -0.2148,                 loss: 0.1551
Episode: 6901/30000 (23.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 240.9113s / 78151.6008 s
agent0:                 episode reward: -0.2452,                 loss: nan
agent1:                 episode reward: 0.2452,                 loss: 0.1540
Episode: 6921/30000 (23.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 254.3788s / 78405.9796 s
agent0:                 episode reward: 0.2518,                 loss: nan
agent1:                 episode reward: -0.2518,                 loss: 0.1525
Episode: 6941/30000 (23.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.5200s / 78657.4996 s
agent0:                 episode reward: 0.4414,                 loss: nan
agent1:                 episode reward: -0.4414,                 loss: 0.1535
Episode: 6961/30000 (23.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.2261s / 78906.7257 s
agent0:                 episode reward: 0.1479,                 loss: nan
agent1:                 episode reward: -0.1479,                 loss: 0.1537
Episode: 6981/30000 (23.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.4121s / 79148.1377 s
agent0:                 episode reward: -0.1640,                 loss: nan
agent1:                 episode reward: 0.1640,                 loss: 0.1530
Episode: 7001/30000 (23.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.1889s / 79400.3267 s
agent0:                 episode reward: 0.0311,                 loss: nan
agent1:                 episode reward: -0.0311,                 loss: 0.1529
Episode: 7021/30000 (23.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.4843s / 79650.8110 s
agent0:                 episode reward: -0.1654,                 loss: nan
agent1:                 episode reward: 0.1654,                 loss: 0.1535
Episode: 7041/30000 (23.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.9691s / 79902.7801 s
agent0:                 episode reward: -0.2685,                 loss: nan
agent1:                 episode reward: 0.2685,                 loss: 0.1543
Episode: 7061/30000 (23.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.7079s / 80148.4880 s
agent0:                 episode reward: -0.1951,                 loss: nan
agent1:                 episode reward: 0.1951,                 loss: 0.1537
Episode: 7081/30000 (23.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.5526s / 80399.0406 s
agent0:                 episode reward: 0.1077,                 loss: nan
agent1:                 episode reward: -0.1077,                 loss: 0.1543
Episode: 7101/30000 (23.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.0454s / 80644.0860 s
agent0:                 episode reward: -0.1994,                 loss: nan
agent1:                 episode reward: 0.1994,                 loss: 0.1529
Episode: 7121/30000 (23.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 255.5249s / 80899.6109 s
agent0:                 episode reward: -0.4837,                 loss: nan
agent1:                 episode reward: 0.4837,                 loss: 0.1530
Episode: 7141/30000 (23.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.5919s / 81145.2028 s
agent0:                 episode reward: 0.0890,                 loss: nan
agent1:                 episode reward: -0.0890,                 loss: 0.1523
Episode: 7161/30000 (23.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 233.1022s / 81378.3050 s
agent0:                 episode reward: 0.1188,                 loss: nan
agent1:                 episode reward: -0.1188,                 loss: 0.1526
Episode: 7181/30000 (23.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.7146s / 81621.0196 s
agent0:                 episode reward: -0.3944,                 loss: nan
agent1:                 episode reward: 0.3944,                 loss: 0.1533
Episode: 7201/30000 (24.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.8095s / 81872.8290 s
agent0:                 episode reward: -0.2339,                 loss: nan
agent1:                 episode reward: 0.2339,                 loss: 0.1544
Episode: 7221/30000 (24.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.7308s / 82123.5598 s
agent0:                 episode reward: -0.2323,                 loss: nan
agent1:                 episode reward: 0.2323,                 loss: 0.1538
Episode: 7241/30000 (24.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.2805s / 82375.8404 s
agent0:                 episode reward: -0.3185,                 loss: nan
agent1:                 episode reward: 0.3185,                 loss: 0.1555
Episode: 7261/30000 (24.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.9044s / 82619.7448 s
agent0:                 episode reward: -0.0651,                 loss: nan
agent1:                 episode reward: 0.0651,                 loss: 0.1535
Episode: 7281/30000 (24.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.7169s / 82871.4617 s
agent0:                 episode reward: -0.0218,                 loss: nan
agent1:                 episode reward: 0.0218,                 loss: 0.1538
Episode: 7301/30000 (24.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.0019s / 83116.4636 s
agent0:                 episode reward: -0.2068,                 loss: nan
agent1:                 episode reward: 0.2068,                 loss: 0.1541
Episode: 7321/30000 (24.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.9131s / 83363.3767 s
agent0:                 episode reward: -0.2186,                 loss: nan
agent1:                 episode reward: 0.2186,                 loss: 0.1543
Episode: 7341/30000 (24.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 258.0765s / 83621.4532 s
agent0:                 episode reward: -0.0701,                 loss: nan
agent1:                 episode reward: 0.0701,                 loss: 0.1550
Episode: 7361/30000 (24.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.7019s / 83871.1551 s
agent0:                 episode reward: -0.3567,                 loss: nan
agent1:                 episode reward: 0.3567,                 loss: 0.1528
Episode: 7381/30000 (24.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 256.0776s / 84127.2327 s
agent0:                 episode reward: -0.2668,                 loss: nan
agent1:                 episode reward: 0.2668,                 loss: 0.1547
Episode: 7401/30000 (24.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 236.1698s / 84363.4026 s
agent0:                 episode reward: -0.0707,                 loss: nan
agent1:                 episode reward: 0.0707,                 loss: 0.1548
Episode: 7421/30000 (24.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.2792s / 84613.6818 s
agent0:                 episode reward: 0.0565,                 loss: nan
agent1:                 episode reward: -0.0565,                 loss: 0.1546
Episode: 7441/30000 (24.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.8852s / 84864.5670 s
agent0:                 episode reward: -0.3557,                 loss: nan
agent1:                 episode reward: 0.3557,                 loss: 0.1556
Episode: 7461/30000 (24.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.7104s / 85110.2774 s
agent0:                 episode reward: -0.2433,                 loss: nan
agent1:                 episode reward: 0.2433,                 loss: 0.1555
Episode: 7481/30000 (24.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.9386s / 85355.2160 s
agent0:                 episode reward: -0.1424,                 loss: nan
agent1:                 episode reward: 0.1424,                 loss: 0.1553
Episode: 7501/30000 (25.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.8850s / 85600.1010 s
agent0:                 episode reward: -0.1190,                 loss: nan
agent1:                 episode reward: 0.1190,                 loss: 0.1534
Episode: 7521/30000 (25.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.6441s / 85842.7451 s
agent0:                 episode reward: 0.1047,                 loss: nan
agent1:                 episode reward: -0.1047,                 loss: 0.1549
Episode: 7541/30000 (25.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.7892s / 86093.5343 s
agent0:                 episode reward: -0.2308,                 loss: nan
agent1:                 episode reward: 0.2308,                 loss: 0.1558
Episode: 7561/30000 (25.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.5925s / 86343.1268 s
agent0:                 episode reward: -0.2730,                 loss: nan
agent1:                 episode reward: 0.2730,                 loss: 0.1528
Episode: 7581/30000 (25.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.9102s / 86591.0370 s
agent0:                 episode reward: 0.0850,                 loss: nan
agent1:                 episode reward: -0.0850,                 loss: 0.1513
Episode: 7601/30000 (25.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.1009s / 86838.1379 s
agent0:                 episode reward: 0.0010,                 loss: nan
agent1:                 episode reward: -0.0010,                 loss: 0.1507
Episode: 7621/30000 (25.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.5515s / 87090.6894 s
agent0:                 episode reward: -0.3429,                 loss: nan
agent1:                 episode reward: 0.3429,                 loss: 0.1509
Episode: 7641/30000 (25.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 259.5496s / 87350.2390 s
agent0:                 episode reward: -0.3304,                 loss: nan
agent1:                 episode reward: 0.3304,                 loss: 0.1523
Episode: 7661/30000 (25.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.2131s / 87602.4522 s
agent0:                 episode reward: -0.2578,                 loss: nan
agent1:                 episode reward: 0.2578,                 loss: 0.1514
Episode: 7681/30000 (25.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.7528s / 87847.2050 s
agent0:                 episode reward: -0.1058,                 loss: nan
agent1:                 episode reward: 0.1058,                 loss: 0.1522
Episode: 7701/30000 (25.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.9535s / 88090.1585 s
agent0:                 episode reward: -0.1456,                 loss: nan
agent1:                 episode reward: 0.1456,                 loss: 0.1497
Episode: 7721/30000 (25.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.0791s / 88333.2377 s
agent0:                 episode reward: -0.1917,                 loss: nan
agent1:                 episode reward: 0.1917,                 loss: 0.1511
Episode: 7741/30000 (25.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.7701s / 88581.0078 s
agent0:                 episode reward: -0.2881,                 loss: nan
agent1:                 episode reward: 0.2881,                 loss: 0.1511
Episode: 7761/30000 (25.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.8501s / 88823.8579 s
agent0:                 episode reward: -0.1391,                 loss: nan
agent1:                 episode reward: 0.1391,                 loss: 0.1519
Episode: 7781/30000 (25.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.2235s / 89073.0814 s
agent0:                 episode reward: 0.0167,                 loss: nan
agent1:                 episode reward: -0.0167,                 loss: 0.1527
Episode: 7801/30000 (26.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 234.0240s / 89307.1053 s
agent0:                 episode reward: -0.0741,                 loss: nan
agent1:                 episode reward: 0.0741,                 loss: 0.1496
Episode: 7821/30000 (26.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.1601s / 89556.2655 s
agent0:                 episode reward: -0.0440,                 loss: nan
agent1:                 episode reward: 0.0440,                 loss: 0.1526
Episode: 7841/30000 (26.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.4799s / 89804.7454 s
agent0:                 episode reward: -0.1384,                 loss: nan
agent1:                 episode reward: 0.1384,                 loss: 0.1514
Episode: 7861/30000 (26.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.7092s / 90056.4546 s
agent0:                 episode reward: -0.3058,                 loss: nan
agent1:                 episode reward: 0.3058,                 loss: 0.1515
Episode: 7881/30000 (26.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.6191s / 90301.0737 s
agent0:                 episode reward: -0.3650,                 loss: nan
agent1:                 episode reward: 0.3650,                 loss: 0.1524
Episode: 7901/30000 (26.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 236.4074s / 90537.4812 s
agent0:                 episode reward: -0.3592,                 loss: nan
agent1:                 episode reward: 0.3592,                 loss: 0.1527
Episode: 7921/30000 (26.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.8522s / 90780.3334 s
agent0:                 episode reward: -0.3844,                 loss: nan
agent1:                 episode reward: 0.3844,                 loss: 0.1540
Episode: 7941/30000 (26.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 233.1772s / 91013.5106 s
agent0:                 episode reward: -0.0725,                 loss: nan
agent1:                 episode reward: 0.0725,                 loss: 0.1550
Episode: 7961/30000 (26.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.9555s / 91256.4661 s
agent0:                 episode reward: -0.4042,                 loss: nan
agent1:                 episode reward: 0.4042,                 loss: 0.1522
Episode: 7981/30000 (26.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.0567s / 91503.5228 s
agent0:                 episode reward: -0.0682,                 loss: nan
agent1:                 episode reward: 0.0682,                 loss: 0.1524
Episode: 8001/30000 (26.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.4025s / 91755.9252 s
agent0:                 episode reward: 0.0337,                 loss: nan
agent1:                 episode reward: -0.0337,                 loss: 0.1515
Episode: 8021/30000 (26.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.1636s / 92001.0888 s
agent0:                 episode reward: -0.1109,                 loss: nan
agent1:                 episode reward: 0.1109,                 loss: 0.1524