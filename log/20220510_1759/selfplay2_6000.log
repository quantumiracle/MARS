2022-05-10 18:20:35.206752: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia:/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia
2022-05-10 18:20:35.206817: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia:/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia
2022-05-10 18:20:35.206823: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
pygame 2.0.1 (SDL 2.0.14, Python 3.6.13)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 33.0, (1,), float32) action space: Discrete(3)
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7f69182f1518>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=32, bias=True)
      (3): ReLU()
      (4): Linear(in_features=32, out_features=32, bias=True)
      (5): ReLU()
      (6): Linear(in_features=32, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=32, bias=True)
      (3): ReLU()
      (4): Linear(in_features=32, out_features=32, bias=True)
      (5): ReLU()
      (6): Linear(in_features=32, out_features=3, bias=True)
    )
  )
)
Error: no exploited model index given!
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  data/model/20220510161908/mdp_arbitrary_mdp_selfplay2/6000_0
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': 1, 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 1.0, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 640, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-3', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220510161908/mdp_arbitrary_mdp_selfplay2/6000_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 1000, 'net_architecture': {'hidden_dim_list': [32, 32, 32], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'selfplay2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'selfplay_score_delta': 1.5, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'against_baseline': False}
Save models to : /home/quantumiracle/research/MARS/data/model/20220510161908_exploit_6000/mdp_arbitrary_mdp_selfplay2. 
 Save logs to: /home/quantumiracle/research/MARS/data/log/20220510161908_exploit_6000/mdp_arbitrary_mdp_selfplay2.
Episode: 1/10000 (0.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8106s / 0.8106 s
agent0:                 episode reward: 1.4231,                 loss: nan
agent1:                 episode reward: -1.4231,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.0643s / 0.8749 s
agent0:                 episode reward: 0.8535,                 loss: nan
agent1:                 episode reward: -0.8535,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.0647s / 0.9395 s
agent0:                 episode reward: 0.6403,                 loss: nan
agent1:                 episode reward: -0.6403,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.0797s / 1.0192 s
agent0:                 episode reward: 0.0295,                 loss: nan
agent1:                 episode reward: -0.0295,                 loss: nan
Episode: 81/10000 (0.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5985s / 1.6177 s
agent0:                 episode reward: 0.3234,                 loss: nan
agent1:                 episode reward: -0.3234,                 loss: 0.4486
Episode: 101/10000 (1.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7173s / 2.3350 s
agent0:                 episode reward: 0.3029,                 loss: nan
agent1:                 episode reward: -0.3029,                 loss: 0.4336
Episode: 121/10000 (1.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6907s / 3.0257 s
agent0:                 episode reward: 0.4218,                 loss: nan
agent1:                 episode reward: -0.4218,                 loss: 0.4117
Episode: 141/10000 (1.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7001s / 3.7259 s
agent0:                 episode reward: 0.6118,                 loss: nan
agent1:                 episode reward: -0.6118,                 loss: 0.3983
Episode: 161/10000 (1.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7134s / 4.4393 s
agent0:                 episode reward: 0.8210,                 loss: nan
agent1:                 episode reward: -0.8210,                 loss: 0.3930
Episode: 181/10000 (1.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6962s / 5.1355 s
agent0:                 episode reward: 0.3066,                 loss: nan
agent1:                 episode reward: -0.3066,                 loss: 0.3567
Episode: 201/10000 (2.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7178s / 5.8533 s
agent0:                 episode reward: 0.4477,                 loss: nan
agent1:                 episode reward: -0.4477,                 loss: 0.3422
Episode: 221/10000 (2.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6987s / 6.5520 s
agent0:                 episode reward: 0.8277,                 loss: nan
agent1:                 episode reward: -0.8277,                 loss: 0.3387
Episode: 241/10000 (2.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7082s / 7.2602 s
agent0:                 episode reward: 0.7848,                 loss: nan
agent1:                 episode reward: -0.7848,                 loss: 0.3393
Episode: 261/10000 (2.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7755s / 8.0357 s
agent0:                 episode reward: 0.3461,                 loss: nan
agent1:                 episode reward: -0.3461,                 loss: 0.3356
Episode: 281/10000 (2.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7098s / 8.7455 s
agent0:                 episode reward: 0.5832,                 loss: nan
agent1:                 episode reward: -0.5832,                 loss: 0.3018
Episode: 301/10000 (3.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7101s / 9.4556 s
agent0:                 episode reward: 0.8035,                 loss: nan
agent1:                 episode reward: -0.8035,                 loss: 0.2903
Episode: 321/10000 (3.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7172s / 10.1728 s
agent0:                 episode reward: 0.9572,                 loss: nan
agent1:                 episode reward: -0.9572,                 loss: 0.2821
Episode: 341/10000 (3.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7374s / 10.9102 s
agent0:                 episode reward: 0.7853,                 loss: nan
agent1:                 episode reward: -0.7853,                 loss: 0.2740
Episode: 361/10000 (3.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7284s / 11.6386 s
agent0:                 episode reward: 0.4222,                 loss: nan
agent1:                 episode reward: -0.4222,                 loss: 0.2682
Episode: 381/10000 (3.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7290s / 12.3676 s
agent0:                 episode reward: 1.0601,                 loss: nan
agent1:                 episode reward: -1.0601,                 loss: 0.2664
Episode: 401/10000 (4.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7326s / 13.1002 s
agent0:                 episode reward: 0.7661,                 loss: nan
agent1:                 episode reward: -0.7661,                 loss: 0.2624
Episode: 421/10000 (4.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7417s / 13.8419 s
agent0:                 episode reward: 0.5241,                 loss: nan
agent1:                 episode reward: -0.5241,                 loss: 0.2626
Episode: 441/10000 (4.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7780s / 14.6199 s
agent0:                 episode reward: 0.7595,                 loss: nan
agent1:                 episode reward: -0.7595,                 loss: 0.2644
Episode: 461/10000 (4.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7329s / 15.3528 s
agent0:                 episode reward: 0.2748,                 loss: nan
agent1:                 episode reward: -0.2748,                 loss: 0.2613
Episode: 481/10000 (4.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7516s / 16.1044 s
agent0:                 episode reward: 0.9213,                 loss: nan
agent1:                 episode reward: -0.9213,                 loss: 0.2636
Episode: 501/10000 (5.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7556s / 16.8600 s
agent0:                 episode reward: 0.3249,                 loss: nan
agent1:                 episode reward: -0.3249,                 loss: 0.2590
Episode: 521/10000 (5.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7472s / 17.6071 s
agent0:                 episode reward: 1.4353,                 loss: nan
agent1:                 episode reward: -1.4353,                 loss: 0.2574
Episode: 541/10000 (5.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7992s / 18.4064 s
agent0:                 episode reward: 0.7411,                 loss: nan
agent1:                 episode reward: -0.7411,                 loss: 0.2561
Episode: 561/10000 (5.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7480s / 19.1544 s
agent0:                 episode reward: -0.4380,                 loss: nan
agent1:                 episode reward: 0.4380,                 loss: 0.2566
Episode: 581/10000 (5.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7969s / 19.9512 s
agent0:                 episode reward: 0.6182,                 loss: nan
agent1:                 episode reward: -0.6182,                 loss: 0.2558
Episode: 601/10000 (6.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7515s / 20.7027 s
agent0:                 episode reward: 0.4973,                 loss: nan
agent1:                 episode reward: -0.4973,                 loss: 0.2524
Episode: 621/10000 (6.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7542s / 21.4568 s
agent0:                 episode reward: 0.1531,                 loss: nan
agent1:                 episode reward: -0.1531,                 loss: 0.2515
Episode: 641/10000 (6.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7850s / 22.2418 s
agent0:                 episode reward: 1.3398,                 loss: nan
agent1:                 episode reward: -1.3398,                 loss: 0.2513
Episode: 661/10000 (6.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7813s / 23.0231 s
agent0:                 episode reward: 0.3924,                 loss: nan
agent1:                 episode reward: -0.3924,                 loss: 0.2515
Episode: 681/10000 (6.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7710s / 23.7941 s
agent0:                 episode reward: 0.7049,                 loss: nan
agent1:                 episode reward: -0.7049,                 loss: 0.2751
Episode: 701/10000 (7.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7750s / 24.5691 s
agent0:                 episode reward: 0.4284,                 loss: nan
agent1:                 episode reward: -0.4284,                 loss: 0.2748
Episode: 721/10000 (7.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7840s / 25.3531 s
agent0:                 episode reward: 0.5722,                 loss: nan
agent1:                 episode reward: -0.5722,                 loss: 0.2700
Episode: 741/10000 (7.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7987s / 26.1518 s
agent0:                 episode reward: 0.3985,                 loss: nan
agent1:                 episode reward: -0.3985,                 loss: 0.2666
Episode: 761/10000 (7.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7660s / 26.9177 s
agent0:                 episode reward: -0.5960,                 loss: nan
agent1:                 episode reward: 0.5960,                 loss: 0.2664
Episode: 781/10000 (7.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7820s / 27.6997 s
agent0:                 episode reward: 0.3061,                 loss: nan
agent1:                 episode reward: -0.3061,                 loss: 0.2802
Episode: 801/10000 (8.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8292s / 28.5289 s
agent0:                 episode reward: 1.1401,                 loss: nan
agent1:                 episode reward: -1.1401,                 loss: 0.2772
Episode: 821/10000 (8.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7876s / 29.3166 s
agent0:                 episode reward: 1.0172,                 loss: nan
agent1:                 episode reward: -1.0172,                 loss: 0.2740
Episode: 841/10000 (8.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7750s / 30.0916 s
agent0:                 episode reward: 0.2451,                 loss: nan
agent1:                 episode reward: -0.2451,                 loss: 0.2736
Episode: 861/10000 (8.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7928s / 30.8844 s
agent0:                 episode reward: 0.7490,                 loss: nan
agent1:                 episode reward: -0.7490,                 loss: 0.2724
Episode: 881/10000 (8.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8116s / 31.6960 s
agent0:                 episode reward: 0.1632,                 loss: nan
agent1:                 episode reward: -0.1632,                 loss: 0.2941
Episode: 901/10000 (9.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7800s / 32.4760 s
agent0:                 episode reward: 1.5028,                 loss: nan
agent1:                 episode reward: -1.5028,                 loss: 0.2922
Episode: 921/10000 (9.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7888s / 33.2648 s
agent0:                 episode reward: 0.1357,                 loss: nan
agent1:                 episode reward: -0.1357,                 loss: 0.2878
Episode: 941/10000 (9.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7857s / 34.0505 s
agent0:                 episode reward: 0.5950,                 loss: nan
agent1:                 episode reward: -0.5950,                 loss: 0.2858
Episode: 961/10000 (9.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7967s / 34.8472 s
agent0:                 episode reward: 1.2865,                 loss: nan
agent1:                 episode reward: -1.2865,                 loss: 0.2832
Episode: 981/10000 (9.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8264s / 35.6735 s
agent0:                 episode reward: 0.3317,                 loss: nan
agent1:                 episode reward: -0.3317,                 loss: 0.3177
Episode: 1001/10000 (10.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8007s / 36.4742 s
agent0:                 episode reward: 0.7183,                 loss: nan
agent1:                 episode reward: -0.7183,                 loss: 0.3180
Episode: 1021/10000 (10.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8248s / 37.2990 s
agent0:                 episode reward: -0.0272,                 loss: nan
agent1:                 episode reward: 0.0272,                 loss: 0.3164
Episode: 1041/10000 (10.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8221s / 38.1211 s
agent0:                 episode reward: 1.2921,                 loss: nan
agent1:                 episode reward: -1.2921,                 loss: 0.3150
Episode: 1061/10000 (10.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8696s / 38.9907 s
agent0:                 episode reward: 0.5260,                 loss: nan
agent1:                 episode reward: -0.5260,                 loss: 0.3148
Episode: 1081/10000 (10.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8353s / 39.8260 s
agent0:                 episode reward: 0.2371,                 loss: nan
agent1:                 episode reward: -0.2371,                 loss: 0.2894
Episode: 1101/10000 (11.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8264s / 40.6523 s
agent0:                 episode reward: 0.2692,                 loss: nan
agent1:                 episode reward: -0.2692,                 loss: 0.2752
Episode: 1121/10000 (11.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8183s / 41.4706 s
agent0:                 episode reward: 0.4039,                 loss: nan
agent1:                 episode reward: -0.4039,                 loss: 0.2752
Episode: 1141/10000 (11.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8221s / 42.2927 s
agent0:                 episode reward: 0.2732,                 loss: nan
agent1:                 episode reward: -0.2732,                 loss: 0.2730
Episode: 1161/10000 (11.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8236s / 43.1163 s
agent0:                 episode reward: 0.3402,                 loss: nan
agent1:                 episode reward: -0.3402,                 loss: 0.2701
Episode: 1181/10000 (11.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8340s / 43.9503 s
agent0:                 episode reward: 0.2916,                 loss: nan
agent1:                 episode reward: -0.2916,                 loss: 0.2170
Episode: 1201/10000 (12.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8261s / 44.7764 s
agent0:                 episode reward: 0.0822,                 loss: nan
agent1:                 episode reward: -0.0822,                 loss: 0.2031
Episode: 1221/10000 (12.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8366s / 45.6131 s
agent0:                 episode reward: 1.0024,                 loss: nan
agent1:                 episode reward: -1.0024,                 loss: 0.2031
Episode: 1241/10000 (12.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8443s / 46.4574 s
agent0:                 episode reward: 0.0106,                 loss: nan
agent1:                 episode reward: -0.0106,                 loss: 0.1988
Episode: 1261/10000 (12.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8401s / 47.2975 s
agent0:                 episode reward: 0.0779,                 loss: nan
agent1:                 episode reward: -0.0779,                 loss: 0.2002
Episode: 1281/10000 (12.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8431s / 48.1406 s
agent0:                 episode reward: 0.8405,                 loss: nan
agent1:                 episode reward: -0.8405,                 loss: 0.1826
Episode: 1301/10000 (13.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9086s / 49.0492 s
agent0:                 episode reward: 0.5573,                 loss: nan
agent1:                 episode reward: -0.5573,                 loss: 0.1772
Episode: 1321/10000 (13.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8374s / 49.8866 s
agent0:                 episode reward: 0.2632,                 loss: nan
agent1:                 episode reward: -0.2632,                 loss: 0.1773
Episode: 1341/10000 (13.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8352s / 50.7218 s
agent0:                 episode reward: 0.3345,                 loss: nan
agent1:                 episode reward: -0.3345,                 loss: 0.1784
Episode: 1361/10000 (13.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8547s / 51.5765 s
agent0:                 episode reward: 0.2098,                 loss: nan
agent1:                 episode reward: -0.2098,                 loss: 0.1778
Episode: 1381/10000 (13.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8484s / 52.4249 s
agent0:                 episode reward: 0.5430,                 loss: nan
agent1:                 episode reward: -0.5430,                 loss: 0.2056
Episode: 1401/10000 (14.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8287s / 53.2536 s
agent0:                 episode reward: 0.6612,                 loss: nan
agent1:                 episode reward: -0.6612,                 loss: 0.2085
Episode: 1421/10000 (14.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8301s / 54.0837 s
agent0:                 episode reward: 0.3064,                 loss: nan
agent1:                 episode reward: -0.3064,                 loss: 0.2066
Episode: 1441/10000 (14.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8524s / 54.9361 s
agent0:                 episode reward: 0.0412,                 loss: nan
agent1:                 episode reward: -0.0412,                 loss: 0.2068
Episode: 1461/10000 (14.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8809s / 55.8170 s
agent0:                 episode reward: -0.2765,                 loss: nan
agent1:                 episode reward: 0.2765,                 loss: 0.2049
Episode: 1481/10000 (14.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8599s / 56.6769 s
agent0:                 episode reward: 0.3877,                 loss: nan
agent1:                 episode reward: -0.3877,                 loss: 0.2267
Episode: 1501/10000 (15.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8466s / 57.5235 s
agent0:                 episode reward: 1.2047,                 loss: nan
agent1:                 episode reward: -1.2047,                 loss: 0.2313
Episode: 1521/10000 (15.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8552s / 58.3788 s
agent0:                 episode reward: 0.1410,                 loss: nan
agent1:                 episode reward: -0.1410,                 loss: 0.2276
Episode: 1541/10000 (15.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9102s / 59.2890 s
agent0:                 episode reward: 0.0316,                 loss: nan
agent1:                 episode reward: -0.0316,                 loss: 0.2276
Episode: 1561/10000 (15.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8602s / 60.1492 s
agent0:                 episode reward: 0.1852,                 loss: nan
agent1:                 episode reward: -0.1852,                 loss: 0.2253
Episode: 1581/10000 (15.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8595s / 61.0087 s
agent0:                 episode reward: 0.1915,                 loss: nan
agent1:                 episode reward: -0.1915,                 loss: 0.2260
Episode: 1601/10000 (16.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8723s / 61.8810 s
agent0:                 episode reward: 0.4546,                 loss: nan
agent1:                 episode reward: -0.4546,                 loss: 0.2244
Episode: 1621/10000 (16.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8547s / 62.7357 s
agent0:                 episode reward: 0.7855,                 loss: nan
agent1:                 episode reward: -0.7855,                 loss: 0.2220
Episode: 1641/10000 (16.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8810s / 63.6167 s
agent0:                 episode reward: 0.5418,                 loss: nan
agent1:                 episode reward: -0.5418,                 loss: 0.2229
Episode: 1661/10000 (16.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9071s / 64.5237 s
agent0:                 episode reward: 0.6136,                 loss: nan
agent1:                 episode reward: -0.6136,                 loss: 0.2213
Episode: 1681/10000 (16.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8722s / 65.3960 s
agent0:                 episode reward: 0.5213,                 loss: nan
agent1:                 episode reward: -0.5213,                 loss: 0.2232
Episode: 1701/10000 (17.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8739s / 66.2698 s
agent0:                 episode reward: 0.2744,                 loss: nan
agent1:                 episode reward: -0.2744,                 loss: 0.2206
Episode: 1721/10000 (17.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8733s / 67.1431 s
agent0:                 episode reward: 0.4854,                 loss: nan
agent1:                 episode reward: -0.4854,                 loss: 0.2180
Episode: 1741/10000 (17.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9161s / 68.0592 s
agent0:                 episode reward: 0.1234,                 loss: nan
agent1:                 episode reward: -0.1234,                 loss: 0.2216
Episode: 1761/10000 (17.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8767s / 68.9359 s
agent0:                 episode reward: -0.1694,                 loss: nan
agent1:                 episode reward: 0.1694,                 loss: 0.2175
Episode: 1781/10000 (17.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9500s / 69.8859 s
agent0:                 episode reward: -0.3100,                 loss: nan
agent1:                 episode reward: 0.3100,                 loss: 0.2342
Episode: 1801/10000 (18.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8998s / 70.7857 s
agent0:                 episode reward: 0.6483,                 loss: nan
agent1:                 episode reward: -0.6483,                 loss: 0.2319
Episode: 1821/10000 (18.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9474s / 71.7331 s
agent0:                 episode reward: 0.4361,                 loss: nan
agent1:                 episode reward: -0.4361,                 loss: 0.2286
Episode: 1841/10000 (18.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9960s / 72.7292 s
agent0:                 episode reward: 0.3655,                 loss: nan
agent1:                 episode reward: -0.3655,                 loss: 0.2287
Episode: 1861/10000 (18.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9530s / 73.6821 s
agent0:                 episode reward: 0.1377,                 loss: nan
agent1:                 episode reward: -0.1377,                 loss: 0.2269
Episode: 1881/10000 (18.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9082s / 74.5903 s
agent0:                 episode reward: -0.2494,                 loss: nan
agent1:                 episode reward: 0.2494,                 loss: 0.2568
Episode: 1901/10000 (19.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9848s / 75.5750 s
agent0:                 episode reward: 0.1769,                 loss: nan
agent1:                 episode reward: -0.1769,                 loss: 0.2580
Episode: 1921/10000 (19.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0854s / 76.6605 s
agent0:                 episode reward: -0.3393,                 loss: nan
agent1:                 episode reward: 0.3393,                 loss: 0.2560
Episode: 1941/10000 (19.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9544s / 77.6149 s
agent0:                 episode reward: 0.0692,                 loss: nan
agent1:                 episode reward: -0.0692,                 loss: 0.2558
Episode: 1961/10000 (19.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0471s / 78.6620 s
agent0:                 episode reward: 0.2063,                 loss: nan
agent1:                 episode reward: -0.2063,                 loss: 0.2557
Episode: 1981/10000 (19.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0955s / 79.7574 s
agent0:                 episode reward: 0.2462,                 loss: nan
agent1:                 episode reward: -0.2462,                 loss: 0.2530
Episode: 2001/10000 (20.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0605s / 80.8180 s
agent0:                 episode reward: 0.4954,                 loss: nan
agent1:                 episode reward: -0.4954,                 loss: 0.2426
Episode: 2021/10000 (20.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9514s / 81.7694 s
agent0:                 episode reward: 0.0701,                 loss: nan
agent1:                 episode reward: -0.0701,                 loss: 0.2412
Episode: 2041/10000 (20.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9937s / 82.7631 s
agent0:                 episode reward: 0.5344,                 loss: nan
agent1:                 episode reward: -0.5344,                 loss: 0.2408
Episode: 2061/10000 (20.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9492s / 83.7123 s
agent0:                 episode reward: 0.9042,                 loss: nan
agent1:                 episode reward: -0.9042,                 loss: 0.2411
Episode: 2081/10000 (20.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0697s / 84.7820 s
agent0:                 episode reward: -0.0494,                 loss: nan
agent1:                 episode reward: 0.0494,                 loss: 0.1811
Episode: 2101/10000 (21.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9807s / 85.7627 s
agent0:                 episode reward: 0.4975,                 loss: nan
agent1:                 episode reward: -0.4975,                 loss: 0.1609
Episode: 2121/10000 (21.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9392s / 86.7019 s
agent0:                 episode reward: -0.0764,                 loss: nan
agent1:                 episode reward: 0.0764,                 loss: 0.1601
Episode: 2141/10000 (21.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0025s / 87.7045 s
agent0:                 episode reward: -0.3946,                 loss: nan
agent1:                 episode reward: 0.3946,                 loss: 0.1606
Episode: 2161/10000 (21.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9954s / 88.6999 s
agent0:                 episode reward: -0.0759,                 loss: nan
agent1:                 episode reward: 0.0759,                 loss: 0.1604
Episode: 2181/10000 (21.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9552s / 89.6551 s
agent0:                 episode reward: 0.0852,                 loss: nan
agent1:                 episode reward: -0.0852,                 loss: 0.1526
Episode: 2201/10000 (22.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9869s / 90.6420 s
agent0:                 episode reward: -0.3269,                 loss: nan
agent1:                 episode reward: 0.3269,                 loss: 0.1468
Episode: 2221/10000 (22.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0195s / 91.6615 s
agent0:                 episode reward: -0.3604,                 loss: nan
agent1:                 episode reward: 0.3604,                 loss: 0.1458
Episode: 2241/10000 (22.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9480s / 92.6095 s
agent0:                 episode reward: 0.7928,                 loss: nan
agent1:                 episode reward: -0.7928,                 loss: 0.1466
Episode: 2261/10000 (22.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9411s / 93.5506 s
agent0:                 episode reward: -0.3118,                 loss: nan
agent1:                 episode reward: 0.3118,                 loss: 0.1452
Episode: 2281/10000 (22.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9609s / 94.5115 s
agent0:                 episode reward: 0.1997,                 loss: nan
agent1:                 episode reward: -0.1997,                 loss: 0.1670
Episode: 2301/10000 (23.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9595s / 95.4710 s
agent0:                 episode reward: -0.5712,                 loss: nan
agent1:                 episode reward: 0.5712,                 loss: 0.1696
Episode: 2321/10000 (23.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9461s / 96.4171 s
agent0:                 episode reward: 0.0749,                 loss: nan
agent1:                 episode reward: -0.0749,                 loss: 0.1691
Episode: 2341/10000 (23.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9781s / 97.3952 s
agent0:                 episode reward: -0.0242,                 loss: nan
agent1:                 episode reward: 0.0242,                 loss: 0.1696
Episode: 2361/10000 (23.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9604s / 98.3556 s
agent0:                 episode reward: -0.7909,                 loss: nan
agent1:                 episode reward: 0.7909,                 loss: 0.1685
Episode: 2381/10000 (23.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9990s / 99.3546 s
agent0:                 episode reward: -0.1881,                 loss: nan
agent1:                 episode reward: 0.1881,                 loss: 0.1956
Episode: 2401/10000 (24.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0276s / 100.3823 s
agent0:                 episode reward: 0.7861,                 loss: nan
agent1:                 episode reward: -0.7861,                 loss: 0.1983
Episode: 2421/10000 (24.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0780s / 101.4603 s
agent0:                 episode reward: 0.0355,                 loss: nan
agent1:                 episode reward: -0.0355,                 loss: 0.1974
Episode: 2441/10000 (24.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1405s / 102.6008 s
agent0:                 episode reward: 0.2018,                 loss: nan
agent1:                 episode reward: -0.2018,                 loss: 0.1950
Episode: 2461/10000 (24.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1430s / 103.7437 s
agent0:                 episode reward: -0.9706,                 loss: nan
agent1:                 episode reward: 0.9706,                 loss: 0.1952
Episode: 2481/10000 (24.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9637s / 104.7074 s
agent0:                 episode reward: -0.2331,                 loss: nan
agent1:                 episode reward: 0.2331,                 loss: 0.2320
Episode: 2501/10000 (25.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9944s / 105.7018 s
agent0:                 episode reward: 0.0906,                 loss: nan
agent1:                 episode reward: -0.0906,                 loss: 0.2374
Episode: 2521/10000 (25.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9819s / 106.6837 s
agent0:                 episode reward: 0.5622,                 loss: nan
agent1:                 episode reward: -0.5622,                 loss: 0.2368
Episode: 2541/10000 (25.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9808s / 107.6645 s
agent0:                 episode reward: 0.0702,                 loss: nan
agent1:                 episode reward: -0.0702,                 loss: 0.2353
Episode: 2561/10000 (25.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9841s / 108.6486 s
agent0:                 episode reward: -0.4213,                 loss: nan
agent1:                 episode reward: 0.4213,                 loss: 0.2333
Episode: 2581/10000 (25.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9828s / 109.6313 s
agent0:                 episode reward: -0.0779,                 loss: nan
agent1:                 episode reward: 0.0779,                 loss: 0.2436
Episode: 2601/10000 (26.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0544s / 110.6857 s
agent0:                 episode reward: 1.1828,                 loss: nan
agent1:                 episode reward: -1.1828,                 loss: 0.2432
Episode: 2621/10000 (26.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0246s / 111.7103 s
agent0:                 episode reward: 0.2972,                 loss: nan
agent1:                 episode reward: -0.2972,                 loss: 0.2407
Episode: 2641/10000 (26.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9805s / 112.6909 s
agent0:                 episode reward: 0.2655,                 loss: nan
agent1:                 episode reward: -0.2655,                 loss: 0.2427
Episode: 2661/10000 (26.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9927s / 113.6836 s
agent0:                 episode reward: -0.0043,                 loss: nan
agent1:                 episode reward: 0.0043,                 loss: 0.2432
Episode: 2681/10000 (26.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9933s / 114.6769 s
agent0:                 episode reward: 0.3275,                 loss: nan
agent1:                 episode reward: -0.3275,                 loss: 0.2552
Episode: 2701/10000 (27.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9943s / 115.6713 s
agent0:                 episode reward: 0.7979,                 loss: nan
agent1:                 episode reward: -0.7979,                 loss: 0.2555
Episode: 2721/10000 (27.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9729s / 116.6442 s
agent0:                 episode reward: 0.3890,                 loss: nan
agent1:                 episode reward: -0.3890,                 loss: 0.2560
Episode: 2741/10000 (27.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9832s / 117.6274 s
agent0:                 episode reward: -0.3719,                 loss: nan
agent1:                 episode reward: 0.3719,                 loss: 0.2553
Episode: 2761/10000 (27.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9937s / 118.6211 s
agent0:                 episode reward: 0.0056,                 loss: nan
agent1:                 episode reward: -0.0056,                 loss: 0.2534
Episode: 2781/10000 (27.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9760s / 119.5971 s
agent0:                 episode reward: -0.5727,                 loss: nan
agent1:                 episode reward: 0.5727,                 loss: 0.2920
Episode: 2801/10000 (28.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0034s / 120.6005 s
agent0:                 episode reward: -0.0195,                 loss: nan
agent1:                 episode reward: 0.0195,                 loss: 0.2908
Episode: 2821/10000 (28.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0290s / 121.6295 s
agent0:                 episode reward: -0.3111,                 loss: nan
agent1:                 episode reward: 0.3111,                 loss: 0.2937
Episode: 2841/10000 (28.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0529s / 122.6824 s
agent0:                 episode reward: 0.5934,                 loss: nan
agent1:                 episode reward: -0.5934,                 loss: 0.2903
Episode: 2861/10000 (28.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0075s / 123.6899 s
agent0:                 episode reward: -0.2769,                 loss: nan
agent1:                 episode reward: 0.2769,                 loss: 0.2894
Episode: 2881/10000 (28.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0265s / 124.7164 s
agent0:                 episode reward: 0.3573,                 loss: nan
agent1:                 episode reward: -0.3573,                 loss: 0.2869
Episode: 2901/10000 (29.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9956s / 125.7120 s
agent0:                 episode reward: 0.2779,                 loss: nan
agent1:                 episode reward: -0.2779,                 loss: 0.2823
Episode: 2921/10000 (29.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0278s / 126.7398 s
agent0:                 episode reward: -0.5826,                 loss: nan
agent1:                 episode reward: 0.5826,                 loss: 0.2811
Episode: 2941/10000 (29.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0269s / 127.7667 s
agent0:                 episode reward: -1.0848,                 loss: nan
agent1:                 episode reward: 1.0848,                 loss: 0.2822
Episode: 2961/10000 (29.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0256s / 128.7923 s
agent0:                 episode reward: -0.3082,                 loss: nan
agent1:                 episode reward: 0.3082,                 loss: 0.2806
Episode: 2981/10000 (29.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0108s / 129.8032 s
agent0:                 episode reward: -0.3386,                 loss: nan
agent1:                 episode reward: 0.3386,                 loss: 0.2637
Episode: 3001/10000 (30.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0927s / 130.8959 s
agent0:                 episode reward: -0.0915,                 loss: nan
agent1:                 episode reward: 0.0915,                 loss: 0.2521
Episode: 3021/10000 (30.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0359s / 131.9318 s
agent0:                 episode reward: -0.1026,                 loss: nan
agent1:                 episode reward: 0.1026,                 loss: 0.2513
Episode: 3041/10000 (30.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0309s / 132.9627 s
agent0:                 episode reward: -0.2248,                 loss: nan
agent1:                 episode reward: 0.2248,                 loss: 0.2485
Episode: 3061/10000 (30.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0390s / 134.0017 s
agent0:                 episode reward: 0.6700,                 loss: nan
agent1:                 episode reward: -0.6700,                 loss: 0.2467
Episode: 3081/10000 (30.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0270s / 135.0287 s
agent0:                 episode reward: -0.1233,                 loss: nan
agent1:                 episode reward: 0.1233,                 loss: 0.2071
Episode: 3101/10000 (31.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0068s / 136.0354 s
agent0:                 episode reward: -0.1101,                 loss: nan
agent1:                 episode reward: 0.1101,                 loss: 0.1963
Episode: 3121/10000 (31.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0358s / 137.0713 s
agent0:                 episode reward: -0.3093,                 loss: nan
agent1:                 episode reward: 0.3093,                 loss: 0.1975
Episode: 3141/10000 (31.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0254s / 138.0967 s
agent0:                 episode reward: -0.2012,                 loss: nan
agent1:                 episode reward: 0.2012,                 loss: 0.1969
Episode: 3161/10000 (31.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0570s / 139.1537 s
agent0:                 episode reward: -0.7309,                 loss: nan
agent1:                 episode reward: 0.7309,                 loss: 0.1948
Episode: 3181/10000 (31.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0453s / 140.1990 s
agent0:                 episode reward: -0.1850,                 loss: nan
agent1:                 episode reward: 0.1850,                 loss: 0.1749
Episode: 3201/10000 (32.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0554s / 141.2544 s
agent0:                 episode reward: -0.3965,                 loss: nan
agent1:                 episode reward: 0.3965,                 loss: 0.1690
Episode: 3221/10000 (32.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0319s / 142.2863 s
agent0:                 episode reward: -0.2383,                 loss: nan
agent1:                 episode reward: 0.2383,                 loss: 0.1692
Episode: 3241/10000 (32.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0429s / 143.3292 s
agent0:                 episode reward: 0.6301,                 loss: nan
agent1:                 episode reward: -0.6301,                 loss: 0.1682
Episode: 3261/10000 (32.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0409s / 144.3701 s
agent0:                 episode reward: -0.4919,                 loss: nan
agent1:                 episode reward: 0.4919,                 loss: 0.1658
Episode: 3281/10000 (32.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0449s / 145.4149 s
agent0:                 episode reward: -0.6595,                 loss: nan
agent1:                 episode reward: 0.6595,                 loss: 0.1806
Episode: 3301/10000 (33.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0488s / 146.4638 s
agent0:                 episode reward: -1.0968,                 loss: nan
agent1:                 episode reward: 1.0968,                 loss: 0.1783
Episode: 3321/10000 (33.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0630s / 147.5268 s
agent0:                 episode reward: -0.7264,                 loss: nan
agent1:                 episode reward: 0.7264,                 loss: 0.1793
Episode: 3341/10000 (33.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0392s / 148.5659 s
agent0:                 episode reward: -0.1029,                 loss: nan
agent1:                 episode reward: 0.1029,                 loss: 0.1774
Episode: 3361/10000 (33.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0601s / 149.6261 s
agent0:                 episode reward: 0.2260,                 loss: nan
agent1:                 episode reward: -0.2260,                 loss: 0.1771
Episode: 3381/10000 (33.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0392s / 150.6653 s
agent0:                 episode reward: -0.8847,                 loss: nan
agent1:                 episode reward: 0.8847,                 loss: 0.1923
Episode: 3401/10000 (34.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0977s / 151.7630 s
agent0:                 episode reward: -0.2883,                 loss: nan
agent1:                 episode reward: 0.2883,                 loss: 0.1936
Episode: 3421/10000 (34.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0492s / 152.8122 s
agent0:                 episode reward: 0.1353,                 loss: nan
agent1:                 episode reward: -0.1353,                 loss: 0.1947
Episode: 3441/10000 (34.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0531s / 153.8653 s
agent0:                 episode reward: -0.1430,                 loss: nan
agent1:                 episode reward: 0.1430,                 loss: 0.1928
Episode: 3461/10000 (34.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0614s / 154.9267 s
agent0:                 episode reward: 0.5623,                 loss: nan
agent1:                 episode reward: -0.5623,                 loss: 0.1928
Episode: 3481/10000 (34.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0736s / 156.0003 s
agent0:                 episode reward: -0.4609,                 loss: nan
agent1:                 episode reward: 0.4609,                 loss: 0.2211
Episode: 3501/10000 (35.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0435s / 157.0438 s
agent0:                 episode reward: -0.0700,                 loss: nan
agent1:                 episode reward: 0.0700,                 loss: 0.2255
Episode: 3521/10000 (35.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0547s / 158.0985 s
agent0:                 episode reward: -0.6311,                 loss: nan
agent1:                 episode reward: 0.6311,                 loss: 0.2236
Episode: 3541/10000 (35.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0624s / 159.1609 s
agent0:                 episode reward: -0.1362,                 loss: nan
agent1:                 episode reward: 0.1362,                 loss: 0.2225
Episode: 3561/10000 (35.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0514s / 160.2123 s
agent0:                 episode reward: -0.4610,                 loss: nan
agent1:                 episode reward: 0.4610,                 loss: 0.2248
Episode: 3581/10000 (35.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0619s / 161.2742 s
agent0:                 episode reward: -0.1991,                 loss: nan
agent1:                 episode reward: 0.1991,                 loss: 0.2551
Episode: 3601/10000 (36.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1514s / 162.4255 s
agent0:                 episode reward: -0.0342,                 loss: nan
agent1:                 episode reward: 0.0342,                 loss: 0.2575
Episode: 3621/10000 (36.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0902s / 163.5157 s
agent0:                 episode reward: -0.0516,                 loss: nan
agent1:                 episode reward: 0.0516,                 loss: 0.2547
Episode: 3641/10000 (36.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0860s / 164.6017 s
agent0:                 episode reward: -0.1605,                 loss: nan
agent1:                 episode reward: 0.1605,                 loss: 0.2518
Episode: 3661/10000 (36.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0889s / 165.6907 s
agent0:                 episode reward: 0.0431,                 loss: nan
agent1:                 episode reward: -0.0431,                 loss: 0.2525
Episode: 3681/10000 (36.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0840s / 166.7747 s
agent0:                 episode reward: -0.3244,                 loss: nan
agent1:                 episode reward: 0.3244,                 loss: 0.2616
Episode: 3701/10000 (37.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0963s / 167.8710 s
agent0:                 episode reward: -0.0752,                 loss: nan
agent1:                 episode reward: 0.0752,                 loss: 0.2593
Episode: 3721/10000 (37.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0890s / 168.9600 s
agent0:                 episode reward: -0.3232,                 loss: nan
agent1:                 episode reward: 0.3232,                 loss: 0.2598
Episode: 3741/10000 (37.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1025s / 170.0625 s
agent0:                 episode reward: -0.8111,                 loss: nan
agent1:                 episode reward: 0.8111,                 loss: 0.2569
Episode: 3761/10000 (37.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0817s / 171.1442 s
agent0:                 episode reward: 0.0627,                 loss: nan
agent1:                 episode reward: -0.0627,                 loss: 0.2570
Episode: 3781/10000 (37.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1877s / 172.3320 s
agent0:                 episode reward: -0.1213,                 loss: nan
agent1:                 episode reward: 0.1213,                 loss: 0.2661
Episode: 3801/10000 (38.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1060s / 173.4380 s
agent0:                 episode reward: -0.0626,                 loss: nan
agent1:                 episode reward: 0.0626,                 loss: 0.2606
Episode: 3821/10000 (38.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0863s / 174.5243 s
agent0:                 episode reward: 0.0308,                 loss: nan
agent1:                 episode reward: -0.0308,                 loss: 0.2595
Episode: 3841/10000 (38.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0883s / 175.6127 s
agent0:                 episode reward: -0.6046,                 loss: nan
agent1:                 episode reward: 0.6046,                 loss: 0.2598
Episode: 3861/10000 (38.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1003s / 176.7130 s
agent0:                 episode reward: -0.3881,                 loss: nan
agent1:                 episode reward: 0.3881,                 loss: 0.2601
Episode: 3881/10000 (38.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1330s / 177.8460 s
agent0:                 episode reward: -0.3524,                 loss: nan
agent1:                 episode reward: 0.3524,                 loss: 0.2548
Episode: 3901/10000 (39.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1025s / 178.9485 s
agent0:                 episode reward: -0.1178,                 loss: nan
agent1:                 episode reward: 0.1178,                 loss: 0.2471
Episode: 3921/10000 (39.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1477s / 180.0961 s
agent0:                 episode reward: -0.2602,                 loss: nan
agent1:                 episode reward: 0.2602,                 loss: 0.2435
Episode: 3941/10000 (39.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1211s / 181.2172 s
agent0:                 episode reward: -0.3068,                 loss: nan
agent1:                 episode reward: 0.3068,                 loss: 0.2443
Episode: 3961/10000 (39.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1805s / 182.3977 s
agent0:                 episode reward: 0.0767,                 loss: nan
agent1:                 episode reward: -0.0767,                 loss: 0.2435
Episode: 3981/10000 (39.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1178s / 183.5156 s
agent0:                 episode reward: 0.3753,                 loss: nan
agent1:                 episode reward: -0.3753,                 loss: 0.1731
Episode: 4001/10000 (40.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1088s / 184.6243 s
agent0:                 episode reward: 1.0116,                 loss: nan
agent1:                 episode reward: -1.0116,                 loss: 0.1510
Episode: 4021/10000 (40.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1330s / 185.7574 s
agent0:                 episode reward: -0.7802,                 loss: nan
agent1:                 episode reward: 0.7802,                 loss: 0.1527
Episode: 4041/10000 (40.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1227s / 186.8800 s
agent0:                 episode reward: -0.0703,                 loss: nan
agent1:                 episode reward: 0.0703,                 loss: 0.1504
Episode: 4061/10000 (40.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1391s / 188.0192 s
agent0:                 episode reward: -0.2025,                 loss: nan
agent1:                 episode reward: 0.2025,                 loss: 0.1514
Episode: 4081/10000 (40.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1399s / 189.1591 s
agent0:                 episode reward: -0.7102,                 loss: nan
agent1:                 episode reward: 0.7102,                 loss: 0.1353
Episode: 4101/10000 (41.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1378s / 190.2969 s
agent0:                 episode reward: -0.0591,                 loss: nan
agent1:                 episode reward: 0.0591,                 loss: 0.1281
Episode: 4121/10000 (41.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1244s / 191.4213 s
agent0:                 episode reward: 0.7030,                 loss: nan
agent1:                 episode reward: -0.7030,                 loss: 0.1261
Episode: 4141/10000 (41.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1808s / 192.6021 s
agent0:                 episode reward: 0.5319,                 loss: nan
agent1:                 episode reward: -0.5319,                 loss: 0.1246
Episode: 4161/10000 (41.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1561s / 193.7581 s
agent0:                 episode reward: -0.6658,                 loss: nan
agent1:                 episode reward: 0.6658,                 loss: 0.1237
Episode: 4181/10000 (41.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1356s / 194.8937 s
agent0:                 episode reward: -0.3522,                 loss: nan
agent1:                 episode reward: 0.3522,                 loss: 0.1582
Episode: 4201/10000 (42.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1350s / 196.0288 s
agent0:                 episode reward: -0.4204,                 loss: nan
agent1:                 episode reward: 0.4204,                 loss: 0.1588
Episode: 4221/10000 (42.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1897s / 197.2184 s
agent0:                 episode reward: -0.2649,                 loss: nan
agent1:                 episode reward: 0.2649,                 loss: 0.1598
Episode: 4241/10000 (42.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1263s / 198.3448 s
agent0:                 episode reward: -0.0406,                 loss: nan
agent1:                 episode reward: 0.0406,                 loss: 0.1591
Episode: 4261/10000 (42.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1537s / 199.4985 s
agent0:                 episode reward: -1.0866,                 loss: nan
agent1:                 episode reward: 1.0866,                 loss: 0.1597
Episode: 4281/10000 (42.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1576s / 200.6561 s
agent0:                 episode reward: -0.7240,                 loss: nan
agent1:                 episode reward: 0.7240,                 loss: 0.1896
Episode: 4301/10000 (43.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1451s / 201.8012 s
agent0:                 episode reward: -0.6903,                 loss: nan
agent1:                 episode reward: 0.6903,                 loss: 0.1878
Episode: 4321/10000 (43.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2184s / 203.0196 s
agent0:                 episode reward: -0.4493,                 loss: nan
agent1:                 episode reward: 0.4493,                 loss: 0.1857
Episode: 4341/10000 (43.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1511s / 204.1707 s
agent0:                 episode reward: -0.4706,                 loss: nan
agent1:                 episode reward: 0.4706,                 loss: 0.1851
Episode: 4361/10000 (43.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1754s / 205.3461 s
agent0:                 episode reward: -0.2632,                 loss: nan
agent1:                 episode reward: 0.2632,                 loss: 0.1812
Episode: 4381/10000 (43.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1757s / 206.5218 s
agent0:                 episode reward: -0.2968,                 loss: nan
agent1:                 episode reward: 0.2968,                 loss: 0.2229
Episode: 4401/10000 (44.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1584s / 207.6802 s
agent0:                 episode reward: -0.1931,                 loss: nan
agent1:                 episode reward: 0.1931,                 loss: 0.2216
Episode: 4421/10000 (44.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1759s / 208.8561 s
agent0:                 episode reward: -1.3408,                 loss: nan
agent1:                 episode reward: 1.3408,                 loss: 0.2198
Episode: 4441/10000 (44.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1871s / 210.0432 s
agent0:                 episode reward: -0.2480,                 loss: nan
agent1:                 episode reward: 0.2480,                 loss: 0.2191
Episode: 4461/10000 (44.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1749s / 211.2182 s
agent0:                 episode reward: -0.7956,                 loss: nan
agent1:                 episode reward: 0.7956,                 loss: 0.2189
Episode: 4481/10000 (44.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1883s / 212.4065 s
agent0:                 episode reward: -0.8198,                 loss: nan
agent1:                 episode reward: 0.8198,                 loss: 0.2297
Episode: 4501/10000 (45.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2594s / 213.6659 s
agent0:                 episode reward: -0.4558,                 loss: nan
agent1:                 episode reward: 0.4558,                 loss: 0.2304
Episode: 4521/10000 (45.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1781s / 214.8440 s
agent0:                 episode reward: -0.4079,                 loss: nan
agent1:                 episode reward: 0.4079,                 loss: 0.2305
Episode: 4541/10000 (45.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1895s / 216.0334 s
agent0:                 episode reward: -0.2559,                 loss: nan
agent1:                 episode reward: 0.2559,                 loss: 0.2307
Episode: 4561/10000 (45.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1911s / 217.2245 s
agent0:                 episode reward: -0.9919,                 loss: nan
agent1:                 episode reward: 0.9919,                 loss: 0.2306
Episode: 4581/10000 (45.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1796s / 218.4041 s
agent0:                 episode reward: -0.8042,                 loss: nan
agent1:                 episode reward: 0.8042,                 loss: 0.2495
Episode: 4601/10000 (46.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1842s / 219.5883 s
agent0:                 episode reward: -0.7631,                 loss: nan
agent1:                 episode reward: 0.7631,                 loss: 0.2501
Episode: 4621/10000 (46.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1938s / 220.7821 s
agent0:                 episode reward: -0.6786,                 loss: nan
agent1:                 episode reward: 0.6786,                 loss: 0.2485
Episode: 4641/10000 (46.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2409s / 222.0230 s
agent0:                 episode reward: -0.3811,                 loss: nan
agent1:                 episode reward: 0.3811,                 loss: 0.2468
Episode: 4661/10000 (46.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2701s / 223.2931 s
agent0:                 episode reward: -0.4690,                 loss: nan
agent1:                 episode reward: 0.4690,                 loss: 0.2449
Episode: 4681/10000 (46.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2073s / 224.5004 s
agent0:                 episode reward: -0.0881,                 loss: nan
agent1:                 episode reward: 0.0881,                 loss: 0.2616
Episode: 4701/10000 (47.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2145s / 225.7149 s
agent0:                 episode reward: -1.1589,                 loss: nan
agent1:                 episode reward: 1.1589,                 loss: 0.2586
Episode: 4721/10000 (47.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2245s / 226.9394 s
agent0:                 episode reward: -0.9309,                 loss: nan
agent1:                 episode reward: 0.9309,                 loss: 0.2560
Episode: 4741/10000 (47.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2111s / 228.1505 s
agent0:                 episode reward: 0.2012,                 loss: nan
agent1:                 episode reward: -0.2012,                 loss: 0.2549
Episode: 4761/10000 (47.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2158s / 229.3663 s
agent0:                 episode reward: -0.7341,                 loss: nan
agent1:                 episode reward: 0.7341,                 loss: 0.2544
Episode: 4781/10000 (47.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2427s / 230.6090 s
agent0:                 episode reward: -0.5344,                 loss: nan
agent1:                 episode reward: 0.5344,                 loss: 0.2493
Episode: 4801/10000 (48.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2072s / 231.8162 s
agent0:                 episode reward: -1.2520,                 loss: nan
agent1:                 episode reward: 1.2520,                 loss: 0.2459
Episode: 4821/10000 (48.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2095s / 233.0257 s
agent0:                 episode reward: -0.2094,                 loss: nan
agent1:                 episode reward: 0.2094,                 loss: 0.2424
Episode: 4841/10000 (48.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2645s / 234.2902 s
agent0:                 episode reward: -0.5007,                 loss: nan
agent1:                 episode reward: 0.5007,                 loss: 0.2429
Episode: 4861/10000 (48.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2125s / 235.5028 s
agent0:                 episode reward: -0.8601,                 loss: nan
agent1:                 episode reward: 0.8601,                 loss: 0.2417
Episode: 4881/10000 (48.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2197s / 236.7225 s
agent0:                 episode reward: -0.4287,                 loss: nan
agent1:                 episode reward: 0.4287,                 loss: 0.2077
Episode: 4901/10000 (49.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2138s / 237.9363 s
agent0:                 episode reward: -0.6187,                 loss: nan
agent1:                 episode reward: 0.6187,                 loss: 0.1971
Episode: 4921/10000 (49.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2706s / 239.2068 s
agent0:                 episode reward: -0.5144,                 loss: nan
agent1:                 episode reward: 0.5144,                 loss: 0.1966
Episode: 4941/10000 (49.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2402s / 240.4470 s
agent0:                 episode reward: -0.6514,                 loss: nan
agent1:                 episode reward: 0.6514,                 loss: 0.1943
Episode: 4961/10000 (49.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2189s / 241.6659 s
agent0:                 episode reward: -0.3484,                 loss: nan
agent1:                 episode reward: 0.3484,                 loss: 0.1959
Episode: 4981/10000 (49.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2220s / 242.8879 s
agent0:                 episode reward: -0.1881,                 loss: nan
agent1:                 episode reward: 0.1881,                 loss: 0.1403
Episode: 5001/10000 (50.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3351s / 244.2230 s
agent0:                 episode reward: -1.7262,                 loss: nan
agent1:                 episode reward: 1.7262,                 loss: 0.1213
Episode: 5021/10000 (50.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2434s / 245.4664 s
agent0:                 episode reward: -0.0648,                 loss: nan
agent1:                 episode reward: 0.0648,                 loss: 0.1198
Episode: 5041/10000 (50.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2540s / 246.7203 s
agent0:                 episode reward: -0.6174,                 loss: nan
agent1:                 episode reward: 0.6174,                 loss: 0.1210
Episode: 5061/10000 (50.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2256s / 247.9459 s
agent0:                 episode reward: -0.5151,                 loss: nan
agent1:                 episode reward: 0.5151,                 loss: 0.1196
Episode: 5081/10000 (50.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2136s / 249.1595 s
agent0:                 episode reward: -0.5032,                 loss: nan
agent1:                 episode reward: 0.5032,                 loss: 0.1395
Episode: 5101/10000 (51.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2393s / 250.3988 s
agent0:                 episode reward: 0.0109,                 loss: nan
agent1:                 episode reward: -0.0109,                 loss: 0.1351
Episode: 5121/10000 (51.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2185s / 251.6173 s
agent0:                 episode reward: -0.8499,                 loss: nan
agent1:                 episode reward: 0.8499,                 loss: 0.1359
Episode: 5141/10000 (51.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2534s / 252.8708 s
agent0:                 episode reward: -0.6644,                 loss: nan
agent1:                 episode reward: 0.6644,                 loss: 0.1349
Episode: 5161/10000 (51.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3140s / 254.1848 s
agent0:                 episode reward: -1.6973,                 loss: nan
agent1:                 episode reward: 1.6973,                 loss: 0.1375
Episode: 5181/10000 (51.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2643s / 255.4491 s
agent0:                 episode reward: -0.6189,                 loss: nan
agent1:                 episode reward: 0.6189,                 loss: 0.1765
Episode: 5201/10000 (52.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2476s / 256.6966 s
agent0:                 episode reward: -0.0906,                 loss: nan
agent1:                 episode reward: 0.0906,                 loss: 0.1764
Episode: 5221/10000 (52.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2542s / 257.9508 s
agent0:                 episode reward: -1.1079,                 loss: nan
agent1:                 episode reward: 1.1079,                 loss: 0.1764
Episode: 5241/10000 (52.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2512s / 259.2020 s
agent0:                 episode reward: -0.8201,                 loss: nan
agent1:                 episode reward: 0.8201,                 loss: 0.1756
Episode: 5261/10000 (52.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2606s / 260.4626 s
agent0:                 episode reward: -0.2160,                 loss: nan
agent1:                 episode reward: 0.2160,                 loss: 0.1746
Episode: 5281/10000 (52.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2612s / 261.7238 s
agent0:                 episode reward: -1.0746,                 loss: nan
agent1:                 episode reward: 1.0746,                 loss: 0.2251
Episode: 5301/10000 (53.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2645s / 262.9883 s
agent0:                 episode reward: -1.1956,                 loss: nan
agent1:                 episode reward: 1.1956,                 loss: 0.2184
Episode: 5321/10000 (53.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2943s / 264.2825 s
agent0:                 episode reward: -0.6450,                 loss: nan
agent1:                 episode reward: 0.6450,                 loss: 0.2197
Episode: 5341/10000 (53.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2578s / 265.5403 s
agent0:                 episode reward: -1.4787,                 loss: nan
agent1:                 episode reward: 1.4787,                 loss: 0.2183
Episode: 5361/10000 (53.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2678s / 266.8081 s
agent0:                 episode reward: -1.2511,                 loss: nan
agent1:                 episode reward: 1.2511,                 loss: 0.2197
Episode: 5381/10000 (53.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2673s / 268.0754 s
agent0:                 episode reward: -0.8479,                 loss: nan
agent1:                 episode reward: 0.8479,                 loss: 0.2391
Episode: 5401/10000 (54.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2729s / 269.3483 s
agent0:                 episode reward: -0.9333,                 loss: nan
agent1:                 episode reward: 0.9333,                 loss: 0.2339
Episode: 5421/10000 (54.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2476s / 270.5960 s
agent0:                 episode reward: -0.4119,                 loss: nan
agent1:                 episode reward: 0.4119,                 loss: 0.2305
Episode: 5441/10000 (54.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2854s / 271.8814 s
agent0:                 episode reward: -1.2585,                 loss: nan
agent1:                 episode reward: 1.2585,                 loss: 0.2309
Episode: 5461/10000 (54.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2801s / 273.1614 s
agent0:                 episode reward: -0.4515,                 loss: nan
agent1:                 episode reward: 0.4515,                 loss: 0.2325
Episode: 5481/10000 (54.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3073s / 274.4687 s
agent0:                 episode reward: -0.4544,                 loss: nan
agent1:                 episode reward: 0.4544,                 loss: 0.2614
Episode: 5501/10000 (55.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2876s / 275.7563 s
agent0:                 episode reward: -0.6535,                 loss: nan
agent1:                 episode reward: 0.6535,                 loss: 0.2519
Episode: 5521/10000 (55.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2919s / 277.0482 s
agent0:                 episode reward: -1.3130,                 loss: nan
agent1:                 episode reward: 1.3130,                 loss: 0.2481
Episode: 5541/10000 (55.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2975s / 278.3457 s
agent0:                 episode reward: -1.0236,                 loss: nan
agent1:                 episode reward: 1.0236,                 loss: 0.2480
Episode: 5561/10000 (55.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3172s / 279.6629 s
agent0:                 episode reward: -1.4623,                 loss: nan
agent1:                 episode reward: 1.4623,                 loss: 0.2456
Episode: 5581/10000 (55.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2767s / 280.9396 s
agent0:                 episode reward: -0.2764,                 loss: nan
agent1:                 episode reward: 0.2764,                 loss: 0.2645
Episode: 5601/10000 (56.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3204s / 282.2600 s
agent0:                 episode reward: -0.6446,                 loss: nan
agent1:                 episode reward: 0.6446,                 loss: 0.2598
Episode: 5621/10000 (56.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2756s / 283.5356 s
agent0:                 episode reward: -1.1468,                 loss: nan
agent1:                 episode reward: 1.1468,                 loss: 0.2588
Episode: 5641/10000 (56.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3761s / 284.9118 s
agent0:                 episode reward: -0.9151,                 loss: nan
agent1:                 episode reward: 0.9151,                 loss: 0.2587
Episode: 5661/10000 (56.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2816s / 286.1934 s
agent0:                 episode reward: -0.3968,                 loss: nan
agent1:                 episode reward: 0.3968,                 loss: 0.2576
Episode: 5681/10000 (56.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2794s / 287.4728 s
agent0:                 episode reward: -0.2877,                 loss: nan
agent1:                 episode reward: 0.2877,                 loss: 0.2222
Episode: 5701/10000 (57.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3267s / 288.7995 s
agent0:                 episode reward: -0.6056,                 loss: nan
agent1:                 episode reward: 0.6056,                 loss: 0.2084
Episode: 5721/10000 (57.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3265s / 290.1260 s
agent0:                 episode reward: -0.1869,                 loss: nan
agent1:                 episode reward: 0.1869,                 loss: 0.2053
Episode: 5741/10000 (57.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3157s / 291.4417 s
agent0:                 episode reward: -0.4907,                 loss: nan
agent1:                 episode reward: 0.4907,                 loss: 0.2070
Episode: 5761/10000 (57.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3379s / 292.7796 s
agent0:                 episode reward: -1.2453,                 loss: nan
agent1:                 episode reward: 1.2453,                 loss: 0.2045
Episode: 5781/10000 (57.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3033s / 294.0829 s
agent0:                 episode reward: -0.6177,                 loss: nan
agent1:                 episode reward: 0.6177,                 loss: 0.1654
Episode: 5801/10000 (58.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3574s / 295.4403 s
agent0:                 episode reward: -0.3260,                 loss: nan
agent1:                 episode reward: 0.3260,                 loss: 0.1500
Episode: 5821/10000 (58.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3187s / 296.7590 s
agent0:                 episode reward: -0.8075,                 loss: nan
agent1:                 episode reward: 0.8075,                 loss: 0.1511
Episode: 5841/10000 (58.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3476s / 298.1066 s
agent0:                 episode reward: -0.1974,                 loss: nan
agent1:                 episode reward: 0.1974,                 loss: 0.1509
Episode: 5861/10000 (58.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3552s / 299.4618 s
agent0:                 episode reward: -0.4678,                 loss: nan
agent1:                 episode reward: 0.4678,                 loss: 0.1497
Episode: 5881/10000 (58.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3059s / 300.7676 s
agent0:                 episode reward: -1.5122,                 loss: nan
agent1:                 episode reward: 1.5122,                 loss: 0.1318
Episode: 5901/10000 (59.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3156s / 302.0832 s
agent0:                 episode reward: 0.0252,                 loss: nan
agent1:                 episode reward: -0.0252,                 loss: 0.1220
Episode: 5921/10000 (59.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2975s / 303.3807 s
agent0:                 episode reward: -1.0980,                 loss: nan
agent1:                 episode reward: 1.0980,                 loss: 0.1204
Episode: 5941/10000 (59.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3164s / 304.6972 s
agent0:                 episode reward: -1.0111,                 loss: nan
agent1:                 episode reward: 1.0111,                 loss: 0.1219
Episode: 5961/10000 (59.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3837s / 306.0808 s
agent0:                 episode reward: -1.0744,                 loss: nan
agent1:                 episode reward: 1.0744,                 loss: 0.1196
Episode: 5981/10000 (59.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3257s / 307.4066 s
agent0:                 episode reward: 0.2532,                 loss: nan
agent1:                 episode reward: -0.2532,                 loss: 0.1625
Episode: 6001/10000 (60.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3435s / 308.7500 s
agent0:                 episode reward: -0.3833,                 loss: nan
agent1:                 episode reward: 0.3833,                 loss: 0.1658
Episode: 6021/10000 (60.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3378s / 310.0878 s
agent0:                 episode reward: -1.3291,                 loss: nan
agent1:                 episode reward: 1.3291,                 loss: 0.1668
Episode: 6041/10000 (60.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3341s / 311.4220 s
agent0:                 episode reward: -1.0368,                 loss: nan
agent1:                 episode reward: 1.0368,                 loss: 0.1663
Episode: 6061/10000 (60.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3390s / 312.7610 s
agent0:                 episode reward: -0.8300,                 loss: nan
agent1:                 episode reward: 0.8300,                 loss: 0.1664
Episode: 6081/10000 (60.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3425s / 314.1035 s
agent0:                 episode reward: -0.3910,                 loss: nan
agent1:                 episode reward: 0.3910,                 loss: 0.1956
Episode: 6101/10000 (61.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4002s / 315.5037 s
agent0:                 episode reward: -0.9022,                 loss: nan
agent1:                 episode reward: 0.9022,                 loss: 0.2007
Episode: 6121/10000 (61.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3372s / 316.8409 s
agent0:                 episode reward: -0.1068,                 loss: nan
agent1:                 episode reward: 0.1068,                 loss: 0.1979
Episode: 6141/10000 (61.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3627s / 318.2035 s
agent0:                 episode reward: -0.9132,                 loss: nan
agent1:                 episode reward: 0.9132,                 loss: 0.1978
Episode: 6161/10000 (61.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3426s / 319.5461 s
agent0:                 episode reward: -0.8439,                 loss: nan
agent1:                 episode reward: 0.8439,                 loss: 0.1967
Episode: 6181/10000 (61.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3509s / 320.8970 s
agent0:                 episode reward: -0.5968,                 loss: nan
agent1:                 episode reward: 0.5968,                 loss: 0.2269
Episode: 6201/10000 (62.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3731s / 322.2701 s
agent0:                 episode reward: -0.7805,                 loss: nan
agent1:                 episode reward: 0.7805,                 loss: 0.2293
Episode: 6221/10000 (62.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3881s / 323.6582 s
agent0:                 episode reward: -1.0388,                 loss: nan
agent1:                 episode reward: 1.0388,                 loss: 0.2265
Episode: 6241/10000 (62.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5657s / 325.2239 s
agent0:                 episode reward: -0.8563,                 loss: nan
agent1:                 episode reward: 0.8563,                 loss: 0.2269
Episode: 6261/10000 (62.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4280s / 326.6519 s
agent0:                 episode reward: -1.1378,                 loss: nan
agent1:                 episode reward: 1.1378,                 loss: 0.2249
Episode: 6281/10000 (62.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3852s / 328.0371 s
agent0:                 episode reward: -1.4615,                 loss: nan
agent1:                 episode reward: 1.4615,                 loss: 0.2450
Episode: 6301/10000 (63.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4463s / 329.4835 s
agent0:                 episode reward: -0.5886,                 loss: nan
agent1:                 episode reward: 0.5886,                 loss: 0.2446
Episode: 6321/10000 (63.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3686s / 330.8521 s
agent0:                 episode reward: -0.2258,                 loss: nan
agent1:                 episode reward: 0.2258,                 loss: 0.2439
Episode: 6341/10000 (63.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3674s / 332.2195 s
agent0:                 episode reward: -0.2757,                 loss: nan
agent1:                 episode reward: 0.2757,                 loss: 0.2437
Episode: 6361/10000 (63.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3784s / 333.5980 s
agent0:                 episode reward: -1.0059,                 loss: nan
agent1:                 episode reward: 1.0059,                 loss: 0.2425
Episode: 6381/10000 (63.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3831s / 334.9810 s
agent0:                 episode reward: -0.9166,                 loss: nan
agent1:                 episode reward: 0.9166,                 loss: 0.2471
Episode: 6401/10000 (64.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4413s / 336.4224 s
agent0:                 episode reward: -0.4368,                 loss: nan
agent1:                 episode reward: 0.4368,                 loss: 0.2427
Episode: 6421/10000 (64.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4055s / 337.8279 s
agent0:                 episode reward: -0.4919,                 loss: nan
agent1:                 episode reward: 0.4919,                 loss: 0.2422
Episode: 6441/10000 (64.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3733s / 339.2012 s
agent0:                 episode reward: -0.0615,                 loss: nan
agent1:                 episode reward: 0.0615,                 loss: 0.2432
Episode: 6461/10000 (64.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3673s / 340.5685 s
agent0:                 episode reward: -0.3530,                 loss: nan
agent1:                 episode reward: 0.3530,                 loss: 0.2434
Episode: 6481/10000 (64.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4023s / 341.9708 s
agent0:                 episode reward: -0.5039,                 loss: nan
agent1:                 episode reward: 0.5039,                 loss: 0.2073
Episode: 6501/10000 (65.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3858s / 343.3566 s
agent0:                 episode reward: -1.0646,                 loss: nan
agent1:                 episode reward: 1.0646,                 loss: 0.1921
Episode: 6521/10000 (65.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4036s / 344.7603 s
agent0:                 episode reward: -1.2649,                 loss: nan
agent1:                 episode reward: 1.2649,                 loss: 0.1945
Episode: 6541/10000 (65.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4405s / 346.2008 s
agent0:                 episode reward: -0.9484,                 loss: nan
agent1:                 episode reward: 0.9484,                 loss: 0.1942
Episode: 6561/10000 (65.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4238s / 347.6247 s
agent0:                 episode reward: -0.4334,                 loss: nan
agent1:                 episode reward: 0.4334,                 loss: 0.1923
Episode: 6581/10000 (65.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3902s / 349.0149 s
agent0:                 episode reward: -0.9224,                 loss: nan
agent1:                 episode reward: 0.9224,                 loss: 0.1683
Episode: 6601/10000 (66.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4026s / 350.4175 s
agent0:                 episode reward: -1.1400,                 loss: nan
agent1:                 episode reward: 1.1400,                 loss: 0.1507
Episode: 6621/10000 (66.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4305s / 351.8480 s
agent0:                 episode reward: -0.8433,                 loss: nan
agent1:                 episode reward: 0.8433,                 loss: 0.1491
Episode: 6641/10000 (66.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3879s / 353.2359 s
agent0:                 episode reward: -1.0686,                 loss: nan
agent1:                 episode reward: 1.0686,                 loss: 0.1498
Episode: 6661/10000 (66.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3944s / 354.6303 s
agent0:                 episode reward: -0.0769,                 loss: nan
agent1:                 episode reward: 0.0769,                 loss: 0.1474
Episode: 6681/10000 (66.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3834s / 356.0137 s
agent0:                 episode reward: -0.9267,                 loss: nan
agent1:                 episode reward: 0.9267,                 loss: 0.1388
Episode: 6701/10000 (67.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5105s / 357.5242 s
agent0:                 episode reward: -0.4589,                 loss: nan
agent1:                 episode reward: 0.4589,                 loss: 0.1307
Episode: 6721/10000 (67.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4302s / 358.9544 s
agent0:                 episode reward: -1.1267,                 loss: nan
agent1:                 episode reward: 1.1267,                 loss: 0.1292
Episode: 6741/10000 (67.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4473s / 360.4017 s
agent0:                 episode reward: -0.3962,                 loss: nan
agent1:                 episode reward: 0.3962,                 loss: 0.1297
Episode: 6761/10000 (67.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4429s / 361.8446 s
agent0:                 episode reward: -0.8334,                 loss: nan
agent1:                 episode reward: 0.8334,                 loss: 0.1297
Episode: 6781/10000 (67.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4617s / 363.3063 s
agent0:                 episode reward: -1.1879,                 loss: nan
agent1:                 episode reward: 1.1879,                 loss: 0.1382
Episode: 6801/10000 (68.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4898s / 364.7961 s
agent0:                 episode reward: -0.9147,                 loss: nan
agent1:                 episode reward: 0.9147,                 loss: 0.1346
Episode: 6821/10000 (68.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4245s / 366.2206 s
agent0:                 episode reward: -0.4876,                 loss: nan
agent1:                 episode reward: 0.4876,                 loss: 0.1337
Episode: 6841/10000 (68.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4999s / 367.7204 s
agent0:                 episode reward: -0.6894,                 loss: nan
agent1:                 episode reward: 0.6894,                 loss: 0.1328
Episode: 6861/10000 (68.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4267s / 369.1471 s
agent0:                 episode reward: -0.3814,                 loss: nan
agent1:                 episode reward: 0.3814,                 loss: 0.1331
Episode: 6881/10000 (68.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4218s / 370.5690 s
agent0:                 episode reward: -0.4991,                 loss: nan
agent1:                 episode reward: 0.4991,                 loss: 0.1651
Episode: 6901/10000 (69.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4614s / 372.0304 s
agent0:                 episode reward: -0.7397,                 loss: nan
agent1:                 episode reward: 0.7397,                 loss: 0.1681
Episode: 6921/10000 (69.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4434s / 373.4738 s
agent0:                 episode reward: -1.9770,                 loss: nan
agent1:                 episode reward: 1.9770,                 loss: 0.1656
Episode: 6941/10000 (69.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4417s / 374.9155 s
agent0:                 episode reward: -1.1906,                 loss: nan
agent1:                 episode reward: 1.1906,                 loss: 0.1653
Episode: 6961/10000 (69.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4225s / 376.3380 s
agent0:                 episode reward: -0.8231,                 loss: nan
agent1:                 episode reward: 0.8231,                 loss: 0.1655
Episode: 6981/10000 (69.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4918s / 377.8298 s
agent0:                 episode reward: -1.1459,                 loss: nan
agent1:                 episode reward: 1.1459,                 loss: 0.2065
Episode: 7001/10000 (70.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4859s / 379.3158 s
agent0:                 episode reward: -0.1733,                 loss: nan
agent1:                 episode reward: 0.1733,                 loss: 0.2064
Episode: 7021/10000 (70.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4619s / 380.7776 s
agent0:                 episode reward: -0.6417,                 loss: nan
agent1:                 episode reward: 0.6417,                 loss: 0.2063
Episode: 7041/10000 (70.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4878s / 382.2654 s
agent0:                 episode reward: -1.4364,                 loss: nan
agent1:                 episode reward: 1.4364,                 loss: 0.2057
Episode: 7061/10000 (70.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4532s / 383.7186 s
agent0:                 episode reward: -2.4466,                 loss: nan
agent1:                 episode reward: 2.4466,                 loss: 0.2056
Episode: 7081/10000 (70.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4503s / 385.1690 s
agent0:                 episode reward: -0.3727,                 loss: nan
agent1:                 episode reward: 0.3727,                 loss: 0.2224
Episode: 7101/10000 (71.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5785s / 386.7475 s
agent0:                 episode reward: -1.2170,                 loss: nan
agent1:                 episode reward: 1.2170,                 loss: 0.2211
Episode: 7121/10000 (71.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6278s / 388.3753 s
agent0:                 episode reward: -1.4855,                 loss: nan
agent1:                 episode reward: 1.4855,                 loss: 0.2199
Episode: 7141/10000 (71.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5025s / 389.8778 s
agent0:                 episode reward: -1.6212,                 loss: nan
agent1:                 episode reward: 1.6212,                 loss: 0.2180
Episode: 7161/10000 (71.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4851s / 391.3629 s
agent0:                 episode reward: -1.4452,                 loss: nan
agent1:                 episode reward: 1.4452,                 loss: 0.2213
Episode: 7181/10000 (71.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4944s / 392.8573 s
agent0:                 episode reward: -0.8419,                 loss: nan
agent1:                 episode reward: 0.8419,                 loss: 0.2367
Episode: 7201/10000 (72.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4723s / 394.3296 s
agent0:                 episode reward: -0.4744,                 loss: nan
agent1:                 episode reward: 0.4744,                 loss: 0.2323
Episode: 7221/10000 (72.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4812s / 395.8107 s
agent0:                 episode reward: -0.4522,                 loss: nan
agent1:                 episode reward: 0.4522,                 loss: 0.2326
Episode: 7241/10000 (72.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4679s / 397.2786 s
agent0:                 episode reward: -1.9279,                 loss: nan
agent1:                 episode reward: 1.9279,                 loss: 0.2302
Episode: 7261/10000 (72.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6027s / 398.8813 s
agent0:                 episode reward: -0.8939,                 loss: nan
agent1:                 episode reward: 0.8939,                 loss: 0.2312
Episode: 7281/10000 (72.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4983s / 400.3795 s
agent0:                 episode reward: -1.1631,                 loss: nan
agent1:                 episode reward: 1.1631,                 loss: 0.2352
Episode: 7301/10000 (73.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5102s / 401.8897 s
agent0:                 episode reward: -0.4828,                 loss: nan
agent1:                 episode reward: 0.4828,                 loss: 0.2287
Episode: 7321/10000 (73.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5290s / 403.4187 s
agent0:                 episode reward: -1.0741,                 loss: nan
agent1:                 episode reward: 1.0741,                 loss: 0.2289
Episode: 7341/10000 (73.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5417s / 404.9605 s
agent0:                 episode reward: -1.1126,                 loss: nan
agent1:                 episode reward: 1.1126,                 loss: 0.2288
Episode: 7361/10000 (73.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5143s / 406.4748 s
agent0:                 episode reward: -0.7430,                 loss: nan
agent1:                 episode reward: 0.7430,                 loss: 0.2298
Episode: 7381/10000 (73.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5619s / 408.0366 s
agent0:                 episode reward: -1.1999,                 loss: nan
agent1:                 episode reward: 1.1999,                 loss: 0.2147
Episode: 7401/10000 (74.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5142s / 409.5509 s
agent0:                 episode reward: -1.5766,                 loss: nan
agent1:                 episode reward: 1.5766,                 loss: 0.2038
Episode: 7421/10000 (74.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5303s / 411.0812 s
agent0:                 episode reward: -1.6813,                 loss: nan
agent1:                 episode reward: 1.6813,                 loss: 0.2008
Episode: 7441/10000 (74.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5364s / 412.6175 s
agent0:                 episode reward: -0.9745,                 loss: nan
agent1:                 episode reward: 0.9745,                 loss: 0.2021
Episode: 7461/10000 (74.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5041s / 414.1216 s
agent0:                 episode reward: -0.3539,                 loss: nan
agent1:                 episode reward: 0.3539,                 loss: 0.2003
Episode: 7481/10000 (74.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5080s / 415.6296 s
agent0:                 episode reward: -0.5615,                 loss: nan
agent1:                 episode reward: 0.5615,                 loss: 0.1611
Episode: 7501/10000 (75.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5574s / 417.1869 s
agent0:                 episode reward: -0.5842,                 loss: nan
agent1:                 episode reward: 0.5842,                 loss: 0.1499
Episode: 7521/10000 (75.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6331s / 418.8200 s
agent0:                 episode reward: 0.3444,                 loss: nan
agent1:                 episode reward: -0.3444,                 loss: 0.1488
Episode: 7541/10000 (75.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5531s / 420.3731 s
agent0:                 episode reward: -0.7431,                 loss: nan
agent1:                 episode reward: 0.7431,                 loss: 0.1472
Episode: 7561/10000 (75.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5305s / 421.9036 s
agent0:                 episode reward: -1.4480,                 loss: nan
agent1:                 episode reward: 1.4480,                 loss: 0.1489
Episode: 7581/10000 (75.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5432s / 423.4467 s
agent0:                 episode reward: -0.9245,                 loss: nan
agent1:                 episode reward: 0.9245,                 loss: 0.1311
Episode: 7601/10000 (76.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5297s / 424.9765 s
agent0:                 episode reward: -0.8484,                 loss: nan
agent1:                 episode reward: 0.8484,                 loss: 0.1234
Episode: 7621/10000 (76.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5261s / 426.5026 s
agent0:                 episode reward: -0.9203,                 loss: nan
agent1:                 episode reward: 0.9203,                 loss: 0.1236
Episode: 7641/10000 (76.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5371s / 428.0397 s
agent0:                 episode reward: -0.3485,                 loss: nan
agent1:                 episode reward: 0.3485,                 loss: 0.1224
Episode: 7661/10000 (76.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6035s / 429.6432 s
agent0:                 episode reward: -0.8724,                 loss: nan
agent1:                 episode reward: 0.8724,                 loss: 0.1233
Episode: 7681/10000 (76.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5355s / 431.1788 s
agent0:                 episode reward: -2.0418,                 loss: nan
agent1:                 episode reward: 2.0418,                 loss: 0.1491
Episode: 7701/10000 (77.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5751s / 432.7538 s
agent0:                 episode reward: -0.7896,                 loss: nan
agent1:                 episode reward: 0.7896,                 loss: 0.1524
Episode: 7721/10000 (77.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5608s / 434.3147 s
agent0:                 episode reward: -0.8282,                 loss: nan
agent1:                 episode reward: 0.8282,                 loss: 0.1521
Episode: 7741/10000 (77.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5699s / 435.8846 s
agent0:                 episode reward: -0.4887,                 loss: nan
agent1:                 episode reward: 0.4887,                 loss: 0.1495
Episode: 7761/10000 (77.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5783s / 437.4629 s
agent0:                 episode reward: -1.0320,                 loss: nan
agent1:                 episode reward: 1.0320,                 loss: 0.1508
Episode: 7781/10000 (77.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6004s / 439.0633 s
agent0:                 episode reward: -1.2100,                 loss: nan
agent1:                 episode reward: 1.2100,                 loss: 0.1753
Episode: 7801/10000 (78.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5703s / 440.6335 s
agent0:                 episode reward: -0.9205,                 loss: nan
agent1:                 episode reward: 0.9205,                 loss: 0.1782
Episode: 7821/10000 (78.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5470s / 442.1805 s
agent0:                 episode reward: -1.0390,                 loss: nan
agent1:                 episode reward: 1.0390,                 loss: 0.1774
Episode: 7841/10000 (78.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5897s / 443.7703 s
agent0:                 episode reward: -0.6282,                 loss: nan
agent1:                 episode reward: 0.6282,                 loss: 0.1784
Episode: 7861/10000 (78.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6617s / 445.4319 s
agent0:                 episode reward: -0.9563,                 loss: nan
agent1:                 episode reward: 0.9563,                 loss: 0.1770
Episode: 7881/10000 (78.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5998s / 447.0317 s
agent0:                 episode reward: -0.9180,                 loss: nan
agent1:                 episode reward: 0.9180,                 loss: 0.2056
Episode: 7901/10000 (79.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5713s / 448.6030 s
agent0:                 episode reward: -1.5897,                 loss: nan
agent1:                 episode reward: 1.5897,                 loss: 0.2079
Episode: 7921/10000 (79.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6339s / 450.2369 s
agent0:                 episode reward: -1.0403,                 loss: nan
agent1:                 episode reward: 1.0403,                 loss: 0.2097
Episode: 7941/10000 (79.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5936s / 451.8306 s
agent0:                 episode reward: -0.8981,                 loss: nan
agent1:                 episode reward: 0.8981,                 loss: 0.2084
Episode: 7961/10000 (79.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5997s / 453.4302 s
agent0:                 episode reward: -1.0828,                 loss: nan
agent1:                 episode reward: 1.0828,                 loss: 0.2081
Episode: 7981/10000 (79.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6465s / 455.0767 s
agent0:                 episode reward: -1.5032,                 loss: nan
agent1:                 episode reward: 1.5032,                 loss: 0.2422
Episode: 8001/10000 (80.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6009s / 456.6776 s
agent0:                 episode reward: -1.2119,                 loss: nan
agent1:                 episode reward: 1.2119,                 loss: 0.2420
Episode: 8021/10000 (80.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5760s / 458.2536 s
agent0:                 episode reward: -0.6696,                 loss: nan
agent1:                 episode reward: 0.6696,                 loss: 0.2408
Episode: 8041/10000 (80.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6469s / 459.9005 s
agent0:                 episode reward: -1.5390,                 loss: nan
agent1:                 episode reward: 1.5390,                 loss: 0.2396
Episode: 8061/10000 (80.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5865s / 461.4870 s
agent0:                 episode reward: -1.3267,                 loss: nan
agent1:                 episode reward: 1.3267,                 loss: 0.2394
Episode: 8081/10000 (80.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6501s / 463.1371 s
agent0:                 episode reward: -0.0389,                 loss: nan
agent1:                 episode reward: 0.0389,                 loss: 0.2479
Episode: 8101/10000 (81.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5993s / 464.7364 s
agent0:                 episode reward: -1.2696,                 loss: nan
agent1:                 episode reward: 1.2696,                 loss: 0.2470
Episode: 8121/10000 (81.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6393s / 466.3758 s
agent0:                 episode reward: -1.3088,                 loss: nan
agent1:                 episode reward: 1.3088,                 loss: 0.2444
Episode: 8141/10000 (81.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6328s / 468.0086 s
agent0:                 episode reward: -0.8349,                 loss: nan
agent1:                 episode reward: 0.8349,                 loss: 0.2444
Episode: 8161/10000 (81.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6581s / 469.6667 s
agent0:                 episode reward: -1.1157,                 loss: nan
agent1:                 episode reward: 1.1157,                 loss: 0.2420
Episode: 8181/10000 (81.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6517s / 471.3184 s
agent0:                 episode reward: -1.2069,                 loss: nan
agent1:                 episode reward: 1.2069,                 loss: 0.2331
Episode: 8201/10000 (82.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6164s / 472.9348 s
agent0:                 episode reward: -0.9061,                 loss: nan
agent1:                 episode reward: 0.9061,                 loss: 0.2258
Episode: 8221/10000 (82.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6486s / 474.5835 s
agent0:                 episode reward: -1.7347,                 loss: nan
agent1:                 episode reward: 1.7347,                 loss: 0.2257
Episode: 8241/10000 (82.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6114s / 476.1948 s
agent0:                 episode reward: -1.1833,                 loss: nan
agent1:                 episode reward: 1.1833,                 loss: 0.2247
Episode: 8261/10000 (82.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6207s / 477.8155 s
agent0:                 episode reward: -1.0679,                 loss: nan
agent1:                 episode reward: 1.0679,                 loss: 0.2229
Episode: 8281/10000 (82.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6872s / 479.5027 s
agent0:                 episode reward: -1.7311,                 loss: nan
agent1:                 episode reward: 1.7311,                 loss: 0.1833
Episode: 8301/10000 (83.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6351s / 481.1378 s
agent0:                 episode reward: -1.7395,                 loss: nan
agent1:                 episode reward: 1.7395,                 loss: 0.1683
Episode: 8321/10000 (83.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6640s / 482.8018 s
agent0:                 episode reward: -1.9155,                 loss: nan
agent1:                 episode reward: 1.9155,                 loss: 0.1679
Episode: 8341/10000 (83.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6505s / 484.4522 s
agent0:                 episode reward: -1.5658,                 loss: nan
agent1:                 episode reward: 1.5658,                 loss: 0.1666
Episode: 8361/10000 (83.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6439s / 486.0961 s
agent0:                 episode reward: -1.5313,                 loss: nan
agent1:                 episode reward: 1.5313,                 loss: 0.1662
Episode: 8381/10000 (83.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6628s / 487.7589 s
agent0:                 episode reward: -1.5256,                 loss: nan
agent1:                 episode reward: 1.5256,                 loss: 0.1525
Episode: 8401/10000 (84.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6355s / 489.3945 s
agent0:                 episode reward: -1.6255,                 loss: nan
agent1:                 episode reward: 1.6255,                 loss: 0.1432
Episode: 8421/10000 (84.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6958s / 491.0902 s
agent0:                 episode reward: -1.3229,                 loss: nan
agent1:                 episode reward: 1.3229,                 loss: 0.1441
Episode: 8441/10000 (84.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6665s / 492.7567 s
agent0:                 episode reward: -1.3269,                 loss: nan
agent1:                 episode reward: 1.3269,                 loss: 0.1445
Episode: 8461/10000 (84.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6737s / 494.4304 s
agent0:                 episode reward: -0.8688,                 loss: nan
agent1:                 episode reward: 0.8688,                 loss: 0.1437
Episode: 8481/10000 (84.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6821s / 496.1124 s
agent0:                 episode reward: -1.0481,                 loss: nan
agent1:                 episode reward: 1.0481,                 loss: 0.1548
Episode: 8501/10000 (85.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6787s / 497.7911 s
agent0:                 episode reward: -0.7515,                 loss: nan
agent1:                 episode reward: 0.7515,                 loss: 0.1505
Episode: 8521/10000 (85.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6767s / 499.4678 s
agent0:                 episode reward: -1.3776,                 loss: nan
agent1:                 episode reward: 1.3776,                 loss: 0.1494
Episode: 8541/10000 (85.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7195s / 501.1873 s
agent0:                 episode reward: -1.3639,                 loss: nan
agent1:                 episode reward: 1.3639,                 loss: 0.1477
Episode: 8561/10000 (85.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6589s / 502.8461 s
agent0:                 episode reward: -0.9415,                 loss: nan
agent1:                 episode reward: 0.9415,                 loss: 0.1492
Episode: 8581/10000 (85.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6984s / 504.5445 s
agent0:                 episode reward: -0.9760,                 loss: nan
agent1:                 episode reward: 0.9760,                 loss: 0.1573
Episode: 8601/10000 (86.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6803s / 506.2249 s
agent0:                 episode reward: -0.9936,                 loss: nan
agent1:                 episode reward: 0.9936,                 loss: 0.1543
Episode: 8621/10000 (86.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6751s / 507.8999 s
agent0:                 episode reward: -1.5886,                 loss: nan
agent1:                 episode reward: 1.5886,                 loss: 0.1539
Episode: 8641/10000 (86.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6762s / 509.5762 s
agent0:                 episode reward: -2.4577,                 loss: nan
agent1:                 episode reward: 2.4577,                 loss: 0.1533
Episode: 8661/10000 (86.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7381s / 511.3143 s
agent0:                 episode reward: -0.9638,                 loss: nan
agent1:                 episode reward: 0.9638,                 loss: 0.1527
Episode: 8681/10000 (86.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7172s / 513.0315 s
agent0:                 episode reward: -1.6183,                 loss: nan
agent1:                 episode reward: 1.6183,                 loss: 0.1863
Episode: 8701/10000 (87.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6890s / 514.7205 s
agent0:                 episode reward: -1.0731,                 loss: nan
agent1:                 episode reward: 1.0731,                 loss: 0.1881
Episode: 8721/10000 (87.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6963s / 516.4168 s
agent0:                 episode reward: -1.5502,                 loss: nan
agent1:                 episode reward: 1.5502,                 loss: 0.1873
Episode: 8741/10000 (87.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6867s / 518.1034 s
agent0:                 episode reward: -1.3451,                 loss: nan
agent1:                 episode reward: 1.3451,                 loss: 0.1884
Episode: 8761/10000 (87.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7149s / 519.8184 s
agent0:                 episode reward: -1.3950,                 loss: nan
agent1:                 episode reward: 1.3950,                 loss: 0.1879
Episode: 8781/10000 (87.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7756s / 521.5940 s
agent0:                 episode reward: -0.9945,                 loss: nan
agent1:                 episode reward: 0.9945,                 loss: 0.2280
Episode: 8801/10000 (88.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7507s / 523.3447 s
agent0:                 episode reward: -1.0810,                 loss: nan
agent1:                 episode reward: 1.0810,                 loss: 0.2313
Episode: 8821/10000 (88.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7178s / 525.0625 s
agent0:                 episode reward: -1.1068,                 loss: nan
agent1:                 episode reward: 1.1068,                 loss: 0.2288
Episode: 8841/10000 (88.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7025s / 526.7650 s
agent0:                 episode reward: -0.6834,                 loss: nan
agent1:                 episode reward: 0.6834,                 loss: 0.2277
Episode: 8861/10000 (88.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7215s / 528.4865 s
agent0:                 episode reward: -1.4306,                 loss: nan
agent1:                 episode reward: 1.4306,                 loss: 0.2276
Episode: 8881/10000 (88.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7352s / 530.2218 s
agent0:                 episode reward: -0.9299,                 loss: nan
agent1:                 episode reward: 0.9299,                 loss: 0.2438
Episode: 8901/10000 (89.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7735s / 531.9953 s
agent0:                 episode reward: -1.2638,                 loss: nan
agent1:                 episode reward: 1.2638,                 loss: 0.2420
Episode: 8921/10000 (89.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7151s / 533.7104 s
agent0:                 episode reward: -1.3711,                 loss: nan
agent1:                 episode reward: 1.3711,                 loss: 0.2391
Episode: 8941/10000 (89.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7723s / 535.4827 s
agent0:                 episode reward: -1.3769,                 loss: nan
agent1:                 episode reward: 1.3769,                 loss: 0.2374
Episode: 8961/10000 (89.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7925s / 537.2752 s
agent0:                 episode reward: -1.3433,                 loss: nan
agent1:                 episode reward: 1.3433,                 loss: 0.2405
Episode: 8981/10000 (89.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7556s / 539.0308 s
agent0:                 episode reward: -0.7138,                 loss: nan
agent1:                 episode reward: 0.7138,                 loss: 0.2602
Episode: 9001/10000 (90.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7676s / 540.7984 s
agent0:                 episode reward: -1.0453,                 loss: nan
agent1:                 episode reward: 1.0453,                 loss: 0.2572
Episode: 9021/10000 (90.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7856s / 542.5840 s
agent0:                 episode reward: -1.1989,                 loss: nan
agent1:                 episode reward: 1.1989,                 loss: 0.2561
Episode: 9041/10000 (90.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7668s / 544.3507 s
agent0:                 episode reward: -0.8863,                 loss: nan
agent1:                 episode reward: 0.8863,                 loss: 0.2586
Episode: 9061/10000 (90.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7640s / 546.1147 s
agent0:                 episode reward: -0.6486,                 loss: nan
agent1:                 episode reward: 0.6486,                 loss: 0.2554
Episode: 9081/10000 (90.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7509s / 547.8657 s
agent0:                 episode reward: -0.8400,                 loss: nan
agent1:                 episode reward: 0.8400,                 loss: 0.2518
Episode: 9101/10000 (91.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7651s / 549.6308 s
agent0:                 episode reward: -1.3510,                 loss: nan
agent1:                 episode reward: 1.3510,                 loss: 0.2469
Episode: 9121/10000 (91.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8340s / 551.4648 s
agent0:                 episode reward: -1.2582,                 loss: nan
agent1:                 episode reward: 1.2582,                 loss: 0.2475
Episode: 9141/10000 (91.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8283s / 553.2931 s
agent0:                 episode reward: -0.6265,                 loss: nan
agent1:                 episode reward: 0.6265,                 loss: 0.2449
Episode: 9161/10000 (91.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8541s / 555.1472 s
agent0:                 episode reward: -1.7579,                 loss: nan
agent1:                 episode reward: 1.7579,                 loss: 0.2476
Episode: 9181/10000 (91.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7840s / 556.9312 s
agent0:                 episode reward: -1.1093,                 loss: nan
agent1:                 episode reward: 1.1093,                 loss: 0.2311
Episode: 9201/10000 (92.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8019s / 558.7331 s
agent0:                 episode reward: -1.7749,                 loss: nan
agent1:                 episode reward: 1.7749,                 loss: 0.2245
Episode: 9221/10000 (92.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7998s / 560.5329 s
agent0:                 episode reward: -0.9609,                 loss: nan
agent1:                 episode reward: 0.9609,                 loss: 0.2260
Episode: 9241/10000 (92.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8935s / 562.4264 s
agent0:                 episode reward: -1.2283,                 loss: nan
agent1:                 episode reward: 1.2283,                 loss: 0.2252
Episode: 9261/10000 (92.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7811s / 564.2075 s
agent0:                 episode reward: -1.0181,                 loss: nan
agent1:                 episode reward: 1.0181,                 loss: 0.2238
Episode: 9281/10000 (92.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7842s / 565.9917 s
agent0:                 episode reward: -1.0256,                 loss: nan
agent1:                 episode reward: 1.0256,                 loss: 0.1945
Episode: 9301/10000 (93.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8522s / 567.8439 s
agent0:                 episode reward: -1.7162,                 loss: nan
agent1:                 episode reward: 1.7162,                 loss: 0.1850
Episode: 9321/10000 (93.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7909s / 569.6348 s
agent0:                 episode reward: -1.1550,                 loss: nan
agent1:                 episode reward: 1.1550,                 loss: 0.1856
Episode: 9341/10000 (93.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8115s / 571.4463 s
agent0:                 episode reward: -1.3686,                 loss: nan
agent1:                 episode reward: 1.3686,                 loss: 0.1862
Episode: 9361/10000 (93.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8761s / 573.3224 s
agent0:                 episode reward: -1.2083,                 loss: nan
agent1:                 episode reward: 1.2083,                 loss: 0.1850
Episode: 9381/10000 (93.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8792s / 575.2016 s
agent0:                 episode reward: -2.1121,                 loss: nan
agent1:                 episode reward: 2.1121,                 loss: 0.1557
Episode: 9401/10000 (94.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8444s / 577.0460 s
agent0:                 episode reward: -1.6111,                 loss: nan
agent1:                 episode reward: 1.6111,                 loss: 0.1471
Episode: 9421/10000 (94.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8426s / 578.8886 s
agent0:                 episode reward: -1.8380,                 loss: nan
agent1:                 episode reward: 1.8380,                 loss: 0.1472
Episode: 9441/10000 (94.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8329s / 580.7215 s
agent0:                 episode reward: -1.3423,                 loss: nan
agent1:                 episode reward: 1.3423,                 loss: 0.1457
Episode: 9461/10000 (94.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8851s / 582.6067 s
agent0:                 episode reward: -1.2622,                 loss: nan
agent1:                 episode reward: 1.2622,                 loss: 0.1472
Episode: 9481/10000 (94.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8414s / 584.4481 s
agent0:                 episode reward: -2.2146,                 loss: nan
agent1:                 episode reward: 2.2146,                 loss: 0.1574
Episode: 9501/10000 (95.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8998s / 586.3479 s
agent0:                 episode reward: -1.8287,                 loss: nan
agent1:                 episode reward: 1.8287,                 loss: 0.1534
Episode: 9521/10000 (95.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8624s / 588.2103 s
agent0:                 episode reward: -0.7467,                 loss: nan
agent1:                 episode reward: 0.7467,                 loss: 0.1532
Episode: 9541/10000 (95.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8217s / 590.0320 s
agent0:                 episode reward: -1.4544,                 loss: nan
agent1:                 episode reward: 1.4544,                 loss: 0.1555
Episode: 9561/10000 (95.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8235s / 591.8555 s
agent0:                 episode reward: -1.9784,                 loss: nan
agent1:                 episode reward: 1.9784,                 loss: 0.1540
Episode: 9581/10000 (95.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8738s / 593.7293 s
agent0:                 episode reward: -0.9378,                 loss: nan
agent1:                 episode reward: 0.9378,                 loss: 0.2055
Episode: 9601/10000 (96.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8640s / 595.5933 s
agent0:                 episode reward: -1.3919,                 loss: nan
agent1:                 episode reward: 1.3919,                 loss: 0.2117
Episode: 9621/10000 (96.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8378s / 597.4311 s
agent0:                 episode reward: -1.0426,                 loss: nan
agent1:                 episode reward: 1.0426,                 loss: 0.2118
Episode: 9641/10000 (96.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8342s / 599.2654 s
agent0:                 episode reward: -1.2142,                 loss: nan
agent1:                 episode reward: 1.2142,                 loss: 0.2122
Episode: 9661/10000 (96.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8522s / 601.1175 s
agent0:                 episode reward: -1.4437,                 loss: nan
agent1:                 episode reward: 1.4437,                 loss: 0.2125
Episode: 9681/10000 (96.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9244s / 603.0419 s
agent0:                 episode reward: -1.2963,                 loss: nan
agent1:                 episode reward: 1.2963,                 loss: 0.2358
Episode: 9701/10000 (97.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8552s / 604.8971 s
agent0:                 episode reward: -0.9015,                 loss: nan
agent1:                 episode reward: 0.9015,                 loss: 0.2377
Episode: 9721/10000 (97.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8872s / 606.7843 s
agent0:                 episode reward: -1.1490,                 loss: nan
agent1:                 episode reward: 1.1490,                 loss: 0.2366
Episode: 9741/10000 (97.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8581s / 608.6424 s
agent0:                 episode reward: -1.3691,                 loss: nan
agent1:                 episode reward: 1.3691,                 loss: 0.2370
Episode: 9761/10000 (97.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8760s / 610.5183 s
agent0:                 episode reward: -1.3867,                 loss: nan
agent1:                 episode reward: 1.3867,                 loss: 0.2362/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

Episode: 9781/10000 (97.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8947s / 612.4131 s
agent0:                 episode reward: -0.9021,                 loss: nan
agent1:                 episode reward: 0.9021,                 loss: 0.2413
Episode: 9801/10000 (98.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9259s / 614.3389 s
agent0:                 episode reward: -0.9665,                 loss: nan
agent1:                 episode reward: 0.9665,                 loss: 0.2384
Episode: 9821/10000 (98.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8863s / 616.2253 s
agent0:                 episode reward: -1.4184,                 loss: nan
agent1:                 episode reward: 1.4184,                 loss: 0.2389
Episode: 9841/10000 (98.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9042s / 618.1295 s
agent0:                 episode reward: -2.2099,                 loss: nan
agent1:                 episode reward: 2.2099,                 loss: 0.2379
Episode: 9861/10000 (98.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9502s / 620.0797 s
agent0:                 episode reward: -1.7237,                 loss: nan
agent1:                 episode reward: 1.7237,                 loss: 0.2382
Episode: 9881/10000 (98.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9177s / 621.9974 s
agent0:                 episode reward: -1.5666,                 loss: nan
agent1:                 episode reward: 1.5666,                 loss: 0.2442
Episode: 9901/10000 (99.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9611s / 623.9585 s
agent0:                 episode reward: -1.0313,                 loss: nan
agent1:                 episode reward: 1.0313,                 loss: 0.2430
Episode: 9921/10000 (99.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9063s / 625.8648 s
agent0:                 episode reward: -1.8247,                 loss: nan
agent1:                 episode reward: 1.8247,                 loss: 0.2437
Episode: 9941/10000 (99.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9266s / 627.7914 s
agent0:                 episode reward: -1.2101,                 loss: nan
agent1:                 episode reward: 1.2101,                 loss: 0.2422
Episode: 9961/10000 (99.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8936s / 629.6851 s
agent0:                 episode reward: -1.3838,                 loss: nan
agent1:                 episode reward: 1.3838,                 loss: 0.2413
Episode: 9981/10000 (99.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9140s / 631.5991 s
agent0:                 episode reward: -1.5557,                 loss: nan
agent1:                 episode reward: 1.5557,                 loss: 0.2488
