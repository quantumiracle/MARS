pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
boxing_v1 pettingzoo
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
random seed: [91, 69]
<SubprocVectorEnv instance>
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
No agent are not learnable.
Arguments:  {'env_name': 'boxing_v1', 'env_type': 'pettingzoo', 'num_envs': 2, 'ram': True, 'seed': 'random', 'algorithm': 'NashDQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 0.1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}}
Save models to : /home/zihan/research/MARS/data/model/20220119_0521/pettingzoo_boxing_v1_nash_dqn. 
 Save logs to: /home/zihan/research/MARS/data/log/20220119_0521/pettingzoo_boxing_v1_nash_dqn.
Episode: 1/10000 (0.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 43.4883s / 43.4883 s
env0_first_0:                 episode reward: -2.0000,                 loss: 0.0056
env0_second_0:                 episode reward: 2.0000,                 loss: 0.0056
env1_first_0:                 episode reward: -13.0000,                 loss: nan
env1_second_0:                 episode reward: 13.0000,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 1558.1818s / 1601.6701 s
env0_first_0:                 episode reward: -1.9000,                 loss: 0.0175
env0_second_0:                 episode reward: 1.9000,                 loss: 0.0169
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 1953.9673s / 3555.6374 s
env0_first_0:                 episode reward: 1.3500,                 loss: 0.0178
env0_second_0:                 episode reward: -1.3500,                 loss: 0.0179
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2066.7230s / 5622.3603 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.0182
env0_second_0:                 episode reward: 1.3000,                 loss: 0.0180
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 81/10000 (0.8100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2103.7477s / 7726.1080 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0157
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0160
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 101/10000 (1.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2098.1921s / 9824.3001 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0150
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0152
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 121/10000 (1.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2102.5478s / 11926.8479 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0163
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0166
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 141/10000 (1.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2117.6597s / 14044.5076 s
env0_first_0:                 episode reward: -1.4500,                 loss: 0.0161
env0_second_0:                 episode reward: 1.4500,                 loss: 0.0160
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 161/10000 (1.6100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2110.4252s / 16154.9329 s
env0_first_0:                 episode reward: -4.2000,                 loss: 0.0160
env0_second_0:                 episode reward: 4.2000,                 loss: 0.0164
env1_first_0:                 episode reward: -2.9500,                 loss: nan
env1_second_0:                 episode reward: 2.9500,                 loss: nan
Episode: 181/10000 (1.8100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2100.2476s / 18255.1805 s
env0_first_0:                 episode reward: -2.6500,                 loss: 0.0178
env0_second_0:                 episode reward: 2.6500,                 loss: 0.0179
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 201/10000 (2.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2111.4073s / 20366.5878 s
env0_first_0:                 episode reward: -1.9500,                 loss: 0.0166
env0_second_0:                 episode reward: 1.9500,                 loss: 0.0163
env1_first_0:                 episode reward: -2.1000,                 loss: nan
env1_second_0:                 episode reward: 2.1000,                 loss: nan
Episode: 221/10000 (2.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2101.4292s / 22468.0170 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0140
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0145
env1_first_0:                 episode reward: -2.0500,                 loss: nan
env1_second_0:                 episode reward: 2.0500,                 loss: nan
Episode: 241/10000 (2.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2100.5032s / 24568.5202 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.0153
env0_second_0:                 episode reward: 3.5500,                 loss: 0.0155
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 261/10000 (2.6100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2089.0678s / 26657.5880 s
env0_first_0:                 episode reward: -1.6500,                 loss: 0.0145
env0_second_0:                 episode reward: 1.6500,                 loss: 0.0150
env1_first_0:                 episode reward: -2.7500,                 loss: nan
env1_second_0:                 episode reward: 2.7500,                 loss: nan
Episode: 281/10000 (2.8100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2097.2665s / 28754.8545 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.0160
env0_second_0:                 episode reward: 3.9000,                 loss: 0.0159
env1_first_0:                 episode reward: -1.8500,                 loss: nan
env1_second_0:                 episode reward: 1.8500,                 loss: nan
Episode: 301/10000 (3.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2099.2551s / 30854.1096 s
env0_first_0:                 episode reward: -2.2000,                 loss: 0.0181
env0_second_0:                 episode reward: 2.2000,                 loss: 0.0185
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
Episode: 321/10000 (3.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2104.9084s / 32959.0180 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.0201
env0_second_0:                 episode reward: 1.2500,                 loss: 0.0194
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 341/10000 (3.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2101.3930s / 35060.4110 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0191
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0186
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 361/10000 (3.6100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2102.0210s / 37162.4320 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0172
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0177
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 381/10000 (3.8100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2425.9119s / 39588.3439 s
env0_first_0:                 episode reward: -2.3000,                 loss: 0.0172
env0_second_0:                 episode reward: 2.3000,                 loss: 0.0173
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 401/10000 (4.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2462.6242s / 42050.9682 s
env0_first_0:                 episode reward: -2.5000,                 loss: 0.0197
env0_second_0:                 episode reward: 2.5000,                 loss: 0.0187
env1_first_0:                 episode reward: -2.1500,                 loss: nan
env1_second_0:                 episode reward: 2.1500,                 loss: nan
Episode: 421/10000 (4.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2468.3536s / 44519.3218 s
env0_first_0:                 episode reward: -3.3500,                 loss: 0.0196
env0_second_0:                 episode reward: 3.3500,                 loss: 0.0189
env1_first_0:                 episode reward: -1.9500,                 loss: nan
env1_second_0:                 episode reward: 1.9500,                 loss: nan
Episode: 441/10000 (4.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2445.8250s / 46965.1468 s
env0_first_0:                 episode reward: -4.6500,                 loss: 0.0190
env0_second_0:                 episode reward: 4.6500,                 loss: 0.0187
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 461/10000 (4.6100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2438.6540s / 49403.8009 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.0173
env0_second_0:                 episode reward: 1.1000,                 loss: 0.0168
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 481/10000 (4.8100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2440.8089s / 51844.6097 s
env0_first_0:                 episode reward: -1.8000,                 loss: 0.0179
env0_second_0:                 episode reward: 1.8000,                 loss: 0.0174
env1_first_0:                 episode reward: 1.5000,                 loss: nan
env1_second_0:                 episode reward: -1.5000,                 loss: nan
Episode: 501/10000 (5.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2436.2443s / 54280.8540 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0195
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0178
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 521/10000 (5.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2449.7406s / 56730.5947 s
env0_first_0:                 episode reward: -2.1500,                 loss: 0.0192
env0_second_0:                 episode reward: 2.1500,                 loss: 0.0182
env1_first_0:                 episode reward: -1.8500,                 loss: nan
env1_second_0:                 episode reward: 1.8500,                 loss: nan
Episode: 541/10000 (5.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2456.7939s / 59187.3886 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.0198
env0_second_0:                 episode reward: 3.9000,                 loss: 0.0200
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 561/10000 (5.6100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2441.4561s / 61628.8447 s
env0_first_0:                 episode reward: -2.5500,                 loss: 0.0190
env0_second_0:                 episode reward: 2.5500,                 loss: 0.0187
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 581/10000 (5.8100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2449.0226s / 64077.8673 s
env0_first_0:                 episode reward: -2.7000,                 loss: 0.0206
env0_second_0:                 episode reward: 2.7000,                 loss: 0.0195
env1_first_0:                 episode reward: -2.9500,                 loss: nan
env1_second_0:                 episode reward: 2.9500,                 loss: nan
Episode: 601/10000 (6.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2455.8460s / 66533.7133 s
env0_first_0:                 episode reward: -1.4500,                 loss: 0.0207
env0_second_0:                 episode reward: 1.4500,                 loss: 0.0207
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 621/10000 (6.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2449.2513s / 68982.9646 s
env0_first_0:                 episode reward: -1.7500,                 loss: 0.0227
env0_second_0:                 episode reward: 1.7500,                 loss: 0.0216
env1_first_0:                 episode reward: -3.2500,                 loss: nan
env1_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 641/10000 (6.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2442.9743s / 71425.9389 s
env0_first_0:                 episode reward: -6.5000,                 loss: 0.0273
env0_second_0:                 episode reward: 6.5000,                 loss: 0.0247
env1_first_0:                 episode reward: -4.5000,                 loss: nan
env1_second_0:                 episode reward: 4.5000,                 loss: nan
Episode: 661/10000 (6.6100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2445.3184s / 73871.2573 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0285
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0270
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 681/10000 (6.8100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2439.7074s / 76310.9647 s
env0_first_0:                 episode reward: -3.1000,                 loss: 0.0273
env0_second_0:                 episode reward: 3.1000,                 loss: 0.0246
env1_first_0:                 episode reward: -6.8500,                 loss: nan
env1_second_0:                 episode reward: 6.8500,                 loss: nan
Episode: 701/10000 (7.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2455.2306s / 78766.1953 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.0345
env0_second_0:                 episode reward: 4.0000,                 loss: 0.0285
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 721/10000 (7.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2451.9642s / 81218.1595 s
env0_first_0:                 episode reward: -7.7000,                 loss: 0.0449
env0_second_0:                 episode reward: 7.7000,                 loss: 0.0369
env1_first_0:                 episode reward: -5.5500,                 loss: nan
env1_second_0:                 episode reward: 5.5500,                 loss: nan
Episode: 741/10000 (7.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2448.1335s / 83666.2930 s
env0_first_0:                 episode reward: -2.7500,                 loss: 0.0500
env0_second_0:                 episode reward: 2.7500,                 loss: 0.0418
env1_first_0:                 episode reward: -5.7500,                 loss: nan
env1_second_0:                 episode reward: 5.7500,                 loss: nan
Episode: 761/10000 (7.6100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2451.0295s / 86117.3225 s
env0_first_0:                 episode reward: -7.4500,                 loss: 0.0435
env0_second_0:                 episode reward: 7.4500,                 loss: 0.0379
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 781/10000 (7.8100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2450.1106s / 88567.4331 s
env0_first_0:                 episode reward: -5.7000,                 loss: 0.0420
env0_second_0:                 episode reward: 5.7000,                 loss: 0.0370
env1_first_0:                 episode reward: -6.3500,                 loss: nan
env1_second_0:                 episode reward: 6.3500,                 loss: nan
Episode: 801/10000 (8.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2445.8349s / 91013.2680 s
env0_first_0:                 episode reward: -4.6000,                 loss: 0.0471
env0_second_0:                 episode reward: 4.6000,                 loss: 0.0445
env1_first_0:                 episode reward: -4.2500,                 loss: nan
env1_second_0:                 episode reward: 4.2500,                 loss: nan
Episode: 821/10000 (8.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2439.0153s / 93452.2833 s
env0_first_0:                 episode reward: -4.1000,                 loss: 0.0466
env0_second_0:                 episode reward: 4.1000,                 loss: 0.0450
env1_first_0:                 episode reward: -6.8000,                 loss: nan
env1_second_0:                 episode reward: 6.8000,                 loss: nan
Episode: 841/10000 (8.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2442.2221s / 95894.5054 s
env0_first_0:                 episode reward: -8.5000,                 loss: 0.0448
env0_second_0:                 episode reward: 8.5000,                 loss: 0.0447
env1_first_0:                 episode reward: -4.7000,                 loss: nan
env1_second_0:                 episode reward: 4.7000,                 loss: nan
Episode: 861/10000 (8.6100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2420.8180s / 98315.3234 s
env0_first_0:                 episode reward: -8.7500,                 loss: 0.0466
env0_second_0:                 episode reward: 8.7500,                 loss: 0.0423
env1_first_0:                 episode reward: -5.5000,                 loss: nan
env1_second_0:                 episode reward: 5.5000,                 loss: nan
Episode: 881/10000 (8.8100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2413.4675s / 100728.7909 s
env0_first_0:                 episode reward: -8.7500,                 loss: 0.0616
env0_second_0:                 episode reward: 8.7500,                 loss: 0.0531
env1_first_0:                 episode reward: -7.9500,                 loss: nan
env1_second_0:                 episode reward: 7.9500,                 loss: nan
Episode: 901/10000 (9.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2405.6622s / 103134.4531 s
env0_first_0:                 episode reward: -5.1500,                 loss: 0.0557
env0_second_0:                 episode reward: 5.1500,                 loss: 0.0552
env1_first_0:                 episode reward: -6.5500,                 loss: nan
env1_second_0:                 episode reward: 6.5500,                 loss: nan
Episode: 921/10000 (9.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2411.2469s / 105545.6999 s
env0_first_0:                 episode reward: -4.4500,                 loss: 0.0470
env0_second_0:                 episode reward: 4.4500,                 loss: 0.0458
env1_first_0:                 episode reward: -8.6500,                 loss: nan
env1_second_0:                 episode reward: 8.6500,                 loss: nan
Episode: 941/10000 (9.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2412.6546s / 107958.3545 s
env0_first_0:                 episode reward: -5.5500,                 loss: 0.0542
env0_second_0:                 episode reward: 5.5500,                 loss: 0.0476
env1_first_0:                 episode reward: -5.9000,                 loss: nan
env1_second_0:                 episode reward: 5.9000,                 loss: nan
Episode: 961/10000 (9.6100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2406.3972s / 110364.7517 s
env0_first_0:                 episode reward: -5.2000,                 loss: 0.0428
env0_second_0:                 episode reward: 5.2000,                 loss: 0.0453
env1_first_0:                 episode reward: -3.3500,                 loss: nan
env1_second_0:                 episode reward: 3.3500,                 loss: nan
Episode: 981/10000 (9.8100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2407.7048s / 112772.4565 s
env0_first_0:                 episode reward: -10.9000,                 loss: 0.0518
env0_second_0:                 episode reward: 10.9000,                 loss: 0.0479
env1_first_0:                 episode reward: -10.6000,                 loss: nan
env1_second_0:                 episode reward: 10.6000,                 loss: nan
Episode: 1001/10000 (10.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2408.1066s / 115180.5631 s
env0_first_0:                 episode reward: -10.6500,                 loss: 0.0642
env0_second_0:                 episode reward: 10.6500,                 loss: 0.0571
env1_first_0:                 episode reward: -8.3000,                 loss: nan
env1_second_0:                 episode reward: 8.3000,                 loss: nan
Episode: 1021/10000 (10.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2413.1882s / 117593.7512 s
env0_first_0:                 episode reward: -8.9000,                 loss: 0.0757
env0_second_0:                 episode reward: 8.9000,                 loss: 0.0676
env1_first_0:                 episode reward: -10.8500,                 loss: nan
env1_second_0:                 episode reward: 10.8500,                 loss: nan
Episode: 1041/10000 (10.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2412.3702s / 120006.1215 s
env0_first_0:                 episode reward: -2.1000,                 loss: 0.0729
env0_second_0:                 episode reward: 2.1000,                 loss: 0.0644
env1_first_0:                 episode reward: -7.8500,                 loss: nan
env1_second_0:                 episode reward: 7.8500,                 loss: nan
Episode: 1061/10000 (10.6100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2416.8817s / 122423.0032 s
env0_first_0:                 episode reward: -2.9500,                 loss: 0.0675
env0_second_0:                 episode reward: 2.9500,                 loss: 0.0576
env1_first_0:                 episode reward: -2.4000,                 loss: nan
env1_second_0:                 episode reward: 2.4000,                 loss: nan
Episode: 1081/10000 (10.8100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2418.0195s / 124841.0228 s
env0_first_0:                 episode reward: -7.8000,                 loss: 0.0610
env0_second_0:                 episode reward: 7.8000,                 loss: 0.0677
env1_first_0:                 episode reward: -6.9000,                 loss: nan
env1_second_0:                 episode reward: 6.9000,                 loss: nan
Episode: 1101/10000 (11.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2403.7901s / 127244.8128 s
env0_first_0:                 episode reward: -4.6500,                 loss: 0.0666
env0_second_0:                 episode reward: 4.6500,                 loss: 0.0669
env1_first_0:                 episode reward: -12.9000,                 loss: nan
env1_second_0:                 episode reward: 12.9000,                 loss: nan
Episode: 1121/10000 (11.2100%),                 avg. length: 1783.45,                last time consumption/overall running time: 2412.2552s / 129657.0680 s
env0_first_0:                 episode reward: -20.4000,                 loss: 0.0781
env0_second_0:                 episode reward: 20.4000,                 loss: 0.0700
env1_first_0:                 episode reward: -18.0500,                 loss: nan
env1_second_0:                 episode reward: 18.0500,                 loss: nan
Episode: 1141/10000 (11.4100%),                 avg. length: 1782.85,                last time consumption/overall running time: 2410.1322s / 132067.2002 s
env0_first_0:                 episode reward: -11.1000,                 loss: 0.0840
env0_second_0:                 episode reward: 11.1000,                 loss: 0.0875
env1_first_0:                 episode reward: -11.0500,                 loss: nan
env1_second_0:                 episode reward: 11.0500,                 loss: nan
Episode: 1161/10000 (11.6100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2415.2645s / 134482.4647 s
env0_first_0:                 episode reward: -13.3500,                 loss: 0.0762
env0_second_0:                 episode reward: 13.3500,                 loss: 0.0811
env1_first_0:                 episode reward: -13.9500,                 loss: nan
env1_second_0:                 episode reward: 13.9500,                 loss: nan
Episode: 1181/10000 (11.8100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2426.2237s / 136908.6884 s
env0_first_0:                 episode reward: -9.1500,                 loss: 0.0700
env0_second_0:                 episode reward: 9.1500,                 loss: 0.0827
env1_first_0:                 episode reward: -14.0500,                 loss: nan
env1_second_0:                 episode reward: 14.0500,                 loss: nan
Episode: 1201/10000 (12.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2421.7592s / 139330.4476 s
env0_first_0:                 episode reward: -17.4000,                 loss: 0.0845
env0_second_0:                 episode reward: 17.4000,                 loss: 0.0926
env1_first_0:                 episode reward: -16.5500,                 loss: nan
env1_second_0:                 episode reward: 16.5500,                 loss: nan
Episode: 1221/10000 (12.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 2418.9771s / 141749.4247 s
env0_first_0:                 episode reward: -20.1000,                 loss: 0.0859
env0_second_0:                 episode reward: 20.1000,                 loss: 0.0820
env1_first_0:                 episode reward: -13.0500,                 loss: nan
env1_second_0:                 episode reward: 13.0500,                 loss: nan
Episode: 1241/10000 (12.4100%),                 avg. length: 1778.8,                last time consumption/overall running time: 2411.8213s / 144161.2460 s
env0_first_0:                 episode reward: -18.9500,                 loss: 0.0746
env0_second_0:                 episode reward: 18.9500,                 loss: 0.0722
env1_first_0:                 episode reward: -14.6500,                 loss: nan
env1_second_0:                 episode reward: 14.6500,                 loss: nan
Episode: 1261/10000 (12.6100%),                 avg. length: 1757.55,                last time consumption/overall running time: 2342.3140s / 146503.5600 s
env0_first_0:                 episode reward: -21.7000,                 loss: 0.0858
env0_second_0:                 episode reward: 21.7000,                 loss: 0.0783
env1_first_0:                 episode reward: -26.6500,                 loss: nan
env1_second_0:                 episode reward: 26.6500,                 loss: nan
Episode: 1281/10000 (12.8100%),                 avg. length: 1713.9,                last time consumption/overall running time: 2272.3444s / 148775.9044 s
env0_first_0:                 episode reward: -28.6500,                 loss: 0.1097
env0_second_0:                 episode reward: 28.6500,                 loss: 0.0981
env1_first_0:                 episode reward: -24.3000,                 loss: nan
env1_second_0:                 episode reward: 24.3000,                 loss: nan
Episode: 1301/10000 (13.0100%),                 avg. length: 1704.75,                last time consumption/overall running time: 2251.5663s / 151027.4707 s
env0_first_0:                 episode reward: -26.4000,                 loss: 0.1259
env0_second_0:                 episode reward: 26.4000,                 loss: 0.1003
env1_first_0:                 episode reward: -25.7500,                 loss: nan
env1_second_0:                 episode reward: 25.7500,                 loss: nan
Episode: 1321/10000 (13.2100%),                 avg. length: 1721.9,                last time consumption/overall running time: 2278.9516s / 153306.4223 s
env0_first_0:                 episode reward: -22.4000,                 loss: 0.1169
env0_second_0:                 episode reward: 22.4000,                 loss: 0.1115
env1_first_0:                 episode reward: -26.6500,                 loss: nan
env1_second_0:                 episode reward: 26.6500,                 loss: nan
Episode: 1341/10000 (13.4100%),                 avg. length: 1616.85,                last time consumption/overall running time: 2137.2557s / 155443.6781 s
env0_first_0:                 episode reward: -29.8500,                 loss: 0.1428
env0_second_0:                 episode reward: 29.8500,                 loss: 0.1295
env1_first_0:                 episode reward: -39.9000,                 loss: nan
env1_second_0:                 episode reward: 39.9000,                 loss: nan
Episode: 1361/10000 (13.6100%),                 avg. length: 1464.65,                last time consumption/overall running time: 1934.2253s / 157377.9033 s
env0_first_0:                 episode reward: -44.0000,                 loss: 0.1769
env0_second_0:                 episode reward: 44.0000,                 loss: 0.1645
env1_first_0:                 episode reward: -35.2000,                 loss: nan
env1_second_0:                 episode reward: 35.2000,                 loss: nan
Episode: 1381/10000 (13.8100%),                 avg. length: 1265.05,                last time consumption/overall running time: 1674.8724s / 159052.7757 s
env0_first_0:                 episode reward: -46.3500,                 loss: 0.2044
env0_second_0:                 episode reward: 46.3500,                 loss: 0.1670
env1_first_0:                 episode reward: -40.8500,                 loss: nan
env1_second_0:                 episode reward: 40.8500,                 loss: nan
Episode: 1401/10000 (14.0100%),                 avg. length: 1141.6,                last time consumption/overall running time: 1503.6871s / 160556.4629 s
env0_first_0:                 episode reward: -52.7500,                 loss: 0.2059
env0_second_0:                 episode reward: 52.7500,                 loss: 0.1756
env1_first_0:                 episode reward: -48.4500,                 loss: nan
env1_second_0:                 episode reward: 48.4500,                 loss: nan
Episode: 1421/10000 (14.2100%),                 avg. length: 906.25,                last time consumption/overall running time: 1185.4364s / 161741.8992 s
env0_first_0:                 episode reward: -49.8500,                 loss: 0.2361
env0_second_0:                 episode reward: 49.8500,                 loss: 0.2042
env1_first_0:                 episode reward: -59.1500,                 loss: nan
env1_second_0:                 episode reward: 59.1500,                 loss: nan
Episode: 1441/10000 (14.4100%),                 avg. length: 1086.95,                last time consumption/overall running time: 1420.5174s / 163162.4167 s
env0_first_0:                 episode reward: -49.5000,                 loss: 0.2707
env0_second_0:                 episode reward: 49.5000,                 loss: 0.2469
env1_first_0:                 episode reward: -50.2000,                 loss: nan
env1_second_0:                 episode reward: 50.2000,                 loss: nan
Episode: 1461/10000 (14.6100%),                 avg. length: 960.65,                last time consumption/overall running time: 1258.8063s / 164421.2229 s
env0_first_0:                 episode reward: -42.1000,                 loss: 0.3397
env0_second_0:                 episode reward: 42.1000,                 loss: 0.2621
env1_first_0:                 episode reward: -60.7000,                 loss: nan
env1_second_0:                 episode reward: 60.7000,                 loss: nan
Episode: 1481/10000 (14.8100%),                 avg. length: 833.35,                last time consumption/overall running time: 1083.7953s / 165505.0183 s
env0_first_0:                 episode reward: -66.8000,                 loss: 0.3537
env0_second_0:                 episode reward: 66.8000,                 loss: 0.2917
env1_first_0:                 episode reward: -51.2000,                 loss: nan
env1_second_0:                 episode reward: 51.2000,                 loss: nan
Episode: 1501/10000 (15.0100%),                 avg. length: 704.7,                last time consumption/overall running time: 927.0093s / 166432.0276 s
env0_first_0:                 episode reward: -69.8000,                 loss: 0.3796
env0_second_0:                 episode reward: 69.8000,                 loss: 0.2962
env1_first_0:                 episode reward: -52.8000,                 loss: nan
env1_second_0:                 episode reward: 52.8000,                 loss: nan
Episode: 1521/10000 (15.2100%),                 avg. length: 767.65,                last time consumption/overall running time: 1004.6692s / 167436.6968 s
env0_first_0:                 episode reward: -59.0500,                 loss: 0.3799
env0_second_0:                 episode reward: 59.0500,                 loss: 0.2890
env1_first_0:                 episode reward: -47.5000,                 loss: nan
env1_second_0:                 episode reward: 47.5000,                 loss: nan
Episode: 1541/10000 (15.4100%),                 avg. length: 642.05,                last time consumption/overall running time: 840.2134s / 168276.9102 s
env0_first_0:                 episode reward: -41.1000,                 loss: 0.4208
env0_second_0:                 episode reward: 41.1000,                 loss: 0.3232
env1_first_0:                 episode reward: -67.7500,                 loss: nan
env1_second_0:                 episode reward: 67.7500,                 loss: nan
Episode: 1561/10000 (15.6100%),                 avg. length: 664.45,                last time consumption/overall running time: 860.3474s / 169137.2576 s
env0_first_0:                 episode reward: -59.7500,                 loss: 0.4432
env0_second_0:                 episode reward: 59.7500,                 loss: 0.3344
env1_first_0:                 episode reward: -63.0000,                 loss: nan
env1_second_0:                 episode reward: 63.0000,                 loss: nan
Episode: 1581/10000 (15.8100%),                 avg. length: 523.45,                last time consumption/overall running time: 683.7015s / 169820.9591 s
env0_first_0:                 episode reward: -64.5000,                 loss: 0.5051
env0_second_0:                 episode reward: 64.5000,                 loss: 0.3901
env1_first_0:                 episode reward: -66.8000,                 loss: nan
env1_second_0:                 episode reward: 66.8000,                 loss: nan
Episode: 1601/10000 (16.0100%),                 avg. length: 624.75,                last time consumption/overall running time: 813.0377s / 170633.9968 s
env0_first_0:                 episode reward: -65.8000,                 loss: 0.5717
env0_second_0:                 episode reward: 65.8000,                 loss: 0.4548
env1_first_0:                 episode reward: -59.8500,                 loss: nan
env1_second_0:                 episode reward: 59.8500,                 loss: nan
Episode: 1621/10000 (16.2100%),                 avg. length: 584.85,                last time consumption/overall running time: 763.0599s / 171397.0567 s
env0_first_0:                 episode reward: -60.0000,                 loss: 0.5976
env0_second_0:                 episode reward: 60.0000,                 loss: 0.4876
env1_first_0:                 episode reward: -66.1500,                 loss: nan
env1_second_0:                 episode reward: 66.1500,                 loss: nan
Episode: 1641/10000 (16.4100%),                 avg. length: 530.25,                last time consumption/overall running time: 689.2730s / 172086.3297 s
env0_first_0:                 episode reward: -51.0000,                 loss: 0.6191
env0_second_0:                 episode reward: 51.0000,                 loss: 0.5360
env1_first_0:                 episode reward: -67.9000,                 loss: nan
env1_second_0:                 episode reward: 67.9000,                 loss: nan
Episode: 1661/10000 (16.6100%),                 avg. length: 537.85,                last time consumption/overall running time: 699.7719s / 172786.1017 s
env0_first_0:                 episode reward: -60.4500,                 loss: 0.6233
env0_second_0:                 episode reward: 60.4500,                 loss: 0.5682
env1_first_0:                 episode reward: -63.2500,                 loss: nan
env1_second_0:                 episode reward: 63.2500,                 loss: nan
Episode: 1681/10000 (16.8100%),                 avg. length: 567.05,                last time consumption/overall running time: 737.1385s / 173523.2401 s
env0_first_0:                 episode reward: -52.8500,                 loss: 0.6988
env0_second_0:                 episode reward: 52.8500,                 loss: 0.5330
env1_first_0:                 episode reward: -65.1500,                 loss: nan
env1_second_0:                 episode reward: 65.1500,                 loss: nan
Episode: 1701/10000 (17.0100%),                 avg. length: 503.3,                last time consumption/overall running time: 659.0368s / 174182.2769 s
env0_first_0:                 episode reward: -59.3500,                 loss: 0.6706
env0_second_0:                 episode reward: 59.3500,                 loss: 0.5751
env1_first_0:                 episode reward: -72.7000,                 loss: nan
env1_second_0:                 episode reward: 72.7000,                 loss: nan
Episode: 1721/10000 (17.2100%),                 avg. length: 530.55,                last time consumption/overall running time: 690.3467s / 174872.6236 s
env0_first_0:                 episode reward: -60.7000,                 loss: 0.6461
env0_second_0:                 episode reward: 60.7000,                 loss: 0.6032
env1_first_0:                 episode reward: -62.2500,                 loss: nan
env1_second_0:                 episode reward: 62.2500,                 loss: nan
Episode: 1741/10000 (17.4100%),                 avg. length: 537.75,                last time consumption/overall running time: 705.7052s / 175578.3288 s
env0_first_0:                 episode reward: -53.7500,                 loss: 0.6529
env0_second_0:                 episode reward: 53.7500,                 loss: 0.6323
env1_first_0:                 episode reward: -67.4000,                 loss: nan
env1_second_0:                 episode reward: 67.4000,                 loss: nan
Episode: 1761/10000 (17.6100%),                 avg. length: 452.05,                last time consumption/overall running time: 592.8030s / 176171.1318 s
env0_first_0:                 episode reward: -56.8500,                 loss: 0.6712
env0_second_0:                 episode reward: 56.8500,                 loss: 0.6585
env1_first_0:                 episode reward: -64.4500,                 loss: nan
env1_second_0:                 episode reward: 64.4500,                 loss: nan
Episode: 1781/10000 (17.8100%),                 avg. length: 406.3,                last time consumption/overall running time: 530.4816s / 176701.6134 s
env0_first_0:                 episode reward: -64.9500,                 loss: 0.7000
env0_second_0:                 episode reward: 64.9500,                 loss: 0.7170
env1_first_0:                 episode reward: -70.0000,                 loss: nan
env1_second_0:                 episode reward: 70.0000,                 loss: nan
Episode: 1801/10000 (18.0100%),                 avg. length: 480.7,                last time consumption/overall running time: 627.9838s / 177329.5972 s
env0_first_0:                 episode reward: -57.0000,                 loss: 0.7263
env0_second_0:                 episode reward: 57.0000,                 loss: 0.6892
env1_first_0:                 episode reward: -59.5500,                 loss: nan
env1_second_0:                 episode reward: 59.5500,                 loss: nan
Episode: 1821/10000 (18.2100%),                 avg. length: 467.2,                last time consumption/overall running time: 609.2251s / 177938.8224 s
env0_first_0:                 episode reward: -73.4000,                 loss: 0.7155
env0_second_0:                 episode reward: 73.4000,                 loss: 0.7554
env1_first_0:                 episode reward: -67.9500,                 loss: nan
env1_second_0:                 episode reward: 67.9500,                 loss: nan
Episode: 1841/10000 (18.4100%),                 avg. length: 422.1,                last time consumption/overall running time: 546.1498s / 178484.9722 s
env0_first_0:                 episode reward: -66.6500,                 loss: 0.7230
env0_second_0:                 episode reward: 66.6500,                 loss: 0.7524
env1_first_0:                 episode reward: -71.3500,                 loss: nan
env1_second_0:                 episode reward: 71.3500,                 loss: nan
Episode: 1861/10000 (18.6100%),                 avg. length: 474.25,                last time consumption/overall running time: 611.9487s / 179096.9209 s
env0_first_0:                 episode reward: -72.6500,                 loss: 0.8278
env0_second_0:                 episode reward: 72.6500,                 loss: 0.7683
env1_first_0:                 episode reward: -68.3500,                 loss: nan
env1_second_0:                 episode reward: 68.3500,                 loss: nan
Episode: 1881/10000 (18.8100%),                 avg. length: 476.25,                last time consumption/overall running time: 619.3912s / 179716.3120 s
env0_first_0:                 episode reward: -69.5500,                 loss: 0.8276
env0_second_0:                 episode reward: 69.5500,                 loss: 0.7760
env1_first_0:                 episode reward: -62.9500,                 loss: nan
env1_second_0:                 episode reward: 62.9500,                 loss: nan
Episode: 1901/10000 (19.0100%),                 avg. length: 503.0,                last time consumption/overall running time: 653.4358s / 180369.7478 s
env0_first_0:                 episode reward: -66.4000,                 loss: 0.8244
env0_second_0:                 episode reward: 66.4000,                 loss: 0.7737
env1_first_0:                 episode reward: -58.1500,                 loss: nan
env1_second_0:                 episode reward: 58.1500,                 loss: nan
Episode: 1921/10000 (19.2100%),                 avg. length: 528.0,                last time consumption/overall running time: 685.3223s / 181055.0701 s
env0_first_0:                 episode reward: -65.4500,                 loss: 0.8011
env0_second_0:                 episode reward: 65.4500,                 loss: 0.7458
env1_first_0:                 episode reward: -59.0500,                 loss: nan
env1_second_0:                 episode reward: 59.0500,                 loss: nan
Episode: 1941/10000 (19.4100%),                 avg. length: 464.7,                last time consumption/overall running time: 596.9917s / 181652.0619 s
env0_first_0:                 episode reward: -71.8500,                 loss: 0.8381
env0_second_0:                 episode reward: 71.8500,                 loss: 0.7710
env1_first_0:                 episode reward: -54.5500,                 loss: nan
env1_second_0:                 episode reward: 54.5500,                 loss: nan
Episode: 1961/10000 (19.6100%),                 avg. length: 387.55,                last time consumption/overall running time: 497.9601s / 182150.0220 s
env0_first_0:                 episode reward: -50.5500,                 loss: 0.8542
env0_second_0:                 episode reward: 50.5500,                 loss: 0.7771
env1_first_0:                 episode reward: -71.4000,                 loss: nan
env1_second_0:                 episode reward: 71.4000,                 loss: nan
Episode: 1981/10000 (19.8100%),                 avg. length: 493.6,                last time consumption/overall running time: 640.9523s / 182790.9744 s
env0_first_0:                 episode reward: -77.6000,                 loss: 0.8693
env0_second_0:                 episode reward: 77.6000,                 loss: 0.7445
env1_first_0:                 episode reward: -52.1000,                 loss: nan
env1_second_0:                 episode reward: 52.1000,                 loss: nan
Episode: 2001/10000 (20.0100%),                 avg. length: 415.0,                last time consumption/overall running time: 530.8331s / 183321.8075 s
env0_first_0:                 episode reward: -71.1500,                 loss: 0.8553
env0_second_0:                 episode reward: 71.1500,                 loss: 0.7574
env1_first_0:                 episode reward: -56.3500,                 loss: nan
env1_second_0:                 episode reward: 56.3500,                 loss: nan
Episode: 2021/10000 (20.2100%),                 avg. length: 402.75,                last time consumption/overall running time: 521.9456s / 183843.7530 s
env0_first_0:                 episode reward: -51.7000,                 loss: 0.9066
env0_second_0:                 episode reward: 51.7000,                 loss: 0.7864
env1_first_0:                 episode reward: -68.8000,                 loss: nan
env1_second_0:                 episode reward: 68.8000,                 loss: nan
Episode: 2041/10000 (20.4100%),                 avg. length: 510.7,                last time consumption/overall running time: 659.0866s / 184502.8397 s
env0_first_0:                 episode reward: -56.3500,                 loss: 1.0288
env0_second_0:                 episode reward: 56.3500,                 loss: 0.8484
env1_first_0:                 episode reward: -64.1500,                 loss: nan
env1_second_0:                 episode reward: 64.1500,                 loss: nan
Episode: 2061/10000 (20.6100%),                 avg. length: 451.55,                last time consumption/overall running time: 576.8619s / 185079.7015 s
env0_first_0:                 episode reward: -65.0000,                 loss: 1.0999
env0_second_0:                 episode reward: 65.0000,                 loss: 0.8824
env1_first_0:                 episode reward: -65.7000,                 loss: nan
env1_second_0:                 episode reward: 65.7000,                 loss: nan
Episode: 2081/10000 (20.8100%),                 avg. length: 537.3,                last time consumption/overall running time: 696.7978s / 185776.4994 s
env0_first_0:                 episode reward: -59.7500,                 loss: 1.1153
env0_second_0:                 episode reward: 59.7500,                 loss: 0.8849
env1_first_0:                 episode reward: -65.3000,                 loss: nan
env1_second_0:                 episode reward: 65.3000,                 loss: nan
Episode: 2101/10000 (21.0100%),                 avg. length: 487.65,                last time consumption/overall running time: 622.9831s / 186399.4825 s
env0_first_0:                 episode reward: -63.7500,                 loss: 1.0517
env0_second_0:                 episode reward: 63.7500,                 loss: 0.8319
env1_first_0:                 episode reward: -45.7500,                 loss: nan
env1_second_0:                 episode reward: 45.7500,                 loss: nan
Episode: 2121/10000 (21.2100%),                 avg. length: 645.55,                last time consumption/overall running time: 825.3888s / 187224.8713 s
env0_first_0:                 episode reward: -51.9000,                 loss: 1.0494
env0_second_0:                 episode reward: 51.9000,                 loss: 0.7760
env1_first_0:                 episode reward: -55.2500,                 loss: nan
env1_second_0:                 episode reward: 55.2500,                 loss: nan
Episode: 2141/10000 (21.4100%),                 avg. length: 426.65,                last time consumption/overall running time: 547.9260s / 187772.7973 s
env0_first_0:                 episode reward: -79.4500,                 loss: 1.0055
env0_second_0:                 episode reward: 79.4500,                 loss: 0.7846
env1_first_0:                 episode reward: -55.7000,                 loss: nan
env1_second_0:                 episode reward: 55.7000,                 loss: nan
Episode: 2161/10000 (21.6100%),                 avg. length: 515.7,                last time consumption/overall running time: 660.0925s / 188432.8898 s
env0_first_0:                 episode reward: -76.5000,                 loss: 0.9080
env0_second_0:                 episode reward: 76.5000,                 loss: 0.7278
env1_first_0:                 episode reward: -40.3000,                 loss: nan
env1_second_0:                 episode reward: 40.3000,                 loss: nan
Episode: 2181/10000 (21.8100%),                 avg. length: 577.65,                last time consumption/overall running time: 735.5887s / 189168.4785 s
env0_first_0:                 episode reward: -46.9500,                 loss: 0.9175
env0_second_0:                 episode reward: 46.9500,                 loss: 0.7494
env1_first_0:                 episode reward: -66.0500,                 loss: nan
env1_second_0:                 episode reward: 66.0500,                 loss: nan
Episode: 2201/10000 (22.0100%),                 avg. length: 557.6,                last time consumption/overall running time: 712.8958s / 189881.3742 s
env0_first_0:                 episode reward: -47.2500,                 loss: 0.9533
env0_second_0:                 episode reward: 47.2500,                 loss: 0.7575
env1_first_0:                 episode reward: -62.6500,                 loss: nan
env1_second_0:                 episode reward: 62.6500,                 loss: nan
Episode: 2221/10000 (22.2100%),                 avg. length: 562.95,                last time consumption/overall running time: 720.6727s / 190602.0470 s
env0_first_0:                 episode reward: -51.4000,                 loss: 1.0017
env0_second_0:                 episode reward: 51.4000,                 loss: 0.7869
env1_first_0:                 episode reward: -70.8000,                 loss: nan
env1_second_0:                 episode reward: 70.8000,                 loss: nan
Episode: 2241/10000 (22.4100%),                 avg. length: 500.55,                last time consumption/overall running time: 638.1305s / 191240.1775 s
env0_first_0:                 episode reward: -57.7500,                 loss: 1.0718
env0_second_0:                 episode reward: 57.7500,                 loss: 0.8292
env1_first_0:                 episode reward: -54.6500,                 loss: nan
env1_second_0:                 episode reward: 54.6500,                 loss: nan
Episode: 2261/10000 (22.6100%),                 avg. length: 549.1,                last time consumption/overall running time: 702.1933s / 191942.3708 s
env0_first_0:                 episode reward: -64.9500,                 loss: 1.0195
env0_second_0:                 episode reward: 64.9500,                 loss: 0.7961
env1_first_0:                 episode reward: -61.1000,                 loss: nan
env1_second_0:                 episode reward: 61.1000,                 loss: nan
Episode: 2281/10000 (22.8100%),                 avg. length: 534.3,                last time consumption/overall running time: 678.5928s / 192620.9636 s
env0_first_0:                 episode reward: -67.2000,                 loss: 0.9882
env0_second_0:                 episode reward: 67.2000,                 loss: 0.7962
env1_first_0:                 episode reward: -51.4000,                 loss: nan
env1_second_0:                 episode reward: 51.4000,                 loss: nan
Episode: 2301/10000 (23.0100%),                 avg. length: 459.8,                last time consumption/overall running time: 580.2348s / 193201.1985 s
env0_first_0:                 episode reward: -65.0500,                 loss: 0.9799
env0_second_0:                 episode reward: 65.0500,                 loss: 0.8064
env1_first_0:                 episode reward: -52.6000,                 loss: nan
env1_second_0:                 episode reward: 52.6000,                 loss: nan
Episode: 2321/10000 (23.2100%),                 avg. length: 590.05,                last time consumption/overall running time: 742.1732s / 193943.3717 s
env0_first_0:                 episode reward: -71.9000,                 loss: 1.0272
env0_second_0:                 episode reward: 71.9000,                 loss: 0.7646
env1_first_0:                 episode reward: -50.4500,                 loss: nan
env1_second_0:                 episode reward: 50.4500,                 loss: nan
Episode: 2341/10000 (23.4100%),                 avg. length: 445.9,                last time consumption/overall running time: 564.0918s / 194507.4635 s
env0_first_0:                 episode reward: -69.7000,                 loss: 1.1042
env0_second_0:                 episode reward: 69.7000,                 loss: 0.7981
env1_first_0:                 episode reward: -49.1500,                 loss: nan
env1_second_0:                 episode reward: 49.1500,                 loss: nan
Episode: 2361/10000 (23.6100%),                 avg. length: 473.65,                last time consumption/overall running time: 599.6379s / 195107.1014 s
env0_first_0:                 episode reward: -48.8000,                 loss: 1.1318
env0_second_0:                 episode reward: 48.8000,                 loss: 0.7928
env1_first_0:                 episode reward: -62.9500,                 loss: nan
env1_second_0:                 episode reward: 62.9500,                 loss: nan
Episode: 2381/10000 (23.8100%),                 avg. length: 561.3,                last time consumption/overall running time: 704.9367s / 195812.0381 s
env0_first_0:                 episode reward: -61.5000,                 loss: 1.1814
env0_second_0:                 episode reward: 61.5000,                 loss: 0.7391
env1_first_0:                 episode reward: -62.1000,                 loss: nan
env1_second_0:                 episode reward: 62.1000,                 loss: nan
Episode: 2401/10000 (24.0100%),                 avg. length: 582.6,                last time consumption/overall running time: 741.6609s / 196553.6989 s
env0_first_0:                 episode reward: -63.7500,                 loss: 1.2656
env0_second_0:                 episode reward: 63.7500,                 loss: 0.7550
env1_first_0:                 episode reward: -51.6500,                 loss: nan
env1_second_0:                 episode reward: 51.6500,                 loss: nan
Episode: 2421/10000 (24.2100%),                 avg. length: 382.25,                last time consumption/overall running time: 480.0064s / 197033.7054 s
env0_first_0:                 episode reward: -63.2000,                 loss: 1.2560
env0_second_0:                 episode reward: 63.2000,                 loss: 0.8050
env1_first_0:                 episode reward: -73.7500,                 loss: nan
env1_second_0:                 episode reward: 73.7500,                 loss: nan
Episode: 2441/10000 (24.4100%),                 avg. length: 494.25,                last time consumption/overall running time: 621.5686s / 197655.2739 s
env0_first_0:                 episode reward: -59.1000,                 loss: 1.3534
env0_second_0:                 episode reward: 59.1000,                 loss: 0.8541
env1_first_0:                 episode reward: -61.3500,                 loss: nan
env1_second_0:                 episode reward: 61.3500,                 loss: nan
Episode: 2461/10000 (24.6100%),                 avg. length: 433.3,                last time consumption/overall running time: 546.6986s / 198201.9725 s
env0_first_0:                 episode reward: -57.5000,                 loss: 1.3269
env0_second_0:                 episode reward: 57.5000,                 loss: 0.7669
env1_first_0:                 episode reward: -72.0000,                 loss: nan
env1_second_0:                 episode reward: 72.0000,                 loss: nan
Episode: 2481/10000 (24.8100%),                 avg. length: 430.55,                last time consumption/overall running time: 542.7125s / 198744.6849 s
env0_first_0:                 episode reward: -67.9000,                 loss: 1.3895
env0_second_0:                 episode reward: 67.9000,                 loss: 0.7970
env1_first_0:                 episode reward: -51.7500,                 loss: nan
env1_second_0:                 episode reward: 51.7500,                 loss: nan
Episode: 2501/10000 (25.0100%),                 avg. length: 411.3,                last time consumption/overall running time: 510.8403s / 199255.5253 s
env0_first_0:                 episode reward: -69.7500,                 loss: 1.3630
env0_second_0:                 episode reward: 69.7500,                 loss: 0.8181
env1_first_0:                 episode reward: -49.8500,                 loss: nan
env1_second_0:                 episode reward: 49.8500,                 loss: nan
Episode: 2521/10000 (25.2100%),                 avg. length: 462.45,                last time consumption/overall running time: 576.2272s / 199831.7524 s
env0_first_0:                 episode reward: -59.5000,                 loss: 1.3301
env0_second_0:                 episode reward: 59.5000,                 loss: 0.7720
env1_first_0:                 episode reward: -56.8500,                 loss: nan
env1_second_0:                 episode reward: 56.8500,                 loss: nan
Episode: 2541/10000 (25.4100%),                 avg. length: 538.05,                last time consumption/overall running time: 667.5055s / 200499.2579 s
env0_first_0:                 episode reward: -58.1000,                 loss: 1.3463
env0_second_0:                 episode reward: 58.1000,                 loss: 0.7347
env1_first_0:                 episode reward: -54.8500,                 loss: nan
env1_second_0:                 episode reward: 54.8500,                 loss: nan
Episode: 2561/10000 (25.6100%),                 avg. length: 545.4,                last time consumption/overall running time: 675.7465s / 201175.0044 s
env0_first_0:                 episode reward: -58.0500,                 loss: 1.3659
env0_second_0:                 episode reward: 58.0500,                 loss: 0.7748
env1_first_0:                 episode reward: -64.7500,                 loss: nan
env1_second_0:                 episode reward: 64.7500,                 loss: nan
Episode: 2581/10000 (25.8100%),                 avg. length: 488.4,                last time consumption/overall running time: 603.2965s / 201778.3009 s
env0_first_0:                 episode reward: -69.9500,                 loss: 1.3325
env0_second_0:                 episode reward: 69.9500,                 loss: 0.7133
env1_first_0:                 episode reward: -52.5000,                 loss: nan
env1_second_0:                 episode reward: 52.5000,                 loss: nan
Episode: 2601/10000 (26.0100%),                 avg. length: 416.25,                last time consumption/overall running time: 518.0812s / 202296.3821 s
env0_first_0:                 episode reward: -57.4500,                 loss: 1.3077
env0_second_0:                 episode reward: 57.4500,                 loss: 0.6927
env1_first_0:                 episode reward: -69.2000,                 loss: nan
env1_second_0:                 episode reward: 69.2000,                 loss: nan
Episode: 2621/10000 (26.2100%),                 avg. length: 555.7,                last time consumption/overall running time: 683.8548s / 202980.2369 s
env0_first_0:                 episode reward: -41.8500,                 loss: 1.2152
env0_second_0:                 episode reward: 41.8500,                 loss: 0.6427
env1_first_0:                 episode reward: -70.9500,                 loss: nan
env1_second_0:                 episode reward: 70.9500,                 loss: nan
Episode: 2641/10000 (26.4100%),                 avg. length: 484.05,                last time consumption/overall running time: 593.6476s / 203573.8845 s
env0_first_0:                 episode reward: -63.7500,                 loss: 1.1395
env0_second_0:                 episode reward: 63.7500,                 loss: 0.6510
env1_first_0:                 episode reward: -55.0500,                 loss: nan
env1_second_0:                 episode reward: 55.0500,                 loss: nan
Episode: 2661/10000 (26.6100%),                 avg. length: 517.55,                last time consumption/overall running time: 636.6301s / 204210.5146 s
env0_first_0:                 episode reward: -58.6000,                 loss: 1.1700
env0_second_0:                 episode reward: 58.6000,                 loss: 0.7147
env1_first_0:                 episode reward: -51.3500,                 loss: nan
env1_second_0:                 episode reward: 51.3500,                 loss: nan
Episode: 2681/10000 (26.8100%),                 avg. length: 411.45,                last time consumption/overall running time: 504.0408s / 204714.5554 s
env0_first_0:                 episode reward: -64.1000,                 loss: 1.1572
env0_second_0:                 episode reward: 64.1000,                 loss: 0.7607
env1_first_0:                 episode reward: -45.3000,                 loss: nan
env1_second_0:                 episode reward: 45.3000,                 loss: nan
Episode: 2701/10000 (27.0100%),                 avg. length: 420.9,                last time consumption/overall running time: 517.2368s / 205231.7922 s
env0_first_0:                 episode reward: -58.5500,                 loss: 1.2281
env0_second_0:                 episode reward: 58.5500,                 loss: 0.7305
env1_first_0:                 episode reward: -65.8500,                 loss: nan
env1_second_0:                 episode reward: 65.8500,                 loss: nan
Episode: 2721/10000 (27.2100%),                 avg. length: 448.05,                last time consumption/overall running time: 547.2673s / 205779.0595 s
env0_first_0:                 episode reward: -61.1000,                 loss: 1.1964
env0_second_0:                 episode reward: 61.1000,                 loss: 0.6936
env1_first_0:                 episode reward: -55.6000,                 loss: nan
env1_second_0:                 episode reward: 55.6000,                 loss: nan
Episode: 2741/10000 (27.4100%),                 avg. length: 445.3,                last time consumption/overall running time: 545.0272s / 206324.0867 s
env0_first_0:                 episode reward: -54.3500,                 loss: 1.2872
env0_second_0:                 episode reward: 54.3500,                 loss: 0.7540
env1_first_0:                 episode reward: -58.2000,                 loss: nan
env1_second_0:                 episode reward: 58.2000,                 loss: nan
Episode: 2761/10000 (27.6100%),                 avg. length: 494.45,                last time consumption/overall running time: 608.5780s / 206932.6647 s
env0_first_0:                 episode reward: -67.1500,                 loss: 1.2485
env0_second_0:                 episode reward: 67.1500,                 loss: 0.7996
env1_first_0:                 episode reward: -57.1000,                 loss: nan
env1_second_0:                 episode reward: 57.1000,                 loss: nan
Episode: 2781/10000 (27.8100%),                 avg. length: 490.65,                last time consumption/overall running time: 603.3080s / 207535.9727 s
env0_first_0:                 episode reward: -77.5000,                 loss: 1.2237
env0_second_0:                 episode reward: 77.5000,                 loss: 0.8082
env1_first_0:                 episode reward: -48.2000,                 loss: nan
env1_second_0:                 episode reward: 48.2000,                 loss: nan
Episode: 2801/10000 (28.0100%),                 avg. length: 423.65,                last time consumption/overall running time: 520.4496s / 208056.4223 s
env0_first_0:                 episode reward: -57.2000,                 loss: 1.2367
env0_second_0:                 episode reward: 57.2000,                 loss: 0.7835
env1_first_0:                 episode reward: -68.8000,                 loss: nan
env1_second_0:                 episode reward: 68.8000,                 loss: nan
Episode: 2821/10000 (28.2100%),                 avg. length: 429.35,                last time consumption/overall running time: 526.5178s / 208582.9401 s
env0_first_0:                 episode reward: -65.3500,                 loss: 1.2358
env0_second_0:                 episode reward: 65.3500,                 loss: 0.8065
env1_first_0:                 episode reward: -59.6500,                 loss: nan
env1_second_0:                 episode reward: 59.6500,                 loss: nan
Episode: 2841/10000 (28.4100%),                 avg. length: 461.95,                last time consumption/overall running time: 569.7636s / 209152.7037 s
env0_first_0:                 episode reward: -53.4500,                 loss: 1.3194
env0_second_0:                 episode reward: 53.4500,                 loss: 0.8568
env1_first_0:                 episode reward: -65.2000,                 loss: nan
env1_second_0:                 episode reward: 65.2000,                 loss: nan
Episode: 2861/10000 (28.6100%),                 avg. length: 492.9,                last time consumption/overall running time: 607.8094s / 209760.5130 s
env0_first_0:                 episode reward: -59.0500,                 loss: 1.3484
env0_second_0:                 episode reward: 59.0500,                 loss: 0.8549
env1_first_0:                 episode reward: -50.7000,                 loss: nan
env1_second_0:                 episode reward: 50.7000,                 loss: nan
Episode: 2881/10000 (28.8100%),                 avg. length: 427.85,                last time consumption/overall running time: 526.4888s / 210287.0019 s
env0_first_0:                 episode reward: -70.8000,                 loss: 1.2688
env0_second_0:                 episode reward: 70.8000,                 loss: 0.7565
env1_first_0:                 episode reward: -63.6000,                 loss: nan
env1_second_0:                 episode reward: 63.6000,                 loss: nan
Episode: 2901/10000 (29.0100%),                 avg. length: 502.0,                last time consumption/overall running time: 617.0681s / 210904.0700 s
env0_first_0:                 episode reward: -60.2500,                 loss: 1.3067
env0_second_0:                 episode reward: 60.2500,                 loss: 0.7361
env1_first_0:                 episode reward: -40.0500,                 loss: nan
env1_second_0:                 episode reward: 40.0500,                 loss: nan
Episode: 2921/10000 (29.2100%),                 avg. length: 443.75,                last time consumption/overall running time: 543.4716s / 211447.5416 s
env0_first_0:                 episode reward: -82.7000,                 loss: 1.2615
env0_second_0:                 episode reward: 82.7000,                 loss: 0.7300
env1_first_0:                 episode reward: -47.1500,                 loss: nan
env1_second_0:                 episode reward: 47.1500,                 loss: nan
Episode: 2941/10000 (29.4100%),                 avg. length: 525.85,                last time consumption/overall running time: 648.1452s / 212095.6868 s
env0_first_0:                 episode reward: -72.9500,                 loss: 1.2380
env0_second_0:                 episode reward: 72.9500,                 loss: 0.7931
env1_first_0:                 episode reward: -51.0000,                 loss: nan
env1_second_0:                 episode reward: 51.0000,                 loss: nan
Episode: 2961/10000 (29.6100%),                 avg. length: 464.5,                last time consumption/overall running time: 569.8175s / 212665.5042 s
env0_first_0:                 episode reward: -56.1500,                 loss: 1.1979
env0_second_0:                 episode reward: 56.1500,                 loss: 0.8008
env1_first_0:                 episode reward: -72.3500,                 loss: nan
env1_second_0:                 episode reward: 72.3500,                 loss: nan
Episode: 2981/10000 (29.8100%),                 avg. length: 445.45,                last time consumption/overall running time: 551.4109s / 213216.9151 s
env0_first_0:                 episode reward: -61.5500,                 loss: 1.1985
env0_second_0:                 episode reward: 61.5500,                 loss: 0.7993
env1_first_0:                 episode reward: -77.1500,                 loss: nan
env1_second_0:                 episode reward: 77.1500,                 loss: nan
Episode: 3001/10000 (30.0100%),                 avg. length: 564.9,                last time consumption/overall running time: 698.6038s / 213915.5189 s
env0_first_0:                 episode reward: -62.9500,                 loss: 1.2260
env0_second_0:                 episode reward: 62.9500,                 loss: 0.7868
env1_first_0:                 episode reward: -60.0500,                 loss: nan
env1_second_0:                 episode reward: 60.0500,                 loss: nan
Episode: 3021/10000 (30.2100%),                 avg. length: 564.55,                last time consumption/overall running time: 682.4656s / 214597.9845 s
env0_first_0:                 episode reward: -53.2000,                 loss: 1.2042
env0_second_0:                 episode reward: 53.2000,                 loss: 0.8326
env1_first_0:                 episode reward: -65.4000,                 loss: nan
env1_second_0:                 episode reward: 65.4000,                 loss: nan
Episode: 3041/10000 (30.4100%),                 avg. length: 447.75,                last time consumption/overall running time: 543.7897s / 215141.7742 s
env0_first_0:                 episode reward: -71.8500,                 loss: 1.1878
env0_second_0:                 episode reward: 71.8500,                 loss: 0.8188
env1_first_0:                 episode reward: -57.4000,                 loss: nan
env1_second_0:                 episode reward: 57.4000,                 loss: nan
Episode: 3061/10000 (30.6100%),                 avg. length: 435.0,                last time consumption/overall running time: 527.9816s / 215669.7557 s
env0_first_0:                 episode reward: -61.7000,                 loss: 1.1576
env0_second_0:                 episode reward: 61.7000,                 loss: 0.8483
env1_first_0:                 episode reward: -62.8500,                 loss: nan
env1_second_0:                 episode reward: 62.8500,                 loss: nan
Episode: 3081/10000 (30.8100%),                 avg. length: 526.05,                last time consumption/overall running time: 638.9806s / 216308.7363 s
env0_first_0:                 episode reward: -61.7500,                 loss: 1.1566
env0_second_0:                 episode reward: 61.7500,                 loss: 0.8019
env1_first_0:                 episode reward: -59.9500,                 loss: nan
env1_second_0:                 episode reward: 59.9500,                 loss: nan
Episode: 3101/10000 (31.0100%),                 avg. length: 507.1,                last time consumption/overall running time: 611.3720s / 216920.1083 s
env0_first_0:                 episode reward: -45.1000,                 loss: 1.2253
env0_second_0:                 episode reward: 45.1000,                 loss: 0.8654
env1_first_0:                 episode reward: -63.4500,                 loss: nan
env1_second_0:                 episode reward: 63.4500,                 loss: nan
Episode: 3121/10000 (31.2100%),                 avg. length: 560.25,                last time consumption/overall running time: 682.4882s / 217602.5965 s
env0_first_0:                 episode reward: -67.7500,                 loss: 1.3400
env0_second_0:                 episode reward: 67.7500,                 loss: 0.8249
env1_first_0:                 episode reward: -51.0000,                 loss: nan
env1_second_0:                 episode reward: 51.0000,                 loss: nan
Episode: 3141/10000 (31.4100%),                 avg. length: 518.1,                last time consumption/overall running time: 622.8159s / 218225.4124 s
env0_first_0:                 episode reward: -66.9000,                 loss: 1.2680
env0_second_0:                 episode reward: 66.9000,                 loss: 0.9039
env1_first_0:                 episode reward: -55.7000,                 loss: nan
env1_second_0:                 episode reward: 55.7000,                 loss: nan
Episode: 3161/10000 (31.6100%),                 avg. length: 476.0,                last time consumption/overall running time: 571.8615s / 218797.2739 s
env0_first_0:                 episode reward: -61.2000,                 loss: 1.2882
env0_second_0:                 episode reward: 61.2000,                 loss: 0.8682
env1_first_0:                 episode reward: -54.2000,                 loss: nan
env1_second_0:                 episode reward: 54.2000,                 loss: nan
Episode: 3181/10000 (31.8100%),                 avg. length: 439.9,                last time consumption/overall running time: 532.5829s / 219329.8568 s
env0_first_0:                 episode reward: -55.4000,                 loss: 1.3361
env0_second_0:                 episode reward: 55.4000,                 loss: 0.8756
env1_first_0:                 episode reward: -63.6500,                 loss: nan
env1_second_0:                 episode reward: 63.6500,                 loss: nan
Episode: 3201/10000 (32.0100%),                 avg. length: 573.2,                last time consumption/overall running time: 693.3330s / 220023.1899 s
env0_first_0:                 episode reward: -51.1500,                 loss: 1.2915
env0_second_0:                 episode reward: 51.1500,                 loss: 0.8649
env1_first_0:                 episode reward: -71.0000,                 loss: nan
env1_second_0:                 episode reward: 71.0000,                 loss: nan
Episode: 3221/10000 (32.2100%),                 avg. length: 603.4,                last time consumption/overall running time: 729.0601s / 220752.2499 s
env0_first_0:                 episode reward: -56.7000,                 loss: 1.2363
env0_second_0:                 episode reward: 56.7000,                 loss: 0.8466
env1_first_0:                 episode reward: -56.9500,                 loss: nan
env1_second_0:                 episode reward: 56.9500,                 loss: nan
Episode: 3241/10000 (32.4100%),                 avg. length: 528.05,                last time consumption/overall running time: 631.1951s / 221383.4450 s
env0_first_0:                 episode reward: -48.2000,                 loss: 1.3278
env0_second_0:                 episode reward: 48.2000,                 loss: 0.8250
env1_first_0:                 episode reward: -67.9000,                 loss: nan
env1_second_0:                 episode reward: 67.9000,                 loss: nan
Episode: 3261/10000 (32.6100%),                 avg. length: 435.0,                last time consumption/overall running time: 523.2190s / 221906.6640 s
env0_first_0:                 episode reward: -60.4000,                 loss: 1.3322
env0_second_0:                 episode reward: 60.4000,                 loss: 0.8715
env1_first_0:                 episode reward: -59.3000,                 loss: nan
env1_second_0:                 episode reward: 59.3000,                 loss: nan
Episode: 3281/10000 (32.8100%),                 avg. length: 514.8,                last time consumption/overall running time: 733.1761s / 222639.8402 s
env0_first_0:                 episode reward: -50.4000,                 loss: 1.2631
env0_second_0:                 episode reward: 50.4000,                 loss: 0.8745
env1_first_0:                 episode reward: -69.7000,                 loss: nan
env1_second_0:                 episode reward: 69.7000,                 loss: nan
Episode: 3301/10000 (33.0100%),                 avg. length: 703.6,                last time consumption/overall running time: 851.6062s / 223491.4464 s
env0_first_0:                 episode reward: -56.4000,                 loss: 1.2477
env0_second_0:                 episode reward: 56.4000,                 loss: 0.8951
env1_first_0:                 episode reward: -56.3500,                 loss: nan
env1_second_0:                 episode reward: 56.3500,                 loss: nan
Episode: 3321/10000 (33.2100%),                 avg. length: 561.7,                last time consumption/overall running time: 678.2015s / 224169.6479 s
env0_first_0:                 episode reward: -55.7500,                 loss: 1.2688
env0_second_0:                 episode reward: 55.7500,                 loss: 0.8579
env1_first_0:                 episode reward: -68.0500,                 loss: nan
env1_second_0:                 episode reward: 68.0500,                 loss: nan
Episode: 3341/10000 (33.4100%),                 avg. length: 609.65,                last time consumption/overall running time: 738.3343s / 224907.9822 s
env0_first_0:                 episode reward: -51.8000,                 loss: 1.2550
env0_second_0:                 episode reward: 51.8000,                 loss: 0.8110
env1_first_0:                 episode reward: -67.6000,                 loss: nan
env1_second_0:                 episode reward: 67.6000,                 loss: nan
Episode: 3361/10000 (33.6100%),                 avg. length: 466.9,                last time consumption/overall running time: 560.8468s / 225468.8290 s
env0_first_0:                 episode reward: -63.0000,                 loss: 1.2109
env0_second_0:                 episode reward: 63.0000,                 loss: 0.7719
env1_first_0:                 episode reward: -63.3500,                 loss: nan
env1_second_0:                 episode reward: 63.3500,                 loss: nan
Episode: 3381/10000 (33.8100%),                 avg. length: 531.65,                last time consumption/overall running time: 635.8103s / 226104.6393 s
env0_first_0:                 episode reward: -66.2000,                 loss: 1.1374
env0_second_0:                 episode reward: 66.2000,                 loss: 0.7822
env1_first_0:                 episode reward: -53.2500,                 loss: nan
env1_second_0:                 episode reward: 53.2500,                 loss: nan
Episode: 3401/10000 (34.0100%),                 avg. length: 416.15,                last time consumption/overall running time: 499.1962s / 226603.8355 s
env0_first_0:                 episode reward: -49.3000,                 loss: 1.2186
env0_second_0:                 episode reward: 49.3000,                 loss: 0.8272
env1_first_0:                 episode reward: -69.0000,                 loss: nan
env1_second_0:                 episode reward: 69.0000,                 loss: nan
Episode: 3421/10000 (34.2100%),                 avg. length: 436.2,                last time consumption/overall running time: 529.0353s / 227132.8708 s
env0_first_0:                 episode reward: -63.2000,                 loss: 1.2970
env0_second_0:                 episode reward: 63.2000,                 loss: 0.8996
env1_first_0:                 episode reward: -59.3000,                 loss: nan
env1_second_0:                 episode reward: 59.3000,                 loss: nan
Episode: 3441/10000 (34.4100%),                 avg. length: 465.05,                last time consumption/overall running time: 561.3674s / 227694.2382 s
env0_first_0:                 episode reward: -59.7500,                 loss: 1.2933
env0_second_0:                 episode reward: 59.7500,                 loss: 0.9572
env1_first_0:                 episode reward: -54.9500,                 loss: nan
env1_second_0:                 episode reward: 54.9500,                 loss: nan
Episode: 3461/10000 (34.6100%),                 avg. length: 484.2,                last time consumption/overall running time: 578.0419s / 228272.2800 s
env0_first_0:                 episode reward: -62.9000,                 loss: 1.4129
env0_second_0:                 episode reward: 62.9000,                 loss: 0.8957
env1_first_0:                 episode reward: -68.8000,                 loss: nan
env1_second_0:                 episode reward: 68.8000,                 loss: nan
Episode: 3481/10000 (34.8100%),                 avg. length: 437.15,                last time consumption/overall running time: 517.8449s / 228790.1249 s
env0_first_0:                 episode reward: -71.2000,                 loss: 1.5557
env0_second_0:                 episode reward: 71.2000,                 loss: 0.9453
env1_first_0:                 episode reward: -42.4500,                 loss: nan
env1_second_0:                 episode reward: 42.4500,                 loss: nan
Episode: 3501/10000 (35.0100%),                 avg. length: 535.1,                last time consumption/overall running time: 634.1273s / 229424.2522 s
env0_first_0:                 episode reward: -50.1500,                 loss: 1.5561
env0_second_0:                 episode reward: 50.1500,                 loss: 0.9965
env1_first_0:                 episode reward: -63.6000,                 loss: nan
env1_second_0:                 episode reward: 63.6000,                 loss: nan
Episode: 3521/10000 (35.2100%),                 avg. length: 607.5,                last time consumption/overall running time: 718.6731s / 230142.9252 s
env0_first_0:                 episode reward: -63.8500,                 loss: 1.5117
env0_second_0:                 episode reward: 63.8500,                 loss: 0.9588
env1_first_0:                 episode reward: -49.8000,                 loss: nan
env1_second_0:                 episode reward: 49.8000,                 loss: nan
Episode: 3541/10000 (35.4100%),                 avg. length: 598.15,                last time consumption/overall running time: 706.6454s / 230849.5707 s
env0_first_0:                 episode reward: -69.2000,                 loss: 1.4620
env0_second_0:                 episode reward: 69.2000,                 loss: 0.9048
env1_first_0:                 episode reward: -53.8500,                 loss: nan
env1_second_0:                 episode reward: 53.8500,                 loss: nan
Episode: 3561/10000 (35.6100%),                 avg. length: 330.75,                last time consumption/overall running time: 393.0682s / 231242.6389 s
env0_first_0:                 episode reward: -57.5000,                 loss: 1.5040
env0_second_0:                 episode reward: 57.5000,                 loss: 0.9012
env1_first_0:                 episode reward: -82.0500,                 loss: nan
env1_second_0:                 episode reward: 82.0500,                 loss: nan
Episode: 3581/10000 (35.8100%),                 avg. length: 565.9,                last time consumption/overall running time: 668.7294s / 231911.3683 s
env0_first_0:                 episode reward: -40.8000,                 loss: 1.4872
env0_second_0:                 episode reward: 40.8000,                 loss: 0.8696
env1_first_0:                 episode reward: -61.6000,                 loss: nan
env1_second_0:                 episode reward: 61.6000,                 loss: nan
Episode: 3601/10000 (36.0100%),                 avg. length: 540.15,                last time consumption/overall running time: 638.8096s / 232550.1779 s
env0_first_0:                 episode reward: -62.3000,                 loss: 1.2952
env0_second_0:                 episode reward: 62.3000,                 loss: 0.8243
env1_first_0:                 episode reward: -42.7500,                 loss: nan
env1_second_0:                 episode reward: 42.7500,                 loss: nan
Episode: 3621/10000 (36.2100%),                 avg. length: 614.15,                last time consumption/overall running time: 725.0348s / 233275.2127 s
env0_first_0:                 episode reward: -60.3500,                 loss: 1.2975
env0_second_0:                 episode reward: 60.3500,                 loss: 0.8067
env1_first_0:                 episode reward: -49.9000,                 loss: nan
env1_second_0:                 episode reward: 49.9000,                 loss: nan
Episode: 3641/10000 (36.4100%),                 avg. length: 714.85,                last time consumption/overall running time: 837.9511s / 234113.1637 s
env0_first_0:                 episode reward: -38.7500,                 loss: 1.0203
env0_second_0:                 episode reward: 38.7500,                 loss: 0.7397
env1_first_0:                 episode reward: -46.6500,                 loss: nan
env1_second_0:                 episode reward: 46.6500,                 loss: nan
Episode: 3661/10000 (36.6100%),                 avg. length: 581.55,                last time consumption/overall running time: 684.5867s / 234797.7505 s
env0_first_0:                 episode reward: -54.4000,                 loss: 0.9344
env0_second_0:                 episode reward: 54.4000,                 loss: 0.6658
env1_first_0:                 episode reward: -54.8000,                 loss: nan
env1_second_0:                 episode reward: 54.8000,                 loss: nan
Episode: 3681/10000 (36.8100%),                 avg. length: 433.2,                last time consumption/overall running time: 516.4277s / 235314.1782 s
env0_first_0:                 episode reward: -54.9000,                 loss: 0.9714
env0_second_0:                 episode reward: 54.9000,                 loss: 0.6840
env1_first_0:                 episode reward: -69.1000,                 loss: nan
env1_second_0:                 episode reward: 69.1000,                 loss: nan
Episode: 3701/10000 (37.0100%),                 avg. length: 663.4,                last time consumption/overall running time: 784.5585s / 236098.7366 s
env0_first_0:                 episode reward: -30.1000,                 loss: 1.0218
env0_second_0:                 episode reward: 30.1000,                 loss: 0.6837
env1_first_0:                 episode reward: -70.7500,                 loss: nan
env1_second_0:                 episode reward: 70.7500,                 loss: nan
Episode: 3721/10000 (37.2100%),                 avg. length: 647.75,                last time consumption/overall running time: 771.4448s / 236870.1815 s
env0_first_0:                 episode reward: -53.7000,                 loss: 1.1681
env0_second_0:                 episode reward: 53.7000,                 loss: 0.7830
env1_first_0:                 episode reward: -56.4500,                 loss: nan
env1_second_0:                 episode reward: 56.4500,                 loss: nan
Episode: 3741/10000 (37.4100%),                 avg. length: 689.55,                last time consumption/overall running time: 811.9912s / 237682.1727 s
env0_first_0:                 episode reward: -56.8000,                 loss: 1.2000
env0_second_0:                 episode reward: 56.8000,                 loss: 0.8121
env1_first_0:                 episode reward: -38.8500,                 loss: nan
env1_second_0:                 episode reward: 38.8500,                 loss: nan
Episode: 3761/10000 (37.6100%),                 avg. length: 475.15,                last time consumption/overall running time: 559.4071s / 238241.5798 s
env0_first_0:                 episode reward: -71.5500,                 loss: 1.1325
env0_second_0:                 episode reward: 71.5500,                 loss: 0.7954
env1_first_0:                 episode reward: -56.0000,                 loss: nan
env1_second_0:                 episode reward: 56.0000,                 loss: nan
Episode: 3781/10000 (37.8100%),                 avg. length: 500.5,                last time consumption/overall running time: 593.8105s / 238835.3903 s
env0_first_0:                 episode reward: -43.6000,                 loss: 1.1349
env0_second_0:                 episode reward: 43.6000,                 loss: 0.7997
env1_first_0:                 episode reward: -72.0500,                 loss: nan
env1_second_0:                 episode reward: 72.0500,                 loss: nan
Episode: 3801/10000 (38.0100%),                 avg. length: 331.25,                last time consumption/overall running time: 388.1797s / 239223.5700 s
env0_first_0:                 episode reward: -61.1500,                 loss: 1.1643
env0_second_0:                 episode reward: 61.1500,                 loss: 0.8468
env1_first_0:                 episode reward: -55.5500,                 loss: nan
env1_second_0:                 episode reward: 55.5500,                 loss: nan
Episode: 3821/10000 (38.2100%),                 avg. length: 553.7,                last time consumption/overall running time: 653.7086s / 239877.2786 s
env0_first_0:                 episode reward: -64.7500,                 loss: 1.0784
env0_second_0:                 episode reward: 64.7500,                 loss: 0.8461
env1_first_0:                 episode reward: -56.8000,                 loss: nan
env1_second_0:                 episode reward: 56.8000,                 loss: nan
Episode: 3841/10000 (38.4100%),                 avg. length: 484.15,                last time consumption/overall running time: 568.8636s / 240446.1422 s
env0_first_0:                 episode reward: -61.3500,                 loss: 1.1939
env0_second_0:                 episode reward: 61.3500,                 loss: 0.8786
env1_first_0:                 episode reward: -46.5000,                 loss: nan
env1_second_0:                 episode reward: 46.5000,                 loss: nan
Episode: 3861/10000 (38.6100%),                 avg. length: 484.1,                last time consumption/overall running time: 569.1303s / 241015.2725 s
env0_first_0:                 episode reward: -67.4000,                 loss: 1.2334
env0_second_0:                 episode reward: 67.4000,                 loss: 0.9066
env1_first_0:                 episode reward: -55.8000,                 loss: nan
env1_second_0:                 episode reward: 55.8000,                 loss: nan
Episode: 3881/10000 (38.8100%),                 avg. length: 512.5,                last time consumption/overall running time: 604.9325s / 241620.2050 s
env0_first_0:                 episode reward: -41.0000,                 loss: 1.2221
env0_second_0:                 episode reward: 41.0000,                 loss: 0.8858
env1_first_0:                 episode reward: -64.3500,                 loss: nan
env1_second_0:                 episode reward: 64.3500,                 loss: nan
Episode: 3901/10000 (39.0100%),                 avg. length: 522.55,                last time consumption/overall running time: 618.1390s / 242238.3440 s
env0_first_0:                 episode reward: -69.3000,                 loss: 1.2016
env0_second_0:                 episode reward: 69.3000,                 loss: 0.9484
env1_first_0:                 episode reward: -51.8500,                 loss: nan
env1_second_0:                 episode reward: 51.8500,                 loss: nan
Episode: 3921/10000 (39.2100%),                 avg. length: 620.95,                last time consumption/overall running time: 730.9895s / 242969.3335 s
env0_first_0:                 episode reward: -54.7500,                 loss: 1.2203
env0_second_0:                 episode reward: 54.7500,                 loss: 0.8853
env1_first_0:                 episode reward: -51.3000,                 loss: nan
env1_second_0:                 episode reward: 51.3000,                 loss: nan
Episode: 3941/10000 (39.4100%),                 avg. length: 557.7,                last time consumption/overall running time: 656.1463s / 243625.4798 s
env0_first_0:                 episode reward: -49.9500,                 loss: 1.1793
env0_second_0:                 episode reward: 49.9500,                 loss: 0.8466
env1_first_0:                 episode reward: -61.6500,                 loss: nan
env1_second_0:                 episode reward: 61.6500,                 loss: nan
Episode: 3961/10000 (39.6100%),                 avg. length: 557.8,                last time consumption/overall running time: 653.2646s / 244278.7444 s
env0_first_0:                 episode reward: -67.7000,                 loss: 1.2126
env0_second_0:                 episode reward: 67.7000,                 loss: 0.8491
env1_first_0:                 episode reward: -52.5000,                 loss: nan
env1_second_0:                 episode reward: 52.5000,                 loss: nan
Episode: 3981/10000 (39.8100%),                 avg. length: 565.2,                last time consumption/overall running time: 667.0553s / 244945.7998 s
env0_first_0:                 episode reward: -46.1500,                 loss: 1.1812
env0_second_0:                 episode reward: 46.1500,                 loss: 0.8188
env1_first_0:                 episode reward: -71.5000,                 loss: nan
env1_second_0:                 episode reward: 71.5000,                 loss: nan
Episode: 4001/10000 (40.0100%),                 avg. length: 454.25,                last time consumption/overall running time: 532.1338s / 245477.9335 s
env0_first_0:                 episode reward: -42.8500,                 loss: 1.1535
env0_second_0:                 episode reward: 42.8500,                 loss: 0.8056
env1_first_0:                 episode reward: -68.0500,                 loss: nan
env1_second_0:                 episode reward: 68.0500,                 loss: nan
Episode: 4021/10000 (40.2100%),                 avg. length: 473.0,                last time consumption/overall running time: 555.0118s / 246032.9453 s
env0_first_0:                 episode reward: -51.8500,                 loss: 1.1799
env0_second_0:                 episode reward: 51.8500,                 loss: 0.8292
env1_first_0:                 episode reward: -58.5000,                 loss: nan
env1_second_0:                 episode reward: 58.5000,                 loss: nan
Episode: 4041/10000 (40.4100%),                 avg. length: 469.95,                last time consumption/overall running time: 555.8291s / 246588.7744 s
env0_first_0:                 episode reward: -57.8500,                 loss: 1.1609
env0_second_0:                 episode reward: 57.8500,                 loss: 0.8329
env1_first_0:                 episode reward: -64.0000,                 loss: nan
env1_second_0:                 episode reward: 64.0000,                 loss: nan
Episode: 4061/10000 (40.6100%),                 avg. length: 504.75,                last time consumption/overall running time: 589.4112s / 247178.1856 s
env0_first_0:                 episode reward: -56.8500,                 loss: 1.1181
env0_second_0:                 episode reward: 56.8500,                 loss: 0.8000
env1_first_0:                 episode reward: -67.3500,                 loss: nan
env1_second_0:                 episode reward: 67.3500,                 loss: nan
Episode: 4081/10000 (40.8100%),                 avg. length: 620.75,                last time consumption/overall running time: 731.4975s / 247909.6831 s
env0_first_0:                 episode reward: -56.9500,                 loss: 1.2171
env0_second_0:                 episode reward: 56.9500,                 loss: 0.9119
env1_first_0:                 episode reward: -54.3000,                 loss: nan
env1_second_0:                 episode reward: 54.3000,                 loss: nan
Episode: 4101/10000 (41.0100%),                 avg. length: 374.85,                last time consumption/overall running time: 441.2118s / 248350.8949 s
env0_first_0:                 episode reward: -64.5500,                 loss: 1.2240
env0_second_0:                 episode reward: 64.5500,                 loss: 0.9428
env1_first_0:                 episode reward: -59.6500,                 loss: nan
env1_second_0:                 episode reward: 59.6500,                 loss: nan
Episode: 4121/10000 (41.2100%),                 avg. length: 495.5,                last time consumption/overall running time: 588.1715s / 248939.0664 s
env0_first_0:                 episode reward: -65.9000,                 loss: 1.2923
env0_second_0:                 episode reward: 65.9000,                 loss: 0.9439
env1_first_0:                 episode reward: -58.6000,                 loss: nan
env1_second_0:                 episode reward: 58.6000,                 loss: nan
Episode: 4141/10000 (41.4100%),                 avg. length: 578.0,                last time consumption/overall running time: 684.9697s / 249624.0361 s
env0_first_0:                 episode reward: -63.8500,                 loss: 1.2079
env0_second_0:                 episode reward: 63.8500,                 loss: 0.9785
env1_first_0:                 episode reward: -41.7500,                 loss: nan
env1_second_0:                 episode reward: 41.7500,                 loss: nan
Episode: 4161/10000 (41.6100%),                 avg. length: 563.95,                last time consumption/overall running time: 661.7663s / 250285.8024 s
env0_first_0:                 episode reward: -64.6000,                 loss: 1.2062
env0_second_0:                 episode reward: 64.6000,                 loss: 0.8986
env1_first_0:                 episode reward: -37.8000,                 loss: nan
env1_second_0:                 episode reward: 37.8000,                 loss: nan
Episode: 4181/10000 (41.8100%),                 avg. length: 541.55,                last time consumption/overall running time: 633.9745s / 250919.7768 s
env0_first_0:                 episode reward: -52.5000,                 loss: 1.1348
env0_second_0:                 episode reward: 52.5000,                 loss: 0.8986
env1_first_0:                 episode reward: -66.6500,                 loss: nan
env1_second_0:                 episode reward: 66.6500,                 loss: nan
Episode: 4201/10000 (42.0100%),                 avg. length: 549.65,                last time consumption/overall running time: 647.4718s / 251567.2486 s
env0_first_0:                 episode reward: -47.7000,                 loss: 1.1491
env0_second_0:                 episode reward: 47.7000,                 loss: 0.9160
env1_first_0:                 episode reward: -58.1500,                 loss: nan
env1_second_0:                 episode reward: 58.1500,                 loss: nan
Episode: 4221/10000 (42.2100%),                 avg. length: 636.3,                last time consumption/overall running time: 755.3477s / 252322.5964 s
env0_first_0:                 episode reward: -45.9500,                 loss: 1.1863
env0_second_0:                 episode reward: 45.9500,                 loss: 0.9245
env1_first_0:                 episode reward: -55.9000,                 loss: nan
env1_second_0:                 episode reward: 55.9000,                 loss: nan
Episode: 4241/10000 (42.4100%),                 avg. length: 435.75,                last time consumption/overall running time: 512.1018s / 252834.6981 s
env0_first_0:                 episode reward: -56.7500,                 loss: 1.3373
env0_second_0:                 episode reward: 56.7500,                 loss: 0.9341
env1_first_0:                 episode reward: -61.2500,                 loss: nan
env1_second_0:                 episode reward: 61.2500,                 loss: nan
Episode: 4261/10000 (42.6100%),                 avg. length: 491.75,                last time consumption/overall running time: 568.7465s / 253403.4446 s
env0_first_0:                 episode reward: -67.6000,                 loss: 1.3478
env0_second_0:                 episode reward: 67.6000,                 loss: 0.9059
env1_first_0:                 episode reward: -56.5500,                 loss: nan
env1_second_0:                 episode reward: 56.5500,                 loss: nan
Episode: 4281/10000 (42.8100%),                 avg. length: 548.15,                last time consumption/overall running time: 638.3772s / 254041.8218 s
env0_first_0:                 episode reward: -65.3000,                 loss: 1.2618
env0_second_0:                 episode reward: 65.3000,                 loss: 0.8856
env1_first_0:                 episode reward: -46.8500,                 loss: nan
env1_second_0:                 episode reward: 46.8500,                 loss: nan
Episode: 4301/10000 (43.0100%),                 avg. length: 430.5,                last time consumption/overall running time: 502.1447s / 254543.9665 s
env0_first_0:                 episode reward: -41.5500,                 loss: 1.2428
env0_second_0:                 episode reward: 41.5500,                 loss: 0.9156
env1_first_0:                 episode reward: -73.1000,                 loss: nan
env1_second_0:                 episode reward: 73.1000,                 loss: nan
Episode: 4321/10000 (43.2100%),                 avg. length: 418.95,                last time consumption/overall running time: 492.3513s / 255036.3178 s
env0_first_0:                 episode reward: -60.7000,                 loss: 1.3056
env0_second_0:                 episode reward: 60.7000,                 loss: 0.9430
env1_first_0:                 episode reward: -58.1500,                 loss: nan
env1_second_0:                 episode reward: 58.1500,                 loss: nan
Episode: 4341/10000 (43.4100%),                 avg. length: 501.5,                last time consumption/overall running time: 582.3479s / 255618.6657 s
env0_first_0:                 episode reward: -61.2500,                 loss: 1.2886
env0_second_0:                 episode reward: 61.2500,                 loss: 0.9096
env1_first_0:                 episode reward: -60.6500,                 loss: nan
env1_second_0:                 episode reward: 60.6500,                 loss: nan
Episode: 4361/10000 (43.6100%),                 avg. length: 605.15,                last time consumption/overall running time: 710.0854s / 256328.7510 s
env0_first_0:                 episode reward: -61.7500,                 loss: 1.3236
env0_second_0:                 episode reward: 61.7500,                 loss: 0.9637
env1_first_0:                 episode reward: -43.9500,                 loss: nan
env1_second_0:                 episode reward: 43.9500,                 loss: nan
Episode: 4381/10000 (43.8100%),                 avg. length: 632.35,                last time consumption/overall running time: 739.7960s / 257068.5470 s
env0_first_0:                 episode reward: -61.9000,                 loss: 1.2602
env0_second_0:                 episode reward: 61.9000,                 loss: 0.9316
env1_first_0:                 episode reward: -40.6000,                 loss: nan
env1_second_0:                 episode reward: 40.6000,                 loss: nan
Episode: 4401/10000 (44.0100%),                 avg. length: 553.5,                last time consumption/overall running time: 645.5868s / 257714.1338 s
env0_first_0:                 episode reward: -40.4000,                 loss: 1.1798
env0_second_0:                 episode reward: 40.4000,                 loss: 0.8441
env1_first_0:                 episode reward: -62.2500,                 loss: nan
env1_second_0:                 episode reward: 62.2500,                 loss: nan
Episode: 4421/10000 (44.2100%),                 avg. length: 861.65,                last time consumption/overall running time: 994.3928s / 258708.5266 s
env0_first_0:                 episode reward: -52.2000,                 loss: 1.0223
env0_second_0:                 episode reward: 52.2000,                 loss: 0.7244
env1_first_0:                 episode reward: -29.2500,                 loss: nan
env1_second_0:                 episode reward: 29.2500,                 loss: nan
Episode: 4441/10000 (44.4100%),                 avg. length: 556.8,                last time consumption/overall running time: 644.4218s / 259352.9484 s
env0_first_0:                 episode reward: -62.3000,                 loss: 0.8916
env0_second_0:                 episode reward: 62.3000,                 loss: 0.6569
env1_first_0:                 episode reward: -57.5000,                 loss: nan
env1_second_0:                 episode reward: 57.5000,                 loss: nan
Episode: 4461/10000 (44.6100%),                 avg. length: 484.8,                last time consumption/overall running time: 560.9090s / 259913.8574 s
env0_first_0:                 episode reward: -51.6000,                 loss: 0.9159
env0_second_0:                 episode reward: 51.6000,                 loss: 0.6790
env1_first_0:                 episode reward: -63.2000,                 loss: nan
env1_second_0:                 episode reward: 63.2000,                 loss: nan
Episode: 4481/10000 (44.8100%),                 avg. length: 464.5,                last time consumption/overall running time: 534.9327s / 260448.7901 s
env0_first_0:                 episode reward: -50.7500,                 loss: 0.9396
env0_second_0:                 episode reward: 50.7500,                 loss: 0.7299
env1_first_0:                 episode reward: -74.9500,                 loss: nan
env1_second_0:                 episode reward: 74.9500,                 loss: nan
Episode: 4501/10000 (45.0100%),                 avg. length: 439.0,                last time consumption/overall running time: 512.9785s / 260961.7686 s
env0_first_0:                 episode reward: -54.9000,                 loss: 1.0162
env0_second_0:                 episode reward: 54.9000,                 loss: 0.7760
env1_first_0:                 episode reward: -55.0500,                 loss: nan
env1_second_0:                 episode reward: 55.0500,                 loss: nan
Episode: 4521/10000 (45.2100%),                 avg. length: 480.3,                last time consumption/overall running time: 551.2092s / 261512.9778 s
env0_first_0:                 episode reward: -42.3000,                 loss: 1.1420
env0_second_0:                 episode reward: 42.3000,                 loss: 0.8672
env1_first_0:                 episode reward: -65.2500,                 loss: nan
env1_second_0:                 episode reward: 65.2500,                 loss: nan
Episode: 4541/10000 (45.4100%),                 avg. length: 547.45,                last time consumption/overall running time: 629.4482s / 262142.4260 s
env0_first_0:                 episode reward: -50.3500,                 loss: 1.1941
env0_second_0:                 episode reward: 50.3500,                 loss: 0.8877
env1_first_0:                 episode reward: -66.0000,                 loss: nan
env1_second_0:                 episode reward: 66.0000,                 loss: nan
Episode: 4561/10000 (45.6100%),                 avg. length: 610.45,                last time consumption/overall running time: 711.9660s / 262854.3920 s
env0_first_0:                 episode reward: -50.7500,                 loss: 1.1945
env0_second_0:                 episode reward: 50.7500,                 loss: 0.9387
env1_first_0:                 episode reward: -55.0500,                 loss: nan
env1_second_0:                 episode reward: 55.0500,                 loss: nan
Episode: 4581/10000 (45.8100%),                 avg. length: 590.95,                last time consumption/overall running time: 681.2799s / 263535.6719 s
env0_first_0:                 episode reward: -53.7000,                 loss: 1.0900
env0_second_0:                 episode reward: 53.7000,                 loss: 0.8618
env1_first_0:                 episode reward: -53.7000,                 loss: nan
env1_second_0:                 episode reward: 53.7000,                 loss: nan
Episode: 4601/10000 (46.0100%),                 avg. length: 584.35,                last time consumption/overall running time: 677.4027s / 264213.0745 s
env0_first_0:                 episode reward: -48.0500,                 loss: 1.0884
env0_second_0:                 episode reward: 48.0500,                 loss: 0.8168
env1_first_0:                 episode reward: -61.1000,                 loss: nan
env1_second_0:                 episode reward: 61.1000,                 loss: nan
Episode: 4621/10000 (46.2100%),                 avg. length: 519.5,                last time consumption/overall running time: 598.6832s / 264811.7577 s
env0_first_0:                 episode reward: -56.4500,                 loss: 1.0047
env0_second_0:                 episode reward: 56.4500,                 loss: 0.7418
env1_first_0:                 episode reward: -50.5500,                 loss: nan
env1_second_0:                 episode reward: 50.5500,                 loss: nan
Episode: 4641/10000 (46.4100%),                 avg. length: 462.65,                last time consumption/overall running time: 535.9744s / 265347.7321 s
env0_first_0:                 episode reward: -65.4500,                 loss: 0.9432
env0_second_0:                 episode reward: 65.4500,                 loss: 0.7306
env1_first_0:                 episode reward: -67.4500,                 loss: nan
env1_second_0:                 episode reward: 67.4500,                 loss: nan
Episode: 4661/10000 (46.6100%),                 avg. length: 481.75,                last time consumption/overall running time: 555.2516s / 265902.9838 s
env0_first_0:                 episode reward: -32.2500,                 loss: 0.9684
env0_second_0:                 episode reward: 32.2500,                 loss: 0.7531
env1_first_0:                 episode reward: -75.1500,                 loss: nan
env1_second_0:                 episode reward: 75.1500,                 loss: nan
Episode: 4681/10000 (46.8100%),                 avg. length: 647.4,                last time consumption/overall running time: 744.7836s / 266647.7674 s
env0_first_0:                 episode reward: -70.9500,                 loss: 0.9936
env0_second_0:                 episode reward: 70.9500,                 loss: 0.8313
env1_first_0:                 episode reward: -34.0000,                 loss: nan
env1_second_0:                 episode reward: 34.0000,                 loss: nan
Episode: 4701/10000 (47.0100%),                 avg. length: 604.15,                last time consumption/overall running time: 703.3019s / 267351.0693 s
env0_first_0:                 episode reward: -53.8500,                 loss: 1.0516
env0_second_0:                 episode reward: 53.8500,                 loss: 0.8051
env1_first_0:                 episode reward: -46.7500,                 loss: nan
env1_second_0:                 episode reward: 46.7500,                 loss: nan
Episode: 4721/10000 (47.2100%),                 avg. length: 664.3,                last time consumption/overall running time: 770.5608s / 268121.6301 s
env0_first_0:                 episode reward: -57.1500,                 loss: 1.0241
env0_second_0:                 episode reward: 57.1500,                 loss: 0.8902
env1_first_0:                 episode reward: -43.9500,                 loss: nan
env1_second_0:                 episode reward: 43.9500,                 loss: nan
Episode: 4741/10000 (47.4100%),                 avg. length: 582.4,                last time consumption/overall running time: 674.8183s / 268796.4484 s
env0_first_0:                 episode reward: -57.1000,                 loss: 1.0295
env0_second_0:                 episode reward: 57.1000,                 loss: 0.9013
env1_first_0:                 episode reward: -52.1500,                 loss: nan
env1_second_0:                 episode reward: 52.1500,                 loss: nan
Episode: 4761/10000 (47.6100%),                 avg. length: 477.4,                last time consumption/overall running time: 557.8410s / 269354.2895 s
env0_first_0:                 episode reward: -63.7500,                 loss: 1.0319
env0_second_0:                 episode reward: 63.7500,                 loss: 0.9503
env1_first_0:                 episode reward: -53.5500,                 loss: nan
env1_second_0:                 episode reward: 53.5500,                 loss: nan
Episode: 4781/10000 (47.8100%),                 avg. length: 489.2,                last time consumption/overall running time: 566.4068s / 269920.6962 s
env0_first_0:                 episode reward: -57.7000,                 loss: 1.0868
env0_second_0:                 episode reward: 57.7000,                 loss: 0.9664
env1_first_0:                 episode reward: -57.5500,                 loss: nan
env1_second_0:                 episode reward: 57.5500,                 loss: nan
Episode: 4801/10000 (48.0100%),                 avg. length: 612.95,                last time consumption/overall running time: 704.1442s / 270624.8405 s
env0_first_0:                 episode reward: -47.4500,                 loss: 1.0113
env0_second_0:                 episode reward: 47.4500,                 loss: 0.9730
env1_first_0:                 episode reward: -58.6000,                 loss: nan
env1_second_0:                 episode reward: 58.6000,                 loss: nan
Episode: 4821/10000 (48.2100%),                 avg. length: 561.55,                last time consumption/overall running time: 649.1121s / 271273.9526 s
env0_first_0:                 episode reward: -48.5000,                 loss: 1.0455
env0_second_0:                 episode reward: 48.5000,                 loss: 0.9297
env1_first_0:                 episode reward: -59.9000,                 loss: nan
env1_second_0:                 episode reward: 59.9000,                 loss: nan
Episode: 4841/10000 (48.4100%),                 avg. length: 589.45,                last time consumption/overall running time: 680.2167s / 271954.1692 s
env0_first_0:                 episode reward: -53.0500,                 loss: 1.0728
env0_second_0:                 episode reward: 53.0500,                 loss: 0.8748
env1_first_0:                 episode reward: -60.7000,                 loss: nan
env1_second_0:                 episode reward: 60.7000,                 loss: nan
Episode: 4861/10000 (48.6100%),                 avg. length: 539.6,                last time consumption/overall running time: 623.3149s / 272577.4841 s
env0_first_0:                 episode reward: -41.9000,                 loss: 1.0422
env0_second_0:                 episode reward: 41.9000,                 loss: 0.7782
env1_first_0:                 episode reward: -67.0500,                 loss: nan
env1_second_0:                 episode reward: 67.0500,                 loss: nan
Episode: 4881/10000 (48.8100%),                 avg. length: 459.35,                last time consumption/overall running time: 528.2581s / 273105.7422 s
env0_first_0:                 episode reward: -56.7500,                 loss: 1.0612
env0_second_0:                 episode reward: 56.7500,                 loss: 0.7988
env1_first_0:                 episode reward: -52.8000,                 loss: nan
env1_second_0:                 episode reward: 52.8000,                 loss: nan
Episode: 4901/10000 (49.0100%),                 avg. length: 554.2,                last time consumption/overall running time: 641.4733s / 273747.2154 s
env0_first_0:                 episode reward: -65.1500,                 loss: 1.0736
env0_second_0:                 episode reward: 65.1500,                 loss: 0.7993
env1_first_0:                 episode reward: -50.2500,                 loss: nan
env1_second_0:                 episode reward: 50.2500,                 loss: nan
Episode: 4921/10000 (49.2100%),                 avg. length: 509.75,                last time consumption/overall running time: 583.2099s / 274330.4253 s
env0_first_0:                 episode reward: -40.8000,                 loss: 1.0035
env0_second_0:                 episode reward: 40.8000,                 loss: 0.8595
env1_first_0:                 episode reward: -71.3500,                 loss: nan
env1_second_0:                 episode reward: 71.3500,                 loss: nan
Episode: 4941/10000 (49.4100%),                 avg. length: 531.0,                last time consumption/overall running time: 615.1229s / 274945.5481 s
env0_first_0:                 episode reward: -66.5000,                 loss: 1.0773
env0_second_0:                 episode reward: 66.5000,                 loss: 0.8951
env1_first_0:                 episode reward: -49.2500,                 loss: nan
env1_second_0:                 episode reward: 49.2500,                 loss: nan
Episode: 4961/10000 (49.6100%),                 avg. length: 536.8,                last time consumption/overall running time: 617.0613s / 275562.6094 s
env0_first_0:                 episode reward: -39.6000,                 loss: 1.0413
env0_second_0:                 episode reward: 39.6000,                 loss: 0.9146
env1_first_0:                 episode reward: -68.9000,                 loss: nan
env1_second_0:                 episode reward: 68.9000,                 loss: nan
Episode: 4981/10000 (49.8100%),                 avg. length: 532.5,                last time consumption/overall running time: 615.4584s / 276178.0679 s
env0_first_0:                 episode reward: -61.3500,                 loss: 0.9944
env0_second_0:                 episode reward: 61.3500,                 loss: 0.9110
env1_first_0:                 episode reward: -49.4500,                 loss: nan
env1_second_0:                 episode reward: 49.4500,                 loss: nan
Episode: 5001/10000 (50.0100%),                 avg. length: 515.35,                last time consumption/overall running time: 593.0252s / 276771.0930 s
env0_first_0:                 episode reward: -54.3000,                 loss: 1.0194
env0_second_0:                 episode reward: 54.3000,                 loss: 0.9208
env1_first_0:                 episode reward: -66.9500,                 loss: nan
env1_second_0:                 episode reward: 66.9500,                 loss: nan
Episode: 5021/10000 (50.2100%),                 avg. length: 610.55,                last time consumption/overall running time: 709.6879s / 277480.7810 s
env0_first_0:                 episode reward: -43.5500,                 loss: 0.9269
env0_second_0:                 episode reward: 43.5500,                 loss: 0.9615
env1_first_0:                 episode reward: -65.9000,                 loss: nan
env1_second_0:                 episode reward: 65.9000,                 loss: nan
Episode: 5041/10000 (50.4100%),                 avg. length: 545.85,                last time consumption/overall running time: 629.0094s / 278109.7903 s
env0_first_0:                 episode reward: -51.0500,                 loss: 0.9484
env0_second_0:                 episode reward: 51.0500,                 loss: 0.9925
env1_first_0:                 episode reward: -54.4000,                 loss: nan
env1_second_0:                 episode reward: 54.4000,                 loss: nan
Episode: 5061/10000 (50.6100%),                 avg. length: 534.75,                last time consumption/overall running time: 618.4530s / 278728.2433 s
env0_first_0:                 episode reward: -45.4500,                 loss: 1.0034
env0_second_0:                 episode reward: 45.4500,                 loss: 1.0344
env1_first_0:                 episode reward: -66.1500,                 loss: nan
env1_second_0:                 episode reward: 66.1500,                 loss: nan
Episode: 5081/10000 (50.8100%),                 avg. length: 568.5,                last time consumption/overall running time: 652.8118s / 279381.0551 s
env0_first_0:                 episode reward: -52.4000,                 loss: 1.0527
env0_second_0:                 episode reward: 52.4000,                 loss: 1.0159
env1_first_0:                 episode reward: -66.8000,                 loss: nan
env1_second_0:                 episode reward: 66.8000,                 loss: nan
Episode: 5101/10000 (51.0100%),                 avg. length: 431.65,                last time consumption/overall running time: 498.0990s / 279879.1541 s
env0_first_0:                 episode reward: -56.0000,                 loss: 1.0039
env0_second_0:                 episode reward: 56.0000,                 loss: 0.9637
env1_first_0:                 episode reward: -60.3000,                 loss: nan
env1_second_0:                 episode reward: 60.3000,                 loss: nan
Episode: 5121/10000 (51.2100%),                 avg. length: 575.15,                last time consumption/overall running time: 663.9115s / 280543.0655 s
env0_first_0:                 episode reward: -61.9000,                 loss: 1.0422
env0_second_0:                 episode reward: 61.9000,                 loss: 0.9234
env1_first_0:                 episode reward: -48.6000,                 loss: nan
env1_second_0:                 episode reward: 48.6000,                 loss: nan
Episode: 5141/10000 (51.4100%),                 avg. length: 793.55,                last time consumption/overall running time: 908.6426s / 281451.7081 s
env0_first_0:                 episode reward: -56.0000,                 loss: 1.0579
env0_second_0:                 episode reward: 56.0000,                 loss: 0.9452
env1_first_0:                 episode reward: -55.4000,                 loss: nan
env1_second_0:                 episode reward: 55.4000,                 loss: nan
Episode: 5161/10000 (51.6100%),                 avg. length: 694.95,                last time consumption/overall running time: 796.7443s / 282248.4525 s
env0_first_0:                 episode reward: -51.7000,                 loss: 0.9694
env0_second_0:                 episode reward: 51.7000,                 loss: 0.9039
env1_first_0:                 episode reward: -57.4500,                 loss: nan
env1_second_0:                 episode reward: 57.4500,                 loss: nan
Episode: 5181/10000 (51.8100%),                 avg. length: 638.7,                last time consumption/overall running time: 725.5636s / 282974.0161 s
env0_first_0:                 episode reward: -60.1500,                 loss: 0.9482
env0_second_0:                 episode reward: 60.1500,                 loss: 0.7874
env1_first_0:                 episode reward: -53.3000,                 loss: nan
env1_second_0:                 episode reward: 53.3000,                 loss: nan
Episode: 5201/10000 (52.0100%),                 avg. length: 555.15,                last time consumption/overall running time: 640.4911s / 283614.5072 s
env0_first_0:                 episode reward: -39.0000,                 loss: 0.9957
env0_second_0:                 episode reward: 39.0000,                 loss: 0.8002
env1_first_0:                 episode reward: -75.7500,                 loss: nan
env1_second_0:                 episode reward: 75.7500,                 loss: nan
Episode: 5221/10000 (52.2100%),                 avg. length: 580.0,                last time consumption/overall running time: 661.8515s / 284276.3587 s
env0_first_0:                 episode reward: -59.1500,                 loss: 1.0347
env0_second_0:                 episode reward: 59.1500,                 loss: 0.8425
env1_first_0:                 episode reward: -58.7000,                 loss: nan
env1_second_0:                 episode reward: 58.7000,                 loss: nan
Episode: 5241/10000 (52.4100%),                 avg. length: 569.8,                last time consumption/overall running time: 657.5452s / 284933.9038 s
env0_first_0:                 episode reward: -49.8000,                 loss: 1.0416
env0_second_0:                 episode reward: 49.8000,                 loss: 0.8724
env1_first_0:                 episode reward: -55.7500,                 loss: nan
env1_second_0:                 episode reward: 55.7500,                 loss: nan
Episode: 5261/10000 (52.6100%),                 avg. length: 554.65,                last time consumption/overall running time: 639.7351s / 285573.6390 s
env0_first_0:                 episode reward: -54.7000,                 loss: 1.0465
env0_second_0:                 episode reward: 54.7000,                 loss: 0.9061
env1_first_0:                 episode reward: -54.7500,                 loss: nan
env1_second_0:                 episode reward: 54.7500,                 loss: nan
Episode: 5281/10000 (52.8100%),                 avg. length: 487.5,                last time consumption/overall running time: 564.0989s / 286137.7378 s
env0_first_0:                 episode reward: -76.1500,                 loss: 1.1213
env0_second_0:                 episode reward: 76.1500,                 loss: 0.9032
env1_first_0:                 episode reward: -40.3500,                 loss: nan
env1_second_0:                 episode reward: 40.3500,                 loss: nan
Episode: 5301/10000 (53.0100%),                 avg. length: 448.5,                last time consumption/overall running time: 516.3843s / 286654.1221 s
env0_first_0:                 episode reward: -56.1000,                 loss: 1.1843
env0_second_0:                 episode reward: 56.1000,                 loss: 0.9544
env1_first_0:                 episode reward: -56.6500,                 loss: nan
env1_second_0:                 episode reward: 56.6500,                 loss: nan
Episode: 5321/10000 (53.2100%),                 avg. length: 407.6,                last time consumption/overall running time: 466.4678s / 287120.5899 s
env0_first_0:                 episode reward: -47.2500,                 loss: 1.2198
env0_second_0:                 episode reward: 47.2500,                 loss: 1.0126
env1_first_0:                 episode reward: -75.5000,                 loss: nan
env1_second_0:                 episode reward: 75.5000,                 loss: nan
Episode: 5341/10000 (53.4100%),                 avg. length: 507.6,                last time consumption/overall running time: 578.5061s / 287699.0960 s
env0_first_0:                 episode reward: -73.0000,                 loss: 1.2266
env0_second_0:                 episode reward: 73.0000,                 loss: 1.0486
env1_first_0:                 episode reward: -45.5000,                 loss: nan
env1_second_0:                 episode reward: 45.5000,                 loss: nan
Episode: 5361/10000 (53.6100%),                 avg. length: 437.1,                last time consumption/overall running time: 499.3195s / 288198.4156 s
env0_first_0:                 episode reward: -59.1500,                 loss: 1.2339
env0_second_0:                 episode reward: 59.1500,                 loss: 0.9665
env1_first_0:                 episode reward: -60.6000,                 loss: nan
env1_second_0:                 episode reward: 60.6000,                 loss: nan
Episode: 5381/10000 (53.8100%),                 avg. length: 572.25,                last time consumption/overall running time: 650.6098s / 288849.0254 s
env0_first_0:                 episode reward: -64.8500,                 loss: 1.2722
env0_second_0:                 episode reward: 64.8500,                 loss: 0.9945
env1_first_0:                 episode reward: -48.8000,                 loss: nan
env1_second_0:                 episode reward: 48.8000,                 loss: nan
Episode: 5401/10000 (54.0100%),                 avg. length: 547.35,                last time consumption/overall running time: 627.5775s / 289476.6029 s
env0_first_0:                 episode reward: -56.1500,                 loss: 1.2552
env0_second_0:                 episode reward: 56.1500,                 loss: 0.9264
env1_first_0:                 episode reward: -65.4500,                 loss: nan
env1_second_0:                 episode reward: 65.4500,                 loss: nan
Episode: 5421/10000 (54.2100%),                 avg. length: 531.15,                last time consumption/overall running time: 605.5645s / 290082.1674 s
env0_first_0:                 episode reward: -57.3000,                 loss: 1.2509
env0_second_0:                 episode reward: 57.3000,                 loss: 0.8941
env1_first_0:                 episode reward: -61.5000,                 loss: nan
env1_second_0:                 episode reward: 61.5000,                 loss: nan
Episode: 5441/10000 (54.4100%),                 avg. length: 416.4,                last time consumption/overall running time: 470.9786s / 290553.1460 s
env0_first_0:                 episode reward: -50.8500,                 loss: 1.2211
env0_second_0:                 episode reward: 50.8500,                 loss: 0.8948
env1_first_0:                 episode reward: -68.2000,                 loss: nan
env1_second_0:                 episode reward: 68.2000,                 loss: nan
Episode: 5461/10000 (54.6100%),                 avg. length: 597.4,                last time consumption/overall running time: 679.9456s / 291233.0916 s
env0_first_0:                 episode reward: -56.7500,                 loss: 1.2445
env0_second_0:                 episode reward: 56.7500,                 loss: 0.8733
env1_first_0:                 episode reward: -57.0000,                 loss: nan
env1_second_0:                 episode reward: 57.0000,                 loss: nan
Episode: 5481/10000 (54.8100%),                 avg. length: 549.5,                last time consumption/overall running time: 617.7337s / 291850.8252 s
env0_first_0:                 episode reward: -62.1500,                 loss: 1.1844
env0_second_0:                 episode reward: 62.1500,                 loss: 0.8965
env1_first_0:                 episode reward: -38.3500,                 loss: nan
env1_second_0:                 episode reward: 38.3500,                 loss: nan
Episode: 5501/10000 (55.0100%),                 avg. length: 568.0,                last time consumption/overall running time: 640.3139s / 292491.1391 s
env0_first_0:                 episode reward: -44.6500,                 loss: 1.1694
env0_second_0:                 episode reward: 44.6500,                 loss: 0.9163
env1_first_0:                 episode reward: -58.3000,                 loss: nan
env1_second_0:                 episode reward: 58.3000,                 loss: nan
Episode: 5521/10000 (55.2100%),                 avg. length: 535.6,                last time consumption/overall running time: 612.4093s / 293103.5484 s
env0_first_0:                 episode reward: -48.3500,                 loss: 1.1625
env0_second_0:                 episode reward: 48.3500,                 loss: 0.9206
env1_first_0:                 episode reward: -52.9500,                 loss: nan
env1_second_0:                 episode reward: 52.9500,                 loss: nan
Episode: 5541/10000 (55.4100%),                 avg. length: 514.8,                last time consumption/overall running time: 575.6522s / 293679.2005 s
env0_first_0:                 episode reward: -61.3500,                 loss: 1.0414
env0_second_0:                 episode reward: 61.3500,                 loss: 0.9362
env1_first_0:                 episode reward: -57.6000,                 loss: nan
env1_second_0:                 episode reward: 57.6000,                 loss: nan
Episode: 5561/10000 (55.6100%),                 avg. length: 472.9,                last time consumption/overall running time: 522.2947s / 294201.4953 s
env0_first_0:                 episode reward: -53.6500,                 loss: 1.1174
env0_second_0:                 episode reward: 53.6500,                 loss: 0.9806
env1_first_0:                 episode reward: -78.9500,                 loss: nan
env1_second_0:                 episode reward: 78.9500,                 loss: nan
Episode: 5581/10000 (55.8100%),                 avg. length: 608.55,                last time consumption/overall running time: 673.2574s / 294874.7527 s
env0_first_0:                 episode reward: -51.8500,                 loss: 1.1169
env0_second_0:                 episode reward: 51.8500,                 loss: 0.9540
env1_first_0:                 episode reward: -61.7000,                 loss: nan
env1_second_0:                 episode reward: 61.7000,                 loss: nan
Episode: 5601/10000 (56.0100%),                 avg. length: 475.9,                last time consumption/overall running time: 527.6384s / 295402.3911 s
env0_first_0:                 episode reward: -54.2500,                 loss: 1.1603
env0_second_0:                 episode reward: 54.2500,                 loss: 0.9831
env1_first_0:                 episode reward: -56.1500,                 loss: nan
env1_second_0:                 episode reward: 56.1500,                 loss: nan
Episode: 5621/10000 (56.2100%),                 avg. length: 527.75,                last time consumption/overall running time: 584.3096s / 295986.7007 s
env0_first_0:                 episode reward: -51.3000,                 loss: 1.1435
env0_second_0:                 episode reward: 51.3000,                 loss: 0.9700
env1_first_0:                 episode reward: -63.2500,                 loss: nan
env1_second_0:                 episode reward: 63.2500,                 loss: nan
Episode: 5641/10000 (56.4100%),                 avg. length: 452.45,                last time consumption/overall running time: 504.2897s / 296490.9904 s
env0_first_0:                 episode reward: -67.1000,                 loss: 1.1604
env0_second_0:                 episode reward: 67.1000,                 loss: 0.9781
env1_first_0:                 episode reward: -67.0000,                 loss: nan
env1_second_0:                 episode reward: 67.0000,                 loss: nan
Episode: 5661/10000 (56.6100%),                 avg. length: 481.7,                last time consumption/overall running time: 537.9747s / 297028.9651 s
env0_first_0:                 episode reward: -64.7500,                 loss: 1.2319
env0_second_0:                 episode reward: 64.7500,                 loss: 1.0145
env1_first_0:                 episode reward: -59.0000,                 loss: nan
env1_second_0:                 episode reward: 59.0000,                 loss: nan
Episode: 5681/10000 (56.8100%),                 avg. length: 660.45,                last time consumption/overall running time: 734.9533s / 297763.9184 s
env0_first_0:                 episode reward: -54.2000,                 loss: 1.2817
env0_second_0:                 episode reward: 54.2000,                 loss: 0.9998
env1_first_0:                 episode reward: -62.8000,                 loss: nan
env1_second_0:                 episode reward: 62.8000,                 loss: nan
Episode: 5701/10000 (57.0100%),                 avg. length: 520.35,                last time consumption/overall running time: 582.2536s / 298346.1720 s
env0_first_0:                 episode reward: -47.1500,                 loss: 1.3321
env0_second_0:                 episode reward: 47.1500,                 loss: 1.0384
env1_first_0:                 episode reward: -64.3500,                 loss: nan
env1_second_0:                 episode reward: 64.3500,                 loss: nan
Episode: 5721/10000 (57.2100%),                 avg. length: 647.35,                last time consumption/overall running time: 715.8244s / 299061.9965 s
env0_first_0:                 episode reward: -61.1000,                 loss: 1.2322
env0_second_0:                 episode reward: 61.1000,                 loss: 1.0211
env1_first_0:                 episode reward: -56.6000,                 loss: nan
env1_second_0:                 episode reward: 56.6000,                 loss: nan
Episode: 5741/10000 (57.4100%),                 avg. length: 545.85,                last time consumption/overall running time: 607.7441s / 299669.7406 s
env0_first_0:                 episode reward: -61.1000,                 loss: 1.1607
env0_second_0:                 episode reward: 61.1000,                 loss: 0.9871
env1_first_0:                 episode reward: -44.5000,                 loss: nan
env1_second_0:                 episode reward: 44.5000,                 loss: nan
Episode: 5761/10000 (57.6100%),                 avg. length: 575.0,                last time consumption/overall running time: 639.3444s / 300309.0850 s
env0_first_0:                 episode reward: -66.1000,                 loss: 1.2453
env0_second_0:                 episode reward: 66.1000,                 loss: 0.9634
env1_first_0:                 episode reward: -47.7000,                 loss: nan
env1_second_0:                 episode reward: 47.7000,                 loss: nan
Episode: 5781/10000 (57.8100%),                 avg. length: 501.65,                last time consumption/overall running time: 556.2145s / 300865.2994 s
env0_first_0:                 episode reward: -69.0000,                 loss: 1.2208
env0_second_0:                 episode reward: 69.0000,                 loss: 0.9241
env1_first_0:                 episode reward: -48.7500,                 loss: nan
env1_second_0:                 episode reward: 48.7500,                 loss: nan
Episode: 5801/10000 (58.0100%),                 avg. length: 510.8,                last time consumption/overall running time: 558.5498s / 301423.8492 s
env0_first_0:                 episode reward: -48.9000,                 loss: 1.1600
env0_second_0:                 episode reward: 48.9000,                 loss: 0.9714
env1_first_0:                 episode reward: -71.4000,                 loss: nan
env1_second_0:                 episode reward: 71.4000,                 loss: nan
Episode: 5821/10000 (58.2100%),                 avg. length: 372.1,                last time consumption/overall running time: 410.7327s / 301834.5819 s
env0_first_0:                 episode reward: -63.2000,                 loss: 1.2225
env0_second_0:                 episode reward: 63.2000,                 loss: 0.9670
env1_first_0:                 episode reward: -70.8500,                 loss: nan
env1_second_0:                 episode reward: 70.8500,                 loss: nan
Episode: 5841/10000 (58.4100%),                 avg. length: 470.9,                last time consumption/overall running time: 518.8259s / 302353.4078 s
env0_first_0:                 episode reward: -64.6000,                 loss: 1.2629
env0_second_0:                 episode reward: 64.6000,                 loss: 1.0314
env1_first_0:                 episode reward: -45.3000,                 loss: nan
env1_second_0:                 episode reward: 45.3000,                 loss: nan
Episode: 5861/10000 (58.6100%),                 avg. length: 517.5,                last time consumption/overall running time: 568.5080s / 302921.9158 s
env0_first_0:                 episode reward: -61.6500,                 loss: 1.3371
env0_second_0:                 episode reward: 61.6500,                 loss: 1.0409
env1_first_0:                 episode reward: -48.6500,                 loss: nan
env1_second_0:                 episode reward: 48.6500,                 loss: nan
Episode: 5881/10000 (58.8100%),                 avg. length: 753.4,                last time consumption/overall running time: 833.2070s / 303755.1228 s
env0_first_0:                 episode reward: -58.0500,                 loss: 1.3307
env0_second_0:                 episode reward: 58.0500,                 loss: 1.0589
env1_first_0:                 episode reward: -44.8500,                 loss: nan
env1_second_0:                 episode reward: 44.8500,                 loss: nan
Episode: 5901/10000 (59.0100%),                 avg. length: 775.75,                last time consumption/overall running time: 846.9406s / 304602.0634 s
env0_first_0:                 episode reward: -56.0500,                 loss: 1.2733
env0_second_0:                 episode reward: 56.0500,                 loss: 1.0410
env1_first_0:                 episode reward: -35.6500,                 loss: nan
env1_second_0:                 episode reward: 35.6500,                 loss: nan
Episode: 5921/10000 (59.2100%),                 avg. length: 540.8,                last time consumption/overall running time: 593.1957s / 305195.2591 s
env0_first_0:                 episode reward: -58.8000,                 loss: 1.1418
env0_second_0:                 episode reward: 58.8000,                 loss: 0.9129
env1_first_0:                 episode reward: -46.4500,                 loss: nan
env1_second_0:                 episode reward: 46.4500,                 loss: nan
Episode: 5941/10000 (59.4100%),                 avg. length: 621.45,                last time consumption/overall running time: 679.4187s / 305874.6778 s
env0_first_0:                 episode reward: -43.0000,                 loss: 1.1450
env0_second_0:                 episode reward: 43.0000,                 loss: 0.8417
env1_first_0:                 episode reward: -53.5000,                 loss: nan
env1_second_0:                 episode reward: 53.5000,                 loss: nan
Episode: 5961/10000 (59.6100%),                 avg. length: 598.5,                last time consumption/overall running time: 653.5592s / 306528.2370 s
env0_first_0:                 episode reward: -63.4500,                 loss: 1.1051
env0_second_0:                 episode reward: 63.4500,                 loss: 0.8416
env1_first_0:                 episode reward: -51.8000,                 loss: nan
env1_second_0:                 episode reward: 51.8000,                 loss: nan
Episode: 5981/10000 (59.8100%),                 avg. length: 426.3,                last time consumption/overall running time: 464.6907s / 306992.9277 s
env0_first_0:                 episode reward: -68.9500,                 loss: 1.0652
env0_second_0:                 episode reward: 68.9500,                 loss: 0.7974
env1_first_0:                 episode reward: -70.4500,                 loss: nan
env1_second_0:                 episode reward: 70.4500,                 loss: nan
Episode: 6001/10000 (60.0100%),                 avg. length: 546.9,                last time consumption/overall running time: 598.7461s / 307591.6737 s
env0_first_0:                 episode reward: -42.3000,                 loss: 1.2222
env0_second_0:                 episode reward: 42.3000,                 loss: 0.8335
env1_first_0:                 episode reward: -71.6500,                 loss: nan
env1_second_0:                 episode reward: 71.6500,                 loss: nan
Episode: 6021/10000 (60.2100%),                 avg. length: 511.65,                last time consumption/overall running time: 564.0903s / 308155.7640 s
env0_first_0:                 episode reward: -64.4000,                 loss: 1.3170
env0_second_0:                 episode reward: 64.4000,                 loss: 0.8936
env1_first_0:                 episode reward: -53.8000,                 loss: nan
env1_second_0:                 episode reward: 53.8000,                 loss: nan
Episode: 6041/10000 (60.4100%),                 avg. length: 710.9,                last time consumption/overall running time: 767.9960s / 308923.7601 s
env0_first_0:                 episode reward: -67.9000,                 loss: 1.3130
env0_second_0:                 episode reward: 67.9000,                 loss: 1.0023
env1_first_0:                 episode reward: -42.0000,                 loss: nan
env1_second_0:                 episode reward: 42.0000,                 loss: nan
Episode: 6061/10000 (60.6100%),                 avg. length: 566.5,                last time consumption/overall running time: 623.7680s / 309547.5280 s
env0_first_0:                 episode reward: -50.0000,                 loss: 1.3269
env0_second_0:                 episode reward: 50.0000,                 loss: 0.9278
env1_first_0:                 episode reward: -52.7000,                 loss: nan
env1_second_0:                 episode reward: 52.7000,                 loss: nan
Episode: 6081/10000 (60.8100%),                 avg. length: 676.15,                last time consumption/overall running time: 723.8631s / 310271.3911 s
env0_first_0:                 episode reward: -52.4500,                 loss: 1.2574
env0_second_0:                 episode reward: 52.4500,                 loss: 0.9236
env1_first_0:                 episode reward: -56.4000,                 loss: nan
env1_second_0:                 episode reward: 56.4000,                 loss: nan
Episode: 6101/10000 (61.0100%),                 avg. length: 426.7,                last time consumption/overall running time: 458.0082s / 310729.3994 s
env0_first_0:                 episode reward: -55.6000,                 loss: 1.3163
env0_second_0:                 episode reward: 55.6000,                 loss: 0.9365
env1_first_0:                 episode reward: -67.1500,                 loss: nan
env1_second_0:                 episode reward: 67.1500,                 loss: nan
Episode: 6121/10000 (61.2100%),                 avg. length: 522.4,                last time consumption/overall running time: 562.6649s / 311292.0643 s
env0_first_0:                 episode reward: -69.4500,                 loss: 1.2609
env0_second_0:                 episode reward: 69.4500,                 loss: 0.9375
env1_first_0:                 episode reward: -37.6000,                 loss: nan
env1_second_0:                 episode reward: 37.6000,                 loss: nan
Episode: 6141/10000 (61.4100%),                 avg. length: 453.35,                last time consumption/overall running time: 495.8611s / 311787.9254 s
env0_first_0:                 episode reward: -58.2000,                 loss: 1.2874
env0_second_0:                 episode reward: 58.2000,                 loss: 0.9505
env1_first_0:                 episode reward: -63.2000,                 loss: nan
env1_second_0:                 episode reward: 63.2000,                 loss: nan
Episode: 6161/10000 (61.6100%),                 avg. length: 518.6,                last time consumption/overall running time: 561.1825s / 312349.1079 s
env0_first_0:                 episode reward: -66.6000,                 loss: 1.3291
env0_second_0:                 episode reward: 66.6000,                 loss: 0.8603
env1_first_0:                 episode reward: -40.4000,                 loss: nan
env1_second_0:                 episode reward: 40.4000,                 loss: nan
Episode: 6181/10000 (61.8100%),                 avg. length: 733.65,                last time consumption/overall running time: 792.3154s / 313141.4233 s
env0_first_0:                 episode reward: -22.5500,                 loss: 1.3312
env0_second_0:                 episode reward: 22.5500,                 loss: 0.8456
env1_first_0:                 episode reward: -66.4500,                 loss: nan
env1_second_0:                 episode reward: 66.4500,                 loss: nan
Episode: 6201/10000 (62.0100%),                 avg. length: 581.3,                last time consumption/overall running time: 623.1783s / 313764.6016 s
env0_first_0:                 episode reward: -58.3000,                 loss: 1.3443
env0_second_0:                 episode reward: 58.3000,                 loss: 0.8125
env1_first_0:                 episode reward: -57.8000,                 loss: nan
env1_second_0:                 episode reward: 57.8000,                 loss: nan
Episode: 6221/10000 (62.2100%),                 avg. length: 445.65,                last time consumption/overall running time: 480.2250s / 314244.8266 s
env0_first_0:                 episode reward: -49.9500,                 loss: 1.2568
env0_second_0:                 episode reward: 49.9500,                 loss: 0.7943
env1_first_0:                 episode reward: -61.0000,                 loss: nan
env1_second_0:                 episode reward: 61.0000,                 loss: nan
Episode: 6241/10000 (62.4100%),                 avg. length: 484.7,                last time consumption/overall running time: 518.1631s / 314762.9897 s
env0_first_0:                 episode reward: -46.1500,                 loss: 1.3220
env0_second_0:                 episode reward: 46.1500,                 loss: 0.7475
env1_first_0:                 episode reward: -61.2000,                 loss: nan
env1_second_0:                 episode reward: 61.2000,                 loss: nan
Episode: 6261/10000 (62.6100%),                 avg. length: 572.6,                last time consumption/overall running time: 615.2371s / 315378.2268 s
env0_first_0:                 episode reward: -48.6500,                 loss: 1.2563
env0_second_0:                 episode reward: 48.6500,                 loss: 0.7784
env1_first_0:                 episode reward: -60.1000,                 loss: nan
env1_second_0:                 episode reward: 60.1000,                 loss: nan
Episode: 6281/10000 (62.8100%),                 avg. length: 476.55,                last time consumption/overall running time: 518.2992s / 315896.5259 s
env0_first_0:                 episode reward: -52.1000,                 loss: 1.2025
env0_second_0:                 episode reward: 52.1000,                 loss: 0.7825
env1_first_0:                 episode reward: -62.7000,                 loss: nan
env1_second_0:                 episode reward: 62.7000,                 loss: nan
Episode: 6301/10000 (63.0100%),                 avg. length: 512.4,                last time consumption/overall running time: 548.1531s / 316444.6790 s
env0_first_0:                 episode reward: -65.9500,                 loss: 1.2561
env0_second_0:                 episode reward: 65.9500,                 loss: 0.7652
env1_first_0:                 episode reward: -59.3000,                 loss: nan
env1_second_0:                 episode reward: 59.3000,                 loss: nan
Episode: 6321/10000 (63.2100%),                 avg. length: 539.2,                last time consumption/overall running time: 571.4262s / 317016.1053 s
env0_first_0:                 episode reward: -64.5000,                 loss: 1.3261
env0_second_0:                 episode reward: 64.5000,                 loss: 0.7673
env1_first_0:                 episode reward: -46.2500,                 loss: nan
env1_second_0:                 episode reward: 46.2500,                 loss: nan
Episode: 6341/10000 (63.4100%),                 avg. length: 452.55,                last time consumption/overall running time: 486.1394s / 317502.2446 s
env0_first_0:                 episode reward: -52.9000,                 loss: 1.3175
env0_second_0:                 episode reward: 52.9000,                 loss: 0.8374
env1_first_0:                 episode reward: -73.5500,                 loss: nan
env1_second_0:                 episode reward: 73.5500,                 loss: nan
Episode: 6361/10000 (63.6100%),                 avg. length: 704.6,                last time consumption/overall running time: 741.3631s / 318243.6077 s
env0_first_0:                 episode reward: -53.2000,                 loss: 1.3100
env0_second_0:                 episode reward: 53.2000,                 loss: 0.8143
env1_first_0:                 episode reward: -62.8500,                 loss: nan
env1_second_0:                 episode reward: 62.8500,                 loss: nan
Episode: 6381/10000 (63.8100%),                 avg. length: 551.4,                last time consumption/overall running time: 580.5983s / 318824.2060 s
env0_first_0:                 episode reward: -36.1500,                 loss: 1.2489
env0_second_0:                 episode reward: 36.1500,                 loss: 0.7832
env1_first_0:                 episode reward: -58.7000,                 loss: nan
env1_second_0:                 episode reward: 58.7000,                 loss: nan
Episode: 6401/10000 (64.0100%),                 avg. length: 499.8,                last time consumption/overall running time: 528.5974s / 319352.8035 s
env0_first_0:                 episode reward: -59.8500,                 loss: 1.2294
env0_second_0:                 episode reward: 59.8500,                 loss: 0.7951
env1_first_0:                 episode reward: -49.2500,                 loss: nan
env1_second_0:                 episode reward: 49.2500,                 loss: nan
Episode: 6421/10000 (64.2100%),                 avg. length: 615.5,                last time consumption/overall running time: 647.0972s / 319999.9007 s
env0_first_0:                 episode reward: -59.4500,                 loss: 1.3048
env0_second_0:                 episode reward: 59.4500,                 loss: 0.8213
env1_first_0:                 episode reward: -52.0500,                 loss: nan
env1_second_0:                 episode reward: 52.0500,                 loss: nan
Episode: 6441/10000 (64.4100%),                 avg. length: 647.35,                last time consumption/overall running time: 683.1694s / 320683.0701 s
env0_first_0:                 episode reward: -53.4000,                 loss: 1.3382
env0_second_0:                 episode reward: 53.4000,                 loss: 0.7709
env1_first_0:                 episode reward: -50.6000,                 loss: nan
env1_second_0:                 episode reward: 50.6000,                 loss: nan
Episode: 6461/10000 (64.6100%),                 avg. length: 520.2,                last time consumption/overall running time: 549.1733s / 321232.2434 s
env0_first_0:                 episode reward: -58.8500,                 loss: 1.3599
env0_second_0:                 episode reward: 58.8500,                 loss: 0.7589
env1_first_0:                 episode reward: -56.4000,                 loss: nan
env1_second_0:                 episode reward: 56.4000,                 loss: nan
Episode: 6481/10000 (64.8100%),                 avg. length: 534.65,                last time consumption/overall running time: 563.3530s / 321795.5964 s
env0_first_0:                 episode reward: -39.8000,                 loss: 1.3133
env0_second_0:                 episode reward: 39.8000,                 loss: 0.8291
env1_first_0:                 episode reward: -64.5500,                 loss: nan
env1_second_0:                 episode reward: 64.5500,                 loss: nan
Episode: 6501/10000 (65.0100%),                 avg. length: 570.0,                last time consumption/overall running time: 593.8414s / 322389.4378 s
env0_first_0:                 episode reward: -54.8000,                 loss: 1.2641
env0_second_0:                 episode reward: 54.8000,                 loss: 0.7672
env1_first_0:                 episode reward: -62.3500,                 loss: nan
env1_second_0:                 episode reward: 62.3500,                 loss: nan
Episode: 6521/10000 (65.2100%),                 avg. length: 569.8,                last time consumption/overall running time: 594.2258s / 322983.6636 s
env0_first_0:                 episode reward: -52.3500,                 loss: 1.2133
env0_second_0:                 episode reward: 52.3500,                 loss: 0.7725
env1_first_0:                 episode reward: -58.1500,                 loss: nan
env1_second_0:                 episode reward: 58.1500,                 loss: nan
Episode: 6541/10000 (65.4100%),                 avg. length: 567.8,                last time consumption/overall running time: 598.5320s / 323582.1956 s
env0_first_0:                 episode reward: -76.2500,                 loss: 1.1269
env0_second_0:                 episode reward: 76.2500,                 loss: 0.8043
env1_first_0:                 episode reward: -40.2500,                 loss: nan
env1_second_0:                 episode reward: 40.2500,                 loss: nan
Episode: 6561/10000 (65.6100%),                 avg. length: 576.15,                last time consumption/overall running time: 600.5653s / 324182.7610 s
env0_first_0:                 episode reward: -53.1000,                 loss: 1.2084
env0_second_0:                 episode reward: 53.1000,                 loss: 0.7908
env1_first_0:                 episode reward: -51.0000,                 loss: nan
env1_second_0:                 episode reward: 51.0000,                 loss: nan
Episode: 6581/10000 (65.8100%),                 avg. length: 674.05,                last time consumption/overall running time: 705.8480s / 324888.6090 s
env0_first_0:                 episode reward: -40.0000,                 loss: 1.2017
env0_second_0:                 episode reward: 40.0000,                 loss: 0.8449
env1_first_0:                 episode reward: -64.7500,                 loss: nan
env1_second_0:                 episode reward: 64.7500,                 loss: nan
Episode: 6601/10000 (66.0100%),                 avg. length: 679.65,                last time consumption/overall running time: 711.3136s / 325599.9226 s
env0_first_0:                 episode reward: -48.1000,                 loss: 1.3095
env0_second_0:                 episode reward: 48.1000,                 loss: 0.9065
env1_first_0:                 episode reward: -48.0500,                 loss: nan
env1_second_0:                 episode reward: 48.0500,                 loss: nan
Episode: 6621/10000 (66.2100%),                 avg. length: 584.95,                last time consumption/overall running time: 609.2655s / 326209.1881 s
env0_first_0:                 episode reward: -67.4000,                 loss: 1.3533
env0_second_0:                 episode reward: 67.4000,                 loss: 0.9857
env1_first_0:                 episode reward: -54.7000,                 loss: nan
env1_second_0:                 episode reward: 54.7000,                 loss: nan
Episode: 6641/10000 (66.4100%),                 avg. length: 683.65,                last time consumption/overall running time: 714.1586s / 326923.3466 s
env0_first_0:                 episode reward: -43.6000,                 loss: 1.3448
env0_second_0:                 episode reward: 43.6000,                 loss: 0.9036
env1_first_0:                 episode reward: -58.4500,                 loss: nan
env1_second_0:                 episode reward: 58.4500,                 loss: nan
Episode: 6661/10000 (66.6100%),                 avg. length: 433.9,                last time consumption/overall running time: 451.0938s / 327374.4404 s
env0_first_0:                 episode reward: -54.1500,                 loss: 1.3951
env0_second_0:                 episode reward: 54.1500,                 loss: 0.8180
env1_first_0:                 episode reward: -59.0500,                 loss: nan
env1_second_0:                 episode reward: 59.0500,                 loss: nan
Episode: 6681/10000 (66.8100%),                 avg. length: 467.0,                last time consumption/overall running time: 485.2249s / 327859.6654 s
env0_first_0:                 episode reward: -55.8500,                 loss: 1.3824
env0_second_0:                 episode reward: 55.8500,                 loss: 0.8648
env1_first_0:                 episode reward: -57.5000,                 loss: nan
env1_second_0:                 episode reward: 57.5000,                 loss: nan
Episode: 6701/10000 (67.0100%),                 avg. length: 508.65,                last time consumption/overall running time: 528.8217s / 328388.4871 s
env0_first_0:                 episode reward: -66.3000,                 loss: 1.3458
env0_second_0:                 episode reward: 66.3000,                 loss: 0.9424
env1_first_0:                 episode reward: -62.1000,                 loss: nan
env1_second_0:                 episode reward: 62.1000,                 loss: nan
Episode: 6721/10000 (67.2100%),                 avg. length: 409.2,                last time consumption/overall running time: 431.4716s / 328819.9586 s
env0_first_0:                 episode reward: -70.9000,                 loss: 1.5131
env0_second_0:                 episode reward: 70.9000,                 loss: 0.9329
env1_first_0:                 episode reward: -58.7500,                 loss: nan
env1_second_0:                 episode reward: 58.7500,                 loss: nan
Episode: 6741/10000 (67.4100%),                 avg. length: 605.55,                last time consumption/overall running time: 627.9201s / 329447.8788 s
env0_first_0:                 episode reward: -49.3000,                 loss: 1.5849
env0_second_0:                 episode reward: 49.3000,                 loss: 1.0653
env1_first_0:                 episode reward: -58.9000,                 loss: nan
env1_second_0:                 episode reward: 58.9000,                 loss: nan
Episode: 6761/10000 (67.6100%),                 avg. length: 525.5,                last time consumption/overall running time: 552.4648s / 330000.3436 s
env0_first_0:                 episode reward: -66.8500,                 loss: 1.5862
env0_second_0:                 episode reward: 66.8500,                 loss: 1.0670
env1_first_0:                 episode reward: -47.6500,                 loss: nan
env1_second_0:                 episode reward: 47.6500,                 loss: nan
Episode: 6781/10000 (67.8100%),                 avg. length: 424.9,                last time consumption/overall running time: 445.4950s / 330445.8386 s
env0_first_0:                 episode reward: -58.7000,                 loss: 1.6488
env0_second_0:                 episode reward: 58.7000,                 loss: 1.0405
env1_first_0:                 episode reward: -63.6500,                 loss: nan
env1_second_0:                 episode reward: 63.6500,                 loss: nan
Episode: 6801/10000 (68.0100%),                 avg. length: 523.0,                last time consumption/overall running time: 541.7922s / 330987.6308 s
env0_first_0:                 episode reward: -47.9500,                 loss: 1.6239
env0_second_0:                 episode reward: 47.9500,                 loss: 1.0162
env1_first_0:                 episode reward: -56.7500,                 loss: nan
env1_second_0:                 episode reward: 56.7500,                 loss: nan
Episode: 6821/10000 (68.2100%),                 avg. length: 616.25,                last time consumption/overall running time: 637.9669s / 331625.5978 s
env0_first_0:                 episode reward: -53.9500,                 loss: 1.4645
env0_second_0:                 episode reward: 53.9500,                 loss: 0.9567
env1_first_0:                 episode reward: -55.9500,                 loss: nan
env1_second_0:                 episode reward: 55.9500,                 loss: nan
Episode: 6841/10000 (68.4100%),                 avg. length: 551.85,                last time consumption/overall running time: 572.2581s / 332197.8558 s
env0_first_0:                 episode reward: -60.1500,                 loss: 1.4832
env0_second_0:                 episode reward: 60.1500,                 loss: 1.0219
env1_first_0:                 episode reward: -44.5500,                 loss: nan
env1_second_0:                 episode reward: 44.5500,                 loss: nan
Episode: 6861/10000 (68.6100%),                 avg. length: 674.75,                last time consumption/overall running time: 702.3892s / 332900.2451 s
env0_first_0:                 episode reward: -56.9500,                 loss: 1.4414
env0_second_0:                 episode reward: 56.9500,                 loss: 0.9978
env1_first_0:                 episode reward: -52.3500,                 loss: nan
env1_second_0:                 episode reward: 52.3500,                 loss: nan
Episode: 6881/10000 (68.8100%),                 avg. length: 571.15,                last time consumption/overall running time: 589.3621s / 333489.6072 s
env0_first_0:                 episode reward: -60.1500,                 loss: 1.5133
env0_second_0:                 episode reward: 60.1500,                 loss: 0.9691
env1_first_0:                 episode reward: -51.1500,                 loss: nan
env1_second_0:                 episode reward: 51.1500,                 loss: nan
Episode: 6901/10000 (69.0100%),                 avg. length: 493.1,                last time consumption/overall running time: 508.9782s / 333998.5854 s
env0_first_0:                 episode reward: -38.5500,                 loss: 1.4662
env0_second_0:                 episode reward: 38.5500,                 loss: 0.9331
env1_first_0:                 episode reward: -69.8000,                 loss: nan
env1_second_0:                 episode reward: 69.8000,                 loss: nan
Episode: 6921/10000 (69.2100%),                 avg. length: 596.95,                last time consumption/overall running time: 607.1608s / 334605.7462 s
env0_first_0:                 episode reward: -76.2000,                 loss: 1.5876
env0_second_0:                 episode reward: 76.2000,                 loss: 0.9695
env1_first_0:                 episode reward: -38.7000,                 loss: nan
env1_second_0:                 episode reward: 38.7000,                 loss: nan
Episode: 6941/10000 (69.4100%),                 avg. length: 551.85,                last time consumption/overall running time: 564.3079s / 335170.0541 s
env0_first_0:                 episode reward: -44.1500,                 loss: 1.6610
env0_second_0:                 episode reward: 44.1500,                 loss: 1.0891
env1_first_0:                 episode reward: -65.4000,                 loss: nan
env1_second_0:                 episode reward: 65.4000,                 loss: nan
Episode: 6961/10000 (69.6100%),                 avg. length: 432.35,                last time consumption/overall running time: 443.9071s / 335613.9612 s
env0_first_0:                 episode reward: -61.4500,                 loss: 1.5673
env0_second_0:                 episode reward: 61.4500,                 loss: 1.0839
env1_first_0:                 episode reward: -54.9000,                 loss: nan
env1_second_0:                 episode reward: 54.9000,                 loss: nan
Episode: 6981/10000 (69.8100%),                 avg. length: 666.2,                last time consumption/overall running time: 683.3465s / 336297.3077 s
env0_first_0:                 episode reward: -41.5500,                 loss: 1.5700
env0_second_0:                 episode reward: 41.5500,                 loss: 0.9859
env1_first_0:                 episode reward: -59.8500,                 loss: nan
env1_second_0:                 episode reward: 59.8500,                 loss: nan
Episode: 7001/10000 (70.0100%),                 avg. length: 519.75,                last time consumption/overall running time: 533.6235s / 336830.9312 s
env0_first_0:                 episode reward: -67.2500,                 loss: 1.6134
env0_second_0:                 episode reward: 67.2500,                 loss: 0.9916
env1_first_0:                 episode reward: -52.6000,                 loss: nan
env1_second_0:                 episode reward: 52.6000,                 loss: nan
Episode: 7021/10000 (70.2100%),                 avg. length: 697.8,                last time consumption/overall running time: 712.7742s / 337543.7055 s
env0_first_0:                 episode reward: -43.5000,                 loss: 1.6579
env0_second_0:                 episode reward: 43.5000,                 loss: 0.9938
env1_first_0:                 episode reward: -52.6500,                 loss: nan
env1_second_0:                 episode reward: 52.6500,                 loss: nan
Episode: 7041/10000 (70.4100%),                 avg. length: 711.95,                last time consumption/overall running time: 725.8150s / 338269.5205 s
env0_first_0:                 episode reward: -58.4000,                 loss: 1.6840
env0_second_0:                 episode reward: 58.4000,                 loss: 0.9242
env1_first_0:                 episode reward: -52.4500,                 loss: nan
env1_second_0:                 episode reward: 52.4500,                 loss: nan
Episode: 7061/10000 (70.6100%),                 avg. length: 822.8,                last time consumption/overall running time: 843.5233s / 339113.0438 s
env0_first_0:                 episode reward: -45.0500,                 loss: 1.7024
env0_second_0:                 episode reward: 45.0500,                 loss: 0.9371
env1_first_0:                 episode reward: -42.1500,                 loss: nan
env1_second_0:                 episode reward: 42.1500,                 loss: nan
Episode: 7081/10000 (70.8100%),                 avg. length: 754.6,                last time consumption/overall running time: 767.9693s / 339881.0131 s
env0_first_0:                 episode reward: -55.2000,                 loss: 1.4241
env0_second_0:                 episode reward: 55.2000,                 loss: 0.9009
env1_first_0:                 episode reward: -59.4000,                 loss: nan
env1_second_0:                 episode reward: 59.4000,                 loss: nan
Episode: 7101/10000 (71.0100%),                 avg. length: 746.45,                last time consumption/overall running time: 760.0001s / 340641.0132 s
env0_first_0:                 episode reward: -46.0000,                 loss: 1.3608
env0_second_0:                 episode reward: 46.0000,                 loss: 0.8873
env1_first_0:                 episode reward: -62.9000,                 loss: nan
env1_second_0:                 episode reward: 62.9000,                 loss: nan
Episode: 7121/10000 (71.2100%),                 avg. length: 674.9,                last time consumption/overall running time: 683.0718s / 341324.0850 s
env0_first_0:                 episode reward: -57.0500,                 loss: 1.2259
env0_second_0:                 episode reward: 57.0500,                 loss: 0.8774
env1_first_0:                 episode reward: -52.6000,                 loss: nan
env1_second_0:                 episode reward: 52.6000,                 loss: nan
Episode: 7141/10000 (71.4100%),                 avg. length: 656.05,                last time consumption/overall running time: 669.5645s / 341993.6494 s
env0_first_0:                 episode reward: -42.4000,                 loss: 1.2868
env0_second_0:                 episode reward: 42.4000,                 loss: 0.9174
env1_first_0:                 episode reward: -57.0500,                 loss: nan
env1_second_0:                 episode reward: 57.0500,                 loss: nan
Episode: 7161/10000 (71.6100%),                 avg. length: 603.5,                last time consumption/overall running time: 611.2891s / 342604.9386 s
env0_first_0:                 episode reward: -50.8000,                 loss: 1.2976
env0_second_0:                 episode reward: 50.8000,                 loss: 0.9089
env1_first_0:                 episode reward: -67.7500,                 loss: nan
env1_second_0:                 episode reward: 67.7500,                 loss: nan
Episode: 7181/10000 (71.8100%),                 avg. length: 486.6,                last time consumption/overall running time: 496.3320s / 343101.2705 s
env0_first_0:                 episode reward: -72.8500,                 loss: 1.4557
env0_second_0:                 episode reward: 72.8500,                 loss: 0.9970
env1_first_0:                 episode reward: -40.7500,                 loss: nan
env1_second_0:                 episode reward: 40.7500,                 loss: nan
Episode: 7201/10000 (72.0100%),                 avg. length: 608.15,                last time consumption/overall running time: 617.5743s / 343718.8449 s
env0_first_0:                 episode reward: -60.3500,                 loss: 1.7164
env0_second_0:                 episode reward: 60.3500,                 loss: 1.0176
env1_first_0:                 episode reward: -53.0000,                 loss: nan
env1_second_0:                 episode reward: 53.0000,                 loss: nan
Episode: 7221/10000 (72.2100%),                 avg. length: 717.05,                last time consumption/overall running time: 728.7657s / 344447.6106 s
env0_first_0:                 episode reward: -67.2000,                 loss: 1.5700
env0_second_0:                 episode reward: 67.2000,                 loss: 1.0681
env1_first_0:                 episode reward: -49.2000,                 loss: nan
env1_second_0:                 episode reward: 49.2000,                 loss: nan
Episode: 7241/10000 (72.4100%),                 avg. length: 469.8,                last time consumption/overall running time: 472.9769s / 344920.5875 s
env0_first_0:                 episode reward: -55.5500,                 loss: 1.8017
env0_second_0:                 episode reward: 55.5500,                 loss: 0.9785
env1_first_0:                 episode reward: -67.9000,                 loss: nan
env1_second_0:                 episode reward: 67.9000,                 loss: nan
Episode: 7261/10000 (72.6100%),                 avg. length: 559.1,                last time consumption/overall running time: 563.5288s / 345484.1163 s
env0_first_0:                 episode reward: -66.2000,                 loss: 1.6986
env0_second_0:                 episode reward: 66.2000,                 loss: 1.0056
env1_first_0:                 episode reward: -46.7000,                 loss: nan
env1_second_0:                 episode reward: 46.7000,                 loss: nan
Episode: 7281/10000 (72.8100%),                 avg. length: 671.55,                last time consumption/overall running time: 678.3606s / 346162.4770 s
env0_first_0:                 episode reward: -54.2500,                 loss: 1.5878
env0_second_0:                 episode reward: 54.2500,                 loss: 0.9528
env1_first_0:                 episode reward: -42.8500,                 loss: nan
env1_second_0:                 episode reward: 42.8500,                 loss: nan
Episode: 7301/10000 (73.0100%),                 avg. length: 801.05,                last time consumption/overall running time: 802.9380s / 346965.4150 s
env0_first_0:                 episode reward: -47.5000,                 loss: 1.6233
env0_second_0:                 episode reward: 47.5000,                 loss: 0.9301
env1_first_0:                 episode reward: -48.1000,                 loss: nan
env1_second_0:                 episode reward: 48.1000,                 loss: nan
Episode: 7321/10000 (73.2100%),                 avg. length: 770.95,                last time consumption/overall running time: 778.7051s / 347744.1201 s
env0_first_0:                 episode reward: -45.1500,                 loss: 1.5421
env0_second_0:                 episode reward: 45.1500,                 loss: 0.8405
env1_first_0:                 episode reward: -51.3500,                 loss: nan
env1_second_0:                 episode reward: 51.3500,                 loss: nan
Episode: 7341/10000 (73.4100%),                 avg. length: 630.6,                last time consumption/overall running time: 633.0676s / 348377.1877 s
env0_first_0:                 episode reward: -50.2500,                 loss: 1.4071
env0_second_0:                 episode reward: 50.2500,                 loss: 0.8854
env1_first_0:                 episode reward: -54.0000,                 loss: nan
env1_second_0:                 episode reward: 54.0000,                 loss: nan
Episode: 7361/10000 (73.6100%),                 avg. length: 516.35,                last time consumption/overall running time: 517.5278s / 348894.7155 s
env0_first_0:                 episode reward: -82.1000,                 loss: 1.4012
env0_second_0:                 episode reward: 82.1000,                 loss: 0.8772
env1_first_0:                 episode reward: -45.0000,                 loss: nan
env1_second_0:                 episode reward: 45.0000,                 loss: nan
Episode: 7381/10000 (73.8100%),                 avg. length: 603.3,                last time consumption/overall running time: 600.2379s / 349494.9534 s
env0_first_0:                 episode reward: -40.8500,                 loss: 1.4740
env0_second_0:                 episode reward: 40.8500,                 loss: 0.9382
env1_first_0:                 episode reward: -67.1500,                 loss: nan
env1_second_0:                 episode reward: 67.1500,                 loss: nan
Episode: 7401/10000 (74.0100%),                 avg. length: 526.7,                last time consumption/overall running time: 527.6388s / 350022.5922 s
env0_first_0:                 episode reward: -51.5500,                 loss: 1.5383
env0_second_0:                 episode reward: 51.5500,                 loss: 0.9579
env1_first_0:                 episode reward: -56.2000,                 loss: nan
env1_second_0:                 episode reward: 56.2000,                 loss: nan
Episode: 7421/10000 (74.2100%),                 avg. length: 661.85,                last time consumption/overall running time: 666.9935s / 350689.5857 s
env0_first_0:                 episode reward: -31.2000,                 loss: 1.4042
env0_second_0:                 episode reward: 31.2000,                 loss: 0.9866
env1_first_0:                 episode reward: -67.6000,                 loss: nan
env1_second_0:                 episode reward: 67.6000,                 loss: nan
Episode: 7441/10000 (74.4100%),                 avg. length: 781.25,                last time consumption/overall running time: 777.7104s / 351467.2961 s
env0_first_0:                 episode reward: -69.1000,                 loss: 1.4433
env0_second_0:                 episode reward: 69.1000,                 loss: 0.9873
env1_first_0:                 episode reward: -39.4000,                 loss: nan
env1_second_0:                 episode reward: 39.4000,                 loss: nan
Episode: 7461/10000 (74.6100%),                 avg. length: 487.55,                last time consumption/overall running time: 489.9439s / 351957.2400 s
env0_first_0:                 episode reward: -62.6500,                 loss: 1.5684
env0_second_0:                 episode reward: 62.6500,                 loss: 1.0042
env1_first_0:                 episode reward: -40.3000,                 loss: nan
env1_second_0:                 episode reward: 40.3000,                 loss: nan
Episode: 7481/10000 (74.8100%),                 avg. length: 467.6,                last time consumption/overall running time: 464.8945s / 352422.1345 s
env0_first_0:                 episode reward: -64.8000,                 loss: 1.6263
env0_second_0:                 episode reward: 64.8000,                 loss: 1.0459
env1_first_0:                 episode reward: -54.9000,                 loss: nan
env1_second_0:                 episode reward: 54.9000,                 loss: nan
Episode: 7501/10000 (75.0100%),                 avg. length: 714.45,                last time consumption/overall running time: 711.5777s / 353133.7122 s
env0_first_0:                 episode reward: -40.0000,                 loss: 1.6283
env0_second_0:                 episode reward: 40.0000,                 loss: 1.0835
env1_first_0:                 episode reward: -61.6000,                 loss: nan
env1_second_0:                 episode reward: 61.6000,                 loss: nan
Episode: 7521/10000 (75.2100%),                 avg. length: 699.0,                last time consumption/overall running time: 697.0927s / 353830.8049 s
env0_first_0:                 episode reward: -57.1500,                 loss: 1.5965
env0_second_0:                 episode reward: 57.1500,                 loss: 1.0553
env1_first_0:                 episode reward: -60.4000,                 loss: nan
env1_second_0:                 episode reward: 60.4000,                 loss: nan
Episode: 7541/10000 (75.4100%),                 avg. length: 599.95,                last time consumption/overall running time: 602.5410s / 354433.3459 s
env0_first_0:                 episode reward: -59.0000,                 loss: 1.5844
env0_second_0:                 episode reward: 59.0000,                 loss: 0.9666
env1_first_0:                 episode reward: -52.0500,                 loss: nan
env1_second_0:                 episode reward: 52.0500,                 loss: nan
Episode: 7561/10000 (75.6100%),                 avg. length: 507.7,                last time consumption/overall running time: 516.4793s / 354949.8252 s
env0_first_0:                 episode reward: -47.3500,                 loss: 1.4861
env0_second_0:                 episode reward: 47.3500,                 loss: 0.9038
env1_first_0:                 episode reward: -65.4500,                 loss: nan
env1_second_0:                 episode reward: 65.4500,                 loss: nan
Episode: 7581/10000 (75.8100%),                 avg. length: 632.5,                last time consumption/overall running time: 629.4355s / 355579.2607 s
env0_first_0:                 episode reward: -51.5500,                 loss: 1.6327
env0_second_0:                 episode reward: 51.5500,                 loss: 0.9235
env1_first_0:                 episode reward: -61.9000,                 loss: nan
env1_second_0:                 episode reward: 61.9000,                 loss: nan
Episode: 7601/10000 (76.0100%),                 avg. length: 830.5,                last time consumption/overall running time: 830.7028s / 356409.9635 s
env0_first_0:                 episode reward: -34.5500,                 loss: 1.6358
env0_second_0:                 episode reward: 34.5500,                 loss: 0.9202
env1_first_0:                 episode reward: -68.1500,                 loss: nan
env1_second_0:                 episode reward: 68.1500,                 loss: nan
Episode: 7621/10000 (76.2100%),                 avg. length: 802.65,                last time consumption/overall running time: 799.0186s / 357208.9820 s
env0_first_0:                 episode reward: -61.3000,                 loss: 1.6876
env0_second_0:                 episode reward: 61.3000,                 loss: 0.8955
env1_first_0:                 episode reward: -53.1000,                 loss: nan
env1_second_0:                 episode reward: 53.1000,                 loss: nan
Episode: 7641/10000 (76.4100%),                 avg. length: 637.25,                last time consumption/overall running time: 627.3346s / 357836.3166 s
env0_first_0:                 episode reward: -58.2000,                 loss: 1.6369
env0_second_0:                 episode reward: 58.2000,                 loss: 1.0235
env1_first_0:                 episode reward: -62.5500,                 loss: nan
env1_second_0:                 episode reward: 62.5500,                 loss: nan
Episode: 7661/10000 (76.6100%),                 avg. length: 643.85,                last time consumption/overall running time: 637.8056s / 358474.1222 s
env0_first_0:                 episode reward: -54.9500,                 loss: 1.5793
env0_second_0:                 episode reward: 54.9500,                 loss: 1.0173
env1_first_0:                 episode reward: -53.0000,                 loss: nan
env1_second_0:                 episode reward: 53.0000,                 loss: nan
Episode: 7681/10000 (76.8100%),                 avg. length: 645.65,                last time consumption/overall running time: 639.2465s / 359113.3687 s
env0_first_0:                 episode reward: -57.9500,                 loss: 1.6939
env0_second_0:                 episode reward: 57.9500,                 loss: 0.9652
env1_first_0:                 episode reward: -57.4500,                 loss: nan
env1_second_0:                 episode reward: 57.4500,                 loss: nan
Episode: 7701/10000 (77.0100%),                 avg. length: 687.15,                last time consumption/overall running time: 682.7572s / 359796.1260 s
env0_first_0:                 episode reward: -53.3500,                 loss: 1.7962
env0_second_0:                 episode reward: 53.3500,                 loss: 0.9435
env1_first_0:                 episode reward: -63.0500,                 loss: nan
env1_second_0:                 episode reward: 63.0500,                 loss: nan
Episode: 7721/10000 (77.2100%),                 avg. length: 741.1,                last time consumption/overall running time: 730.3961s / 360526.5220 s
env0_first_0:                 episode reward: -57.0500,                 loss: 1.7459
env0_second_0:                 episode reward: 57.0500,                 loss: 0.9049
env1_first_0:                 episode reward: -45.6000,                 loss: nan
env1_second_0:                 episode reward: 45.6000,                 loss: nan
Episode: 7741/10000 (77.4100%),                 avg. length: 803.9,                last time consumption/overall running time: 797.3249s / 361323.8469 s
env0_first_0:                 episode reward: -53.5500,                 loss: 1.6660
env0_second_0:                 episode reward: 53.5500,                 loss: 0.8922
env1_first_0:                 episode reward: -45.5000,                 loss: nan
env1_second_0:                 episode reward: 45.5000,                 loss: nan
Episode: 7761/10000 (77.6100%),                 avg. length: 672.9,                last time consumption/overall running time: 663.8244s / 361987.6713 s
env0_first_0:                 episode reward: -64.7500,                 loss: 1.5446
env0_second_0:                 episode reward: 64.7500,                 loss: 0.8224
env1_first_0:                 episode reward: -34.9500,                 loss: nan
env1_second_0:                 episode reward: 34.9500,                 loss: nan
Episode: 7781/10000 (77.8100%),                 avg. length: 599.7,                last time consumption/overall running time: 597.6682s / 362585.3395 s
env0_first_0:                 episode reward: -51.8000,                 loss: 1.4585
env0_second_0:                 episode reward: 51.8000,                 loss: 0.8303
env1_first_0:                 episode reward: -56.1500,                 loss: nan
env1_second_0:                 episode reward: 56.1500,                 loss: nan
Episode: 7801/10000 (78.0100%),                 avg. length: 637.45,                last time consumption/overall running time: 633.3095s / 363218.6490 s
env0_first_0:                 episode reward: -51.7500,                 loss: 1.5041
env0_second_0:                 episode reward: 51.7500,                 loss: 0.9152
env1_first_0:                 episode reward: -54.6500,                 loss: nan
env1_second_0:                 episode reward: 54.6500,                 loss: nan
Episode: 7821/10000 (78.2100%),                 avg. length: 874.7,                last time consumption/overall running time: 860.6920s / 364079.3410 s
env0_first_0:                 episode reward: -41.9500,                 loss: 1.3834
env0_second_0:                 episode reward: 41.9500,                 loss: 0.9334
env1_first_0:                 episode reward: -58.4000,                 loss: nan
env1_second_0:                 episode reward: 58.4000,                 loss: nan
Episode: 7841/10000 (78.4100%),                 avg. length: 591.3,                last time consumption/overall running time: 581.4186s / 364660.7595 s
env0_first_0:                 episode reward: -61.5000,                 loss: 1.3528
env0_second_0:                 episode reward: 61.5000,                 loss: 0.9088
env1_first_0:                 episode reward: -51.8000,                 loss: nan
env1_second_0:                 episode reward: 51.8000,                 loss: nan
Episode: 7861/10000 (78.6100%),                 avg. length: 789.0,                last time consumption/overall running time: 778.8809s / 365439.6404 s
env0_first_0:                 episode reward: -31.8500,                 loss: 1.2948
env0_second_0:                 episode reward: 31.8500,                 loss: 0.8860
env1_first_0:                 episode reward: -60.8500,                 loss: nan
env1_second_0:                 episode reward: 60.8500,                 loss: nan
Episode: 7881/10000 (78.8100%),                 avg. length: 606.25,                last time consumption/overall running time: 600.2780s / 366039.9184 s
env0_first_0:                 episode reward: -60.7000,                 loss: 1.3111
env0_second_0:                 episode reward: 60.7000,                 loss: 0.9403
env1_first_0:                 episode reward: -56.1500,                 loss: nan
env1_second_0:                 episode reward: 56.1500,                 loss: nan
Episode: 7901/10000 (79.0100%),                 avg. length: 475.15,                last time consumption/overall running time: 474.8269s / 366514.7453 s
env0_first_0:                 episode reward: -65.9000,                 loss: 1.4609
env0_second_0:                 episode reward: 65.9000,                 loss: 1.0502
env1_first_0:                 episode reward: -54.9500,                 loss: nan
env1_second_0:                 episode reward: 54.9500,                 loss: nan
Episode: 7921/10000 (79.2100%),                 avg. length: 614.9,                last time consumption/overall running time: 607.1967s / 367121.9420 s
env0_first_0:                 episode reward: -62.0500,                 loss: 1.4392
env0_second_0:                 episode reward: 62.0500,                 loss: 1.1200
env1_first_0:                 episode reward: -54.2000,                 loss: nan
env1_second_0:                 episode reward: 54.2000,                 loss: nan
Episode: 7941/10000 (79.4100%),                 avg. length: 638.45,                last time consumption/overall running time: 626.4539s / 367748.3960 s
env0_first_0:                 episode reward: -38.4500,                 loss: 1.4042
env0_second_0:                 episode reward: 38.4500,                 loss: 1.1941
env1_first_0:                 episode reward: -69.5500,                 loss: nan
env1_second_0:                 episode reward: 69.5500,                 loss: nan
Episode: 7961/10000 (79.6100%),                 avg. length: 797.9,                last time consumption/overall running time: 782.3631s / 368530.7590 s
env0_first_0:                 episode reward: -52.1000,                 loss: 1.4771
env0_second_0:                 episode reward: 52.1000,                 loss: 1.2465
env1_first_0:                 episode reward: -46.6500,                 loss: nan
env1_second_0:                 episode reward: 46.6500,                 loss: nan
Episode: 7981/10000 (79.8100%),                 avg. length: 614.35,                last time consumption/overall running time: 601.6375s / 369132.3965 s
env0_first_0:                 episode reward: -62.3500,                 loss: 1.3772
env0_second_0:                 episode reward: 62.3500,                 loss: 1.1240
env1_first_0:                 episode reward: -50.0000,                 loss: nan
env1_second_0:                 episode reward: 50.0000,                 loss: nan
Episode: 8001/10000 (80.0100%),                 avg. length: 529.55,                last time consumption/overall running time: 517.5154s / 369649.9119 s
env0_first_0:                 episode reward: -60.9000,                 loss: 1.3569
env0_second_0:                 episode reward: 60.9000,                 loss: 1.1958
env1_first_0:                 episode reward: -45.5000,                 loss: nan
env1_second_0:                 episode reward: 45.5000,                 loss: nan
Episode: 8021/10000 (80.2100%),                 avg. length: 474.1,                last time consumption/overall running time: 467.2088s / 370117.1207 s
env0_first_0:                 episode reward: -56.5000,                 loss: 1.5064
env0_second_0:                 episode reward: 56.5000,                 loss: 1.1762
env1_first_0:                 episode reward: -67.3500,                 loss: nan
env1_second_0:                 episode reward: 67.3500,                 loss: nan
Episode: 8041/10000 (80.4100%),                 avg. length: 618.85,                last time consumption/overall running time: 603.3443s / 370720.4650 s
env0_first_0:                 episode reward: -52.8500,                 loss: 1.5100
env0_second_0:                 episode reward: 52.8500,                 loss: 1.2276
env1_first_0:                 episode reward: -57.3500,                 loss: nan
env1_second_0:                 episode reward: 57.3500,                 loss: nan
Episode: 8061/10000 (80.6100%),                 avg. length: 721.55,                last time consumption/overall running time: 710.8186s / 371431.2836 s
env0_first_0:                 episode reward: -51.3500,                 loss: 1.6051
env0_second_0:                 episode reward: 51.3500,                 loss: 1.2311
env1_first_0:                 episode reward: -50.2000,                 loss: nan
env1_second_0:                 episode reward: 50.2000,                 loss: nan
Episode: 8081/10000 (80.8100%),                 avg. length: 824.2,                last time consumption/overall running time: 804.1385s / 372235.4221 s
env0_first_0:                 episode reward: -53.1000,                 loss: 1.5882
env0_second_0:                 episode reward: 53.1000,                 loss: 1.1767
env1_first_0:                 episode reward: -47.2000,                 loss: nan
env1_second_0:                 episode reward: 47.2000,                 loss: nan
Episode: 8101/10000 (81.0100%),                 avg. length: 520.05,                last time consumption/overall running time: 513.0114s / 372748.4335 s
env0_first_0:                 episode reward: -54.2000,                 loss: 1.5283
env0_second_0:                 episode reward: 54.2000,                 loss: 1.0760
env1_first_0:                 episode reward: -49.0500,                 loss: nan
env1_second_0:                 episode reward: 49.0500,                 loss: nan
Episode: 8121/10000 (81.2100%),                 avg. length: 507.5,                last time consumption/overall running time: 496.0377s / 373244.4712 s
env0_first_0:                 episode reward: -55.9000,                 loss: 1.4668
env0_second_0:                 episode reward: 55.9000,                 loss: 1.0187
env1_first_0:                 episode reward: -47.1000,                 loss: nan
env1_second_0:                 episode reward: 47.1000,                 loss: nan
Episode: 8141/10000 (81.4100%),                 avg. length: 823.05,                last time consumption/overall running time: 798.8742s / 374043.3454 s
env0_first_0:                 episode reward: -41.1000,                 loss: 1.4175
env0_second_0:                 episode reward: 41.1000,                 loss: 0.9769
env1_first_0:                 episode reward: -47.0000,                 loss: nan
env1_second_0:                 episode reward: 47.0000,                 loss: nan
Episode: 8161/10000 (81.6100%),                 avg. length: 649.65,                last time consumption/overall running time: 629.2778s / 374672.6232 s
env0_first_0:                 episode reward: -45.0000,                 loss: 1.4522
env0_second_0:                 episode reward: 45.0000,                 loss: 0.9792
env1_first_0:                 episode reward: -62.3000,                 loss: nan
env1_second_0:                 episode reward: 62.3000,                 loss: nan
Episode: 8181/10000 (81.8100%),                 avg. length: 619.15,                last time consumption/overall running time: 596.9934s / 375269.6167 s
env0_first_0:                 episode reward: -51.5500,                 loss: 1.4017
env0_second_0:                 episode reward: 51.5500,                 loss: 1.0184
env1_first_0:                 episode reward: -56.2000,                 loss: nan
env1_second_0:                 episode reward: 56.2000,                 loss: nan
Episode: 8201/10000 (82.0100%),                 avg. length: 612.25,                last time consumption/overall running time: 592.2472s / 375861.8639 s
env0_first_0:                 episode reward: -53.2500,                 loss: 1.4876
env0_second_0:                 episode reward: 53.2500,                 loss: 0.9752
env1_first_0:                 episode reward: -48.0000,                 loss: nan
env1_second_0:                 episode reward: 48.0000,                 loss: nan
Episode: 8221/10000 (82.2100%),                 avg. length: 663.35,                last time consumption/overall running time: 640.3880s / 376502.2518 s
env0_first_0:                 episode reward: -33.2500,                 loss: 1.5061
env0_second_0:                 episode reward: 33.2500,                 loss: 0.9422
env1_first_0:                 episode reward: -56.5500,                 loss: nan
env1_second_0:                 episode reward: 56.5500,                 loss: nan
Episode: 8241/10000 (82.4100%),                 avg. length: 680.3,                last time consumption/overall running time: 659.1198s / 377161.3717 s
env0_first_0:                 episode reward: -54.9000,                 loss: 1.3683
env0_second_0:                 episode reward: 54.9000,                 loss: 0.9532
env1_first_0:                 episode reward: -52.6500,                 loss: nan
env1_second_0:                 episode reward: 52.6500,                 loss: nan
Episode: 8261/10000 (82.6100%),                 avg. length: 930.2,                last time consumption/overall running time: 898.1520s / 378059.5236 s
env0_first_0:                 episode reward: -44.0000,                 loss: 1.2160
env0_second_0:                 episode reward: 44.0000,                 loss: 0.9093
env1_first_0:                 episode reward: -35.6000,                 loss: nan
env1_second_0:                 episode reward: 35.6000,                 loss: nan
Episode: 8281/10000 (82.8100%),                 avg. length: 494.4,                last time consumption/overall running time: 481.9668s / 378541.4904 s
env0_first_0:                 episode reward: -68.5000,                 loss: 1.2300
env0_second_0:                 episode reward: 68.5000,                 loss: 0.8644
env1_first_0:                 episode reward: -51.5500,                 loss: nan
env1_second_0:                 episode reward: 51.5500,                 loss: nan
Episode: 8301/10000 (83.0100%),                 avg. length: 574.45,                last time consumption/overall running time: 556.8205s / 379098.3110 s
env0_first_0:                 episode reward: -58.3500,                 loss: 1.2368
env0_second_0:                 episode reward: 58.3500,                 loss: 0.8699
env1_first_0:                 episode reward: -42.1000,                 loss: nan
env1_second_0:                 episode reward: 42.1000,                 loss: nan
Episode: 8321/10000 (83.2100%),                 avg. length: 654.65,                last time consumption/overall running time: 635.3583s / 379733.6692 s
env0_first_0:                 episode reward: -56.8000,                 loss: 1.4892
env0_second_0:                 episode reward: 56.8000,                 loss: 0.8784
env1_first_0:                 episode reward: -51.2000,                 loss: nan
env1_second_0:                 episode reward: 51.2000,                 loss: nan
Episode: 8341/10000 (83.4100%),                 avg. length: 480.3,                last time consumption/overall running time: 464.1836s / 380197.8528 s
env0_first_0:                 episode reward: -48.7000,                 loss: 1.4252
env0_second_0:                 episode reward: 48.7000,                 loss: 0.9160
env1_first_0:                 episode reward: -57.1000,                 loss: nan
env1_second_0:                 episode reward: 57.1000,                 loss: nan
Episode: 8361/10000 (83.6100%),                 avg. length: 586.95,                last time consumption/overall running time: 569.4095s / 380767.2623 s
env0_first_0:                 episode reward: -40.9500,                 loss: 1.5298
env0_second_0:                 episode reward: 40.9500,                 loss: 0.9303
env1_first_0:                 episode reward: -66.1500,                 loss: nan
env1_second_0:                 episode reward: 66.1500,                 loss: nan
Episode: 8381/10000 (83.8100%),                 avg. length: 622.95,                last time consumption/overall running time: 601.0462s / 381368.3084 s
env0_first_0:                 episode reward: -46.0500,                 loss: 1.3458
env0_second_0:                 episode reward: 46.0500,                 loss: 0.8977
env1_first_0:                 episode reward: -65.1500,                 loss: nan
env1_second_0:                 episode reward: 65.1500,                 loss: nan
Episode: 8401/10000 (84.0100%),                 avg. length: 634.65,                last time consumption/overall running time: 618.8136s / 381987.1220 s
env0_first_0:                 episode reward: -73.7500,                 loss: 1.3986
env0_second_0:                 episode reward: 73.7500,                 loss: 0.9374
env1_first_0:                 episode reward: -47.3000,                 loss: nan
env1_second_0:                 episode reward: 47.3000,                 loss: nan
Episode: 8421/10000 (84.2100%),                 avg. length: 699.95,                last time consumption/overall running time: 677.0968s / 382664.2188 s
env0_first_0:                 episode reward: -60.7000,                 loss: 1.4001
env0_second_0:                 episode reward: 60.7000,                 loss: 0.9200
env1_first_0:                 episode reward: -49.7000,                 loss: nan
env1_second_0:                 episode reward: 49.7000,                 loss: nan
Episode: 8441/10000 (84.4100%),                 avg. length: 522.25,                last time consumption/overall running time: 509.3355s / 383173.5542 s
env0_first_0:                 episode reward: -48.7500,                 loss: 1.5075
env0_second_0:                 episode reward: 48.7500,                 loss: 1.0193
env1_first_0:                 episode reward: -64.5500,                 loss: nan
env1_second_0:                 episode reward: 64.5500,                 loss: nan
Episode: 8461/10000 (84.6100%),                 avg. length: 640.25,                last time consumption/overall running time: 620.2746s / 383793.8288 s
env0_first_0:                 episode reward: -57.4000,                 loss: 1.5298
env0_second_0:                 episode reward: 57.4000,                 loss: 1.0615
env1_first_0:                 episode reward: -58.9000,                 loss: nan
env1_second_0:                 episode reward: 58.9000,                 loss: nan
Episode: 8481/10000 (84.8100%),                 avg. length: 673.8,                last time consumption/overall running time: 651.1521s / 384444.9809 s
env0_first_0:                 episode reward: -55.6000,                 loss: 1.6983
env0_second_0:                 episode reward: 55.6000,                 loss: 1.0696
env1_first_0:                 episode reward: -52.1500,                 loss: nan
env1_second_0:                 episode reward: 52.1500,                 loss: nan
Episode: 8501/10000 (85.0100%),                 avg. length: 570.85,                last time consumption/overall running time: 549.5412s / 384994.5221 s
env0_first_0:                 episode reward: -41.8000,                 loss: 1.5454
env0_second_0:                 episode reward: 41.8000,                 loss: 1.1790
env1_first_0:                 episode reward: -68.0500,                 loss: nan
env1_second_0:                 episode reward: 68.0500,                 loss: nan
Episode: 8521/10000 (85.2100%),                 avg. length: 626.45,                last time consumption/overall running time: 622.4411s / 385616.9631 s
env0_first_0:                 episode reward: -42.3500,                 loss: 1.5368
env0_second_0:                 episode reward: 42.3500,                 loss: 1.1795
env1_first_0:                 episode reward: -60.8000,                 loss: nan
env1_second_0:                 episode reward: 60.8000,                 loss: nan
Episode: 8541/10000 (85.4100%),                 avg. length: 533.95,                last time consumption/overall running time: 585.8492s / 386202.8124 s
env0_first_0:                 episode reward: -49.0000,                 loss: 1.4976
env0_second_0:                 episode reward: 49.0000,                 loss: 1.2512
env1_first_0:                 episode reward: -53.1000,                 loss: nan
env1_second_0:                 episode reward: 53.1000,                 loss: nan
Episode: 8561/10000 (85.6100%),                 avg. length: 541.6,                last time consumption/overall running time: 591.7771s / 386794.5895 s
env0_first_0:                 episode reward: -51.0000,                 loss: 1.4347
env0_second_0:                 episode reward: 51.0000,                 loss: 1.2067
env1_first_0:                 episode reward: -70.4500,                 loss: nan
env1_second_0:                 episode reward: 70.4500,                 loss: nan
Episode: 8581/10000 (85.8100%),                 avg. length: 672.25,                last time consumption/overall running time: 731.6672s / 387526.2566 s
env0_first_0:                 episode reward: -54.5500,                 loss: 1.3697
env0_second_0:                 episode reward: 54.5500,                 loss: 1.2031
env1_first_0:                 episode reward: -64.8000,                 loss: nan
env1_second_0:                 episode reward: 64.8000,                 loss: nan
Episode: 8601/10000 (86.0100%),                 avg. length: 527.5,                last time consumption/overall running time: 580.3441s / 388106.6007 s
env0_first_0:                 episode reward: -54.3000,                 loss: 1.3271
env0_second_0:                 episode reward: 54.3000,                 loss: 1.1465
env1_first_0:                 episode reward: -62.1500,                 loss: nan
env1_second_0:                 episode reward: 62.1500,                 loss: nan
Episode: 8621/10000 (86.2100%),                 avg. length: 527.65,                last time consumption/overall running time: 577.5095s / 388684.1102 s
env0_first_0:                 episode reward: -56.7000,                 loss: 1.3349
env0_second_0:                 episode reward: 56.7000,                 loss: 1.1260
env1_first_0:                 episode reward: -65.3000,                 loss: nan
env1_second_0:                 episode reward: 65.3000,                 loss: nan
Episode: 8641/10000 (86.4100%),                 avg. length: 663.9,                last time consumption/overall running time: 729.0294s / 389413.1396 s
env0_first_0:                 episode reward: -72.2000,                 loss: 1.3664
env0_second_0:                 episode reward: 72.2000,                 loss: 1.0928
env1_first_0:                 episode reward: -57.5500,                 loss: nan
env1_second_0:                 episode reward: 57.5500,                 loss: nan
Episode: 8661/10000 (86.6100%),                 avg. length: 513.25,                last time consumption/overall running time: 564.5685s / 389977.7081 s
env0_first_0:                 episode reward: -55.5500,                 loss: 1.2275
env0_second_0:                 episode reward: 55.5500,                 loss: 1.0422
env1_first_0:                 episode reward: -71.9500,                 loss: nan
env1_second_0:                 episode reward: 71.9500,                 loss: nan
Episode: 8681/10000 (86.8100%),                 avg. length: 629.8,                last time consumption/overall running time: 696.6171s / 390674.3252 s
env0_first_0:                 episode reward: -60.3500,                 loss: 1.3904
env0_second_0:                 episode reward: 60.3500,                 loss: 1.0453
env1_first_0:                 episode reward: -58.8500,                 loss: nan
env1_second_0:                 episode reward: 58.8500,                 loss: nan
Episode: 8701/10000 (87.0100%),                 avg. length: 841.55,                last time consumption/overall running time: 932.7534s / 391607.0786 s
env0_first_0:                 episode reward: -53.2000,                 loss: 1.3652
env0_second_0:                 episode reward: 53.2000,                 loss: 1.0010
env1_first_0:                 episode reward: -61.3000,                 loss: nan
env1_second_0:                 episode reward: 61.3000,                 loss: nan
Episode: 8721/10000 (87.2100%),                 avg. length: 631.2,                last time consumption/overall running time: 692.8275s / 392299.9062 s
env0_first_0:                 episode reward: -51.5000,                 loss: 1.3284
env0_second_0:                 episode reward: 51.5000,                 loss: 0.9699
env1_first_0:                 episode reward: -61.2000,                 loss: nan
env1_second_0:                 episode reward: 61.2000,                 loss: nan
Episode: 8741/10000 (87.4100%),                 avg. length: 675.85,                last time consumption/overall running time: 738.5441s / 393038.4503 s
env0_first_0:                 episode reward: -53.3500,                 loss: 1.4253
env0_second_0:                 episode reward: 53.3500,                 loss: 0.9654
env1_first_0:                 episode reward: -54.7500,                 loss: nan
env1_second_0:                 episode reward: 54.7500,                 loss: nan
Episode: 8761/10000 (87.6100%),                 avg. length: 752.15,                last time consumption/overall running time: 824.2546s / 393862.7049 s
env0_first_0:                 episode reward: -38.2000,                 loss: 1.2963
env0_second_0:                 episode reward: 38.2000,                 loss: 1.0470
env1_first_0:                 episode reward: -55.4500,                 loss: nan
env1_second_0:                 episode reward: 55.4500,                 loss: nan
Episode: 8781/10000 (87.8100%),                 avg. length: 698.0,                last time consumption/overall running time: 756.3309s / 394619.0358 s
env0_first_0:                 episode reward: -63.3500,                 loss: 1.3254
env0_second_0:                 episode reward: 63.3500,                 loss: 1.0848
env1_first_0:                 episode reward: -43.0000,                 loss: nan
env1_second_0:                 episode reward: 43.0000,                 loss: nan
Episode: 8801/10000 (88.0100%),                 avg. length: 535.1,                last time consumption/overall running time: 581.5259s / 395200.5618 s
env0_first_0:                 episode reward: -71.8000,                 loss: 1.4376
env0_second_0:                 episode reward: 71.8000,                 loss: 1.0180
env1_first_0:                 episode reward: -43.5000,                 loss: nan
env1_second_0:                 episode reward: 43.5000,                 loss: nan
Episode: 8821/10000 (88.2100%),                 avg. length: 538.65,                last time consumption/overall running time: 588.4746s / 395789.0364 s
env0_first_0:                 episode reward: -53.1000,                 loss: 1.3950
env0_second_0:                 episode reward: 53.1000,                 loss: 1.0465
env1_first_0:                 episode reward: -63.1500,                 loss: nan
env1_second_0:                 episode reward: 63.1500,                 loss: nan
Episode: 8841/10000 (88.4100%),                 avg. length: 514.7,                last time consumption/overall running time: 560.6206s / 396349.6570 s
env0_first_0:                 episode reward: -56.1500,                 loss: 1.4360
env0_second_0:                 episode reward: 56.1500,                 loss: 1.0949
env1_first_0:                 episode reward: -58.3000,                 loss: nan
env1_second_0:                 episode reward: 58.3000,                 loss: nan
Episode: 8861/10000 (88.6100%),                 avg. length: 601.4,                last time consumption/overall running time: 662.8494s / 397012.5065 s
env0_first_0:                 episode reward: -49.2500,                 loss: 1.5047
env0_second_0:                 episode reward: 49.2500,                 loss: 1.0825
env1_first_0:                 episode reward: -65.0500,                 loss: nan
env1_second_0:                 episode reward: 65.0500,                 loss: nan
Episode: 8881/10000 (88.8100%),                 avg. length: 458.25,                last time consumption/overall running time: 496.0021s / 397508.5086 s
env0_first_0:                 episode reward: -53.7000,                 loss: 1.4921
env0_second_0:                 episode reward: 53.7000,                 loss: 1.1868
env1_first_0:                 episode reward: -76.4000,                 loss: nan
env1_second_0:                 episode reward: 76.4000,                 loss: nan
Episode: 8901/10000 (89.0100%),                 avg. length: 789.4,                last time consumption/overall running time: 852.5636s / 398361.0722 s
env0_first_0:                 episode reward: -65.8000,                 loss: 1.5237
env0_second_0:                 episode reward: 65.8000,                 loss: 1.1575
env1_first_0:                 episode reward: -48.5500,                 loss: nan
env1_second_0:                 episode reward: 48.5500,                 loss: nan
Episode: 8921/10000 (89.2100%),                 avg. length: 592.05,                last time consumption/overall running time: 640.9639s / 399002.0361 s
env0_first_0:                 episode reward: -65.0000,                 loss: 1.4235
env0_second_0:                 episode reward: 65.0000,                 loss: 1.1281
env1_first_0:                 episode reward: -64.3500,                 loss: nan
env1_second_0:                 episode reward: 64.3500,                 loss: nan
Episode: 8941/10000 (89.4100%),                 avg. length: 776.05,                last time consumption/overall running time: 832.1930s / 399834.2291 s
env0_first_0:                 episode reward: -50.4000,                 loss: 1.4754
env0_second_0:                 episode reward: 50.4000,                 loss: 1.2140
env1_first_0:                 episode reward: -59.4500,                 loss: nan
env1_second_0:                 episode reward: 59.4500,                 loss: nan
Episode: 8961/10000 (89.6100%),                 avg. length: 604.35,                last time consumption/overall running time: 655.0534s / 400489.2825 s
env0_first_0:                 episode reward: -62.2000,                 loss: 1.5774
env0_second_0:                 episode reward: 62.2000,                 loss: 1.1286
env1_first_0:                 episode reward: -49.4000,                 loss: nan
env1_second_0:                 episode reward: 49.4000,                 loss: nan
Episode: 8981/10000 (89.8100%),                 avg. length: 611.2,                last time consumption/overall running time: 658.0745s / 401147.3570 s
env0_first_0:                 episode reward: -71.3000,                 loss: 1.5949
env0_second_0:                 episode reward: 71.3000,                 loss: 1.0749
env1_first_0:                 episode reward: -31.4000,                 loss: nan
env1_second_0:                 episode reward: 31.4000,                 loss: nan
Episode: 9001/10000 (90.0100%),                 avg. length: 767.6,                last time consumption/overall running time: 831.0806s / 401978.4376 s
env0_first_0:                 episode reward: -43.7000,                 loss: 1.2191
env0_second_0:                 episode reward: 43.7000,                 loss: 0.9714
env1_first_0:                 episode reward: -61.7500,                 loss: nan
env1_second_0:                 episode reward: 61.7500,                 loss: nan
Episode: 9021/10000 (90.2100%),                 avg. length: 698.05,                last time consumption/overall running time: 747.9919s / 402726.4294 s
env0_first_0:                 episode reward: -42.6000,                 loss: 1.2679
env0_second_0:                 episode reward: 42.6000,                 loss: 0.9878
env1_first_0:                 episode reward: -74.0000,                 loss: nan
env1_second_0:                 episode reward: 74.0000,                 loss: nan
Episode: 9041/10000 (90.4100%),                 avg. length: 588.8,                last time consumption/overall running time: 639.4111s / 403365.8405 s
env0_first_0:                 episode reward: -46.2500,                 loss: 1.2939
env0_second_0:                 episode reward: 46.2500,                 loss: 0.9972
env1_first_0:                 episode reward: -67.0000,                 loss: nan
env1_second_0:                 episode reward: 67.0000,                 loss: nan
Episode: 9061/10000 (90.6100%),                 avg. length: 521.2,                last time consumption/overall running time: 560.7205s / 403926.5610 s
env0_first_0:                 episode reward: -60.2500,                 loss: 1.4204
env0_second_0:                 episode reward: 60.2500,                 loss: 1.0599
env1_first_0:                 episode reward: -70.6000,                 loss: nan
env1_second_0:                 episode reward: 70.6000,                 loss: nan
Episode: 9081/10000 (90.8100%),                 avg. length: 540.05,                last time consumption/overall running time: 578.2634s / 404504.8244 s
env0_first_0:                 episode reward: -57.2500,                 loss: 1.5179
env0_second_0:                 episode reward: 57.2500,                 loss: 1.1842
env1_first_0:                 episode reward: -56.8000,                 loss: nan
env1_second_0:                 episode reward: 56.8000,                 loss: nan
Episode: 9101/10000 (91.0100%),                 avg. length: 679.1,                last time consumption/overall running time: 727.2212s / 405232.0456 s
env0_first_0:                 episode reward: -44.4500,                 loss: 1.5261
env0_second_0:                 episode reward: 44.4500,                 loss: 1.2018
env1_first_0:                 episode reward: -65.2500,                 loss: nan
env1_second_0:                 episode reward: 65.2500,                 loss: nan
Episode: 9121/10000 (91.2100%),                 avg. length: 643.75,                last time consumption/overall running time: 687.5203s / 405919.5659 s
env0_first_0:                 episode reward: -61.0000,                 loss: 1.4652
env0_second_0:                 episode reward: 61.0000,                 loss: 1.1463
env1_first_0:                 episode reward: -60.1500,                 loss: nan
env1_second_0:                 episode reward: 60.1500,                 loss: nan
Episode: 9141/10000 (91.4100%),                 avg. length: 1090.1,                last time consumption/overall running time: 1166.3157s / 407085.8816 s
env0_first_0:                 episode reward: -51.1000,                 loss: 1.4584
env0_second_0:                 episode reward: 51.1000,                 loss: 1.1208
env1_first_0:                 episode reward: -43.9500,                 loss: nan
env1_second_0:                 episode reward: 43.9500,                 loss: nan
Episode: 9161/10000 (91.6100%),                 avg. length: 756.35,                last time consumption/overall running time: 810.5054s / 407896.3869 s
env0_first_0:                 episode reward: -51.9500,                 loss: 1.4304
env0_second_0:                 episode reward: 51.9500,                 loss: 1.0947
env1_first_0:                 episode reward: -37.8500,                 loss: nan
env1_second_0:                 episode reward: 37.8500,                 loss: nan
Episode: 9181/10000 (91.8100%),                 avg. length: 546.55,                last time consumption/overall running time: 584.5299s / 408480.9168 s
env0_first_0:                 episode reward: -60.3500,                 loss: 1.4391
env0_second_0:                 episode reward: 60.3500,                 loss: 1.1477
env1_first_0:                 episode reward: -54.2000,                 loss: nan
env1_second_0:                 episode reward: 54.2000,                 loss: nan
Episode: 9201/10000 (92.0100%),                 avg. length: 825.15,                last time consumption/overall running time: 880.3722s / 409361.2891 s
env0_first_0:                 episode reward: -44.2500,                 loss: 1.3758
env0_second_0:                 episode reward: 44.2500,                 loss: 1.2195
env1_first_0:                 episode reward: -46.1500,                 loss: nan
env1_second_0:                 episode reward: 46.1500,                 loss: nan
Episode: 9221/10000 (92.2100%),                 avg. length: 644.35,                last time consumption/overall running time: 684.2734s / 410045.5625 s
env0_first_0:                 episode reward: -55.7500,                 loss: 1.4993
env0_second_0:                 episode reward: 55.7500,                 loss: 1.1390
env1_first_0:                 episode reward: -42.5500,                 loss: nan
env1_second_0:                 episode reward: 42.5500,                 loss: nan
Episode: 9241/10000 (92.4100%),                 avg. length: 792.55,                last time consumption/overall running time: 845.1388s / 410890.7013 s
env0_first_0:                 episode reward: -47.3000,                 loss: 1.3774
env0_second_0:                 episode reward: 47.3000,                 loss: 0.9447
env1_first_0:                 episode reward: -54.8000,                 loss: nan
env1_second_0:                 episode reward: 54.8000,                 loss: nan
Episode: 9261/10000 (92.6100%),                 avg. length: 638.15,                last time consumption/overall running time: 673.0002s / 411563.7015 s
env0_first_0:                 episode reward: -48.1500,                 loss: 1.2517
env0_second_0:                 episode reward: 48.1500,                 loss: 0.8924
env1_first_0:                 episode reward: -56.2500,                 loss: nan
env1_second_0:                 episode reward: 56.2500,                 loss: nan
Episode: 9281/10000 (92.8100%),                 avg. length: 900.15,                last time consumption/overall running time: 958.5610s / 412522.2624 s
env0_first_0:                 episode reward: -54.1000,                 loss: 1.3321
env0_second_0:                 episode reward: 54.1000,                 loss: 0.8803
env1_first_0:                 episode reward: -57.3000,                 loss: nan
env1_second_0:                 episode reward: 57.3000,                 loss: nan
Episode: 9301/10000 (93.0100%),                 avg. length: 752.05,                last time consumption/overall running time: 796.0223s / 413318.2847 s
env0_first_0:                 episode reward: -34.7500,                 loss: 1.3202
env0_second_0:                 episode reward: 34.7500,                 loss: 0.9626
env1_first_0:                 episode reward: -61.5500,                 loss: nan
env1_second_0:                 episode reward: 61.5500,                 loss: nan
Episode: 9321/10000 (93.2100%),                 avg. length: 662.95,                last time consumption/overall running time: 709.7051s / 414027.9898 s
env0_first_0:                 episode reward: -57.8000,                 loss: 1.3362
env0_second_0:                 episode reward: 57.8000,                 loss: 1.0187
env1_first_0:                 episode reward: -45.9000,                 loss: nan
env1_second_0:                 episode reward: 45.9000,                 loss: nan
Episode: 9341/10000 (93.4100%),                 avg. length: 712.25,                last time consumption/overall running time: 755.5741s / 414783.5638 s
env0_first_0:                 episode reward: -42.0500,                 loss: 1.3594
env0_second_0:                 episode reward: 42.0500,                 loss: 1.0739
env1_first_0:                 episode reward: -57.9500,                 loss: nan
env1_second_0:                 episode reward: 57.9500,                 loss: nan
Episode: 9361/10000 (93.6100%),                 avg. length: 651.0,                last time consumption/overall running time: 693.5718s / 415477.1357 s
env0_first_0:                 episode reward: -47.1000,                 loss: 1.3770
env0_second_0:                 episode reward: 47.1000,                 loss: 1.0904
env1_first_0:                 episode reward: -64.3000,                 loss: nan
env1_second_0:                 episode reward: 64.3000,                 loss: nan
Episode: 9381/10000 (93.8100%),                 avg. length: 602.1,                last time consumption/overall running time: 636.3875s / 416113.5232 s
env0_first_0:                 episode reward: -39.1500,                 loss: 1.4969
env0_second_0:                 episode reward: 39.1500,                 loss: 1.1129
env1_first_0:                 episode reward: -69.8500,                 loss: nan
env1_second_0:                 episode reward: 69.8500,                 loss: nan
Episode: 9401/10000 (94.0100%),                 avg. length: 597.3,                last time consumption/overall running time: 631.6471s / 416745.1702 s
env0_first_0:                 episode reward: -53.3000,                 loss: 1.4822
env0_second_0:                 episode reward: 53.3000,                 loss: 1.1197
env1_first_0:                 episode reward: -57.9000,                 loss: nan
env1_second_0:                 episode reward: 57.9000,                 loss: nan
Episode: 9421/10000 (94.2100%),                 avg. length: 548.65,                last time consumption/overall running time: 584.3652s / 417329.5354 s
env0_first_0:                 episode reward: -45.6500,                 loss: 1.4065
env0_second_0:                 episode reward: 45.6500,                 loss: 1.1800
env1_first_0:                 episode reward: -60.8500,                 loss: nan
env1_second_0:                 episode reward: 60.8500,                 loss: nan
Episode: 9441/10000 (94.4100%),                 avg. length: 622.85,                last time consumption/overall running time: 671.2265s / 418000.7619 s
env0_first_0:                 episode reward: -55.3000,                 loss: 1.4323
env0_second_0:                 episode reward: 55.3000,                 loss: 1.1023
env1_first_0:                 episode reward: -65.6500,                 loss: nan
env1_second_0:                 episode reward: 65.6500,                 loss: nan
Episode: 9461/10000 (94.6100%),                 avg. length: 534.35,                last time consumption/overall running time: 567.1138s / 418567.8757 s
env0_first_0:                 episode reward: -59.7500,                 loss: 1.4155
env0_second_0:                 episode reward: 59.7500,                 loss: 1.1813
env1_first_0:                 episode reward: -56.6500,                 loss: nan
env1_second_0:                 episode reward: 56.6500,                 loss: nan
Episode: 9481/10000 (94.8100%),                 avg. length: 395.75,                last time consumption/overall running time: 426.5728s / 418994.4485 s
env0_first_0:                 episode reward: -64.9000,                 loss: 1.5636
env0_second_0:                 episode reward: 64.9000,                 loss: 1.1331
env1_first_0:                 episode reward: -65.4500,                 loss: nan
env1_second_0:                 episode reward: 65.4500,                 loss: nan
Episode: 9501/10000 (95.0100%),                 avg. length: 518.3,                last time consumption/overall running time: 546.2236s / 419540.6721 s
env0_first_0:                 episode reward: -51.2500,                 loss: 1.6470
env0_second_0:                 episode reward: 51.2500,                 loss: 1.1878
env1_first_0:                 episode reward: -54.8000,                 loss: nan
env1_second_0:                 episode reward: 54.8000,                 loss: nan
Episode: 9521/10000 (95.2100%),                 avg. length: 454.15,                last time consumption/overall running time: 478.9857s / 420019.6577 s
env0_first_0:                 episode reward: -59.0000,                 loss: 1.7511
env0_second_0:                 episode reward: 59.0000,                 loss: 1.1371
env1_first_0:                 episode reward: -43.9000,                 loss: nan
env1_second_0:                 episode reward: 43.9000,                 loss: nan
Episode: 9541/10000 (95.4100%),                 avg. length: 644.5,                last time consumption/overall running time: 685.7065s / 420705.3642 s
env0_first_0:                 episode reward: -49.6500,                 loss: 1.6877
env0_second_0:                 episode reward: 49.6500,                 loss: 1.2405
env1_first_0:                 episode reward: -59.8000,                 loss: nan
env1_second_0:                 episode reward: 59.8000,                 loss: nan
Episode: 9561/10000 (95.6100%),                 avg. length: 518.85,                last time consumption/overall running time: 545.1809s / 421250.5451 s
env0_first_0:                 episode reward: -56.9000,                 loss: 1.6913
env0_second_0:                 episode reward: 56.9000,                 loss: 1.2928
env1_first_0:                 episode reward: -43.6500,                 loss: nan
env1_second_0:                 episode reward: 43.6500,                 loss: nan
Episode: 9581/10000 (95.8100%),                 avg. length: 537.5,                last time consumption/overall running time: 563.5770s / 421814.1221 s
env0_first_0:                 episode reward: -52.8000,                 loss: 1.6942
env0_second_0:                 episode reward: 52.8000,                 loss: 1.1901
env1_first_0:                 episode reward: -51.3000,                 loss: nan
env1_second_0:                 episode reward: 51.3000,                 loss: nan
Episode: 9601/10000 (96.0100%),                 avg. length: 604.75,                last time consumption/overall running time: 645.8475s / 422459.9696 s
env0_first_0:                 episode reward: -61.4000,                 loss: 1.6977
env0_second_0:                 episode reward: 61.4000,                 loss: 1.0948
env1_first_0:                 episode reward: -48.4000,                 loss: nan
env1_second_0:                 episode reward: 48.4000,                 loss: nan
Episode: 9621/10000 (96.2100%),                 avg. length: 691.35,                last time consumption/overall running time: 729.1749s / 423189.1445 s
env0_first_0:                 episode reward: -60.5500,                 loss: 1.5258
env0_second_0:                 episode reward: 60.5500,                 loss: 1.0813
env1_first_0:                 episode reward: -58.2500,                 loss: nan
env1_second_0:                 episode reward: 58.2500,                 loss: nan
Episode: 9641/10000 (96.4100%),                 avg. length: 527.25,                last time consumption/overall running time: 552.7206s / 423741.8651 s
env0_first_0:                 episode reward: -63.0500,                 loss: 1.6670
env0_second_0:                 episode reward: 63.0500,                 loss: 1.2344
env1_first_0:                 episode reward: -43.7000,                 loss: nan
env1_second_0:                 episode reward: 43.7000,                 loss: nan
Episode: 9661/10000 (96.6100%),                 avg. length: 869.0,                last time consumption/overall running time: 909.4545s / 424651.3197 s
env0_first_0:                 episode reward: -31.7000,                 loss: 1.5276
env0_second_0:                 episode reward: 31.7000,                 loss: 1.1782
env1_first_0:                 episode reward: -62.2000,                 loss: nan
env1_second_0:                 episode reward: 62.2000,                 loss: nan
Episode: 9681/10000 (96.8100%),                 avg. length: 636.9,                last time consumption/overall running time: 665.1689s / 425316.4885 s
env0_first_0:                 episode reward: -60.9500,                 loss: 1.3783
env0_second_0:                 episode reward: 60.9500,                 loss: 1.1626
env1_first_0:                 episode reward: -44.2000,                 loss: nan
env1_second_0:                 episode reward: 44.2000,                 loss: nan
Episode: 9701/10000 (97.0100%),                 avg. length: 732.35,                last time consumption/overall running time: 767.6368s / 426084.1253 s
env0_first_0:                 episode reward: -44.7000,                 loss: 1.5314
env0_second_0:                 episode reward: 44.7000,                 loss: 1.1925
env1_first_0:                 episode reward: -52.2000,                 loss: nan
env1_second_0:                 episode reward: 52.2000,                 loss: nan
Episode: 9721/10000 (97.2100%),                 avg. length: 658.6,                last time consumption/overall running time: 686.8854s / 426771.0107 s
env0_first_0:                 episode reward: -39.9000,                 loss: 1.4536
env0_second_0:                 episode reward: 39.9000,                 loss: 1.1513
env1_first_0:                 episode reward: -62.6000,                 loss: nan
env1_second_0:                 episode reward: 62.6000,                 loss: nan
Episode: 9741/10000 (97.4100%),                 avg. length: 615.2,                last time consumption/overall running time: 645.7319s / 427416.7425 s
env0_first_0:                 episode reward: -60.0000,                 loss: 1.5568
env0_second_0:                 episode reward: 60.0000,                 loss: 1.1837
env1_first_0:                 episode reward: -40.1000,                 loss: nan
env1_second_0:                 episode reward: 40.1000,                 loss: nan
Episode: 9761/10000 (97.6100%),                 avg. length: 683.85,                last time consumption/overall running time: 725.1618s / 428141.9043 sLoad boxing_v1 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
Load boxing_v1 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
/home/zihan/research/MARS/mars/rl/agents/nash_dqn.py:293: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1641801999604/work/torch/csrc/utils/tensor_new.cpp:210.)
  action = torch.FloatTensor(action).to(self.device)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

env0_first_0:                 episode reward: -53.0500,                 loss: 1.5742
env0_second_0:                 episode reward: 53.0500,                 loss: 1.1375
env1_first_0:                 episode reward: -35.3500,                 loss: nan
env1_second_0:                 episode reward: 35.3500,                 loss: nan
Episode: 9781/10000 (97.8100%),                 avg. length: 535.4,                last time consumption/overall running time: 571.2466s / 428713.1509 s
env0_first_0:                 episode reward: -65.4500,                 loss: 1.6473
env0_second_0:                 episode reward: 65.4500,                 loss: 1.1077
env1_first_0:                 episode reward: -41.5000,                 loss: nan
env1_second_0:                 episode reward: 41.5000,                 loss: nan
Episode: 9801/10000 (98.0100%),                 avg. length: 844.6,                last time consumption/overall running time: 876.4158s / 429589.5667 s
env0_first_0:                 episode reward: -69.1500,                 loss: 1.7050
env0_second_0:                 episode reward: 69.1500,                 loss: 1.1339
env1_first_0:                 episode reward: -17.8000,                 loss: nan
env1_second_0:                 episode reward: 17.8000,                 loss: nan
Episode: 9821/10000 (98.2100%),                 avg. length: 782.8,                last time consumption/overall running time: 816.0945s / 430405.6612 s
env0_first_0:                 episode reward: -58.6500,                 loss: 1.6467
env0_second_0:                 episode reward: 58.6500,                 loss: 1.0854
env1_first_0:                 episode reward: -29.8000,                 loss: nan
env1_second_0:                 episode reward: 29.8000,                 loss: nan
Episode: 9841/10000 (98.4100%),                 avg. length: 818.7,                last time consumption/overall running time: 858.6047s / 431264.2659 s
env0_first_0:                 episode reward: -46.0500,                 loss: 1.6130
env0_second_0:                 episode reward: 46.0500,                 loss: 1.1803
env1_first_0:                 episode reward: -45.6500,                 loss: nan
env1_second_0:                 episode reward: 45.6500,                 loss: nan
Episode: 9861/10000 (98.6100%),                 avg. length: 666.7,                last time consumption/overall running time: 693.0088s / 431957.2746 s
env0_first_0:                 episode reward: -59.1500,                 loss: 1.6084
env0_second_0:                 episode reward: 59.1500,                 loss: 1.1233
env1_first_0:                 episode reward: -59.0500,                 loss: nan
env1_second_0:                 episode reward: 59.0500,                 loss: nan
Episode: 9881/10000 (98.8100%),                 avg. length: 827.15,                last time consumption/overall running time: 861.7188s / 432818.9934 s
env0_first_0:                 episode reward: -43.1500,                 loss: 1.6118
env0_second_0:                 episode reward: 43.1500,                 loss: 1.0872
env1_first_0:                 episode reward: -51.7500,                 loss: nan
env1_second_0:                 episode reward: 51.7500,                 loss: nan
Episode: 9901/10000 (99.0100%),                 avg. length: 642.75,                last time consumption/overall running time: 672.5851s / 433491.5785 s
env0_first_0:                 episode reward: -61.4000,                 loss: 1.5490
env0_second_0:                 episode reward: 61.4000,                 loss: 1.0714
env1_first_0:                 episode reward: -46.5000,                 loss: nan
env1_second_0:                 episode reward: 46.5000,                 loss: nan
Episode: 9921/10000 (99.2100%),                 avg. length: 762.35,                last time consumption/overall running time: 795.2046s / 434286.7831 s
env0_first_0:                 episode reward: -44.6000,                 loss: 1.4929
env0_second_0:                 episode reward: 44.6000,                 loss: 1.0456
env1_first_0:                 episode reward: -45.4500,                 loss: nan
env1_second_0:                 episode reward: 45.4500,                 loss: nan
Episode: 9941/10000 (99.4100%),                 avg. length: 777.8,                last time consumption/overall running time: 817.8472s / 435104.6303 s
env0_first_0:                 episode reward: -52.8000,                 loss: 1.5055
env0_second_0:                 episode reward: 52.8000,                 loss: 1.0374
env1_first_0:                 episode reward: -42.4500,                 loss: nan
env1_second_0:                 episode reward: 42.4500,                 loss: nan
Episode: 9961/10000 (99.6100%),                 avg. length: 757.6,                last time consumption/overall running time: 793.0371s / 435897.6674 s
env0_first_0:                 episode reward: -54.3500,                 loss: 1.4113
env0_second_0:                 episode reward: 54.3500,                 loss: 1.1633
env1_first_0:                 episode reward: -60.2000,                 loss: nan
env1_second_0:                 episode reward: 60.2000,                 loss: nan
Episode: 9981/10000 (99.8100%),                 avg. length: 667.95,                last time consumption/overall running time: 701.2362s / 436598.9035 s
env0_first_0:                 episode reward: -41.1500,                 loss: 1.4192
env0_second_0:                 episode reward: 41.1500,                 loss: 1.1291
env1_first_0:                 episode reward: -58.6500,                 loss: nan
env1_second_0:                 episode reward: 58.6500,                 loss: nan
