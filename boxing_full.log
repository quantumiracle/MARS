/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
wandb: Currently logged in as: quantumiracle. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.13.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/zihan/research/MARS/wandb/run-20221221_035417-236a7ulf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run happy-jazz-2
wandb: ‚≠êÔ∏è View project at https://wandb.ai/quantumiracle/boxing_v5full_length
wandb: üöÄ View run at https://wandb.ai/quantumiracle/boxing_v5full_length/runs/236a7ulf
A.L.E: Arcade Learning Environment (version 0.7.4+069f8bd)
[Powered by Stella]
ALE/Boxing-v5 gym
record video: interval 1000, length 300
Load ALE/Boxing-v5 environment in type gym.
Env observation space: Box(0, 1, (3, 210, 160), uint8) action space: Discrete(18)
random seed: 35
<RecordVideo<mars.env.wrappers.mars_wrappers.Gym2AgentWrapper object at 0x7f2fc9ef2a90>>
Agents No. [1] (index starting from 0) are not learnable.
Arguments:  {'env_name': 'ALE/Boxing-v5', 'env_type': 'gym', 'num_envs': 1, 'ram': False, 'seed': 'random', 'adversarial': False, 'record_video': True, 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 1000000}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 50000, 'max_steps_per_episode': 10000, 'train_start_frame': 10000, 'save_id': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': True, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'wandb_activate': True, 'wandb_entity': 'quantumiracle', 'wandb_project': 'boxing_v5full_length', 'wandb_group': '', 'wandb_name': '', 'net_architecture': {'hidden_dim_list': [512, 512], 'hidden_activation': 'ReLU', 'output_activation': False, 'channel_list': [32, 64, 64], 'kernel_size_list': [8, 4, 3], 'stride_list': [4, 2, 1]}, 'marl_method': False, 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}}
Save models to : /data/zihan/research/MARS/data/model/0/gym_ALE/Boxing-v5_False. 
 Save logs to: /data/zihan/research/MARS/data/log/0/gym_ALE/Boxing-v5_False.
Episode: 1/50000 (0.0020%),                 avg. length: 1786.0,                last time consumption/overall running time: 5.24s / 5.24 s
first_0:                 episode reward: 9.0000,                 loss: nan
Episode: 21/50000 (0.0420%),                 avg. length: 1786.0,                last time consumption/overall running time: 2204.66s / 2209.91 s
first_0:                 episode reward: 1.6000,                 loss: 0.0996
Episode: 41/50000 (0.0820%),                 avg. length: 1786.0,                last time consumption/overall running time: 2961.51s / 5171.41 s
first_0:                 episode reward: -0.2500,                 loss: 0.0336
Episode: 61/50000 (0.1220%),                 avg. length: 1786.0,                last time consumption/overall running time: 3478.66s / 8650.08 s
first_0:                 episode reward: 2.0500,                 loss: 0.0271
Episode: 81/50000 (0.1620%),                 avg. length: 1786.0,                last time consumption/overall running time: 3010.27s / 11660.35 s
first_0:                 episode reward: 2.4500,                 loss: 0.0271
Episode: 101/50000 (0.2020%),                 avg. length: 1786.0,                last time consumption/overall running time: 3039.41s / 14699.75 s
first_0:                 episode reward: 2.0500,                 loss: 0.0291
Episode: 121/50000 (0.2420%),                 avg. length: 1786.0,                last time consumption/overall running time: 3065.61s / 17765.37 s
first_0:                 episode reward: 0.5500,                 loss: 0.0269
Episode: 141/50000 (0.2820%),                 avg. length: 1786.0,                last time consumption/overall running time: 3052.26s / 20817.63 s
first_0:                 episode reward: 0.9000,                 loss: 0.0257
Episode: 161/50000 (0.3220%),                 avg. length: 1786.0,                last time consumption/overall running time: 3069.73s / 23887.36 s
first_0:                 episode reward: 3.2500,                 loss: 0.0272
Episode: 181/50000 (0.3620%),                 avg. length: 1786.0,                last time consumption/overall running time: 3041.13s / 26928.49 s
first_0:                 episode reward: 3.5500,                 loss: 0.0278
Episode: 201/50000 (0.4020%),                 avg. length: 1786.0,                last time consumption/overall running time: 3037.51s / 29965.99 s
first_0:                 episode reward: 2.1000,                 loss: 0.0278
Episode: 221/50000 (0.4420%),                 avg. length: 1786.0,                last time consumption/overall running time: 3078.21s / 33044.21 s
first_0:                 episode reward: 1.3000,                 loss: 0.0287
Episode: 241/50000 (0.4820%),                 avg. length: 1786.0,                last time consumption/overall running time: 3043.49s / 36087.70 s
first_0:                 episode reward: 5.2500,                 loss: 0.0288
Episode: 261/50000 (0.5220%),                 avg. length: 1786.0,                last time consumption/overall running time: 3014.89s / 39102.59 s
first_0:                 episode reward: 4.8000,                 loss: 0.0290
Episode: 281/50000 (0.5620%),                 avg. length: 1786.0,                last time consumption/overall running time: 3027.72s / 42130.32 s
first_0:                 episode reward: 3.5500,                 loss: 0.0294
Episode: 301/50000 (0.6020%),                 avg. length: 1786.0,                last time consumption/overall running time: 3044.73s / 45175.04 s
first_0:                 episode reward: 0.5500,                 loss: 0.0309
Episode: 321/50000 (0.6420%),                 avg. length: 1786.0,                last time consumption/overall running time: 3056.14s / 48231.19 s
first_0:                 episode reward: 1.1500,                 loss: 0.0304
Episode: 341/50000 (0.6820%),                 avg. length: 1786.0,                last time consumption/overall running time: 3074.18s / 51305.36 s
first_0:                 episode reward: 2.8000,                 loss: 0.0303
Episode: 361/50000 (0.7220%),                 avg. length: 1786.0,                last time consumption/overall running time: 3049.72s / 54355.08 s
first_0:                 episode reward: 1.1000,                 loss: 0.0301
Episode: 381/50000 (0.7620%),                 avg. length: 1786.0,                last time consumption/overall running time: 3064.04s / 57419.13 s
first_0:                 episode reward: 5.0000,                 loss: 0.0302
Episode: 401/50000 (0.8020%),                 avg. length: 1786.0,                last time consumption/overall running time: 3076.35s / 60495.47 s
first_0:                 episode reward: 1.9000,                 loss: 0.0301
Episode: 421/50000 (0.8420%),                 avg. length: 1786.0,                last time consumption/overall running time: 3057.75s / 63553.22 s
first_0:                 episode reward: 2.0500,                 loss: 0.0302
Episode: 441/50000 (0.8820%),                 avg. length: 1786.0,                last time consumption/overall running time: 3047.61s / 66600.83 s
first_0:                 episode reward: -0.1500,                 loss: 0.0295
Episode: 461/50000 (0.9220%),                 avg. length: 1786.0,                last time consumption/overall running time: 3073.52s / 69674.35 s
first_0:                 episode reward: 1.6500,                 loss: 0.0293
Episode: 481/50000 (0.9620%),                 avg. length: 1786.0,                last time consumption/overall running time: 3055.96s / 72730.32 s
first_0:                 episode reward: 1.5000,                 loss: 0.0290
Episode: 501/50000 (1.0020%),                 avg. length: 1786.0,                last time consumption/overall running time: 3076.46s / 75806.78 s
first_0:                 episode reward: -0.3000,                 loss: 0.0288
Episode: 521/50000 (1.0420%),                 avg. length: 1786.0,                last time consumption/overall running time: 3066.23s / 78873.01 s
first_0:                 episode reward: -0.7500,                 loss: 0.0285
Episode: 541/50000 (1.0820%),                 avg. length: 1786.0,                last time consumption/overall running time: 3056.88s / 81929.89 s
first_0:                 episode reward: 0.1000,                 loss: 0.0279
Episode: 561/50000 (1.1220%),                 avg. length: 1786.0,                last time consumption/overall running time: 3065.23s / 84995.12 s
first_0:                 episode reward: -3.7000,                 loss: 0.0280
Episode: 581/50000 (1.1620%),                 avg. length: 1786.0,                last time consumption/overall running time: 3075.48s / 88070.61 s
first_0:                 episode reward: -1.8000,                 loss: 0.0276
Episode: 601/50000 (1.2020%),                 avg. length: 1786.0,                last time consumption/overall running time: 3077.91s / 91148.52 s
first_0:                 episode reward: 0.2000,                 loss: 0.0272
Episode: 621/50000 (1.2420%),                 avg. length: 1786.0,                last time consumption/overall running time: 3128.78s / 94277.30 s
first_0:                 episode reward: -0.5000,                 loss: 0.0281
Episode: 641/50000 (1.2820%),                 avg. length: 1786.0,                last time consumption/overall running time: 3087.80s / 97365.10 s
first_0:                 episode reward: -1.3500,                 loss: 0.0279
Episode: 661/50000 (1.3220%),                 avg. length: 1786.0,                last time consumption/overall running time: 3062.02s / 100427.12 s
first_0:                 episode reward: -2.1000,                 loss: 0.0278
Episode: 681/50000 (1.3620%),                 avg. length: 1786.0,                last time consumption/overall running time: 3098.91s / 103526.04 s
first_0:                 episode reward: -3.6000,                 loss: 0.0274
Episode: 701/50000 (1.4020%),                 avg. length: 1786.0,                last time consumption/overall running time: 3112.94s / 106638.97 s
first_0:                 episode reward: -2.2000,                 loss: 0.0277
Episode: 721/50000 (1.4420%),                 avg. length: 1786.0,                last time consumption/overall running time: 3040.84s / 109679.81 s
first_0:                 episode reward: -2.0000,                 loss: 0.0278
Episode: 741/50000 (1.4820%),                 avg. length: 1786.0,                last time consumption/overall running time: 3053.67s / 112733.48 s
first_0:                 episode reward: -2.8000,                 loss: 0.0283
Episode: 761/50000 (1.5220%),                 avg. length: 1786.0,                last time consumption/overall running time: 3118.87s / 115852.35 s
first_0:                 episode reward: 0.2000,                 loss: 0.0275
Episode: 781/50000 (1.5620%),                 avg. length: 1786.0,                last time consumption/overall running time: 3101.42s / 118953.77 s
first_0:                 episode reward: -3.4000,                 loss: 0.0278
Episode: 801/50000 (1.6020%),                 avg. length: 1786.0,                last time consumption/overall running time: 3063.49s / 122017.25 s
first_0:                 episode reward: -4.2000,                 loss: 0.0273
Episode: 821/50000 (1.6420%),                 avg. length: 1786.0,                last time consumption/overall running time: 3102.59s / 125119.85 s
first_0:                 episode reward: -3.0000,                 loss: 0.0278
Episode: 841/50000 (1.6820%),                 avg. length: 1786.0,                last time consumption/overall running time: 3088.40s / 128208.25 s
first_0:                 episode reward: -2.9500,                 loss: 0.0288
Episode: 861/50000 (1.7220%),                 avg. length: 1786.0,                last time consumption/overall running time: 3113.90s / 131322.15 s
first_0:                 episode reward: -4.5500,                 loss: 0.0283
Episode: 881/50000 (1.7620%),                 avg. length: 1786.0,                last time consumption/overall running time: 3096.56s / 134418.71 s
first_0:                 episode reward: -3.7500,                 loss: 0.0281
Episode: 901/50000 (1.8020%),                 avg. length: 1786.0,                last time consumption/overall running time: 3086.82s / 137505.52 s
first_0:                 episode reward: -6.9000,                 loss: 0.0281
Episode: 921/50000 (1.8420%),                 avg. length: 1786.0,                last time consumption/overall running time: 3125.65s / 140631.17 s
first_0:                 episode reward: -3.1000,                 loss: 0.0282
Episode: 941/50000 (1.8820%),                 avg. length: 1786.0,                last time consumption/overall running time: 3100.46s / 143731.63 s
first_0:                 episode reward: -6.5500,                 loss: 0.0281
Episode: 961/50000 (1.9220%),                 avg. length: 1786.0,                last time consumption/overall running time: 3152.77s / 146884.39 s
first_0:                 episode reward: -7.0000,                 loss: 0.0288
Episode: 981/50000 (1.9620%),                 avg. length: 1786.0,                last time consumption/overall running time: 3083.22s / 149967.61 s
first_0:                 episode reward: -3.1000,                 loss: 0.0292
Episode: 1001/50000 (2.0020%),                 avg. length: 1786.0,                last time consumption/overall running time: 3115.82s / 153083.43 s
first_0:                 episode reward: -3.5500,                 loss: 0.0290
Episode: 1021/50000 (2.0420%),                 avg. length: 1786.0,                last time consumption/overall running time: 3143.12s / 156226.55 s
first_0:                 episode reward: -5.1000,                 loss: 0.0285
Episode: 1041/50000 (2.0820%),                 avg. length: 1786.0,                last time consumption/overall running time: 3089.37s / 159315.93 s
first_0:                 episode reward: -6.1000,                 loss: 0.0280
Episode: 1061/50000 (2.1220%),                 avg. length: 1786.0,                last time consumption/overall running time: 3152.10s / 162468.03 s
first_0:                 episode reward: -8.6500,                 loss: 0.0280
Episode: 1081/50000 (2.1620%),                 avg. length: 1786.0,                last time consumption/overall running time: 3133.05s / 165601.08 s
first_0:                 episode reward: -3.7000,                 loss: 0.0278
Episode: 1101/50000 (2.2020%),                 avg. length: 1786.0,                last time consumption/overall running time: 3188.28s / 168789.36 s
first_0:                 episode reward: -4.2500,                 loss: 0.0282
Episode: 1121/50000 (2.2420%),                 avg. length: 1786.0,                last time consumption/overall running time: 3126.72s / 171916.08 s
first_0:                 episode reward: -7.2000,                 loss: 0.0289
Episode: 1141/50000 (2.2820%),                 avg. length: 1786.0,                last time consumption/overall running time: 3206.14s / 175122.22 s
first_0:                 episode reward: -6.3500,                 loss: 0.0284
Episode: 1161/50000 (2.3220%),                 avg. length: 1786.0,                last time consumption/overall running time: 3121.33s / 178243.56 s
first_0:                 episode reward: -7.0000,                 loss: 0.0282
Episode: 1181/50000 (2.3620%),                 avg. length: 1786.0,                last time consumption/overall running time: 3106.65s / 181350.21 s
first_0:                 episode reward: -8.1500,                 loss: 0.0291
Episode: 1201/50000 (2.4020%),                 avg. length: 1786.0,                last time consumption/overall running time: 3100.35s / 184450.56 s
first_0:                 episode reward: -5.9500,                 loss: 0.0290
Episode: 1221/50000 (2.4420%),                 avg. length: 1786.0,                last time consumption/overall running time: 3114.65s / 187565.21 s
first_0:                 episode reward: -5.8500,                 loss: 0.0290
Episode: 1241/50000 (2.4820%),                 avg. length: 1786.0,                last time consumption/overall running time: 3112.02s / 190677.23 s
first_0:                 episode reward: -5.2500,                 loss: 0.0303
Episode: 1261/50000 (2.5220%),                 avg. length: 1786.0,                last time consumption/overall running time: 3117.78s / 193795.01 s
first_0:                 episode reward: -4.7500,                 loss: 0.0293
Episode: 1281/50000 (2.5620%),                 avg. length: 1786.0,                last time consumption/overall running time: 3122.26s / 196917.27 s/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/gym/utils/seeding.py:160: DeprecationWarning: [33mWARN: Function `hash_seed(seed, max_bytes)` is marked as deprecated and will be removed in the future. [0m
  "Function `hash_seed(seed, max_bytes)` is marked as deprecated and will be removed in the future. "
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/gym/utils/seeding.py:204: DeprecationWarning: [33mWARN: Function `_bigint_from_bytes(bytes)` is marked as deprecated and will be removed in the future. [0m
  "Function `_bigint_from_bytes(bytes)` is marked as deprecated and will be removed in the future. "
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/gym/core.py:330: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  "Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future."
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/gym/wrappers/step_api_compatibility.py:40: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  "Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future."
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/gym/wrappers/record_video.py:79: UserWarning: [33mWARN: Overwriting existing videos at /data/zihan/research/MARS/data/videos/gym_ALE/Boxing-v5_DQN_0 folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)[0m
  f"Overwriting existing videos at {self.video_folder} folder "
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/wandb/sdk/lib/import_hooks.py:246: DeprecationWarning: Deprecated since Python 3.4. Use importlib.util.find_spec() instead.
  loader = importlib.find_loader(fullname, path)
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/gym/utils/passive_env_checker.py:196: UserWarning: [33mWARN: Future gym versions will require that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.[0m
  "Future gym versions will require that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information."
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/gym/wrappers/monitoring/video_recorder.py:68: DeprecationWarning: [33mWARN: `env.metadata["render.modes"] is marked as deprecated and will be replaced with `env.metadata["render_modes"]` see https://github.com/openai/gym/pull/2654 for more details[0m
  '`env.metadata["render.modes"] is marked as deprecated and will be replaced '
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/gym/wrappers/monitoring/video_recorder.py:79: DeprecationWarning: [33mWARN: Recording ability for environment ALE/Boxing-v5 initialized with `render_mode=None` is marked as deprecated and will be removed in the future.[0m
  f"Recording ability for environment {env.spec.id} initialized with `render_mode=None` is marked "
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/gym/core.py:52: DeprecationWarning: [33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.
See here for more information: https://www.gymlibrary.ml/content/api/[0m
  "The argument mode in render method is deprecated; "
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/gym/utils/passive_env_checker.py:281: UserWarning: [33mWARN: No render modes was declared in the environment (env.metadata['render_modes'] is None or not defined), you may have trouble when calling `.render()`.[0m
  "No render modes was declared in the environment (env.metadata['render_modes'] is None or not defined), you may have trouble when calling `.render()`."
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/gym/utils/passive_env_checker.py:228: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  "Core environment is written in old step API which returns one bool instead of two. "
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/gym/core.py:52: DeprecationWarning: [33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.
See here for more information: https://www.gymlibrary.ml/content/api/[0m
  "The argument mode in render method is deprecated; "
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/gym/core.py:58: DeprecationWarning: [33mWARN: You are calling render method, but you didn't specified the argument render_mode at environment initialization. To maintain backward compatibility, the environment will render in human mode.
If you want to render in human mode, initialize the environment in this way: gym.make('EnvName', render_mode='human') and don't call the render method.
See here for more information: https://www.gymlibrary.ml/content/api/[0m
  "You are calling render method, "
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/gym/wrappers/monitoring/video_recorder.py:68: DeprecationWarning: [33mWARN: `env.metadata["render.modes"] is marked as deprecated and will be replaced with `env.metadata["render_modes"]` see https://github.com/openai/gym/pull/2654 for more details[0m
  '`env.metadata["render.modes"] is marked as deprecated and will be replaced '
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/gym/wrappers/monitoring/video_recorder.py:79: DeprecationWarning: [33mWARN: Recording ability for environment ALE/Boxing-v5 initialized with `render_mode=None` is marked as deprecated and will be removed in the future.[0m
  f"Recording ability for environment {env.spec.id} initialized with `render_mode=None` is marked "
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/gym/core.py:58: DeprecationWarning: [33mWARN: You are calling render method, but you didn't specified the argument render_mode at environment initialization. To maintain backward compatibility, the environment will render in human mode.
If you want to render in human mode, initialize the environment in this way: gym.make('EnvName', render_mode='human') and don't call the render method.
See here for more information: https://www.gymlibrary.ml/content/api/[0m
  "You are calling render method, "
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/gym/core.py:52: DeprecationWarning: [33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.
See here for more information: https://www.gymlibrary.ml/content/api/[0m
  "The argument mode in render method is deprecated; "
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/gym/wrappers/monitoring/video_recorder.py:68: DeprecationWarning: [33mWARN: `env.metadata["render.modes"] is marked as deprecated and will be replaced with `env.metadata["render_modes"]` see https://github.com/openai/gym/pull/2654 for more details[0m
  '`env.metadata["render.modes"] is marked as deprecated and will be replaced '
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/gym/wrappers/monitoring/video_recorder.py:79: DeprecationWarning: [33mWARN: Recording ability for environment ALE/Boxing-v5 initialized with `render_mode=None` is marked as deprecated and will be removed in the future.[0m
  f"Recording ability for environment {env.spec.id} initialized with `render_mode=None` is marked "

first_0:                 episode reward: -8.9500,                 loss: 0.0290
Episode: 1301/50000 (2.6020%),                 avg. length: 1786.0,                last time consumption/overall running time: 3225.11s / 200142.38 s
first_0:                 episode reward: -6.3500,                 loss: 0.0289
Episode: 1321/50000 (2.6420%),                 avg. length: 1786.0,                last time consumption/overall running time: 3143.05s / 203285.44 s
first_0:                 episode reward: -7.1000,                 loss: 0.0290
Episode: 1341/50000 (2.6820%),                 avg. length: 1786.0,                last time consumption/overall running time: 3136.47s / 206421.91 s
first_0:                 episode reward: -6.5000,                 loss: 0.0299
Episode: 1361/50000 (2.7220%),                 avg. length: 1786.0,                last time consumption/overall running time: 3086.22s / 209508.12 s
first_0:                 episode reward: -8.3500,                 loss: 0.0292
Episode: 1381/50000 (2.7620%),                 avg. length: 1786.0,                last time consumption/overall running time: 3046.01s / 212554.14 s
first_0:                 episode reward: -8.7000,                 loss: 0.0289
Episode: 1401/50000 (2.8020%),                 avg. length: 1786.0,                last time consumption/overall running time: 3069.72s / 215623.86 s
first_0:                 episode reward: -8.1000,                 loss: 0.0290
Episode: 1421/50000 (2.8420%),                 avg. length: 1786.0,                last time consumption/overall running time: 3040.33s / 218664.18 s
first_0:                 episode reward: -6.9000,                 loss: 0.0299
Episode: 1441/50000 (2.8820%),                 avg. length: 1786.0,                last time consumption/overall running time: 3060.43s / 221724.61 s
first_0:                 episode reward: -6.8500,                 loss: 0.0297
Episode: 1461/50000 (2.9220%),                 avg. length: 1786.0,                last time consumption/overall running time: 3075.14s / 224799.76 s
first_0:                 episode reward: -8.1000,                 loss: 0.0297
Episode: 1481/50000 (2.9620%),                 avg. length: 1786.0,                last time consumption/overall running time: 3064.79s / 227864.55 s
first_0:                 episode reward: -5.0000,                 loss: 0.0298
Episode: 1501/50000 (3.0020%),                 avg. length: 1786.0,                last time consumption/overall running time: 3068.39s / 230932.93 s
first_0:                 episode reward: -7.0500,                 loss: 0.0297
Episode: 1521/50000 (3.0420%),                 avg. length: 1786.0,                last time consumption/overall running time: 3093.67s / 234026.61 s
first_0:                 episode reward: -4.7000,                 loss: 0.0295
Episode: 1541/50000 (3.0820%),                 avg. length: 1786.0,                last time consumption/overall running time: 3060.61s / 237087.22 s
first_0:                 episode reward: -7.9000,                 loss: 0.0299
Episode: 1561/50000 (3.1220%),                 avg. length: 1786.0,                last time consumption/overall running time: 3070.69s / 240157.91 s
first_0:                 episode reward: -7.5500,                 loss: 0.0302
Episode: 1581/50000 (3.1620%),                 avg. length: 1786.0,                last time consumption/overall running time: 3055.81s / 243213.72 s
first_0:                 episode reward: -6.7500,                 loss: 0.0296
Episode: 1601/50000 (3.2020%),                 avg. length: 1786.0,                last time consumption/overall running time: 3094.30s / 246308.02 s
first_0:                 episode reward: -8.6500,                 loss: 0.0297
Episode: 1621/50000 (3.2420%),                 avg. length: 1786.0,                last time consumption/overall running time: 3071.28s / 249379.30 s
first_0:                 episode reward: -9.7000,                 loss: 0.0372
Episode: 1641/50000 (3.2820%),                 avg. length: 1786.0,                last time consumption/overall running time: 3061.55s / 252440.85 s
first_0:                 episode reward: -8.9500,                 loss: 0.0312
Episode: 1661/50000 (3.3220%),                 avg. length: 1786.0,                last time consumption/overall running time: 3059.17s / 255500.02 s
first_0:                 episode reward: -8.8500,                 loss: 0.0305
Episode: 1681/50000 (3.3620%),                 avg. length: 1786.0,                last time consumption/overall running time: 3069.21s / 258569.23 s
first_0:                 episode reward: -5.7500,                 loss: 0.0317
Episode: 1701/50000 (3.4020%),                 avg. length: 1786.0,                last time consumption/overall running time: 3079.76s / 261648.99 s
first_0:                 episode reward: -4.7000,                 loss: 0.0321
Episode: 1721/50000 (3.4420%),                 avg. length: 1786.0,                last time consumption/overall running time: 3064.07s / 264713.06 s
first_0:                 episode reward: -8.6000,                 loss: 0.0322
Episode: 1741/50000 (3.4820%),                 avg. length: 1786.0,                last time consumption/overall running time: 3080.59s / 267793.65 s
first_0:                 episode reward: -8.2000,                 loss: 0.0319
Episode: 1761/50000 (3.5220%),                 avg. length: 1786.0,                last time consumption/overall running time: 3086.41s / 270880.06 s
first_0:                 episode reward: -9.2500,                 loss: 0.0316
Episode: 1781/50000 (3.5620%),                 avg. length: 1786.0,                last time consumption/overall running time: 3070.83s / 273950.89 s
first_0:                 episode reward: -8.5500,                 loss: 0.0315
Episode: 1801/50000 (3.6020%),                 avg. length: 1786.0,                last time consumption/overall running time: 3089.53s / 277040.43 s
first_0:                 episode reward: -6.5000,                 loss: 0.0319
Episode: 1821/50000 (3.6420%),                 avg. length: 1786.0,                last time consumption/overall running time: 3088.00s / 280128.42 s
first_0:                 episode reward: -11.3500,                 loss: 0.0327
Episode: 1841/50000 (3.6820%),                 avg. length: 1786.0,                last time consumption/overall running time: 3082.36s / 283210.78 s
first_0:                 episode reward: -10.8500,                 loss: 0.0332
Episode: 1861/50000 (3.7220%),                 avg. length: 1786.0,                last time consumption/overall running time: 3088.09s / 286298.87 s
first_0:                 episode reward: -6.7000,                 loss: 0.0327
Episode: 1881/50000 (3.7620%),                 avg. length: 1786.0,                last time consumption/overall running time: 3077.67s / 289376.55 s
first_0:                 episode reward: -14.6500,                 loss: 0.0329
Episode: 1901/50000 (3.8020%),                 avg. length: 1786.0,                last time consumption/overall running time: 3082.05s / 292458.60 s
first_0:                 episode reward: -8.8000,                 loss: 0.0326
Episode: 1921/50000 (3.8420%),                 avg. length: 1786.0,                last time consumption/overall running time: 3092.13s / 295550.73 s
first_0:                 episode reward: -8.8000,                 loss: 0.0330
Episode: 1941/50000 (3.8820%),                 avg. length: 1786.0,                last time consumption/overall running time: 3097.13s / 298647.85 s
first_0:                 episode reward: -10.5000,                 loss: 0.0327
Episode: 1961/50000 (3.9220%),                 avg. length: 1786.0,                last time consumption/overall running time: 3069.20s / 301717.05 s
first_0:                 episode reward: -12.8000,                 loss: 0.0325
Episode: 1981/50000 (3.9620%),                 avg. length: 1786.0,                last time consumption/overall running time: 3084.32s / 304801.37 s
first_0:                 episode reward: -10.9000,                 loss: 0.0339
Episode: 2001/50000 (4.0020%),                 avg. length: 1786.0,                last time consumption/overall running time: 3089.88s / 307891.25 swandb: Network error (ReadTimeout), entering retry loop.
wandb: Network error (ReadTimeout), entering retry loop.
wandb: Network error (ReadTimeout), entering retry loop.
wandb: Network error (ReadTimeout), entering retry loop.
wandb: ERROR Error while calling W&B API: internal database error (<Response [500]>)
wandb: ERROR Error while calling W&B API: internal database error (<Response [500]>)
wandb: ERROR Error while calling W&B API: internal database error (<Response [500]>)
wandb: ERROR Error while calling W&B API: internal database error (<Response [500]>)
wandb: Network error (ReadTimeout), entering retry loop.

first_0:                 episode reward: -9.4000,                 loss: 0.0395
Episode: 2021/50000 (4.0420%),                 avg. length: 1786.0,                last time consumption/overall running time: 3079.38s / 310970.63 s
first_0:                 episode reward: -8.5000,                 loss: 0.0355
Episode: 2041/50000 (4.0820%),                 avg. length: 1786.0,                last time consumption/overall running time: 3119.21s / 314089.85 s
first_0:                 episode reward: -9.6500,                 loss: 0.0340
Episode: 2061/50000 (4.1220%),                 avg. length: 1786.0,                last time consumption/overall running time: 3106.16s / 317196.01 s
first_0:                 episode reward: -6.1000,                 loss: 0.0350
Episode: 2081/50000 (4.1620%),                 avg. length: 1786.0,                last time consumption/overall running time: 3122.45s / 320318.46 s
first_0:                 episode reward: -10.4500,                 loss: 0.0346
Episode: 2101/50000 (4.2020%),                 avg. length: 1786.0,                last time consumption/overall running time: 3176.79s / 323495.25 s
first_0:                 episode reward: -9.0000,                 loss: 0.0348
Episode: 2121/50000 (4.2420%),                 avg. length: 1786.0,                last time consumption/overall running time: 3162.82s / 326658.06 s
first_0:                 episode reward: -11.5000,                 loss: 0.0376
Episode: 2141/50000 (4.2820%),                 avg. length: 1786.0,                last time consumption/overall running time: 3189.12s / 329847.19 s
first_0:                 episode reward: -11.8000,                 loss: 0.0407
Episode: 2161/50000 (4.3220%),                 avg. length: 1786.0,                last time consumption/overall running time: 3239.09s / 333086.27 s
first_0:                 episode reward: -18.1000,                 loss: 0.0384
Episode: 2181/50000 (4.3620%),                 avg. length: 1786.0,                last time consumption/overall running time: 3162.15s / 336248.42 s
first_0:                 episode reward: -16.2000,                 loss: 0.0366
Episode: 2201/50000 (4.4020%),                 avg. length: 1786.0,                last time consumption/overall running time: 3184.01s / 339432.43 s
first_0:                 episode reward: -7.9000,                 loss: 0.0342
Episode: 2221/50000 (4.4420%),                 avg. length: 1786.0,                last time consumption/overall running time: 3136.38s / 342568.81 s
first_0:                 episode reward: -11.6000,                 loss: 0.0343
Episode: 2241/50000 (4.4820%),                 avg. length: 1786.0,                last time consumption/overall running time: 3170.72s / 345739.53 s
first_0:                 episode reward: -10.3500,                 loss: 0.0372
Episode: 2261/50000 (4.5220%),                 avg. length: 1786.0,                last time consumption/overall running time: 3208.37s / 348947.90 s
first_0:                 episode reward: -12.7000,                 loss: 0.0370
Episode: 2281/50000 (4.5620%),                 avg. length: 1786.0,                last time consumption/overall running time: 3187.08s / 352134.98 s
first_0:                 episode reward: -16.2500,                 loss: 0.0356
Episode: 2301/50000 (4.6020%),                 avg. length: 1786.0,                last time consumption/overall running time: 3231.22s / 355366.20 s
first_0:                 episode reward: -17.0000,                 loss: 0.0360
Episode: 2321/50000 (4.6420%),                 avg. length: 1786.0,                last time consumption/overall running time: 3262.99s / 358629.19 s
first_0:                 episode reward: -20.2000,                 loss: 0.0379
Episode: 2341/50000 (4.6820%),                 avg. length: 1786.0,                last time consumption/overall running time: 3279.36s / 361908.55 s
first_0:                 episode reward: -15.8000,                 loss: 0.0409
Episode: 2361/50000 (4.7220%),                 avg. length: 1786.0,                last time consumption/overall running time: 3290.58s / 365199.13 s
first_0:                 episode reward: -19.0000,                 loss: 0.0373
Episode: 2381/50000 (4.7620%),                 avg. length: 1786.0,                last time consumption/overall running time: 3273.02s / 368472.15 s
first_0:                 episode reward: -13.9000,                 loss: 0.0398
Episode: 2401/50000 (4.8020%),                 avg. length: 1786.0,                last time consumption/overall running time: 3237.55s / 371709.70 s
first_0:                 episode reward: -12.1000,                 loss: 0.0394
Episode: 2421/50000 (4.8420%),                 avg. length: 1786.0,                last time consumption/overall running time: 3272.71s / 374982.41 s
first_0:                 episode reward: -13.1000,                 loss: 0.0407
Episode: 2441/50000 (4.8820%),                 avg. length: 1786.0,                last time consumption/overall running time: 3197.63s / 378180.04 s
first_0:                 episode reward: -19.3000,                 loss: 0.0407
Episode: 2461/50000 (4.9220%),                 avg. length: 1786.0,                last time consumption/overall running time: 3242.73s / 381422.77 s
first_0:                 episode reward: -14.0000,                 loss: 0.0402
Episode: 2481/50000 (4.9620%),                 avg. length: 1786.0,                last time consumption/overall running time: 3227.65s / 384650.43 s
first_0:                 episode reward: -15.4500,                 loss: 0.0419
Episode: 2501/50000 (5.0020%),                 avg. length: 1786.0,                last time consumption/overall running time: 3278.69s / 387929.12 s
first_0:                 episode reward: -13.4000,                 loss: 0.0435
Episode: 2521/50000 (5.0420%),                 avg. length: 1786.0,                last time consumption/overall running time: 3207.73s / 391136.85 s
first_0:                 episode reward: -21.7000,                 loss: 0.0439
Episode: 2541/50000 (5.0820%),                 avg. length: 1786.0,                last time consumption/overall running time: 3251.88s / 394388.73 s
first_0:                 episode reward: -21.2000,                 loss: 0.0425
Episode: 2561/50000 (5.1220%),                 avg. length: 1786.0,                last time consumption/overall running time: 3273.90s / 397662.63 s
first_0:                 episode reward: -18.9000,                 loss: 0.0440
Episode: 2581/50000 (5.1620%),                 avg. length: 1786.0,                last time consumption/overall running time: 3208.90s / 400871.53 s
first_0:                 episode reward: -14.8500,                 loss: 0.0422
Episode: 2601/50000 (5.2020%),                 avg. length: 1786.0,                last time consumption/overall running time: 3292.83s / 404164.36 s
first_0:                 episode reward: -21.2000,                 loss: 0.0410
Episode: 2621/50000 (5.2420%),                 avg. length: 1786.0,                last time consumption/overall running time: 3213.46s / 407377.82 s
first_0:                 episode reward: -18.3500,                 loss: 0.0421
Episode: 2641/50000 (5.2820%),                 avg. length: 1786.0,                last time consumption/overall running time: 3204.99s / 410582.81 s
first_0:                 episode reward: -23.5500,                 loss: 0.0409
Episode: 2661/50000 (5.3220%),                 avg. length: 1786.0,                last time consumption/overall running time: 3434.19s / 414017.00 s
first_0:                 episode reward: -24.5500,                 loss: 0.0389
Episode: 2681/50000 (5.3620%),                 avg. length: 1786.0,                last time consumption/overall running time: 3274.56s / 417291.55 s
first_0:                 episode reward: -20.2500,                 loss: 0.0389
Episode: 2701/50000 (5.4020%),                 avg. length: 1786.0,                last time consumption/overall running time: 3273.17s / 420564.73 s
first_0:                 episode reward: -17.7000,                 loss: 0.0395
Episode: 2721/50000 (5.4420%),                 avg. length: 1786.0,                last time consumption/overall running time: 3348.06s / 423912.79 s
first_0:                 episode reward: -19.3000,                 loss: 0.0415
Episode: 2741/50000 (5.4820%),                 avg. length: 1786.0,                last time consumption/overall running time: 3274.62s / 427187.41 s
first_0:                 episode reward: -19.9500,                 loss: 0.0428
Episode: 2761/50000 (5.5220%),                 avg. length: 1786.0,                last time consumption/overall running time: 3341.76s / 430529.17 s
first_0:                 episode reward: -12.6500,                 loss: 0.0380
Episode: 2781/50000 (5.5620%),                 avg. length: 1786.0,                last time consumption/overall running time: 3415.12s / 433944.30 s
first_0:                 episode reward: -21.9000,                 loss: 0.0379
Episode: 2801/50000 (5.6020%),                 avg. length: 1786.0,                last time consumption/overall running time: 3295.10s / 437239.40 s
first_0:                 episode reward: -28.0000,                 loss: 0.0449
Episode: 2821/50000 (5.6420%),                 avg. length: 1786.0,                last time consumption/overall running time: 3233.62s / 440473.02 s
first_0:                 episode reward: -22.6000,                 loss: 0.0417
Episode: 2841/50000 (5.6820%),                 avg. length: 1786.0,                last time consumption/overall running time: 3226.82s / 443699.83 s
first_0:                 episode reward: -20.1500,                 loss: 0.0400
Episode: 2861/50000 (5.7220%),                 avg. length: 1786.0,                last time consumption/overall running time: 3392.56s / 447092.39 s
first_0:                 episode reward: -18.7000,                 loss: 0.0382
Episode: 2881/50000 (5.7620%),                 avg. length: 1786.0,                last time consumption/overall running time: 3270.80s / 450363.20 s
first_0:                 episode reward: -29.5500,                 loss: 0.0406
Episode: 2901/50000 (5.8020%),                 avg. length: 1786.0,                last time consumption/overall running time: 3246.42s / 453609.62 s
first_0:                 episode reward: -26.0000,                 loss: 0.0384
Episode: 2921/50000 (5.8420%),                 avg. length: 1786.0,                last time consumption/overall running time: 3323.33s / 456932.95 s
first_0:                 episode reward: -21.0000,                 loss: 0.0380
Episode: 2941/50000 (5.8820%),                 avg. length: 1786.0,                last time consumption/overall running time: 3279.87s / 460212.82 s
first_0:                 episode reward: -17.5500,                 loss: 0.0413
Episode: 2961/50000 (5.9220%),                 avg. length: 1786.0,                last time consumption/overall running time: 3281.69s / 463494.51 s
first_0:                 episode reward: -24.5500,                 loss: 0.0399
Episode: 2981/50000 (5.9620%),                 avg. length: 1786.0,                last time consumption/overall running time: 3275.44s / 466769.95 s
first_0:                 episode reward: -20.4000,                 loss: 0.0426
Episode: 3001/50000 (6.0020%),                 avg. length: 1786.0,                last time consumption/overall running time: 3393.23s / 470163.18 s
first_0:                 episode reward: -22.4500,                 loss: 0.0407
Episode: 3021/50000 (6.0420%),                 avg. length: 1786.0,                last time consumption/overall running time: 3402.59s / 473565.77 s
first_0:                 episode reward: -21.5500,                 loss: 0.0464
Episode: 3041/50000 (6.0820%),                 avg. length: 1786.0,                last time consumption/overall running time: 3286.87s / 476852.64 s
first_0:                 episode reward: -21.4000,                 loss: 0.0469
Episode: 3061/50000 (6.1220%),                 avg. length: 1786.0,                last time consumption/overall running time: 3354.36s / 480207.00 s
first_0:                 episode reward: -17.4500,                 loss: 0.0514
Episode: 3081/50000 (6.1620%),                 avg. length: 1786.0,                last time consumption/overall running time: 3235.33s / 483442.33 s
first_0:                 episode reward: -19.6500,                 loss: 0.0432
Episode: 3101/50000 (6.2020%),                 avg. length: 1786.0,                last time consumption/overall running time: 3519.32s / 486961.65 s
first_0:                 episode reward: -18.6000,                 loss: 0.0409
Episode: 3121/50000 (6.2420%),                 avg. length: 1786.0,                last time consumption/overall running time: 4132.29s / 491093.94 s
first_0:                 episode reward: -17.7000,                 loss: 0.0407
Episode: 3141/50000 (6.2820%),                 avg. length: 1786.0,                last time consumption/overall running time: 3282.30s / 494376.24 s
first_0:                 episode reward: -23.6500,                 loss: 0.0421
Episode: 3161/50000 (6.3220%),                 avg. length: 1786.0,                last time consumption/overall running time: 2943.74s / 497319.98 s
first_0:                 episode reward: -22.1500,                 loss: 0.0410
Episode: 3181/50000 (6.3620%),                 avg. length: 1786.0,                last time consumption/overall running time: 3479.64s / 500799.62 s
first_0:                 episode reward: -21.7500,                 loss: 0.0438
Episode: 3201/50000 (6.4020%),                 avg. length: 1786.0,                last time consumption/overall running time: 4038.64s / 504838.26 s
first_0:                 episode reward: -25.6000,                 loss: 0.0440
Episode: 3221/50000 (6.4420%),                 avg. length: 1779.7,                last time consumption/overall running time: 4032.23s / 508870.49 s
first_0:                 episode reward: -30.9000,                 loss: 0.0442
Episode: 3241/50000 (6.4820%),                 avg. length: 1786.0,                last time consumption/overall running time: 3991.18s / 512861.67 s
first_0:                 episode reward: -23.8000,                 loss: 0.0464
Episode: 3261/50000 (6.5220%),                 avg. length: 1786.0,                last time consumption/overall running time: 3978.11s / 516839.78 s
first_0:                 episode reward: -27.2000,                 loss: 0.0441
Episode: 3281/50000 (6.5620%),                 avg. length: 1786.0,                last time consumption/overall running time: 3467.51s / 520307.29 s
first_0:                 episode reward: -29.8000,                 loss: 0.0421
Episode: 3301/50000 (6.6020%),                 avg. length: 1786.0,                last time consumption/overall running time: 3038.63s / 523345.92 s
first_0:                 episode reward: -20.1500,                 loss: 0.0383
Episode: 3321/50000 (6.6420%),                 avg. length: 1786.0,                last time consumption/overall running time: 3932.65s / 527278.57 s
first_0:                 episode reward: -25.8000,                 loss: 0.0395
Episode: 3341/50000 (6.6820%),                 avg. length: 1786.0,                last time consumption/overall running time: 2957.93s / 530236.50 s
first_0:                 episode reward: -19.6000,                 loss: 0.0394
Episode: 3361/50000 (6.7220%),                 avg. length: 1786.0,                last time consumption/overall running time: 2978.07s / 533214.57 s
first_0:                 episode reward: -19.8000,                 loss: 0.0392
Episode: 3381/50000 (6.7620%),                 avg. length: 1786.0,                last time consumption/overall running time: 2969.46s / 536184.03 s
first_0:                 episode reward: -22.9000,                 loss: 0.0380
Episode: 3401/50000 (6.8020%),                 avg. length: 1786.0,                last time consumption/overall running time: 2922.40s / 539106.43 s
first_0:                 episode reward: -22.1000,                 loss: 0.0395
Episode: 3421/50000 (6.8420%),                 avg. length: 1786.0,                last time consumption/overall running time: 3030.29s / 542136.71 s
first_0:                 episode reward: -21.5500,                 loss: 0.0408
Episode: 3441/50000 (6.8820%),                 avg. length: 1786.0,                last time consumption/overall running time: 2955.39s / 545092.11 swandb: Network error (ReadTimeout), entering retry loop.
wandb: ERROR Error while calling W&B API: internal database error (<Response [500]>)
wandb: ERROR Error while calling W&B API: internal database error (<Response [500]>)

first_0:                 episode reward: -23.0500,                 loss: 0.0444
Episode: 3461/50000 (6.9220%),                 avg. length: 1786.0,                last time consumption/overall running time: 2958.93s / 548051.04 s
first_0:                 episode reward: -25.7000,                 loss: 0.0443
Episode: 3481/50000 (6.9620%),                 avg. length: 1786.0,                last time consumption/overall running time: 2930.78s / 550981.82 s
first_0:                 episode reward: -15.6500,                 loss: 0.0452
Episode: 3501/50000 (7.0020%),                 avg. length: 1786.0,                last time consumption/overall running time: 2963.96s / 553945.77 s
first_0:                 episode reward: -18.3000,                 loss: 0.0404
Episode: 3521/50000 (7.0420%),                 avg. length: 1786.0,                last time consumption/overall running time: 2981.61s / 556927.38 s
first_0:                 episode reward: -23.4500,                 loss: 0.0374
Episode: 3541/50000 (7.0820%),                 avg. length: 1786.0,                last time consumption/overall running time: 2985.56s / 559912.94 s
first_0:                 episode reward: -17.8000,                 loss: 0.0348
Episode: 3561/50000 (7.1220%),                 avg. length: 1786.0,                last time consumption/overall running time: 2947.25s / 562860.19 s
first_0:                 episode reward: -18.9000,                 loss: 0.0384
Episode: 3581/50000 (7.1620%),                 avg. length: 1786.0,                last time consumption/overall running time: 3007.04s / 565867.23 s
first_0:                 episode reward: -27.3500,                 loss: 0.0395
Episode: 3601/50000 (7.2020%),                 avg. length: 1786.0,                last time consumption/overall running time: 2974.64s / 568841.87 s
first_0:                 episode reward: -23.8500,                 loss: 0.0398
Episode: 3621/50000 (7.2420%),                 avg. length: 1786.0,                last time consumption/overall running time: 2998.83s / 571840.70 s
first_0:                 episode reward: -28.1500,                 loss: 0.0424
Episode: 3641/50000 (7.2820%),                 avg. length: 1786.0,                last time consumption/overall running time: 3012.64s / 574853.34 s
first_0:                 episode reward: -19.9000,                 loss: 0.0445
Episode: 3661/50000 (7.3220%),                 avg. length: 1786.0,                last time consumption/overall running time: 2978.76s / 577832.10 s
first_0:                 episode reward: -20.5000,                 loss: 0.0422
Episode: 3681/50000 (7.3620%),                 avg. length: 1786.0,                last time consumption/overall running time: 3209.99s / 581042.09 s
first_0:                 episode reward: -23.2000,                 loss: 0.0368
Episode: 3701/50000 (7.4020%),                 avg. length: 1786.0,                last time consumption/overall running time: 3141.40s / 584183.49 s
first_0:                 episode reward: -23.2000,                 loss: 0.0338
Episode: 3721/50000 (7.4420%),                 avg. length: 1786.0,                last time consumption/overall running time: 3396.80s / 587580.29 s
first_0:                 episode reward: -22.6500,                 loss: 0.0373
Episode: 3741/50000 (7.4820%),                 avg. length: 1786.0,                last time consumption/overall running time: 3019.96s / 590600.25 s
first_0:                 episode reward: -22.4500,                 loss: 0.0398
Episode: 3761/50000 (7.5220%),                 avg. length: 1786.0,                last time consumption/overall running time: 3160.92s / 593761.17 s
first_0:                 episode reward: -24.9000,                 loss: 0.0420
Episode: 3781/50000 (7.5620%),                 avg. length: 1786.0,                last time consumption/overall running time: 3110.36s / 596871.53 s
first_0:                 episode reward: -21.4000,                 loss: 0.0423
Episode: 3801/50000 (7.6020%),                 avg. length: 1786.0,                last time consumption/overall running time: 3429.36s / 600300.89 s
first_0:                 episode reward: -24.9500,                 loss: 0.0415
Episode: 3821/50000 (7.6420%),                 avg. length: 1786.0,                last time consumption/overall running time: 3444.07s / 603744.96 s
first_0:                 episode reward: -21.8000,                 loss: 0.0428
Episode: 3841/50000 (7.6820%),                 avg. length: 1786.0,                last time consumption/overall running time: 3057.47s / 606802.43 s
first_0:                 episode reward: -23.3000,                 loss: 0.0411
Episode: 3861/50000 (7.7220%),                 avg. length: 1786.0,                last time consumption/overall running time: 3026.89s / 609829.31 s
first_0:                 episode reward: -20.1500,                 loss: 0.0409
Episode: 3881/50000 (7.7620%),                 avg. length: 1786.0,                last time consumption/overall running time: 3015.54s / 612844.86 s
first_0:                 episode reward: -17.2000,                 loss: 0.0445
Episode: 3901/50000 (7.8020%),                 avg. length: 1786.0,                last time consumption/overall running time: 2979.08s / 615823.94 s
first_0:                 episode reward: -23.0500,                 loss: 0.0420
Episode: 3921/50000 (7.8420%),                 avg. length: 1786.0,                last time consumption/overall running time: 2935.45s / 618759.39 s
first_0:                 episode reward: -22.4000,                 loss: 0.0425
Episode: 3941/50000 (7.8820%),                 avg. length: 1786.0,                last time consumption/overall running time: 3010.76s / 621770.15 s
first_0:                 episode reward: -32.4500,                 loss: 0.0402
Episode: 3961/50000 (7.9220%),                 avg. length: 1786.0,                last time consumption/overall running time: 3083.78s / 624853.93 s
first_0:                 episode reward: -22.6000,                 loss: 0.0388
Episode: 3981/50000 (7.9620%),                 avg. length: 1786.0,                last time consumption/overall running time: 3305.73s / 628159.67 s
first_0:                 episode reward: -26.0500,                 loss: 0.0369
Episode: 4001/50000 (8.0020%),                 avg. length: 1786.0,                last time consumption/overall running time: 2944.87s / 631104.54 s
first_0:                 episode reward: -28.8000,                 loss: 0.0368
Episode: 4021/50000 (8.0420%),                 avg. length: 1786.0,                last time consumption/overall running time: 2934.78s / 634039.32 s
first_0:                 episode reward: -32.1000,                 loss: 0.0704
Episode: 4041/50000 (8.0820%),                 avg. length: 1786.0,                last time consumption/overall running time: 2947.84s / 636987.16 s
first_0:                 episode reward: -26.0500,                 loss: 0.0403
Episode: 4061/50000 (8.1220%),                 avg. length: 1786.0,                last time consumption/overall running time: 3033.58s / 640020.74 s
first_0:                 episode reward: -23.0000,                 loss: 0.0372
Episode: 4081/50000 (8.1620%),                 avg. length: 1786.0,                last time consumption/overall running time: 3324.38s / 643345.12 s
first_0:                 episode reward: -21.2000,                 loss: 0.0357
Episode: 4101/50000 (8.2020%),                 avg. length: 1786.0,                last time consumption/overall running time: 3077.46s / 646422.58 s
first_0:                 episode reward: -22.0000,                 loss: 0.0353
Episode: 4121/50000 (8.2420%),                 avg. length: 1786.0,                last time consumption/overall running time: 3010.34s / 649432.92 s
first_0:                 episode reward: -19.9000,                 loss: 0.0403
Episode: 4141/50000 (8.2820%),                 avg. length: 1786.0,                last time consumption/overall running time: 3103.95s / 652536.86 s
first_0:                 episode reward: -21.5500,                 loss: 0.0430
Episode: 4161/50000 (8.3220%),                 avg. length: 1786.0,                last time consumption/overall running time: 3035.98s / 655572.85 swandb: Network error (ReadTimeout), entering retry loop.

first_0:                 episode reward: -16.4500,                 loss: 0.0439
Episode: 4181/50000 (8.3620%),                 avg. length: 1786.0,                last time consumption/overall running time: 3075.23s / 658648.08 s
first_0:                 episode reward: -20.5500,                 loss: 0.0397
Episode: 4201/50000 (8.4020%),                 avg. length: 1786.0,                last time consumption/overall running time: 3036.56s / 661684.64 s
first_0:                 episode reward: -26.0000,                 loss: 0.0400
Episode: 4221/50000 (8.4420%),                 avg. length: 1786.0,                last time consumption/overall running time: 2987.81s / 664672.45 s
first_0:                 episode reward: -18.8500,                 loss: 0.0428
Episode: 4241/50000 (8.4820%),                 avg. length: 1786.0,                last time consumption/overall running time: 3033.97s / 667706.42 s
first_0:                 episode reward: -27.2500,                 loss: 0.0430
Episode: 4261/50000 (8.5220%),                 avg. length: 1762.15,                last time consumption/overall running time: 3068.09s / 670774.51 s
first_0:                 episode reward: -63.0500,                 loss: 0.0486
Episode: 4281/50000 (8.5620%),                 avg. length: 1768.1,                last time consumption/overall running time: 3278.52s / 674053.03 s
first_0:                 episode reward: -41.6000,                 loss: 0.0394
Episode: 4301/50000 (8.6020%),                 avg. length: 1786.0,                last time consumption/overall running time: 3080.81s / 677133.84 s
first_0:                 episode reward: -21.4000,                 loss: 0.0426
Episode: 4321/50000 (8.6420%),                 avg. length: 1786.0,                last time consumption/overall running time: 3043.91s / 680177.74 s
first_0:                 episode reward: -16.5500,                 loss: 0.0406
Episode: 4341/50000 (8.6820%),                 avg. length: 1786.0,                last time consumption/overall running time: 3188.63s / 683366.38 s
first_0:                 episode reward: -24.4000,                 loss: 0.0444
Episode: 4361/50000 (8.7220%),                 avg. length: 1786.0,                last time consumption/overall running time: 3136.07s / 686502.44 s
first_0:                 episode reward: -23.2500,                 loss: 0.0445
Episode: 4381/50000 (8.7620%),                 avg. length: 1786.0,                last time consumption/overall running time: 3111.93s / 689614.38 s
first_0:                 episode reward: -23.2500,                 loss: 0.0423
Episode: 4401/50000 (8.8020%),                 avg. length: 1786.0,                last time consumption/overall running time: 3267.58s / 692881.95 s
first_0:                 episode reward: -22.3500,                 loss: 0.0420
Episode: 4421/50000 (8.8420%),                 avg. length: 1786.0,                last time consumption/overall running time: 3359.06s / 696241.02 s
first_0:                 episode reward: -21.7000,                 loss: 0.0504
Episode: 4441/50000 (8.8820%),                 avg. length: 1786.0,                last time consumption/overall running time: 3370.89s / 699611.91 s
first_0:                 episode reward: -19.6500,                 loss: 0.0449
Episode: 4461/50000 (8.9220%),                 avg. length: 1786.0,                last time consumption/overall running time: 3383.82s / 702995.73 s
first_0:                 episode reward: -23.8000,                 loss: 0.0413
Episode: 4481/50000 (8.9620%),                 avg. length: 1786.0,                last time consumption/overall running time: 3389.35s / 706385.08 s
first_0:                 episode reward: -18.4500,                 loss: 0.0414
Episode: 4501/50000 (9.0020%),                 avg. length: 1786.0,                last time consumption/overall running time: 3379.33s / 709764.41 s
first_0:                 episode reward: -18.6500,                 loss: 0.0403
Episode: 4521/50000 (9.0420%),                 avg. length: 1786.0,                last time consumption/overall running time: 3385.61s / 713150.03 s
first_0:                 episode reward: -22.8000,                 loss: 0.0404
Episode: 4541/50000 (9.0820%),                 avg. length: 1786.0,                last time consumption/overall running time: 3384.35s / 716534.38 s
first_0:                 episode reward: -26.9500,                 loss: 0.0422
Episode: 4561/50000 (9.1220%),                 avg. length: 1786.0,                last time consumption/overall running time: 3389.98s / 719924.37 s
first_0:                 episode reward: -27.4000,                 loss: 0.0438
Episode: 4581/50000 (9.1620%),                 avg. length: 1786.0,                last time consumption/overall running time: 3393.27s / 723317.63 s
first_0:                 episode reward: -34.9500,                 loss: 0.0442
Episode: 4601/50000 (9.2020%),                 avg. length: 1786.0,                last time consumption/overall running time: 3391.89s / 726709.53 s
first_0:                 episode reward: -31.4500,                 loss: 0.0399
Episode: 4621/50000 (9.2420%),                 avg. length: 1786.0,                last time consumption/overall running time: 3401.09s / 730110.62 s
first_0:                 episode reward: -23.6000,                 loss: 0.0389
Episode: 4641/50000 (9.2820%),                 avg. length: 1758.85,                last time consumption/overall running time: 3403.12s / 733513.73 s
first_0:                 episode reward: -43.1500,                 loss: 0.0417
Episode: 4661/50000 (9.3220%),                 avg. length: 1786.0,                last time consumption/overall running time: 3509.89s / 737023.62 s
first_0:                 episode reward: -30.0500,                 loss: 0.0433
Episode: 4681/50000 (9.3620%),                 avg. length: 1786.0,                last time consumption/overall running time: 3503.01s / 740526.63 s
first_0:                 episode reward: -27.3500,                 loss: 0.0439
Episode: 4701/50000 (9.4020%),                 avg. length: 1786.0,                last time consumption/overall running time: 3535.29s / 744061.92 s
first_0:                 episode reward: -30.7000,                 loss: 0.0549
Episode: 4721/50000 (9.4420%),                 avg. length: 1786.0,                last time consumption/overall running time: 3532.30s / 747594.21 s
first_0:                 episode reward: -20.8000,                 loss: 0.0457
Episode: 4741/50000 (9.4820%),                 avg. length: 1786.0,                last time consumption/overall running time: 3528.79s / 751123.00 s
first_0:                 episode reward: -16.5000,                 loss: 0.0436
Episode: 4761/50000 (9.5220%),                 avg. length: 1786.0,                last time consumption/overall running time: 3504.00s / 754627.00 s
first_0:                 episode reward: -21.2000,                 loss: 0.0403
Episode: 4781/50000 (9.5620%),                 avg. length: 1786.0,                last time consumption/overall running time: 3478.83s / 758105.83 s
first_0:                 episode reward: -19.6500,                 loss: 0.0396
Episode: 4801/50000 (9.6020%),                 avg. length: 1786.0,                last time consumption/overall running time: 3850.24s / 761956.07 s
first_0:                 episode reward: -19.1500,                 loss: 0.0385
Episode: 4821/50000 (9.6420%),                 avg. length: 1786.0,                last time consumption/overall running time: 3845.08s / 765801.15 s
first_0:                 episode reward: -15.9000,                 loss: 0.0396
Episode: 4841/50000 (9.6820%),                 avg. length: 1786.0,                last time consumption/overall running time: 3848.23s / 769649.38 s
first_0:                 episode reward: -20.1500,                 loss: 0.0394
Episode: 4861/50000 (9.7220%),                 avg. length: 1786.0,                last time consumption/overall running time: 3851.12s / 773500.50 s
first_0:                 episode reward: -26.5000,                 loss: 0.0405
Episode: 4881/50000 (9.7620%),                 avg. length: 1786.0,                last time consumption/overall running time: 3942.91s / 777443.42 s
first_0:                 episode reward: -32.1000,                 loss: 0.0422
Episode: 4901/50000 (9.8020%),                 avg. length: 1786.0,                last time consumption/overall running time: 3935.26s / 781378.68 s
first_0:                 episode reward: -32.8500,                 loss: 0.0435
Episode: 4921/50000 (9.8420%),                 avg. length: 1786.0,                last time consumption/overall running time: 3893.94s / 785272.61 s
first_0:                 episode reward: -33.0500,                 loss: 0.0400
Episode: 4941/50000 (9.8820%),                 avg. length: 1786.0,                last time consumption/overall running time: 3868.97s / 789141.58 s
first_0:                 episode reward: -22.1500,                 loss: 0.0408
Episode: 4961/50000 (9.9220%),                 avg. length: 1786.0,                last time consumption/overall running time: 3869.70s / 793011.28 s
first_0:                 episode reward: -30.0500,                 loss: 0.0422
Episode: 4981/50000 (9.9620%),                 avg. length: 1786.0,                last time consumption/overall running time: 3858.44s / 796869.72 s
first_0:                 episode reward: -27.8000,                 loss: 0.0434
Episode: 5001/50000 (10.0020%),                 avg. length: 1786.0,                last time consumption/overall running time: 3885.28s / 800755.00 s
first_0:                 episode reward: -20.5000,                 loss: 0.0476
Episode: 5021/50000 (10.0420%),                 avg. length: 1786.0,                last time consumption/overall running time: 3861.96s / 804616.96 s
first_0:                 episode reward: -17.2000,                 loss: 0.0480
Episode: 5041/50000 (10.0820%),                 avg. length: 1786.0,                last time consumption/overall running time: 3860.52s / 808477.48 s
first_0:                 episode reward: -16.2000,                 loss: 0.0414
Episode: 5061/50000 (10.1220%),                 avg. length: 1786.0,                last time consumption/overall running time: 3873.38s / 812350.86 s
first_0:                 episode reward: -20.4000,                 loss: 0.0418
Episode: 5081/50000 (10.1620%),                 avg. length: 1786.0,                last time consumption/overall running time: 3865.85s / 816216.71 s
first_0:                 episode reward: -21.0500,                 loss: 0.0401
Episode: 5101/50000 (10.2020%),                 avg. length: 1786.0,                last time consumption/overall running time: 4179.26s / 820395.97 s
first_0:                 episode reward: -23.3000,                 loss: 0.0408
Episode: 5121/50000 (10.2420%),                 avg. length: 1786.0,                last time consumption/overall running time: 4445.88s / 824841.85 s
first_0:                 episode reward: -24.0500,                 loss: 0.0421
Episode: 5141/50000 (10.2820%),                 avg. length: 1786.0,                last time consumption/overall running time: 4439.53s / 829281.38 s
first_0:                 episode reward: -26.7000,                 loss: 0.0438
Episode: 5161/50000 (10.3220%),                 avg. length: 1786.0,                last time consumption/overall running time: 4467.24s / 833748.62 s
first_0:                 episode reward: -23.7500,                 loss: 0.0437
Episode: 5181/50000 (10.3620%),                 avg. length: 1786.0,                last time consumption/overall running time: 4588.54s / 838337.16 s
first_0:                 episode reward: -20.5000,                 loss: 0.0433
Episode: 5201/50000 (10.4020%),                 avg. length: 1786.0,                last time consumption/overall running time: 4562.84s / 842900.00 s
first_0:                 episode reward: -22.4500,                 loss: 0.0468
Episode: 5221/50000 (10.4420%),                 avg. length: 1786.0,                last time consumption/overall running time: 4537.08s / 847437.08 s
first_0:                 episode reward: -35.2500,                 loss: 0.0536
Episode: 5241/50000 (10.4820%),                 avg. length: 1786.0,                last time consumption/overall running time: 4561.43s / 851998.51 s
first_0:                 episode reward: -37.1500,                 loss: 0.0465
Episode: 5261/50000 (10.5220%),                 avg. length: 1786.0,                last time consumption/overall running time: 4558.94s / 856557.45 s
first_0:                 episode reward: -28.6500,                 loss: 0.0443
Episode: 5281/50000 (10.5620%),                 avg. length: 1786.0,                last time consumption/overall running time: 4543.59s / 861101.03 s
first_0:                 episode reward: -21.2500,                 loss: 0.0412
Episode: 5301/50000 (10.6020%),                 avg. length: 1786.0,                last time consumption/overall running time: 4548.51s / 865649.55 s
first_0:                 episode reward: -35.8000,                 loss: 0.0458
Episode: 5321/50000 (10.6420%),                 avg. length: 1786.0,                last time consumption/overall running time: 4517.49s / 870167.03 s
first_0:                 episode reward: -25.0500,                 loss: 0.0397
Episode: 5341/50000 (10.6820%),                 avg. length: 1786.0,                last time consumption/overall running time: 4519.13s / 874686.17 s
first_0:                 episode reward: -22.7500,                 loss: 0.0416
Episode: 5361/50000 (10.7220%),                 avg. length: 1786.0,                last time consumption/overall running time: 4541.82s / 879227.99 s
first_0:                 episode reward: -18.9000,                 loss: 0.0580
Episode: 5381/50000 (10.7620%),                 avg. length: 1786.0,                last time consumption/overall running time: 4530.12s / 883758.11 s
first_0:                 episode reward: -31.3500,                 loss: 0.0454
Episode: 5401/50000 (10.8020%),                 avg. length: 1786.0,                last time consumption/overall running time: 4544.45s / 888302.56 s
first_0:                 episode reward: -27.5500,                 loss: 0.0594
Episode: 5421/50000 (10.8420%),                 avg. length: 1786.0,                last time consumption/overall running time: 4535.43s / 892837.99 s
first_0:                 episode reward: -24.1500,                 loss: 0.0453
Episode: 5441/50000 (10.8820%),                 avg. length: 1786.0,                last time consumption/overall running time: 4532.55s / 897370.55 s
first_0:                 episode reward: -18.9000,                 loss: 0.0470
Episode: 5461/50000 (10.9220%),                 avg. length: 1769.35,                last time consumption/overall running time: 4485.58s / 901856.13 s
first_0:                 episode reward: -52.5500,                 loss: 0.0501
Episode: 5481/50000 (10.9620%),                 avg. length: 1761.05,                last time consumption/overall running time: 4466.59s / 906322.71 s
first_0:                 episode reward: -39.5500,                 loss: 0.0496
Episode: 5501/50000 (11.0020%),                 avg. length: 1786.0,                last time consumption/overall running time: 4531.86s / 910854.58 s
first_0:                 episode reward: -19.8000,                 loss: 0.0506
Episode: 5521/50000 (11.0420%),                 avg. length: 1786.0,                last time consumption/overall running time: 4530.98s / 915385.55 s
first_0:                 episode reward: -27.6500,                 loss: 0.0516
Episode: 5541/50000 (11.0820%),                 avg. length: 1786.0,                last time consumption/overall running time: 4520.75s / 919906.30 s
first_0:                 episode reward: -29.0000,                 loss: 0.0556
Episode: 5561/50000 (11.1220%),                 avg. length: 1786.0,                last time consumption/overall running time: 4532.10s / 924438.40 s
first_0:                 episode reward: -40.3500,                 loss: 0.0568
Episode: 5581/50000 (11.1620%),                 avg. length: 1786.0,                last time consumption/overall running time: 4566.67s / 929005.08 s
first_0:                 episode reward: -23.1000,                 loss: 0.0484
Episode: 5601/50000 (11.2020%),                 avg. length: 1786.0,                last time consumption/overall running time: 4539.43s / 933544.51 s
first_0:                 episode reward: -22.2500,                 loss: 0.0427
Episode: 5621/50000 (11.2420%),                 avg. length: 1786.0,                last time consumption/overall running time: 4534.15s / 938078.66 s
first_0:                 episode reward: -24.4500,                 loss: 0.0474
Episode: 5641/50000 (11.2820%),                 avg. length: 1767.35,                last time consumption/overall running time: 4498.10s / 942576.76 s
first_0:                 episode reward: -34.8000,                 loss: 0.0438
Episode: 5661/50000 (11.3220%),                 avg. length: 1786.0,                last time consumption/overall running time: 4537.16s / 947113.91 s
first_0:                 episode reward: -23.2500,                 loss: 0.0432
Episode: 5681/50000 (11.3620%),                 avg. length: 1786.0,                last time consumption/overall running time: 4531.63s / 951645.55 s
first_0:                 episode reward: -26.7000,                 loss: 0.0433
Episode: 5701/50000 (11.4020%),                 avg. length: 1786.0,                last time consumption/overall running time: 4548.57s / 956194.12 s
first_0:                 episode reward: -30.3000,                 loss: 0.0463
Episode: 5721/50000 (11.4420%),                 avg. length: 1786.0,                last time consumption/overall running time: 4533.36s / 960727.48 s
first_0:                 episode reward: -20.6000,                 loss: 0.0423
Episode: 5741/50000 (11.4820%),                 avg. length: 1786.0,                last time consumption/overall running time: 4536.44s / 965263.91 s
first_0:                 episode reward: -24.9000,                 loss: 0.0434
Episode: 5761/50000 (11.5220%),                 avg. length: 1786.0,                last time consumption/overall running time: 4531.93s / 969795.84 s
first_0:                 episode reward: -24.4500,                 loss: 0.0465
Episode: 5781/50000 (11.5620%),                 avg. length: 1786.0,                last time consumption/overall running time: 4533.17s / 974329.01 s
first_0:                 episode reward: -31.0000,                 loss: 0.0469
Episode: 5801/50000 (11.6020%),                 avg. length: 1786.0,                last time consumption/overall running time: 4544.08s / 978873.09 s
first_0:                 episode reward: -25.2000,                 loss: 0.0489
Episode: 5821/50000 (11.6420%),                 avg. length: 1786.0,                last time consumption/overall running time: 4547.68s / 983420.77 s
first_0:                 episode reward: -30.1500,                 loss: 0.0524
Episode: 5841/50000 (11.6820%),                 avg. length: 1786.0,                last time consumption/overall running time: 4541.86s / 987962.63 s
first_0:                 episode reward: -21.9000,                 loss: 0.0628
Episode: 5861/50000 (11.7220%),                 avg. length: 1786.0,                last time consumption/overall running time: 4539.30s / 992501.94 s
first_0:                 episode reward: -18.9500,                 loss: 0.0471
Episode: 5881/50000 (11.7620%),                 avg. length: 1786.0,                last time consumption/overall running time: 4554.60s / 997056.54 s
first_0:                 episode reward: -19.2500,                 loss: 0.0431
Episode: 5901/50000 (11.8020%),                 avg. length: 1786.0,                last time consumption/overall running time: 4540.33s / 1001596.87 s
first_0:                 episode reward: -20.2000,                 loss: 0.0434
Episode: 5921/50000 (11.8420%),                 avg. length: 1786.0,                last time consumption/overall running time: 4534.31s / 1006131.18 s
first_0:                 episode reward: -25.8000,                 loss: 0.0484
Episode: 5941/50000 (11.8820%),                 avg. length: 1786.0,                last time consumption/overall running time: 4550.44s / 1010681.62 s
first_0:                 episode reward: -22.3500,                 loss: 0.0455
Episode: 5961/50000 (11.9220%),                 avg. length: 1786.0,                last time consumption/overall running time: 4543.30s / 1015224.91 s
first_0:                 episode reward: -45.5000,                 loss: 0.0598
Episode: 5981/50000 (11.9620%),                 avg. length: 1701.65,                last time consumption/overall running time: 4356.63s / 1019581.54 s
first_0:                 episode reward: -57.2500,                 loss: 0.0492
Episode: 6001/50000 (12.0020%),                 avg. length: 1786.0,                last time consumption/overall running time: 4562.41s / 1024143.95 s
first_0:                 episode reward: -26.0000,                 loss: 0.0556
Episode: 6021/50000 (12.0420%),                 avg. length: 1786.0,                last time consumption/overall running time: 4531.23s / 1028675.18 s
first_0:                 episode reward: -27.3500,                 loss: 0.0490
Episode: 6041/50000 (12.0820%),                 avg. length: 1786.0,                last time consumption/overall running time: 4528.30s / 1033203.48 s
first_0:                 episode reward: -23.5500,                 loss: 0.0441
Episode: 6061/50000 (12.1220%),                 avg. length: 1786.0,                last time consumption/overall running time: 4522.39s / 1037725.87 s
first_0:                 episode reward: -27.4000,                 loss: 0.0432
Episode: 6081/50000 (12.1620%),                 avg. length: 1786.0,                last time consumption/overall running time: 4520.19s / 1042246.06 s
first_0:                 episode reward: -16.1000,                 loss: 0.0413
Episode: 6101/50000 (12.2020%),                 avg. length: 1786.0,                last time consumption/overall running time: 4512.79s / 1046758.85 s
first_0:                 episode reward: -15.1500,                 loss: 0.0458
Episode: 6121/50000 (12.2420%),                 avg. length: 1786.0,                last time consumption/overall running time: 4516.84s / 1051275.69 s
first_0:                 episode reward: -42.3000,                 loss: 0.0503
Episode: 6141/50000 (12.2820%),                 avg. length: 1786.0,                last time consumption/overall running time: 4513.99s / 1055789.68 s
first_0:                 episode reward: -25.6500,                 loss: 0.0475
Episode: 6161/50000 (12.3220%),                 avg. length: 1786.0,                last time consumption/overall running time: 4513.78s / 1060303.46 s
first_0:                 episode reward: -25.6000,                 loss: 0.0511
Episode: 6181/50000 (12.3620%),                 avg. length: 1786.0,                last time consumption/overall running time: 4512.55s / 1064816.01 s
first_0:                 episode reward: -27.1000,                 loss: 0.0506
Episode: 6201/50000 (12.4020%),                 avg. length: 1786.0,                last time consumption/overall running time: 4530.63s / 1069346.64 s
first_0:                 episode reward: -38.4500,                 loss: 0.0536
Episode: 6221/50000 (12.4420%),                 avg. length: 1786.0,                last time consumption/overall running time: 4539.22s / 1073885.86 s
first_0:                 episode reward: -28.7500,                 loss: 0.0534
Episode: 6241/50000 (12.4820%),                 avg. length: 1786.0,                last time consumption/overall running time: 4533.94s / 1078419.80 s
first_0:                 episode reward: -19.5000,                 loss: 0.0565
Episode: 6261/50000 (12.5220%),                 avg. length: 1786.0,                last time consumption/overall running time: 4531.48s / 1082951.28 s
first_0:                 episode reward: -31.0000,                 loss: 0.0548
Episode: 6281/50000 (12.5620%),                 avg. length: 1786.0,                last time consumption/overall running time: 4533.10s / 1087484.38 s
first_0:                 episode reward: -27.6000,                 loss: 0.0526
Episode: 6301/50000 (12.6020%),                 avg. length: 1786.0,                last time consumption/overall running time: 4517.68s / 1092002.06 s
first_0:                 episode reward: -22.8500,                 loss: 0.0511
Episode: 6321/50000 (12.6420%),                 avg. length: 1786.0,                last time consumption/overall running time: 4519.28s / 1096521.33 s/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/gym/core.py:58: DeprecationWarning: [33mWARN: You are calling render method, but you didn't specified the argument render_mode at environment initialization. To maintain backward compatibility, the environment will render in human mode.
If you want to render in human mode, initialize the environment in this way: gym.make('EnvName', render_mode='human') and don't call the render method.
See here for more information: https://www.gymlibrary.ml/content/api/[0m
  "You are calling render method, "
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/gym/core.py:52: DeprecationWarning: [33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.
See here for more information: https://www.gymlibrary.ml/content/api/[0m
  "The argument mode in render method is deprecated; "
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/gym/wrappers/monitoring/video_recorder.py:68: DeprecationWarning: [33mWARN: `env.metadata["render.modes"] is marked as deprecated and will be replaced with `env.metadata["render_modes"]` see https://github.com/openai/gym/pull/2654 for more details[0m
  '`env.metadata["render.modes"] is marked as deprecated and will be replaced '
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/gym/wrappers/monitoring/video_recorder.py:79: DeprecationWarning: [33mWARN: Recording ability for environment ALE/Boxing-v5 initialized with `render_mode=None` is marked as deprecated and will be removed in the future.[0m
  f"Recording ability for environment {env.spec.id} initialized with `render_mode=None` is marked "
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/gym/core.py:58: DeprecationWarning: [33mWARN: You are calling render method, but you didn't specified the argument render_mode at environment initialization. To maintain backward compatibility, the environment will render in human mode.
If you want to render in human mode, initialize the environment in this way: gym.make('EnvName', render_mode='human') and don't call the render method.
See here for more information: https://www.gymlibrary.ml/content/api/[0m
  "You are calling render method, "
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/gym/core.py:52: DeprecationWarning: [33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.
See here for more information: https://www.gymlibrary.ml/content/api/[0m
  "The argument mode in render method is deprecated; "
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/gym/wrappers/monitoring/video_recorder.py:68: DeprecationWarning: [33mWARN: `env.metadata["render.modes"] is marked as deprecated and will be replaced with `env.metadata["render_modes"]` see https://github.com/openai/gym/pull/2654 for more details[0m
  '`env.metadata["render.modes"] is marked as deprecated and will be replaced '
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/gym/wrappers/monitoring/video_recorder.py:79: DeprecationWarning: [33mWARN: Recording ability for environment ALE/Boxing-v5 initialized with `render_mode=None` is marked as deprecated and will be removed in the future.[0m
  f"Recording ability for environment {env.spec.id} initialized with `render_mode=None` is marked "
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/gym/core.py:58: DeprecationWarning: [33mWARN: You are calling render method, but you didn't specified the argument render_mode at environment initialization. To maintain backward compatibility, the environment will render in human mode.
If you want to render in human mode, initialize the environment in this way: gym.make('EnvName', render_mode='human') and don't call the render method.
See here for more information: https://www.gymlibrary.ml/content/api/[0m
  "You are calling render method, "
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/gym/core.py:52: DeprecationWarning: [33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.
See here for more information: https://www.gymlibrary.ml/content/api/[0m
  "The argument mode in render method is deprecated; "
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/gym/wrappers/monitoring/video_recorder.py:68: DeprecationWarning: [33mWARN: `env.metadata["render.modes"] is marked as deprecated and will be replaced with `env.metadata["render_modes"]` see https://github.com/openai/gym/pull/2654 for more details[0m
  '`env.metadata["render.modes"] is marked as deprecated and will be replaced '
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/gym/wrappers/monitoring/video_recorder.py:79: DeprecationWarning: [33mWARN: Recording ability for environment ALE/Boxing-v5 initialized with `render_mode=None` is marked as deprecated and will be removed in the future.[0m
  f"Recording ability for environment {env.spec.id} initialized with `render_mode=None` is marked "
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/gym/core.py:58: DeprecationWarning: [33mWARN: You are calling render method, but you didn't specified the argument render_mode at environment initialization. To maintain backward compatibility, the environment will render in human mode.
If you want to render in human mode, initialize the environment in this way: gym.make('EnvName', render_mode='human') and don't call the render method.
See here for more information: https://www.gymlibrary.ml/content/api/[0m
  "You are calling render method, "
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/gym/core.py:52: DeprecationWarning: [33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.
See here for more information: https://www.gymlibrary.ml/content/api/[0m
  "The argument mode in render method is deprecated; "
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/gym/wrappers/monitoring/video_recorder.py:68: DeprecationWarning: [33mWARN: `env.metadata["render.modes"] is marked as deprecated and will be replaced with `env.metadata["render_modes"]` see https://github.com/openai/gym/pull/2654 for more details[0m
  '`env.metadata["render.modes"] is marked as deprecated and will be replaced '
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/gym/wrappers/monitoring/video_recorder.py:79: DeprecationWarning: [33mWARN: Recording ability for environment ALE/Boxing-v5 initialized with `render_mode=None` is marked as deprecated and will be removed in the future.[0m
  f"Recording ability for environment {env.spec.id} initialized with `render_mode=None` is marked "
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/gym/core.py:58: DeprecationWarning: [33mWARN: You are calling render method, but you didn't specified the argument render_mode at environment initialization. To maintain backward compatibility, the environment will render in human mode.
If you want to render in human mode, initialize the environment in this way: gym.make('EnvName', render_mode='human') and don't call the render method.
See here for more information: https://www.gymlibrary.ml/content/api/[0m
  "You are calling render method, "
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/gym/core.py:52: DeprecationWarning: [33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.
See here for more information: https://www.gymlibrary.ml/content/api/[0m
  "The argument mode in render method is deprecated; "
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/gym/wrappers/monitoring/video_recorder.py:68: DeprecationWarning: [33mWARN: `env.metadata["render.modes"] is marked as deprecated and will be replaced with `env.metadata["render_modes"]` see https://github.com/openai/gym/pull/2654 for more details[0m
  '`env.metadata["render.modes"] is marked as deprecated and will be replaced '
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/gym/wrappers/monitoring/video_recorder.py:79: DeprecationWarning: [33mWARN: Recording ability for environment ALE/Boxing-v5 initialized with `render_mode=None` is marked as deprecated and will be removed in the future.[0m
  f"Recording ability for environment {env.spec.id} initialized with `render_mode=None` is marked "

first_0:                 episode reward: -31.1000,                 loss: 0.0515
Episode: 6341/50000 (12.6820%),                 avg. length: 1786.0,                last time consumption/overall running time: 4524.77s / 1101046.11 s
first_0:                 episode reward: -21.2000,                 loss: 0.0538
Episode: 6361/50000 (12.7220%),                 avg. length: 1786.0,                last time consumption/overall running time: 4518.60s / 1105564.70 s
first_0:                 episode reward: -23.2500,                 loss: 0.0495
Episode: 6381/50000 (12.7620%),                 avg. length: 1786.0,                last time consumption/overall running time: 4532.65s / 1110097.35 s
first_0:                 episode reward: -16.7000,                 loss: 0.0465
Episode: 6401/50000 (12.8020%),                 avg. length: 1786.0,                last time consumption/overall running time: 4539.66s / 1114637.01 s
first_0:                 episode reward: -15.3000,                 loss: 0.0494
Episode: 6421/50000 (12.8420%),                 avg. length: 1786.0,                last time consumption/overall running time: 4512.04s / 1119149.06 s
first_0:                 episode reward: -19.0000,                 loss: 0.0514
Episode: 6441/50000 (12.8820%),                 avg. length: 1786.0,                last time consumption/overall running time: 4515.41s / 1123664.46 s
first_0:                 episode reward: -19.2000,                 loss: 0.0461
Episode: 6461/50000 (12.9220%),                 avg. length: 1786.0,                last time consumption/overall running time: 4518.57s / 1128183.04 s
first_0:                 episode reward: -28.4500,                 loss: 0.0463
Episode: 6481/50000 (12.9620%),                 avg. length: 1786.0,                last time consumption/overall running time: 4523.09s / 1132706.13 s
first_0:                 episode reward: -33.5500,                 loss: 0.0511
Episode: 6501/50000 (13.0020%),                 avg. length: 1786.0,                last time consumption/overall running time: 4531.81s / 1137237.93 s
first_0:                 episode reward: -32.8000,                 loss: 0.0474
Episode: 6521/50000 (13.0420%),                 avg. length: 1786.0,                last time consumption/overall running time: 4529.33s / 1141767.27 s
first_0:                 episode reward: -31.1000,                 loss: 0.0461
Episode: 6541/50000 (13.0820%),                 avg. length: 1768.65,                last time consumption/overall running time: 4490.61s / 1146257.88 s
first_0:                 episode reward: -35.5000,                 loss: 0.0611
Episode: 6561/50000 (13.1220%),                 avg. length: 1786.0,                last time consumption/overall running time: 4515.53s / 1150773.41 s
first_0:                 episode reward: -20.5500,                 loss: 0.0562
Episode: 6581/50000 (13.1620%),                 avg. length: 1786.0,                last time consumption/overall running time: 4526.88s / 1155300.28 s
first_0:                 episode reward: -20.3500,                 loss: 0.0548
Episode: 6601/50000 (13.2020%),                 avg. length: 1786.0,                last time consumption/overall running time: 4509.77s / 1159810.05 s
first_0:                 episode reward: -25.1500,                 loss: 0.0512
Episode: 6621/50000 (13.2420%),                 avg. length: 1786.0,                last time consumption/overall running time: 4517.03s / 1164327.08 s
first_0:                 episode reward: -36.1500,                 loss: 0.0596
Episode: 6641/50000 (13.2820%),                 avg. length: 1699.35,                last time consumption/overall running time: 4322.86s / 1168649.93 s
first_0:                 episode reward: -52.9000,                 loss: 0.0599
Episode: 6661/50000 (13.3220%),                 avg. length: 1786.0,                last time consumption/overall running time: 4537.95s / 1173187.88 s
first_0:                 episode reward: -19.8500,                 loss: 0.0561
Episode: 6681/50000 (13.3620%),                 avg. length: 1786.0,                last time consumption/overall running time: 4538.96s / 1177726.84 s
first_0:                 episode reward: -20.4000,                 loss: 0.0494
Episode: 6701/50000 (13.4020%),                 avg. length: 1786.0,                last time consumption/overall running time: 4523.95s / 1182250.79 s
first_0:                 episode reward: -14.9500,                 loss: 0.0501
Episode: 6721/50000 (13.4420%),                 avg. length: 1786.0,                last time consumption/overall running time: 4524.40s / 1186775.19 s
first_0:                 episode reward: -30.2000,                 loss: 0.0467
Episode: 6741/50000 (13.4820%),                 avg. length: 1786.0,                last time consumption/overall running time: 4514.79s / 1191289.98 s
first_0:                 episode reward: -24.9500,                 loss: 0.0497
Episode: 6761/50000 (13.5220%),                 avg. length: 1786.0,                last time consumption/overall running time: 4512.50s / 1195802.49 s
first_0:                 episode reward: -26.9000,                 loss: 0.0544
Episode: 6781/50000 (13.5620%),                 avg. length: 1786.0,                last time consumption/overall running time: 4517.92s / 1200320.40 s
first_0:                 episode reward: -23.5500,                 loss: 0.0599
Episode: 6801/50000 (13.6020%),                 avg. length: 1786.0,                last time consumption/overall running time: 4487.42s / 1204807.82 s
first_0:                 episode reward: -15.7500,                 loss: 0.0566
Episode: 6821/50000 (13.6420%),                 avg. length: 1786.0,                last time consumption/overall running time: 4498.18s / 1209306.00 s
first_0:                 episode reward: -19.7500,                 loss: 0.0629
Episode: 6841/50000 (13.6820%),                 avg. length: 1786.0,                last time consumption/overall running time: 4459.37s / 1213765.37 s
first_0:                 episode reward: -26.9500,                 loss: 0.0475
Episode: 6861/50000 (13.7220%),                 avg. length: 1786.0,                last time consumption/overall running time: 4468.91s / 1218234.28 s
first_0:                 episode reward: -22.2500,                 loss: 0.0511
Episode: 6881/50000 (13.7620%),                 avg. length: 1786.0,                last time consumption/overall running time: 4534.26s / 1222768.54 s
first_0:                 episode reward: -35.6000,                 loss: 0.0610
Episode: 6901/50000 (13.8020%),                 avg. length: 1734.8,                last time consumption/overall running time: 4405.93s / 1227174.47 s
first_0:                 episode reward: -47.2500,                 loss: 0.0542
Episode: 6921/50000 (13.8420%),                 avg. length: 1786.0,                last time consumption/overall running time: 4527.28s / 1231701.75 s
first_0:                 episode reward: -22.4000,                 loss: 0.0529
Episode: 6941/50000 (13.8820%),                 avg. length: 1786.0,                last time consumption/overall running time: 4546.65s / 1236248.39 s
first_0:                 episode reward: -30.6500,                 loss: 0.0554
Episode: 6961/50000 (13.9220%),                 avg. length: 1786.0,                last time consumption/overall running time: 4535.16s / 1240783.55 s
first_0:                 episode reward: -22.3000,                 loss: 0.0538
Episode: 6981/50000 (13.9620%),                 avg. length: 1786.0,                last time consumption/overall running time: 4544.83s / 1245328.38 s
first_0:                 episode reward: -16.6000,                 loss: 0.0561
Episode: 7001/50000 (14.0020%),                 avg. length: 1786.0,                last time consumption/overall running time: 4547.86s / 1249876.24 s
first_0:                 episode reward: -30.7000,                 loss: 0.0654
Episode: 7021/50000 (14.0420%),                 avg. length: 1786.0,                last time consumption/overall running time: 4537.31s / 1254413.56 s
first_0:                 episode reward: -40.0500,                 loss: 0.0531
Episode: 7041/50000 (14.0820%),                 avg. length: 1786.0,                last time consumption/overall running time: 4533.89s / 1258947.45 s
first_0:                 episode reward: -31.8000,                 loss: 0.0503
Episode: 7061/50000 (14.1220%),                 avg. length: 1786.0,                last time consumption/overall running time: 4551.33s / 1263498.78 s
first_0:                 episode reward: -28.7000,                 loss: 0.0508
Episode: 7081/50000 (14.1620%),                 avg. length: 1786.0,                last time consumption/overall running time: 4534.40s / 1268033.18 s
first_0:                 episode reward: -29.7000,                 loss: 0.0537
Episode: 7101/50000 (14.2020%),                 avg. length: 1786.0,                last time consumption/overall running time: 4780.00s / 1272813.18 s
first_0:                 episode reward: -25.8000,                 loss: 0.0503
Episode: 7121/50000 (14.2420%),                 avg. length: 1786.0,                last time consumption/overall running time: 4801.66s / 1277614.84 s
first_0:                 episode reward: -26.8500,                 loss: 0.0532
Episode: 7141/50000 (14.2820%),                 avg. length: 1786.0,                last time consumption/overall running time: 4797.04s / 1282411.88 s
first_0:                 episode reward: -23.0000,                 loss: 0.0542
Episode: 7161/50000 (14.3220%),                 avg. length: 1786.0,                last time consumption/overall running time: 4803.72s / 1287215.60 s
first_0:                 episode reward: -33.2000,                 loss: 0.0537
Episode: 7181/50000 (14.3620%),                 avg. length: 1786.0,                last time consumption/overall running time: 4808.37s / 1292023.97 s
first_0:                 episode reward: -24.7500,                 loss: 0.0602
Episode: 7201/50000 (14.4020%),                 avg. length: 1786.0,                last time consumption/overall running time: 4829.88s / 1296853.85 s
first_0:                 episode reward: -18.0000,                 loss: 0.0584
Episode: 7221/50000 (14.4420%),                 avg. length: 1786.0,                last time consumption/overall running time: 4809.05s / 1301662.90 s
first_0:                 episode reward: -23.7500,                 loss: 0.0613
Episode: 7241/50000 (14.4820%),                 avg. length: 1786.0,                last time consumption/overall running time: 4807.11s / 1306470.02 s
first_0:                 episode reward: -29.0000,                 loss: 0.0570
Episode: 7261/50000 (14.5220%),                 avg. length: 1786.0,                last time consumption/overall running time: 4834.99s / 1311305.01 s
first_0:                 episode reward: -20.4000,                 loss: 0.0512
Episode: 7281/50000 (14.5620%),                 avg. length: 1786.0,                last time consumption/overall running time: 4829.34s / 1316134.35 s
first_0:                 episode reward: -31.4000,                 loss: 0.0533
Episode: 7301/50000 (14.6020%),                 avg. length: 1786.0,                last time consumption/overall running time: 4812.60s / 1320946.94 s
first_0:                 episode reward: -27.5500,                 loss: 0.0567
Episode: 7321/50000 (14.6420%),                 avg. length: 1786.0,                last time consumption/overall running time: 4818.82s / 1325765.77 s
first_0:                 episode reward: -22.9500,                 loss: 0.0589
Episode: 7341/50000 (14.6820%),                 avg. length: 1753.8,                last time consumption/overall running time: 4750.88s / 1330516.64 s
first_0:                 episode reward: -27.6500,                 loss: 0.0637
Episode: 7361/50000 (14.7220%),                 avg. length: 1786.0,                last time consumption/overall running time: 4829.31s / 1335345.95 s
first_0:                 episode reward: -25.3000,                 loss: 0.0624
Episode: 7381/50000 (14.7620%),                 avg. length: 1786.0,                last time consumption/overall running time: 4807.69s / 1340153.64 s
first_0:                 episode reward: -24.3000,                 loss: 0.0665
Episode: 7401/50000 (14.8020%),                 avg. length: 1786.0,                last time consumption/overall running time: 4818.71s / 1344972.35 s
first_0:                 episode reward: -20.8500,                 loss: 0.0677
Episode: 7421/50000 (14.8420%),                 avg. length: 1786.0,                last time consumption/overall running time: 4812.22s / 1349784.57 s
first_0:                 episode reward: -24.4500,                 loss: 0.0593
Episode: 7441/50000 (14.8820%),                 avg. length: 1786.0,                last time consumption/overall running time: 4807.98s / 1354592.55 s
first_0:                 episode reward: -30.3000,                 loss: 0.0515
Episode: 7461/50000 (14.9220%),                 avg. length: 1786.0,                last time consumption/overall running time: 4816.54s / 1359409.10 s
first_0:                 episode reward: -28.8500,                 loss: 0.0527
Episode: 7481/50000 (14.9620%),                 avg. length: 1786.0,                last time consumption/overall running time: 4804.39s / 1364213.49 s
first_0:                 episode reward: -24.7500,                 loss: 0.0623
Episode: 7501/50000 (15.0020%),                 avg. length: 1786.0,                last time consumption/overall running time: 4802.88s / 1369016.37 s
first_0:                 episode reward: -24.0500,                 loss: 0.0671
Episode: 7521/50000 (15.0420%),                 avg. length: 1786.0,                last time consumption/overall running time: 4807.57s / 1373823.94 s
first_0:                 episode reward: -34.6500,                 loss: 0.0635
Episode: 7541/50000 (15.0820%),                 avg. length: 1786.0,                last time consumption/overall running time: 4805.65s / 1378629.60 s
first_0:                 episode reward: -25.7000,                 loss: 0.0607
Episode: 7561/50000 (15.1220%),                 avg. length: 1786.0,                last time consumption/overall running time: 4954.64s / 1383584.24 s
first_0:                 episode reward: -38.4000,                 loss: 0.0701
Episode: 7581/50000 (15.1620%),                 avg. length: 1786.0,                last time consumption/overall running time: 5980.81s / 1389565.04 s
first_0:                 episode reward: -28.8500,                 loss: 0.0776
Episode: 7601/50000 (15.2020%),                 avg. length: 1786.0,                last time consumption/overall running time: 5965.29s / 1395530.34 s
first_0:                 episode reward: -36.2000,                 loss: 0.0793
Episode: 7621/50000 (15.2420%),                 avg. length: 1786.0,                last time consumption/overall running time: 5968.12s / 1401498.46 s
first_0:                 episode reward: -26.0000,                 loss: 0.0816
Episode: 7641/50000 (15.2820%),                 avg. length: 1786.0,                last time consumption/overall running time: 5985.78s / 1407484.24 s
first_0:                 episode reward: -36.3000,                 loss: 0.0806
Episode: 7661/50000 (15.3220%),                 avg. length: 1786.0,                last time consumption/overall running time: 5990.67s / 1413474.91 s
first_0:                 episode reward: -24.5000,                 loss: 0.0833
Episode: 7681/50000 (15.3620%),                 avg. length: 1786.0,                last time consumption/overall running time: 5974.36s / 1419449.26 s
first_0:                 episode reward: -19.8000,                 loss: 0.0787
Episode: 7701/50000 (15.4020%),                 avg. length: 1786.0,                last time consumption/overall running time: 5963.77s / 1425413.03 s
first_0:                 episode reward: -32.5000,                 loss: 0.0710
Episode: 7721/50000 (15.4420%),                 avg. length: 1786.0,                last time consumption/overall running time: 5924.61s / 1431337.64 s
first_0:                 episode reward: -25.6000,                 loss: 0.0710
Episode: 7741/50000 (15.4820%),                 avg. length: 1786.0,                last time consumption/overall running time: 6023.38s / 1437361.03 s