2022-05-11 14:10:43.312385: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia:/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia
2022-05-11 14:10:43.312454: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia:/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia
2022-05-11 14:10:43.312461: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
pygame 2.0.1 (SDL 2.0.14, Python 3.6.13)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 12.0, (1,), float32) action space: Discrete(3)
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7f551a888f60>
3 3 3
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
Error: no exploited model index given!
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  data/model/20220511131205/mdp_arbitrary_mdp_selfplay2/40000_0
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': 1, 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 1.0, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 8000}, 'num_process': 1, 'batch_size': 640, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220511131205/mdp_arbitrary_mdp_selfplay2/40000_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 1000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'selfplay2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'selfplay_score_delta': 1.5, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'against_baseline': False}
Save models to : /home/quantumiracle/research/MARS/data/model/20220511131205_exploit_40000/mdp_arbitrary_mdp_selfplay2. 
 Save logs to: /home/quantumiracle/research/MARS/data/log/20220511131205_exploit_40000/mdp_arbitrary_mdp_selfplay2.
Episode: 1/30000 (0.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8182s / 0.8182 s
agent0:                 episode reward: 0.4220,                 loss: nan
agent1:                 episode reward: -0.4220,                 loss: nan
Episode: 21/30000 (0.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0229s / 0.8411 s
agent0:                 episode reward: 0.0489,                 loss: nan
agent1:                 episode reward: -0.0489,                 loss: nan
Episode: 41/30000 (0.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0230s / 0.8641 s
agent0:                 episode reward: 0.7125,                 loss: nan
agent1:                 episode reward: -0.7125,                 loss: nan
Episode: 61/30000 (0.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0227s / 0.8868 s
agent0:                 episode reward: 0.1120,                 loss: nan
agent1:                 episode reward: -0.1120,                 loss: nan
Episode: 81/30000 (0.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0232s / 0.9100 s
agent0:                 episode reward: 0.3300,                 loss: nan
agent1:                 episode reward: -0.3300,                 loss: nan
Episode: 101/30000 (0.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0235s / 0.9334 s
agent0:                 episode reward: 0.5786,                 loss: nan
agent1:                 episode reward: -0.5786,                 loss: nan
Episode: 121/30000 (0.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0238s / 0.9573 s
agent0:                 episode reward: 0.5272,                 loss: nan
agent1:                 episode reward: -0.5272,                 loss: nan
Episode: 141/30000 (0.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0233s / 0.9806 s
agent0:                 episode reward: 0.2652,                 loss: nan
agent1:                 episode reward: -0.2652,                 loss: nan
Episode: 161/30000 (0.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0234s / 1.0040 s
agent0:                 episode reward: 0.0917,                 loss: nan
agent1:                 episode reward: -0.0917,                 loss: nan
Episode: 181/30000 (0.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0234s / 1.0274 s
agent0:                 episode reward: -0.1389,                 loss: nan
agent1:                 episode reward: 0.1389,                 loss: nan
Episode: 201/30000 (0.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0310s / 1.0584 s
agent0:                 episode reward: 0.2586,                 loss: nan
agent1:                 episode reward: -0.2586,                 loss: nan
Episode: 221/30000 (0.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1064s / 1.1648 s
agent0:                 episode reward: 0.5949,                 loss: nan
agent1:                 episode reward: -0.5949,                 loss: 0.4602
Episode: 241/30000 (0.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2195s / 1.3843 s
agent0:                 episode reward: 0.4044,                 loss: nan
agent1:                 episode reward: -0.4044,                 loss: 0.4150
Episode: 261/30000 (0.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2247s / 1.6090 s
agent0:                 episode reward: 0.1779,                 loss: nan
agent1:                 episode reward: -0.1779,                 loss: 0.3990
Episode: 281/30000 (0.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2203s / 1.8293 s
agent0:                 episode reward: -0.2822,                 loss: nan
agent1:                 episode reward: 0.2822,                 loss: 0.3822
Episode: 301/30000 (1.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2385s / 2.0678 s
agent0:                 episode reward: 0.0721,                 loss: nan
agent1:                 episode reward: -0.0721,                 loss: 0.3640
Episode: 321/30000 (1.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2207s / 2.2885 s
agent0:                 episode reward: 0.1351,                 loss: nan
agent1:                 episode reward: -0.1351,                 loss: 0.3538
Episode: 341/30000 (1.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2212s / 2.5097 s
agent0:                 episode reward: 0.1723,                 loss: nan
agent1:                 episode reward: -0.1723,                 loss: 0.3455
Episode: 361/30000 (1.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2197s / 2.7294 s
agent0:                 episode reward: 0.0070,                 loss: nan
agent1:                 episode reward: -0.0070,                 loss: 0.3339
Episode: 381/30000 (1.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2197s / 2.9490 s
agent0:                 episode reward: 0.0154,                 loss: nan
agent1:                 episode reward: -0.0154,                 loss: 0.3185
Episode: 401/30000 (1.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2173s / 3.1663 s
agent0:                 episode reward: 0.1848,                 loss: nan
agent1:                 episode reward: -0.1848,                 loss: 0.3115
Episode: 421/30000 (1.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2218s / 3.3881 s
agent0:                 episode reward: -0.0623,                 loss: nan
agent1:                 episode reward: 0.0623,                 loss: 0.3069
Episode: 441/30000 (1.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2187s / 3.6067 s
agent0:                 episode reward: 0.2221,                 loss: nan
agent1:                 episode reward: -0.2221,                 loss: 0.3045
Episode: 461/30000 (1.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2377s / 3.8445 s
agent0:                 episode reward: -0.1899,                 loss: nan
agent1:                 episode reward: 0.1899,                 loss: 0.2986
Episode: 481/30000 (1.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2651s / 4.1095 s
agent0:                 episode reward: 0.4007,                 loss: nan
agent1:                 episode reward: -0.4007,                 loss: 0.2973
Episode: 501/30000 (1.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2287s / 4.3382 s
agent0:                 episode reward: -0.3146,                 loss: nan
agent1:                 episode reward: 0.3146,                 loss: 0.2936
Episode: 521/30000 (1.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2252s / 4.5635 s
agent0:                 episode reward: -0.1634,                 loss: nan
agent1:                 episode reward: 0.1634,                 loss: 0.2927
Episode: 541/30000 (1.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2327s / 4.7961 s
agent0:                 episode reward: -0.3138,                 loss: nan
agent1:                 episode reward: 0.3138,                 loss: 0.2885
Episode: 561/30000 (1.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2277s / 5.0239 s
agent0:                 episode reward: 0.1124,                 loss: nan
agent1:                 episode reward: -0.1124,                 loss: 0.3169
Episode: 581/30000 (1.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2277s / 5.2516 s
agent0:                 episode reward: 0.1052,                 loss: nan
agent1:                 episode reward: -0.1052,                 loss: 0.2678
Episode: 601/30000 (2.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2248s / 5.4764 s
agent0:                 episode reward: 0.1792,                 loss: nan
agent1:                 episode reward: -0.1792,                 loss: 0.2594
Episode: 621/30000 (2.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2475s / 5.7239 s
agent0:                 episode reward: 0.0248,                 loss: nan
agent1:                 episode reward: -0.0248,                 loss: 0.2540
Episode: 641/30000 (2.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2261s / 5.9500 s
agent0:                 episode reward: 0.5152,                 loss: nan
agent1:                 episode reward: -0.5152,                 loss: 0.2518
Episode: 661/30000 (2.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2224s / 6.1724 s
agent0:                 episode reward: -0.0928,                 loss: nan
agent1:                 episode reward: 0.0928,                 loss: 0.2462
Episode: 681/30000 (2.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2285s / 6.4008 s
agent0:                 episode reward: -0.1223,                 loss: nan
agent1:                 episode reward: 0.1223,                 loss: 0.2456
Episode: 701/30000 (2.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2357s / 6.6365 s
agent0:                 episode reward: 0.0013,                 loss: nan
agent1:                 episode reward: -0.0013,                 loss: 0.2385
Episode: 721/30000 (2.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2272s / 6.8637 s
agent0:                 episode reward: -0.0715,                 loss: nan
agent1:                 episode reward: 0.0715,                 loss: 0.2379
Episode: 741/30000 (2.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2243s / 7.0880 s
agent0:                 episode reward: -0.1862,                 loss: nan
agent1:                 episode reward: 0.1862,                 loss: 0.2342
Episode: 761/30000 (2.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2296s / 7.3176 s
agent0:                 episode reward: -0.2519,                 loss: nan
agent1:                 episode reward: 0.2519,                 loss: 0.2309
Episode: 781/30000 (2.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2547s / 7.5723 s
agent0:                 episode reward: 0.3639,                 loss: nan
agent1:                 episode reward: -0.3639,                 loss: 0.2311
Episode: 801/30000 (2.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2539s / 7.8262 s
agent0:                 episode reward: -0.2874,                 loss: nan
agent1:                 episode reward: 0.2874,                 loss: 0.2249
Episode: 821/30000 (2.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2302s / 8.0564 s
agent0:                 episode reward: -0.0151,                 loss: nan
agent1:                 episode reward: 0.0151,                 loss: 0.2289
Episode: 841/30000 (2.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2370s / 8.2934 s
agent0:                 episode reward: -0.3501,                 loss: nan
agent1:                 episode reward: 0.3501,                 loss: 0.2254
Episode: 861/30000 (2.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2487s / 8.5420 s
agent0:                 episode reward: 0.1737,                 loss: nan
agent1:                 episode reward: -0.1737,                 loss: 0.2245
Episode: 881/30000 (2.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2365s / 8.7786 s
agent0:                 episode reward: -0.3012,                 loss: nan
agent1:                 episode reward: 0.3012,                 loss: 0.2341
Episode: 901/30000 (3.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2373s / 9.0159 s
agent0:                 episode reward: 0.1451,                 loss: nan
agent1:                 episode reward: -0.1451,                 loss: 0.3610
Episode: 921/30000 (3.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2356s / 9.2515 s
agent0:                 episode reward: 0.0273,                 loss: nan
agent1:                 episode reward: -0.0273,                 loss: 0.3372
Episode: 941/30000 (3.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2317s / 9.4832 s
agent0:                 episode reward: -0.2317,                 loss: nan
agent1:                 episode reward: 0.2317,                 loss: 0.3326
Episode: 961/30000 (3.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2348s / 9.7180 s
agent0:                 episode reward: 0.3179,                 loss: nan
agent1:                 episode reward: -0.3179,                 loss: 0.3302
Episode: 981/30000 (3.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2366s / 9.9545 s
agent0:                 episode reward: -0.1514,                 loss: nan
agent1:                 episode reward: 0.1514,                 loss: 0.3239
Episode: 1001/30000 (3.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2378s / 10.1923 s
agent0:                 episode reward: -0.0978,                 loss: nan
agent1:                 episode reward: 0.0978,                 loss: 0.3226
Episode: 1021/30000 (3.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2369s / 10.4292 s
agent0:                 episode reward: -0.2005,                 loss: nan
agent1:                 episode reward: 0.2005,                 loss: 0.3188
Episode: 1041/30000 (3.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2465s / 10.6757 s
agent0:                 episode reward: -0.2970,                 loss: nan
agent1:                 episode reward: 0.2970,                 loss: 0.3173
Episode: 1061/30000 (3.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2385s / 10.9142 s
agent0:                 episode reward: 0.0795,                 loss: nan
agent1:                 episode reward: -0.0795,                 loss: 0.3137
Episode: 1081/30000 (3.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2378s / 11.1519 s
agent0:                 episode reward: -0.3095,                 loss: nan
agent1:                 episode reward: 0.3095,                 loss: 0.3143
Episode: 1101/30000 (3.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2409s / 11.3929 s
agent0:                 episode reward: -0.3123,                 loss: nan
agent1:                 episode reward: 0.3123,                 loss: 0.3118
Episode: 1121/30000 (3.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2359s / 11.6288 s
agent0:                 episode reward: -0.1347,                 loss: nan
agent1:                 episode reward: 0.1347,                 loss: 0.3087
Episode: 1141/30000 (3.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2406s / 11.8694 s
agent0:                 episode reward: -0.0956,                 loss: nan
agent1:                 episode reward: 0.0956,                 loss: 0.3080
Episode: 1161/30000 (3.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2368s / 12.1062 s
agent0:                 episode reward: -0.1263,                 loss: nan
agent1:                 episode reward: 0.1263,                 loss: 0.3027
Episode: 1181/30000 (3.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2536s / 12.3597 s
agent0:                 episode reward: -0.2616,                 loss: nan
agent1:                 episode reward: 0.2616,                 loss: 0.3033
Episode: 1201/30000 (4.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2363s / 12.5960 s
agent0:                 episode reward: -0.5443,                 loss: nan
agent1:                 episode reward: 0.5443,                 loss: 0.3023
Episode: 1221/30000 (4.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2364s / 12.8324 s
agent0:                 episode reward: -0.4316,                 loss: nan
agent1:                 episode reward: 0.4316,                 loss: 0.2907
Episode: 1241/30000 (4.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2365s / 13.0689 s
agent0:                 episode reward: 0.0082,                 loss: nan
agent1:                 episode reward: -0.0082,                 loss: 0.2501
Episode: 1261/30000 (4.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2389s / 13.3078 s
agent0:                 episode reward: -0.1888,                 loss: nan
agent1:                 episode reward: 0.1888,                 loss: 0.2502
Episode: 1281/30000 (4.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2380s / 13.5458 s
agent0:                 episode reward: 0.0731,                 loss: nan
agent1:                 episode reward: -0.0731,                 loss: 0.2456
Episode: 1301/30000 (4.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2491s / 13.7949 s
agent0:                 episode reward: -0.1827,                 loss: nan
agent1:                 episode reward: 0.1827,                 loss: 0.2480
Episode: 1321/30000 (4.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2370s / 14.0319 s
agent0:                 episode reward: -0.0181,                 loss: nan
agent1:                 episode reward: 0.0181,                 loss: 0.2458
Episode: 1341/30000 (4.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2914s / 14.3233 s
agent0:                 episode reward: -0.1385,                 loss: nan
agent1:                 episode reward: 0.1385,                 loss: 0.2471
Episode: 1361/30000 (4.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2395s / 14.5628 s
agent0:                 episode reward: -0.2446,                 loss: nan
agent1:                 episode reward: 0.2446,                 loss: 0.2489
Episode: 1381/30000 (4.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2803s / 14.8432 s
agent0:                 episode reward: -0.1496,                 loss: nan
agent1:                 episode reward: 0.1496,                 loss: 0.2433
Episode: 1401/30000 (4.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2398s / 15.0830 s
agent0:                 episode reward: -0.4411,                 loss: nan
agent1:                 episode reward: 0.4411,                 loss: 0.2438
Episode: 1421/30000 (4.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2409s / 15.3239 s
agent0:                 episode reward: -0.0595,                 loss: nan
agent1:                 episode reward: 0.0595,                 loss: 0.2453
Episode: 1441/30000 (4.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2403s / 15.5642 s
agent0:                 episode reward: -0.1056,                 loss: nan
agent1:                 episode reward: 0.1056,                 loss: 0.2467
Episode: 1461/30000 (4.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2456s / 15.8098 s
agent0:                 episode reward: -0.3744,                 loss: nan
agent1:                 episode reward: 0.3744,                 loss: 0.2453
Episode: 1481/30000 (4.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2656s / 16.0754 s
agent0:                 episode reward: -0.3119,                 loss: nan
agent1:                 episode reward: 0.3119,                 loss: 0.2462
Episode: 1501/30000 (5.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2440s / 16.3193 s
agent0:                 episode reward: -0.2419,                 loss: nan
agent1:                 episode reward: 0.2419,                 loss: 0.2431
Episode: 1521/30000 (5.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2441s / 16.5635 s
agent0:                 episode reward: -0.5529,                 loss: nan
agent1:                 episode reward: 0.5529,                 loss: 0.2422
Episode: 1541/30000 (5.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3126s / 16.8761 s
agent0:                 episode reward: -0.0438,                 loss: nan
agent1:                 episode reward: 0.0438,                 loss: 0.2441
Episode: 1561/30000 (5.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2414s / 17.1174 s
agent0:                 episode reward: -0.4363,                 loss: nan
agent1:                 episode reward: 0.4363,                 loss: 0.2470
Episode: 1581/30000 (5.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2407s / 17.3581 s
agent0:                 episode reward: -0.2975,                 loss: nan
agent1:                 episode reward: 0.2975,                 loss: 0.2332
Episode: 1601/30000 (5.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2446s / 17.6027 s
agent0:                 episode reward: -0.3805,                 loss: nan
agent1:                 episode reward: 0.3805,                 loss: 0.2320
Episode: 1621/30000 (5.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2474s / 17.8502 s
agent0:                 episode reward: -0.3829,                 loss: nan
agent1:                 episode reward: 0.3829,                 loss: 0.2308
Episode: 1641/30000 (5.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2460s / 18.0962 s
agent0:                 episode reward: -0.3296,                 loss: nan
agent1:                 episode reward: 0.3296,                 loss: 0.2310
Episode: 1661/30000 (5.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2484s / 18.3446 s
agent0:                 episode reward: -0.6144,                 loss: nan
agent1:                 episode reward: 0.6144,                 loss: 0.2306
Episode: 1681/30000 (5.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2497s / 18.5943 s
agent0:                 episode reward: -0.6795,                 loss: nan
agent1:                 episode reward: 0.6795,                 loss: 0.2279
Episode: 1701/30000 (5.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2491s / 18.8434 s
agent0:                 episode reward: -0.2451,                 loss: nan
agent1:                 episode reward: 0.2451,                 loss: 0.2283
Episode: 1721/30000 (5.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2483s / 19.0917 s
agent0:                 episode reward: -0.2322,                 loss: nan
agent1:                 episode reward: 0.2322,                 loss: 0.2299
Episode: 1741/30000 (5.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2507s / 19.3425 s
agent0:                 episode reward: -0.5677,                 loss: nan
agent1:                 episode reward: 0.5677,                 loss: 0.2254
Episode: 1761/30000 (5.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2497s / 19.5922 s
agent0:                 episode reward: -0.8153,                 loss: nan
agent1:                 episode reward: 0.8153,                 loss: 0.2241
Episode: 1781/30000 (5.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2603s / 19.8525 s
agent0:                 episode reward: 0.0771,                 loss: nan
agent1:                 episode reward: -0.0771,                 loss: 0.2263
Episode: 1801/30000 (6.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2519s / 20.1044 s
agent0:                 episode reward: -0.3573,                 loss: nan
agent1:                 episode reward: 0.3573,                 loss: 0.2261
Episode: 1821/30000 (6.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2509s / 20.3553 s
agent0:                 episode reward: -0.2676,                 loss: nan
agent1:                 episode reward: 0.2676,                 loss: 0.2218
Episode: 1841/30000 (6.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2442s / 20.5996 s
agent0:                 episode reward: -0.2907,                 loss: nan
agent1:                 episode reward: 0.2907,                 loss: 0.2250
Episode: 1861/30000 (6.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2490s / 20.8486 s
agent0:                 episode reward: -0.3939,                 loss: nan
agent1:                 episode reward: 0.3939,                 loss: 0.2269
Episode: 1881/30000 (6.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2485s / 21.0971 s
agent0:                 episode reward: -0.4663,                 loss: nan
agent1:                 episode reward: 0.4663,                 loss: 0.2314
Episode: 1901/30000 (6.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2504s / 21.3475 s
agent0:                 episode reward: -0.2246,                 loss: nan
agent1:                 episode reward: 0.2246,                 loss: 0.2830
Episode: 1921/30000 (6.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2519s / 21.5994 s
agent0:                 episode reward: -0.3086,                 loss: nan
agent1:                 episode reward: 0.3086,                 loss: 0.2792
Episode: 1941/30000 (6.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2519s / 21.8513 s
agent0:                 episode reward: -0.3002,                 loss: nan
agent1:                 episode reward: 0.3002,                 loss: 0.2749
Episode: 1961/30000 (6.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2516s / 22.1028 s
agent0:                 episode reward: -0.4885,                 loss: nan
agent1:                 episode reward: 0.4885,                 loss: 0.2727
Episode: 1981/30000 (6.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2529s / 22.3558 s
agent0:                 episode reward: -0.3205,                 loss: nan
agent1:                 episode reward: 0.3205,                 loss: 0.2782
Episode: 2001/30000 (6.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2526s / 22.6083 s
agent0:                 episode reward: -0.7044,                 loss: nan
agent1:                 episode reward: 0.7044,                 loss: 0.2755
Episode: 2021/30000 (6.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2647s / 22.8731 s
agent0:                 episode reward: -0.7388,                 loss: nan
agent1:                 episode reward: 0.7388,                 loss: 0.2742
Episode: 2041/30000 (6.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2538s / 23.1268 s
agent0:                 episode reward: -0.1710,                 loss: nan
agent1:                 episode reward: 0.1710,                 loss: 0.2739
Episode: 2061/30000 (6.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2504s / 23.3772 s
agent0:                 episode reward: -0.2457,                 loss: nan
agent1:                 episode reward: 0.2457,                 loss: 0.2726
Episode: 2081/30000 (6.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2994s / 23.6766 s
agent0:                 episode reward: -0.1948,                 loss: nan
agent1:                 episode reward: 0.1948,                 loss: 0.2740
Episode: 2101/30000 (7.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2505s / 23.9271 s
agent0:                 episode reward: -0.0728,                 loss: nan
agent1:                 episode reward: 0.0728,                 loss: 0.2758
Episode: 2121/30000 (7.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2506s / 24.1777 s
agent0:                 episode reward: -0.8606,                 loss: nan
agent1:                 episode reward: 0.8606,                 loss: 0.2749
Episode: 2141/30000 (7.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3068s / 24.4845 s
agent0:                 episode reward: -0.3674,                 loss: nan
agent1:                 episode reward: 0.3674,                 loss: 0.2741
Episode: 2161/30000 (7.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2587s / 24.7432 s
agent0:                 episode reward: -0.2834,                 loss: nan
agent1:                 episode reward: 0.2834,                 loss: 0.2713
Episode: 2181/30000 (7.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2550s / 24.9982 s
agent0:                 episode reward: -0.4687,                 loss: nan
agent1:                 episode reward: 0.4687,                 loss: 0.2727
Episode: 2201/30000 (7.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2763s / 25.2745 s
agent0:                 episode reward: -0.0737,                 loss: nan
agent1:                 episode reward: 0.0737,                 loss: 0.2718
Episode: 2221/30000 (7.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2553s / 25.5298 s
agent0:                 episode reward: -0.5405,                 loss: nan
agent1:                 episode reward: 0.5405,                 loss: 0.2597
Episode: 2241/30000 (7.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2665s / 25.7963 s
agent0:                 episode reward: -0.4473,                 loss: nan
agent1:                 episode reward: 0.4473,                 loss: 0.2304
Episode: 2261/30000 (7.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2564s / 26.0527 s
agent0:                 episode reward: -0.4555,                 loss: nan
agent1:                 episode reward: 0.4555,                 loss: 0.2318
Episode: 2281/30000 (7.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2596s / 26.3123 s
agent0:                 episode reward: -0.4091,                 loss: nan
agent1:                 episode reward: 0.4091,                 loss: 0.2303
Episode: 2301/30000 (7.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2600s / 26.5723 s
agent0:                 episode reward: -0.5062,                 loss: nan
agent1:                 episode reward: 0.5062,                 loss: 0.2301
Episode: 2321/30000 (7.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2644s / 26.8367 s
agent0:                 episode reward: -0.6308,                 loss: nan
agent1:                 episode reward: 0.6308,                 loss: 0.2310
Episode: 2341/30000 (7.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2659s / 27.1026 s
agent0:                 episode reward: -0.5024,                 loss: nan
agent1:                 episode reward: 0.5024,                 loss: 0.2280
Episode: 2361/30000 (7.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2569s / 27.3595 s
agent0:                 episode reward: -0.6001,                 loss: nan
agent1:                 episode reward: 0.6001,                 loss: 0.2325
Episode: 2381/30000 (7.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2590s / 27.6186 s
agent0:                 episode reward: -0.3566,                 loss: nan
agent1:                 episode reward: 0.3566,                 loss: 0.2294
Episode: 2401/30000 (8.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2611s / 27.8797 s
agent0:                 episode reward: -0.4135,                 loss: nan
agent1:                 episode reward: 0.4135,                 loss: 0.2289
Episode: 2421/30000 (8.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2626s / 28.1423 s
agent0:                 episode reward: -0.6307,                 loss: nan
agent1:                 episode reward: 0.6307,                 loss: 0.2290
Episode: 2441/30000 (8.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2640s / 28.4063 s
agent0:                 episode reward: -0.2260,                 loss: nan
agent1:                 episode reward: 0.2260,                 loss: 0.2295
Episode: 2461/30000 (8.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2618s / 28.6680 s
agent0:                 episode reward: -0.8288,                 loss: nan
agent1:                 episode reward: 0.8288,                 loss: 0.2276
Episode: 2481/30000 (8.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2688s / 28.9368 s
agent0:                 episode reward: -0.2314,                 loss: nan
agent1:                 episode reward: 0.2314,                 loss: 0.2287
Episode: 2501/30000 (8.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2603s / 29.1972 s
agent0:                 episode reward: -0.3424,                 loss: nan
agent1:                 episode reward: 0.3424,                 loss: 0.2292
Episode: 2521/30000 (8.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2573s / 29.4545 s
agent0:                 episode reward: -0.2527,                 loss: nan
agent1:                 episode reward: 0.2527,                 loss: 0.2274
Episode: 2541/30000 (8.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2610s / 29.7155 s
agent0:                 episode reward: -0.4219,                 loss: nan
agent1:                 episode reward: 0.4219,                 loss: 0.2278
Episode: 2561/30000 (8.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2611s / 29.9765 s
agent0:                 episode reward: -0.5309,                 loss: nan
agent1:                 episode reward: 0.5309,                 loss: 0.2333
Episode: 2581/30000 (8.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2603s / 30.2369 s
agent0:                 episode reward: -0.6704,                 loss: nan
agent1:                 episode reward: 0.6704,                 loss: 0.2251
Episode: 2601/30000 (8.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2580s / 30.4949 s
agent0:                 episode reward: -0.5113,                 loss: nan
agent1:                 episode reward: 0.5113,                 loss: 0.2247
Episode: 2621/30000 (8.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2615s / 30.7565 s
agent0:                 episode reward: -0.4747,                 loss: nan
agent1:                 episode reward: 0.4747,                 loss: 0.2240
Episode: 2641/30000 (8.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2535s / 31.0100 s
agent0:                 episode reward: -0.7438,                 loss: nan
agent1:                 episode reward: 0.7438,                 loss: 0.2231
Episode: 2661/30000 (8.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2594s / 31.2694 s
agent0:                 episode reward: -0.4722,                 loss: nan
agent1:                 episode reward: 0.4722,                 loss: 0.2237
Episode: 2681/30000 (8.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2587s / 31.5282 s
agent0:                 episode reward: -0.4245,                 loss: nan
agent1:                 episode reward: 0.4245,                 loss: 0.2213
Episode: 2701/30000 (9.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2722s / 31.8003 s
agent0:                 episode reward: -0.4406,                 loss: nan
agent1:                 episode reward: 0.4406,                 loss: 0.2221
Episode: 2721/30000 (9.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2633s / 32.0637 s
agent0:                 episode reward: -0.5547,                 loss: nan
agent1:                 episode reward: 0.5547,                 loss: 0.2213
Episode: 2741/30000 (9.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2681s / 32.3318 s
agent0:                 episode reward: -0.6477,                 loss: nan
agent1:                 episode reward: 0.6477,                 loss: 0.2213
Episode: 2761/30000 (9.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2632s / 32.5949 s
agent0:                 episode reward: -0.4692,                 loss: nan
agent1:                 episode reward: 0.4692,                 loss: 0.2211
Episode: 2781/30000 (9.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2639s / 32.8588 s
agent0:                 episode reward: -0.6500,                 loss: nan
agent1:                 episode reward: 0.6500,                 loss: 0.2208
Episode: 2801/30000 (9.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2632s / 33.1221 s
agent0:                 episode reward: -0.9154,                 loss: nan
agent1:                 episode reward: 0.9154,                 loss: 0.2229
Episode: 2821/30000 (9.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2894s / 33.4115 s
agent0:                 episode reward: -0.5467,                 loss: nan
agent1:                 episode reward: 0.5467,                 loss: 0.2215
Episode: 2841/30000 (9.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2650s / 33.6765 s
agent0:                 episode reward: -0.9356,                 loss: nan
agent1:                 episode reward: 0.9356,                 loss: 0.2209
Episode: 2861/30000 (9.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2665s / 33.9430 s
agent0:                 episode reward: -0.4886,                 loss: nan
agent1:                 episode reward: 0.4886,                 loss: 0.2215
Episode: 2881/30000 (9.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2668s / 34.2098 s
agent0:                 episode reward: -0.2062,                 loss: nan
agent1:                 episode reward: 0.2062,                 loss: 0.2224
Episode: 2901/30000 (9.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2629s / 34.4728 s
agent0:                 episode reward: -0.1094,                 loss: nan
agent1:                 episode reward: 0.1094,                 loss: 0.2704
Episode: 2921/30000 (9.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3681s / 34.8408 s
agent0:                 episode reward: -0.5469,                 loss: nan
agent1:                 episode reward: 0.5469,                 loss: 0.2592
Episode: 2941/30000 (9.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2778s / 35.1186 s
agent0:                 episode reward: -0.8426,                 loss: nan
agent1:                 episode reward: 0.8426,                 loss: 0.2547
Episode: 2961/30000 (9.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2648s / 35.3834 s
agent0:                 episode reward: -0.2349,                 loss: nan
agent1:                 episode reward: 0.2349,                 loss: 0.2546
Episode: 2981/30000 (9.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2652s / 35.6486 s
agent0:                 episode reward: -0.0271,                 loss: nan
agent1:                 episode reward: 0.0271,                 loss: 0.2558
Episode: 3001/30000 (10.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2643s / 35.9129 s
agent0:                 episode reward: -0.3278,                 loss: nan
agent1:                 episode reward: 0.3278,                 loss: 0.2543
Episode: 3021/30000 (10.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2639s / 36.1767 s
agent0:                 episode reward: -0.7212,                 loss: nan
agent1:                 episode reward: 0.7212,                 loss: 0.2560
Episode: 3041/30000 (10.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2694s / 36.4462 s
agent0:                 episode reward: -0.5265,                 loss: nan
agent1:                 episode reward: 0.5265,                 loss: 0.2561
Episode: 3061/30000 (10.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2703s / 36.7165 s
agent0:                 episode reward: -0.3644,                 loss: nan
agent1:                 episode reward: 0.3644,                 loss: 0.2569
Episode: 3081/30000 (10.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2717s / 36.9881 s
agent0:                 episode reward: -0.6864,                 loss: nan
agent1:                 episode reward: 0.6864,                 loss: 0.2599
Episode: 3101/30000 (10.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2749s / 37.2630 s
agent0:                 episode reward: -0.3827,                 loss: nan
agent1:                 episode reward: 0.3827,                 loss: 0.2565
Episode: 3121/30000 (10.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2721s / 37.5351 s
agent0:                 episode reward: -0.6546,                 loss: nan
agent1:                 episode reward: 0.6546,                 loss: 0.2559
Episode: 3141/30000 (10.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2777s / 37.8128 s
agent0:                 episode reward: -0.3352,                 loss: nan
agent1:                 episode reward: 0.3352,                 loss: 0.2573
Episode: 3161/30000 (10.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2734s / 38.0862 s
agent0:                 episode reward: -0.6790,                 loss: nan
agent1:                 episode reward: 0.6790,                 loss: 0.2562
Episode: 3181/30000 (10.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2720s / 38.3582 s
agent0:                 episode reward: -0.8969,                 loss: nan
agent1:                 episode reward: 0.8969,                 loss: 0.2572
Episode: 3201/30000 (10.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2696s / 38.6279 s
agent0:                 episode reward: -0.4415,                 loss: nan
agent1:                 episode reward: 0.4415,                 loss: 0.2599
Episode: 3221/30000 (10.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2716s / 38.8994 s
agent0:                 episode reward: -0.4437,                 loss: nan
agent1:                 episode reward: 0.4437,                 loss: 0.2440
Episode: 3241/30000 (10.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2731s / 39.1725 s
agent0:                 episode reward: -0.8194,                 loss: nan
agent1:                 episode reward: 0.8194,                 loss: 0.2131
Episode: 3261/30000 (10.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2752s / 39.4477 s
agent0:                 episode reward: -0.3778,                 loss: nan
agent1:                 episode reward: 0.3778,                 loss: 0.2105
Episode: 3281/30000 (10.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2720s / 39.7197 s
agent0:                 episode reward: -0.5284,                 loss: nan
agent1:                 episode reward: 0.5284,                 loss: 0.2130
Episode: 3301/30000 (11.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2713s / 39.9910 s
agent0:                 episode reward: -0.3208,                 loss: nan
agent1:                 episode reward: 0.3208,                 loss: 0.2109
Episode: 3321/30000 (11.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2704s / 40.2614 s
agent0:                 episode reward: -0.4824,                 loss: nan
agent1:                 episode reward: 0.4824,                 loss: 0.2089
Episode: 3341/30000 (11.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2736s / 40.5350 s
agent0:                 episode reward: -0.8680,                 loss: nan
agent1:                 episode reward: 0.8680,                 loss: 0.2099
Episode: 3361/30000 (11.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2895s / 40.8245 s
agent0:                 episode reward: -0.7513,                 loss: nan
agent1:                 episode reward: 0.7513,                 loss: 0.2089
Episode: 3381/30000 (11.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2760s / 41.1005 s
agent0:                 episode reward: -0.9460,                 loss: nan
agent1:                 episode reward: 0.9460,                 loss: 0.2105
Episode: 3401/30000 (11.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2747s / 41.3752 s
agent0:                 episode reward: -0.9185,                 loss: nan
agent1:                 episode reward: 0.9185,                 loss: 0.2089
Episode: 3421/30000 (11.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2862s / 41.6615 s
agent0:                 episode reward: -0.3987,                 loss: nan
agent1:                 episode reward: 0.3987,                 loss: 0.2093
Episode: 3441/30000 (11.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2833s / 41.9448 s
agent0:                 episode reward: -0.7304,                 loss: nan
agent1:                 episode reward: 0.7304,                 loss: 0.2071
Episode: 3461/30000 (11.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2790s / 42.2238 s
agent0:                 episode reward: -0.6407,                 loss: nan
agent1:                 episode reward: 0.6407,                 loss: 0.2098
Episode: 3481/30000 (11.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2759s / 42.4996 s
agent0:                 episode reward: -0.7979,                 loss: nan
agent1:                 episode reward: 0.7979,                 loss: 0.2096
Episode: 3501/30000 (11.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2790s / 42.7786 s
agent0:                 episode reward: -0.4599,                 loss: nan
agent1:                 episode reward: 0.4599,                 loss: 0.2121
Episode: 3521/30000 (11.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2713s / 43.0499 s
agent0:                 episode reward: -0.3403,                 loss: nan
agent1:                 episode reward: 0.3403,                 loss: 0.2095
Episode: 3541/30000 (11.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2749s / 43.3249 s
agent0:                 episode reward: -0.9045,                 loss: nan
agent1:                 episode reward: 0.9045,                 loss: 0.2108
Episode: 3561/30000 (11.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2750s / 43.5999 s
agent0:                 episode reward: -0.5955,                 loss: nan
agent1:                 episode reward: 0.5955,                 loss: 0.2310
Episode: 3581/30000 (11.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2879s / 43.8878 s
agent0:                 episode reward: -0.6607,                 loss: nan
agent1:                 episode reward: 0.6607,                 loss: 0.2350
Episode: 3601/30000 (12.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2784s / 44.1661 s
agent0:                 episode reward: -0.5842,                 loss: nan
agent1:                 episode reward: 0.5842,                 loss: 0.2374
Episode: 3621/30000 (12.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2777s / 44.4438 s
agent0:                 episode reward: -0.5007,                 loss: nan
agent1:                 episode reward: 0.5007,                 loss: 0.2368
Episode: 3641/30000 (12.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2791s / 44.7229 s
agent0:                 episode reward: -0.3787,                 loss: nan
agent1:                 episode reward: 0.3787,                 loss: 0.2391
Episode: 3661/30000 (12.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3599s / 45.0828 s
agent0:                 episode reward: -0.3690,                 loss: nan
agent1:                 episode reward: 0.3690,                 loss: 0.2390
Episode: 3681/30000 (12.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2776s / 45.3604 s
agent0:                 episode reward: -0.6493,                 loss: nan
agent1:                 episode reward: 0.6493,                 loss: 0.2385
Episode: 3701/30000 (12.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2847s / 45.6451 s
agent0:                 episode reward: -0.7410,                 loss: nan
agent1:                 episode reward: 0.7410,                 loss: 0.2372
Episode: 3721/30000 (12.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2780s / 45.9231 s
agent0:                 episode reward: -0.6980,                 loss: nan
agent1:                 episode reward: 0.6980,                 loss: 0.2373
Episode: 3741/30000 (12.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2800s / 46.2031 s
agent0:                 episode reward: -0.4452,                 loss: nan
agent1:                 episode reward: 0.4452,                 loss: 0.2373
Episode: 3761/30000 (12.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2809s / 46.4840 s
agent0:                 episode reward: -0.6749,                 loss: nan
agent1:                 episode reward: 0.6749,                 loss: 0.2361
Episode: 3781/30000 (12.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2773s / 46.7613 s
agent0:                 episode reward: -0.4640,                 loss: nan
agent1:                 episode reward: 0.4640,                 loss: 0.2373
Episode: 3801/30000 (12.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2887s / 47.0499 s
agent0:                 episode reward: -0.7291,                 loss: nan
agent1:                 episode reward: 0.7291,                 loss: 0.2370
Episode: 3821/30000 (12.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2913s / 47.3412 s
agent0:                 episode reward: -0.6754,                 loss: nan
agent1:                 episode reward: 0.6754,                 loss: 0.2395
Episode: 3841/30000 (12.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2816s / 47.6228 s
agent0:                 episode reward: -0.7700,                 loss: nan
agent1:                 episode reward: 0.7700,                 loss: 0.2339
Episode: 3861/30000 (12.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2788s / 47.9015 s
agent0:                 episode reward: -0.6703,                 loss: nan
agent1:                 episode reward: 0.6703,                 loss: 0.2348
Episode: 3881/30000 (12.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2743s / 48.1758 s
agent0:                 episode reward: -0.2718,                 loss: nan
agent1:                 episode reward: 0.2718,                 loss: 0.2355
Episode: 3901/30000 (13.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2805s / 48.4563 s
agent0:                 episode reward: -1.1171,                 loss: nan
agent1:                 episode reward: 1.1171,                 loss: 0.2373
Episode: 3921/30000 (13.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2824s / 48.7387 s
agent0:                 episode reward: -1.0475,                 loss: nan
agent1:                 episode reward: 1.0475,                 loss: 0.2361
Episode: 3941/30000 (13.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2812s / 49.0199 s
agent0:                 episode reward: -0.7567,                 loss: nan
agent1:                 episode reward: 0.7567,                 loss: 0.2337
Episode: 3961/30000 (13.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2809s / 49.3008 s
agent0:                 episode reward: -0.6533,                 loss: nan
agent1:                 episode reward: 0.6533,                 loss: 0.2339
Episode: 3981/30000 (13.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2824s / 49.5832 s
agent0:                 episode reward: -0.7632,                 loss: nan
agent1:                 episode reward: 0.7632,                 loss: 0.2358
Episode: 4001/30000 (13.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3040s / 49.8872 s
agent0:                 episode reward: -0.4621,                 loss: nan
agent1:                 episode reward: 0.4621,                 loss: 0.2366
Episode: 4021/30000 (13.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3083s / 50.1954 s
agent0:                 episode reward: -0.5307,                 loss: nan
agent1:                 episode reward: 0.5307,                 loss: 0.2412
Episode: 4041/30000 (13.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2775s / 50.4729 s
agent0:                 episode reward: -0.7402,                 loss: nan
agent1:                 episode reward: 0.7402,                 loss: 0.2378
Episode: 4061/30000 (13.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3086s / 50.7815 s
agent0:                 episode reward: -0.7049,                 loss: nan
agent1:                 episode reward: 0.7049,                 loss: 0.2364
Episode: 4081/30000 (13.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2817s / 51.0632 s
agent0:                 episode reward: -0.3455,                 loss: nan
agent1:                 episode reward: 0.3455,                 loss: 0.2382
Episode: 4101/30000 (13.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2840s / 51.3473 s
agent0:                 episode reward: -0.7330,                 loss: nan
agent1:                 episode reward: 0.7330,                 loss: 0.2382
Episode: 4121/30000 (13.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2842s / 51.6315 s
agent0:                 episode reward: -0.6337,                 loss: nan
agent1:                 episode reward: 0.6337,                 loss: 0.2388
Episode: 4141/30000 (13.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2835s / 51.9150 s
agent0:                 episode reward: -0.6285,                 loss: nan
agent1:                 episode reward: 0.6285,                 loss: 0.2401
Episode: 4161/30000 (13.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2834s / 52.1984 s
agent0:                 episode reward: -0.5815,                 loss: nan
agent1:                 episode reward: 0.5815,                 loss: 0.2359
Episode: 4181/30000 (13.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2847s / 52.4831 s
agent0:                 episode reward: -0.6373,                 loss: nan
agent1:                 episode reward: 0.6373,                 loss: 0.2355
Episode: 4201/30000 (14.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2860s / 52.7691 s
agent0:                 episode reward: -0.3713,                 loss: nan
agent1:                 episode reward: 0.3713,                 loss: 0.2373
Episode: 4221/30000 (14.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3142s / 53.0833 s
agent0:                 episode reward: -0.8229,                 loss: nan
agent1:                 episode reward: 0.8229,                 loss: 0.2321
Episode: 4241/30000 (14.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2871s / 53.3704 s
agent0:                 episode reward: -0.4416,                 loss: nan
agent1:                 episode reward: 0.4416,                 loss: 0.2205
Episode: 4261/30000 (14.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2890s / 53.6594 s
agent0:                 episode reward: -0.2954,                 loss: nan
agent1:                 episode reward: 0.2954,                 loss: 0.2184
Episode: 4281/30000 (14.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2879s / 53.9473 s
agent0:                 episode reward: -0.3335,                 loss: nan
agent1:                 episode reward: 0.3335,                 loss: 0.2189
Episode: 4301/30000 (14.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2867s / 54.2340 s
agent0:                 episode reward: -0.8089,                 loss: nan
agent1:                 episode reward: 0.8089,                 loss: 0.2204
Episode: 4321/30000 (14.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2874s / 54.5214 s
agent0:                 episode reward: -0.7720,                 loss: nan
agent1:                 episode reward: 0.7720,                 loss: 0.2206
Episode: 4341/30000 (14.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2948s / 54.8162 s
agent0:                 episode reward: -0.5882,                 loss: nan
agent1:                 episode reward: 0.5882,                 loss: 0.2224
Episode: 4361/30000 (14.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3935s / 55.2098 s
agent0:                 episode reward: -0.2424,                 loss: nan
agent1:                 episode reward: 0.2424,                 loss: 0.2221
Episode: 4381/30000 (14.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3125s / 55.5223 s
agent0:                 episode reward: -0.3864,                 loss: nan
agent1:                 episode reward: 0.3864,                 loss: 0.2231
Episode: 4401/30000 (14.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2882s / 55.8105 s
agent0:                 episode reward: -0.7615,                 loss: nan
agent1:                 episode reward: 0.7615,                 loss: 0.2189
Episode: 4421/30000 (14.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2935s / 56.1040 s
agent0:                 episode reward: -1.0644,                 loss: nan
agent1:                 episode reward: 1.0644,                 loss: 0.2198
Episode: 4441/30000 (14.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2908s / 56.3948 s
agent0:                 episode reward: -0.8605,                 loss: nan
agent1:                 episode reward: 0.8605,                 loss: 0.2181
Episode: 4461/30000 (14.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2869s / 56.6818 s
agent0:                 episode reward: -0.7575,                 loss: nan
agent1:                 episode reward: 0.7575,                 loss: 0.2186
Episode: 4481/30000 (14.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2854s / 56.9671 s
agent0:                 episode reward: -0.2039,                 loss: nan
agent1:                 episode reward: 0.2039,                 loss: 0.2181
Episode: 4501/30000 (15.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2906s / 57.2578 s
agent0:                 episode reward: -0.6853,                 loss: nan
agent1:                 episode reward: 0.6853,                 loss: 0.2201
Episode: 4521/30000 (15.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2938s / 57.5516 s
agent0:                 episode reward: -0.5156,                 loss: nan
agent1:                 episode reward: 0.5156,                 loss: 0.2185
Episode: 4541/30000 (15.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2904s / 57.8421 s
agent0:                 episode reward: -0.4560,                 loss: nan
agent1:                 episode reward: 0.4560,                 loss: 0.2197
Episode: 4561/30000 (15.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2911s / 58.1332 s
agent0:                 episode reward: -0.9611,                 loss: nan
agent1:                 episode reward: 0.9611,                 loss: 0.2341
Episode: 4581/30000 (15.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3326s / 58.4658 s
agent0:                 episode reward: -0.7996,                 loss: nan
agent1:                 episode reward: 0.7996,                 loss: 0.2401
Episode: 4601/30000 (15.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2929s / 58.7587 s
agent0:                 episode reward: -0.6481,                 loss: nan
agent1:                 episode reward: 0.6481,                 loss: 0.2393
Episode: 4621/30000 (15.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3002s / 59.0589 s
agent0:                 episode reward: -0.8517,                 loss: nan
agent1:                 episode reward: 0.8517,                 loss: 0.2382
Episode: 4641/30000 (15.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2991s / 59.3580 s
agent0:                 episode reward: -0.3936,                 loss: nan
agent1:                 episode reward: 0.3936,                 loss: 0.2419
Episode: 4661/30000 (15.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3100s / 59.6680 s
agent0:                 episode reward: -0.5855,                 loss: nan
agent1:                 episode reward: 0.5855,                 loss: 0.2372
Episode: 4681/30000 (15.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2900s / 59.9580 s
agent0:                 episode reward: -0.8089,                 loss: nan
agent1:                 episode reward: 0.8089,                 loss: 0.2423
Episode: 4701/30000 (15.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2923s / 60.2504 s
agent0:                 episode reward: -0.8092,                 loss: nan
agent1:                 episode reward: 0.8092,                 loss: 0.2380
Episode: 4721/30000 (15.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2905s / 60.5409 s
agent0:                 episode reward: -0.9894,                 loss: nan
agent1:                 episode reward: 0.9894,                 loss: 0.2368
Episode: 4741/30000 (15.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2915s / 60.8323 s
agent0:                 episode reward: -0.5527,                 loss: nan
agent1:                 episode reward: 0.5527,                 loss: 0.2380
Episode: 4761/30000 (15.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2906s / 61.1230 s
agent0:                 episode reward: -0.6157,                 loss: nan
agent1:                 episode reward: 0.6157,                 loss: 0.2381
Episode: 4781/30000 (15.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2886s / 61.4116 s
agent0:                 episode reward: -0.8603,                 loss: nan
agent1:                 episode reward: 0.8603,                 loss: 0.2346
Episode: 4801/30000 (16.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3187s / 61.7303 s
agent0:                 episode reward: -0.5875,                 loss: nan
agent1:                 episode reward: 0.5875,                 loss: 0.2382
Episode: 4821/30000 (16.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3034s / 62.0337 s
agent0:                 episode reward: -0.9043,                 loss: nan
agent1:                 episode reward: 0.9043,                 loss: 0.2386
Episode: 4841/30000 (16.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2992s / 62.3329 s
agent0:                 episode reward: -0.4587,                 loss: nan
agent1:                 episode reward: 0.4587,                 loss: 0.2399
Episode: 4861/30000 (16.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2982s / 62.6311 s
agent0:                 episode reward: -0.7290,                 loss: nan
agent1:                 episode reward: 0.7290,                 loss: 0.2412
Episode: 4881/30000 (16.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2961s / 62.9272 s
agent0:                 episode reward: -0.7698,                 loss: nan
agent1:                 episode reward: 0.7698,                 loss: 0.2351
Episode: 4901/30000 (16.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2963s / 63.2235 s
agent0:                 episode reward: -0.7036,                 loss: nan
agent1:                 episode reward: 0.7036,                 loss: 0.2332
Episode: 4921/30000 (16.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2989s / 63.5224 s
agent0:                 episode reward: -0.7071,                 loss: nan
agent1:                 episode reward: 0.7071,                 loss: 0.2304
Episode: 4941/30000 (16.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3007s / 63.8230 s
agent0:                 episode reward: -0.6374,                 loss: nan
agent1:                 episode reward: 0.6374,                 loss: 0.2286
Episode: 4961/30000 (16.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2966s / 64.1196 s
agent0:                 episode reward: -0.5705,                 loss: nan
agent1:                 episode reward: 0.5705,                 loss: 0.2324
Episode: 4981/30000 (16.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2952s / 64.4148 s
agent0:                 episode reward: -0.6308,                 loss: nan
agent1:                 episode reward: 0.6308,                 loss: 0.2274
Episode: 5001/30000 (16.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3016s / 64.7165 s
agent0:                 episode reward: -0.7121,                 loss: nan
agent1:                 episode reward: 0.7121,                 loss: 0.2314
Episode: 5021/30000 (16.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3082s / 65.0247 s
agent0:                 episode reward: -0.4369,                 loss: nan
agent1:                 episode reward: 0.4369,                 loss: 0.2272
Episode: 5041/30000 (16.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3244s / 65.3491 s
agent0:                 episode reward: -0.9423,                 loss: nan
agent1:                 episode reward: 0.9423,                 loss: 0.2323
Episode: 5061/30000 (16.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3408s / 65.6900 s
agent0:                 episode reward: -0.7041,                 loss: nan
agent1:                 episode reward: 0.7041,                 loss: 0.2312
Episode: 5081/30000 (16.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2962s / 65.9862 s
agent0:                 episode reward: -0.8805,                 loss: nan
agent1:                 episode reward: 0.8805,                 loss: 0.2353
Episode: 5101/30000 (17.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2947s / 66.2809 s
agent0:                 episode reward: -0.6065,                 loss: nan
agent1:                 episode reward: 0.6065,                 loss: 0.2322
Episode: 5121/30000 (17.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3194s / 66.6003 s
agent0:                 episode reward: -0.4816,                 loss: nan
agent1:                 episode reward: 0.4816,                 loss: 0.2280
Episode: 5141/30000 (17.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2996s / 66.8999 s
agent0:                 episode reward: -0.5890,                 loss: nan
agent1:                 episode reward: 0.5890,                 loss: 0.2296
Episode: 5161/30000 (17.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2961s / 67.1960 s
agent0:                 episode reward: -0.6614,                 loss: nan
agent1:                 episode reward: 0.6614,                 loss: 0.2330
Episode: 5181/30000 (17.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3121s / 67.5081 s
agent0:                 episode reward: -0.8651,                 loss: nan
agent1:                 episode reward: 0.8651,                 loss: 0.2313
Episode: 5201/30000 (17.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2979s / 67.8060 s
agent0:                 episode reward: -0.9760,                 loss: nan
agent1:                 episode reward: 0.9760,                 loss: 0.2304
Episode: 5221/30000 (17.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3073s / 68.1133 s
agent0:                 episode reward: -0.7878,                 loss: nan
agent1:                 episode reward: 0.7878,                 loss: 0.2281
Episode: 5241/30000 (17.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3020s / 68.4153 s
agent0:                 episode reward: -0.7124,                 loss: nan
agent1:                 episode reward: 0.7124,                 loss: 0.2146
Episode: 5261/30000 (17.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2974s / 68.7127 s
agent0:                 episode reward: -0.7571,                 loss: nan
agent1:                 episode reward: 0.7571,                 loss: 0.2194
Episode: 5281/30000 (17.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2949s / 69.0075 s
agent0:                 episode reward: -0.4922,                 loss: nan
agent1:                 episode reward: 0.4922,                 loss: 0.2173
Episode: 5301/30000 (17.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3026s / 69.3101 s
agent0:                 episode reward: -0.6786,                 loss: nan
agent1:                 episode reward: 0.6786,                 loss: 0.2169
Episode: 5321/30000 (17.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2981s / 69.6082 s
agent0:                 episode reward: -0.4682,                 loss: nan
agent1:                 episode reward: 0.4682,                 loss: 0.2157
Episode: 5341/30000 (17.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2969s / 69.9051 s
agent0:                 episode reward: -1.1344,                 loss: nan
agent1:                 episode reward: 1.1344,                 loss: 0.2166
Episode: 5361/30000 (17.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2996s / 70.2048 s
agent0:                 episode reward: -0.8834,                 loss: nan
agent1:                 episode reward: 0.8834,                 loss: 0.2176
Episode: 5381/30000 (17.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3006s / 70.5053 s
agent0:                 episode reward: -0.8512,                 loss: nan
agent1:                 episode reward: 0.8512,                 loss: 0.2166
Episode: 5401/30000 (18.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3032s / 70.8085 s
agent0:                 episode reward: -0.7397,                 loss: nan
agent1:                 episode reward: 0.7397,                 loss: 0.2159
Episode: 5421/30000 (18.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3380s / 71.1465 s
agent0:                 episode reward: -0.7339,                 loss: nan
agent1:                 episode reward: 0.7339,                 loss: 0.2186
Episode: 5441/30000 (18.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3043s / 71.4508 s
agent0:                 episode reward: -0.7856,                 loss: nan
agent1:                 episode reward: 0.7856,                 loss: 0.2134
Episode: 5461/30000 (18.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3226s / 71.7734 s
agent0:                 episode reward: -0.6857,                 loss: nan
agent1:                 episode reward: 0.6857,                 loss: 0.2163
Episode: 5481/30000 (18.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3180s / 72.0913 s
agent0:                 episode reward: -0.7034,                 loss: nan
agent1:                 episode reward: 0.7034,                 loss: 0.2126
Episode: 5501/30000 (18.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3055s / 72.3968 s
agent0:                 episode reward: -0.8069,                 loss: nan
agent1:                 episode reward: 0.8069,                 loss: 0.2126
Episode: 5521/30000 (18.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3105s / 72.7073 s
agent0:                 episode reward: -0.6666,                 loss: nan
agent1:                 episode reward: 0.6666,                 loss: 0.2181
Episode: 5541/30000 (18.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3046s / 73.0118 s
agent0:                 episode reward: -0.4742,                 loss: nan
agent1:                 episode reward: 0.4742,                 loss: 0.2138
Episode: 5561/30000 (18.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3132s / 73.3250 s
agent0:                 episode reward: -0.8632,                 loss: nan
agent1:                 episode reward: 0.8632,                 loss: 0.2363
Episode: 5581/30000 (18.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3105s / 73.6355 s
agent0:                 episode reward: -1.0435,                 loss: nan
agent1:                 episode reward: 1.0435,                 loss: 0.2397
Episode: 5601/30000 (18.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3134s / 73.9489 s
agent0:                 episode reward: -0.6930,                 loss: nan
agent1:                 episode reward: 0.6930,                 loss: 0.2382
Episode: 5621/30000 (18.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3176s / 74.2664 s
agent0:                 episode reward: -0.6253,                 loss: nan
agent1:                 episode reward: 0.6253,                 loss: 0.2373
Episode: 5641/30000 (18.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3060s / 74.5724 s
agent0:                 episode reward: -0.7420,                 loss: nan
agent1:                 episode reward: 0.7420,                 loss: 0.2335
Episode: 5661/30000 (18.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3243s / 74.8968 s
agent0:                 episode reward: -0.8315,                 loss: nan
agent1:                 episode reward: 0.8315,                 loss: 0.2351
Episode: 5681/30000 (18.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3111s / 75.2078 s
agent0:                 episode reward: -0.6181,                 loss: nan
agent1:                 episode reward: 0.6181,                 loss: 0.2345
Episode: 5701/30000 (19.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3088s / 75.5166 s
agent0:                 episode reward: -0.8237,                 loss: nan
agent1:                 episode reward: 0.8237,                 loss: 0.2357
Episode: 5721/30000 (19.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3671s / 75.8837 s
agent0:                 episode reward: -0.6885,                 loss: nan
agent1:                 episode reward: 0.6885,                 loss: 0.2365
Episode: 5741/30000 (19.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3088s / 76.1925 s
agent0:                 episode reward: -0.5980,                 loss: nan
agent1:                 episode reward: 0.5980,                 loss: 0.2352
Episode: 5761/30000 (19.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3082s / 76.5007 s
agent0:                 episode reward: -0.8232,                 loss: nan
agent1:                 episode reward: 0.8232,                 loss: 0.2344
Episode: 5781/30000 (19.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3086s / 76.8093 s
agent0:                 episode reward: -0.7284,                 loss: nan
agent1:                 episode reward: 0.7284,                 loss: 0.2357
Episode: 5801/30000 (19.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3170s / 77.1263 s
agent0:                 episode reward: -0.7202,                 loss: nan
agent1:                 episode reward: 0.7202,                 loss: 0.2337
Episode: 5821/30000 (19.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3126s / 77.4389 s
agent0:                 episode reward: -0.4938,                 loss: nan
agent1:                 episode reward: 0.4938,                 loss: 0.2350
Episode: 5841/30000 (19.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3282s / 77.7671 s
agent0:                 episode reward: -0.4050,                 loss: nan
agent1:                 episode reward: 0.4050,                 loss: 0.2371
Episode: 5861/30000 (19.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3133s / 78.0805 s
agent0:                 episode reward: -1.0144,                 loss: nan
agent1:                 episode reward: 1.0144,                 loss: 0.2385
Episode: 5881/30000 (19.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3142s / 78.3946 s
agent0:                 episode reward: -0.8101,                 loss: nan
agent1:                 episode reward: 0.8101,                 loss: 0.2380
Episode: 5901/30000 (19.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3128s / 78.7075 s
agent0:                 episode reward: -0.6103,                 loss: nan
agent1:                 episode reward: 0.6103,                 loss: 0.2209
Episode: 5921/30000 (19.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3089s / 79.0164 s
agent0:                 episode reward: -0.9723,                 loss: nan
agent1:                 episode reward: 0.9723,                 loss: 0.2217
Episode: 5941/30000 (19.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3133s / 79.3297 s
agent0:                 episode reward: -0.7364,                 loss: nan
agent1:                 episode reward: 0.7364,                 loss: 0.2239
Episode: 5961/30000 (19.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3084s / 79.6382 s
agent0:                 episode reward: -0.7856,                 loss: nan
agent1:                 episode reward: 0.7856,                 loss: 0.2170
Episode: 5981/30000 (19.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3147s / 79.9529 s
agent0:                 episode reward: -0.9229,                 loss: nan
agent1:                 episode reward: 0.9229,                 loss: 0.2201
Episode: 6001/30000 (20.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3213s / 80.2742 s
agent0:                 episode reward: -0.8330,                 loss: nan
agent1:                 episode reward: 0.8330,                 loss: 0.2200
Episode: 6021/30000 (20.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3163s / 80.5905 s
agent0:                 episode reward: -0.6308,                 loss: nan
agent1:                 episode reward: 0.6308,                 loss: 0.2217
Episode: 6041/30000 (20.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3119s / 80.9024 s
agent0:                 episode reward: -0.6852,                 loss: nan
agent1:                 episode reward: 0.6852,                 loss: 0.2169
Episode: 6061/30000 (20.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3136s / 81.2160 s
agent0:                 episode reward: -0.6356,                 loss: nan
agent1:                 episode reward: 0.6356,                 loss: 0.2219
Episode: 6081/30000 (20.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3129s / 81.5289 s
agent0:                 episode reward: -0.8866,                 loss: nan
agent1:                 episode reward: 0.8866,                 loss: 0.2212
Episode: 6101/30000 (20.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3126s / 81.8415 s
agent0:                 episode reward: -0.9601,                 loss: nan
agent1:                 episode reward: 0.9601,                 loss: 0.2208
Episode: 6121/30000 (20.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3155s / 82.1570 s
agent0:                 episode reward: -1.0080,                 loss: nan
agent1:                 episode reward: 1.0080,                 loss: 0.2202
Episode: 6141/30000 (20.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3145s / 82.4714 s
agent0:                 episode reward: -0.6836,                 loss: nan
agent1:                 episode reward: 0.6836,                 loss: 0.2193
Episode: 6161/30000 (20.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3215s / 82.7929 s
agent0:                 episode reward: -0.8265,                 loss: nan
agent1:                 episode reward: 0.8265,                 loss: 0.2224
Episode: 6181/30000 (20.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3351s / 83.1280 s
agent0:                 episode reward: -0.5946,                 loss: nan
agent1:                 episode reward: 0.5946,                 loss: 0.2231
Episode: 6201/30000 (20.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3572s / 83.4851 s
agent0:                 episode reward: -0.9944,                 loss: nan
agent1:                 episode reward: 0.9944,                 loss: 0.2228
Episode: 6221/30000 (20.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3215s / 83.8067 s
agent0:                 episode reward: -0.5709,                 loss: nan
agent1:                 episode reward: 0.5709,                 loss: 0.2248
Episode: 6241/30000 (20.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3184s / 84.1250 s
agent0:                 episode reward: -0.8993,                 loss: nan
agent1:                 episode reward: 0.8993,                 loss: 0.2317
Episode: 6261/30000 (20.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3202s / 84.4452 s
agent0:                 episode reward: -0.9888,                 loss: nan
agent1:                 episode reward: 0.9888,                 loss: 0.2285
Episode: 6281/30000 (20.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3203s / 84.7655 s
agent0:                 episode reward: -0.7675,                 loss: nan
agent1:                 episode reward: 0.7675,                 loss: 0.2316
Episode: 6301/30000 (21.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3191s / 85.0846 s
agent0:                 episode reward: -0.4084,                 loss: nan
agent1:                 episode reward: 0.4084,                 loss: 0.2267
Episode: 6321/30000 (21.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3184s / 85.4030 s
agent0:                 episode reward: -0.5404,                 loss: nan
agent1:                 episode reward: 0.5404,                 loss: 0.2275
Episode: 6341/30000 (21.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3197s / 85.7227 s
agent0:                 episode reward: -0.7186,                 loss: nan
agent1:                 episode reward: 0.7186,                 loss: 0.2303
Episode: 6361/30000 (21.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3789s / 86.1016 s
agent0:                 episode reward: -0.9783,                 loss: nan
agent1:                 episode reward: 0.9783,                 loss: 0.2284
Episode: 6381/30000 (21.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3221s / 86.4237 s
agent0:                 episode reward: -0.9565,                 loss: nan
agent1:                 episode reward: 0.9565,                 loss: 0.2310
Episode: 6401/30000 (21.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3197s / 86.7434 s
agent0:                 episode reward: -0.7692,                 loss: nan
agent1:                 episode reward: 0.7692,                 loss: 0.2305
Episode: 6421/30000 (21.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3181s / 87.0615 s
agent0:                 episode reward: -0.6302,                 loss: nan
agent1:                 episode reward: 0.6302,                 loss: 0.2257
Episode: 6441/30000 (21.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3773s / 87.4388 s
agent0:                 episode reward: -0.9043,                 loss: nan
agent1:                 episode reward: 0.9043,                 loss: 0.2307
Episode: 6461/30000 (21.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3287s / 87.7675 s
agent0:                 episode reward: -0.7281,                 loss: nan
agent1:                 episode reward: 0.7281,                 loss: 0.2283
Episode: 6481/30000 (21.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3166s / 88.0840 s
agent0:                 episode reward: -0.8281,                 loss: nan
agent1:                 episode reward: 0.8281,                 loss: 0.2314
Episode: 6501/30000 (21.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3180s / 88.4020 s
agent0:                 episode reward: -0.6993,                 loss: nan
agent1:                 episode reward: 0.6993,                 loss: 0.2285
Episode: 6521/30000 (21.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3445s / 88.7465 s
agent0:                 episode reward: -0.5068,                 loss: nan
agent1:                 episode reward: 0.5068,                 loss: 0.2280
Episode: 6541/30000 (21.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3333s / 89.0798 s
agent0:                 episode reward: -1.0142,                 loss: nan
agent1:                 episode reward: 1.0142,                 loss: 0.2298
Episode: 6561/30000 (21.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3259s / 89.4057 s
agent0:                 episode reward: -0.8648,                 loss: nan
agent1:                 episode reward: 0.8648,                 loss: 0.2223
Episode: 6581/30000 (21.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3181s / 89.7238 s
agent0:                 episode reward: -0.7589,                 loss: nan
agent1:                 episode reward: 0.7589,                 loss: 0.2242
Episode: 6601/30000 (22.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3164s / 90.0402 s
agent0:                 episode reward: -0.8972,                 loss: nan
agent1:                 episode reward: 0.8972,                 loss: 0.2216
Episode: 6621/30000 (22.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3257s / 90.3658 s
agent0:                 episode reward: -0.8548,                 loss: nan
agent1:                 episode reward: 0.8548,                 loss: 0.2223
Episode: 6641/30000 (22.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3242s / 90.6901 s
agent0:                 episode reward: -0.8727,                 loss: nan
agent1:                 episode reward: 0.8727,                 loss: 0.2259
Episode: 6661/30000 (22.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3194s / 91.0094 s
agent0:                 episode reward: -0.9037,                 loss: nan
agent1:                 episode reward: 0.9037,                 loss: 0.2240
Episode: 6681/30000 (22.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3250s / 91.3345 s
agent0:                 episode reward: -0.7035,                 loss: nan
agent1:                 episode reward: 0.7035,                 loss: 0.2224
Episode: 6701/30000 (22.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3422s / 91.6766 s
agent0:                 episode reward: -0.4501,                 loss: nan
agent1:                 episode reward: 0.4501,                 loss: 0.2223
Episode: 6721/30000 (22.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3263s / 92.0030 s
agent0:                 episode reward: -0.5936,                 loss: nan
agent1:                 episode reward: 0.5936,                 loss: 0.2217
Episode: 6741/30000 (22.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3647s / 92.3677 s
agent0:                 episode reward: -0.8057,                 loss: nan
agent1:                 episode reward: 0.8057,                 loss: 0.2221
Episode: 6761/30000 (22.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3265s / 92.6942 s
agent0:                 episode reward: -0.7066,                 loss: nan
agent1:                 episode reward: 0.7066,                 loss: 0.2249
Episode: 6781/30000 (22.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3229s / 93.0171 s
agent0:                 episode reward: -0.5135,                 loss: nan
agent1:                 episode reward: 0.5135,                 loss: 0.2266
Episode: 6801/30000 (22.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3226s / 93.3397 s
agent0:                 episode reward: -0.5320,                 loss: nan
agent1:                 episode reward: 0.5320,                 loss: 0.2276
Episode: 6821/30000 (22.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3219s / 93.6616 s
agent0:                 episode reward: -1.0116,                 loss: nan
agent1:                 episode reward: 1.0116,                 loss: 0.2247
Episode: 6841/30000 (22.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3251s / 93.9867 s
agent0:                 episode reward: -0.4725,                 loss: nan
agent1:                 episode reward: 0.4725,                 loss: 0.2251
Episode: 6861/30000 (22.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3204s / 94.3072 s
agent0:                 episode reward: -0.6265,                 loss: nan
agent1:                 episode reward: 0.6265,                 loss: 0.2239
Episode: 6881/30000 (22.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3243s / 94.6314 s
agent0:                 episode reward: -0.7370,                 loss: nan
agent1:                 episode reward: 0.7370,                 loss: 0.2227
Episode: 6901/30000 (23.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3241s / 94.9555 s
agent0:                 episode reward: -0.8375,                 loss: nan
agent1:                 episode reward: 0.8375,                 loss: 0.2372
Episode: 6921/30000 (23.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3596s / 95.3151 s
agent0:                 episode reward: -1.0227,                 loss: nan
agent1:                 episode reward: 1.0227,                 loss: 0.2351
Episode: 6941/30000 (23.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3491s / 95.6641 s
agent0:                 episode reward: -0.7097,                 loss: nan
agent1:                 episode reward: 0.7097,                 loss: 0.2314
Episode: 6961/30000 (23.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3215s / 95.9857 s
agent0:                 episode reward: -0.8448,                 loss: nan
agent1:                 episode reward: 0.8448,                 loss: 0.2352
Episode: 6981/30000 (23.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3776s / 96.3633 s
agent0:                 episode reward: -0.5064,                 loss: nan
agent1:                 episode reward: 0.5064,                 loss: 0.2336
Episode: 7001/30000 (23.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3259s / 96.6892 s
agent0:                 episode reward: -0.7444,                 loss: nan
agent1:                 episode reward: 0.7444,                 loss: 0.2351
Episode: 7021/30000 (23.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3588s / 97.0480 s
agent0:                 episode reward: -0.8273,                 loss: nan
agent1:                 episode reward: 0.8273,                 loss: 0.2338
Episode: 7041/30000 (23.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3255s / 97.3736 s
agent0:                 episode reward: -0.6604,                 loss: nan
agent1:                 episode reward: 0.6604,                 loss: 0.2331
Episode: 7061/30000 (23.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3235s / 97.6970 s
agent0:                 episode reward: -0.3881,                 loss: nan
agent1:                 episode reward: 0.3881,                 loss: 0.2361
Episode: 7081/30000 (23.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3355s / 98.0325 s
agent0:                 episode reward: -0.7967,                 loss: nan
agent1:                 episode reward: 0.7967,                 loss: 0.2328
Episode: 7101/30000 (23.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3376s / 98.3701 s
agent0:                 episode reward: -0.5433,                 loss: nan
agent1:                 episode reward: 0.5433,                 loss: 0.2315
Episode: 7121/30000 (23.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3317s / 98.7018 s
agent0:                 episode reward: -0.9054,                 loss: nan
agent1:                 episode reward: 0.9054,                 loss: 0.2349
Episode: 7141/30000 (23.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3306s / 99.0324 s
agent0:                 episode reward: -0.4686,                 loss: nan
agent1:                 episode reward: 0.4686,                 loss: 0.2350
Episode: 7161/30000 (23.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3309s / 99.3633 s
agent0:                 episode reward: -0.9071,                 loss: nan
agent1:                 episode reward: 0.9071,                 loss: 0.2355
Episode: 7181/30000 (23.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3280s / 99.6913 s
agent0:                 episode reward: -0.4426,                 loss: nan
agent1:                 episode reward: 0.4426,                 loss: 0.2315
Episode: 7201/30000 (24.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3670s / 100.0583 s
agent0:                 episode reward: -1.0558,                 loss: nan
agent1:                 episode reward: 1.0558,                 loss: 0.2337
Episode: 7221/30000 (24.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3322s / 100.3905 s
agent0:                 episode reward: -1.0435,                 loss: nan
agent1:                 episode reward: 1.0435,                 loss: 0.2305
Episode: 7241/30000 (24.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3303s / 100.7208 s
agent0:                 episode reward: -1.1233,                 loss: nan
agent1:                 episode reward: 1.1233,                 loss: 0.2107
Episode: 7261/30000 (24.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3292s / 101.0499 s
agent0:                 episode reward: -0.9653,                 loss: nan
agent1:                 episode reward: 0.9653,                 loss: 0.2154
Episode: 7281/30000 (24.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3427s / 101.3926 s
agent0:                 episode reward: -0.7855,                 loss: nan
agent1:                 episode reward: 0.7855,                 loss: 0.2131
Episode: 7301/30000 (24.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3316s / 101.7242 s
agent0:                 episode reward: -0.9286,                 loss: nan
agent1:                 episode reward: 0.9286,                 loss: 0.2156
Episode: 7321/30000 (24.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3322s / 102.0564 s
agent0:                 episode reward: -0.7215,                 loss: nan
agent1:                 episode reward: 0.7215,                 loss: 0.2152
Episode: 7341/30000 (24.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3333s / 102.3897 s
agent0:                 episode reward: -0.8888,                 loss: nan
agent1:                 episode reward: 0.8888,                 loss: 0.2110
Episode: 7361/30000 (24.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3364s / 102.7261 s
agent0:                 episode reward: -1.0327,                 loss: nan
agent1:                 episode reward: 1.0327,                 loss: 0.2138
Episode: 7381/30000 (24.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3318s / 103.0579 s
agent0:                 episode reward: -0.8557,                 loss: nan
agent1:                 episode reward: 0.8557,                 loss: 0.2122
Episode: 7401/30000 (24.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3314s / 103.3893 s
agent0:                 episode reward: -1.1393,                 loss: nan
agent1:                 episode reward: 1.1393,                 loss: 0.2149
Episode: 7421/30000 (24.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3446s / 103.7339 s
agent0:                 episode reward: -0.9710,                 loss: nan
agent1:                 episode reward: 0.9710,                 loss: 0.2139
Episode: 7441/30000 (24.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3324s / 104.0663 s
agent0:                 episode reward: -0.7651,                 loss: nan
agent1:                 episode reward: 0.7651,                 loss: 0.2148
Episode: 7461/30000 (24.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3421s / 104.4084 s
agent0:                 episode reward: -0.8880,                 loss: nan
agent1:                 episode reward: 0.8880,                 loss: 0.2100
Episode: 7481/30000 (24.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3348s / 104.7432 s
agent0:                 episode reward: -0.5225,                 loss: nan
agent1:                 episode reward: 0.5225,                 loss: 0.2139
Episode: 7501/30000 (25.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3373s / 105.0805 s
agent0:                 episode reward: -0.6175,                 loss: nan
agent1:                 episode reward: 0.6175,                 loss: 0.2151
Episode: 7521/30000 (25.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3363s / 105.4168 s
agent0:                 episode reward: -0.9286,                 loss: nan
agent1:                 episode reward: 0.9286,                 loss: 0.2144
Episode: 7541/30000 (25.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3392s / 105.7560 s
agent0:                 episode reward: -0.7968,                 loss: nan
agent1:                 episode reward: 0.7968,                 loss: 0.2144
Episode: 7561/30000 (25.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3373s / 106.0933 s
agent0:                 episode reward: -0.9093,                 loss: nan
agent1:                 episode reward: 0.9093,                 loss: 0.2310
Episode: 7581/30000 (25.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3792s / 106.4725 s
agent0:                 episode reward: -0.8249,                 loss: nan
agent1:                 episode reward: 0.8249,                 loss: 0.2373
Episode: 7601/30000 (25.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3391s / 106.8116 s
agent0:                 episode reward: -1.3721,                 loss: nan
agent1:                 episode reward: 1.3721,                 loss: 0.2351
Episode: 7621/30000 (25.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3475s / 107.1591 s
agent0:                 episode reward: -0.9726,                 loss: nan
agent1:                 episode reward: 0.9726,                 loss: 0.2395
Episode: 7641/30000 (25.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3481s / 107.5071 s
agent0:                 episode reward: -0.7706,                 loss: nan
agent1:                 episode reward: 0.7706,                 loss: 0.2368
Episode: 7661/30000 (25.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3389s / 107.8460 s
agent0:                 episode reward: -0.9596,                 loss: nan
agent1:                 episode reward: 0.9596,                 loss: 0.2346
Episode: 7681/30000 (25.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3627s / 108.2088 s
agent0:                 episode reward: -0.8920,                 loss: nan
agent1:                 episode reward: 0.8920,                 loss: 0.2355
Episode: 7701/30000 (25.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3403s / 108.5491 s
agent0:                 episode reward: -0.5967,                 loss: nan
agent1:                 episode reward: 0.5967,                 loss: 0.2365
Episode: 7721/30000 (25.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3401s / 108.8892 s
agent0:                 episode reward: -0.7559,                 loss: nan
agent1:                 episode reward: 0.7559,                 loss: 0.2338
Episode: 7741/30000 (25.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3374s / 109.2266 s
agent0:                 episode reward: -0.6799,                 loss: nan
agent1:                 episode reward: 0.6799,                 loss: 0.2365
Episode: 7761/30000 (25.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3406s / 109.5672 s
agent0:                 episode reward: -0.4813,                 loss: nan
agent1:                 episode reward: 0.4813,                 loss: 0.2352
Episode: 7781/30000 (25.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3394s / 109.9065 s
agent0:                 episode reward: -0.8878,                 loss: nan
agent1:                 episode reward: 0.8878,                 loss: 0.2379
Episode: 7801/30000 (26.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3517s / 110.2583 s
agent0:                 episode reward: -0.8177,                 loss: nan
agent1:                 episode reward: 0.8177,                 loss: 0.2395
Episode: 7821/30000 (26.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3434s / 110.6017 s
agent0:                 episode reward: -0.8834,                 loss: nan
agent1:                 episode reward: 0.8834,                 loss: 0.2391
Episode: 7841/30000 (26.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3429s / 110.9445 s
agent0:                 episode reward: -0.7007,                 loss: nan
agent1:                 episode reward: 0.7007,                 loss: 0.2358
Episode: 7861/30000 (26.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3449s / 111.2894 s
agent0:                 episode reward: -0.8579,                 loss: nan
agent1:                 episode reward: 0.8579,                 loss: 0.2347
Episode: 7881/30000 (26.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3441s / 111.6335 s
agent0:                 episode reward: -0.5887,                 loss: nan
agent1:                 episode reward: 0.5887,                 loss: 0.2366
Episode: 7901/30000 (26.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3389s / 111.9724 s
agent0:                 episode reward: -0.8977,                 loss: nan
agent1:                 episode reward: 0.8977,                 loss: 0.2277
Episode: 7921/30000 (26.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3406s / 112.3130 s
agent0:                 episode reward: -0.9651,                 loss: nan
agent1:                 episode reward: 0.9651,                 loss: 0.2330
Episode: 7941/30000 (26.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3461s / 112.6590 s
agent0:                 episode reward: -0.6890,                 loss: nan
agent1:                 episode reward: 0.6890,                 loss: 0.2317
Episode: 7961/30000 (26.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3402s / 112.9992 s
agent0:                 episode reward: -0.8478,                 loss: nan
agent1:                 episode reward: 0.8478,                 loss: 0.2307
Episode: 7981/30000 (26.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3511s / 113.3503 s
agent0:                 episode reward: -0.8897,                 loss: nan
agent1:                 episode reward: 0.8897,                 loss: 0.2324
Episode: 8001/30000 (26.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3416s / 113.6919 s
agent0:                 episode reward: -0.4039,                 loss: nan
agent1:                 episode reward: 0.4039,                 loss: 0.2289
Episode: 8021/30000 (26.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3408s / 114.0328 s
agent0:                 episode reward: -0.6863,                 loss: nan
agent1:                 episode reward: 0.6863,                 loss: 0.2307
Episode: 8041/30000 (26.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3393s / 114.3721 s
agent0:                 episode reward: -0.7389,                 loss: nan
agent1:                 episode reward: 0.7389,                 loss: 0.2277
Episode: 8061/30000 (26.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3425s / 114.7146 s
agent0:                 episode reward: -0.6899,                 loss: nan
agent1:                 episode reward: 0.6899,                 loss: 0.2290
Episode: 8081/30000 (26.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3453s / 115.0599 s
agent0:                 episode reward: -0.6223,                 loss: nan
agent1:                 episode reward: 0.6223,                 loss: 0.2308
Episode: 8101/30000 (27.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3335s / 115.3934 s
agent0:                 episode reward: -0.9215,                 loss: nan
agent1:                 episode reward: 0.9215,                 loss: 0.2330
Episode: 8121/30000 (27.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3400s / 115.7334 s
agent0:                 episode reward: -0.6095,                 loss: nan
agent1:                 episode reward: 0.6095,                 loss: 0.2278
Episode: 8141/30000 (27.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3440s / 116.0774 s
agent0:                 episode reward: -0.4589,                 loss: nan
agent1:                 episode reward: 0.4589,                 loss: 0.2288
Episode: 8161/30000 (27.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3652s / 116.4426 s
agent0:                 episode reward: -0.9915,                 loss: nan
agent1:                 episode reward: 0.9915,                 loss: 0.2314
Episode: 8181/30000 (27.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3940s / 116.8366 s
agent0:                 episode reward: -0.5807,                 loss: nan
agent1:                 episode reward: 0.5807,                 loss: 0.2323
Episode: 8201/30000 (27.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3465s / 117.1831 s
agent0:                 episode reward: -0.9021,                 loss: nan
agent1:                 episode reward: 0.9021,                 loss: 0.2335
Episode: 8221/30000 (27.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3462s / 117.5293 s
agent0:                 episode reward: -0.3165,                 loss: nan
agent1:                 episode reward: 0.3165,                 loss: 0.2349
Episode: 8241/30000 (27.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3413s / 117.8707 s
agent0:                 episode reward: -0.3118,                 loss: nan
agent1:                 episode reward: 0.3118,                 loss: 0.2287
Episode: 8261/30000 (27.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3553s / 118.2260 s
agent0:                 episode reward: -0.9000,                 loss: nan
agent1:                 episode reward: 0.9000,                 loss: 0.2234
Episode: 8281/30000 (27.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3485s / 118.5745 s
agent0:                 episode reward: -0.8679,                 loss: nan
agent1:                 episode reward: 0.8679,                 loss: 0.2246
Episode: 8301/30000 (27.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3439s / 118.9184 s
agent0:                 episode reward: -0.8544,                 loss: nan
agent1:                 episode reward: 0.8544,                 loss: 0.2262
Episode: 8321/30000 (27.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3535s / 119.2719 s
agent0:                 episode reward: -0.8221,                 loss: nan
agent1:                 episode reward: 0.8221,                 loss: 0.2241
Episode: 8341/30000 (27.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3474s / 119.6193 s
agent0:                 episode reward: -0.5142,                 loss: nan
agent1:                 episode reward: 0.5142,                 loss: 0.2249
Episode: 8361/30000 (27.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3461s / 119.9654 s
agent0:                 episode reward: -0.4887,                 loss: nan
agent1:                 episode reward: 0.4887,                 loss: 0.2234
Episode: 8381/30000 (27.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3441s / 120.3095 s
agent0:                 episode reward: -0.8027,                 loss: nan
agent1:                 episode reward: 0.8027,                 loss: 0.2260
Episode: 8401/30000 (28.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3447s / 120.6542 s
agent0:                 episode reward: -0.9875,                 loss: nan
agent1:                 episode reward: 0.9875,                 loss: 0.2227
Episode: 8421/30000 (28.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3451s / 120.9993 s
agent0:                 episode reward: -0.8068,                 loss: nan
agent1:                 episode reward: 0.8068,                 loss: 0.2224
Episode: 8441/30000 (28.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3489s / 121.3482 s
agent0:                 episode reward: -0.6124,                 loss: nan
agent1:                 episode reward: 0.6124,                 loss: 0.2237
Episode: 8461/30000 (28.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3472s / 121.6954 s
agent0:                 episode reward: -0.7390,                 loss: nan
agent1:                 episode reward: 0.7390,                 loss: 0.2254
Episode: 8481/30000 (28.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3490s / 122.0445 s
agent0:                 episode reward: -0.2565,                 loss: nan
agent1:                 episode reward: 0.2565,                 loss: 0.2266
Episode: 8501/30000 (28.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3586s / 122.4030 s
agent0:                 episode reward: -0.7285,                 loss: nan
agent1:                 episode reward: 0.7285,                 loss: 0.2272
Episode: 8521/30000 (28.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3467s / 122.7498 s
agent0:                 episode reward: -0.8046,                 loss: nan
agent1:                 episode reward: 0.8046,                 loss: 0.2224
Episode: 8541/30000 (28.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3477s / 123.0974 s
agent0:                 episode reward: -0.6496,                 loss: nan
agent1:                 episode reward: 0.6496,                 loss: 0.2253
Episode: 8561/30000 (28.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3607s / 123.4581 s
agent0:                 episode reward: -1.1308,                 loss: nan
agent1:                 episode reward: 1.1308,                 loss: 0.2327
Episode: 8581/30000 (28.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3446s / 123.8028 s
agent0:                 episode reward: -0.7745,                 loss: nan
agent1:                 episode reward: 0.7745,                 loss: 0.2368
Episode: 8601/30000 (28.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3426s / 124.1454 s
agent0:                 episode reward: -0.3050,                 loss: nan
agent1:                 episode reward: 0.3050,                 loss: 0.2332
Episode: 8621/30000 (28.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3400s / 124.4853 s
agent0:                 episode reward: -0.7861,                 loss: nan
agent1:                 episode reward: 0.7861,                 loss: 0.2335
Episode: 8641/30000 (28.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3705s / 124.8559 s
agent0:                 episode reward: -0.6615,                 loss: nan
agent1:                 episode reward: 0.6615,                 loss: 0.2357
Episode: 8661/30000 (28.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3854s / 125.2413 s
agent0:                 episode reward: -0.8696,                 loss: nan
agent1:                 episode reward: 0.8696,                 loss: 0.2335
Episode: 8681/30000 (28.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3555s / 125.5968 s
agent0:                 episode reward: -0.7985,                 loss: nan
agent1:                 episode reward: 0.7985,                 loss: 0.2345
Episode: 8701/30000 (29.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3465s / 125.9433 s
agent0:                 episode reward: -0.7259,                 loss: nan
agent1:                 episode reward: 0.7259,                 loss: 0.2356
Episode: 8721/30000 (29.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3471s / 126.2904 s
agent0:                 episode reward: -0.7728,                 loss: nan
agent1:                 episode reward: 0.7728,                 loss: 0.2330
Episode: 8741/30000 (29.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3462s / 126.6366 s
agent0:                 episode reward: -0.7621,                 loss: nan
agent1:                 episode reward: 0.7621,                 loss: 0.2345
Episode: 8761/30000 (29.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4062s / 127.0428 s
agent0:                 episode reward: -0.5055,                 loss: nan
agent1:                 episode reward: 0.5055,                 loss: 0.2346
Episode: 8781/30000 (29.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3524s / 127.3953 s
agent0:                 episode reward: -1.0473,                 loss: nan
agent1:                 episode reward: 1.0473,                 loss: 0.2329
Episode: 8801/30000 (29.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3469s / 127.7422 s
agent0:                 episode reward: -0.5434,                 loss: nan
agent1:                 episode reward: 0.5434,                 loss: 0.2316
Episode: 8821/30000 (29.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3468s / 128.0890 s
agent0:                 episode reward: -0.9763,                 loss: nan
agent1:                 episode reward: 0.9763,                 loss: 0.2337
Episode: 8841/30000 (29.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3657s / 128.4547 s
agent0:                 episode reward: -0.8824,                 loss: nan
agent1:                 episode reward: 0.8824,                 loss: 0.2342
Episode: 8861/30000 (29.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3697s / 128.8244 s
agent0:                 episode reward: -0.8555,                 loss: nan
agent1:                 episode reward: 0.8555,                 loss: 0.2318
Episode: 8881/30000 (29.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3541s / 129.1786 s
agent0:                 episode reward: -0.5887,                 loss: nan
agent1:                 episode reward: 0.5887,                 loss: 0.2327
Episode: 8901/30000 (29.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3466s / 129.5252 s
agent0:                 episode reward: -0.7710,                 loss: nan
agent1:                 episode reward: 0.7710,                 loss: 0.2313
Episode: 8921/30000 (29.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3578s / 129.8830 s
agent0:                 episode reward: -1.2452,                 loss: nan
agent1:                 episode reward: 1.2452,                 loss: 0.2307
Episode: 8941/30000 (29.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3510s / 130.2340 s
agent0:                 episode reward: -0.7814,                 loss: nan
agent1:                 episode reward: 0.7814,                 loss: 0.2323
Episode: 8961/30000 (29.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3465s / 130.5805 s
agent0:                 episode reward: -1.0916,                 loss: nan
agent1:                 episode reward: 1.0916,                 loss: 0.2284
Episode: 8981/30000 (29.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3468s / 130.9274 s
agent0:                 episode reward: -0.7975,                 loss: nan
agent1:                 episode reward: 0.7975,                 loss: 0.2320
Episode: 9001/30000 (30.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3588s / 131.2862 s
agent0:                 episode reward: -0.7724,                 loss: nan
agent1:                 episode reward: 0.7724,                 loss: 0.2308
Episode: 9021/30000 (30.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3550s / 131.6412 s
agent0:                 episode reward: -0.7783,                 loss: nan
agent1:                 episode reward: 0.7783,                 loss: 0.2310
Episode: 9041/30000 (30.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3563s / 131.9975 s
agent0:                 episode reward: -0.8227,                 loss: nan
agent1:                 episode reward: 0.8227,                 loss: 0.2295
Episode: 9061/30000 (30.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3538s / 132.3513 s
agent0:                 episode reward: -0.6909,                 loss: nan
agent1:                 episode reward: 0.6909,                 loss: 0.2327
Episode: 9081/30000 (30.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3521s / 132.7034 s
agent0:                 episode reward: -0.8748,                 loss: nan
agent1:                 episode reward: 0.8748,                 loss: 0.2332
Episode: 9101/30000 (30.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3743s / 133.0777 s
agent0:                 episode reward: -0.7023,                 loss: nan
agent1:                 episode reward: 0.7023,                 loss: 0.2298
Episode: 9121/30000 (30.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3707s / 133.4484 s
agent0:                 episode reward: -0.8950,                 loss: nan
agent1:                 episode reward: 0.8950,                 loss: 0.2296
Episode: 9141/30000 (30.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3564s / 133.8048 s
agent0:                 episode reward: -0.9394,                 loss: nan
agent1:                 episode reward: 0.9394,                 loss: 0.2311
Episode: 9161/30000 (30.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3491s / 134.1539 s
agent0:                 episode reward: -0.6234,                 loss: nan
agent1:                 episode reward: 0.6234,                 loss: 0.2314
Episode: 9181/30000 (30.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3608s / 134.5147 s
agent0:                 episode reward: -0.9307,                 loss: nan
agent1:                 episode reward: 0.9307,                 loss: 0.2287
Episode: 9201/30000 (30.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3518s / 134.8665 s
agent0:                 episode reward: -0.5086,                 loss: nan
agent1:                 episode reward: 0.5086,                 loss: 0.2324
Episode: 9221/30000 (30.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3545s / 135.2210 s
agent0:                 episode reward: -0.8277,                 loss: nan
agent1:                 episode reward: 0.8277,                 loss: 0.2313
Episode: 9241/30000 (30.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3486s / 135.5696 s
agent0:                 episode reward: -0.9000,                 loss: nan
agent1:                 episode reward: 0.9000,                 loss: 0.2342
Episode: 9261/30000 (30.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3553s / 135.9249 s
agent0:                 episode reward: -1.0284,                 loss: nan
agent1:                 episode reward: 1.0284,                 loss: 0.2334
Episode: 9281/30000 (30.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3544s / 136.2794 s
agent0:                 episode reward: -0.7714,                 loss: nan
agent1:                 episode reward: 0.7714,                 loss: 0.2340
Episode: 9301/30000 (31.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3515s / 136.6309 s
agent0:                 episode reward: -0.6634,                 loss: nan
agent1:                 episode reward: 0.6634,                 loss: 0.2371
Episode: 9321/30000 (31.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3806s / 137.0115 s
agent0:                 episode reward: -0.9854,                 loss: nan
agent1:                 episode reward: 0.9854,                 loss: 0.2363
Episode: 9341/30000 (31.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4347s / 137.4462 s
agent0:                 episode reward: -0.6304,                 loss: nan
agent1:                 episode reward: 0.6304,                 loss: 0.2350
Episode: 9361/30000 (31.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3605s / 137.8067 s
agent0:                 episode reward: -0.4487,                 loss: nan
agent1:                 episode reward: 0.4487,                 loss: 0.2359
Episode: 9381/30000 (31.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3517s / 138.1584 s
agent0:                 episode reward: -0.4071,                 loss: nan
agent1:                 episode reward: 0.4071,                 loss: 0.2400
Episode: 9401/30000 (31.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3634s / 138.5218 s
agent0:                 episode reward: -0.8859,                 loss: nan
agent1:                 episode reward: 0.8859,                 loss: 0.2361
Episode: 9421/30000 (31.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3570s / 138.8788 s
agent0:                 episode reward: -0.9046,                 loss: nan
agent1:                 episode reward: 0.9046,                 loss: 0.2360
Episode: 9441/30000 (31.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3530s / 139.2318 s
agent0:                 episode reward: -0.8493,                 loss: nan
agent1:                 episode reward: 0.8493,                 loss: 0.2348
Episode: 9461/30000 (31.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3593s / 139.5911 s
agent0:                 episode reward: -0.9498,                 loss: nan
agent1:                 episode reward: 0.9498,                 loss: 0.2357
Episode: 9481/30000 (31.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3564s / 139.9475 s
agent0:                 episode reward: -0.9410,                 loss: nan
agent1:                 episode reward: 0.9410,                 loss: 0.2349
Episode: 9501/30000 (31.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3578s / 140.3052 s
agent0:                 episode reward: -0.6879,                 loss: nan
agent1:                 episode reward: 0.6879,                 loss: 0.2359
Episode: 9521/30000 (31.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3578s / 140.6630 s
agent0:                 episode reward: -0.9567,                 loss: nan
agent1:                 episode reward: 0.9567,                 loss: 0.2374
Episode: 9541/30000 (31.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3578s / 141.0207 s
agent0:                 episode reward: -0.7164,                 loss: nan
agent1:                 episode reward: 0.7164,                 loss: 0.2340
Episode: 9561/30000 (31.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3727s / 141.3934 s
agent0:                 episode reward: -0.5859,                 loss: nan
agent1:                 episode reward: 0.5859,                 loss: 0.2418
Episode: 9581/30000 (31.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3583s / 141.7517 s
agent0:                 episode reward: -0.9618,                 loss: nan
agent1:                 episode reward: 0.9618,                 loss: 0.2426
Episode: 9601/30000 (32.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3549s / 142.1067 s
agent0:                 episode reward: -0.9041,                 loss: nan
agent1:                 episode reward: 0.9041,                 loss: 0.2462
Episode: 9621/30000 (32.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3584s / 142.4651 s
agent0:                 episode reward: -0.8293,                 loss: nan
agent1:                 episode reward: 0.8293,                 loss: 0.2473
Episode: 9641/30000 (32.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3595s / 142.8245 s
agent0:                 episode reward: -0.6802,                 loss: nan
agent1:                 episode reward: 0.6802,                 loss: 0.2419
Episode: 9661/30000 (32.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3568s / 143.1813 s
agent0:                 episode reward: -1.0212,                 loss: nan
agent1:                 episode reward: 1.0212,                 loss: 0.2434
Episode: 9681/30000 (32.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3906s / 143.5719 s
agent0:                 episode reward: -0.7041,                 loss: nan
agent1:                 episode reward: 0.7041,                 loss: 0.2425
Episode: 9701/30000 (32.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3595s / 143.9314 s
agent0:                 episode reward: -0.7724,                 loss: nan
agent1:                 episode reward: 0.7724,                 loss: 0.2412
Episode: 9721/30000 (32.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3898s / 144.3212 s
agent0:                 episode reward: -1.0198,                 loss: nan
agent1:                 episode reward: 1.0198,                 loss: 0.2460
Episode: 9741/30000 (32.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3605s / 144.6817 s
agent0:                 episode reward: -0.7067,                 loss: nan
agent1:                 episode reward: 0.7067,                 loss: 0.2408
Episode: 9761/30000 (32.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3602s / 145.0419 s
agent0:                 episode reward: -0.8395,                 loss: nan
agent1:                 episode reward: 0.8395,                 loss: 0.2473
Episode: 9781/30000 (32.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3621s / 145.4041 s
agent0:                 episode reward: -0.8647,                 loss: nan
agent1:                 episode reward: 0.8647,                 loss: 0.2453
Episode: 9801/30000 (32.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3595s / 145.7636 s
agent0:                 episode reward: -0.9848,                 loss: nan
agent1:                 episode reward: 0.9848,                 loss: 0.2444
Episode: 9821/30000 (32.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3623s / 146.1259 s
agent0:                 episode reward: -0.4741,                 loss: nan
agent1:                 episode reward: 0.4741,                 loss: 0.2442
Episode: 9841/30000 (32.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3734s / 146.4993 s
agent0:                 episode reward: -0.7708,                 loss: nan
agent1:                 episode reward: 0.7708,                 loss: 0.2439
Episode: 9861/30000 (32.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3594s / 146.8587 s
agent0:                 episode reward: -0.3461,                 loss: nan
agent1:                 episode reward: 0.3461,                 loss: 0.2410
Episode: 9881/30000 (32.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3582s / 147.2169 s
agent0:                 episode reward: -0.5923,                 loss: nan
agent1:                 episode reward: 0.5923,                 loss: 0.2433
Episode: 9901/30000 (33.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4147s / 147.6316 s
agent0:                 episode reward: -0.9319,                 loss: nan
agent1:                 episode reward: 0.9319,                 loss: 0.2313
Episode: 9921/30000 (33.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3626s / 147.9942 s
agent0:                 episode reward: -0.7279,                 loss: nan
agent1:                 episode reward: 0.7279,                 loss: 0.2368
Episode: 9941/30000 (33.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3605s / 148.3547 s
agent0:                 episode reward: -0.6995,                 loss: nan
agent1:                 episode reward: 0.6995,                 loss: 0.2278
Episode: 9961/30000 (33.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3753s / 148.7300 s
agent0:                 episode reward: -1.0355,                 loss: nan
agent1:                 episode reward: 1.0355,                 loss: 0.2324
Episode: 9981/30000 (33.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3609s / 149.0909 s
agent0:                 episode reward: -0.6938,                 loss: nan
agent1:                 episode reward: 0.6938,                 loss: 0.2350
Episode: 10001/30000 (33.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3759s / 149.4668 s
agent0:                 episode reward: -0.7980,                 loss: nan
agent1:                 episode reward: 0.7980,                 loss: 0.2355
Episode: 10021/30000 (33.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3851s / 149.8518 s
agent0:                 episode reward: -0.8817,                 loss: nan
agent1:                 episode reward: 0.8817,                 loss: 0.2331
Episode: 10041/30000 (33.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3635s / 150.2153 s
agent0:                 episode reward: -0.9764,                 loss: nan
agent1:                 episode reward: 0.9764,                 loss: 0.2323
Episode: 10061/30000 (33.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4079s / 150.6232 s
agent0:                 episode reward: -0.8231,                 loss: nan
agent1:                 episode reward: 0.8231,                 loss: 0.2334
Episode: 10081/30000 (33.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3652s / 150.9884 s
agent0:                 episode reward: -0.8451,                 loss: nan
agent1:                 episode reward: 0.8451,                 loss: 0.2327
Episode: 10101/30000 (33.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3617s / 151.3502 s
agent0:                 episode reward: -0.9172,                 loss: nan
agent1:                 episode reward: 0.9172,                 loss: 0.2319
Episode: 10121/30000 (33.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3885s / 151.7386 s
agent0:                 episode reward: -0.5990,                 loss: nan
agent1:                 episode reward: 0.5990,                 loss: 0.2287
Episode: 10141/30000 (33.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3619s / 152.1005 s
agent0:                 episode reward: -0.8891,                 loss: nan
agent1:                 episode reward: 0.8891,                 loss: 0.2339
Episode: 10161/30000 (33.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3776s / 152.4781 s
agent0:                 episode reward: -0.7703,                 loss: nan
agent1:                 episode reward: 0.7703,                 loss: 0.2325
Episode: 10181/30000 (33.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3663s / 152.8443 s
agent0:                 episode reward: -0.8485,                 loss: nan
agent1:                 episode reward: 0.8485,                 loss: 0.2307
Episode: 10201/30000 (34.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3687s / 153.2130 s
agent0:                 episode reward: -0.8648,                 loss: nan
agent1:                 episode reward: 0.8648,                 loss: 0.2341
Episode: 10221/30000 (34.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3636s / 153.5766 s
agent0:                 episode reward: -0.9166,                 loss: nan
agent1:                 episode reward: 0.9166,                 loss: 0.2330
Episode: 10241/30000 (34.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3692s / 153.9458 s
agent0:                 episode reward: -0.9532,                 loss: nan
agent1:                 episode reward: 0.9532,                 loss: 0.2296
Episode: 10261/30000 (34.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3848s / 154.3306 s
agent0:                 episode reward: -0.8943,                 loss: nan
agent1:                 episode reward: 0.8943,                 loss: 0.2304
Episode: 10281/30000 (34.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4079s / 154.7385 s
agent0:                 episode reward: -0.9683,                 loss: nan
agent1:                 episode reward: 0.9683,                 loss: 0.2304
Episode: 10301/30000 (34.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3842s / 155.1227 s
agent0:                 episode reward: -0.8546,                 loss: nan
agent1:                 episode reward: 0.8546,                 loss: 0.2335
Episode: 10321/30000 (34.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3738s / 155.4965 s
agent0:                 episode reward: -0.8551,                 loss: nan
agent1:                 episode reward: 0.8551,                 loss: 0.2293
Episode: 10341/30000 (34.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3690s / 155.8655 s
agent0:                 episode reward: -0.8989,                 loss: nan
agent1:                 episode reward: 0.8989,                 loss: 0.2342
Episode: 10361/30000 (34.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3721s / 156.2376 s
agent0:                 episode reward: -0.5749,                 loss: nan
agent1:                 episode reward: 0.5749,                 loss: 0.2273
Episode: 10381/30000 (34.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3733s / 156.6109 s
agent0:                 episode reward: -0.7504,                 loss: nan
agent1:                 episode reward: 0.7504,                 loss: 0.2306
Episode: 10401/30000 (34.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3711s / 156.9819 s
agent0:                 episode reward: -0.8664,                 loss: nan
agent1:                 episode reward: 0.8664,                 loss: 0.2333
Episode: 10421/30000 (34.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3693s / 157.3512 s
agent0:                 episode reward: -0.8096,                 loss: nan
agent1:                 episode reward: 0.8096,                 loss: 0.2327
Episode: 10441/30000 (34.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4426s / 157.7938 s
agent0:                 episode reward: -1.0447,                 loss: nan
agent1:                 episode reward: 1.0447,                 loss: 0.2314
Episode: 10461/30000 (34.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3748s / 158.1685 s
agent0:                 episode reward: -0.9965,                 loss: nan
agent1:                 episode reward: 0.9965,                 loss: 0.2345
Episode: 10481/30000 (34.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3839s / 158.5525 s
agent0:                 episode reward: -0.6841,                 loss: nan
agent1:                 episode reward: 0.6841,                 loss: 0.2291
Episode: 10501/30000 (35.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3866s / 158.9391 s
agent0:                 episode reward: -1.1107,                 loss: nan
agent1:                 episode reward: 1.1107,                 loss: 0.2300
Episode: 10521/30000 (35.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3763s / 159.3154 s
agent0:                 episode reward: -0.6667,                 loss: nan
agent1:                 episode reward: 0.6667,                 loss: 0.2292
Episode: 10541/30000 (35.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3708s / 159.6862 s
agent0:                 episode reward: -0.9559,                 loss: nan
agent1:                 episode reward: 0.9559,                 loss: 0.2353
Episode: 10561/30000 (35.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3660s / 160.0522 s
agent0:                 episode reward: -0.7902,                 loss: nan
agent1:                 episode reward: 0.7902,                 loss: 0.2510
Episode: 10581/30000 (35.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3672s / 160.4194 s
agent0:                 episode reward: -0.4755,                 loss: nan
agent1:                 episode reward: 0.4755,                 loss: 0.2557
Episode: 10601/30000 (35.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3714s / 160.7907 s
agent0:                 episode reward: -0.8131,                 loss: nan
agent1:                 episode reward: 0.8131,                 loss: 0.2504
Episode: 10621/30000 (35.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3720s / 161.1627 s
agent0:                 episode reward: -0.9596,                 loss: nan
agent1:                 episode reward: 0.9596,                 loss: 0.2523
Episode: 10641/30000 (35.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3968s / 161.5595 s
agent0:                 episode reward: -1.1005,                 loss: nan
agent1:                 episode reward: 1.1005,                 loss: 0.2534
Episode: 10661/30000 (35.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3796s / 161.9391 s
agent0:                 episode reward: -0.8673,                 loss: nan
agent1:                 episode reward: 0.8673,                 loss: 0.2531
Episode: 10681/30000 (35.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3709s / 162.3100 s
agent0:                 episode reward: -0.8748,                 loss: nan
agent1:                 episode reward: 0.8748,                 loss: 0.2523
Episode: 10701/30000 (35.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3778s / 162.6879 s
agent0:                 episode reward: -0.8033,                 loss: nan
agent1:                 episode reward: 0.8033,                 loss: 0.2541
Episode: 10721/30000 (35.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4069s / 163.0947 s
agent0:                 episode reward: -0.1982,                 loss: nan
agent1:                 episode reward: 0.1982,                 loss: 0.2484
Episode: 10741/30000 (35.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4048s / 163.4995 s
agent0:                 episode reward: -0.6211,                 loss: nan
agent1:                 episode reward: 0.6211,                 loss: 0.2507
Episode: 10761/30000 (35.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3686s / 163.8681 s
agent0:                 episode reward: -0.8044,                 loss: nan
agent1:                 episode reward: 0.8044,                 loss: 0.2553
Episode: 10781/30000 (35.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3771s / 164.2451 s
agent0:                 episode reward: -0.7542,                 loss: nan
agent1:                 episode reward: 0.7542,                 loss: 0.2528
Episode: 10801/30000 (36.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3746s / 164.6197 s
agent0:                 episode reward: -0.7803,                 loss: nan
agent1:                 episode reward: 0.7803,                 loss: 0.2555
Episode: 10821/30000 (36.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3758s / 164.9955 s
agent0:                 episode reward: -0.4980,                 loss: nan
agent1:                 episode reward: 0.4980,                 loss: 0.2495
Episode: 10841/30000 (36.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3763s / 165.3718 s
agent0:                 episode reward: -0.8835,                 loss: nan
agent1:                 episode reward: 0.8835,                 loss: 0.2539
Episode: 10861/30000 (36.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3744s / 165.7462 s
agent0:                 episode reward: -0.8387,                 loss: nan
agent1:                 episode reward: 0.8387,                 loss: 0.2569
Episode: 10881/30000 (36.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3959s / 166.1421 s
agent0:                 episode reward: -0.9681,                 loss: nan
agent1:                 episode reward: 0.9681,                 loss: 0.2530
Episode: 10901/30000 (36.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3770s / 166.5191 s
agent0:                 episode reward: -0.8652,                 loss: nan
agent1:                 episode reward: 0.8652,                 loss: 0.2323
Episode: 10921/30000 (36.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3809s / 166.9001 s
agent0:                 episode reward: -0.7601,                 loss: nan
agent1:                 episode reward: 0.7601,                 loss: 0.2315
Episode: 10941/30000 (36.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3863s / 167.2864 s
agent0:                 episode reward: -0.9677,                 loss: nan
agent1:                 episode reward: 0.9677,                 loss: 0.2278
Episode: 10961/30000 (36.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3759s / 167.6624 s
agent0:                 episode reward: -0.7248,                 loss: nan
agent1:                 episode reward: 0.7248,                 loss: 0.2308
Episode: 10981/30000 (36.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4202s / 168.0826 s
agent0:                 episode reward: -0.7940,                 loss: nan
agent1:                 episode reward: 0.7940,                 loss: 0.2324
Episode: 11001/30000 (36.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3793s / 168.4619 s
agent0:                 episode reward: -0.5999,                 loss: nan
agent1:                 episode reward: 0.5999,                 loss: 0.2314
Episode: 11021/30000 (36.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3811s / 168.8430 s
agent0:                 episode reward: -0.3561,                 loss: nan
agent1:                 episode reward: 0.3561,                 loss: 0.2320
Episode: 11041/30000 (36.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3765s / 169.2195 s
agent0:                 episode reward: -0.7280,                 loss: nan
agent1:                 episode reward: 0.7280,                 loss: 0.2297
Episode: 11061/30000 (36.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3811s / 169.6006 s
agent0:                 episode reward: -1.1621,                 loss: nan
agent1:                 episode reward: 1.1621,                 loss: 0.2250
Episode: 11081/30000 (36.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3799s / 169.9805 s
agent0:                 episode reward: -0.7292,                 loss: nan
agent1:                 episode reward: 0.7292,                 loss: 0.2292
Episode: 11101/30000 (37.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3848s / 170.3653 s
agent0:                 episode reward: -1.0070,                 loss: nan
agent1:                 episode reward: 1.0070,                 loss: 0.2249
Episode: 11121/30000 (37.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3791s / 170.7444 s
agent0:                 episode reward: -0.9254,                 loss: nan
agent1:                 episode reward: 0.9254,                 loss: 0.2293
Episode: 11141/30000 (37.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4043s / 171.1487 s
agent0:                 episode reward: -1.0530,                 loss: nan
agent1:                 episode reward: 1.0530,                 loss: 0.2281
Episode: 11161/30000 (37.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3835s / 171.5322 s
agent0:                 episode reward: -0.6740,                 loss: nan
agent1:                 episode reward: 0.6740,                 loss: 0.2282
Episode: 11181/30000 (37.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3784s / 171.9106 s
agent0:                 episode reward: -1.2934,                 loss: nan
agent1:                 episode reward: 1.2934,                 loss: 0.2298
Episode: 11201/30000 (37.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3737s / 172.2843 s
agent0:                 episode reward: -0.9044,                 loss: nan
agent1:                 episode reward: 0.9044,                 loss: 0.2311
Episode: 11221/30000 (37.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3782s / 172.6625 s
agent0:                 episode reward: -0.5262,                 loss: nan
agent1:                 episode reward: 0.5262,                 loss: 0.2357
Episode: 11241/30000 (37.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3786s / 173.0410 s
agent0:                 episode reward: -0.8811,                 loss: nan
agent1:                 episode reward: 0.8811,                 loss: 0.2367
Episode: 11261/30000 (37.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4147s / 173.4557 s
agent0:                 episode reward: -0.9154,                 loss: nan
agent1:                 episode reward: 0.9154,                 loss: 0.2298
Episode: 11281/30000 (37.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3771s / 173.8328 s
agent0:                 episode reward: -0.7968,                 loss: nan
agent1:                 episode reward: 0.7968,                 loss: 0.2349
Episode: 11301/30000 (37.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3868s / 174.2196 s
agent0:                 episode reward: -1.0558,                 loss: nan
agent1:                 episode reward: 1.0558,                 loss: 0.2349
Episode: 11321/30000 (37.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4102s / 174.6298 s
agent0:                 episode reward: -0.7866,                 loss: nan
agent1:                 episode reward: 0.7866,                 loss: 0.2395
Episode: 11341/30000 (37.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3808s / 175.0106 s
agent0:                 episode reward: -0.7482,                 loss: nan
agent1:                 episode reward: 0.7482,                 loss: 0.2314
Episode: 11361/30000 (37.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3805s / 175.3910 s
agent0:                 episode reward: -0.8151,                 loss: nan
agent1:                 episode reward: 0.8151,                 loss: 0.2352
Episode: 11381/30000 (37.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3812s / 175.7722 s
agent0:                 episode reward: -0.8681,                 loss: nan
agent1:                 episode reward: 0.8681,                 loss: 0.2317
Episode: 11401/30000 (38.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3877s / 176.1599 s
agent0:                 episode reward: -1.0517,                 loss: nan
agent1:                 episode reward: 1.0517,                 loss: 0.2359
Episode: 11421/30000 (38.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4095s / 176.5694 s
agent0:                 episode reward: -0.8407,                 loss: nan
agent1:                 episode reward: 0.8407,                 loss: 0.2357
Episode: 11441/30000 (38.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3825s / 176.9519 s
agent0:                 episode reward: -0.9019,                 loss: nan
agent1:                 episode reward: 0.9019,                 loss: 0.2315
Episode: 11461/30000 (38.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3777s / 177.3296 s
agent0:                 episode reward: -0.7777,                 loss: nan
agent1:                 episode reward: 0.7777,                 loss: 0.2362
Episode: 11481/30000 (38.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3820s / 177.7116 s
agent0:                 episode reward: -0.4739,                 loss: nan
agent1:                 episode reward: 0.4739,                 loss: 0.2354
Episode: 11501/30000 (38.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4220s / 178.1336 s
agent0:                 episode reward: -0.7879,                 loss: nan
agent1:                 episode reward: 0.7879,                 loss: 0.2376
Episode: 11521/30000 (38.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4150s / 178.5487 s
agent0:                 episode reward: -0.7314,                 loss: nan
agent1:                 episode reward: 0.7314,                 loss: 0.2372
Episode: 11541/30000 (38.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3862s / 178.9348 s
agent0:                 episode reward: -0.9084,                 loss: nan
agent1:                 episode reward: 0.9084,                 loss: 0.2317
Episode: 11561/30000 (38.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4026s / 179.3374 s
agent0:                 episode reward: -0.8457,                 loss: nan
agent1:                 episode reward: 0.8457,                 loss: 0.2523
Episode: 11581/30000 (38.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3890s / 179.7264 s
agent0:                 episode reward: -0.6337,                 loss: nan
agent1:                 episode reward: 0.6337,                 loss: 0.2525
Episode: 11601/30000 (38.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3861s / 180.1124 s
agent0:                 episode reward: -1.0542,                 loss: nan
agent1:                 episode reward: 1.0542,                 loss: 0.2557
Episode: 11621/30000 (38.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3928s / 180.5052 s
agent0:                 episode reward: -0.8503,                 loss: nan
agent1:                 episode reward: 0.8503,                 loss: 0.2596
Episode: 11641/30000 (38.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3894s / 180.8946 s
agent0:                 episode reward: -0.9166,                 loss: nan
agent1:                 episode reward: 0.9166,                 loss: 0.2545
Episode: 11661/30000 (38.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3849s / 181.2794 s
agent0:                 episode reward: -0.7575,                 loss: nan
agent1:                 episode reward: 0.7575,                 loss: 0.2552
Episode: 11681/30000 (38.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3866s / 181.6660 s
agent0:                 episode reward: -0.9682,                 loss: nan
agent1:                 episode reward: 0.9682,                 loss: 0.2518
Episode: 11701/30000 (39.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3817s / 182.0477 s
agent0:                 episode reward: -0.6752,                 loss: nan
agent1:                 episode reward: 0.6752,                 loss: 0.2569
Episode: 11721/30000 (39.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4144s / 182.4621 s
agent0:                 episode reward: -0.5507,                 loss: nan
agent1:                 episode reward: 0.5507,                 loss: 0.2526
Episode: 11741/30000 (39.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4004s / 182.8626 s
agent0:                 episode reward: -0.9180,                 loss: nan
agent1:                 episode reward: 0.9180,                 loss: 0.2546
Episode: 11761/30000 (39.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3899s / 183.2524 s
agent0:                 episode reward: -0.6548,                 loss: nan
agent1:                 episode reward: 0.6548,                 loss: 0.2546
Episode: 11781/30000 (39.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3863s / 183.6387 s
agent0:                 episode reward: -0.7115,                 loss: nan
agent1:                 episode reward: 0.7115,                 loss: 0.2532
Episode: 11801/30000 (39.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3880s / 184.0266 s
agent0:                 episode reward: -1.0340,                 loss: nan
agent1:                 episode reward: 1.0340,                 loss: 0.2560
Episode: 11821/30000 (39.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3886s / 184.4152 s
agent0:                 episode reward: -0.7968,                 loss: nan
agent1:                 episode reward: 0.7968,                 loss: 0.2591
Episode: 11841/30000 (39.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4028s / 184.8180 s
agent0:                 episode reward: -0.8484,                 loss: nan
agent1:                 episode reward: 0.8484,                 loss: 0.2552
Episode: 11861/30000 (39.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3808s / 185.1987 s
agent0:                 episode reward: -0.9818,                 loss: nan
agent1:                 episode reward: 0.9818,                 loss: 0.2543
Episode: 11881/30000 (39.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3985s / 185.5972 s
agent0:                 episode reward: -0.6063,                 loss: nan
agent1:                 episode reward: 0.6063,                 loss: 0.2522
Episode: 11901/30000 (39.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3832s / 185.9804 s
agent0:                 episode reward: -0.7350,                 loss: nan
agent1:                 episode reward: 0.7350,                 loss: 0.2330
Episode: 11921/30000 (39.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3868s / 186.3672 s
agent0:                 episode reward: -0.6989,                 loss: nan
agent1:                 episode reward: 0.6989,                 loss: 0.2345
Episode: 11941/30000 (39.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3976s / 186.7648 s
agent0:                 episode reward: -1.0116,                 loss: nan
agent1:                 episode reward: 1.0116,                 loss: 0.2327
Episode: 11961/30000 (39.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3892s / 187.1540 s
agent0:                 episode reward: -0.8636,                 loss: nan
agent1:                 episode reward: 0.8636,                 loss: 0.2352
Episode: 11981/30000 (39.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3976s / 187.5516 s
agent0:                 episode reward: -0.7087,                 loss: nan
agent1:                 episode reward: 0.7087,                 loss: 0.2343
Episode: 12001/30000 (40.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4096s / 187.9612 s
agent0:                 episode reward: -1.2774,                 loss: nan
agent1:                 episode reward: 1.2774,                 loss: 0.2348
Episode: 12021/30000 (40.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4504s / 188.4115 s
agent0:                 episode reward: -0.6523,                 loss: nan
agent1:                 episode reward: 0.6523,                 loss: 0.2332
Episode: 12041/30000 (40.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3985s / 188.8100 s
agent0:                 episode reward: -1.1549,                 loss: nan
agent1:                 episode reward: 1.1549,                 loss: 0.2310
Episode: 12061/30000 (40.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4001s / 189.2101 s
agent0:                 episode reward: -0.8408,                 loss: nan
agent1:                 episode reward: 0.8408,                 loss: 0.2311
Episode: 12081/30000 (40.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3952s / 189.6053 s
agent0:                 episode reward: -0.8155,                 loss: nan
agent1:                 episode reward: 0.8155,                 loss: 0.2353
Episode: 12101/30000 (40.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3915s / 189.9968 s
agent0:                 episode reward: -0.7262,                 loss: nan
agent1:                 episode reward: 0.7262,                 loss: 0.2340
Episode: 12121/30000 (40.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3971s / 190.3938 s
agent0:                 episode reward: -0.7753,                 loss: nan
agent1:                 episode reward: 0.7753,                 loss: 0.2300
Episode: 12141/30000 (40.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3960s / 190.7898 s
agent0:                 episode reward: -1.1555,                 loss: nan
agent1:                 episode reward: 1.1555,                 loss: 0.2339
Episode: 12161/30000 (40.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4208s / 191.2106 s
agent0:                 episode reward: -0.6485,                 loss: nan
agent1:                 episode reward: 0.6485,                 loss: 0.2376
Episode: 12181/30000 (40.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4027s / 191.6133 s
agent0:                 episode reward: -0.8687,                 loss: nan
agent1:                 episode reward: 0.8687,                 loss: 0.2303
Episode: 12201/30000 (40.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3994s / 192.0127 s
agent0:                 episode reward: -0.9145,                 loss: nan
agent1:                 episode reward: 0.9145,                 loss: 0.2351
Episode: 12221/30000 (40.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4003s / 192.4129 s
agent0:                 episode reward: -0.8252,                 loss: nan
agent1:                 episode reward: 0.8252,                 loss: 0.2369
Episode: 12241/30000 (40.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3979s / 192.8108 s
agent0:                 episode reward: -0.9941,                 loss: nan
agent1:                 episode reward: 0.9941,                 loss: 0.2465
Episode: 12261/30000 (40.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4021s / 193.2129 s
agent0:                 episode reward: -0.7699,                 loss: nan
agent1:                 episode reward: 0.7699,                 loss: 0.2493
Episode: 12281/30000 (40.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4004s / 193.6132 s
agent0:                 episode reward: -1.0175,                 loss: nan
agent1:                 episode reward: 1.0175,                 loss: 0.2485
Episode: 12301/30000 (41.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4018s / 194.0150 s
agent0:                 episode reward: -0.9094,                 loss: nan
agent1:                 episode reward: 0.9094,                 loss: 0.2482
Episode: 12321/30000 (41.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4096s / 194.4246 s
agent0:                 episode reward: -0.7041,                 loss: nan
agent1:                 episode reward: 0.7041,                 loss: 0.2453
Episode: 12341/30000 (41.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3959s / 194.8206 s
agent0:                 episode reward: -0.4553,                 loss: nan
agent1:                 episode reward: 0.4553,                 loss: 0.2487
Episode: 12361/30000 (41.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3996s / 195.2202 s
agent0:                 episode reward: -0.7068,                 loss: nan
agent1:                 episode reward: 0.7068,                 loss: 0.2507
Episode: 12381/30000 (41.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3955s / 195.6157 s
agent0:                 episode reward: -1.0795,                 loss: nan
agent1:                 episode reward: 1.0795,                 loss: 0.2463
Episode: 12401/30000 (41.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4003s / 196.0160 s
agent0:                 episode reward: -0.9586,                 loss: nan
agent1:                 episode reward: 0.9586,                 loss: 0.2484
Episode: 12421/30000 (41.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3940s / 196.4100 s
agent0:                 episode reward: -0.9926,                 loss: nan
agent1:                 episode reward: 0.9926,                 loss: 0.2466
Episode: 12441/30000 (41.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4043s / 196.8143 s
agent0:                 episode reward: -0.8983,                 loss: nan
agent1:                 episode reward: 0.8983,                 loss: 0.2465
Episode: 12461/30000 (41.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4062s / 197.2205 s
agent0:                 episode reward: -0.8397,                 loss: nan
agent1:                 episode reward: 0.8397,                 loss: 0.2499
Episode: 12481/30000 (41.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4239s / 197.6444 s
agent0:                 episode reward: -0.9870,                 loss: nan
agent1:                 episode reward: 0.9870,                 loss: 0.2504
Episode: 12501/30000 (41.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3926s / 198.0370 s
agent0:                 episode reward: -0.6743,                 loss: nan
agent1:                 episode reward: 0.6743,                 loss: 0.2529
Episode: 12521/30000 (41.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4069s / 198.4439 s
agent0:                 episode reward: -0.5859,                 loss: nan
agent1:                 episode reward: 0.5859,                 loss: 0.2469
Episode: 12541/30000 (41.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4575s / 198.9015 s
agent0:                 episode reward: -0.6583,                 loss: nan
agent1:                 episode reward: 0.6583,                 loss: 0.2477
Episode: 12561/30000 (41.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4261s / 199.3275 s
agent0:                 episode reward: -0.7677,                 loss: nan
agent1:                 episode reward: 0.7677,                 loss: 0.2389
Episode: 12581/30000 (41.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4022s / 199.7298 s
agent0:                 episode reward: -0.7433,                 loss: nan
agent1:                 episode reward: 0.7433,                 loss: 0.2392
Episode: 12601/30000 (42.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3982s / 200.1280 s
agent0:                 episode reward: -0.5974,                 loss: nan
agent1:                 episode reward: 0.5974,                 loss: 0.2359
Episode: 12621/30000 (42.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4074s / 200.5354 s
agent0:                 episode reward: -0.9074,                 loss: nan
agent1:                 episode reward: 0.9074,                 loss: 0.2358
Episode: 12641/30000 (42.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4072s / 200.9426 s
agent0:                 episode reward: -0.6089,                 loss: nan
agent1:                 episode reward: 0.6089,                 loss: 0.2393
Episode: 12661/30000 (42.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4005s / 201.3432 s
agent0:                 episode reward: -0.8173,                 loss: nan
agent1:                 episode reward: 0.8173,                 loss: 0.2400
Episode: 12681/30000 (42.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4099s / 201.7531 s
agent0:                 episode reward: -0.7406,                 loss: nan
agent1:                 episode reward: 0.7406,                 loss: 0.2373
Episode: 12701/30000 (42.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4034s / 202.1564 s
agent0:                 episode reward: -0.3739,                 loss: nan
agent1:                 episode reward: 0.3739,                 loss: 0.2346
Episode: 12721/30000 (42.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4046s / 202.5610 s
agent0:                 episode reward: -0.9072,                 loss: nan
agent1:                 episode reward: 0.9072,                 loss: 0.2404
Episode: 12741/30000 (42.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4014s / 202.9624 s
agent0:                 episode reward: -1.0527,                 loss: nan
agent1:                 episode reward: 1.0527,                 loss: 0.2390
Episode: 12761/30000 (42.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4059s / 203.3684 s
agent0:                 episode reward: -0.8346,                 loss: nan
agent1:                 episode reward: 0.8346,                 loss: 0.2380
Episode: 12781/30000 (42.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3944s / 203.7628 s
agent0:                 episode reward: -0.6614,                 loss: nan
agent1:                 episode reward: 0.6614,                 loss: 0.2367
Episode: 12801/30000 (42.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4019s / 204.1647 s
agent0:                 episode reward: -1.0734,                 loss: nan
agent1:                 episode reward: 1.0734,                 loss: 0.2374
Episode: 12821/30000 (42.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3941s / 204.5588 s
agent0:                 episode reward: -0.9066,                 loss: nan
agent1:                 episode reward: 0.9066,                 loss: 0.2390
Episode: 12841/30000 (42.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4041s / 204.9629 s
agent0:                 episode reward: -0.9473,                 loss: nan
agent1:                 episode reward: 0.9473,                 loss: 0.2394
Episode: 12861/30000 (42.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3978s / 205.3607 s
agent0:                 episode reward: -0.9850,                 loss: nan
agent1:                 episode reward: 0.9850,                 loss: 0.2406
Episode: 12881/30000 (42.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4080s / 205.7687 s
agent0:                 episode reward: -0.9315,                 loss: nan
agent1:                 episode reward: 0.9315,                 loss: 0.2409
Episode: 12901/30000 (43.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4457s / 206.2143 s
agent0:                 episode reward: -0.5477,                 loss: nan
agent1:                 episode reward: 0.5477,                 loss: 0.2513
Episode: 12921/30000 (43.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4116s / 206.6259 s
agent0:                 episode reward: -0.9400,                 loss: nan
agent1:                 episode reward: 0.9400,                 loss: 0.2503
Episode: 12941/30000 (43.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4009s / 207.0268 s
agent0:                 episode reward: -0.7447,                 loss: nan
agent1:                 episode reward: 0.7447,                 loss: 0.2499
Episode: 12961/30000 (43.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4013s / 207.4281 s
agent0:                 episode reward: -0.9473,                 loss: nan
agent1:                 episode reward: 0.9473,                 loss: 0.2544
Episode: 12981/30000 (43.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4164s / 207.8445 s
agent0:                 episode reward: -0.7973,                 loss: nan
agent1:                 episode reward: 0.7973,                 loss: 0.2553
Episode: 13001/30000 (43.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4016s / 208.2461 s
agent0:                 episode reward: -0.6348,                 loss: nan
agent1:                 episode reward: 0.6348,                 loss: 0.2518
Episode: 13021/30000 (43.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4051s / 208.6512 s
agent0:                 episode reward: -1.0838,                 loss: nan
agent1:                 episode reward: 1.0838,                 loss: 0.2511
Episode: 13041/30000 (43.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4556s / 209.1067 s
agent0:                 episode reward: -0.8066,                 loss: nan
agent1:                 episode reward: 0.8066,                 loss: 0.2501
Episode: 13061/30000 (43.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4232s / 209.5300 s
agent0:                 episode reward: -0.8647,                 loss: nan
agent1:                 episode reward: 0.8647,                 loss: 0.2516
Episode: 13081/30000 (43.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4075s / 209.9375 s
agent0:                 episode reward: -1.0683,                 loss: nan
agent1:                 episode reward: 1.0683,                 loss: 0.2500
Episode: 13101/30000 (43.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4063s / 210.3438 s
agent0:                 episode reward: -0.6642,                 loss: nan
agent1:                 episode reward: 0.6642,                 loss: 0.2531
Episode: 13121/30000 (43.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4102s / 210.7540 s
agent0:                 episode reward: -0.5530,                 loss: nan
agent1:                 episode reward: 0.5530,                 loss: 0.2504
Episode: 13141/30000 (43.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4035s / 211.1575 s
agent0:                 episode reward: -0.7769,                 loss: nan
agent1:                 episode reward: 0.7769,                 loss: 0.2523
Episode: 13161/30000 (43.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4052s / 211.5627 s
agent0:                 episode reward: -1.0511,                 loss: nan
agent1:                 episode reward: 1.0511,                 loss: 0.2533
Episode: 13181/30000 (43.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4105s / 211.9732 s
agent0:                 episode reward: -0.8608,                 loss: nan
agent1:                 episode reward: 0.8608,                 loss: 0.2511
Episode: 13201/30000 (44.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4147s / 212.3880 s
agent0:                 episode reward: -0.9100,                 loss: nan
agent1:                 episode reward: 0.9100,                 loss: 0.2569
Episode: 13221/30000 (44.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4125s / 212.8004 s
agent0:                 episode reward: -0.8268,                 loss: nan
agent1:                 episode reward: 0.8268,                 loss: 0.2495
Episode: 13241/30000 (44.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4048s / 213.2052 s
agent0:                 episode reward: -0.8801,                 loss: nan
agent1:                 episode reward: 0.8801,                 loss: 0.2492
Episode: 13261/30000 (44.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4385s / 213.6437 s
agent0:                 episode reward: -0.8949,                 loss: nan
agent1:                 episode reward: 0.8949,                 loss: 0.2460
Episode: 13281/30000 (44.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4029s / 214.0466 s
agent0:                 episode reward: -1.2036,                 loss: nan
agent1:                 episode reward: 1.2036,                 loss: 0.2480
Episode: 13301/30000 (44.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4027s / 214.4493 s
agent0:                 episode reward: -0.8489,                 loss: nan
agent1:                 episode reward: 0.8489,                 loss: 0.2459
Episode: 13321/30000 (44.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4048s / 214.8541 s
agent0:                 episode reward: -0.6227,                 loss: nan
agent1:                 episode reward: 0.6227,                 loss: 0.2459
Episode: 13341/30000 (44.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4114s / 215.2655 s
agent0:                 episode reward: -0.7842,                 loss: nan
agent1:                 episode reward: 0.7842,                 loss: 0.2435
Episode: 13361/30000 (44.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4086s / 215.6741 s
agent0:                 episode reward: -0.5409,                 loss: nan
agent1:                 episode reward: 0.5409,                 loss: 0.2477
Episode: 13381/30000 (44.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4165s / 216.0907 s
agent0:                 episode reward: -0.7029,                 loss: nan
agent1:                 episode reward: 0.7029,                 loss: 0.2469
Episode: 13401/30000 (44.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4092s / 216.4998 s
agent0:                 episode reward: -1.0725,                 loss: nan
agent1:                 episode reward: 1.0725,                 loss: 0.2474
Episode: 13421/30000 (44.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4028s / 216.9026 s
agent0:                 episode reward: -0.9666,                 loss: nan
agent1:                 episode reward: 0.9666,                 loss: 0.2485
Episode: 13441/30000 (44.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4102s / 217.3127 s
agent0:                 episode reward: -0.9644,                 loss: nan
agent1:                 episode reward: 0.9644,                 loss: 0.2488
Episode: 13461/30000 (44.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4086s / 217.7214 s
agent0:                 episode reward: -0.6650,                 loss: nan
agent1:                 episode reward: 0.6650,                 loss: 0.2449
Episode: 13481/30000 (44.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4045s / 218.1259 s
agent0:                 episode reward: -0.8498,                 loss: nan
agent1:                 episode reward: 0.8498,                 loss: 0.2452
Episode: 13501/30000 (45.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4202s / 218.5461 s
agent0:                 episode reward: -1.0297,                 loss: nan
agent1:                 episode reward: 1.0297,                 loss: 0.2454
Episode: 13521/30000 (45.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4133s / 218.9594 s
agent0:                 episode reward: -0.6420,                 loss: nan
agent1:                 episode reward: 0.6420,                 loss: 0.2436
Episode: 13541/30000 (45.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4658s / 219.4252 s
agent0:                 episode reward: -0.6922,                 loss: nan
agent1:                 episode reward: 0.6922,                 loss: 0.2499
Episode: 13561/30000 (45.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4170s / 219.8423 s
agent0:                 episode reward: -0.6584,                 loss: nan
agent1:                 episode reward: 0.6584,                 loss: 0.2465
Episode: 13581/30000 (45.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4134s / 220.2557 s
agent0:                 episode reward: -0.7746,                 loss: nan
agent1:                 episode reward: 0.7746,                 loss: 0.2422
Episode: 13601/30000 (45.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4123s / 220.6680 s
agent0:                 episode reward: -0.2451,                 loss: nan
agent1:                 episode reward: 0.2451,                 loss: 0.2448
Episode: 13621/30000 (45.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4101s / 221.0781 s
agent0:                 episode reward: -0.6365,                 loss: nan
agent1:                 episode reward: 0.6365,                 loss: 0.2434
Episode: 13641/30000 (45.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4336s / 221.5116 s
agent0:                 episode reward: -0.8355,                 loss: nan
agent1:                 episode reward: 0.8355,                 loss: 0.2440
Episode: 13661/30000 (45.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4104s / 221.9221 s
agent0:                 episode reward: -0.7741,                 loss: nan
agent1:                 episode reward: 0.7741,                 loss: 0.2468
Episode: 13681/30000 (45.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4119s / 222.3340 s
agent0:                 episode reward: -0.7379,                 loss: nan
agent1:                 episode reward: 0.7379,                 loss: 0.2454
Episode: 13701/30000 (45.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4127s / 222.7467 s
agent0:                 episode reward: -0.9324,                 loss: nan
agent1:                 episode reward: 0.9324,                 loss: 0.2451
Episode: 13721/30000 (45.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4153s / 223.1619 s
agent0:                 episode reward: -0.6793,                 loss: nan
agent1:                 episode reward: 0.6793,                 loss: 0.2406
Episode: 13741/30000 (45.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4135s / 223.5754 s
agent0:                 episode reward: -0.7260,                 loss: nan
agent1:                 episode reward: 0.7260,                 loss: 0.2419
Episode: 13761/30000 (45.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4185s / 223.9940 s
agent0:                 episode reward: -0.7707,                 loss: nan
agent1:                 episode reward: 0.7707,                 loss: 0.2454
Episode: 13781/30000 (45.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4536s / 224.4476 s
agent0:                 episode reward: -0.7793,                 loss: nan
agent1:                 episode reward: 0.7793,                 loss: 0.2460
Episode: 13801/30000 (46.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4202s / 224.8678 s
agent0:                 episode reward: -0.5501,                 loss: nan
agent1:                 episode reward: 0.5501,                 loss: 0.2406
Episode: 13821/30000 (46.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4163s / 225.2841 s
agent0:                 episode reward: -0.9766,                 loss: nan
agent1:                 episode reward: 0.9766,                 loss: 0.2425
Episode: 13841/30000 (46.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4139s / 225.6980 s
agent0:                 episode reward: -0.5809,                 loss: nan
agent1:                 episode reward: 0.5809,                 loss: 0.2476
Episode: 13861/30000 (46.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4155s / 226.1135 s
agent0:                 episode reward: -0.9348,                 loss: nan
agent1:                 episode reward: 0.9348,                 loss: 0.2406
Episode: 13881/30000 (46.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4096s / 226.5232 s
agent0:                 episode reward: -0.6194,                 loss: nan
agent1:                 episode reward: 0.6194,                 loss: 0.2421
Episode: 13901/30000 (46.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4175s / 226.9406 s
agent0:                 episode reward: -0.9078,                 loss: nan
agent1:                 episode reward: 0.9078,                 loss: 0.2557
Episode: 13921/30000 (46.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4187s / 227.3593 s
agent0:                 episode reward: -0.6770,                 loss: nan
agent1:                 episode reward: 0.6770,                 loss: 0.2538
Episode: 13941/30000 (46.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4125s / 227.7719 s
agent0:                 episode reward: -0.8786,                 loss: nan
agent1:                 episode reward: 0.8786,                 loss: 0.2519
Episode: 13961/30000 (46.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4160s / 228.1878 s
agent0:                 episode reward: -0.9428,                 loss: nan
agent1:                 episode reward: 0.9428,                 loss: 0.2519
Episode: 13981/30000 (46.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4109s / 228.5987 s
agent0:                 episode reward: -1.0140,                 loss: nan
agent1:                 episode reward: 1.0140,                 loss: 0.2569
Episode: 14001/30000 (46.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4173s / 229.0160 s
agent0:                 episode reward: -0.8142,                 loss: nan
agent1:                 episode reward: 0.8142,                 loss: 0.2529
Episode: 14021/30000 (46.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4616s / 229.4776 s
agent0:                 episode reward: -0.5523,                 loss: nan
agent1:                 episode reward: 0.5523,                 loss: 0.2531
Episode: 14041/30000 (46.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4387s / 229.9163 s
agent0:                 episode reward: -0.8357,                 loss: nan
agent1:                 episode reward: 0.8357,                 loss: 0.2540
Episode: 14061/30000 (46.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4627s / 230.3790 s
agent0:                 episode reward: -0.6412,                 loss: nan
agent1:                 episode reward: 0.6412,                 loss: 0.2537
Episode: 14081/30000 (46.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4191s / 230.7981 s
agent0:                 episode reward: -0.4878,                 loss: nan
agent1:                 episode reward: 0.4878,                 loss: 0.2530
Episode: 14101/30000 (47.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4226s / 231.2207 s
agent0:                 episode reward: -0.8831,                 loss: nan
agent1:                 episode reward: 0.8831,                 loss: 0.2545
Episode: 14121/30000 (47.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4203s / 231.6410 s
agent0:                 episode reward: -0.8537,                 loss: nan
agent1:                 episode reward: 0.8537,                 loss: 0.2548
Episode: 14141/30000 (47.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4187s / 232.0597 s
agent0:                 episode reward: -0.9733,                 loss: nan
agent1:                 episode reward: 0.9733,                 loss: 0.2496
Episode: 14161/30000 (47.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4422s / 232.5019 s
agent0:                 episode reward: -0.8844,                 loss: nan
agent1:                 episode reward: 0.8844,                 loss: 0.2528
Episode: 14181/30000 (47.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4193s / 232.9211 s
agent0:                 episode reward: -0.7218,                 loss: nan
agent1:                 episode reward: 0.7218,                 loss: 0.2513
Episode: 14201/30000 (47.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4491s / 233.3703 s
agent0:                 episode reward: -0.6307,                 loss: nan
agent1:                 episode reward: 0.6307,                 loss: 0.2520
Episode: 14221/30000 (47.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4235s / 233.7938 s
agent0:                 episode reward: -0.9499,                 loss: nan
agent1:                 episode reward: 0.9499,                 loss: 0.2533
Episode: 14241/30000 (47.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4444s / 234.2381 s
agent0:                 episode reward: -0.8284,                 loss: nan
agent1:                 episode reward: 0.8284,                 loss: 0.2474
Episode: 14261/30000 (47.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4182s / 234.6563 s
agent0:                 episode reward: -0.7536,                 loss: nan
agent1:                 episode reward: 0.7536,                 loss: 0.2454
Episode: 14281/30000 (47.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4193s / 235.0756 s
agent0:                 episode reward: -0.6417,                 loss: nan
agent1:                 episode reward: 0.6417,                 loss: 0.2491
Episode: 14301/30000 (47.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4151s / 235.4908 s
agent0:                 episode reward: -0.4823,                 loss: nan
agent1:                 episode reward: 0.4823,                 loss: 0.2463
Episode: 14321/30000 (47.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4258s / 235.9166 s
agent0:                 episode reward: -1.0764,                 loss: nan
agent1:                 episode reward: 1.0764,                 loss: 0.2448
Episode: 14341/30000 (47.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4281s / 236.3447 s
agent0:                 episode reward: -0.8846,                 loss: nan
agent1:                 episode reward: 0.8846,                 loss: 0.2447
Episode: 14361/30000 (47.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4287s / 236.7734 s
agent0:                 episode reward: -0.8366,                 loss: nan
agent1:                 episode reward: 0.8366,                 loss: 0.2465
Episode: 14381/30000 (47.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4212s / 237.1945 s
agent0:                 episode reward: -0.5745,                 loss: nan
agent1:                 episode reward: 0.5745,                 loss: 0.2445
Episode: 14401/30000 (48.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4292s / 237.6237 s
agent0:                 episode reward: -0.6335,                 loss: nan
agent1:                 episode reward: 0.6335,                 loss: 0.2465
Episode: 14421/30000 (48.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4200s / 238.0438 s
agent0:                 episode reward: -0.9802,                 loss: nan
agent1:                 episode reward: 0.9802,                 loss: 0.2455
Episode: 14441/30000 (48.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4233s / 238.4670 s
agent0:                 episode reward: -0.6386,                 loss: nan
agent1:                 episode reward: 0.6386,                 loss: 0.2445
Episode: 14461/30000 (48.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4260s / 238.8930 s
agent0:                 episode reward: -0.5289,                 loss: nan
agent1:                 episode reward: 0.5289,                 loss: 0.2481
Episode: 14481/30000 (48.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4275s / 239.3205 s
agent0:                 episode reward: -0.5668,                 loss: nan
agent1:                 episode reward: 0.5668,                 loss: 0.2447
Episode: 14501/30000 (48.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4825s / 239.8030 s
agent0:                 episode reward: -0.8384,                 loss: nan
agent1:                 episode reward: 0.8384,                 loss: 0.2471
Episode: 14521/30000 (48.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4277s / 240.2308 s
agent0:                 episode reward: -0.9236,                 loss: nan
agent1:                 episode reward: 0.9236,                 loss: 0.2504
Episode: 14541/30000 (48.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4375s / 240.6682 s
agent0:                 episode reward: -0.8336,                 loss: nan
agent1:                 episode reward: 0.8336,                 loss: 0.2492
Episode: 14561/30000 (48.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4357s / 241.1040 s
agent0:                 episode reward: -0.7640,                 loss: nan
agent1:                 episode reward: 0.7640,                 loss: 0.2462
Episode: 14581/30000 (48.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4259s / 241.5299 s
agent0:                 episode reward: -0.9986,                 loss: nan
agent1:                 episode reward: 0.9986,                 loss: 0.2509
Episode: 14601/30000 (48.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4272s / 241.9571 s
agent0:                 episode reward: -0.6134,                 loss: nan
agent1:                 episode reward: 0.6134,                 loss: 0.2517
Episode: 14621/30000 (48.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4301s / 242.3872 s
agent0:                 episode reward: -0.6354,                 loss: nan
agent1:                 episode reward: 0.6354,                 loss: 0.2566
Episode: 14641/30000 (48.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4219s / 242.8091 s
agent0:                 episode reward: -0.7379,                 loss: nan
agent1:                 episode reward: 0.7379,                 loss: 0.2501
Episode: 14661/30000 (48.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4248s / 243.2339 s
agent0:                 episode reward: -0.8674,                 loss: nan
agent1:                 episode reward: 0.8674,                 loss: 0.2527
Episode: 14681/30000 (48.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4318s / 243.6657 s
agent0:                 episode reward: -0.8484,                 loss: nan
agent1:                 episode reward: 0.8484,                 loss: 0.2515
Episode: 14701/30000 (49.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4262s / 244.0919 s
agent0:                 episode reward: -0.6596,                 loss: nan
agent1:                 episode reward: 0.6596,                 loss: 0.2557
Episode: 14721/30000 (49.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4288s / 244.5207 s
agent0:                 episode reward: -0.7833,                 loss: nan
agent1:                 episode reward: 0.7833,                 loss: 0.2541
Episode: 14741/30000 (49.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4289s / 244.9496 s
agent0:                 episode reward: -0.7142,                 loss: nan
agent1:                 episode reward: 0.7142,                 loss: 0.2518
Episode: 14761/30000 (49.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4433s / 245.3929 s
agent0:                 episode reward: -0.4615,                 loss: nan
agent1:                 episode reward: 0.4615,                 loss: 0.2499
Episode: 14781/30000 (49.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4369s / 245.8299 s
agent0:                 episode reward: -0.6386,                 loss: nan
agent1:                 episode reward: 0.6386,                 loss: 0.2486
Episode: 14801/30000 (49.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4306s / 246.2605 s
agent0:                 episode reward: -0.7388,                 loss: nan
agent1:                 episode reward: 0.7388,                 loss: 0.2502
Episode: 14821/30000 (49.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4296s / 246.6901 s
agent0:                 episode reward: -0.8464,                 loss: nan
agent1:                 episode reward: 0.8464,                 loss: 0.2527
Episode: 14841/30000 (49.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4304s / 247.1205 s
agent0:                 episode reward: -0.6168,                 loss: nan
agent1:                 episode reward: 0.6168,                 loss: 0.2526
Episode: 14861/30000 (49.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4256s / 247.5462 s
agent0:                 episode reward: -0.5649,                 loss: nan
agent1:                 episode reward: 0.5649,                 loss: 0.2512
Episode: 14881/30000 (49.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4321s / 247.9783 s
agent0:                 episode reward: -1.0694,                 loss: nan
agent1:                 episode reward: 1.0694,                 loss: 0.2528
Episode: 14901/30000 (49.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4407s / 248.4189 s
agent0:                 episode reward: -0.4347,                 loss: nan
agent1:                 episode reward: 0.4347,                 loss: 0.2517
Episode: 14921/30000 (49.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4351s / 248.8540 s
agent0:                 episode reward: -0.9791,                 loss: nan
agent1:                 episode reward: 0.9791,                 loss: 0.2455
Episode: 14941/30000 (49.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4490s / 249.3030 s
agent0:                 episode reward: -0.9669,                 loss: nan
agent1:                 episode reward: 0.9669,                 loss: 0.2440
Episode: 14961/30000 (49.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4310s / 249.7340 s
agent0:                 episode reward: -1.0271,                 loss: nan
agent1:                 episode reward: 1.0271,                 loss: 0.2480
Episode: 14981/30000 (49.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5083s / 250.2423 s
agent0:                 episode reward: -1.1608,                 loss: nan
agent1:                 episode reward: 1.1608,                 loss: 0.2485
Episode: 15001/30000 (50.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4350s / 250.6773 s
agent0:                 episode reward: -0.9816,                 loss: nan
agent1:                 episode reward: 0.9816,                 loss: 0.2476
Episode: 15021/30000 (50.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4352s / 251.1125 s
agent0:                 episode reward: -0.4741,                 loss: nan
agent1:                 episode reward: 0.4741,                 loss: 0.2458
Episode: 15041/30000 (50.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4469s / 251.5594 s
agent0:                 episode reward: -0.8495,                 loss: nan
agent1:                 episode reward: 0.8495,                 loss: 0.2481
Episode: 15061/30000 (50.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4360s / 251.9954 s
agent0:                 episode reward: -1.2742,                 loss: nan
agent1:                 episode reward: 1.2742,                 loss: 0.2501
Episode: 15081/30000 (50.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4335s / 252.4289 s
agent0:                 episode reward: -1.0191,                 loss: nan
agent1:                 episode reward: 1.0191,                 loss: 0.2504
Episode: 15101/30000 (50.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4435s / 252.8724 s
agent0:                 episode reward: -0.8597,                 loss: nan
agent1:                 episode reward: 0.8597,                 loss: 0.2469
Episode: 15121/30000 (50.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4328s / 253.3052 s
agent0:                 episode reward: -0.6753,                 loss: nan
agent1:                 episode reward: 0.6753,                 loss: 0.2486
Episode: 15141/30000 (50.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4344s / 253.7396 s
agent0:                 episode reward: -1.1037,                 loss: nan
agent1:                 episode reward: 1.1037,                 loss: 0.2486
Episode: 15161/30000 (50.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4362s / 254.1758 s
agent0:                 episode reward: -0.6041,                 loss: nan
agent1:                 episode reward: 0.6041,                 loss: 0.2468
Episode: 15181/30000 (50.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4446s / 254.6204 s
agent0:                 episode reward: -0.7818,                 loss: nan
agent1:                 episode reward: 0.7818,                 loss: 0.2473
Episode: 15201/30000 (50.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4333s / 255.0537 s
agent0:                 episode reward: -1.1054,                 loss: nan
agent1:                 episode reward: 1.1054,                 loss: 0.2484
Episode: 15221/30000 (50.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4383s / 255.4920 s
agent0:                 episode reward: -0.8619,                 loss: nan
agent1:                 episode reward: 0.8619,                 loss: 0.2450
Episode: 15241/30000 (50.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4317s / 255.9237 s
agent0:                 episode reward: -0.8756,                 loss: nan
agent1:                 episode reward: 0.8756,                 loss: 0.2423
Episode: 15261/30000 (50.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4348s / 256.3585 s
agent0:                 episode reward: -0.7136,                 loss: nan
agent1:                 episode reward: 0.7136,                 loss: 0.2412
Episode: 15281/30000 (50.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4374s / 256.7959 s
agent0:                 episode reward: -0.8185,                 loss: nan
agent1:                 episode reward: 0.8185,                 loss: 0.2442
Episode: 15301/30000 (51.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4353s / 257.2312 s
agent0:                 episode reward: -0.9619,                 loss: nan
agent1:                 episode reward: 0.9619,                 loss: 0.2438
Episode: 15321/30000 (51.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4678s / 257.6989 s
agent0:                 episode reward: -1.0579,                 loss: nan
agent1:                 episode reward: 1.0579,                 loss: 0.2397
Episode: 15341/30000 (51.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4363s / 258.1352 s
agent0:                 episode reward: -0.8820,                 loss: nan
agent1:                 episode reward: 0.8820,                 loss: 0.2431
Episode: 15361/30000 (51.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4382s / 258.5734 s
agent0:                 episode reward: -1.0576,                 loss: nan
agent1:                 episode reward: 1.0576,                 loss: 0.2390
Episode: 15381/30000 (51.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4325s / 259.0059 s
agent0:                 episode reward: -0.9832,                 loss: nan
agent1:                 episode reward: 0.9832,                 loss: 0.2446
Episode: 15401/30000 (51.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4327s / 259.4386 s
agent0:                 episode reward: -1.0762,                 loss: nan
agent1:                 episode reward: 1.0762,                 loss: 0.2372
Episode: 15421/30000 (51.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4374s / 259.8760 s
agent0:                 episode reward: -1.0507,                 loss: nan
agent1:                 episode reward: 1.0507,                 loss: 0.2392
Episode: 15441/30000 (51.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5155s / 260.3914 s
agent0:                 episode reward: -0.6605,                 loss: nan
agent1:                 episode reward: 0.6605,                 loss: 0.2404
Episode: 15461/30000 (51.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4349s / 260.8263 s
agent0:                 episode reward: -0.8806,                 loss: nan
agent1:                 episode reward: 0.8806,                 loss: 0.2422
Episode: 15481/30000 (51.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4350s / 261.2613 s
agent0:                 episode reward: -0.8553,                 loss: nan
agent1:                 episode reward: 0.8553,                 loss: 0.2464
Episode: 15501/30000 (51.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4429s / 261.7042 s
agent0:                 episode reward: -0.7291,                 loss: nan
agent1:                 episode reward: 0.7291,                 loss: 0.2453
Episode: 15521/30000 (51.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4311s / 262.1354 s
agent0:                 episode reward: -0.6455,                 loss: nan
agent1:                 episode reward: 0.6455,                 loss: 0.2432
Episode: 15541/30000 (51.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4397s / 262.5750 s
agent0:                 episode reward: -0.8803,                 loss: nan
agent1:                 episode reward: 0.8803,                 loss: 0.2428
Episode: 15561/30000 (51.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4420s / 263.0170 s
agent0:                 episode reward: -0.7507,                 loss: nan
agent1:                 episode reward: 0.7507,                 loss: 0.2525
Episode: 15581/30000 (51.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4456s / 263.4626 s
agent0:                 episode reward: -1.0241,                 loss: nan
agent1:                 episode reward: 1.0241,                 loss: 0.2555
Episode: 15601/30000 (52.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4352s / 263.8978 s
agent0:                 episode reward: -0.5910,                 loss: nan
agent1:                 episode reward: 0.5910,                 loss: 0.2533
Episode: 15621/30000 (52.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4428s / 264.3406 s
agent0:                 episode reward: -0.7916,                 loss: nan
agent1:                 episode reward: 0.7916,                 loss: 0.2545
Episode: 15641/30000 (52.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4352s / 264.7759 s
agent0:                 episode reward: -1.0611,                 loss: nan
agent1:                 episode reward: 1.0611,                 loss: 0.2517
Episode: 15661/30000 (52.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4383s / 265.2141 s
agent0:                 episode reward: -0.9765,                 loss: nan
agent1:                 episode reward: 0.9765,                 loss: 0.2562
Episode: 15681/30000 (52.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5153s / 265.7294 s
agent0:                 episode reward: -0.9194,                 loss: nan
agent1:                 episode reward: 0.9194,                 loss: 0.2566
Episode: 15701/30000 (52.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4449s / 266.1743 s
agent0:                 episode reward: -1.0258,                 loss: nan
agent1:                 episode reward: 1.0258,                 loss: 0.2515
Episode: 15721/30000 (52.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4595s / 266.6338 s
agent0:                 episode reward: -0.9107,                 loss: nan
agent1:                 episode reward: 0.9107,                 loss: 0.2530
Episode: 15741/30000 (52.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4457s / 267.0795 s
agent0:                 episode reward: -0.6405,                 loss: nan
agent1:                 episode reward: 0.6405,                 loss: 0.2524
Episode: 15761/30000 (52.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4416s / 267.5211 s
agent0:                 episode reward: -0.6506,                 loss: nan
agent1:                 episode reward: 0.6506,                 loss: 0.2548
Episode: 15781/30000 (52.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4400s / 267.9611 s
agent0:                 episode reward: -1.1273,                 loss: nan
agent1:                 episode reward: 1.1273,                 loss: 0.2544
Episode: 15801/30000 (52.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4392s / 268.4003 s
agent0:                 episode reward: -1.0090,                 loss: nan
agent1:                 episode reward: 1.0090,                 loss: 0.2514
Episode: 15821/30000 (52.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4413s / 268.8417 s
agent0:                 episode reward: -0.9465,                 loss: nan
agent1:                 episode reward: 0.9465,                 loss: 0.2564
Episode: 15841/30000 (52.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4478s / 269.2895 s
agent0:                 episode reward: -0.5583,                 loss: nan
agent1:                 episode reward: 0.5583,                 loss: 0.2553
Episode: 15861/30000 (52.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4421s / 269.7315 s
agent0:                 episode reward: -0.7036,                 loss: nan
agent1:                 episode reward: 0.7036,                 loss: 0.2556
Episode: 15881/30000 (52.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4382s / 270.1698 s
agent0:                 episode reward: -1.0809,                 loss: nan
agent1:                 episode reward: 1.0809,                 loss: 0.2509
Episode: 15901/30000 (53.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4909s / 270.6606 s
agent0:                 episode reward: -1.0117,                 loss: nan
agent1:                 episode reward: 1.0117,                 loss: 0.2522
Episode: 15921/30000 (53.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4410s / 271.1017 s
agent0:                 episode reward: -0.8426,                 loss: nan
agent1:                 episode reward: 0.8426,                 loss: 0.2487
Episode: 15941/30000 (53.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4407s / 271.5424 s
agent0:                 episode reward: -0.9500,                 loss: nan
agent1:                 episode reward: 0.9500,                 loss: 0.2538
Episode: 15961/30000 (53.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4431s / 271.9855 s
agent0:                 episode reward: -0.8059,                 loss: nan
agent1:                 episode reward: 0.8059,                 loss: 0.2514
Episode: 15981/30000 (53.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4559s / 272.4414 s
agent0:                 episode reward: -0.7720,                 loss: nan
agent1:                 episode reward: 0.7720,                 loss: 0.2557
Episode: 16001/30000 (53.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4437s / 272.8851 s
agent0:                 episode reward: -0.6304,                 loss: nan
agent1:                 episode reward: 0.6304,                 loss: 0.2525
Episode: 16021/30000 (53.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4421s / 273.3272 s
agent0:                 episode reward: -0.8600,                 loss: nan
agent1:                 episode reward: 0.8600,                 loss: 0.2540
Episode: 16041/30000 (53.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4492s / 273.7764 s
agent0:                 episode reward: -0.8635,                 loss: nan
agent1:                 episode reward: 0.8635,                 loss: 0.2525
Episode: 16061/30000 (53.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4605s / 274.2369 s
agent0:                 episode reward: -0.6783,                 loss: nan
agent1:                 episode reward: 0.6783,                 loss: 0.2504
Episode: 16081/30000 (53.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4401s / 274.6770 s
agent0:                 episode reward: -0.5680,                 loss: nan
agent1:                 episode reward: 0.5680,                 loss: 0.2523
Episode: 16101/30000 (53.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4485s / 275.1255 s
agent0:                 episode reward: -0.9259,                 loss: nan
agent1:                 episode reward: 0.9259,                 loss: 0.2529
Episode: 16121/30000 (53.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4606s / 275.5861 s
agent0:                 episode reward: -0.9242,                 loss: nan
agent1:                 episode reward: 0.9242,                 loss: 0.2533
Episode: 16141/30000 (53.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4385s / 276.0245 s
agent0:                 episode reward: -0.7522,                 loss: nan
agent1:                 episode reward: 0.7522,                 loss: 0.2565
Episode: 16161/30000 (53.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4410s / 276.4656 s
agent0:                 episode reward: -0.9520,                 loss: nan
agent1:                 episode reward: 0.9520,                 loss: 0.2562
Episode: 16181/30000 (53.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4470s / 276.9126 s
agent0:                 episode reward: -0.5786,                 loss: nan
agent1:                 episode reward: 0.5786,                 loss: 0.2522
Episode: 16201/30000 (54.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4433s / 277.3559 s
agent0:                 episode reward: -1.0789,                 loss: nan
agent1:                 episode reward: 1.0789,                 loss: 0.2549
Episode: 16221/30000 (54.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4438s / 277.7997 s
agent0:                 episode reward: -0.7372,                 loss: nan
agent1:                 episode reward: 0.7372,                 loss: 0.2479
Episode: 16241/30000 (54.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4479s / 278.2476 s
agent0:                 episode reward: -0.8412,                 loss: nan
agent1:                 episode reward: 0.8412,                 loss: 0.2412
Episode: 16261/30000 (54.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4508s / 278.6984 s
agent0:                 episode reward: -0.9077,                 loss: nan
agent1:                 episode reward: 0.9077,                 loss: 0.2456
Episode: 16281/30000 (54.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4410s / 279.1394 s
agent0:                 episode reward: -0.9610,                 loss: nan
agent1:                 episode reward: 0.9610,                 loss: 0.2482
Episode: 16301/30000 (54.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4458s / 279.5852 s
agent0:                 episode reward: -0.8972,                 loss: nan
agent1:                 episode reward: 0.8972,                 loss: 0.2487
Episode: 16321/30000 (54.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4466s / 280.0318 s
agent0:                 episode reward: -0.8849,                 loss: nan
agent1:                 episode reward: 0.8849,                 loss: 0.2425
Episode: 16341/30000 (54.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4585s / 280.4903 s
agent0:                 episode reward: -0.5374,                 loss: nan
agent1:                 episode reward: 0.5374,                 loss: 0.2456
Episode: 16361/30000 (54.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5116s / 281.0019 s
agent0:                 episode reward: -0.5177,                 loss: nan
agent1:                 episode reward: 0.5177,                 loss: 0.2418
Episode: 16381/30000 (54.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4569s / 281.4588 s
agent0:                 episode reward: -0.9601,                 loss: nan
agent1:                 episode reward: 0.9601,                 loss: 0.2476
Episode: 16401/30000 (54.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4505s / 281.9093 s
agent0:                 episode reward: -1.0359,                 loss: nan
agent1:                 episode reward: 1.0359,                 loss: 0.2431
Episode: 16421/30000 (54.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4693s / 282.3786 s
agent0:                 episode reward: -0.8841,                 loss: nan
agent1:                 episode reward: 0.8841,                 loss: 0.2463
Episode: 16441/30000 (54.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4505s / 282.8291 s
agent0:                 episode reward: -1.0032,                 loss: nan
agent1:                 episode reward: 1.0032,                 loss: 0.2454
Episode: 16461/30000 (54.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4438s / 283.2729 s
agent0:                 episode reward: -0.8921,                 loss: nan
agent1:                 episode reward: 0.8921,                 loss: 0.2441
Episode: 16481/30000 (54.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4471s / 283.7200 s
agent0:                 episode reward: -0.8760,                 loss: nan
agent1:                 episode reward: 0.8760,                 loss: 0.2466
Episode: 16501/30000 (55.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4486s / 284.1687 s
agent0:                 episode reward: -0.8668,                 loss: nan
agent1:                 episode reward: 0.8668,                 loss: 0.2493
Episode: 16521/30000 (55.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4797s / 284.6483 s
agent0:                 episode reward: -0.4368,                 loss: nan
agent1:                 episode reward: 0.4368,                 loss: 0.2479
Episode: 16541/30000 (55.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4512s / 285.0995 s
agent0:                 episode reward: -0.5133,                 loss: nan
agent1:                 episode reward: 0.5133,                 loss: 0.2430
Episode: 16561/30000 (55.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4457s / 285.5452 s
agent0:                 episode reward: -0.8044,                 loss: nan
agent1:                 episode reward: 0.8044,                 loss: 0.2456
Episode: 16581/30000 (55.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4832s / 286.0284 s
agent0:                 episode reward: -0.8782,                 loss: nan
agent1:                 episode reward: 0.8782,                 loss: 0.2383
Episode: 16601/30000 (55.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4481s / 286.4764 s
agent0:                 episode reward: -0.7652,                 loss: nan
agent1:                 episode reward: 0.7652,                 loss: 0.2417
Episode: 16621/30000 (55.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4663s / 286.9428 s
agent0:                 episode reward: -0.6616,                 loss: nan
agent1:                 episode reward: 0.6616,                 loss: 0.2464
Episode: 16641/30000 (55.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4574s / 287.4002 s
agent0:                 episode reward: -0.8837,                 loss: nan
agent1:                 episode reward: 0.8837,                 loss: 0.2423
Episode: 16661/30000 (55.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4580s / 287.8581 s
agent0:                 episode reward: -0.7584,                 loss: nan
agent1:                 episode reward: 0.7584,                 loss: 0.2431
Episode: 16681/30000 (55.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4572s / 288.3153 s
agent0:                 episode reward: -0.9836,                 loss: nan
agent1:                 episode reward: 0.9836,                 loss: 0.2421
Episode: 16701/30000 (55.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4522s / 288.7675 s
agent0:                 episode reward: -0.8015,                 loss: nan
agent1:                 episode reward: 0.8015,                 loss: 0.2443
Episode: 16721/30000 (55.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4484s / 289.2159 s
agent0:                 episode reward: -0.6845,                 loss: nan
agent1:                 episode reward: 0.6845,                 loss: 0.2458
Episode: 16741/30000 (55.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4437s / 289.6596 s
agent0:                 episode reward: -0.7525,                 loss: nan
agent1:                 episode reward: 0.7525,                 loss: 0.2411
Episode: 16761/30000 (55.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4503s / 290.1099 s
agent0:                 episode reward: -0.8742,                 loss: nan
agent1:                 episode reward: 0.8742,                 loss: 0.2445
Episode: 16781/30000 (55.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4884s / 290.5984 s
agent0:                 episode reward: -1.1738,                 loss: nan
agent1:                 episode reward: 1.1738,                 loss: 0.2444
Episode: 16801/30000 (56.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5043s / 291.1026 s
agent0:                 episode reward: -0.7054,                 loss: nan
agent1:                 episode reward: 0.7054,                 loss: 0.2434
Episode: 16821/30000 (56.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4525s / 291.5551 s
agent0:                 episode reward: -1.0496,                 loss: nan
agent1:                 episode reward: 1.0496,                 loss: 0.2457
Episode: 16841/30000 (56.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4534s / 292.0086 s
agent0:                 episode reward: -0.9301,                 loss: nan
agent1:                 episode reward: 0.9301,                 loss: 0.2480
Episode: 16861/30000 (56.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4564s / 292.4649 s
agent0:                 episode reward: -1.0975,                 loss: nan
agent1:                 episode reward: 1.0975,                 loss: 0.2464
Episode: 16881/30000 (56.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4538s / 292.9187 s
agent0:                 episode reward: -0.8244,                 loss: nan
agent1:                 episode reward: 0.8244,                 loss: 0.2490
Episode: 16901/30000 (56.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4597s / 293.3784 s
agent0:                 episode reward: -1.2688,                 loss: nan
agent1:                 episode reward: 1.2688,                 loss: 0.2673
Episode: 16921/30000 (56.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4764s / 293.8548 s
agent0:                 episode reward: -0.6384,                 loss: nan
agent1:                 episode reward: 0.6384,                 loss: 0.2646
Episode: 16941/30000 (56.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4587s / 294.3135 s
agent0:                 episode reward: -0.7381,                 loss: nan
agent1:                 episode reward: 0.7381,                 loss: 0.2628
Episode: 16961/30000 (56.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4567s / 294.7702 s
agent0:                 episode reward: -0.8936,                 loss: nan
agent1:                 episode reward: 0.8936,                 loss: 0.2643
Episode: 16981/30000 (56.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4547s / 295.2249 s
agent0:                 episode reward: -1.0407,                 loss: nan
agent1:                 episode reward: 1.0407,                 loss: 0.2645
Episode: 17001/30000 (56.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4543s / 295.6793 s
agent0:                 episode reward: -0.6273,                 loss: nan
agent1:                 episode reward: 0.6273,                 loss: 0.2657
Episode: 17021/30000 (56.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4586s / 296.1379 s
agent0:                 episode reward: -0.8693,                 loss: nan
agent1:                 episode reward: 0.8693,                 loss: 0.2666
Episode: 17041/30000 (56.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4663s / 296.6041 s
agent0:                 episode reward: -0.7864,                 loss: nan
agent1:                 episode reward: 0.7864,                 loss: 0.2661
Episode: 17061/30000 (56.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4590s / 297.0631 s
agent0:                 episode reward: -0.6695,                 loss: nan
agent1:                 episode reward: 0.6695,                 loss: 0.2647
Episode: 17081/30000 (56.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4594s / 297.5225 s
agent0:                 episode reward: -1.0088,                 loss: nan
agent1:                 episode reward: 1.0088,                 loss: 0.2620
Episode: 17101/30000 (57.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4638s / 297.9863 s
agent0:                 episode reward: -0.8350,                 loss: nan
agent1:                 episode reward: 0.8350,                 loss: 0.2678
Episode: 17121/30000 (57.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4833s / 298.4697 s
agent0:                 episode reward: -0.9152,                 loss: nan
agent1:                 episode reward: 0.9152,                 loss: 0.2593
Episode: 17141/30000 (57.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4975s / 298.9671 s
agent0:                 episode reward: -0.7523,                 loss: nan
agent1:                 episode reward: 0.7523,                 loss: 0.2615
Episode: 17161/30000 (57.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4638s / 299.4309 s
agent0:                 episode reward: -0.9217,                 loss: nan
agent1:                 episode reward: 0.9217,                 loss: 0.2640
Episode: 17181/30000 (57.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4783s / 299.9092 s
agent0:                 episode reward: -1.1279,                 loss: nan
agent1:                 episode reward: 1.1279,                 loss: 0.2660
Episode: 17201/30000 (57.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4562s / 300.3655 s
agent0:                 episode reward: -0.8221,                 loss: nan
agent1:                 episode reward: 0.8221,                 loss: 0.2653
Episode: 17221/30000 (57.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4672s / 300.8326 s
agent0:                 episode reward: -0.7986,                 loss: nan
agent1:                 episode reward: 0.7986,                 loss: 0.2593
Episode: 17241/30000 (57.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5122s / 301.3448 s
agent0:                 episode reward: -0.8266,                 loss: nan
agent1:                 episode reward: 0.8266,                 loss: 0.2432
Episode: 17261/30000 (57.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5016s / 301.8464 s
agent0:                 episode reward: -0.7516,                 loss: nan
agent1:                 episode reward: 0.7516,                 loss: 0.2397
Episode: 17281/30000 (57.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4582s / 302.3046 s
agent0:                 episode reward: -1.2920,                 loss: nan
agent1:                 episode reward: 1.2920,                 loss: 0.2377
Episode: 17301/30000 (57.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4800s / 302.7846 s
agent0:                 episode reward: -0.8485,                 loss: nan
agent1:                 episode reward: 0.8485,                 loss: 0.2428
Episode: 17321/30000 (57.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4590s / 303.2436 s
agent0:                 episode reward: -0.7665,                 loss: nan
agent1:                 episode reward: 0.7665,                 loss: 0.2435
Episode: 17341/30000 (57.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4572s / 303.7008 s
agent0:                 episode reward: -0.9841,                 loss: nan
agent1:                 episode reward: 0.9841,                 loss: 0.2425
Episode: 17361/30000 (57.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4556s / 304.1563 s
agent0:                 episode reward: -1.2785,                 loss: nan
agent1:                 episode reward: 1.2785,                 loss: 0.2438
Episode: 17381/30000 (57.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4571s / 304.6134 s
agent0:                 episode reward: -0.9820,                 loss: nan
agent1:                 episode reward: 0.9820,                 loss: 0.2408
Episode: 17401/30000 (58.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4590s / 305.0724 s
agent0:                 episode reward: -0.8089,                 loss: nan
agent1:                 episode reward: 0.8089,                 loss: 0.2432
Episode: 17421/30000 (58.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4652s / 305.5376 s
agent0:                 episode reward: -1.0241,                 loss: nan
agent1:                 episode reward: 1.0241,                 loss: 0.2430
Episode: 17441/30000 (58.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4563s / 305.9939 s
agent0:                 episode reward: -0.9208,                 loss: nan
agent1:                 episode reward: 0.9208,                 loss: 0.2387
Episode: 17461/30000 (58.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4917s / 306.4856 s
agent0:                 episode reward: -0.7418,                 loss: nan
agent1:                 episode reward: 0.7418,                 loss: 0.2381
Episode: 17481/30000 (58.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4650s / 306.9506 s
agent0:                 episode reward: -1.0304,                 loss: nan
agent1:                 episode reward: 1.0304,                 loss: 0.2428
Episode: 17501/30000 (58.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4793s / 307.4299 s
agent0:                 episode reward: -0.9544,                 loss: nan
agent1:                 episode reward: 0.9544,                 loss: 0.2397
Episode: 17521/30000 (58.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4632s / 307.8931 s
agent0:                 episode reward: -0.8641,                 loss: nan
agent1:                 episode reward: 0.8641,                 loss: 0.2401
Episode: 17541/30000 (58.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4556s / 308.3487 s
agent0:                 episode reward: -0.9793,                 loss: nan
agent1:                 episode reward: 0.9793,                 loss: 0.2398
Episode: 17561/30000 (58.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4738s / 308.8225 s
agent0:                 episode reward: -0.8996,                 loss: nan
agent1:                 episode reward: 0.8996,                 loss: 0.2493
Episode: 17581/30000 (58.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4609s / 309.2834 s
agent0:                 episode reward: -0.6003,                 loss: nan
agent1:                 episode reward: 0.6003,                 loss: 0.2476
Episode: 17601/30000 (58.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4603s / 309.7437 s
agent0:                 episode reward: -0.6524,                 loss: nan
agent1:                 episode reward: 0.6524,                 loss: 0.2522
Episode: 17621/30000 (58.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4726s / 310.2164 s
agent0:                 episode reward: -0.7968,                 loss: nan
agent1:                 episode reward: 0.7968,                 loss: 0.2484
Episode: 17641/30000 (58.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4756s / 310.6920 s
agent0:                 episode reward: -0.8545,                 loss: nan
agent1:                 episode reward: 0.8545,                 loss: 0.2440
Episode: 17661/30000 (58.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4747s / 311.1667 s
agent0:                 episode reward: -0.6933,                 loss: nan
agent1:                 episode reward: 0.6933,                 loss: 0.2491
Episode: 17681/30000 (58.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5256s / 311.6923 s
agent0:                 episode reward: -0.8759,                 loss: nan
agent1:                 episode reward: 0.8759,                 loss: 0.2459
Episode: 17701/30000 (59.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4670s / 312.1593 s
agent0:                 episode reward: -0.7252,                 loss: nan
agent1:                 episode reward: 0.7252,                 loss: 0.2464
Episode: 17721/30000 (59.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4991s / 312.6584 s
agent0:                 episode reward: -0.7397,                 loss: nan
agent1:                 episode reward: 0.7397,                 loss: 0.2513
Episode: 17741/30000 (59.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4678s / 313.1262 s
agent0:                 episode reward: -0.7806,                 loss: nan
agent1:                 episode reward: 0.7806,                 loss: 0.2491
Episode: 17761/30000 (59.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5024s / 313.6286 s
agent0:                 episode reward: -0.7189,                 loss: nan
agent1:                 episode reward: 0.7189,                 loss: 0.2482
Episode: 17781/30000 (59.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4927s / 314.1214 s
agent0:                 episode reward: -0.6557,                 loss: nan
agent1:                 episode reward: 0.6557,                 loss: 0.2475
Episode: 17801/30000 (59.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4725s / 314.5939 s
agent0:                 episode reward: -0.9164,                 loss: nan
agent1:                 episode reward: 0.9164,                 loss: 0.2512
Episode: 17821/30000 (59.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4651s / 315.0590 s
agent0:                 episode reward: -0.7835,                 loss: nan
agent1:                 episode reward: 0.7835,                 loss: 0.2441
Episode: 17841/30000 (59.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4893s / 315.5482 s
agent0:                 episode reward: -0.8494,                 loss: nan
agent1:                 episode reward: 0.8494,                 loss: 0.2498
Episode: 17861/30000 (59.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4990s / 316.0473 s
agent0:                 episode reward: -0.8868,                 loss: nan
agent1:                 episode reward: 0.8868,                 loss: 0.2520
Episode: 17881/30000 (59.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4788s / 316.5261 s
agent0:                 episode reward: -0.5088,                 loss: nan
agent1:                 episode reward: 0.5088,                 loss: 0.2534
Episode: 17901/30000 (59.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4650s / 316.9911 s
agent0:                 episode reward: -0.8667,                 loss: nan
agent1:                 episode reward: 0.8667,                 loss: 0.2669
Episode: 17921/30000 (59.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4732s / 317.4644 s
agent0:                 episode reward: -0.9013,                 loss: nan
agent1:                 episode reward: 0.9013,                 loss: 0.2603
Episode: 17941/30000 (59.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4774s / 317.9418 s
agent0:                 episode reward: -0.7357,                 loss: nan
agent1:                 episode reward: 0.7357,                 loss: 0.2670
Episode: 17961/30000 (59.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4713s / 318.4131 s
agent0:                 episode reward: -1.0839,                 loss: nan
agent1:                 episode reward: 1.0839,                 loss: 0.2620
Episode: 17981/30000 (59.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4728s / 318.8859 s
agent0:                 episode reward: -0.6528,                 loss: nan
agent1:                 episode reward: 0.6528,                 loss: 0.2648
Episode: 18001/30000 (60.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4741s / 319.3600 s
agent0:                 episode reward: -0.6077,                 loss: nan
agent1:                 episode reward: 0.6077,                 loss: 0.2646
Episode: 18021/30000 (60.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4882s / 319.8483 s
agent0:                 episode reward: -0.3886,                 loss: nan
agent1:                 episode reward: 0.3886,                 loss: 0.2630
Episode: 18041/30000 (60.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4916s / 320.3399 s
agent0:                 episode reward: -0.5820,                 loss: nan
agent1:                 episode reward: 0.5820,                 loss: 0.2607
Episode: 18061/30000 (60.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4661s / 320.8060 s
agent0:                 episode reward: -1.0135,                 loss: nan
agent1:                 episode reward: 1.0135,                 loss: 0.2654
Episode: 18081/30000 (60.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4900s / 321.2960 s
agent0:                 episode reward: -0.5409,                 loss: nan
agent1:                 episode reward: 0.5409,                 loss: 0.2683
Episode: 18101/30000 (60.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5224s / 321.8184 s
agent0:                 episode reward: -0.7218,                 loss: nan
agent1:                 episode reward: 0.7218,                 loss: 0.2626
Episode: 18121/30000 (60.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4751s / 322.2935 s
agent0:                 episode reward: -0.7852,                 loss: nan
agent1:                 episode reward: 0.7852,                 loss: 0.2585
Episode: 18141/30000 (60.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4691s / 322.7626 s
agent0:                 episode reward: -0.6951,                 loss: nan
agent1:                 episode reward: 0.6951,                 loss: 0.2640
Episode: 18161/30000 (60.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4687s / 323.2313 s
agent0:                 episode reward: -0.4793,                 loss: nan
agent1:                 episode reward: 0.4793,                 loss: 0.2669
Episode: 18181/30000 (60.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5159s / 323.7471 s
agent0:                 episode reward: -0.9141,                 loss: nan
agent1:                 episode reward: 0.9141,                 loss: 0.2634
Episode: 18201/30000 (60.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4756s / 324.2227 s
agent0:                 episode reward: -0.7044,                 loss: nan
agent1:                 episode reward: 0.7044,                 loss: 0.2644
Episode: 18221/30000 (60.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4764s / 324.6991 s
agent0:                 episode reward: -0.7133,                 loss: nan
agent1:                 episode reward: 0.7133,                 loss: 0.2568
Episode: 18241/30000 (60.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4747s / 325.1738 s
agent0:                 episode reward: -0.7827,                 loss: nan
agent1:                 episode reward: 0.7827,                 loss: 0.2365
Episode: 18261/30000 (60.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5331s / 325.7069 s
agent0:                 episode reward: -1.0505,                 loss: nan
agent1:                 episode reward: 1.0505,                 loss: 0.2382
Episode: 18281/30000 (60.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4737s / 326.1806 s
agent0:                 episode reward: -0.9394,                 loss: nan
agent1:                 episode reward: 0.9394,                 loss: 0.2382
Episode: 18301/30000 (61.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4855s / 326.6661 s
agent0:                 episode reward: -1.0431,                 loss: nan
agent1:                 episode reward: 1.0431,                 loss: 0.2355
Episode: 18321/30000 (61.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5244s / 327.1905 s
agent0:                 episode reward: -0.5621,                 loss: nan
agent1:                 episode reward: 0.5621,                 loss: 0.2333
Episode: 18341/30000 (61.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4689s / 327.6595 s
agent0:                 episode reward: -0.8330,                 loss: nan
agent1:                 episode reward: 0.8330,                 loss: 0.2365
Episode: 18361/30000 (61.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4739s / 328.1334 s
agent0:                 episode reward: -0.9757,                 loss: nan
agent1:                 episode reward: 0.9757,                 loss: 0.2326
Episode: 18381/30000 (61.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4787s / 328.6120 s
agent0:                 episode reward: -0.7718,                 loss: nan
agent1:                 episode reward: 0.7718,                 loss: 0.2353
Episode: 18401/30000 (61.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4814s / 329.0934 s
agent0:                 episode reward: -0.6228,                 loss: nan
agent1:                 episode reward: 0.6228,                 loss: 0.2373
Episode: 18421/30000 (61.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4886s / 329.5820 s
agent0:                 episode reward: -0.5178,                 loss: nan
agent1:                 episode reward: 0.5178,                 loss: 0.2347
Episode: 18441/30000 (61.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4750s / 330.0571 s
agent0:                 episode reward: -0.8887,                 loss: nan
agent1:                 episode reward: 0.8887,                 loss: 0.2364
Episode: 18461/30000 (61.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4756s / 330.5327 s
agent0:                 episode reward: -0.8758,                 loss: nan
agent1:                 episode reward: 0.8758,                 loss: 0.2356
Episode: 18481/30000 (61.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4789s / 331.0116 s
agent0:                 episode reward: -1.0358,                 loss: nan
agent1:                 episode reward: 1.0358,                 loss: 0.2386
Episode: 18501/30000 (61.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4825s / 331.4940 s
agent0:                 episode reward: -0.7982,                 loss: nan
agent1:                 episode reward: 0.7982,                 loss: 0.2319
Episode: 18521/30000 (61.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5211s / 332.0152 s
agent0:                 episode reward: -0.8457,                 loss: nan
agent1:                 episode reward: 0.8457,                 loss: 0.2357
Episode: 18541/30000 (61.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4817s / 332.4969 s
agent0:                 episode reward: -1.0241,                 loss: nan
agent1:                 episode reward: 1.0241,                 loss: 0.2347
Episode: 18561/30000 (61.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4973s / 332.9942 s
agent0:                 episode reward: -0.8502,                 loss: nan
agent1:                 episode reward: 0.8502,                 loss: 0.2547
Episode: 18581/30000 (61.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4779s / 333.4721 s
agent0:                 episode reward: -0.8865,                 loss: nan
agent1:                 episode reward: 0.8865,                 loss: 0.2561
Episode: 18601/30000 (62.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5006s / 333.9727 s
agent0:                 episode reward: -0.6696,                 loss: nan
agent1:                 episode reward: 0.6696,                 loss: 0.2555
Episode: 18621/30000 (62.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4893s / 334.4621 s
agent0:                 episode reward: -0.5332,                 loss: nan
agent1:                 episode reward: 0.5332,                 loss: 0.2612
Episode: 18641/30000 (62.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4819s / 334.9440 s
agent0:                 episode reward: -0.4134,                 loss: nan
agent1:                 episode reward: 0.4134,                 loss: 0.2618
Episode: 18661/30000 (62.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4808s / 335.4248 s
agent0:                 episode reward: -0.5309,                 loss: nan
agent1:                 episode reward: 0.5309,                 loss: 0.2602
Episode: 18681/30000 (62.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4902s / 335.9149 s
agent0:                 episode reward: -0.6057,                 loss: nan
agent1:                 episode reward: 0.6057,                 loss: 0.2592
Episode: 18701/30000 (62.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4830s / 336.3979 s
agent0:                 episode reward: -0.9229,                 loss: nan
agent1:                 episode reward: 0.9229,                 loss: 0.2591
Episode: 18721/30000 (62.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4803s / 336.8783 s
agent0:                 episode reward: -0.6186,                 loss: nan
agent1:                 episode reward: 0.6186,                 loss: 0.2551
Episode: 18741/30000 (62.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4758s / 337.3541 s
agent0:                 episode reward: -0.9806,                 loss: nan
agent1:                 episode reward: 0.9806,                 loss: 0.2603
Episode: 18761/30000 (62.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4795s / 337.8336 s
agent0:                 episode reward: -0.7505,                 loss: nan
agent1:                 episode reward: 0.7505,                 loss: 0.2569
Episode: 18781/30000 (62.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4798s / 338.3134 s
agent0:                 episode reward: -0.9004,                 loss: nan
agent1:                 episode reward: 0.9004,                 loss: 0.2583
Episode: 18801/30000 (62.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5031s / 338.8166 s
agent0:                 episode reward: -0.9596,                 loss: nan
agent1:                 episode reward: 0.9596,                 loss: 0.2589
Episode: 18821/30000 (62.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4824s / 339.2990 s
agent0:                 episode reward: -0.6036,                 loss: nan
agent1:                 episode reward: 0.6036,                 loss: 0.2599
Episode: 18841/30000 (62.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4828s / 339.7817 s
agent0:                 episode reward: -1.0215,                 loss: nan
agent1:                 episode reward: 1.0215,                 loss: 0.2604
Episode: 18861/30000 (62.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4756s / 340.2573 s
agent0:                 episode reward: -0.5769,                 loss: nan
agent1:                 episode reward: 0.5769,                 loss: 0.2602
Episode: 18881/30000 (62.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4795s / 340.7369 s
agent0:                 episode reward: -0.9940,                 loss: nan
agent1:                 episode reward: 0.9940,                 loss: 0.2614
Episode: 18901/30000 (63.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4791s / 341.2160 s
agent0:                 episode reward: -1.0199,                 loss: nan
agent1:                 episode reward: 1.0199,                 loss: 0.2628
Episode: 18921/30000 (63.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4897s / 341.7056 s
agent0:                 episode reward: -0.7880,                 loss: nan
agent1:                 episode reward: 0.7880,                 loss: 0.2574
Episode: 18941/30000 (63.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5424s / 342.2480 s
agent0:                 episode reward: -1.2247,                 loss: nan
agent1:                 episode reward: 1.2247,                 loss: 0.2560
Episode: 18961/30000 (63.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4916s / 342.7396 s
agent0:                 episode reward: -0.6674,                 loss: nan
agent1:                 episode reward: 0.6674,                 loss: 0.2563
Episode: 18981/30000 (63.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4890s / 343.2286 s
agent0:                 episode reward: -0.6204,                 loss: nan
agent1:                 episode reward: 0.6204,                 loss: 0.2514
Episode: 19001/30000 (63.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4856s / 343.7142 s
agent0:                 episode reward: -1.0094,                 loss: nan
agent1:                 episode reward: 1.0094,                 loss: 0.2569
Episode: 19021/30000 (63.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4859s / 344.2001 s
agent0:                 episode reward: -0.9394,                 loss: nan
agent1:                 episode reward: 0.9394,                 loss: 0.2568
Episode: 19041/30000 (63.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5104s / 344.7106 s
agent0:                 episode reward: -1.0938,                 loss: nan
agent1:                 episode reward: 1.0938,                 loss: 0.2561
Episode: 19061/30000 (63.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4861s / 345.1967 s
agent0:                 episode reward: -0.7604,                 loss: nan
agent1:                 episode reward: 0.7604,                 loss: 0.2523
Episode: 19081/30000 (63.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4903s / 345.6870 s
agent0:                 episode reward: -1.0197,                 loss: nan
agent1:                 episode reward: 1.0197,                 loss: 0.2590
Episode: 19101/30000 (63.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4749s / 346.1619 s
agent0:                 episode reward: -0.8114,                 loss: nan
agent1:                 episode reward: 0.8114,                 loss: 0.2529
Episode: 19121/30000 (63.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4779s / 346.6398 s
agent0:                 episode reward: -0.7074,                 loss: nan
agent1:                 episode reward: 0.7074,                 loss: 0.2540
Episode: 19141/30000 (63.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4795s / 347.1193 s
agent0:                 episode reward: -0.9179,                 loss: nan
agent1:                 episode reward: 0.9179,                 loss: 0.2586
Episode: 19161/30000 (63.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4900s / 347.6093 s
agent0:                 episode reward: -0.8331,                 loss: nan
agent1:                 episode reward: 0.8331,                 loss: 0.2559
Episode: 19181/30000 (63.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4776s / 348.0869 s
agent0:                 episode reward: -1.0202,                 loss: nan
agent1:                 episode reward: 1.0202,                 loss: 0.2540
Episode: 19201/30000 (64.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4791s / 348.5660 s
agent0:                 episode reward: -1.0967,                 loss: nan
agent1:                 episode reward: 1.0967,                 loss: 0.2543
Episode: 19221/30000 (64.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4818s / 349.0478 s
agent0:                 episode reward: -0.4951,                 loss: nan
agent1:                 episode reward: 0.4951,                 loss: 0.2536
Episode: 19241/30000 (64.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4899s / 349.5377 s
agent0:                 episode reward: -1.1204,                 loss: nan
agent1:                 episode reward: 1.1204,                 loss: 0.2256
Episode: 19261/30000 (64.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4905s / 350.0282 s
agent0:                 episode reward: -0.7708,                 loss: nan
agent1:                 episode reward: 0.7708,                 loss: 0.2246
Episode: 19281/30000 (64.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5229s / 350.5511 s
agent0:                 episode reward: -0.7624,                 loss: nan
agent1:                 episode reward: 0.7624,                 loss: 0.2184
Episode: 19301/30000 (64.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4944s / 351.0455 s
agent0:                 episode reward: -0.7873,                 loss: nan
agent1:                 episode reward: 0.7873,                 loss: 0.2216
Episode: 19321/30000 (64.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4969s / 351.5424 s
agent0:                 episode reward: -0.6175,                 loss: nan
agent1:                 episode reward: 0.6175,                 loss: 0.2231
Episode: 19341/30000 (64.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4829s / 352.0253 s
agent0:                 episode reward: -0.8246,                 loss: nan
agent1:                 episode reward: 0.8246,                 loss: 0.2215
Episode: 19361/30000 (64.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5554s / 352.5807 s
agent0:                 episode reward: -0.7962,                 loss: nan
agent1:                 episode reward: 0.7962,                 loss: 0.2250
Episode: 19381/30000 (64.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4913s / 353.0720 s
agent0:                 episode reward: -0.7062,                 loss: nan
agent1:                 episode reward: 0.7062,                 loss: 0.2206
Episode: 19401/30000 (64.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5098s / 353.5818 s
agent0:                 episode reward: -0.8946,                 loss: nan
agent1:                 episode reward: 0.8946,                 loss: 0.2210
Episode: 19421/30000 (64.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4928s / 354.0746 s
agent0:                 episode reward: -0.7743,                 loss: nan
agent1:                 episode reward: 0.7743,                 loss: 0.2227
Episode: 19441/30000 (64.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4885s / 354.5631 s
agent0:                 episode reward: -0.7708,                 loss: nan
agent1:                 episode reward: 0.7708,                 loss: 0.2236
Episode: 19461/30000 (64.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4813s / 355.0444 s
agent0:                 episode reward: -0.5840,                 loss: nan
agent1:                 episode reward: 0.5840,                 loss: 0.2221
Episode: 19481/30000 (64.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5005s / 355.5449 s
agent0:                 episode reward: -0.7299,                 loss: nan
agent1:                 episode reward: 0.7299,                 loss: 0.2199
Episode: 19501/30000 (65.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4861s / 356.0309 s
agent0:                 episode reward: -0.9483,                 loss: nan
agent1:                 episode reward: 0.9483,                 loss: 0.2213
Episode: 19521/30000 (65.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5207s / 356.5516 s
agent0:                 episode reward: -1.0107,                 loss: nan
agent1:                 episode reward: 1.0107,                 loss: 0.2246
Episode: 19541/30000 (65.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4901s / 357.0417 s
agent0:                 episode reward: -0.7959,                 loss: nan
agent1:                 episode reward: 0.7959,                 loss: 0.2255
Episode: 19561/30000 (65.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4900s / 357.5317 s
agent0:                 episode reward: -0.3984,                 loss: nan
agent1:                 episode reward: 0.3984,                 loss: 0.2544
Episode: 19581/30000 (65.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4918s / 358.0235 s
agent0:                 episode reward: -0.8869,                 loss: nan
agent1:                 episode reward: 0.8869,                 loss: 0.2636
Episode: 19601/30000 (65.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4970s / 358.5205 s
agent0:                 episode reward: -0.7318,                 loss: nan
agent1:                 episode reward: 0.7318,                 loss: 0.2661
Episode: 19621/30000 (65.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5152s / 359.0357 s
agent0:                 episode reward: -0.7940,                 loss: nan
agent1:                 episode reward: 0.7940,                 loss: 0.2638
Episode: 19641/30000 (65.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5052s / 359.5409 s
agent0:                 episode reward: -0.7704,                 loss: nan
agent1:                 episode reward: 0.7704,                 loss: 0.2614
Episode: 19661/30000 (65.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4926s / 360.0334 s
agent0:                 episode reward: -0.5475,                 loss: nan
agent1:                 episode reward: 0.5475,                 loss: 0.2658
Episode: 19681/30000 (65.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4937s / 360.5272 s
agent0:                 episode reward: -0.5765,                 loss: nan
agent1:                 episode reward: 0.5765,                 loss: 0.2649
Episode: 19701/30000 (65.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4919s / 361.0191 s
agent0:                 episode reward: -0.7154,                 loss: nan
agent1:                 episode reward: 0.7154,                 loss: 0.2690
Episode: 19721/30000 (65.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4937s / 361.5128 s
agent0:                 episode reward: -0.6233,                 loss: nan
agent1:                 episode reward: 0.6233,                 loss: 0.2673
Episode: 19741/30000 (65.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4929s / 362.0057 s
agent0:                 episode reward: -0.8673,                 loss: nan
agent1:                 episode reward: 0.8673,                 loss: 0.2613
Episode: 19761/30000 (65.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5122s / 362.5179 s
agent0:                 episode reward: -0.9930,                 loss: nan
agent1:                 episode reward: 0.9930,                 loss: 0.2650
Episode: 19781/30000 (65.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5439s / 363.0618 s
agent0:                 episode reward: -0.9176,                 loss: nan
agent1:                 episode reward: 0.9176,                 loss: 0.2620
Episode: 19801/30000 (66.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4942s / 363.5560 s
agent0:                 episode reward: -0.8406,                 loss: nan
agent1:                 episode reward: 0.8406,                 loss: 0.2634
Episode: 19821/30000 (66.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4974s / 364.0534 s
agent0:                 episode reward: -1.1559,                 loss: nan
agent1:                 episode reward: 1.1559,                 loss: 0.2616
Episode: 19841/30000 (66.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4952s / 364.5486 s
agent0:                 episode reward: -1.1112,                 loss: nan
agent1:                 episode reward: 1.1112,                 loss: 0.2581
Episode: 19861/30000 (66.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4983s / 365.0469 s
agent0:                 episode reward: -0.5447,                 loss: nan
agent1:                 episode reward: 0.5447,                 loss: 0.2636
Episode: 19881/30000 (66.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5024s / 365.5493 s
agent0:                 episode reward: -0.6657,                 loss: nan
agent1:                 episode reward: 0.6657,                 loss: 0.2659
Episode: 19901/30000 (66.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5021s / 366.0514 s
agent0:                 episode reward: -0.6478,                 loss: nan
agent1:                 episode reward: 0.6478,                 loss: 0.2634
Episode: 19921/30000 (66.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4933s / 366.5447 s
agent0:                 episode reward: -1.3132,                 loss: nan
agent1:                 episode reward: 1.3132,                 loss: 0.2575
Episode: 19941/30000 (66.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5171s / 367.0618 s
agent0:                 episode reward: -0.5928,                 loss: nan
agent1:                 episode reward: 0.5928,                 loss: 0.2552
Episode: 19961/30000 (66.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4899s / 367.5517 s
agent0:                 episode reward: -1.0534,                 loss: nan
agent1:                 episode reward: 1.0534,                 loss: 0.2595
Episode: 19981/30000 (66.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4909s / 368.0426 s
agent0:                 episode reward: -0.9485,                 loss: nan
agent1:                 episode reward: 0.9485,                 loss: 0.2584
Episode: 20001/30000 (66.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5015s / 368.5441 s
agent0:                 episode reward: -1.0789,                 loss: nan
agent1:                 episode reward: 1.0789,                 loss: 0.2570
Episode: 20021/30000 (66.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4972s / 369.0413 s
agent0:                 episode reward: -0.6873,                 loss: nan
agent1:                 episode reward: 0.6873,                 loss: 0.2551
Episode: 20041/30000 (66.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4942s / 369.5355 s
agent0:                 episode reward: -0.8280,                 loss: nan
agent1:                 episode reward: 0.8280,                 loss: 0.2565
Episode: 20061/30000 (66.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4953s / 370.0308 s
agent0:                 episode reward: -0.9941,                 loss: nan
agent1:                 episode reward: 0.9941,                 loss: 0.2608
Episode: 20081/30000 (66.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4936s / 370.5243 s
agent0:                 episode reward: -0.7768,                 loss: nan
agent1:                 episode reward: 0.7768,                 loss: 0.2579
Episode: 20101/30000 (67.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4941s / 371.0184 s
agent0:                 episode reward: -0.6584,                 loss: nan
agent1:                 episode reward: 0.6584,                 loss: 0.2576
Episode: 20121/30000 (67.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5043s / 371.5227 s
agent0:                 episode reward: -0.8415,                 loss: nan
agent1:                 episode reward: 0.8415,                 loss: 0.2568
Episode: 20141/30000 (67.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5068s / 372.0295 s
agent0:                 episode reward: -1.0778,                 loss: nan
agent1:                 episode reward: 1.0778,                 loss: 0.2595
Episode: 20161/30000 (67.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5016s / 372.5311 s
agent0:                 episode reward: -0.9853,                 loss: nan
agent1:                 episode reward: 0.9853,                 loss: 0.2575
Episode: 20181/30000 (67.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5539s / 373.0850 s
agent0:                 episode reward: -0.5804,                 loss: nan
agent1:                 episode reward: 0.5804,                 loss: 0.2558
Episode: 20201/30000 (67.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5065s / 373.5915 s
agent0:                 episode reward: -0.5936,                 loss: nan
agent1:                 episode reward: 0.5936,                 loss: 0.2561
Episode: 20221/30000 (67.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5081s / 374.0996 s
agent0:                 episode reward: -0.9417,                 loss: nan
agent1:                 episode reward: 0.9417,                 loss: 0.2533
Episode: 20241/30000 (67.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5143s / 374.6139 s
agent0:                 episode reward: -0.5411,                 loss: nan
agent1:                 episode reward: 0.5411,                 loss: 0.2298
Episode: 20261/30000 (67.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5049s / 375.1189 s
agent0:                 episode reward: -1.0236,                 loss: nan
agent1:                 episode reward: 1.0236,                 loss: 0.2292
Episode: 20281/30000 (67.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5133s / 375.6322 s
agent0:                 episode reward: -0.4662,                 loss: nan
agent1:                 episode reward: 0.4662,                 loss: 0.2273
Episode: 20301/30000 (67.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4996s / 376.1318 s
agent0:                 episode reward: -0.5545,                 loss: nan
agent1:                 episode reward: 0.5545,                 loss: 0.2274
Episode: 20321/30000 (67.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4966s / 376.6284 s
agent0:                 episode reward: -0.7713,                 loss: nan
agent1:                 episode reward: 0.7713,                 loss: 0.2294
Episode: 20341/30000 (67.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5057s / 377.1341 s
agent0:                 episode reward: -1.0919,                 loss: nan
agent1:                 episode reward: 1.0919,                 loss: 0.2327
Episode: 20361/30000 (67.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5148s / 377.6489 s
agent0:                 episode reward: -0.7930,                 loss: nan
agent1:                 episode reward: 0.7930,                 loss: 0.2285
Episode: 20381/30000 (67.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5011s / 378.1500 s
agent0:                 episode reward: -0.7486,                 loss: nan
agent1:                 episode reward: 0.7486,                 loss: 0.2296
Episode: 20401/30000 (68.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5056s / 378.6556 s
agent0:                 episode reward: -0.8821,                 loss: nan
agent1:                 episode reward: 0.8821,                 loss: 0.2257
Episode: 20421/30000 (68.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5062s / 379.1619 s
agent0:                 episode reward: -0.9219,                 loss: nan
agent1:                 episode reward: 0.9219,                 loss: 0.2247
Episode: 20441/30000 (68.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5084s / 379.6703 s
agent0:                 episode reward: -0.7088,                 loss: nan
agent1:                 episode reward: 0.7088,                 loss: 0.2289
Episode: 20461/30000 (68.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5054s / 380.1757 s
agent0:                 episode reward: -0.6894,                 loss: nan
agent1:                 episode reward: 0.6894,                 loss: 0.2298
Episode: 20481/30000 (68.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4995s / 380.6752 s
agent0:                 episode reward: -0.7499,                 loss: nan
agent1:                 episode reward: 0.7499,                 loss: 0.2296
Episode: 20501/30000 (68.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5060s / 381.1812 s
agent0:                 episode reward: -0.9890,                 loss: nan
agent1:                 episode reward: 0.9890,                 loss: 0.2319
Episode: 20521/30000 (68.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5020s / 381.6831 s
agent0:                 episode reward: -0.9055,                 loss: nan
agent1:                 episode reward: 0.9055,                 loss: 0.2290
Episode: 20541/30000 (68.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5147s / 382.1978 s
agent0:                 episode reward: -0.8080,                 loss: nan
agent1:                 episode reward: 0.8080,                 loss: 0.2275
Episode: 20561/30000 (68.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5008s / 382.6985 s
agent0:                 episode reward: -0.9757,                 loss: nan
agent1:                 episode reward: 0.9757,                 loss: 0.2620
Episode: 20581/30000 (68.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5545s / 383.2531 s
agent0:                 episode reward: -0.7121,                 loss: nan
agent1:                 episode reward: 0.7121,                 loss: 0.2703
Episode: 20601/30000 (68.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5460s / 383.7990 s
agent0:                 episode reward: -0.8349,                 loss: nan
agent1:                 episode reward: 0.8349,                 loss: 0.2638
Episode: 20621/30000 (68.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5008s / 384.2998 s
agent0:                 episode reward: -1.0821,                 loss: nan
agent1:                 episode reward: 1.0821,                 loss: 0.2697
Episode: 20641/30000 (68.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5046s / 384.8044 s
agent0:                 episode reward: -1.0614,                 loss: nan
agent1:                 episode reward: 1.0614,                 loss: 0.2685
Episode: 20661/30000 (68.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5072s / 385.3116 s
agent0:                 episode reward: -0.6849,                 loss: nan
agent1:                 episode reward: 0.6849,                 loss: 0.2717
Episode: 20681/30000 (68.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4964s / 385.8080 s
agent0:                 episode reward: -1.0900,                 loss: nan
agent1:                 episode reward: 1.0900,                 loss: 0.2712
Episode: 20701/30000 (69.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4979s / 386.3059 s
agent0:                 episode reward: -0.9901,                 loss: nan
agent1:                 episode reward: 0.9901,                 loss: 0.2657
Episode: 20721/30000 (69.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5091s / 386.8150 s
agent0:                 episode reward: -0.8719,                 loss: nan
agent1:                 episode reward: 0.8719,                 loss: 0.2737
Episode: 20741/30000 (69.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5067s / 387.3218 s
agent0:                 episode reward: -0.6903,                 loss: nan
agent1:                 episode reward: 0.6903,                 loss: 0.2650
Episode: 20761/30000 (69.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5101s / 387.8319 s
agent0:                 episode reward: -0.8994,                 loss: nan
agent1:                 episode reward: 0.8994,                 loss: 0.2724
Episode: 20781/30000 (69.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5064s / 388.3383 s
agent0:                 episode reward: -1.2029,                 loss: nan
agent1:                 episode reward: 1.2029,                 loss: 0.2728
Episode: 20801/30000 (69.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5092s / 388.8476 s
agent0:                 episode reward: -1.0359,                 loss: nan
agent1:                 episode reward: 1.0359,                 loss: 0.2729
Episode: 20821/30000 (69.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5111s / 389.3587 s
agent0:                 episode reward: -0.6070,                 loss: nan
agent1:                 episode reward: 0.6070,                 loss: 0.2683
Episode: 20841/30000 (69.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5173s / 389.8759 s
agent0:                 episode reward: -1.1099,                 loss: nan
agent1:                 episode reward: 1.1099,                 loss: 0.2678
Episode: 20861/30000 (69.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5091s / 390.3850 s
agent0:                 episode reward: -0.7110,                 loss: nan
agent1:                 episode reward: 0.7110,                 loss: 0.2716
Episode: 20881/30000 (69.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5104s / 390.8954 s
agent0:                 episode reward: -0.5911,                 loss: nan
agent1:                 episode reward: 0.5911,                 loss: 0.2732
Episode: 20901/30000 (69.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5085s / 391.4039 s
agent0:                 episode reward: -0.9601,                 loss: nan
agent1:                 episode reward: 0.9601,                 loss: 0.2539
Episode: 20921/30000 (69.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5308s / 391.9347 s
agent0:                 episode reward: -0.8954,                 loss: nan
agent1:                 episode reward: 0.8954,                 loss: 0.2522
Episode: 20941/30000 (69.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5082s / 392.4429 s
agent0:                 episode reward: -1.0206,                 loss: nan
agent1:                 episode reward: 1.0206,                 loss: 0.2521
Episode: 20961/30000 (69.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5119s / 392.9548 s
agent0:                 episode reward: -1.0879,                 loss: nan
agent1:                 episode reward: 1.0879,                 loss: 0.2537
Episode: 20981/30000 (69.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5491s / 393.5039 s
agent0:                 episode reward: -0.8653,                 loss: nan
agent1:                 episode reward: 0.8653,                 loss: 0.2541
Episode: 21001/30000 (70.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5114s / 394.0153 s
agent0:                 episode reward: -0.9917,                 loss: nan
agent1:                 episode reward: 0.9917,                 loss: 0.2518
Episode: 21021/30000 (70.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5084s / 394.5237 s
agent0:                 episode reward: -0.9494,                 loss: nan
agent1:                 episode reward: 0.9494,                 loss: 0.2504
Episode: 21041/30000 (70.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5080s / 395.0317 s
agent0:                 episode reward: -0.9241,                 loss: nan
agent1:                 episode reward: 0.9241,                 loss: 0.2524
Episode: 21061/30000 (70.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5256s / 395.5573 s
agent0:                 episode reward: -0.8585,                 loss: nan
agent1:                 episode reward: 0.8585,                 loss: 0.2524
Episode: 21081/30000 (70.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5233s / 396.0805 s
agent0:                 episode reward: -0.7579,                 loss: nan
agent1:                 episode reward: 0.7579,                 loss: 0.2517
Episode: 21101/30000 (70.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5134s / 396.5939 s
agent0:                 episode reward: -0.7811,                 loss: nan
agent1:                 episode reward: 0.7811,                 loss: 0.2525
Episode: 21121/30000 (70.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5123s / 397.1062 s
agent0:                 episode reward: -0.7337,                 loss: nan
agent1:                 episode reward: 0.7337,                 loss: 0.2494
Episode: 21141/30000 (70.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5135s / 397.6197 s
agent0:                 episode reward: -0.7026,                 loss: nan
agent1:                 episode reward: 0.7026,                 loss: 0.2532
Episode: 21161/30000 (70.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5145s / 398.1342 s
agent0:                 episode reward: -0.9536,                 loss: nan
agent1:                 episode reward: 0.9536,                 loss: 0.2542
Episode: 21181/30000 (70.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5217s / 398.6560 s
agent0:                 episode reward: -0.7939,                 loss: nan
agent1:                 episode reward: 0.7939,                 loss: 0.2543
Episode: 21201/30000 (70.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5321s / 399.1880 s
agent0:                 episode reward: -0.7968,                 loss: nan
agent1:                 episode reward: 0.7968,                 loss: 0.2521
Episode: 21221/30000 (70.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5057s / 399.6938 s
agent0:                 episode reward: -0.8828,                 loss: nan
agent1:                 episode reward: 0.8828,                 loss: 0.2551
Episode: 21241/30000 (70.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5275s / 400.2213 s
agent0:                 episode reward: -1.0196,                 loss: nan
agent1:                 episode reward: 1.0196,                 loss: 0.2259
Episode: 21261/30000 (70.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5107s / 400.7319 s
agent0:                 episode reward: -0.7509,                 loss: nan
agent1:                 episode reward: 0.7509,                 loss: 0.2300
Episode: 21281/30000 (70.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5131s / 401.2450 s
agent0:                 episode reward: -0.3423,                 loss: nan
agent1:                 episode reward: 0.3423,                 loss: 0.2277
Episode: 21301/30000 (71.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5375s / 401.7825 s
agent0:                 episode reward: -0.3885,                 loss: nan
agent1:                 episode reward: 0.3885,                 loss: 0.2264
Episode: 21321/30000 (71.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5242s / 402.3067 s
agent0:                 episode reward: -1.1354,                 loss: nan
agent1:                 episode reward: 1.1354,                 loss: 0.2293
Episode: 21341/30000 (71.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5130s / 402.8197 s
agent0:                 episode reward: -0.8467,                 loss: nan
agent1:                 episode reward: 0.8467,                 loss: 0.2232
Episode: 21361/30000 (71.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5104s / 403.3302 s
agent0:                 episode reward: -0.5522,                 loss: nan
agent1:                 episode reward: 0.5522,                 loss: 0.2248
Episode: 21381/30000 (71.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5643s / 403.8945 s
agent0:                 episode reward: -0.9477,                 loss: nan
agent1:                 episode reward: 0.9477,                 loss: 0.2275
Episode: 21401/30000 (71.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5188s / 404.4133 s
agent0:                 episode reward: -0.8648,                 loss: nan
agent1:                 episode reward: 0.8648,                 loss: 0.2271
Episode: 21421/30000 (71.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5235s / 404.9368 s
agent0:                 episode reward: -0.8070,                 loss: nan
agent1:                 episode reward: 0.8070,                 loss: 0.2243
Episode: 21441/30000 (71.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5163s / 405.4531 s
agent0:                 episode reward: -1.0454,                 loss: nan
agent1:                 episode reward: 1.0454,                 loss: 0.2237
Episode: 21461/30000 (71.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5152s / 405.9683 s
agent0:                 episode reward: -0.9356,                 loss: nan
agent1:                 episode reward: 0.9356,                 loss: 0.2259
Episode: 21481/30000 (71.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5170s / 406.4853 s
agent0:                 episode reward: -1.1265,                 loss: nan
agent1:                 episode reward: 1.1265,                 loss: 0.2229
Episode: 21501/30000 (71.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5209s / 407.0062 s
agent0:                 episode reward: -0.7285,                 loss: nan
agent1:                 episode reward: 0.7285,                 loss: 0.2279
Episode: 21521/30000 (71.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5153s / 407.5214 s
agent0:                 episode reward: -0.7787,                 loss: nan
agent1:                 episode reward: 0.7787,                 loss: 0.2256
Episode: 21541/30000 (71.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5223s / 408.0437 s
agent0:                 episode reward: -1.0530,                 loss: nan
agent1:                 episode reward: 1.0530,                 loss: 0.2289
Episode: 21561/30000 (71.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5298s / 408.5735 s
agent0:                 episode reward: -1.0054,                 loss: nan
agent1:                 episode reward: 1.0054,                 loss: 0.2740
Episode: 21581/30000 (71.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5150s / 409.0885 s
agent0:                 episode reward: -0.8003,                 loss: nan
agent1:                 episode reward: 0.8003,                 loss: 0.2755
Episode: 21601/30000 (72.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5155s / 409.6041 s
agent0:                 episode reward: -1.4389,                 loss: nan
agent1:                 episode reward: 1.4389,                 loss: 0.2751
Episode: 21621/30000 (72.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5152s / 410.1193 s
agent0:                 episode reward: -1.0534,                 loss: nan
agent1:                 episode reward: 1.0534,                 loss: 0.2741
Episode: 21641/30000 (72.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5097s / 410.6290 s
agent0:                 episode reward: -0.7910,                 loss: nan
agent1:                 episode reward: 0.7910,                 loss: 0.2731
Episode: 21661/30000 (72.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5152s / 411.1443 s
agent0:                 episode reward: -0.6760,                 loss: nan
agent1:                 episode reward: 0.6760,                 loss: 0.2761
Episode: 21681/30000 (72.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5148s / 411.6590 s
agent0:                 episode reward: -0.9385,                 loss: nan
agent1:                 episode reward: 0.9385,                 loss: 0.2738
Episode: 21701/30000 (72.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5199s / 412.1789 s
agent0:                 episode reward: -0.6830,                 loss: nan
agent1:                 episode reward: 0.6830,                 loss: 0.2752
Episode: 21721/30000 (72.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5197s / 412.6986 s
agent0:                 episode reward: -0.7265,                 loss: nan
agent1:                 episode reward: 0.7265,                 loss: 0.2733
Episode: 21741/30000 (72.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5141s / 413.2127 s
agent0:                 episode reward: -0.7159,                 loss: nan
agent1:                 episode reward: 0.7159,                 loss: 0.2709
Episode: 21761/30000 (72.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5306s / 413.7433 s
agent0:                 episode reward: -0.8059,                 loss: nan
agent1:                 episode reward: 0.8059,                 loss: 0.2745
Episode: 21781/30000 (72.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5755s / 414.3189 s
agent0:                 episode reward: -0.7699,                 loss: nan
agent1:                 episode reward: 0.7699,                 loss: 0.2727
Episode: 21801/30000 (72.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5225s / 414.8414 s
agent0:                 episode reward: -0.9848,                 loss: nan
agent1:                 episode reward: 0.9848,                 loss: 0.2775
Episode: 21821/30000 (72.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5194s / 415.3608 s
agent0:                 episode reward: -0.5037,                 loss: nan
agent1:                 episode reward: 0.5037,                 loss: 0.2714
Episode: 21841/30000 (72.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5173s / 415.8780 s
agent0:                 episode reward: -0.9133,                 loss: nan
agent1:                 episode reward: 0.9133,                 loss: 0.2755
Episode: 21861/30000 (72.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5160s / 416.3941 s
agent0:                 episode reward: -1.0179,                 loss: nan
agent1:                 episode reward: 1.0179,                 loss: 0.2767
Episode: 21881/30000 (72.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5384s / 416.9324 s
agent0:                 episode reward: -1.1347,                 loss: nan
agent1:                 episode reward: 1.1347,                 loss: 0.2805
Episode: 21901/30000 (73.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5217s / 417.4541 s
agent0:                 episode reward: -0.8400,                 loss: nan
agent1:                 episode reward: 0.8400,                 loss: 0.2496
Episode: 21921/30000 (73.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5207s / 417.9748 s
agent0:                 episode reward: -0.9048,                 loss: nan
agent1:                 episode reward: 0.9048,                 loss: 0.2520
Episode: 21941/30000 (73.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5210s / 418.4958 s
agent0:                 episode reward: -0.6759,                 loss: nan
agent1:                 episode reward: 0.6759,                 loss: 0.2452
Episode: 21961/30000 (73.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5171s / 419.0129 s
agent0:                 episode reward: -0.5250,                 loss: nan
agent1:                 episode reward: 0.5250,                 loss: 0.2467
Episode: 21981/30000 (73.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5488s / 419.5618 s
agent0:                 episode reward: -0.8084,                 loss: nan
agent1:                 episode reward: 0.8084,                 loss: 0.2506
Episode: 22001/30000 (73.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5173s / 420.0791 s
agent0:                 episode reward: -0.6383,                 loss: nan
agent1:                 episode reward: 0.6383,                 loss: 0.2461
Episode: 22021/30000 (73.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5191s / 420.5982 s
agent0:                 episode reward: -0.5873,                 loss: nan
agent1:                 episode reward: 0.5873,                 loss: 0.2454
Episode: 22041/30000 (73.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5189s / 421.1171 s
agent0:                 episode reward: -0.9294,                 loss: nan
agent1:                 episode reward: 0.9294,                 loss: 0.2490
Episode: 22061/30000 (73.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5195s / 421.6366 s
agent0:                 episode reward: -0.9750,                 loss: nan
agent1:                 episode reward: 0.9750,                 loss: 0.2461
Episode: 22081/30000 (73.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5209s / 422.1575 s
agent0:                 episode reward: -0.9146,                 loss: nan
agent1:                 episode reward: 0.9146,                 loss: 0.2468
Episode: 22101/30000 (73.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5635s / 422.7211 s
agent0:                 episode reward: -0.7961,                 loss: nan
agent1:                 episode reward: 0.7961,                 loss: 0.2440
Episode: 22121/30000 (73.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5297s / 423.2508 s
agent0:                 episode reward: -0.5317,                 loss: nan
agent1:                 episode reward: 0.5317,                 loss: 0.2461
Episode: 22141/30000 (73.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5264s / 423.7772 s
agent0:                 episode reward: -0.9921,                 loss: nan
agent1:                 episode reward: 0.9921,                 loss: 0.2453
Episode: 22161/30000 (73.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5976s / 424.3748 s
agent0:                 episode reward: -0.9613,                 loss: nan
agent1:                 episode reward: 0.9613,                 loss: 0.2460
Episode: 22181/30000 (73.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5287s / 424.9035 s
agent0:                 episode reward: -0.9081,                 loss: nan
agent1:                 episode reward: 0.9081,                 loss: 0.2440
Episode: 22201/30000 (74.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5481s / 425.4516 s
agent0:                 episode reward: -0.7702,                 loss: nan
agent1:                 episode reward: 0.7702,                 loss: 0.2455
Episode: 22221/30000 (74.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5385s / 425.9901 s
agent0:                 episode reward: -0.7362,                 loss: nan
agent1:                 episode reward: 0.7362,                 loss: 0.2560
Episode: 22241/30000 (74.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5326s / 426.5228 s
agent0:                 episode reward: -0.7543,                 loss: nan
agent1:                 episode reward: 0.7543,                 loss: 0.2284
Episode: 22261/30000 (74.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5314s / 427.0542 s
agent0:                 episode reward: -0.9073,                 loss: nan
agent1:                 episode reward: 0.9073,                 loss: 0.2244
Episode: 22281/30000 (74.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5343s / 427.5884 s
agent0:                 episode reward: -0.8081,                 loss: nan
agent1:                 episode reward: 0.8081,                 loss: 0.2259
Episode: 22301/30000 (74.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5250s / 428.1134 s
agent0:                 episode reward: -0.9687,                 loss: nan
agent1:                 episode reward: 0.9687,                 loss: 0.2230
Episode: 22321/30000 (74.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5364s / 428.6498 s
agent0:                 episode reward: -0.7612,                 loss: nan
agent1:                 episode reward: 0.7612,                 loss: 0.2248
Episode: 22341/30000 (74.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5266s / 429.1763 s
agent0:                 episode reward: -1.1698,                 loss: nan
agent1:                 episode reward: 1.1698,                 loss: 0.2235
Episode: 22361/30000 (74.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5260s / 429.7024 s
agent0:                 episode reward: -1.1716,                 loss: nan
agent1:                 episode reward: 1.1716,                 loss: 0.2259
Episode: 22381/30000 (74.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5749s / 430.2773 s
agent0:                 episode reward: -0.9613,                 loss: nan
agent1:                 episode reward: 0.9613,                 loss: 0.2215
Episode: 22401/30000 (74.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5306s / 430.8079 s
agent0:                 episode reward: -0.8658,                 loss: nan
agent1:                 episode reward: 0.8658,                 loss: 0.2214
Episode: 22421/30000 (74.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5318s / 431.3397 s
agent0:                 episode reward: -0.9628,                 loss: nan
agent1:                 episode reward: 0.9628,                 loss: 0.2200
Episode: 22441/30000 (74.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5442s / 431.8839 s
agent0:                 episode reward: -0.7740,                 loss: nan
agent1:                 episode reward: 0.7740,                 loss: 0.2228
Episode: 22461/30000 (74.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5307s / 432.4146 s
agent0:                 episode reward: -0.5223,                 loss: nan
agent1:                 episode reward: 0.5223,                 loss: 0.2224
Episode: 22481/30000 (74.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5345s / 432.9491 s
agent0:                 episode reward: -0.9103,                 loss: nan
agent1:                 episode reward: 0.9103,                 loss: 0.2231
Episode: 22501/30000 (75.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5599s / 433.5090 s
agent0:                 episode reward: -0.6508,                 loss: nan
agent1:                 episode reward: 0.6508,                 loss: 0.2208
Episode: 22521/30000 (75.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5296s / 434.0386 s
agent0:                 episode reward: -1.0304,                 loss: nan
agent1:                 episode reward: 1.0304,                 loss: 0.2205
Episode: 22541/30000 (75.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5890s / 434.6277 s
agent0:                 episode reward: -0.7828,                 loss: nan
agent1:                 episode reward: 0.7828,                 loss: 0.2185
Episode: 22561/30000 (75.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5360s / 435.1636 s
agent0:                 episode reward: -0.8582,                 loss: nan
agent1:                 episode reward: 0.8582,                 loss: 0.2813
Episode: 22581/30000 (75.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5321s / 435.6957 s
agent0:                 episode reward: -0.6745,                 loss: nan
agent1:                 episode reward: 0.6745,                 loss: 0.2729
Episode: 22601/30000 (75.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5313s / 436.2270 s
agent0:                 episode reward: -0.9382,                 loss: nan
agent1:                 episode reward: 0.9382,                 loss: 0.2722
Episode: 22621/30000 (75.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5267s / 436.7537 s
agent0:                 episode reward: -0.6896,                 loss: nan
agent1:                 episode reward: 0.6896,                 loss: 0.2754
Episode: 22641/30000 (75.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5357s / 437.2893 s
agent0:                 episode reward: -0.4797,                 loss: nan
agent1:                 episode reward: 0.4797,                 loss: 0.2768
Episode: 22661/30000 (75.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5482s / 437.8375 s
agent0:                 episode reward: -0.6580,                 loss: nan
agent1:                 episode reward: 0.6580,                 loss: 0.2710
Episode: 22681/30000 (75.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5348s / 438.3723 s
agent0:                 episode reward: -0.9499,                 loss: nan
agent1:                 episode reward: 0.9499,                 loss: 0.2747
Episode: 22701/30000 (75.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5383s / 438.9106 s
agent0:                 episode reward: -0.7246,                 loss: nan
agent1:                 episode reward: 0.7246,                 loss: 0.2730
Episode: 22721/30000 (75.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5388s / 439.4494 s
agent0:                 episode reward: -0.9845,                 loss: nan
agent1:                 episode reward: 0.9845,                 loss: 0.2726
Episode: 22741/30000 (75.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5383s / 439.9877 s
agent0:                 episode reward: -1.1232,                 loss: nan
agent1:                 episode reward: 1.1232,                 loss: 0.2722
Episode: 22761/30000 (75.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5347s / 440.5224 s
agent0:                 episode reward: -0.8410,                 loss: nan
agent1:                 episode reward: 0.8410,                 loss: 0.2698
Episode: 22781/30000 (75.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5566s / 441.0790 s
agent0:                 episode reward: -1.1517,                 loss: nan
agent1:                 episode reward: 1.1517,                 loss: 0.2711
Episode: 22801/30000 (76.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5385s / 441.6176 s
agent0:                 episode reward: -0.6722,                 loss: nan
agent1:                 episode reward: 0.6722,                 loss: 0.2702
Episode: 22821/30000 (76.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5405s / 442.1580 s
agent0:                 episode reward: -1.0494,                 loss: nan
agent1:                 episode reward: 1.0494,                 loss: 0.2722
Episode: 22841/30000 (76.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5824s / 442.7404 s
agent0:                 episode reward: -0.9355,                 loss: nan
agent1:                 episode reward: 0.9355,                 loss: 0.2701
Episode: 22861/30000 (76.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5590s / 443.2994 s
agent0:                 episode reward: -0.9250,                 loss: nan
agent1:                 episode reward: 0.9250,                 loss: 0.2714
Episode: 22881/30000 (76.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5835s / 443.8829 s
agent0:                 episode reward: -0.7770,                 loss: nan
agent1:                 episode reward: 0.7770,                 loss: 0.2693
Episode: 22901/30000 (76.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5325s / 444.4154 s
agent0:                 episode reward: -0.8130,                 loss: nan
agent1:                 episode reward: 0.8130,                 loss: 0.2387
Episode: 22921/30000 (76.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6057s / 445.0210 s
agent0:                 episode reward: -0.6887,                 loss: nan
agent1:                 episode reward: 0.6887,                 loss: 0.2358
Episode: 22941/30000 (76.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5354s / 445.5564 s
agent0:                 episode reward: -0.9238,                 loss: nan
agent1:                 episode reward: 0.9238,                 loss: 0.2341
Episode: 22961/30000 (76.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5443s / 446.1007 s
agent0:                 episode reward: -0.9914,                 loss: nan
agent1:                 episode reward: 0.9914,                 loss: 0.2441
Episode: 22981/30000 (76.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5428s / 446.6435 s
agent0:                 episode reward: -0.7689,                 loss: nan
agent1:                 episode reward: 0.7689,                 loss: 0.2361
Episode: 23001/30000 (76.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5867s / 447.2302 s
agent0:                 episode reward: -0.6639,                 loss: nan
agent1:                 episode reward: 0.6639,                 loss: 0.2358
Episode: 23021/30000 (76.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5358s / 447.7660 s
agent0:                 episode reward: -0.8651,                 loss: nan
agent1:                 episode reward: 0.8651,                 loss: 0.2348
Episode: 23041/30000 (76.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5477s / 448.3137 s
agent0:                 episode reward: -0.5919,                 loss: nan
agent1:                 episode reward: 0.5919,                 loss: 0.2345
Episode: 23061/30000 (76.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5469s / 448.8606 s
agent0:                 episode reward: -1.1422,                 loss: nan
agent1:                 episode reward: 1.1422,                 loss: 0.2366
Episode: 23081/30000 (76.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5470s / 449.4075 s
agent0:                 episode reward: -0.7103,                 loss: nan
agent1:                 episode reward: 0.7103,                 loss: 0.2368
Episode: 23101/30000 (77.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5666s / 449.9741 s
agent0:                 episode reward: -1.0486,                 loss: nan
agent1:                 episode reward: 1.0486,                 loss: 0.2337
Episode: 23121/30000 (77.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5729s / 450.5470 s
agent0:                 episode reward: -1.2814,                 loss: nan
agent1:                 episode reward: 1.2814,                 loss: 0.2367
Episode: 23141/30000 (77.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5648s / 451.1118 s
agent0:                 episode reward: -0.8478,                 loss: nan
agent1:                 episode reward: 0.8478,                 loss: 0.2344
Episode: 23161/30000 (77.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5410s / 451.6528 s
agent0:                 episode reward: -0.7923,                 loss: nan
agent1:                 episode reward: 0.7923,                 loss: 0.2373
Episode: 23181/30000 (77.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5664s / 452.2192 s
agent0:                 episode reward: -0.8280,                 loss: nan
agent1:                 episode reward: 0.8280,                 loss: 0.2372
Episode: 23201/30000 (77.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5552s / 452.7745 s
agent0:                 episode reward: -0.7351,                 loss: nan
agent1:                 episode reward: 0.7351,                 loss: 0.2387
Episode: 23221/30000 (77.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5445s / 453.3190 s
agent0:                 episode reward: -0.7538,                 loss: nan
agent1:                 episode reward: 0.7538,                 loss: 0.2454
Episode: 23241/30000 (77.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5432s / 453.8622 s
agent0:                 episode reward: -0.5238,                 loss: nan
agent1:                 episode reward: 0.5238,                 loss: 0.2391
Episode: 23261/30000 (77.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5444s / 454.4066 s
agent0:                 episode reward: -0.8086,                 loss: nan
agent1:                 episode reward: 0.8086,                 loss: 0.2378
Episode: 23281/30000 (77.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5888s / 454.9954 s
agent0:                 episode reward: -0.8406,                 loss: nan
agent1:                 episode reward: 0.8406,                 loss: 0.2284
Episode: 23301/30000 (77.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5477s / 455.5431 s
agent0:                 episode reward: -1.2850,                 loss: nan
agent1:                 episode reward: 1.2850,                 loss: 0.2345
Episode: 23321/30000 (77.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5476s / 456.0907 s
agent0:                 episode reward: -0.6576,                 loss: nan
agent1:                 episode reward: 0.6576,                 loss: 0.2333
Episode: 23341/30000 (77.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5512s / 456.6419 s
agent0:                 episode reward: -0.7139,                 loss: nan
agent1:                 episode reward: 0.7139,                 loss: 0.2338
Episode: 23361/30000 (77.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5842s / 457.2261 s
agent0:                 episode reward: -0.6661,                 loss: nan
agent1:                 episode reward: 0.6661,                 loss: 0.2349
Episode: 23381/30000 (77.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5569s / 457.7830 s
agent0:                 episode reward: -1.0840,                 loss: nan
agent1:                 episode reward: 1.0840,                 loss: 0.2296
Episode: 23401/30000 (78.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5617s / 458.3448 s
agent0:                 episode reward: -1.2243,                 loss: nan
agent1:                 episode reward: 1.2243,                 loss: 0.2287
Episode: 23421/30000 (78.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5541s / 458.8989 s
agent0:                 episode reward: -0.9884,                 loss: nan
agent1:                 episode reward: 0.9884,                 loss: 0.2364
Episode: 23441/30000 (78.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5426s / 459.4414 s
agent0:                 episode reward: -0.5775,                 loss: nan
agent1:                 episode reward: 0.5775,                 loss: 0.2325
Episode: 23461/30000 (78.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5373s / 459.9788 s
agent0:                 episode reward: -0.7443,                 loss: nan
agent1:                 episode reward: 0.7443,                 loss: 0.2289
Episode: 23481/30000 (78.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5402s / 460.5189 s
agent0:                 episode reward: -0.8235,                 loss: nan
agent1:                 episode reward: 0.8235,                 loss: 0.2349
Episode: 23501/30000 (78.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5443s / 461.0633 s
agent0:                 episode reward: -0.9996,                 loss: nan
agent1:                 episode reward: 0.9996,                 loss: 0.2258
Episode: 23521/30000 (78.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5609s / 461.6241 s
agent0:                 episode reward: -0.6950,                 loss: nan
agent1:                 episode reward: 0.6950,                 loss: 0.2326
Episode: 23541/30000 (78.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5493s / 462.1734 s
agent0:                 episode reward: -1.0660,                 loss: nan
agent1:                 episode reward: 1.0660,                 loss: 0.2306
Episode: 23561/30000 (78.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5445s / 462.7179 s
agent0:                 episode reward: -0.6664,                 loss: nan
agent1:                 episode reward: 0.6664,                 loss: 0.2858
Episode: 23581/30000 (78.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5591s / 463.2770 s
agent0:                 episode reward: -0.6751,                 loss: nan
agent1:                 episode reward: 0.6751,                 loss: 0.2700
Episode: 23601/30000 (78.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5496s / 463.8266 s
agent0:                 episode reward: -0.9461,                 loss: nan
agent1:                 episode reward: 0.9461,                 loss: 0.2682
Episode: 23621/30000 (78.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5488s / 464.3754 s
agent0:                 episode reward: -0.9077,                 loss: nan
agent1:                 episode reward: 0.9077,                 loss: 0.2708
Episode: 23641/30000 (78.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5507s / 464.9260 s
agent0:                 episode reward: -0.7711,                 loss: nan
agent1:                 episode reward: 0.7711,                 loss: 0.2680
Episode: 23661/30000 (78.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6066s / 465.5327 s
agent0:                 episode reward: -0.6163,                 loss: nan
agent1:                 episode reward: 0.6163,                 loss: 0.2680
Episode: 23681/30000 (78.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5602s / 466.0929 s
agent0:                 episode reward: -0.8657,                 loss: nan
agent1:                 episode reward: 0.8657,                 loss: 0.2728
Episode: 23701/30000 (79.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6146s / 466.7074 s
agent0:                 episode reward: -1.0903,                 loss: nan
agent1:                 episode reward: 1.0903,                 loss: 0.2682
Episode: 23721/30000 (79.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5737s / 467.2812 s
agent0:                 episode reward: -0.8500,                 loss: nan
agent1:                 episode reward: 0.8500,                 loss: 0.2675
Episode: 23741/30000 (79.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5538s / 467.8350 s
agent0:                 episode reward: -0.7457,                 loss: nan
agent1:                 episode reward: 0.7457,                 loss: 0.2643
Episode: 23761/30000 (79.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5528s / 468.3877 s
agent0:                 episode reward: -0.7887,                 loss: nan
agent1:                 episode reward: 0.7887,                 loss: 0.2689
Episode: 23781/30000 (79.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5584s / 468.9461 s
agent0:                 episode reward: -0.5573,                 loss: nan
agent1:                 episode reward: 0.5573,                 loss: 0.2668
Episode: 23801/30000 (79.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5538s / 469.5000 s
agent0:                 episode reward: -0.9869,                 loss: nan
agent1:                 episode reward: 0.9869,                 loss: 0.2665
Episode: 23821/30000 (79.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5759s / 470.0759 s
agent0:                 episode reward: -0.8201,                 loss: nan
agent1:                 episode reward: 0.8201,                 loss: 0.2680
Episode: 23841/30000 (79.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5593s / 470.6352 s
agent0:                 episode reward: -0.8314,                 loss: nan
agent1:                 episode reward: 0.8314,                 loss: 0.2665
Episode: 23861/30000 (79.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5568s / 471.1920 s
agent0:                 episode reward: -0.9121,                 loss: nan
agent1:                 episode reward: 0.9121,                 loss: 0.2679
Episode: 23881/30000 (79.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5495s / 471.7414 s
agent0:                 episode reward: -1.0494,                 loss: nan
agent1:                 episode reward: 1.0494,                 loss: 0.2690
Episode: 23901/30000 (79.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5471s / 472.2885 s
agent0:                 episode reward: -1.0301,                 loss: nan
agent1:                 episode reward: 1.0301,                 loss: 0.2431
Episode: 23921/30000 (79.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5539s / 472.8424 s
agent0:                 episode reward: -0.5571,                 loss: nan
agent1:                 episode reward: 0.5571,                 loss: 0.2332
Episode: 23941/30000 (79.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5693s / 473.4117 s
agent0:                 episode reward: -1.0661,                 loss: nan
agent1:                 episode reward: 1.0661,                 loss: 0.2320
Episode: 23961/30000 (79.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5556s / 473.9673 s
agent0:                 episode reward: -0.8510,                 loss: nan
agent1:                 episode reward: 0.8510,                 loss: 0.2280
Episode: 23981/30000 (79.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5494s / 474.5167 s
agent0:                 episode reward: -0.8056,                 loss: nan
agent1:                 episode reward: 0.8056,                 loss: 0.2311
Episode: 24001/30000 (80.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5703s / 475.0870 s
agent0:                 episode reward: -0.6628,                 loss: nan
agent1:                 episode reward: 0.6628,                 loss: 0.2311
Episode: 24021/30000 (80.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5977s / 475.6847 s
agent0:                 episode reward: -1.1794,                 loss: nan
agent1:                 episode reward: 1.1794,                 loss: 0.2327
Episode: 24041/30000 (80.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5584s / 476.2431 s
agent0:                 episode reward: -0.9617,                 loss: nan
agent1:                 episode reward: 0.9617,                 loss: 0.2310
Episode: 24061/30000 (80.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5633s / 476.8064 s
agent0:                 episode reward: -1.1539,                 loss: nan
agent1:                 episode reward: 1.1539,                 loss: 0.2289
Episode: 24081/30000 (80.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5547s / 477.3611 s
agent0:                 episode reward: -0.8493,                 loss: nan
agent1:                 episode reward: 0.8493,                 loss: 0.2323
Episode: 24101/30000 (80.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5605s / 477.9216 s
agent0:                 episode reward: -0.6505,                 loss: nan
agent1:                 episode reward: 0.6505,                 loss: 0.2299
Episode: 24121/30000 (80.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5567s / 478.4784 s
agent0:                 episode reward: -0.7380,                 loss: nan
agent1:                 episode reward: 0.7380,                 loss: 0.2308
Episode: 24141/30000 (80.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5735s / 479.0518 s
agent0:                 episode reward: -0.9258,                 loss: nan
agent1:                 episode reward: 0.9258,                 loss: 0.2305
Episode: 24161/30000 (80.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5626s / 479.6144 s
agent0:                 episode reward: -1.0068,                 loss: nan
agent1:                 episode reward: 1.0068,                 loss: 0.2293
Episode: 24181/30000 (80.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5871s / 480.2016 s
agent0:                 episode reward: -0.7947,                 loss: nan
agent1:                 episode reward: 0.7947,                 loss: 0.2304
Episode: 24201/30000 (80.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5952s / 480.7967 s
agent0:                 episode reward: -1.0002,                 loss: nan
agent1:                 episode reward: 1.0002,                 loss: 0.2335
Episode: 24221/30000 (80.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5575s / 481.3542 s
agent0:                 episode reward: -0.6633,                 loss: nan
agent1:                 episode reward: 0.6633,                 loss: 0.2457
Episode: 24241/30000 (80.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5553s / 481.9095 s
agent0:                 episode reward: -0.7520,                 loss: nan
agent1:                 episode reward: 0.7520,                 loss: 0.2445
Episode: 24261/30000 (80.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5731s / 482.4826 s
agent0:                 episode reward: -0.8679,                 loss: nan
agent1:                 episode reward: 0.8679,                 loss: 0.2427
Episode: 24281/30000 (80.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5626s / 483.0451 s
agent0:                 episode reward: -0.8215,                 loss: nan
agent1:                 episode reward: 0.8215,                 loss: 0.2435
Episode: 24301/30000 (81.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6098s / 483.6549 s
agent0:                 episode reward: -0.8587,                 loss: nan
agent1:                 episode reward: 0.8587,                 loss: 0.2419
Episode: 24321/30000 (81.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5596s / 484.2145 s
agent0:                 episode reward: -0.9424,                 loss: nan
agent1:                 episode reward: 0.9424,                 loss: 0.2420
Episode: 24341/30000 (81.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5553s / 484.7698 s
agent0:                 episode reward: -0.7067,                 loss: nan
agent1:                 episode reward: 0.7067,                 loss: 0.2450
Episode: 24361/30000 (81.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5571s / 485.3269 s
agent0:                 episode reward: -0.3435,                 loss: nan
agent1:                 episode reward: 0.3435,                 loss: 0.2452
Episode: 24381/30000 (81.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6341s / 485.9610 s
agent0:                 episode reward: -0.8994,                 loss: nan
agent1:                 episode reward: 0.8994,                 loss: 0.2446
Episode: 24401/30000 (81.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5619s / 486.5229 s
agent0:                 episode reward: -0.9279,                 loss: nan
agent1:                 episode reward: 0.9279,                 loss: 0.2402
Episode: 24421/30000 (81.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5669s / 487.0897 s
agent0:                 episode reward: -0.6470,                 loss: nan
agent1:                 episode reward: 0.6470,                 loss: 0.2426
Episode: 24441/30000 (81.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5650s / 487.6547 s
agent0:                 episode reward: -0.6145,                 loss: nan
agent1:                 episode reward: 0.6145,                 loss: 0.2421
Episode: 24461/30000 (81.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5759s / 488.2306 s
agent0:                 episode reward: -1.0848,                 loss: nan
agent1:                 episode reward: 1.0848,                 loss: 0.2388
Episode: 24481/30000 (81.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5707s / 488.8013 s
agent0:                 episode reward: -0.6903,                 loss: nan
agent1:                 episode reward: 0.6903,                 loss: 0.2440
Episode: 24501/30000 (81.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5674s / 489.3687 s
agent0:                 episode reward: -0.8708,                 loss: nan
agent1:                 episode reward: 0.8708,                 loss: 0.2429
Episode: 24521/30000 (81.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5640s / 489.9328 s
agent0:                 episode reward: -0.7255,                 loss: nan
agent1:                 episode reward: 0.7255,                 loss: 0.2435
Episode: 24541/30000 (81.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5576s / 490.4903 s
agent0:                 episode reward: -0.6409,                 loss: nan
agent1:                 episode reward: 0.6409,                 loss: 0.2405
Episode: 24561/30000 (81.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5589s / 491.0492 s
agent0:                 episode reward: -0.8463,                 loss: nan
agent1:                 episode reward: 0.8463,                 loss: 0.2888
Episode: 24581/30000 (81.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5911s / 491.6403 s
agent0:                 episode reward: -0.8200,                 loss: nan
agent1:                 episode reward: 0.8200,                 loss: 0.2476
Episode: 24601/30000 (82.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5615s / 492.2018 s
agent0:                 episode reward: -1.0106,                 loss: nan
agent1:                 episode reward: 1.0106,                 loss: 0.2509
Episode: 24621/30000 (82.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5686s / 492.7704 s
agent0:                 episode reward: -0.7260,                 loss: nan
agent1:                 episode reward: 0.7260,                 loss: 0.2436
Episode: 24641/30000 (82.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5961s / 493.3665 s
agent0:                 episode reward: -0.7682,                 loss: nan
agent1:                 episode reward: 0.7682,                 loss: 0.2471
Episode: 24661/30000 (82.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5666s / 493.9331 s
agent0:                 episode reward: -0.5263,                 loss: nan
agent1:                 episode reward: 0.5263,                 loss: 0.2489
Episode: 24681/30000 (82.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5684s / 494.5016 s
agent0:                 episode reward: -0.7167,                 loss: nan
agent1:                 episode reward: 0.7167,                 loss: 0.2470
Episode: 24701/30000 (82.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5822s / 495.0838 s
agent0:                 episode reward: -0.5358,                 loss: nan
agent1:                 episode reward: 0.5358,                 loss: 0.2417
Episode: 24721/30000 (82.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5645s / 495.6483 s
agent0:                 episode reward: -0.8168,                 loss: nan
agent1:                 episode reward: 0.8168,                 loss: 0.2438
Episode: 24741/30000 (82.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6158s / 496.2641 s
agent0:                 episode reward: -0.8480,                 loss: nan
agent1:                 episode reward: 0.8480,                 loss: 0.2451
Episode: 24761/30000 (82.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5736s / 496.8377 s
agent0:                 episode reward: -1.0754,                 loss: nan
agent1:                 episode reward: 1.0754,                 loss: 0.2418
Episode: 24781/30000 (82.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5901s / 497.4278 s
agent0:                 episode reward: -0.9890,                 loss: nan
agent1:                 episode reward: 0.9890,                 loss: 0.2457
Episode: 24801/30000 (82.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5686s / 497.9963 s
agent0:                 episode reward: -0.9795,                 loss: nan
agent1:                 episode reward: 0.9795,                 loss: 0.2435
Episode: 24821/30000 (82.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5671s / 498.5634 s
agent0:                 episode reward: -0.6937,                 loss: nan
agent1:                 episode reward: 0.6937,                 loss: 0.2415
Episode: 24841/30000 (82.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5805s / 499.1439 s
agent0:                 episode reward: -0.6896,                 loss: nan
agent1:                 episode reward: 0.6896,                 loss: 0.2477
Episode: 24861/30000 (82.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6084s / 499.7523 s
agent0:                 episode reward: -0.9601,                 loss: nan
agent1:                 episode reward: 0.9601,                 loss: 0.2444
Episode: 24881/30000 (82.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5746s / 500.3269 s
agent0:                 episode reward: -0.8465,                 loss: nan
agent1:                 episode reward: 0.8465,                 loss: 0.2555
Episode: 24901/30000 (83.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5686s / 500.8955 s
agent0:                 episode reward: -0.7673,                 loss: nan
agent1:                 episode reward: 0.7673,                 loss: 0.2309
Episode: 24921/30000 (83.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5666s / 501.4621 s
agent0:                 episode reward: 0.0520,                 loss: nan
agent1:                 episode reward: -0.0520,                 loss: 0.2023
Episode: 24941/30000 (83.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5909s / 502.0530 s
agent0:                 episode reward: -0.5394,                 loss: nan
agent1:                 episode reward: 0.5394,                 loss: 0.2003
Episode: 24961/30000 (83.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5694s / 502.6224 s
agent0:                 episode reward: -0.4785,                 loss: nan
agent1:                 episode reward: 0.4785,                 loss: 0.2025
Episode: 24981/30000 (83.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5707s / 503.1931 s
agent0:                 episode reward: -0.7879,                 loss: nan
agent1:                 episode reward: 0.7879,                 loss: 0.1996
Episode: 25001/30000 (83.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6096s / 503.8026 s
agent0:                 episode reward: -0.4078,                 loss: nan
agent1:                 episode reward: 0.4078,                 loss: 0.1990
Episode: 25021/30000 (83.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5649s / 504.3675 s
agent0:                 episode reward: -0.9032,                 loss: nan
agent1:                 episode reward: 0.9032,                 loss: 0.2030
Episode: 25041/30000 (83.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5666s / 504.9341 s
agent0:                 episode reward: -0.6274,                 loss: nan
agent1:                 episode reward: 0.6274,                 loss: 0.2020
Episode: 25061/30000 (83.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5654s / 505.4995 s
agent0:                 episode reward: -0.7128,                 loss: nan
agent1:                 episode reward: 0.7128,                 loss: 0.2005
Episode: 25081/30000 (83.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5958s / 506.0953 s
agent0:                 episode reward: -1.1050,                 loss: nan
agent1:                 episode reward: 1.1050,                 loss: 0.1971
Episode: 25101/30000 (83.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6052s / 506.7005 s
agent0:                 episode reward: -0.5100,                 loss: nan
agent1:                 episode reward: 0.5100,                 loss: 0.1997
Episode: 25121/30000 (83.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5730s / 507.2736 s
agent0:                 episode reward: -0.8687,                 loss: nan
agent1:                 episode reward: 0.8687,                 loss: 0.1998
Episode: 25141/30000 (83.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5743s / 507.8479 s
agent0:                 episode reward: -0.6854,                 loss: nan
agent1:                 episode reward: 0.6854,                 loss: 0.2028
Episode: 25161/30000 (83.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5951s / 508.4430 s
agent0:                 episode reward: -0.6751,                 loss: nan
agent1:                 episode reward: 0.6751,                 loss: 0.1984
Episode: 25181/30000 (83.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5746s / 509.0175 s
agent0:                 episode reward: -0.6862,                 loss: nan
agent1:                 episode reward: 0.6862,                 loss: 0.1997
Episode: 25201/30000 (84.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5866s / 509.6041 s
agent0:                 episode reward: -0.8406,                 loss: nan
agent1:                 episode reward: 0.8406,                 loss: 0.2005
Episode: 25221/30000 (84.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5715s / 510.1756 s
agent0:                 episode reward: -0.8664,                 loss: nan
agent1:                 episode reward: 0.8664,                 loss: 0.2351
Episode: 25241/30000 (84.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5730s / 510.7487 s
agent0:                 episode reward: -0.8118,                 loss: nan
agent1:                 episode reward: 0.8118,                 loss: 0.2640
Episode: 25261/30000 (84.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5745s / 511.3232 s
agent0:                 episode reward: -0.6429,                 loss: nan
agent1:                 episode reward: 0.6429,                 loss: 0.2555
Episode: 25281/30000 (84.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5745s / 511.8976 s
agent0:                 episode reward: -0.8476,                 loss: nan
agent1:                 episode reward: 0.8476,                 loss: 0.2620
Episode: 25301/30000 (84.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5884s / 512.4860 s
agent0:                 episode reward: -1.2714,                 loss: nan
agent1:                 episode reward: 1.2714,                 loss: 0.2587
Episode: 25321/30000 (84.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5799s / 513.0660 s
agent0:                 episode reward: -0.8204,                 loss: nan
agent1:                 episode reward: 0.8204,                 loss: 0.2637
Episode: 25341/30000 (84.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5851s / 513.6511 s
agent0:                 episode reward: -0.6356,                 loss: nan
agent1:                 episode reward: 0.6356,                 loss: 0.2631
Episode: 25361/30000 (84.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5916s / 514.2427 s
agent0:                 episode reward: -0.6810,                 loss: nan
agent1:                 episode reward: 0.6810,                 loss: 0.2592
Episode: 25381/30000 (84.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5779s / 514.8207 s
agent0:                 episode reward: -1.0077,                 loss: nan
agent1:                 episode reward: 1.0077,                 loss: 0.2620
Episode: 25401/30000 (84.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5839s / 515.4046 s
agent0:                 episode reward: -0.9319,                 loss: nan
agent1:                 episode reward: 0.9319,                 loss: 0.2606
Episode: 25421/30000 (84.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5801s / 515.9847 s
agent0:                 episode reward: -0.8739,                 loss: nan
agent1:                 episode reward: 0.8739,                 loss: 0.2621
Episode: 25441/30000 (84.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6567s / 516.6414 s
agent0:                 episode reward: -0.5175,                 loss: nan
agent1:                 episode reward: 0.5175,                 loss: 0.2588
Episode: 25461/30000 (84.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5762s / 517.2176 s
agent0:                 episode reward: -0.7800,                 loss: nan
agent1:                 episode reward: 0.7800,                 loss: 0.2576
Episode: 25481/30000 (84.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5830s / 517.8006 s
agent0:                 episode reward: -0.8715,                 loss: nan
agent1:                 episode reward: 0.8715,                 loss: 0.2616
Episode: 25501/30000 (85.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5778s / 518.3784 s
agent0:                 episode reward: -0.9651,                 loss: nan
agent1:                 episode reward: 0.9651,                 loss: 0.2624
Episode: 25521/30000 (85.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5781s / 518.9565 s
agent0:                 episode reward: -1.0396,                 loss: nan
agent1:                 episode reward: 1.0396,                 loss: 0.2598
Episode: 25541/30000 (85.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5808s / 519.5374 s
agent0:                 episode reward: -0.6797,                 loss: nan
agent1:                 episode reward: 0.6797,                 loss: 0.2603
Episode: 25561/30000 (85.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5813s / 520.1187 s
agent0:                 episode reward: -0.9792,                 loss: nan
agent1:                 episode reward: 0.9792,                 loss: 0.2861
Episode: 25581/30000 (85.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5759s / 520.6946 s
agent0:                 episode reward: -0.9371,                 loss: nan
agent1:                 episode reward: 0.9371,                 loss: 0.2442
Episode: 25601/30000 (85.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5862s / 521.2808 s
agent0:                 episode reward: -0.6945,                 loss: nan
agent1:                 episode reward: 0.6945,                 loss: 0.2430
Episode: 25621/30000 (85.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5770s / 521.8578 s
agent0:                 episode reward: -1.2619,                 loss: nan
agent1:                 episode reward: 1.2619,                 loss: 0.2415
Episode: 25641/30000 (85.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5822s / 522.4400 s
agent0:                 episode reward: -0.9491,                 loss: nan
agent1:                 episode reward: 0.9491,                 loss: 0.2410
Episode: 25661/30000 (85.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5780s / 523.0181 s
agent0:                 episode reward: -0.8513,                 loss: nan
agent1:                 episode reward: 0.8513,                 loss: 0.2415
Episode: 25681/30000 (85.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5862s / 523.6043 s
agent0:                 episode reward: -0.6293,                 loss: nan
agent1:                 episode reward: 0.6293,                 loss: 0.2380
Episode: 25701/30000 (85.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5837s / 524.1880 s
agent0:                 episode reward: -0.9740,                 loss: nan
agent1:                 episode reward: 0.9740,                 loss: 0.2394
Episode: 25721/30000 (85.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6141s / 524.8021 s
agent0:                 episode reward: -1.1527,                 loss: nan
agent1:                 episode reward: 1.1527,                 loss: 0.2422
Episode: 25741/30000 (85.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5759s / 525.3780 s
agent0:                 episode reward: -0.3297,                 loss: nan
agent1:                 episode reward: 0.3297,                 loss: 0.2423
Episode: 25761/30000 (85.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5831s / 525.9610 s
agent0:                 episode reward: -0.7737,                 loss: nan
agent1:                 episode reward: 0.7737,                 loss: 0.2429
Episode: 25781/30000 (85.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6085s / 526.5695 s
agent0:                 episode reward: -0.9102,                 loss: nan
agent1:                 episode reward: 0.9102,                 loss: 0.2421
Episode: 25801/30000 (86.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6243s / 527.1939 s
agent0:                 episode reward: -0.7655,                 loss: nan
agent1:                 episode reward: 0.7655,                 loss: 0.2410
Episode: 25821/30000 (86.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5913s / 527.7852 s
agent0:                 episode reward: -0.7149,                 loss: nan
agent1:                 episode reward: 0.7149,                 loss: 0.2385
Episode: 25841/30000 (86.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6178s / 528.4030 s
agent0:                 episode reward: -0.8758,                 loss: nan
agent1:                 episode reward: 0.8758,                 loss: 0.2411
Episode: 25861/30000 (86.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6135s / 529.0165 s
agent0:                 episode reward: -0.7804,                 loss: nan
agent1:                 episode reward: 0.7804,                 loss: 0.2403
Episode: 25881/30000 (86.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5875s / 529.6040 s
agent0:                 episode reward: -0.9459,                 loss: nan
agent1:                 episode reward: 0.9459,                 loss: 0.2516
Episode: 25901/30000 (86.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5806s / 530.1846 s
agent0:                 episode reward: -0.3969,                 loss: nan
agent1:                 episode reward: 0.3969,                 loss: 0.2331
Episode: 25921/30000 (86.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5951s / 530.7797 s
agent0:                 episode reward: -1.0927,                 loss: nan
agent1:                 episode reward: 1.0927,                 loss: 0.1931
Episode: 25941/30000 (86.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5877s / 531.3674 s
agent0:                 episode reward: -0.7628,                 loss: nan
agent1:                 episode reward: 0.7628,                 loss: 0.1931
Episode: 25961/30000 (86.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5931s / 531.9605 s
agent0:                 episode reward: -0.6621,                 loss: nan
agent1:                 episode reward: 0.6621,                 loss: 0.1947
Episode: 25981/30000 (86.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5912s / 532.5518 s
agent0:                 episode reward: -0.5142,                 loss: nan
agent1:                 episode reward: 0.5142,                 loss: 0.1933
Episode: 26001/30000 (86.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6031s / 533.1549 s
agent0:                 episode reward: -0.8108,                 loss: nan
agent1:                 episode reward: 0.8108,                 loss: 0.1931
Episode: 26021/30000 (86.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5903s / 533.7452 s
agent0:                 episode reward: -0.4643,                 loss: nan
agent1:                 episode reward: 0.4643,                 loss: 0.1915
Episode: 26041/30000 (86.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5937s / 534.3389 s
agent0:                 episode reward: -0.9924,                 loss: nan
agent1:                 episode reward: 0.9924,                 loss: 0.1940
Episode: 26061/30000 (86.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5892s / 534.9280 s
agent0:                 episode reward: -0.6874,                 loss: nan
agent1:                 episode reward: 0.6874,                 loss: 0.1917
Episode: 26081/30000 (86.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5883s / 535.5163 s
agent0:                 episode reward: -0.4305,                 loss: nan
agent1:                 episode reward: 0.4305,                 loss: 0.1925
Episode: 26101/30000 (87.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5954s / 536.1118 s
agent0:                 episode reward: -0.7690,                 loss: nan
agent1:                 episode reward: 0.7690,                 loss: 0.1947
Episode: 26121/30000 (87.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6000s / 536.7118 s
agent0:                 episode reward: -0.9015,                 loss: nan
agent1:                 episode reward: 0.9015,                 loss: 0.1952
Episode: 26141/30000 (87.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6598s / 537.3716 s
agent0:                 episode reward: -0.8100,                 loss: nan
agent1:                 episode reward: 0.8100,                 loss: 0.1942
Episode: 26161/30000 (87.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5905s / 537.9620 s
agent0:                 episode reward: -0.6065,                 loss: nan
agent1:                 episode reward: 0.6065,                 loss: 0.1929
Episode: 26181/30000 (87.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5906s / 538.5526 s
agent0:                 episode reward: -0.7546,                 loss: nan
agent1:                 episode reward: 0.7546,                 loss: 0.1960
Episode: 26201/30000 (87.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5943s / 539.1469 s
agent0:                 episode reward: -0.8679,                 loss: nan
agent1:                 episode reward: 0.8679,                 loss: 0.1929
Episode: 26221/30000 (87.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5907s / 539.7376 s
agent0:                 episode reward: -0.9259,                 loss: nan
agent1:                 episode reward: 0.9259,                 loss: 0.2345
Episode: 26241/30000 (87.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5895s / 540.3271 s
agent0:                 episode reward: -1.0103,                 loss: nan
agent1:                 episode reward: 1.0103,                 loss: 0.2816
Episode: 26261/30000 (87.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6329s / 540.9599 s
agent0:                 episode reward: -0.7456,                 loss: nan
agent1:                 episode reward: 0.7456,                 loss: 0.2725
Episode: 26281/30000 (87.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6414s / 541.6013 s
agent0:                 episode reward: -1.2000,                 loss: nan
agent1:                 episode reward: 1.2000,                 loss: 0.2759
Episode: 26301/30000 (87.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5920s / 542.1933 s
agent0:                 episode reward: -0.9753,                 loss: nan
agent1:                 episode reward: 0.9753,                 loss: 0.2762
Episode: 26321/30000 (87.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5975s / 542.7908 s
agent0:                 episode reward: -1.0864,                 loss: nan
agent1:                 episode reward: 1.0864,                 loss: 0.2741
Episode: 26341/30000 (87.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5903s / 543.3811 s
agent0:                 episode reward: -0.6815,                 loss: nan
agent1:                 episode reward: 0.6815,                 loss: 0.2729
Episode: 26361/30000 (87.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5997s / 543.9808 s
agent0:                 episode reward: -0.6432,                 loss: nan
agent1:                 episode reward: 0.6432,                 loss: 0.2749
Episode: 26381/30000 (87.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5989s / 544.5797 s
agent0:                 episode reward: -0.7466,                 loss: nan
agent1:                 episode reward: 0.7466,                 loss: 0.2786
Episode: 26401/30000 (88.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5957s / 545.1754 s
agent0:                 episode reward: -1.0272,                 loss: nan
agent1:                 episode reward: 1.0272,                 loss: 0.2762
Episode: 26421/30000 (88.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6193s / 545.7947 s
agent0:                 episode reward: -0.6821,                 loss: nan
agent1:                 episode reward: 0.6821,                 loss: 0.2765
Episode: 26441/30000 (88.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5930s / 546.3877 s
agent0:                 episode reward: -0.7334,                 loss: nan
agent1:                 episode reward: 0.7334,                 loss: 0.2767
Episode: 26461/30000 (88.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5930s / 546.9807 s
agent0:                 episode reward: -0.6962,                 loss: nan
agent1:                 episode reward: 0.6962,                 loss: 0.2758
Episode: 26481/30000 (88.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6689s / 547.6496 s
agent0:                 episode reward: -1.1236,                 loss: nan
agent1:                 episode reward: 1.1236,                 loss: 0.2811
Episode: 26501/30000 (88.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6050s / 548.2547 s
agent0:                 episode reward: -0.9916,                 loss: nan
agent1:                 episode reward: 0.9916,                 loss: 0.2722
Episode: 26521/30000 (88.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5992s / 548.8538 s
agent0:                 episode reward: -0.8677,                 loss: nan
agent1:                 episode reward: 0.8677,                 loss: 0.2755
Episode: 26541/30000 (88.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6010s / 549.4548 s
agent0:                 episode reward: -0.8103,                 loss: nan
agent1:                 episode reward: 0.8103,                 loss: 0.2772
Episode: 26561/30000 (88.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6173s / 550.0722 s
agent0:                 episode reward: -0.6820,                 loss: nan
agent1:                 episode reward: 0.6820,                 loss: 0.2827
Episode: 26581/30000 (88.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5931s / 550.6652 s
agent0:                 episode reward: -0.9831,                 loss: nan
agent1:                 episode reward: 0.9831,                 loss: 0.2409
Episode: 26601/30000 (88.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6029s / 551.2681 s
agent0:                 episode reward: -0.8536,                 loss: nan
agent1:                 episode reward: 0.8536,                 loss: 0.2369
Episode: 26621/30000 (88.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5998s / 551.8679 s
agent0:                 episode reward: -0.3976,                 loss: nan
agent1:                 episode reward: 0.3976,                 loss: 0.2380
Episode: 26641/30000 (88.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5994s / 552.4673 s
agent0:                 episode reward: -0.8509,                 loss: nan
agent1:                 episode reward: 0.8509,                 loss: 0.2369
Episode: 26661/30000 (88.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5990s / 553.0663 s
agent0:                 episode reward: -0.9462,                 loss: nan
agent1:                 episode reward: 0.9462,                 loss: 0.2407
Episode: 26681/30000 (88.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6659s / 553.7322 s
agent0:                 episode reward: -0.5176,                 loss: nan
agent1:                 episode reward: 0.5176,                 loss: 0.2390
Episode: 26701/30000 (89.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6225s / 554.3547 s
agent0:                 episode reward: -0.6530,                 loss: nan
agent1:                 episode reward: 0.6530,                 loss: 0.2364
Episode: 26721/30000 (89.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5979s / 554.9526 s
agent0:                 episode reward: -0.9594,                 loss: nan
agent1:                 episode reward: 0.9594,                 loss: 0.2373
Episode: 26741/30000 (89.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5975s / 555.5501 s
agent0:                 episode reward: -1.0548,                 loss: nan
agent1:                 episode reward: 1.0548,                 loss: 0.2366
Episode: 26761/30000 (89.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5966s / 556.1467 s
agent0:                 episode reward: -0.9317,                 loss: nan
agent1:                 episode reward: 0.9317,                 loss: 0.2349
Episode: 26781/30000 (89.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5998s / 556.7465 s
agent0:                 episode reward: -0.8999,                 loss: nan
agent1:                 episode reward: 0.8999,                 loss: 0.2356
Episode: 26801/30000 (89.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6558s / 557.4023 s
agent0:                 episode reward: -1.0256,                 loss: nan
agent1:                 episode reward: 1.0256,                 loss: 0.2380
Episode: 26821/30000 (89.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6226s / 558.0248 s
agent0:                 episode reward: -0.6458,                 loss: nan
agent1:                 episode reward: 0.6458,                 loss: 0.2375
Episode: 26841/30000 (89.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6263s / 558.6512 s
agent0:                 episode reward: -0.9202,                 loss: nan
agent1:                 episode reward: 0.9202,                 loss: 0.2381
Episode: 26861/30000 (89.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6060s / 559.2572 s
agent0:                 episode reward: -0.7621,                 loss: nan
agent1:                 episode reward: 0.7621,                 loss: 0.2348
Episode: 26881/30000 (89.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6045s / 559.8617 s
agent0:                 episode reward: -0.9213,                 loss: nan
agent1:                 episode reward: 0.9213,                 loss: 0.2509
Episode: 26901/30000 (89.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6119s / 560.4736 s
agent0:                 episode reward: -0.7877,                 loss: nan
agent1:                 episode reward: 0.7877,                 loss: 0.2344
Episode: 26921/30000 (89.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5999s / 561.0734 s
agent0:                 episode reward: -0.5738,                 loss: nan
agent1:                 episode reward: 0.5738,                 loss: 0.1868
Episode: 26941/30000 (89.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6071s / 561.6806 s
agent0:                 episode reward: -0.8213,                 loss: nan
agent1:                 episode reward: 0.8213,                 loss: 0.1862
Episode: 26961/30000 (89.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5961s / 562.2767 s
agent0:                 episode reward: -0.8118,                 loss: nan
agent1:                 episode reward: 0.8118,                 loss: 0.1873
Episode: 26981/30000 (89.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6121s / 562.8887 s
agent0:                 episode reward: -0.9049,                 loss: nan
agent1:                 episode reward: 0.9049,                 loss: 0.1867
Episode: 27001/30000 (90.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6160s / 563.5047 s
agent0:                 episode reward: -0.7532,                 loss: nan
agent1:                 episode reward: 0.7532,                 loss: 0.1865
Episode: 27021/30000 (90.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6058s / 564.1106 s
agent0:                 episode reward: -1.3185,                 loss: nan
agent1:                 episode reward: 1.3185,                 loss: 0.1878
Episode: 27041/30000 (90.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6187s / 564.7293 s
agent0:                 episode reward: -0.7295,                 loss: nan
agent1:                 episode reward: 0.7295,                 loss: 0.1842
Episode: 27061/30000 (90.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6124s / 565.3416 s
agent0:                 episode reward: -0.6693,                 loss: nan
agent1:                 episode reward: 0.6693,                 loss: 0.1859
Episode: 27081/30000 (90.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6085s / 565.9501 s
agent0:                 episode reward: -0.9542,                 loss: nan
agent1:                 episode reward: 0.9542,                 loss: 0.1864
Episode: 27101/30000 (90.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6529s / 566.6030 s
agent0:                 episode reward: -0.8410,                 loss: nan
agent1:                 episode reward: 0.8410,                 loss: 0.1870
Episode: 27121/30000 (90.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6167s / 567.2197 s
agent0:                 episode reward: -0.9994,                 loss: nan
agent1:                 episode reward: 0.9994,                 loss: 0.1887
Episode: 27141/30000 (90.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6539s / 567.8736 s
agent0:                 episode reward: -0.8951,                 loss: nan
agent1:                 episode reward: 0.8951,                 loss: 0.1850
Episode: 27161/30000 (90.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6103s / 568.4839 s
agent0:                 episode reward: -0.7681,                 loss: nan
agent1:                 episode reward: 0.7681,                 loss: 0.1863
Episode: 27181/30000 (90.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6086s / 569.0925 s
agent0:                 episode reward: -1.0262,                 loss: nan
agent1:                 episode reward: 1.0262,                 loss: 0.1860
Episode: 27201/30000 (90.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6122s / 569.7046 s
agent0:                 episode reward: -0.6966,                 loss: nan
agent1:                 episode reward: 0.6966,                 loss: 0.1873
Episode: 27221/30000 (90.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6066s / 570.3113 s
agent0:                 episode reward: -0.8591,                 loss: nan
agent1:                 episode reward: 0.8591,                 loss: 0.2477
Episode: 27241/30000 (90.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6034s / 570.9147 s
agent0:                 episode reward: -0.9774,                 loss: nan
agent1:                 episode reward: 0.9774,                 loss: 0.2896
Episode: 27261/30000 (90.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6105s / 571.5252 s
agent0:                 episode reward: -0.6184,                 loss: nan
agent1:                 episode reward: 0.6184,                 loss: 0.2872
Episode: 27281/30000 (90.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6147s / 572.1399 s
agent0:                 episode reward: -0.8656,                 loss: nan
agent1:                 episode reward: 0.8656,                 loss: 0.2867
Episode: 27301/30000 (91.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6104s / 572.7503 s
agent0:                 episode reward: -0.9493,                 loss: nan
agent1:                 episode reward: 0.9493,                 loss: 0.2911
Episode: 27321/30000 (91.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6089s / 573.3592 s
agent0:                 episode reward: -0.8158,                 loss: nan
agent1:                 episode reward: 0.8158,                 loss: 0.2900
Episode: 27341/30000 (91.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6097s / 573.9689 s
agent0:                 episode reward: -0.8955,                 loss: nan
agent1:                 episode reward: 0.8955,                 loss: 0.2881
Episode: 27361/30000 (91.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6526s / 574.6215 s
agent0:                 episode reward: -0.7110,                 loss: nan
agent1:                 episode reward: 0.7110,                 loss: 0.2893
Episode: 27381/30000 (91.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6190s / 575.2406 s
agent0:                 episode reward: -1.0902,                 loss: nan
agent1:                 episode reward: 1.0902,                 loss: 0.2917
Episode: 27401/30000 (91.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6193s / 575.8598 s
agent0:                 episode reward: -0.7808,                 loss: nan
agent1:                 episode reward: 0.7808,                 loss: 0.2888
Episode: 27421/30000 (91.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6145s / 576.4744 s
agent0:                 episode reward: -1.1607,                 loss: nan
agent1:                 episode reward: 1.1607,                 loss: 0.2877
Episode: 27441/30000 (91.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6114s / 577.0858 s
agent0:                 episode reward: -0.8043,                 loss: nan
agent1:                 episode reward: 0.8043,                 loss: 0.2879
Episode: 27461/30000 (91.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6181s / 577.7038 s
agent0:                 episode reward: -1.0413,                 loss: nan
agent1:                 episode reward: 1.0413,                 loss: 0.2900
Episode: 27481/30000 (91.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6821s / 578.3860 s
agent0:                 episode reward: -0.9445,                 loss: nan
agent1:                 episode reward: 0.9445,                 loss: 0.2862
Episode: 27501/30000 (91.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6183s / 579.0043 s
agent0:                 episode reward: -0.6000,                 loss: nan
agent1:                 episode reward: 0.6000,                 loss: 0.2869
Episode: 27521/30000 (91.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6561s / 579.6603 s
agent0:                 episode reward: -0.8363,                 loss: nan
agent1:                 episode reward: 0.8363,                 loss: 0.2859
Episode: 27541/30000 (91.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6139s / 580.2742 s
agent0:                 episode reward: -0.8881,                 loss: nan
agent1:                 episode reward: 0.8881,                 loss: 0.2846
Episode: 27561/30000 (91.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6656s / 580.9398 s
agent0:                 episode reward: -0.3844,                 loss: nan
agent1:                 episode reward: 0.3844,                 loss: 0.2698
Episode: 27581/30000 (91.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6239s / 581.5637 s
agent0:                 episode reward: -0.9799,                 loss: nan
agent1:                 episode reward: 0.9799,                 loss: 0.2457
Episode: 27601/30000 (92.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6339s / 582.1976 s
agent0:                 episode reward: -1.2195,                 loss: nan
agent1:                 episode reward: 1.2195,                 loss: 0.2421
Episode: 27621/30000 (92.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6324s / 582.8301 s
agent0:                 episode reward: -0.9699,                 loss: nan
agent1:                 episode reward: 0.9699,                 loss: 0.2435
Episode: 27641/30000 (92.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6198s / 583.4498 s
agent0:                 episode reward: -1.2601,                 loss: nan
agent1:                 episode reward: 1.2601,                 loss: 0.2402
Episode: 27661/30000 (92.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6260s / 584.0758 s
agent0:                 episode reward: -0.8616,                 loss: nan
agent1:                 episode reward: 0.8616,                 loss: 0.2429
Episode: 27681/30000 (92.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6268s / 584.7026 s
agent0:                 episode reward: -1.0421,                 loss: nan
agent1:                 episode reward: 1.0421,                 loss: 0.2422
Episode: 27701/30000 (92.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6174s / 585.3200 s
agent0:                 episode reward: -0.9922,                 loss: nan
agent1:                 episode reward: 0.9922,                 loss: 0.2393
Episode: 27721/30000 (92.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6172s / 585.9372 s
agent0:                 episode reward: -0.9119,                 loss: nan
agent1:                 episode reward: 0.9119,                 loss: 0.2420
Episode: 27741/30000 (92.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6935s / 586.6307 s
agent0:                 episode reward: -0.9206,                 loss: nan
agent1:                 episode reward: 0.9206,                 loss: 0.2413
Episode: 27761/30000 (92.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6415s / 587.2721 s
agent0:                 episode reward: -1.0380,                 loss: nan
agent1:                 episode reward: 1.0380,                 loss: 0.2408
Episode: 27781/30000 (92.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6194s / 587.8916 s
agent0:                 episode reward: -0.8436,                 loss: nan
agent1:                 episode reward: 0.8436,                 loss: 0.2401
Episode: 27801/30000 (92.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6841s / 588.5757 s
agent0:                 episode reward: -0.5460,                 loss: nan
agent1:                 episode reward: 0.5460,                 loss: 0.2403
Episode: 27821/30000 (92.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6260s / 589.2017 s
agent0:                 episode reward: -0.8428,                 loss: nan
agent1:                 episode reward: 0.8428,                 loss: 0.2400
Episode: 27841/30000 (92.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6274s / 589.8291 s
agent0:                 episode reward: -0.9153,                 loss: nan
agent1:                 episode reward: 0.9153,                 loss: 0.2401
Episode: 27861/30000 (92.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6290s / 590.4582 s
agent0:                 episode reward: -0.8281,                 loss: nan
agent1:                 episode reward: 0.8281,                 loss: 0.2374
Episode: 27881/30000 (92.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6492s / 591.1073 s
agent0:                 episode reward: -0.9057,                 loss: nan
agent1:                 episode reward: 0.9057,                 loss: 0.2513
Episode: 27901/30000 (93.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6292s / 591.7365 s
agent0:                 episode reward: -0.6750,                 loss: nan
agent1:                 episode reward: 0.6750,                 loss: 0.2322
Episode: 27921/30000 (93.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6283s / 592.3648 s
agent0:                 episode reward: -0.6338,                 loss: nan
agent1:                 episode reward: 0.6338,                 loss: 0.1929
Episode: 27941/30000 (93.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6365s / 593.0013 s
agent0:                 episode reward: -0.5765,                 loss: nan
agent1:                 episode reward: 0.5765,                 loss: 0.1936
Episode: 27961/30000 (93.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6339s / 593.6352 s
agent0:                 episode reward: -0.6674,                 loss: nan
agent1:                 episode reward: 0.6674,                 loss: 0.1925
Episode: 27981/30000 (93.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6227s / 594.2579 s
agent0:                 episode reward: -0.7587,                 loss: nan
agent1:                 episode reward: 0.7587,                 loss: 0.1942
Episode: 28001/30000 (93.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6373s / 594.8952 s
agent0:                 episode reward: -0.8674,                 loss: nan
agent1:                 episode reward: 0.8674,                 loss: 0.1918
Episode: 28021/30000 (93.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6193s / 595.5145 s
agent0:                 episode reward: -0.9069,                 loss: nan
agent1:                 episode reward: 0.9069,                 loss: 0.1953
Episode: 28041/30000 (93.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6253s / 596.1398 s
agent0:                 episode reward: -1.1666,                 loss: nan
agent1:                 episode reward: 1.1666,                 loss: 0.1910
Episode: 28061/30000 (93.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6319s / 596.7717 s
agent0:                 episode reward: -0.7652,                 loss: nan
agent1:                 episode reward: 0.7652,                 loss: 0.1923
Episode: 28081/30000 (93.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6592s / 597.4309 s
agent0:                 episode reward: -1.0388,                 loss: nan
agent1:                 episode reward: 1.0388,                 loss: 0.1920
Episode: 28101/30000 (93.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6345s / 598.0654 s
agent0:                 episode reward: -0.5763,                 loss: nan
agent1:                 episode reward: 0.5763,                 loss: 0.1942
Episode: 28121/30000 (93.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6775s / 598.7429 s
agent0:                 episode reward: -0.8266,                 loss: nan
agent1:                 episode reward: 0.8266,                 loss: 0.1918
Episode: 28141/30000 (93.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6633s / 599.4062 s
agent0:                 episode reward: -0.6845,                 loss: nan
agent1:                 episode reward: 0.6845,                 loss: 0.1934
Episode: 28161/30000 (93.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6381s / 600.0444 s
agent0:                 episode reward: -0.7151,                 loss: nan
agent1:                 episode reward: 0.7151,                 loss: 0.1929
Episode: 28181/30000 (93.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6305s / 600.6748 s
agent0:                 episode reward: -0.7691,                 loss: nan
agent1:                 episode reward: 0.7691,                 loss: 0.1881
Episode: 28201/30000 (94.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6343s / 601.3092 s
agent0:                 episode reward: -0.9444,                 loss: nan
agent1:                 episode reward: 0.9444,                 loss: 0.1922
Episode: 28221/30000 (94.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6310s / 601.9402 s
agent0:                 episode reward: -0.6155,                 loss: nan
agent1:                 episode reward: 0.6155,                 loss: 0.2613
Episode: 28241/30000 (94.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6584s / 602.5985 s
agent0:                 episode reward: -0.6968,                 loss: nan
agent1:                 episode reward: 0.6968,                 loss: 0.2880
Episode: 28261/30000 (94.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6285s / 603.2270 s
agent0:                 episode reward: -0.8272,                 loss: nan
agent1:                 episode reward: 0.8272,                 loss: 0.2872
Episode: 28281/30000 (94.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6280s / 603.8551 s
agent0:                 episode reward: -0.8325,                 loss: nan
agent1:                 episode reward: 0.8325,                 loss: 0.2839
Episode: 28301/30000 (94.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6255s / 604.4805 s
agent0:                 episode reward: -0.9098,                 loss: nan
agent1:                 episode reward: 0.9098,                 loss: 0.2848
Episode: 28321/30000 (94.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6547s / 605.1352 s
agent0:                 episode reward: -0.7736,                 loss: nan
agent1:                 episode reward: 0.7736,                 loss: 0.2848
Episode: 28341/30000 (94.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6577s / 605.7930 s
agent0:                 episode reward: -0.9421,                 loss: nan
agent1:                 episode reward: 0.9421,                 loss: 0.2848
Episode: 28361/30000 (94.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6268s / 606.4197 s
agent0:                 episode reward: -0.7251,                 loss: nan
agent1:                 episode reward: 0.7251,                 loss: 0.2774
Episode: 28381/30000 (94.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6257s / 607.0454 s
agent0:                 episode reward: -0.5739,                 loss: nan
agent1:                 episode reward: 0.5739,                 loss: 0.2814
Episode: 28401/30000 (94.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6481s / 607.6934 s
agent0:                 episode reward: -1.1808,                 loss: nan
agent1:                 episode reward: 1.1808,                 loss: 0.2831
Episode: 28421/30000 (94.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6640s / 608.3574 s
agent0:                 episode reward: -0.6296,                 loss: nan
agent1:                 episode reward: 0.6296,                 loss: 0.2802
Episode: 28441/30000 (94.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7481s / 609.1055 s
agent0:                 episode reward: -0.9115,                 loss: nan
agent1:                 episode reward: 0.9115,                 loss: 0.2795
Episode: 28461/30000 (94.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6343s / 609.7399 s
agent0:                 episode reward: -0.5485,                 loss: nan
agent1:                 episode reward: 0.5485,                 loss: 0.2825
Episode: 28481/30000 (94.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6292s / 610.3691 s
agent0:                 episode reward: -0.9803,                 loss: nan
agent1:                 episode reward: 0.9803,                 loss: 0.2818
Episode: 28501/30000 (95.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6325s / 611.0015 s
agent0:                 episode reward: -0.9483,                 loss: nan
agent1:                 episode reward: 0.9483,                 loss: 0.2787
Episode: 28521/30000 (95.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6327s / 611.6342 s
agent0:                 episode reward: -0.9480,                 loss: nan
agent1:                 episode reward: 0.9480,                 loss: 0.2836
Episode: 28541/30000 (95.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6303s / 612.2645 s
agent0:                 episode reward: -0.5912,                 loss: nan
agent1:                 episode reward: 0.5912,                 loss: 0.2822
Episode: 28561/30000 (95.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6464s / 612.9109 s
agent0:                 episode reward: -0.8790,                 loss: nan
agent1:                 episode reward: 0.8790,                 loss: 0.2639
Episode: 28581/30000 (95.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6530s / 613.5639 s
agent0:                 episode reward: -0.7397,                 loss: nan
agent1:                 episode reward: 0.7397,                 loss: 0.2372
Episode: 28601/30000 (95.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6434s / 614.2073 s
agent0:                 episode reward: -1.2603,                 loss: nan
agent1:                 episode reward: 1.2603,                 loss: 0.2359
Episode: 28621/30000 (95.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6388s / 614.8461 s
agent0:                 episode reward: -0.7102,                 loss: nan
agent1:                 episode reward: 0.7102,                 loss: 0.2329
Episode: 28641/30000 (95.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6454s / 615.4915 s
agent0:                 episode reward: -0.7595,                 loss: nan
agent1:                 episode reward: 0.7595,                 loss: 0.2350
Episode: 28661/30000 (95.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6607s / 616.1522 s
agent0:                 episode reward: -0.3870,                 loss: nan
agent1:                 episode reward: 0.3870,                 loss: 0.2346
Episode: 28681/30000 (95.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6393s / 616.7915 s
agent0:                 episode reward: -1.1199,                 loss: nan
agent1:                 episode reward: 1.1199,                 loss: 0.2341
Episode: 28701/30000 (95.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6460s / 617.4376 s
agent0:                 episode reward: -0.8666,                 loss: nan
agent1:                 episode reward: 0.8666,                 loss: 0.2373
Episode: 28721/30000 (95.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6741s / 618.1117 s
agent0:                 episode reward: -0.7111,                 loss: nan
agent1:                 episode reward: 0.7111,                 loss: 0.2343
Episode: 28741/30000 (95.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6390s / 618.7506 s
agent0:                 episode reward: -0.6974,                 loss: nan
agent1:                 episode reward: 0.6974,                 loss: 0.2359
Episode: 28761/30000 (95.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6944s / 619.4450 s
agent0:                 episode reward: -0.9492,                 loss: nan
agent1:                 episode reward: 0.9492,                 loss: 0.2322
Episode: 28781/30000 (95.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6489s / 620.0940 s
agent0:                 episode reward: -0.6901,                 loss: nan
agent1:                 episode reward: 0.6901,                 loss: 0.2357
Episode: 28801/30000 (96.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6385s / 620.7325 s
agent0:                 episode reward: -0.8651,                 loss: nan
agent1:                 episode reward: 0.8651,                 loss: 0.2353
Episode: 28821/30000 (96.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6388s / 621.3713 s
agent0:                 episode reward: -0.9562,                 loss: nan
agent1:                 episode reward: 0.9562,                 loss: 0.2378
Episode: 28841/30000 (96.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6388s / 622.0101 s
agent0:                 episode reward: -0.6900,                 loss: nan
agent1:                 episode reward: 0.6900,                 loss: 0.2338
Episode: 28861/30000 (96.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6382s / 622.6483 s
agent0:                 episode reward: -0.9980,                 loss: nan
agent1:                 episode reward: 0.9980,                 loss: 0.2364
Episode: 28881/30000 (96.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6482s / 623.2965 s
agent0:                 episode reward: -0.7493,                 loss: nan
agent1:                 episode reward: 0.7493,                 loss: 0.2410
Episode: 28901/30000 (96.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6467s / 623.9431 s
agent0:                 episode reward: -0.7091,                 loss: nan
agent1:                 episode reward: 0.7091,                 loss: 0.2277
Episode: 28921/30000 (96.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6995s / 624.6427 s
agent0:                 episode reward: -0.6548,                 loss: nan
agent1:                 episode reward: 0.6548,                 loss: 0.2035
Episode: 28941/30000 (96.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6506s / 625.2933 s
agent0:                 episode reward: -0.7496,                 loss: nan
agent1:                 episode reward: 0.7496,                 loss: 0.2040
Episode: 28961/30000 (96.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6470s / 625.9402 s
agent0:                 episode reward: -0.8875,                 loss: nan
agent1:                 episode reward: 0.8875,                 loss: 0.1991
Episode: 28981/30000 (96.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6479s / 626.5881 s
agent0:                 episode reward: -0.7909,                 loss: nan
agent1:                 episode reward: 0.7909,                 loss: 0.1994
Episode: 29001/30000 (96.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6508s / 627.2389 s
agent0:                 episode reward: -0.9897,                 loss: nan
agent1:                 episode reward: 0.9897,                 loss: 0.2056
Episode: 29021/30000 (96.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6458s / 627.8847 s
agent0:                 episode reward: -0.7843,                 loss: nan
agent1:                 episode reward: 0.7843,                 loss: 0.1964
Episode: 29041/30000 (96.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6353s / 628.5200 s
agent0:                 episode reward: -0.8241,                 loss: nan
agent1:                 episode reward: 0.8241,                 loss: 0.2005
Episode: 29061/30000 (96.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7032s / 629.2232 s
agent0:                 episode reward: -0.6173,                 loss: nan
agent1:                 episode reward: 0.6173,                 loss: 0.2011
Episode: 29081/30000 (96.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6553s / 629.8785 s
agent0:                 episode reward: -0.9030,                 loss: nan
agent1:                 episode reward: 0.9030,                 loss: 0.1968
Episode: 29101/30000 (97.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6473s / 630.5257 s
agent0:                 episode reward: -0.9626,                 loss: nan
agent1:                 episode reward: 0.9626,                 loss: 0.1992
Episode: 29121/30000 (97.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6418s / 631.1675 s
agent0:                 episode reward: -1.0428,                 loss: nan
agent1:                 episode reward: 1.0428,                 loss: 0.1980
Episode: 29141/30000 (97.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6474s / 631.8149 s
agent0:                 episode reward: -0.6472,                 loss: nan
agent1:                 episode reward: 0.6472,                 loss: 0.1988
Episode: 29161/30000 (97.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6674s / 632.4824 s
agent0:                 episode reward: -0.8712,                 loss: nan
agent1:                 episode reward: 0.8712,                 loss: 0.1984
Episode: 29181/30000 (97.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6515s / 633.1339 s
agent0:                 episode reward: -0.8193,                 loss: nan
agent1:                 episode reward: 0.8193,                 loss: 0.2002
Episode: 29201/30000 (97.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6420s / 633.7758 s
agent0:                 episode reward: -1.0291,                 loss: nan
agent1:                 episode reward: 1.0291,                 loss: 0.2013
Episode: 29221/30000 (97.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6399s / 634.4157 s
agent0:                 episode reward: -0.8998,                 loss: nan
agent1:                 episode reward: 0.8998,                 loss: 0.2760
Episode: 29241/30000 (97.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6558s / 635.0715 s
agent0:                 episode reward: -0.7405,                 loss: nan
agent1:                 episode reward: 0.7405,                 loss: 0.2756
Episode: 29261/30000 (97.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6549s / 635.7263 s
agent0:                 episode reward: -1.1049,                 loss: nan
agent1:                 episode reward: 1.1049,                 loss: 0.2693
Episode: 29281/30000 (97.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6453s / 636.3717 s
agent0:                 episode reward: -0.7667,                 loss: nan
agent1:                 episode reward: 0.7667,                 loss: 0.2730
Episode: 29301/30000 (97.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6466s / 637.0183 s
agent0:                 episode reward: -1.0232,                 loss: nan
agent1:                 episode reward: 1.0232,                 loss: 0.2698
Episode: 29321/30000 (97.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6486s / 637.6669 s
agent0:                 episode reward: -1.2953,                 loss: nan
agent1:                 episode reward: 1.2953,                 loss: 0.2678
Episode: 29341/30000 (97.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6560s / 638.3229 s
agent0:                 episode reward: -0.8039,                 loss: nan
agent1:                 episode reward: 0.8039,                 loss: 0.2699
Episode: 29361/30000 (97.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7003s / 639.0232 s
agent0:                 episode reward: -1.0121,                 loss: nan
agent1:                 episode reward: 1.0121,                 loss: 0.2709
Episode: 29381/30000 (97.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7540s / 639.7773 s
agent0:                 episode reward: -0.8724,                 loss: nan
agent1:                 episode reward: 0.8724,                 loss: 0.2697
Episode: 29401/30000 (98.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6587s / 640.4359 s
agent0:                 episode reward: -1.0014,                 loss: nan
agent1:                 episode reward: 1.0014,                 loss: 0.2694
Episode: 29421/30000 (98.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6668s / 641.1027 s
agent0:                 episode reward: -0.9978,                 loss: nan
agent1:                 episode reward: 0.9978,                 loss: 0.2686
Episode: 29441/30000 (98.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6516s / 641.7543 s
agent0:                 episode reward: -0.8024,                 loss: nan
agent1:                 episode reward: 0.8024,                 loss: 0.2709
Episode: 29461/30000 (98.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6424s / 642.3968 s
agent0:                 episode reward: -0.9582,                 loss: nan
agent1:                 episode reward: 0.9582,                 loss: 0.2696
Episode: 29481/30000 (98.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6500s / 643.0467 s
agent0:                 episode reward: -0.7283,                 loss: nan
agent1:                 episode reward: 0.7283,                 loss: 0.2686
Episode: 29501/30000 (98.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6479s / 643.6947 s
agent0:                 episode reward: -0.8660,                 loss: nan
agent1:                 episode reward: 0.8660,                 loss: 0.2698
Episode: 29521/30000 (98.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6582s / 644.3528 s
agent0:                 episode reward: -0.9264,                 loss: nan
agent1:                 episode reward: 0.9264,                 loss: 0.2660
Episode: 29541/30000 (98.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6450s / 644.9978 s
agent0:                 episode reward: -0.6106,                 loss: nan
agent1:                 episode reward: 0.6106,                 loss: 0.2713
Episode: 29561/30000 (98.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6566s / 645.6544 s
agent0:                 episode reward: -0.8752,                 loss: nan
agent1:                 episode reward: 0.8752,                 loss: 0.2588
Episode: 29581/30000 (98.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6708s / 646.3252 s
agent0:                 episode reward: -1.1854,                 loss: nan
agent1:                 episode reward: 1.1854,                 loss: 0.2241
Episode: 29601/30000 (98.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6530s / 646.9783 s
agent0:                 episode reward: -0.7996,                 loss: nan
agent1:                 episode reward: 0.7996,                 loss: 0.2246
Episode: 29621/30000 (98.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6690s / 647.6473 s
agent0:                 episode reward: -0.5248,                 loss: nan
agent1:                 episode reward: 0.5248,                 loss: 0.2238
Episode: 29641/30000 (98.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6519s / 648.2992 s
agent0:                 episode reward: -0.9136,                 loss: nan
agent1:                 episode reward: 0.9136,                 loss: 0.2243/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

Episode: 29661/30000 (98.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6545s / 648.9536 s
agent0:                 episode reward: -0.6373,                 loss: nan
agent1:                 episode reward: 0.6373,                 loss: 0.2215
Episode: 29681/30000 (98.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7032s / 649.6569 s
agent0:                 episode reward: -0.9734,                 loss: nan
agent1:                 episode reward: 0.9734,                 loss: 0.2244
Episode: 29701/30000 (99.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6784s / 650.3352 s
agent0:                 episode reward: -1.1709,                 loss: nan
agent1:                 episode reward: 1.1709,                 loss: 0.2245
Episode: 29721/30000 (99.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6600s / 650.9952 s
agent0:                 episode reward: -1.3085,                 loss: nan
agent1:                 episode reward: 1.3085,                 loss: 0.2214
Episode: 29741/30000 (99.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6560s / 651.6512 s
agent0:                 episode reward: -1.3098,                 loss: nan
agent1:                 episode reward: 1.3098,                 loss: 0.2263
Episode: 29761/30000 (99.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6548s / 652.3060 s
agent0:                 episode reward: -0.7594,                 loss: nan
agent1:                 episode reward: 0.7594,                 loss: 0.2214
Episode: 29781/30000 (99.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6538s / 652.9598 s
agent0:                 episode reward: -0.6488,                 loss: nan
agent1:                 episode reward: 0.6488,                 loss: 0.2229
Episode: 29801/30000 (99.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6624s / 653.6221 s
agent0:                 episode reward: -0.8894,                 loss: nan
agent1:                 episode reward: 0.8894,                 loss: 0.2179
Episode: 29821/30000 (99.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6537s / 654.2758 s
agent0:                 episode reward: -0.5445,                 loss: nan
agent1:                 episode reward: 0.5445,                 loss: 0.2229
Episode: 29841/30000 (99.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6511s / 654.9269 s
agent0:                 episode reward: -0.7258,                 loss: nan
agent1:                 episode reward: 0.7258,                 loss: 0.2230
Episode: 29861/30000 (99.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6650s / 655.5919 s
agent0:                 episode reward: -0.8818,                 loss: nan
agent1:                 episode reward: 0.8818,                 loss: 0.2221
Episode: 29881/30000 (99.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6696s / 656.2615 s
agent0:                 episode reward: -0.9776,                 loss: nan
agent1:                 episode reward: 0.9776,                 loss: 0.2309
Episode: 29901/30000 (99.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6561s / 656.9177 s
agent0:                 episode reward: -0.9622,                 loss: nan
agent1:                 episode reward: 0.9622,                 loss: 0.2325
Episode: 29921/30000 (99.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6698s / 657.5874 s
agent0:                 episode reward: -0.5068,                 loss: nan
agent1:                 episode reward: 0.5068,                 loss: 0.2111
Episode: 29941/30000 (99.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6501s / 658.2376 s
agent0:                 episode reward: -0.9266,                 loss: nan
agent1:                 episode reward: 0.9266,                 loss: 0.2067
Episode: 29961/30000 (99.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6583s / 658.8958 s
agent0:                 episode reward: -0.7976,                 loss: nan
agent1:                 episode reward: 0.7976,                 loss: 0.2086
Episode: 29981/30000 (99.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6721s / 659.5679 s
agent0:                 episode reward: -1.0231,                 loss: nan
agent1:                 episode reward: 1.0231,                 loss: 0.2067
