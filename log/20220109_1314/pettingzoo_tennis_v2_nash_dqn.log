pygame 2.0.0 (SDL 2.0.12, python 3.7.10)
Hello from the pygame community. https://www.pygame.org/contribute.html
tennis_v2 pettingzoo
Load tennis_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
random seed: 13
<mars.env.wrappers.mars_wrappers.Dict2TupleWrapper object at 0x7f958ff99950>
No agent are not learnable.
{'env_name': 'tennis_v2', 'env_type': 'pettingzoo', 'num_envs': 1, 'ram': True, 'seed': 'random', 'algorithm': 'NashDQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 0.1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': True, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [64, 64, 64, 64], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}, 'add_components': {'replay_buffer': <AutoProxy[replay_buffer] object, typeid 'replay_buffer' at 0x7f959110a050>}}
pygame 2.0.0 (SDL 2.0.12, python 3.7.10)
Hello from the pygame community. https://www.pygame.org/contribute.html
tennis_v2 pettingzoo
Load tennis_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
random seed: 75
Arguments:  {'env_name': 'tennis_v2', 'env_type': 'pettingzoo', 'num_envs': 1, 'ram': True, 'seed': 'random', 'algorithm': 'NashDQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 0.1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': True, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [64, 64, 64, 64], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}, 'add_components': {'replay_buffer': <AutoProxy[replay_buffer] object, typeid 'replay_buffer' at 0x7f2732d8f650>}}
Save models to : /home/zihan/research/MARS/data/model/0/pettingzoo_tennis_v2_nash_dqn. 
 Save logs to: /home/zihan/research/MARS/data/log/0/pettingzoo_tennis_v2_nash_dqn.
Process ID: 0, episode: 20/10000 (0.2000%),                     avg. length: 9623.65,                    last time consumption/overall running time: 2541.8247s / 2541.8247 s
first_0:                     episode reward: 2.8500
second_0:                     episode reward: -2.8500
Process ID: 0, episode: 40/10000 (0.4000%),                     avg. length: 9999.0,                    last time consumption/overall running time: 2970.3813s / 5512.2060 s
first_0:                     episode reward: 4.1500
second_0:                     episode reward: -4.1500
Process ID: 0, episode: 60/10000 (0.6000%),                     avg. length: 9999.0,                    last time consumption/overall running time: 2973.3068s / 8485.5128 s
first_0:                     episode reward: 1.0500
second_0:                     episode reward: -1.0500
Process ID: 0, episode: 80/10000 (0.8000%),                     avg. length: 9255.35,                    last time consumption/overall running time: 2751.4012s / 11236.9140 s
first_0:                     episode reward: -4.2000
second_0:                     episode reward: 4.2000
Process ID: 0, episode: 100/10000 (1.0000%),                     avg. length: 9968.1,                    last time consumption/overall running time: 2960.0710s / 14196.9850 s
first_0:                     episode reward: 5.7000
second_0:                     episode reward: -5.7000
Process ID: 0, episode: 120/10000 (1.2000%),                     avg. length: 9999.0,                    last time consumption/overall running time: 2976.3018s / 17173.2868 s
first_0:                     episode reward: 1.5000
second_0:                     episode reward: -1.5000
Process ID: 0, episode: 140/10000 (1.4000%),                     avg. length: 9260.15,                    last time consumption/overall running time: 2756.0101s / 19929.2969 s
first_0:                     episode reward: 0.1000
second_0:                     episode reward: -0.1000
Process ID: 0, episode: 160/10000 (1.6000%),                     avg. length: 8707.8,                    last time consumption/overall running time: 2585.5669s / 22514.8638 s
first_0:                     episode reward: 1.2500
second_0:                     episode reward: -1.2500
Process ID: 0, episode: 180/10000 (1.8000%),                     avg. length: 8516.1,                    last time consumption/overall running time: 2536.1073s / 25050.9712 s
first_0:                     episode reward: -3.9000
second_0:                     episode reward: 3.9000
Process ID: 0, episode: 200/10000 (2.0000%),                     avg. length: 7688.15,                    last time consumption/overall running time: 2289.0177s / 27339.9889 s
first_0:                     episode reward: -4.3500
second_0:                     episode reward: 4.3500
Process ID: 0, episode: 220/10000 (2.2000%),                     avg. length: 7634.3,                    last time consumption/overall running time: 2269.7569s / 29609.7458 s
first_0:                     episode reward: -4.3500
second_0:                     episode reward: 4.3500
Process ID: 0, episode: 240/10000 (2.4000%),                     avg. length: 8072.95,                    last time consumption/overall running time: 2402.2436s / 32011.9894 s
first_0:                     episode reward: -6.4000
second_0:                     episode reward: 6.4000
Process ID: 0, episode: 260/10000 (2.6000%),                     avg. length: 7824.45,                    last time consumption/overall running time: 2324.2730s / 34336.2624 s
first_0:                     episode reward: -4.8000
second_0:                     episode reward: 4.8000
Process ID: 0, episode: 280/10000 (2.8000%),                     avg. length: 5651.05,                    last time consumption/overall running time: 1673.9305s / 36010.1929 s
first_0:                     episode reward: -9.0500
second_0:                     episode reward: 9.0500
Process ID: 0, episode: 300/10000 (3.0000%),                     avg. length: 6025.0,                    last time consumption/overall running time: 1790.7376s / 37800.9304 s
first_0:                     episode reward: -3.7500
second_0:                     episode reward: 3.7500
Process ID: 0, episode: 320/10000 (3.2000%),                     avg. length: 5252.0,                    last time consumption/overall running time: 1561.4574s / 39362.3879 s
first_0:                     episode reward: -5.3000
second_0:                     episode reward: 5.3000
Process ID: 0, episode: 340/10000 (3.4000%),                     avg. length: 4638.75,                    last time consumption/overall running time: 1380.5794s / 40742.9673 s
first_0:                     episode reward: -4.5000
second_0:                     episode reward: 4.5000
Process ID: 0, episode: 360/10000 (3.6000%),                     avg. length: 4462.7,                    last time consumption/overall running time: 1328.2148s / 42071.1820 s
first_0:                     episode reward: -5.3000
second_0:                     episode reward: 5.3000
Process ID: 0, episode: 380/10000 (3.8000%),                     avg. length: 4574.9,                    last time consumption/overall running time: 1370.4677s / 43441.6497 s
first_0:                     episode reward: -8.5500
second_0:                     episode reward: 8.5500
Process ID: 0, episode: 400/10000 (4.0000%),                     avg. length: 4974.6,                    last time consumption/overall running time: 1485.5623s / 44927.2120 s
first_0:                     episode reward: -9.1000
second_0:                     episode reward: 9.1000
Process ID: 0, episode: 420/10000 (4.2000%),                     avg. length: 4483.95,                    last time consumption/overall running time: 1341.2990s / 46268.5110 s
first_0:                     episode reward: -9.2000
second_0:                     episode reward: 9.2000
Process ID: 0, episode: 440/10000 (4.4000%),                     avg. length: 4151.9,                    last time consumption/overall running time: 1238.1566s / 47506.6676 s
first_0:                     episode reward: -8.7500
second_0:                     episode reward: 8.7500
Process ID: 0, episode: 460/10000 (4.6000%),                     avg. length: 3319.1,                    last time consumption/overall running time: 995.2526s / 48501.9201 s
first_0:                     episode reward: -10.8500
second_0:                     episode reward: 10.8500
Process ID: 0, episode: 480/10000 (4.8000%),                     avg. length: 4149.95,                    last time consumption/overall running time: 1242.5610s / 49744.4812 spygame 2.0.0 (SDL 2.0.12, python 3.7.10)
Hello from the pygame community. https://www.pygame.org/contribute.html
tennis_v2 pettingzoo
Load tennis_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
random seed: 35
Arguments:  {'env_name': 'tennis_v2', 'env_type': 'pettingzoo', 'num_envs': 1, 'ram': True, 'seed': 'random', 'algorithm': 'NashDQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 0.1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': True, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [64, 64, 64, 64], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}, 'add_components': {'replay_buffer': <AutoProxy[replay_buffer] object, typeid 'replay_buffer' at 0x7f2732d8f610>}}
Save models to : /home/zihan/research/MARS/data/model/1/pettingzoo_tennis_v2_nash_dqn. 
 Save logs to: /home/zihan/research/MARS/data/log/1/pettingzoo_tennis_v2_nash_dqn.
Process ID: 1, episode: 20/10000 (0.2000%),                     avg. length: 9226.3,                    last time consumption/overall running time: 2415.3015s / 2415.3015 s
first_0:                     episode reward: 2.5500
second_0:                     episode reward: -2.5500
Process ID: 1, episode: 40/10000 (0.4000%),                     avg. length: 9665.15,                    last time consumption/overall running time: 2868.4778s / 5283.7793 s
first_0:                     episode reward: 3.4000
second_0:                     episode reward: -3.4000
Process ID: 1, episode: 60/10000 (0.6000%),                     avg. length: 9639.95,                    last time consumption/overall running time: 2864.9610s / 8148.7403 s
first_0:                     episode reward: 2.6500
second_0:                     episode reward: -2.6500
Process ID: 1, episode: 80/10000 (0.8000%),                     avg. length: 8803.05,                    last time consumption/overall running time: 2619.0419s / 10767.7822 s
first_0:                     episode reward: 3.7000
second_0:                     episode reward: -3.7000
Process ID: 1, episode: 100/10000 (1.0000%),                     avg. length: 9365.5,                    last time consumption/overall running time: 2781.9447s / 13549.7269 s
first_0:                     episode reward: 1.5500
second_0:                     episode reward: -1.5500
Process ID: 1, episode: 120/10000 (1.2000%),                     avg. length: 9014.05,                    last time consumption/overall running time: 2678.7641s / 16228.4910 s
first_0:                     episode reward: 0.9500
second_0:                     episode reward: -0.9500
Process ID: 1, episode: 140/10000 (1.4000%),                     avg. length: 9542.0,                    last time consumption/overall running time: 2831.2735s / 19059.7645 s
first_0:                     episode reward: -1.5000
second_0:                     episode reward: 1.5000
Process ID: 1, episode: 160/10000 (1.6000%),                     avg. length: 9287.05,                    last time consumption/overall running time: 2753.7670s / 21813.5315 s
first_0:                     episode reward: -3.8500
second_0:                     episode reward: 3.8500
Process ID: 1, episode: 180/10000 (1.8000%),                     avg. length: 9645.8,                    last time consumption/overall running time: 2879.3743s / 24692.9058 s
first_0:                     episode reward: -0.6000
second_0:                     episode reward: 0.6000
Process ID: 1, episode: 200/10000 (2.0000%),                     avg. length: 8173.5,                    last time consumption/overall running time: 2439.7483s / 27132.6541 s
first_0:                     episode reward: -0.8000
second_0:                     episode reward: 0.8000
Process ID: 1, episode: 220/10000 (2.2000%),                     avg. length: 7902.3,                    last time consumption/overall running time: 2349.4936s / 29482.1477 s
first_0:                     episode reward: -4.4500
second_0:                     episode reward: 4.4500
Process ID: 1, episode: 240/10000 (2.4000%),                     avg. length: 7386.2,                    last time consumption/overall running time: 2201.2531s / 31683.4008 s
first_0:                     episode reward: -5.5000
second_0:                     episode reward: 5.5000
Process ID: 1, episode: 260/10000 (2.6000%),                     avg. length: 5924.6,                    last time consumption/overall running time: 1764.3648s / 33447.7655 s
first_0:                     episode reward: -2.0500
second_0:                     episode reward: 2.0500
Process ID: 1, episode: 280/10000 (2.8000%),                     avg. length: 7214.2,                    last time consumption/overall running time: 2150.5942s / 35598.3597 s
first_0:                     episode reward: -4.9000
second_0:                     episode reward: 4.9000
Process ID: 1, episode: 300/10000 (3.0000%),                     avg. length: 6058.55,                    last time consumption/overall running time: 1808.5230s / 37406.8827 s
first_0:                     episode reward: -3.8000
second_0:                     episode reward: 3.8000
Process ID: 1, episode: 320/10000 (3.2000%),                     avg. length: 6398.1,                    last time consumption/overall running time: 1896.9498s / 39303.8324 s
first_0:                     episode reward: -2.7500
second_0:                     episode reward: 2.7500
Process ID: 1, episode: 340/10000 (3.4000%),                     avg. length: 5230.25,                    last time consumption/overall running time: 1553.3249s / 40857.1574 s
first_0:                     episode reward: -7.0500
second_0:                     episode reward: 7.0500
Process ID: 1, episode: 360/10000 (3.6000%),                     avg. length: 5506.6,                    last time consumption/overall running time: 1631.4094s / 42488.5667 s
first_0:                     episode reward: -8.5500
second_0:                     episode reward: 8.5500
Process ID: 1, episode: 380/10000 (3.8000%),                     avg. length: 5756.75,                    last time consumption/overall running time: 1714.8152s / 44203.3819 s
first_0:                     episode reward: -7.9500
second_0:                     episode reward: 7.9500
Process ID: 1, episode: 400/10000 (4.0000%),                     avg. length: 4205.65,                    last time consumption/overall running time: 1248.1264s / 45451.5083 s
first_0:                     episode reward: -5.9500
second_0:                     episode reward: 5.9500
Process ID: 1, episode: 420/10000 (4.2000%),                     avg. length: 4200.6,                    last time consumption/overall running time: 1250.2493s / 46701.7576 s
first_0:                     episode reward: -9.8000
second_0:                     episode reward: 9.8000
Process ID: 1, episode: 440/10000 (4.4000%),                     avg. length: 4360.05,                    last time consumption/overall running time: 1305.6907s / 48007.4483 s
first_0:                     episode reward: -10.2500
second_0:                     episode reward: 10.2500
Process ID: 1, episode: 460/10000 (4.6000%),                     avg. length: 4552.7,                    last time consumption/overall running time: 1365.5557s / 49373.0040 s
first_0:                     episode reward: -7.7000
second_0:                     episode reward: 7.7000
Process ID: 1, episode: 480/10000 (4.8000%),                     avg. length: 4650.45,                    last time consumption/overall running time: 1390.8257s / 50763.8297 s
first_0:                     episode reward: -10.2000
second_0:                     episode reward: 10.2000
Process ID: 0, episode: 500/10000 (5.0000%),                     avg. length: 3886.9,                    last time consumption/overall running time: 1163.4904s / 50907.9715 s
first_0:                     episode reward: -5.9500
second_0:                     episode reward: 5.9500
Process ID: 0, episode: 520/10000 (5.2000%),                     avg. length: 3372.95,                    last time consumption/overall running time: 1008.7651s / 51916.7366 s
first_0:                     episode reward: -7.5500
second_0:                     episode reward: 7.5500
Process ID: 0, episode: 540/10000 (5.4000%),                     avg. length: 3476.8,                    last time consumption/overall running time: 1038.1261s / 52954.8627 s
first_0:                     episode reward: -9.5500
second_0:                     episode reward: 9.5500
Process ID: 0, episode: 560/10000 (5.6000%),                     avg. length: 3475.3,                    last time consumption/overall running time: 1042.8772s / 53997.7399 s
first_0:                     episode reward: -11.5000
second_0:                     episode reward: 11.5000
Process ID: 0, episode: 580/10000 (5.8000%),                     avg. length: 4075.7,                    last time consumption/overall running time: 1217.5582s / 55215.2981 s
first_0:                     episode reward: -9.4500
second_0:                     episode reward: 9.4500
Process ID: 0, episode: 600/10000 (6.0000%),                     avg. length: 3297.2,                    last time consumption/overall running time: 982.6727s / 56197.9708 s
first_0:                     episode reward: -9.1000
second_0:                     episode reward: 9.1000
Process ID: 0, episode: 620/10000 (6.2000%),                     avg. length: 3624.25,                    last time consumption/overall running time: 1085.1502s / 57283.1210 s
first_0:                     episode reward: -12.2500
second_0:                     episode reward: 12.2500
Process ID: 0, episode: 640/10000 (6.4000%),                     avg. length: 2919.7,                    last time consumption/overall running time: 869.9443s / 58153.0653 s
first_0:                     episode reward: -13.4000
second_0:                     episode reward: 13.4000
Process ID: 0, episode: 660/10000 (6.6000%),                     avg. length: 3565.0,                    last time consumption/overall running time: 1065.5125s / 59218.5778 s
first_0:                     episode reward: -9.1000
second_0:                     episode reward: 9.1000
Process ID: 0, episode: 680/10000 (6.8000%),                     avg. length: 4039.45,                    last time consumption/overall running time: 1205.9415s / 60424.5193 s
first_0:                     episode reward: -10.7500
second_0:                     episode reward: 10.7500
Process ID: 0, episode: 700/10000 (7.0000%),                     avg. length: 4159.65,                    last time consumption/overall running time: 1247.2913s / 61671.8106 s
first_0:                     episode reward: -8.5000
second_0:                     episode reward: 8.5000
Process ID: 0, episode: 720/10000 (7.2000%),                     avg. length: 3624.8,                    last time consumption/overall running time: 1084.7635s / 62756.5741 s
first_0:                     episode reward: -11.1500
second_0:                     episode reward: 11.1500
Process ID: 0, episode: 740/10000 (7.4000%),                     avg. length: 3714.5,                    last time consumption/overall running time: 1110.2944s / 63866.8685 s
first_0:                     episode reward: -11.4000
second_0:                     episode reward: 11.4000
Process ID: 0, episode: 760/10000 (7.6000%),                     avg. length: 3440.5,                    last time consumption/overall running time: 1031.1249s / 64897.9934 s
first_0:                     episode reward: -9.6500
second_0:                     episode reward: 9.6500
Process ID: 0, episode: 780/10000 (7.8000%),                     avg. length: 4097.1,                    last time consumption/overall running time: 1227.0739s / 66125.0673 s
first_0:                     episode reward: -9.5500
second_0:                     episode reward: 9.5500
Process ID: 0, episode: 800/10000 (8.0000%),                     avg. length: 4493.95,                    last time consumption/overall running time: 1350.9309s / 67475.9981 s
first_0:                     episode reward: -9.3000
second_0:                     episode reward: 9.3000
Process ID: 0, episode: 820/10000 (8.2000%),                     avg. length: 3928.9,                    last time consumption/overall running time: 1175.0784s / 68651.0766 s
first_0:                     episode reward: -8.0500
second_0:                     episode reward: 8.0500
Process ID: 0, episode: 840/10000 (8.4000%),                     avg. length: 3774.85,                    last time consumption/overall running time: 1130.2318s / 69781.3083 s
first_0:                     episode reward: -8.0000
second_0:                     episode reward: 8.0000
Process ID: 0, episode: 860/10000 (8.6000%),                     avg. length: 5270.85,                    last time consumption/overall running time: 1576.9145s / 71358.2229 s
first_0:                     episode reward: -8.3000
second_0:                     episode reward: 8.3000
Process ID: 0, episode: 880/10000 (8.8000%),                     avg. length: 4207.2,                    last time consumption/overall running time: 1256.5588s / 72614.7816 s
first_0:                     episode reward: -9.5500
second_0:                     episode reward: 9.5500
Process ID: 0, episode: 900/10000 (9.0000%),                     avg. length: 5314.65,                    last time consumption/overall running time: 1585.0687s / 74199.8503 s
first_0:                     episode reward: -4.3000
second_0:                     episode reward: 4.3000
Process ID: 0, episode: 920/10000 (9.2000%),                     avg. length: 5209.5,                    last time consumption/overall running time: 1642.3621s / 75842.2124 s
first_0:                     episode reward: -2.0000
second_0:                     episode reward: 2.0000
Process ID: 0, episode: 940/10000 (9.4000%),                     avg. length: 4752.7,                    last time consumption/overall running time: 1430.8436s / 77273.0561 s
first_0:                     episode reward: -0.2500
second_0:                     episode reward: 0.2500
Process ID: 0, episode: 960/10000 (9.6000%),                     avg. length: 5391.3,                    last time consumption/overall running time: 1619.5087s / 78892.5648 s
first_0:                     episode reward: 1.1500
second_0:                     episode reward: -1.1500
Process ID: 0, episode: 980/10000 (9.8000%),                     avg. length: 5155.55,                    last time consumption/overall running time: 1550.0270s / 80442.5918 s
first_0:                     episode reward: 1.1000
second_0:                     episode reward: -1.1000
Process ID: 0, episode: 1000/10000 (10.0000%),                     avg. length: 6800.65,                    last time consumption/overall running time: 2039.0999s / 82481.6917 s
first_0:                     episode reward: -0.3500
second_0:                     episode reward: 0.3500
Process ID: 0, episode: 1020/10000 (10.2000%),                     avg. length: 5849.9,                    last time consumption/overall running time: 1752.1154s / 84233.8071 s
first_0:                     episode reward: 4.7000
second_0:                     episode reward: -4.7000
Process ID: 0, episode: 1040/10000 (10.4000%),                     avg. length: 4922.05,                    last time consumption/overall running time: 1473.9417s / 85707.7488 s
first_0:                     episode reward: 4.6000
second_0:                     episode reward: -4.6000
Process ID: 0, episode: 1060/10000 (10.6000%),                     avg. length: 5826.05,                    last time consumption/overall running time: 1742.4256s / 87450.1743 s
first_0:                     episode reward: 4.2500
first_0:                     episode reward: -7.2000
second_0:                     episode reward: 7.2000
Process ID: 1, episode: 500/10000 (5.0000%),                     avg. length: 3788.5,                    last time consumption/overall running time: 1134.7242s / 51898.5539 s
first_0:                     episode reward: -5.0500
second_0:                     episode reward: 5.0500
Process ID: 1, episode: 520/10000 (5.2000%),                     avg. length: 3765.35,                    last time consumption/overall running time: 1124.9836s / 53023.5375 s
first_0:                     episode reward: -10.1500
second_0:                     episode reward: 10.1500
Process ID: 1, episode: 540/10000 (5.4000%),                     avg. length: 3600.25,                    last time consumption/overall running time: 1080.6498s / 54104.1873 s
first_0:                     episode reward: -10.9000
second_0:                     episode reward: 10.9000
Process ID: 1, episode: 560/10000 (5.6000%),                     avg. length: 3454.1,                    last time consumption/overall running time: 1033.1136s / 55137.3010 s
first_0:                     episode reward: -10.8000
second_0:                     episode reward: 10.8000
Process ID: 1, episode: 580/10000 (5.8000%),                     avg. length: 3423.95,                    last time consumption/overall running time: 1022.4359s / 56159.7369 s
first_0:                     episode reward: -10.8000
second_0:                     episode reward: 10.8000
Process ID: 1, episode: 600/10000 (6.0000%),                     avg. length: 3529.85,                    last time consumption/overall running time: 1054.8992s / 57214.6361 s
first_0:                     episode reward: -11.6000
second_0:                     episode reward: 11.6000
Process ID: 1, episode: 620/10000 (6.2000%),                     avg. length: 3225.9,                    last time consumption/overall running time: 965.4235s / 58180.0596 s
first_0:                     episode reward: -11.4000
second_0:                     episode reward: 11.4000
Process ID: 1, episode: 640/10000 (6.4000%),                     avg. length: 3711.05,                    last time consumption/overall running time: 1109.4265s / 59289.4861 s
first_0:                     episode reward: -9.8000
second_0:                     episode reward: 9.8000
Process ID: 1, episode: 660/10000 (6.6000%),                     avg. length: 4014.05,                    last time consumption/overall running time: 1201.7218s / 60491.2079 s
first_0:                     episode reward: -7.6000
second_0:                     episode reward: 7.6000
Process ID: 1, episode: 680/10000 (6.8000%),                     avg. length: 3921.35,                    last time consumption/overall running time: 1170.9980s / 61662.2059 s
first_0:                     episode reward: -9.1000
second_0:                     episode reward: 9.1000
Process ID: 1, episode: 700/10000 (7.0000%),                     avg. length: 3654.05,                    last time consumption/overall running time: 1096.2101s / 62758.4160 s
first_0:                     episode reward: -8.8500
second_0:                     episode reward: 8.8500
Process ID: 1, episode: 720/10000 (7.2000%),                     avg. length: 3503.5,                    last time consumption/overall running time: 1048.8121s / 63807.2282 s
first_0:                     episode reward: -11.9000
second_0:                     episode reward: 11.9000
Process ID: 1, episode: 740/10000 (7.4000%),                     avg. length: 3439.8,                    last time consumption/overall running time: 1034.9897s / 64842.2179 s
first_0:                     episode reward: -9.6000
second_0:                     episode reward: 9.6000
Process ID: 1, episode: 760/10000 (7.6000%),                     avg. length: 4889.2,                    last time consumption/overall running time: 1468.0374s / 66310.2553 s
first_0:                     episode reward: -5.4000
second_0:                     episode reward: 5.4000
Process ID: 1, episode: 780/10000 (7.8000%),                     avg. length: 3794.7,                    last time consumption/overall running time: 1139.1012s / 67449.3565 s
first_0:                     episode reward: -8.2000
second_0:                     episode reward: 8.2000
Process ID: 1, episode: 800/10000 (8.0000%),                     avg. length: 4150.8,                    last time consumption/overall running time: 1243.9353s / 68693.2917 s
first_0:                     episode reward: -10.5000
second_0:                     episode reward: 10.5000
Process ID: 1, episode: 820/10000 (8.2000%),                     avg. length: 5266.05,                    last time consumption/overall running time: 1576.7967s / 70270.0884 s
first_0:                     episode reward: -10.1000
second_0:                     episode reward: 10.1000
Process ID: 1, episode: 840/10000 (8.4000%),                     avg. length: 3728.95,                    last time consumption/overall running time: 1112.1674s / 71382.2558 s
first_0:                     episode reward: -8.1500
second_0:                     episode reward: 8.1500
Process ID: 1, episode: 860/10000 (8.6000%),                     avg. length: 5352.25,                    last time consumption/overall running time: 1601.9194s / 72984.1752 s
first_0:                     episode reward: -4.9500
second_0:                     episode reward: 4.9500
Process ID: 1, episode: 880/10000 (8.8000%),                     avg. length: 4107.9,                    last time consumption/overall running time: 1231.0101s / 74215.1853 s
first_0:                     episode reward: -11.6000
second_0:                     episode reward: 11.6000
Process ID: 1, episode: 900/10000 (9.0000%),                     avg. length: 5116.25,                    last time consumption/overall running time: 1530.8048s / 75745.9901 s
first_0:                     episode reward: -5.5500
second_0:                     episode reward: 5.5500
Process ID: 1, episode: 920/10000 (9.2000%),                     avg. length: 5914.9,                    last time consumption/overall running time: 1863.6886s / 77609.6788 s
first_0:                     episode reward: 2.6500
second_0:                     episode reward: -2.6500
Process ID: 1, episode: 940/10000 (9.4000%),                     avg. length: 5275.25,                    last time consumption/overall running time: 1638.8144s / 79248.4931 s
first_0:                     episode reward: 2.7000
second_0:                     episode reward: -2.7000
Process ID: 1, episode: 960/10000 (9.6000%),                     avg. length: 5431.55,                    last time consumption/overall running time: 1629.5441s / 80878.0373 s
first_0:                     episode reward: 0.6000
second_0:                     episode reward: -0.6000
Process ID: 1, episode: 980/10000 (9.8000%),                     avg. length: 5791.25,                    last time consumption/overall running time: 1739.0100s / 82617.0472 s
first_0:                     episode reward: -1.2500
second_0:                     episode reward: 1.2500
Process ID: 1, episode: 1000/10000 (10.0000%),                     avg. length: 6034.6,                    last time consumption/overall running time: 1811.0641s / 84428.1114 s
first_0:                     episode reward: 1.2000
second_0:                     episode reward: -1.2000
Process ID: 1, episode: 1020/10000 (10.2000%),                     avg. length: 6374.85,                    last time consumption/overall running time: 1911.3947s / 86339.5061 s
first_0:                     episode reward: 3.3500
second_0:                     episode reward: -3.3500
Process ID: 1, episode: 1040/10000 (10.4000%),                     avg. length: 5435.3,                    last time consumption/overall running time: 1626.9217s / 87966.4278 s
first_0:                     episode reward: 3.4000
second_0:                     episode reward: -3.4000
Process ID: 1, episode: 1060/10000 (10.6000%),                     avg. length: 5409.35,                    last time consumption/overall running time: 1624.2597s / 89590.6875 s