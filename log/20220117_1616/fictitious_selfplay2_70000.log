pygame 2.0.0 (SDL 2.0.12, python 3.7.10)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 12.0, (1,), float32) action space: Discrete(3)
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7f848698fbd0>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
Agents No. [0] (index starting from 0) are not learnable.
Load meta strategy:  [[0.008 0.008 0.008 ... 0.008 0.008 0.008]
 [0.008 0.008 0.008 ... 0.008 0.008 0.008]]
Load checkpoints (policy family):  [['50' '5253' '7615' ... '68375' '68763' '69316']
 ['193' '5289' '7712' ... '68517' '68913' '69450']]
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': 1, 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000, 'update_itr': 1}, 'batch_size': 640, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'cpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220117153310/epi_70000/', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'fictitious_selfplay2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'selfplay_score_delta': 1.5, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'against_baseline': False}
Save models to : /home/zihan/research/MARS/data/model/20220117153310_exploit_70000/mdp_arbitrary_mdp_fictitious_selfplay2. 
 Save logs to: /home/zihan/research/MARS/data/log/20220117153310_exploit_70000/mdp_arbitrary_mdp_fictitious_selfplay2.
Episode: 1/30000 (0.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 6.8494s / 6.8494 s
agent0:                 episode reward: -1.0358,                 loss: nan
agent1:                 episode reward: 1.0358,                 loss: nan
Episode: 21/30000 (0.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 7.7368s / 14.5862 s
agent0:                 episode reward: 0.0813,                 loss: nan
agent1:                 episode reward: -0.0813,                 loss: nan
Episode: 41/30000 (0.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 6.5417s / 21.1280 s
agent0:                 episode reward: -0.2151,                 loss: nan
agent1:                 episode reward: 0.2151,                 loss: nan
Episode: 61/30000 (0.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 5.7939s / 26.9219 s
agent0:                 episode reward: 0.0336,                 loss: nan
agent1:                 episode reward: -0.0336,                 loss: nan
Episode: 81/30000 (0.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 7.0495s / 33.9713 s
agent0:                 episode reward: -0.4656,                 loss: nan
agent1:                 episode reward: 0.4656,                 loss: nan
Episode: 101/30000 (0.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 7.3001s / 41.2714 s
agent0:                 episode reward: 0.1114,                 loss: nan
agent1:                 episode reward: -0.1114,                 loss: nan
Episode: 121/30000 (0.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 6.6232s / 47.8947 s
agent0:                 episode reward: 0.0484,                 loss: nan
agent1:                 episode reward: -0.0484,                 loss: nan
Episode: 141/30000 (0.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 6.6283s / 54.5229 s
agent0:                 episode reward: -0.1023,                 loss: nan
agent1:                 episode reward: 0.1023,                 loss: nan
Episode: 161/30000 (0.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 7.2686s / 61.7916 s
agent0:                 episode reward: 0.2404,                 loss: nan
agent1:                 episode reward: -0.2404,                 loss: nan
Episode: 181/30000 (0.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 6.8058s / 68.5973 s
agent0:                 episode reward: 0.2529,                 loss: nan
agent1:                 episode reward: -0.2529,                 loss: nan
Episode: 201/30000 (0.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 7.0784s / 75.6757 s
agent0:                 episode reward: 0.2391,                 loss: nan
agent1:                 episode reward: -0.2391,                 loss: nan
Episode: 221/30000 (0.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 98.1652s / 173.8409 s
agent0:                 episode reward: 0.0331,                 loss: nan
agent1:                 episode reward: -0.0331,                 loss: 0.1816
Episode: 241/30000 (0.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.2812s / 415.1221 s
agent0:                 episode reward: 0.2457,                 loss: nan
agent1:                 episode reward: -0.2457,                 loss: 0.1733
Episode: 261/30000 (0.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.5916s / 664.7138 s
agent0:                 episode reward: 0.6521,                 loss: nan
agent1:                 episode reward: -0.6521,                 loss: 0.1689
Episode: 281/30000 (0.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 233.7834s / 898.4972 s
agent0:                 episode reward: -0.0450,                 loss: nan
agent1:                 episode reward: 0.0450,                 loss: 0.1661
Episode: 301/30000 (1.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 237.2478s / 1135.7450 s
agent0:                 episode reward: -0.2593,                 loss: nan
agent1:                 episode reward: 0.2593,                 loss: 0.1630
Episode: 321/30000 (1.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 239.1222s / 1374.8672 s
agent0:                 episode reward: -0.1556,                 loss: nan
agent1:                 episode reward: 0.1556,                 loss: 0.1610
Episode: 341/30000 (1.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.3728s / 1620.2400 s
agent0:                 episode reward: -0.0988,                 loss: nan
agent1:                 episode reward: 0.0988,                 loss: 0.1587
Episode: 361/30000 (1.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 235.0253s / 1855.2653 s
agent0:                 episode reward: 0.2011,                 loss: nan
agent1:                 episode reward: -0.2011,                 loss: 0.1571
Episode: 381/30000 (1.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.9973s / 2101.2626 s
agent0:                 episode reward: -0.3265,                 loss: nan
agent1:                 episode reward: 0.3265,                 loss: 0.1569
Episode: 401/30000 (1.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 240.6977s / 2341.9603 s
agent0:                 episode reward: -0.0567,                 loss: nan
agent1:                 episode reward: 0.0567,                 loss: 0.1559
Episode: 421/30000 (1.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 239.0750s / 2581.0353 s
agent0:                 episode reward: 0.2481,                 loss: nan
agent1:                 episode reward: -0.2481,                 loss: 0.1554
Episode: 441/30000 (1.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 238.1619s / 2819.1972 s
agent0:                 episode reward: -0.0391,                 loss: nan
agent1:                 episode reward: 0.0391,                 loss: 0.1547
Episode: 461/30000 (1.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.7669s / 3067.9641 s
agent0:                 episode reward: -0.2923,                 loss: nan
agent1:                 episode reward: 0.2923,                 loss: 0.1526
Episode: 481/30000 (1.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.3605s / 3314.3246 s
agent0:                 episode reward: -0.1185,                 loss: nan
agent1:                 episode reward: 0.1185,                 loss: 0.1506
Episode: 501/30000 (1.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.4404s / 3559.7651 s
agent0:                 episode reward: 0.4188,                 loss: nan
agent1:                 episode reward: -0.4188,                 loss: 0.1501
Episode: 521/30000 (1.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.5660s / 3806.3311 s
agent0:                 episode reward: 0.2281,                 loss: nan
agent1:                 episode reward: -0.2281,                 loss: 0.1495
Episode: 541/30000 (1.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 253.1555s / 4059.4866 s
agent0:                 episode reward: -0.1849,                 loss: nan
agent1:                 episode reward: 0.1849,                 loss: 0.1487
Episode: 561/30000 (1.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.6263s / 4312.1129 s
agent0:                 episode reward: -0.0767,                 loss: nan
agent1:                 episode reward: 0.0767,                 loss: 0.1592
Episode: 581/30000 (1.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.0307s / 4555.1435 s
agent0:                 episode reward: -0.0746,                 loss: nan
agent1:                 episode reward: 0.0746,                 loss: 0.1576
Episode: 601/30000 (2.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.9407s / 4797.0843 s
agent0:                 episode reward: -0.0057,                 loss: nan
agent1:                 episode reward: 0.0057,                 loss: 0.1552
Episode: 621/30000 (2.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.9821s / 5040.0664 s
agent0:                 episode reward: 0.3350,                 loss: nan
agent1:                 episode reward: -0.3350,                 loss: 0.1535
Episode: 641/30000 (2.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 236.8549s / 5276.9213 s
agent0:                 episode reward: 0.0386,                 loss: nan
agent1:                 episode reward: -0.0386,                 loss: 0.1525
Episode: 661/30000 (2.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.9639s / 5525.8852 s
agent0:                 episode reward: -0.0560,                 loss: nan
agent1:                 episode reward: 0.0560,                 loss: 0.1520
Episode: 681/30000 (2.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.7532s / 5772.6384 s
agent0:                 episode reward: -0.3115,                 loss: nan
agent1:                 episode reward: 0.3115,                 loss: 0.1525
Episode: 701/30000 (2.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.3577s / 6023.9961 s
agent0:                 episode reward: 0.0389,                 loss: nan
agent1:                 episode reward: -0.0389,                 loss: 0.1515
Episode: 721/30000 (2.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.1036s / 6270.0998 s
agent0:                 episode reward: -0.1803,                 loss: nan
agent1:                 episode reward: 0.1803,                 loss: 0.1521
Episode: 741/30000 (2.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.2619s / 6512.3616 s
agent0:                 episode reward: -0.2226,                 loss: nan
agent1:                 episode reward: 0.2226,                 loss: 0.1507
Episode: 761/30000 (2.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.2746s / 6759.6362 s
agent0:                 episode reward: -0.3714,                 loss: nan
agent1:                 episode reward: 0.3714,                 loss: 0.1515
Episode: 781/30000 (2.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.7805s / 7010.4167 s
agent0:                 episode reward: 0.2948,                 loss: nan
agent1:                 episode reward: -0.2948,                 loss: 0.1502
Episode: 801/30000 (2.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.7199s / 7254.1366 s
agent0:                 episode reward: 0.1258,                 loss: nan
agent1:                 episode reward: -0.1258,                 loss: 0.1513
Episode: 821/30000 (2.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.7966s / 7497.9332 s
agent0:                 episode reward: -0.0389,                 loss: nan
agent1:                 episode reward: 0.0389,                 loss: 0.1503
Episode: 841/30000 (2.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 255.2067s / 7753.1399 s
agent0:                 episode reward: -0.0080,                 loss: nan
agent1:                 episode reward: 0.0080,                 loss: 0.1498
Episode: 861/30000 (2.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 240.6861s / 7993.8259 s
agent0:                 episode reward: 0.0806,                 loss: nan
agent1:                 episode reward: -0.0806,                 loss: 0.1489
Episode: 881/30000 (2.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.6910s / 8238.5169 s
agent0:                 episode reward: 0.1709,                 loss: nan
agent1:                 episode reward: -0.1709,                 loss: 0.1478
Episode: 901/30000 (3.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 239.0297s / 8477.5466 s
agent0:                 episode reward: -0.2825,                 loss: nan
agent1:                 episode reward: 0.2825,                 loss: 0.1483
Episode: 921/30000 (3.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.3662s / 8721.9128 s
agent0:                 episode reward: 0.3271,                 loss: nan
agent1:                 episode reward: -0.3271,                 loss: 0.1454
Episode: 941/30000 (3.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.0692s / 8969.9820 s
agent0:                 episode reward: -0.1116,                 loss: nan
agent1:                 episode reward: 0.1116,                 loss: 0.1462
Episode: 961/30000 (3.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.4421s / 9219.4241 s
agent0:                 episode reward: 0.0361,                 loss: nan
agent1:                 episode reward: -0.0361,                 loss: 0.1438
Episode: 981/30000 (3.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.3752s / 9466.7993 s
agent0:                 episode reward: -0.0467,                 loss: nan
agent1:                 episode reward: 0.0467,                 loss: 0.1446
Episode: 1001/30000 (3.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 234.1219s / 9700.9212 s
agent0:                 episode reward: -0.0220,                 loss: nan
agent1:                 episode reward: 0.0220,                 loss: 0.1435
Episode: 1021/30000 (3.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.9863s / 9942.9075 s
agent0:                 episode reward: -0.0515,                 loss: nan
agent1:                 episode reward: 0.0515,                 loss: 0.1433
Episode: 1041/30000 (3.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.9709s / 10185.8784 s
agent0:                 episode reward: 0.0181,                 loss: nan
agent1:                 episode reward: -0.0181,                 loss: 0.1433
Episode: 1061/30000 (3.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.9700s / 10430.8484 s
agent0:                 episode reward: -0.2285,                 loss: nan
agent1:                 episode reward: 0.2285,                 loss: 0.1428
Episode: 1081/30000 (3.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.4271s / 10680.2755 s
agent0:                 episode reward: -0.3495,                 loss: nan
agent1:                 episode reward: 0.3495,                 loss: 0.1427
Episode: 1101/30000 (3.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.4781s / 10921.7536 s
agent0:                 episode reward: 0.1327,                 loss: nan
agent1:                 episode reward: -0.1327,                 loss: 0.1432
Episode: 1121/30000 (3.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.7610s / 11168.5146 s
agent0:                 episode reward: 0.2032,                 loss: nan
agent1:                 episode reward: -0.2032,                 loss: 0.1411
Episode: 1141/30000 (3.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.1154s / 11413.6300 s
agent0:                 episode reward: 0.0601,                 loss: nan
agent1:                 episode reward: -0.0601,                 loss: 0.1406
Episode: 1161/30000 (3.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 258.0809s / 11671.7109 s
agent0:                 episode reward: -0.3809,                 loss: nan
agent1:                 episode reward: 0.3809,                 loss: 0.1397
Episode: 1181/30000 (3.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.4678s / 11920.1787 s
agent0:                 episode reward: 0.0100,                 loss: nan
agent1:                 episode reward: -0.0100,                 loss: 0.1410
Episode: 1201/30000 (4.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.2857s / 12167.4644 s
agent0:                 episode reward: -0.1525,                 loss: nan
agent1:                 episode reward: 0.1525,                 loss: 0.1393
Episode: 1221/30000 (4.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.6040s / 12417.0684 s
agent0:                 episode reward: -0.1064,                 loss: nan
agent1:                 episode reward: 0.1064,                 loss: 0.1399
Episode: 1241/30000 (4.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.4958s / 12668.5642 s
agent0:                 episode reward: 0.1682,                 loss: nan
agent1:                 episode reward: -0.1682,                 loss: 0.1386
Episode: 1261/30000 (4.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.5931s / 12913.1572 s
agent0:                 episode reward: -0.2087,                 loss: nan
agent1:                 episode reward: 0.2087,                 loss: 0.1402
Episode: 1281/30000 (4.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.9698s / 13155.1270 s
agent0:                 episode reward: -0.1998,                 loss: nan
agent1:                 episode reward: 0.1998,                 loss: 0.1386
Episode: 1301/30000 (4.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 237.6146s / 13392.7417 s
agent0:                 episode reward: 0.3376,                 loss: nan
agent1:                 episode reward: -0.3376,                 loss: 0.1381
Episode: 1321/30000 (4.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.3292s / 13638.0709 s
agent0:                 episode reward: -0.1476,                 loss: nan
agent1:                 episode reward: 0.1476,                 loss: 0.1375
Episode: 1341/30000 (4.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.8173s / 13886.8882 s
agent0:                 episode reward: 0.0885,                 loss: nan
agent1:                 episode reward: -0.0885,                 loss: 0.1375
Episode: 1361/30000 (4.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.8686s / 14138.7568 s
agent0:                 episode reward: 0.0534,                 loss: nan
agent1:                 episode reward: -0.0534,                 loss: 0.1365
Episode: 1381/30000 (4.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.0716s / 14384.8284 s
agent0:                 episode reward: -0.1004,                 loss: nan
agent1:                 episode reward: 0.1004,                 loss: 0.1382
Episode: 1401/30000 (4.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 239.5175s / 14624.3459 s
agent0:                 episode reward: -0.0454,                 loss: nan
agent1:                 episode reward: 0.0454,                 loss: 0.1359
Episode: 1421/30000 (4.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 240.3043s / 14864.6502 s
agent0:                 episode reward: -0.1770,                 loss: nan
agent1:                 episode reward: 0.1770,                 loss: 0.1375
Episode: 1441/30000 (4.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 257.8463s / 15122.4965 s
agent0:                 episode reward: 0.1518,                 loss: nan
agent1:                 episode reward: -0.1518,                 loss: 0.1355
Episode: 1461/30000 (4.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.0881s / 15363.5846 s
agent0:                 episode reward: 0.0306,                 loss: nan
agent1:                 episode reward: -0.0306,                 loss: 0.1376
Episode: 1481/30000 (4.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.3263s / 15613.9109 s
agent0:                 episode reward: -0.4169,                 loss: nan
agent1:                 episode reward: 0.4169,                 loss: 0.1360
Episode: 1501/30000 (5.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.5251s / 15855.4360 s
agent0:                 episode reward: -0.2636,                 loss: nan
agent1:                 episode reward: 0.2636,                 loss: 0.1354
Episode: 1521/30000 (5.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.7399s / 16100.1759 s
agent0:                 episode reward: -0.5361,                 loss: nan
agent1:                 episode reward: 0.5361,                 loss: 0.1358
Episode: 1541/30000 (5.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.0259s / 16345.2018 s
agent0:                 episode reward: -0.1471,                 loss: nan
agent1:                 episode reward: 0.1471,                 loss: 0.1342
Episode: 1561/30000 (5.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.6403s / 16592.8421 s
agent0:                 episode reward: -0.4010,                 loss: nan
agent1:                 episode reward: 0.4010,                 loss: 0.1344
Episode: 1581/30000 (5.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.0155s / 16833.8576 s
agent0:                 episode reward: -0.2149,                 loss: nan
agent1:                 episode reward: 0.2149,                 loss: 0.1342
Episode: 1601/30000 (5.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 238.6591s / 17072.5168 s
agent0:                 episode reward: -0.5328,                 loss: nan
agent1:                 episode reward: 0.5328,                 loss: 0.1324
Episode: 1621/30000 (5.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.0584s / 17317.5752 s
agent0:                 episode reward: 0.2006,                 loss: nan
agent1:                 episode reward: -0.2006,                 loss: 0.1343
Episode: 1641/30000 (5.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.5883s / 17568.1635 s
agent0:                 episode reward: -0.5096,                 loss: nan
agent1:                 episode reward: 0.5096,                 loss: 0.1338
Episode: 1661/30000 (5.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 240.9349s / 17809.0983 s
agent0:                 episode reward: -0.0434,                 loss: nan
agent1:                 episode reward: 0.0434,                 loss: 0.1337
Episode: 1681/30000 (5.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.6467s / 18050.7451 s
agent0:                 episode reward: -0.3833,                 loss: nan
agent1:                 episode reward: 0.3833,                 loss: 0.1329
Episode: 1701/30000 (5.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 237.3144s / 18288.0595 s
agent0:                 episode reward: -0.0529,                 loss: nan
agent1:                 episode reward: 0.0529,                 loss: 0.1323
Episode: 1721/30000 (5.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.4025s / 18534.4620 s
agent0:                 episode reward: -0.1828,                 loss: nan
agent1:                 episode reward: 0.1828,                 loss: 0.1327
Episode: 1741/30000 (5.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.6059s / 18786.0679 s
agent0:                 episode reward: -0.6178,                 loss: nan
agent1:                 episode reward: 0.6178,                 loss: 0.1318
Episode: 1761/30000 (5.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.0141s / 19034.0819 s
agent0:                 episode reward: 0.2427,                 loss: nan
agent1:                 episode reward: -0.2427,                 loss: 0.1325
Episode: 1781/30000 (5.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 239.8883s / 19273.9702 s
agent0:                 episode reward: 0.0050,                 loss: nan
agent1:                 episode reward: -0.0050,                 loss: 0.1326
Episode: 1801/30000 (6.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.7671s / 19521.7373 s
agent0:                 episode reward: -0.3861,                 loss: nan
agent1:                 episode reward: 0.3861,                 loss: 0.1326
Episode: 1821/30000 (6.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.7916s / 19769.5290 s
agent0:                 episode reward: -0.0974,                 loss: nan
agent1:                 episode reward: 0.0974,                 loss: 0.1344
Episode: 1841/30000 (6.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.1908s / 20017.7197 s
agent0:                 episode reward: -0.3864,                 loss: nan
agent1:                 episode reward: 0.3864,                 loss: 0.1335
Episode: 1861/30000 (6.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.3132s / 20266.0329 s
agent0:                 episode reward: -0.1464,                 loss: nan
agent1:                 episode reward: 0.1464,                 loss: 0.1327
Episode: 1881/30000 (6.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.3083s / 20516.3412 s
agent0:                 episode reward: -0.5147,                 loss: nan
agent1:                 episode reward: 0.5147,                 loss: 0.1333
Episode: 1901/30000 (6.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.6876s / 20761.0288 s
agent0:                 episode reward: -0.3608,                 loss: nan
agent1:                 episode reward: 0.3608,                 loss: 0.1336
Episode: 1921/30000 (6.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.5900s / 21007.6188 s
agent0:                 episode reward: -0.0062,                 loss: nan
agent1:                 episode reward: 0.0062,                 loss: 0.1347
Episode: 1941/30000 (6.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.8511s / 21251.4699 s
agent0:                 episode reward: -0.2746,                 loss: nan
agent1:                 episode reward: 0.2746,                 loss: 0.1354
Episode: 1961/30000 (6.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 239.8612s / 21491.3311 s
agent0:                 episode reward: -0.1262,                 loss: nan
agent1:                 episode reward: 0.1262,                 loss: 0.1351
Episode: 1981/30000 (6.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 255.7788s / 21747.1099 s
agent0:                 episode reward: -0.1672,                 loss: nan
agent1:                 episode reward: 0.1672,                 loss: 0.1335
Episode: 2001/30000 (6.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 255.2974s / 22002.4072 s
agent0:                 episode reward: -0.1995,                 loss: nan
agent1:                 episode reward: 0.1995,                 loss: 0.1328
Episode: 2021/30000 (6.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.3810s / 22249.7882 s
agent0:                 episode reward: 0.3350,                 loss: nan
agent1:                 episode reward: -0.3350,                 loss: 0.1331
Episode: 2041/30000 (6.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.0597s / 22491.8479 s
agent0:                 episode reward: -0.4185,                 loss: nan
agent1:                 episode reward: 0.4185,                 loss: 0.1327
Episode: 2061/30000 (6.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.1819s / 22735.0298 s
agent0:                 episode reward: -0.1057,                 loss: nan
agent1:                 episode reward: 0.1057,                 loss: 0.1328
Episode: 2081/30000 (6.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.2039s / 22980.2337 s
agent0:                 episode reward: -0.4448,                 loss: nan
agent1:                 episode reward: 0.4448,                 loss: 0.1322
Episode: 2101/30000 (7.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.6006s / 23226.8344 s
agent0:                 episode reward: 0.0370,                 loss: nan
agent1:                 episode reward: -0.0370,                 loss: 0.1340
Episode: 2121/30000 (7.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.4481s / 23471.2824 s
agent0:                 episode reward: 0.0449,                 loss: nan
agent1:                 episode reward: -0.0449,                 loss: 0.1330
Episode: 2141/30000 (7.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.8282s / 23718.1106 s
agent0:                 episode reward: -0.3541,                 loss: nan
agent1:                 episode reward: 0.3541,                 loss: 0.1322
Episode: 2161/30000 (7.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.1047s / 23969.2153 s
agent0:                 episode reward: -0.0093,                 loss: nan
agent1:                 episode reward: 0.0093,                 loss: 0.1339
Episode: 2181/30000 (7.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.0247s / 24211.2400 s
agent0:                 episode reward: -0.1020,                 loss: nan
agent1:                 episode reward: 0.1020,                 loss: 0.1333
Episode: 2201/30000 (7.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.7247s / 24457.9647 s
agent0:                 episode reward: -0.0307,                 loss: nan
agent1:                 episode reward: 0.0307,                 loss: 0.1328
Episode: 2221/30000 (7.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.8374s / 24701.8020 s
agent0:                 episode reward: -0.1704,                 loss: nan
agent1:                 episode reward: 0.1704,                 loss: 0.1339
Episode: 2241/30000 (7.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.6722s / 24947.4742 s
agent0:                 episode reward: -0.1360,                 loss: nan
agent1:                 episode reward: 0.1360,                 loss: 0.1346
Episode: 2261/30000 (7.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.8170s / 25199.2912 s
agent0:                 episode reward: 0.2786,                 loss: nan
agent1:                 episode reward: -0.2786,                 loss: 0.1356
Episode: 2281/30000 (7.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.0756s / 25442.3668 s
agent0:                 episode reward: -0.0759,                 loss: nan
agent1:                 episode reward: 0.0759,                 loss: 0.1361
Episode: 2301/30000 (7.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.9752s / 25689.3420 s
agent0:                 episode reward: 0.0436,                 loss: nan
agent1:                 episode reward: -0.0436,                 loss: 0.1333
Episode: 2321/30000 (7.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 240.9347s / 25930.2767 s
agent0:                 episode reward: -0.1061,                 loss: nan
agent1:                 episode reward: 0.1061,                 loss: 0.1328
Episode: 2341/30000 (7.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 240.2543s / 26170.5310 s
agent0:                 episode reward: -0.1278,                 loss: nan
agent1:                 episode reward: 0.1278,                 loss: 0.1335
Episode: 2361/30000 (7.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 253.2004s / 26423.7314 s
agent0:                 episode reward: -0.3640,                 loss: nan
agent1:                 episode reward: 0.3640,                 loss: 0.1346
Episode: 2381/30000 (7.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.6434s / 26674.3748 s
agent0:                 episode reward: -0.3396,                 loss: nan
agent1:                 episode reward: 0.3396,                 loss: 0.1342
Episode: 2401/30000 (8.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.3507s / 26916.7255 s
agent0:                 episode reward: -0.3052,                 loss: nan
agent1:                 episode reward: 0.3052,                 loss: 0.1348
Episode: 2421/30000 (8.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.3652s / 27158.0907 s
agent0:                 episode reward: -0.2895,                 loss: nan
agent1:                 episode reward: 0.2895,                 loss: 0.1350
Episode: 2441/30000 (8.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.4498s / 27404.5405 s
agent0:                 episode reward: -0.2183,                 loss: nan
agent1:                 episode reward: 0.2183,                 loss: 0.1343
Episode: 2461/30000 (8.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 260.9095s / 27665.4500 s
agent0:                 episode reward: 0.1660,                 loss: nan
agent1:                 episode reward: -0.1660,                 loss: 0.1355
Episode: 2481/30000 (8.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 257.7055s / 27923.1555 s
agent0:                 episode reward: -0.3839,                 loss: nan
agent1:                 episode reward: 0.3839,                 loss: 0.1348
Episode: 2501/30000 (8.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 241.3295s / 28164.4851 s
agent0:                 episode reward: -0.0526,                 loss: nan
agent1:                 episode reward: 0.0526,                 loss: 0.1355
Episode: 2521/30000 (8.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.3303s / 28411.8154 s
agent0:                 episode reward: 0.0942,                 loss: nan
agent1:                 episode reward: -0.0942,                 loss: 0.1352
Episode: 2541/30000 (8.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.8382s / 28659.6536 s
agent0:                 episode reward: -0.3075,                 loss: nan
agent1:                 episode reward: 0.3075,                 loss: 0.1339
Episode: 2561/30000 (8.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 239.5714s / 28899.2251 s
agent0:                 episode reward: 0.0389,                 loss: nan
agent1:                 episode reward: -0.0389,                 loss: 0.1346
Episode: 2581/30000 (8.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.5922s / 29148.8173 s
agent0:                 episode reward: 0.1877,                 loss: nan
agent1:                 episode reward: -0.1877,                 loss: 0.1333
Episode: 2601/30000 (8.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 254.8513s / 29403.6685 s
agent0:                 episode reward: -0.1753,                 loss: nan
agent1:                 episode reward: 0.1753,                 loss: 0.1332
Episode: 2621/30000 (8.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.3541s / 29654.0226 s
agent0:                 episode reward: -0.1221,                 loss: nan
agent1:                 episode reward: 0.1221,                 loss: 0.1325
Episode: 2641/30000 (8.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.6644s / 29903.6871 s
agent0:                 episode reward: -0.2524,                 loss: nan
agent1:                 episode reward: 0.2524,                 loss: 0.1341
Episode: 2661/30000 (8.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.7468s / 30152.4339 s
agent0:                 episode reward: -0.3422,                 loss: nan
agent1:                 episode reward: 0.3422,                 loss: 0.1343
Episode: 2681/30000 (8.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.9490s / 30401.3829 s
agent0:                 episode reward: -0.1212,                 loss: nan
agent1:                 episode reward: 0.1212,                 loss: 0.1332
Episode: 2701/30000 (9.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.7220s / 30648.1049 s
agent0:                 episode reward: -0.0021,                 loss: nan
agent1:                 episode reward: 0.0021,                 loss: 0.1335
Episode: 2721/30000 (9.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.5015s / 30898.6064 s
agent0:                 episode reward: -0.1459,                 loss: nan
agent1:                 episode reward: 0.1459,                 loss: 0.1322
Episode: 2741/30000 (9.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.9626s / 31150.5691 s
agent0:                 episode reward: -0.1577,                 loss: nan
agent1:                 episode reward: 0.1577,                 loss: 0.1326
Episode: 2761/30000 (9.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 236.9499s / 31387.5190 s
agent0:                 episode reward: 0.1819,                 loss: nan
agent1:                 episode reward: -0.1819,                 loss: 0.1335
Episode: 2781/30000 (9.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.0838s / 31632.6028 s
agent0:                 episode reward: -0.3226,                 loss: nan
agent1:                 episode reward: 0.3226,                 loss: 0.1318
Episode: 2801/30000 (9.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.3293s / 31881.9321 s
agent0:                 episode reward: -0.0237,                 loss: nan
agent1:                 episode reward: 0.0237,                 loss: 0.1339
Episode: 2821/30000 (9.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 255.6623s / 32137.5944 s
agent0:                 episode reward: -0.3528,                 loss: nan
agent1:                 episode reward: 0.3528,                 loss: 0.1321
Episode: 2841/30000 (9.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.2155s / 32383.8100 s
agent0:                 episode reward: -0.3171,                 loss: nan
agent1:                 episode reward: 0.3171,                 loss: 0.1340
Episode: 2861/30000 (9.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.6794s / 32630.4893 s
agent0:                 episode reward: -0.2732,                 loss: nan
agent1:                 episode reward: 0.2732,                 loss: 0.1328
Episode: 2881/30000 (9.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.0286s / 32877.5180 s
agent0:                 episode reward: -0.1232,                 loss: nan
agent1:                 episode reward: 0.1232,                 loss: 0.1329
Episode: 2901/30000 (9.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.7108s / 33127.2288 s
agent0:                 episode reward: -0.1963,                 loss: nan
agent1:                 episode reward: 0.1963,                 loss: 0.1357
Episode: 2921/30000 (9.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.2218s / 33375.4505 s
agent0:                 episode reward: -0.1139,                 loss: nan
agent1:                 episode reward: 0.1139,                 loss: 0.1357
Episode: 2941/30000 (9.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 254.3002s / 33629.7508 s
agent0:                 episode reward: -0.5633,                 loss: nan
agent1:                 episode reward: 0.5633,                 loss: 0.1359
Episode: 2961/30000 (9.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.0653s / 33872.8161 s
agent0:                 episode reward: -0.3250,                 loss: nan
agent1:                 episode reward: 0.3250,                 loss: 0.1354
Episode: 2981/30000 (9.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.3649s / 34124.1810 s
agent0:                 episode reward: -0.1818,                 loss: nan
agent1:                 episode reward: 0.1818,                 loss: 0.1365
Episode: 3001/30000 (10.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.7606s / 34370.9415 s
agent0:                 episode reward: -0.3918,                 loss: nan
agent1:                 episode reward: 0.3918,                 loss: 0.1361
Episode: 3021/30000 (10.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.0548s / 34615.9963 s
agent0:                 episode reward: 0.0143,                 loss: nan
agent1:                 episode reward: -0.0143,                 loss: 0.1366
Episode: 3041/30000 (10.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.0876s / 34858.0839 s
agent0:                 episode reward: -0.0052,                 loss: nan
agent1:                 episode reward: 0.0052,                 loss: 0.1353
Episode: 3061/30000 (10.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.2900s / 35104.3739 s
agent0:                 episode reward: -0.3095,                 loss: nan
agent1:                 episode reward: 0.3095,                 loss: 0.1359
Episode: 3081/30000 (10.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.7969s / 35346.1708 s
agent0:                 episode reward: -0.4254,                 loss: nan
agent1:                 episode reward: 0.4254,                 loss: 0.1360
Episode: 3101/30000 (10.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.1268s / 35590.2975 s
agent0:                 episode reward: -0.2012,                 loss: nan
agent1:                 episode reward: 0.2012,                 loss: 0.1365
Episode: 3121/30000 (10.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.4294s / 35839.7270 s
agent0:                 episode reward: -0.5049,                 loss: nan
agent1:                 episode reward: 0.5049,                 loss: 0.1369
Episode: 3141/30000 (10.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.5552s / 36086.2822 s
agent0:                 episode reward: -0.4664,                 loss: nan
agent1:                 episode reward: 0.4664,                 loss: 0.1348
Episode: 3161/30000 (10.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.0383s / 36330.3205 s
agent0:                 episode reward: -0.1458,                 loss: nan
agent1:                 episode reward: 0.1458,                 loss: 0.1352
Episode: 3181/30000 (10.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.4973s / 36582.8178 s
agent0:                 episode reward: -0.2136,                 loss: nan
agent1:                 episode reward: 0.2136,                 loss: 0.1375
Episode: 3201/30000 (10.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 254.3700s / 36837.1877 s
agent0:                 episode reward: -0.1707,                 loss: nan
agent1:                 episode reward: 0.1707,                 loss: 0.1355
Episode: 3221/30000 (10.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.1909s / 37083.3787 s
agent0:                 episode reward: -0.0155,                 loss: nan
agent1:                 episode reward: 0.0155,                 loss: 0.1368
Episode: 3241/30000 (10.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 240.0135s / 37323.3922 s
agent0:                 episode reward: 0.3439,                 loss: nan
agent1:                 episode reward: -0.3439,                 loss: 0.1354
Episode: 3261/30000 (10.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.7456s / 37566.1378 s
agent0:                 episode reward: -0.1480,                 loss: nan
agent1:                 episode reward: 0.1480,                 loss: 0.1369
Episode: 3281/30000 (10.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 254.4723s / 37820.6101 s
agent0:                 episode reward: -0.2374,                 loss: nan
agent1:                 episode reward: 0.2374,                 loss: 0.1363
Episode: 3301/30000 (11.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.9017s / 38065.5118 s
agent0:                 episode reward: -0.4086,                 loss: nan
agent1:                 episode reward: 0.4086,                 loss: 0.1364
Episode: 3321/30000 (11.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.4158s / 38308.9276 s
agent0:                 episode reward: 0.1216,                 loss: nan
agent1:                 episode reward: -0.1216,                 loss: 0.1359
Episode: 3341/30000 (11.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.6386s / 38551.5661 s
agent0:                 episode reward: -0.0875,                 loss: nan
agent1:                 episode reward: 0.0875,                 loss: 0.1364
Episode: 3361/30000 (11.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 238.0884s / 38789.6545 s
agent0:                 episode reward: -0.1792,                 loss: nan
agent1:                 episode reward: 0.1792,                 loss: 0.1352
Episode: 3381/30000 (11.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.3828s / 39033.0373 s
agent0:                 episode reward: -0.1326,                 loss: nan
agent1:                 episode reward: 0.1326,                 loss: 0.1366
Episode: 3401/30000 (11.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.2582s / 39283.2955 s
agent0:                 episode reward: -0.1640,                 loss: nan
agent1:                 episode reward: 0.1640,                 loss: 0.1367
Episode: 3421/30000 (11.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.7401s / 39534.0356 s
agent0:                 episode reward: -0.4444,                 loss: nan
agent1:                 episode reward: 0.4444,                 loss: 0.1364
Episode: 3441/30000 (11.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.5064s / 39777.5420 s
agent0:                 episode reward: -0.6703,                 loss: nan
agent1:                 episode reward: 0.6703,                 loss: 0.1358
Episode: 3461/30000 (11.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.9888s / 40022.5308 s
agent0:                 episode reward: -0.1631,                 loss: nan
agent1:                 episode reward: 0.1631,                 loss: 0.1369
Episode: 3481/30000 (11.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.3735s / 40267.9044 s
agent0:                 episode reward: 0.2985,                 loss: nan
agent1:                 episode reward: -0.2985,                 loss: 0.1361
Episode: 3501/30000 (11.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 253.6539s / 40521.5582 s
agent0:                 episode reward: -0.2318,                 loss: nan
agent1:                 episode reward: 0.2318,                 loss: 0.1365
Episode: 3521/30000 (11.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.7630s / 40769.3213 s
agent0:                 episode reward: -0.2668,                 loss: nan
agent1:                 episode reward: 0.2668,                 loss: 0.1363
Episode: 3541/30000 (11.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.2315s / 41020.5528 s
agent0:                 episode reward: -0.3217,                 loss: nan
agent1:                 episode reward: 0.3217,                 loss: 0.1368
Episode: 3561/30000 (11.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 237.8393s / 41258.3921 s
agent0:                 episode reward: -0.1577,                 loss: nan
agent1:                 episode reward: 0.1577,                 loss: 0.1351
Episode: 3581/30000 (11.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.6273s / 41503.0194 s
agent0:                 episode reward: -0.3390,                 loss: nan
agent1:                 episode reward: 0.3390,                 loss: 0.1374
Episode: 3601/30000 (12.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 253.9762s / 41756.9956 s
agent0:                 episode reward: -0.0700,                 loss: nan
agent1:                 episode reward: 0.0700,                 loss: 0.1356
Episode: 3621/30000 (12.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.4434s / 42007.4390 s
agent0:                 episode reward: -0.0653,                 loss: nan
agent1:                 episode reward: 0.0653,                 loss: 0.1357
Episode: 3641/30000 (12.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 232.2594s / 42239.6984 s
agent0:                 episode reward: -0.1601,                 loss: nan
agent1:                 episode reward: 0.1601,                 loss: 0.1365
Episode: 3661/30000 (12.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.8686s / 42487.5669 s
agent0:                 episode reward: -0.2089,                 loss: nan
agent1:                 episode reward: 0.2089,                 loss: 0.1364
Episode: 3681/30000 (12.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.9160s / 42730.4829 s
agent0:                 episode reward: 0.1421,                 loss: nan
agent1:                 episode reward: -0.1421,                 loss: 0.1343
Episode: 3701/30000 (12.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.4399s / 42979.9228 s
agent0:                 episode reward: 0.1751,                 loss: nan
agent1:                 episode reward: -0.1751,                 loss: 0.1359
Episode: 3721/30000 (12.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.0090s / 43230.9318 s
agent0:                 episode reward: -0.2374,                 loss: nan
agent1:                 episode reward: 0.2374,                 loss: 0.1366
Episode: 3741/30000 (12.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 255.5562s / 43486.4881 s
agent0:                 episode reward: -0.3678,                 loss: nan
agent1:                 episode reward: 0.3678,                 loss: 0.1364
Episode: 3761/30000 (12.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.4890s / 43736.9771 s
agent0:                 episode reward: -0.2781,                 loss: nan
agent1:                 episode reward: 0.2781,                 loss: 0.1342
Episode: 3781/30000 (12.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.7959s / 43979.7730 s
agent0:                 episode reward: -0.4361,                 loss: nan
agent1:                 episode reward: 0.4361,                 loss: 0.1357
Episode: 3801/30000 (12.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.0123s / 44230.7853 s
agent0:                 episode reward: 0.1928,                 loss: nan
agent1:                 episode reward: -0.1928,                 loss: 0.1360
Episode: 3821/30000 (12.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 254.1121s / 44484.8973 s
agent0:                 episode reward: -0.1419,                 loss: nan
agent1:                 episode reward: 0.1419,                 loss: 0.1357
Episode: 3841/30000 (12.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 255.2293s / 44740.1266 s
agent0:                 episode reward: 0.0150,                 loss: nan
agent1:                 episode reward: -0.0150,                 loss: 0.1367
Episode: 3861/30000 (12.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.3112s / 44990.4378 s
agent0:                 episode reward: -0.2934,                 loss: nan
agent1:                 episode reward: 0.2934,                 loss: 0.1370
Episode: 3881/30000 (12.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.5032s / 45240.9410 s
agent0:                 episode reward: -0.0596,                 loss: nan
agent1:                 episode reward: 0.0596,                 loss: 0.1366
Episode: 3901/30000 (13.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 254.2030s / 45495.1441 s
agent0:                 episode reward: -0.2406,                 loss: nan
agent1:                 episode reward: 0.2406,                 loss: 0.1379
Episode: 3921/30000 (13.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.3951s / 45744.5392 s
agent0:                 episode reward: 0.0110,                 loss: nan
agent1:                 episode reward: -0.0110,                 loss: 0.1374
Episode: 3941/30000 (13.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.3509s / 45993.8901 s
agent0:                 episode reward: 0.0415,                 loss: nan
agent1:                 episode reward: -0.0415,                 loss: 0.1367
Episode: 3961/30000 (13.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.7791s / 46242.6692 s
agent0:                 episode reward: -0.2768,                 loss: nan
agent1:                 episode reward: 0.2768,                 loss: 0.1370
Episode: 3981/30000 (13.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.7170s / 46487.3862 s
agent0:                 episode reward: -0.3694,                 loss: nan
agent1:                 episode reward: 0.3694,                 loss: 0.1374
Episode: 4001/30000 (13.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.6024s / 46730.9886 s
agent0:                 episode reward: -0.1525,                 loss: nan
agent1:                 episode reward: 0.1525,                 loss: 0.1382
Episode: 4021/30000 (13.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.5487s / 46983.5373 s
agent0:                 episode reward: -0.2604,                 loss: nan
agent1:                 episode reward: 0.2604,                 loss: 0.1363
Episode: 4041/30000 (13.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.3102s / 47235.8474 s
agent0:                 episode reward: -0.4924,                 loss: nan
agent1:                 episode reward: 0.4924,                 loss: 0.1382
Episode: 4061/30000 (13.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.3454s / 47487.1928 s
agent0:                 episode reward: -0.4886,                 loss: nan
agent1:                 episode reward: 0.4886,                 loss: 0.1374
Episode: 4081/30000 (13.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.6229s / 47739.8157 s
agent0:                 episode reward: -0.6685,                 loss: nan
agent1:                 episode reward: 0.6685,                 loss: 0.1368
Episode: 4101/30000 (13.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.8747s / 47983.6904 s
agent0:                 episode reward: -0.2850,                 loss: nan
agent1:                 episode reward: 0.2850,                 loss: 0.1369
Episode: 4121/30000 (13.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.4856s / 48234.1760 s
agent0:                 episode reward: -0.0882,                 loss: nan
agent1:                 episode reward: 0.0882,                 loss: 0.1381
Episode: 4141/30000 (13.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.8142s / 48485.9902 s
agent0:                 episode reward: -0.1831,                 loss: nan
agent1:                 episode reward: 0.1831,                 loss: 0.1361
Episode: 4161/30000 (13.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 254.0505s / 48740.0407 s
agent0:                 episode reward: 0.1772,                 loss: nan
agent1:                 episode reward: -0.1772,                 loss: 0.1362
Episode: 4181/30000 (13.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.6285s / 48986.6692 s
agent0:                 episode reward: -0.0549,                 loss: nan
agent1:                 episode reward: 0.0549,                 loss: 0.1368
Episode: 4201/30000 (14.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 253.0527s / 49239.7220 s
agent0:                 episode reward: -0.0668,                 loss: nan
agent1:                 episode reward: 0.0668,                 loss: 0.1360
Episode: 4221/30000 (14.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.1752s / 49485.8972 s
agent0:                 episode reward: -0.3306,                 loss: nan
agent1:                 episode reward: 0.3306,                 loss: 0.1378
Episode: 4241/30000 (14.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 253.3006s / 49739.1978 s
agent0:                 episode reward: -0.3105,                 loss: nan
agent1:                 episode reward: 0.3105,                 loss: 0.1373
Episode: 4261/30000 (14.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 240.6796s / 49979.8774 s
agent0:                 episode reward: -0.2773,                 loss: nan
agent1:                 episode reward: 0.2773,                 loss: 0.1379
Episode: 4281/30000 (14.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 255.7347s / 50235.6121 s
agent0:                 episode reward: 0.3132,                 loss: nan
agent1:                 episode reward: -0.3132,                 loss: 0.1371
Episode: 4301/30000 (14.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.0817s / 50483.6937 s
agent0:                 episode reward: 0.1672,                 loss: nan
agent1:                 episode reward: -0.1672,                 loss: 0.1384
Episode: 4321/30000 (14.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 237.2827s / 50720.9765 s
agent0:                 episode reward: -0.0464,                 loss: nan
agent1:                 episode reward: 0.0464,                 loss: 0.1374
Episode: 4341/30000 (14.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 257.1580s / 50978.1345 s
agent0:                 episode reward: 0.1101,                 loss: nan
agent1:                 episode reward: -0.1101,                 loss: 0.1361
Episode: 4361/30000 (14.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 241.1838s / 51219.3182 s
agent0:                 episode reward: -0.4993,                 loss: nan
agent1:                 episode reward: 0.4993,                 loss: 0.1371
Episode: 4381/30000 (14.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.8733s / 51465.1915 s
agent0:                 episode reward: -0.6301,                 loss: nan
agent1:                 episode reward: 0.6301,                 loss: 0.1383
Episode: 4401/30000 (14.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.8618s / 51711.0533 s
agent0:                 episode reward: 0.3731,                 loss: nan
agent1:                 episode reward: -0.3731,                 loss: 0.1365
Episode: 4421/30000 (14.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.9024s / 51957.9557 s
agent0:                 episode reward: -0.4788,                 loss: nan
agent1:                 episode reward: 0.4788,                 loss: 0.1376
Episode: 4441/30000 (14.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.9697s / 52203.9254 s
agent0:                 episode reward: -0.2351,                 loss: nan
agent1:                 episode reward: 0.2351,                 loss: 0.1361
Episode: 4461/30000 (14.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.0999s / 52454.0253 s
agent0:                 episode reward: -0.6408,                 loss: nan
agent1:                 episode reward: 0.6408,                 loss: 0.1358
Episode: 4481/30000 (14.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 258.2172s / 52712.2426 s
agent0:                 episode reward: -0.0339,                 loss: nan
agent1:                 episode reward: 0.0339,                 loss: 0.1370
Episode: 4501/30000 (15.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.7713s / 52962.0138 s
agent0:                 episode reward: -0.1988,                 loss: nan
agent1:                 episode reward: 0.1988,                 loss: 0.1374
Episode: 4521/30000 (15.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 253.4151s / 53215.4289 s
agent0:                 episode reward: -0.4612,                 loss: nan
agent1:                 episode reward: 0.4612,                 loss: 0.1368
Episode: 4541/30000 (15.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.7963s / 53458.2253 s
agent0:                 episode reward: 0.0790,                 loss: nan
agent1:                 episode reward: -0.0790,                 loss: 0.1384
Episode: 4561/30000 (15.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.6940s / 53707.9193 s
agent0:                 episode reward: -0.1897,                 loss: nan
agent1:                 episode reward: 0.1897,                 loss: 0.1373
Episode: 4581/30000 (15.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.8140s / 53957.7333 s
agent0:                 episode reward: -0.1933,                 loss: nan
agent1:                 episode reward: 0.1933,                 loss: 0.1375
Episode: 4601/30000 (15.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 254.5489s / 54212.2822 s
agent0:                 episode reward: -0.2434,                 loss: nan
agent1:                 episode reward: 0.2434,                 loss: 0.1354
Episode: 4621/30000 (15.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.3096s / 54458.5918 s
agent0:                 episode reward: -0.5792,                 loss: nan
agent1:                 episode reward: 0.5792,                 loss: 0.1349
Episode: 4641/30000 (15.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 239.0164s / 54697.6082 s
agent0:                 episode reward: -0.2322,                 loss: nan
agent1:                 episode reward: 0.2322,                 loss: 0.1371
Episode: 4661/30000 (15.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 241.7584s / 54939.3666 s
agent0:                 episode reward: 0.0624,                 loss: nan
agent1:                 episode reward: -0.0624,                 loss: 0.1363
Episode: 4681/30000 (15.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.7697s / 55186.1364 s
agent0:                 episode reward: 0.0922,                 loss: nan
agent1:                 episode reward: -0.0922,                 loss: 0.1360
Episode: 4701/30000 (15.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.3272s / 55434.4636 s
agent0:                 episode reward: -0.3274,                 loss: nan
agent1:                 episode reward: 0.3274,                 loss: 0.1371
Episode: 4721/30000 (15.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 239.7294s / 55674.1929 s
agent0:                 episode reward: 0.4034,                 loss: nan
agent1:                 episode reward: -0.4034,                 loss: 0.1353
Episode: 4741/30000 (15.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.0770s / 55915.2699 s
agent0:                 episode reward: -0.3593,                 loss: nan
agent1:                 episode reward: 0.3593,                 loss: 0.1369
Episode: 4761/30000 (15.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 261.9339s / 56177.2038 s
agent0:                 episode reward: -0.5583,                 loss: nan
agent1:                 episode reward: 0.5583,                 loss: 0.1354
Episode: 4781/30000 (15.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 256.5534s / 56433.7571 s
agent0:                 episode reward: -0.3804,                 loss: nan
agent1:                 episode reward: 0.3804,                 loss: 0.1361
Episode: 4801/30000 (16.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 253.2914s / 56687.0486 s
agent0:                 episode reward: -0.1570,                 loss: nan
agent1:                 episode reward: 0.1570,                 loss: 0.1351
Episode: 4821/30000 (16.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 240.0833s / 56927.1318 s
agent0:                 episode reward: -0.1722,                 loss: nan
agent1:                 episode reward: 0.1722,                 loss: 0.1347
Episode: 4841/30000 (16.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 258.3237s / 57185.4555 s
agent0:                 episode reward: -0.3506,                 loss: nan
agent1:                 episode reward: 0.3506,                 loss: 0.1349
Episode: 4861/30000 (16.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.0168s / 57436.4723 s
agent0:                 episode reward: -0.0043,                 loss: nan
agent1:                 episode reward: 0.0043,                 loss: 0.1341
Episode: 4881/30000 (16.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.9556s / 57682.4279 s
agent0:                 episode reward: -0.5147,                 loss: nan
agent1:                 episode reward: 0.5147,                 loss: 0.1351
Episode: 4901/30000 (16.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.2221s / 57931.6500 s
agent0:                 episode reward: 0.0370,                 loss: nan
agent1:                 episode reward: -0.0370,                 loss: 0.1344
Episode: 4921/30000 (16.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 253.8701s / 58185.5201 s
agent0:                 episode reward: -0.2391,                 loss: nan
agent1:                 episode reward: 0.2391,                 loss: 0.1340
Episode: 4941/30000 (16.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.6938s / 58428.2139 s
agent0:                 episode reward: -0.3760,                 loss: nan
agent1:                 episode reward: 0.3760,                 loss: 0.1343
Episode: 4961/30000 (16.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.4496s / 58675.6635 s
agent0:                 episode reward: -0.0644,                 loss: nan
agent1:                 episode reward: 0.0644,                 loss: 0.1337
Episode: 4981/30000 (16.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 240.6207s / 58916.2843 s
agent0:                 episode reward: -0.2124,                 loss: nan
agent1:                 episode reward: 0.2124,                 loss: 0.1344
Episode: 5001/30000 (16.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.6687s / 59164.9530 s
agent0:                 episode reward: 0.0577,                 loss: nan
agent1:                 episode reward: -0.0577,                 loss: 0.1330
Episode: 5021/30000 (16.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 253.1778s / 59418.1307 s
agent0:                 episode reward: 0.1356,                 loss: nan
agent1:                 episode reward: -0.1356,                 loss: 0.1333
Episode: 5041/30000 (16.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.7832s / 59664.9140 s
agent0:                 episode reward: -0.1195,                 loss: nan
agent1:                 episode reward: 0.1195,                 loss: 0.1342
Episode: 5061/30000 (16.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.2687s / 59916.1827 s
agent0:                 episode reward: 0.0654,                 loss: nan
agent1:                 episode reward: -0.0654,                 loss: 0.1345
Episode: 5081/30000 (16.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.4813s / 60167.6639 s
agent0:                 episode reward: -0.4805,                 loss: nan
agent1:                 episode reward: 0.4805,                 loss: 0.1342
Episode: 5101/30000 (17.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 253.8658s / 60421.5297 s
agent0:                 episode reward: -0.3794,                 loss: nan
agent1:                 episode reward: 0.3794,                 loss: 0.1347
Episode: 5121/30000 (17.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.3066s / 60667.8362 s
agent0:                 episode reward: -0.4766,                 loss: nan
agent1:                 episode reward: 0.4766,                 loss: 0.1353
Episode: 5141/30000 (17.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.5610s / 60915.3972 s
agent0:                 episode reward: -0.1021,                 loss: nan
agent1:                 episode reward: 0.1021,                 loss: 0.1347
Episode: 5161/30000 (17.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.3208s / 61163.7180 s
agent0:                 episode reward: -0.3982,                 loss: nan
agent1:                 episode reward: 0.3982,                 loss: 0.1348
Episode: 5181/30000 (17.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.7819s / 61410.4999 s
agent0:                 episode reward: -0.2156,                 loss: nan
agent1:                 episode reward: 0.2156,                 loss: 0.1357
Episode: 5201/30000 (17.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.3086s / 61656.8084 s
agent0:                 episode reward: -0.1042,                 loss: nan
agent1:                 episode reward: 0.1042,                 loss: 0.1337
Episode: 5221/30000 (17.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.8574s / 61906.6658 s
agent0:                 episode reward: -0.2314,                 loss: nan
agent1:                 episode reward: 0.2314,                 loss: 0.1341
Episode: 5241/30000 (17.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.1237s / 62157.7896 s
agent0:                 episode reward: -0.2631,                 loss: nan
agent1:                 episode reward: 0.2631,                 loss: 0.1340
Episode: 5261/30000 (17.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 257.4778s / 62415.2674 s
agent0:                 episode reward: -0.5431,                 loss: nan
agent1:                 episode reward: 0.5431,                 loss: 0.1353
Episode: 5281/30000 (17.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.2909s / 62666.5583 s
agent0:                 episode reward: -0.2861,                 loss: nan
agent1:                 episode reward: 0.2861,                 loss: 0.1353
Episode: 5301/30000 (17.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.9904s / 62918.5487 s
agent0:                 episode reward: -0.1908,                 loss: nan
agent1:                 episode reward: 0.1908,                 loss: 0.1356
Episode: 5321/30000 (17.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.5281s / 63165.0767 s
agent0:                 episode reward: -0.2886,                 loss: nan
agent1:                 episode reward: 0.2886,                 loss: 0.1359
Episode: 5341/30000 (17.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.9828s / 63418.0595 s
agent0:                 episode reward: -0.0563,                 loss: nan
agent1:                 episode reward: 0.0563,                 loss: 0.1354
Episode: 5361/30000 (17.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.8281s / 63663.8876 s
agent0:                 episode reward: -0.6137,                 loss: nan
agent1:                 episode reward: 0.6137,                 loss: 0.1352
Episode: 5381/30000 (17.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.5047s / 63913.3923 s
agent0:                 episode reward: -0.1224,                 loss: nan
agent1:                 episode reward: 0.1224,                 loss: 0.1360
Episode: 5401/30000 (18.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.0815s / 64157.4738 s
agent0:                 episode reward: -0.5010,                 loss: nan
agent1:                 episode reward: 0.5010,                 loss: 0.1345
Episode: 5421/30000 (18.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 255.3987s / 64412.8726 s
agent0:                 episode reward: -0.4705,                 loss: nan
agent1:                 episode reward: 0.4705,                 loss: 0.1361
Episode: 5441/30000 (18.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.3923s / 64665.2648 s
agent0:                 episode reward: -0.1369,                 loss: nan
agent1:                 episode reward: 0.1369,                 loss: 0.1348
Episode: 5461/30000 (18.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.7297s / 64912.9945 s
agent0:                 episode reward: -0.5882,                 loss: nan
agent1:                 episode reward: 0.5882,                 loss: 0.1355
Episode: 5481/30000 (18.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 239.2694s / 65152.2639 s
agent0:                 episode reward: -0.1456,                 loss: nan
agent1:                 episode reward: 0.1456,                 loss: 0.1350
Episode: 5501/30000 (18.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.7702s / 65399.0341 s
agent0:                 episode reward: -0.3829,                 loss: nan
agent1:                 episode reward: 0.3829,                 loss: 0.1351
Episode: 5521/30000 (18.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.6684s / 65641.7025 s
agent0:                 episode reward: -0.4932,                 loss: nan
agent1:                 episode reward: 0.4932,                 loss: 0.1346
Episode: 5541/30000 (18.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.7414s / 65890.4439 s
agent0:                 episode reward: 0.0519,                 loss: nan
agent1:                 episode reward: -0.0519,                 loss: 0.1338
Episode: 5561/30000 (18.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 257.5919s / 66148.0358 s
agent0:                 episode reward: 0.0130,                 loss: nan
agent1:                 episode reward: -0.0130,                 loss: 0.1361
Episode: 5581/30000 (18.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.2674s / 66394.3033 s
agent0:                 episode reward: -0.4535,                 loss: nan
agent1:                 episode reward: 0.4535,                 loss: 0.1351
Episode: 5601/30000 (18.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.0954s / 66641.3987 s
agent0:                 episode reward: 0.1945,                 loss: nan
agent1:                 episode reward: -0.1945,                 loss: 0.1356
Episode: 5621/30000 (18.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.1474s / 66883.5461 s
agent0:                 episode reward: -0.0372,                 loss: nan
agent1:                 episode reward: 0.0372,                 loss: 0.1359
Episode: 5641/30000 (18.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.7541s / 67130.3002 s
agent0:                 episode reward: -0.3116,                 loss: nan
agent1:                 episode reward: 0.3116,                 loss: 0.1347
Episode: 5661/30000 (18.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 254.8646s / 67385.1648 s
agent0:                 episode reward: -0.3564,                 loss: nan
agent1:                 episode reward: 0.3564,                 loss: 0.1361
Episode: 5681/30000 (18.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 253.7731s / 67638.9379 s
agent0:                 episode reward: -0.2550,                 loss: nan
agent1:                 episode reward: 0.2550,                 loss: 0.1355
Episode: 5701/30000 (19.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.5713s / 67886.5092 s
agent0:                 episode reward: -0.1227,                 loss: nan
agent1:                 episode reward: 0.1227,                 loss: 0.1345
Episode: 5721/30000 (19.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.5767s / 68136.0859 s
agent0:                 episode reward: -0.3016,                 loss: nan
agent1:                 episode reward: 0.3016,                 loss: 0.1362
Episode: 5741/30000 (19.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.3790s / 68387.4650 s
agent0:                 episode reward: -0.0437,                 loss: nan
agent1:                 episode reward: 0.0437,                 loss: 0.1356
Episode: 5761/30000 (19.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.2797s / 68639.7446 s
agent0:                 episode reward: -0.2571,                 loss: nan
agent1:                 episode reward: 0.2571,                 loss: 0.1358
Episode: 5781/30000 (19.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 257.2545s / 68896.9991 s
agent0:                 episode reward: -0.1342,                 loss: nan
agent1:                 episode reward: 0.1342,                 loss: 0.1369
Episode: 5801/30000 (19.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 257.8301s / 69154.8292 s
agent0:                 episode reward: -0.0778,                 loss: nan
agent1:                 episode reward: 0.0778,                 loss: 0.1352
Episode: 5821/30000 (19.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.0912s / 69404.9204 s
agent0:                 episode reward: -0.0662,                 loss: nan
agent1:                 episode reward: 0.0662,                 loss: 0.1351
Episode: 5841/30000 (19.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 255.4093s / 69660.3298 s
agent0:                 episode reward: -0.4268,                 loss: nan
agent1:                 episode reward: 0.4268,                 loss: 0.1350
Episode: 5861/30000 (19.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.5253s / 69911.8550 s
agent0:                 episode reward: -0.5721,                 loss: nan
agent1:                 episode reward: 0.5721,                 loss: 0.1353
Episode: 5881/30000 (19.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 253.5350s / 70165.3900 s
agent0:                 episode reward: -0.0711,                 loss: nan
agent1:                 episode reward: 0.0711,                 loss: 0.1361
Episode: 5901/30000 (19.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.8566s / 70418.2466 s
agent0:                 episode reward: -0.1690,                 loss: nan
agent1:                 episode reward: 0.1690,                 loss: 0.1403
Episode: 5921/30000 (19.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.6744s / 70665.9211 s
agent0:                 episode reward: -0.0809,                 loss: nan
agent1:                 episode reward: 0.0809,                 loss: 0.1389
Episode: 5941/30000 (19.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.7393s / 70908.6604 s
agent0:                 episode reward: -0.3871,                 loss: nan
agent1:                 episode reward: 0.3871,                 loss: 0.1382
Episode: 5961/30000 (19.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.3962s / 71158.0566 s
agent0:                 episode reward: -0.4175,                 loss: nan
agent1:                 episode reward: 0.4175,                 loss: 0.1402
Episode: 5981/30000 (19.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.4788s / 71407.5354 s
agent0:                 episode reward: -0.0958,                 loss: nan
agent1:                 episode reward: 0.0958,                 loss: 0.1387
Episode: 6001/30000 (20.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 254.6667s / 71662.2021 s
agent0:                 episode reward: -0.1930,                 loss: nan
agent1:                 episode reward: 0.1930,                 loss: 0.1382
Episode: 6021/30000 (20.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.0669s / 71908.2691 s
agent0:                 episode reward: -0.4110,                 loss: nan
agent1:                 episode reward: 0.4110,                 loss: 0.1382
Episode: 6041/30000 (20.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.0101s / 72159.2792 s
agent0:                 episode reward: -0.9224,                 loss: nan
agent1:                 episode reward: 0.9224,                 loss: 0.1389
Episode: 6061/30000 (20.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.8223s / 72412.1015 s
agent0:                 episode reward: -0.5252,                 loss: nan
agent1:                 episode reward: 0.5252,                 loss: 0.1384
Episode: 6081/30000 (20.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.4083s / 72657.5098 s
agent0:                 episode reward: -0.0532,                 loss: nan
agent1:                 episode reward: 0.0532,                 loss: 0.1393
Episode: 6101/30000 (20.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.6417s / 72904.1515 s
agent0:                 episode reward: 0.0926,                 loss: nan
agent1:                 episode reward: -0.0926,                 loss: 0.1396
Episode: 6121/30000 (20.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.5220s / 73153.6735 s
agent0:                 episode reward: -0.3690,                 loss: nan
agent1:                 episode reward: 0.3690,                 loss: 0.1397
Episode: 6141/30000 (20.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.6881s / 73403.3616 s
agent0:                 episode reward: -0.4030,                 loss: nan
agent1:                 episode reward: 0.4030,                 loss: 0.1381
Episode: 6161/30000 (20.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.7055s / 73650.0671 s
agent0:                 episode reward: 0.0865,                 loss: nan
agent1:                 episode reward: -0.0865,                 loss: 0.1402
Episode: 6181/30000 (20.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.3363s / 73897.4034 s
agent0:                 episode reward: -0.6381,                 loss: nan
agent1:                 episode reward: 0.6381,                 loss: 0.1389
Episode: 6201/30000 (20.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.2665s / 74145.6699 s
agent0:                 episode reward: -0.4473,                 loss: nan
agent1:                 episode reward: 0.4473,                 loss: 0.1407
Episode: 6221/30000 (20.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.7512s / 74396.4210 s
agent0:                 episode reward: -0.3412,                 loss: nan
agent1:                 episode reward: 0.3412,                 loss: 0.1382
Episode: 6241/30000 (20.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 258.1682s / 74654.5892 s
agent0:                 episode reward: -0.3219,                 loss: nan
agent1:                 episode reward: 0.3219,                 loss: 0.1367
Episode: 6261/30000 (20.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.1354s / 74906.7246 s
agent0:                 episode reward: -0.3463,                 loss: nan
agent1:                 episode reward: 0.3463,                 loss: 0.1357
Episode: 6281/30000 (20.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 259.9201s / 75166.6447 s
agent0:                 episode reward: -0.6170,                 loss: nan
agent1:                 episode reward: 0.6170,                 loss: 0.1346
Episode: 6301/30000 (21.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.5809s / 75419.2256 s
agent0:                 episode reward: 0.0446,                 loss: nan
agent1:                 episode reward: -0.0446,                 loss: 0.1334
Episode: 6321/30000 (21.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.2827s / 75671.5083 s
agent0:                 episode reward: -0.6168,                 loss: nan
agent1:                 episode reward: 0.6168,                 loss: 0.1352
Episode: 6341/30000 (21.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.9678s / 75916.4760 s
agent0:                 episode reward: -0.2272,                 loss: nan
agent1:                 episode reward: 0.2272,                 loss: 0.1349
Episode: 6361/30000 (21.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.9252s / 76163.4013 s
agent0:                 episode reward: -0.2199,                 loss: nan
agent1:                 episode reward: 0.2199,                 loss: 0.1349
Episode: 6381/30000 (21.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.9015s / 76407.3028 s
agent0:                 episode reward: -0.5656,                 loss: nan
agent1:                 episode reward: 0.5656,                 loss: 0.1345
Episode: 6401/30000 (21.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.0849s / 76659.3877 s
agent0:                 episode reward: -0.3910,                 loss: nan
agent1:                 episode reward: 0.3910,                 loss: 0.1352
Episode: 6421/30000 (21.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.8351s / 76910.2228 s
agent0:                 episode reward: -0.3924,                 loss: nan
agent1:                 episode reward: 0.3924,                 loss: 0.1359
Episode: 6441/30000 (21.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.2351s / 77155.4578 s
agent0:                 episode reward: -0.6393,                 loss: nan
agent1:                 episode reward: 0.6393,                 loss: 0.1352
Episode: 6461/30000 (21.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 257.8709s / 77413.3287 s
agent0:                 episode reward: -0.1143,                 loss: nan
agent1:                 episode reward: 0.1143,                 loss: 0.1355
Episode: 6481/30000 (21.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.6994s / 77665.0281 s
agent0:                 episode reward: -0.2737,                 loss: nan
agent1:                 episode reward: 0.2737,                 loss: 0.1344
Episode: 6501/30000 (21.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.8169s / 77913.8449 s
agent0:                 episode reward: -0.0513,                 loss: nan
agent1:                 episode reward: 0.0513,                 loss: 0.1351
Episode: 6521/30000 (21.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.8613s / 78164.7063 s
agent0:                 episode reward: -0.5536,                 loss: nan
agent1:                 episode reward: 0.5536,                 loss: 0.1344
Episode: 6541/30000 (21.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.8639s / 78417.5702 s
agent0:                 episode reward: -0.5298,                 loss: nan
agent1:                 episode reward: 0.5298,                 loss: 0.1350
Episode: 6561/30000 (21.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.1124s / 78658.6826 s
agent0:                 episode reward: -0.1652,                 loss: nan
agent1:                 episode reward: 0.1652,                 loss: 0.1344
Episode: 6581/30000 (21.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.2290s / 78904.9115 s
agent0:                 episode reward: -0.3030,                 loss: nan
agent1:                 episode reward: 0.3030,                 loss: 0.1378
Episode: 6601/30000 (22.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.5649s / 79155.4764 s
agent0:                 episode reward: -0.7144,                 loss: nan
agent1:                 episode reward: 0.7144,                 loss: 0.1355
Episode: 6621/30000 (22.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.6117s / 79404.0881 s
agent0:                 episode reward: -0.2536,                 loss: nan
agent1:                 episode reward: 0.2536,                 loss: 0.1360
Episode: 6641/30000 (22.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.8430s / 79649.9311 s
agent0:                 episode reward: -0.3456,                 loss: nan
agent1:                 episode reward: 0.3456,                 loss: 0.1353
Episode: 6661/30000 (22.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.1969s / 79893.1280 s
agent0:                 episode reward: -0.5179,                 loss: nan
agent1:                 episode reward: 0.5179,                 loss: 0.1358
Episode: 6681/30000 (22.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.5812s / 80139.7092 s
agent0:                 episode reward: -0.4601,                 loss: nan
agent1:                 episode reward: 0.4601,                 loss: 0.1364
Episode: 6701/30000 (22.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.1944s / 80389.9036 s
agent0:                 episode reward: 0.1435,                 loss: nan
agent1:                 episode reward: -0.1435,                 loss: 0.1369
Episode: 6721/30000 (22.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.8926s / 80633.7962 s
agent0:                 episode reward: -0.1836,                 loss: nan
agent1:                 episode reward: 0.1836,                 loss: 0.1357
Episode: 6741/30000 (22.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.2812s / 80880.0774 s
agent0:                 episode reward: -0.3169,                 loss: nan
agent1:                 episode reward: 0.3169,                 loss: 0.1369
Episode: 6761/30000 (22.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.0850s / 81129.1624 s
agent0:                 episode reward: -0.3247,                 loss: nan
agent1:                 episode reward: 0.3247,                 loss: 0.1364
Episode: 6781/30000 (22.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 261.0024s / 81390.1648 s
agent0:                 episode reward: -0.1601,                 loss: nan
agent1:                 episode reward: 0.1601,                 loss: 0.1369
Episode: 6801/30000 (22.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.8355s / 81636.0002 s
agent0:                 episode reward: -0.1883,                 loss: nan
agent1:                 episode reward: 0.1883,                 loss: 0.1364
Episode: 6821/30000 (22.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.7092s / 81882.7094 s
agent0:                 episode reward: -0.5132,                 loss: nan
agent1:                 episode reward: 0.5132,                 loss: 0.1362
Episode: 6841/30000 (22.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 256.3747s / 82139.0841 s
agent0:                 episode reward: -0.5940,                 loss: nan
agent1:                 episode reward: 0.5940,                 loss: 0.1366
Episode: 6861/30000 (22.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.7811s / 82384.8652 s
agent0:                 episode reward: -0.7361,                 loss: nan
agent1:                 episode reward: 0.7361,                 loss: 0.1357
Episode: 6881/30000 (22.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.1478s / 82627.0129 s
agent0:                 episode reward: -0.3824,                 loss: nan
agent1:                 episode reward: 0.3824,                 loss: 0.1362
Episode: 6901/30000 (23.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.7767s / 82875.7896 s
agent0:                 episode reward: -0.0312,                 loss: nan
agent1:                 episode reward: 0.0312,                 loss: 0.1346
Episode: 6921/30000 (23.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.0492s / 83124.8388 s
agent0:                 episode reward: -0.7167,                 loss: nan
agent1:                 episode reward: 0.7167,                 loss: 0.1344
Episode: 6941/30000 (23.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.0980s / 83376.9368 s
agent0:                 episode reward: -0.0098,                 loss: nan
agent1:                 episode reward: 0.0098,                 loss: 0.1336
Episode: 6961/30000 (23.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 254.1899s / 83631.1266 s
agent0:                 episode reward: -0.6278,                 loss: nan
agent1:                 episode reward: 0.6278,                 loss: 0.1352
Episode: 6981/30000 (23.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 259.7958s / 83890.9224 s
agent0:                 episode reward: -0.1707,                 loss: nan
agent1:                 episode reward: 0.1707,                 loss: 0.1338
Episode: 7001/30000 (23.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.2045s / 84136.1269 s
agent0:                 episode reward: -0.4672,                 loss: nan
agent1:                 episode reward: 0.4672,                 loss: 0.1347
Episode: 7021/30000 (23.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.3853s / 84383.5122 s
agent0:                 episode reward: -0.2513,                 loss: nan
agent1:                 episode reward: 0.2513,                 loss: 0.1336
Episode: 7041/30000 (23.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 255.0708s / 84638.5831 s
agent0:                 episode reward: -0.1272,                 loss: nan
agent1:                 episode reward: 0.1272,                 loss: 0.1347
Episode: 7061/30000 (23.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.8645s / 84884.4475 s
agent0:                 episode reward: -0.5028,                 loss: nan
agent1:                 episode reward: 0.5028,                 loss: 0.1333
Episode: 7081/30000 (23.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.6871s / 85135.1346 s
agent0:                 episode reward: -0.1102,                 loss: nan
agent1:                 episode reward: 0.1102,                 loss: 0.1342
Episode: 7101/30000 (23.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.8488s / 85387.9834 s
agent0:                 episode reward: -0.3054,                 loss: nan
agent1:                 episode reward: 0.3054,                 loss: 0.1363
Episode: 7121/30000 (23.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.8568s / 85633.8402 s
agent0:                 episode reward: -0.3721,                 loss: nan
agent1:                 episode reward: 0.3721,                 loss: 0.1343
Episode: 7141/30000 (23.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 253.6254s / 85887.4656 s
agent0:                 episode reward: -0.4221,                 loss: nan
agent1:                 episode reward: 0.4221,                 loss: 0.1341
Episode: 7161/30000 (23.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.5717s / 86134.0373 s
agent0:                 episode reward: -0.8709,                 loss: nan
agent1:                 episode reward: 0.8709,                 loss: 0.1361
Episode: 7181/30000 (23.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.8467s / 86384.8840 s
agent0:                 episode reward: -0.2695,                 loss: nan
agent1:                 episode reward: 0.2695,                 loss: 0.1346
Episode: 7201/30000 (24.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.0267s / 86635.9107 s
agent0:                 episode reward: -0.2553,                 loss: nan
agent1:                 episode reward: 0.2553,                 loss: 0.1344
Episode: 7221/30000 (24.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 253.2708s / 86889.1815 s
agent0:                 episode reward: -0.3453,                 loss: nan
agent1:                 episode reward: 0.3453,                 loss: 0.1347
Episode: 7241/30000 (24.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.3469s / 87138.5284 s
agent0:                 episode reward: -0.3844,                 loss: nan
agent1:                 episode reward: 0.3844,                 loss: 0.1328
Episode: 7261/30000 (24.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.9059s / 87385.4343 s
agent0:                 episode reward: 0.1915,                 loss: nan
agent1:                 episode reward: -0.1915,                 loss: 0.1328
Episode: 7281/30000 (24.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.2197s / 87633.6541 s
agent0:                 episode reward: -0.4720,                 loss: nan
agent1:                 episode reward: 0.4720,                 loss: 0.1326
Episode: 7301/30000 (24.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 253.7863s / 87887.4403 s
agent0:                 episode reward: -0.6201,                 loss: nan
agent1:                 episode reward: 0.6201,                 loss: 0.1312
Episode: 7321/30000 (24.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 253.7231s / 88141.1634 s
agent0:                 episode reward: -0.2716,                 loss: nan
agent1:                 episode reward: 0.2716,                 loss: 0.1342
Episode: 7341/30000 (24.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.2940s / 88393.4574 s
agent0:                 episode reward: -0.1486,                 loss: nan
agent1:                 episode reward: 0.1486,                 loss: 0.1337
Episode: 7361/30000 (24.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 254.3449s / 88647.8023 s
agent0:                 episode reward: -0.5483,                 loss: nan
agent1:                 episode reward: 0.5483,                 loss: 0.1331
Episode: 7381/30000 (24.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.6336s / 88891.4360 s
agent0:                 episode reward: -0.4537,                 loss: nan
agent1:                 episode reward: 0.4537,                 loss: 0.1334
Episode: 7401/30000 (24.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 254.2793s / 89145.7153 s
agent0:                 episode reward: -0.7568,                 loss: nan
agent1:                 episode reward: 0.7568,                 loss: 0.1328
Episode: 7421/30000 (24.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 255.7142s / 89401.4295 s
agent0:                 episode reward: -0.3041,                 loss: nan
agent1:                 episode reward: 0.3041,                 loss: 0.1328
Episode: 7441/30000 (24.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 256.3801s / 89657.8096 s
agent0:                 episode reward: -0.5986,                 loss: nan
agent1:                 episode reward: 0.5986,                 loss: 0.1331
Episode: 7461/30000 (24.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.2995s / 89909.1090 s
agent0:                 episode reward: -0.3274,                 loss: nan
agent1:                 episode reward: 0.3274,                 loss: 0.1331
Episode: 7481/30000 (24.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.1579s / 90157.2670 s