pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
boxing_v1 pettingzoo
Load boxing_v1 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
random seed: 95
<mars.env.wrappers.mars_wrappers.Dict2TupleWrapper object at 0x7f127bdc16a0>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  ./data/model/20220429_0152/pettingzoo_boxing_v1_nash_dqn_exploiter/1_0
Arguments:  {'env_name': 'boxing_v1', 'env_type': 'pettingzoo', 'num_envs': 1, 'ram': True, 'seed': 'random', 'algorithm': 'NashDQNExploiter', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 100000, 'exploiter_update_itr': 3}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': './data/model/20220429_0152/pettingzoo_boxing_v1_nash_dqn_exploiter/1_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn_exploiter', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}, 'against_baseline': False, 'idx_exploited_model': 0}
Save models to : /home/zihan/research/MARS/data/model/20220429_0152_exploit_first_/pettingzoo_boxing_v1_nash_dqn_exploiter. 
 Save logs to: /home/zihan/research/MARS/data/log/20220429_0152_exploit_first_/pettingzoo_boxing_v1_nash_dqn_exploiter.
Episode: 1/10000 (0.0100%),                 avg. length: 233.0,                last time consumption/overall running time: 10.4187s / 10.4187 s
first_0:                 episode reward: 100.0000,                 loss: nan
second_0:                 episode reward: -100.0000,                 loss: 0.3833
Episode: 21/10000 (0.2100%),                 avg. length: 258.35,                last time consumption/overall running time: 82.7921s / 93.2107 s
first_0:                 episode reward: 97.0000,                 loss: nan
second_0:                 episode reward: -97.0000,                 loss: 0.0910
Episode: 41/10000 (0.4100%),                 avg. length: 266.6,                last time consumption/overall running time: 86.2777s / 179.4884 s
first_0:                 episode reward: 88.1500,                 loss: nan
second_0:                 episode reward: -88.1500,                 loss: 0.0456
Episode: 61/10000 (0.6100%),                 avg. length: 267.6,                last time consumption/overall running time: 87.8156s / 267.3041 s
first_0:                 episode reward: 82.3000,                 loss: nan
second_0:                 episode reward: -82.3000,                 loss: 0.0371
Episode: 81/10000 (0.8100%),                 avg. length: 266.4,                last time consumption/overall running time: 88.1742s / 355.4783 s
first_0:                 episode reward: 91.2000,                 loss: nan
second_0:                 episode reward: -91.2000,                 loss: 0.0342
Episode: 101/10000 (1.0100%),                 avg. length: 261.55,                last time consumption/overall running time: 87.3382s / 442.8165 s
first_0:                 episode reward: 95.2000,                 loss: nan
second_0:                 episode reward: -95.2000,                 loss: 0.0333
Episode: 121/10000 (1.2100%),                 avg. length: 269.05,                last time consumption/overall running time: 90.3345s / 533.1510 s
first_0:                 episode reward: 90.1000,                 loss: nan
second_0:                 episode reward: -90.1000,                 loss: 0.0325
Episode: 141/10000 (1.4100%),                 avg. length: 275.8,                last time consumption/overall running time: 92.6531s / 625.8041 s
first_0:                 episode reward: 91.8000,                 loss: nan
second_0:                 episode reward: -91.8000,                 loss: 0.0306
Episode: 161/10000 (1.6100%),                 avg. length: 268.8,                last time consumption/overall running time: 91.4724s / 717.2765 s
first_0:                 episode reward: 74.2000,                 loss: nan
second_0:                 episode reward: -74.2000,                 loss: 0.0287
Episode: 181/10000 (1.8100%),                 avg. length: 290.85,                last time consumption/overall running time: 99.4389s / 816.7155 s
first_0:                 episode reward: 65.2500,                 loss: nan
second_0:                 episode reward: -65.2500,                 loss: 0.0269
Episode: 201/10000 (2.0100%),                 avg. length: 278.1,                last time consumption/overall running time: 95.4696s / 912.1851 s
first_0:                 episode reward: 73.8500,                 loss: nan
second_0:                 episode reward: -73.8500,                 loss: 0.0246
Episode: 221/10000 (2.2100%),                 avg. length: 293.6,                last time consumption/overall running time: 101.4956s / 1013.6807 s
first_0:                 episode reward: 59.5000,                 loss: nan
second_0:                 episode reward: -59.5000,                 loss: 0.0232
Episode: 241/10000 (2.4100%),                 avg. length: 266.15,                last time consumption/overall running time: 91.8900s / 1105.5706 s
first_0:                 episode reward: 83.5000,                 loss: nan
second_0:                 episode reward: -83.5000,                 loss: 0.0227
Episode: 261/10000 (2.6100%),                 avg. length: 286.3,                last time consumption/overall running time: 98.7227s / 1204.2933 s
first_0:                 episode reward: 51.9000,                 loss: nan
second_0:                 episode reward: -51.9000,                 loss: 0.0216
Episode: 281/10000 (2.8100%),                 avg. length: 282.85,                last time consumption/overall running time: 98.9889s / 1303.2822 s
first_0:                 episode reward: 66.7000,                 loss: nan
second_0:                 episode reward: -66.7000,                 loss: 0.0212
Episode: 301/10000 (3.0100%),                 avg. length: 281.55,                last time consumption/overall running time: 99.1191s / 1402.4012 s
first_0:                 episode reward: 75.4000,                 loss: nan
second_0:                 episode reward: -75.4000,                 loss: 0.0199
Episode: 321/10000 (3.2100%),                 avg. length: 280.65,                last time consumption/overall running time: 99.5047s / 1501.9059 s
first_0:                 episode reward: 56.5000,                 loss: nan
second_0:                 episode reward: -56.5000,                 loss: 0.0197
Episode: 341/10000 (3.4100%),                 avg. length: 295.85,                last time consumption/overall running time: 104.7728s / 1606.6787 s
first_0:                 episode reward: 31.0000,                 loss: nan
second_0:                 episode reward: -31.0000,                 loss: 0.0191
Episode: 361/10000 (3.6100%),                 avg. length: 292.55,                last time consumption/overall running time: 104.9075s / 1711.5862 s
first_0:                 episode reward: 44.3500,                 loss: nan
second_0:                 episode reward: -44.3500,                 loss: 0.0184
Episode: 381/10000 (3.8100%),                 avg. length: 285.7,                last time consumption/overall running time: 103.2352s / 1814.8213 s
first_0:                 episode reward: 51.9000,                 loss: nan
second_0:                 episode reward: -51.9000,                 loss: 0.0181
Episode: 401/10000 (4.0100%),                 avg. length: 275.9,                last time consumption/overall running time: 99.7668s / 1914.5881 s
first_0:                 episode reward: 62.5500,                 loss: nan
second_0:                 episode reward: -62.5500,                 loss: 0.0179
Episode: 421/10000 (4.2100%),                 avg. length: 283.5,                last time consumption/overall running time: 102.3271s / 2016.9152 s
first_0:                 episode reward: 46.4500,                 loss: nan
second_0:                 episode reward: -46.4500,                 loss: 0.0169
Episode: 441/10000 (4.4100%),                 avg. length: 293.1,                last time consumption/overall running time: 105.8782s / 2122.7934 s
first_0:                 episode reward: 25.0500,                 loss: nan
second_0:                 episode reward: -25.0500,                 loss: 0.0172
Episode: 461/10000 (4.6100%),                 avg. length: 291.65,                last time consumption/overall running time: 106.0166s / 2228.8101 s
first_0:                 episode reward: 30.4500,                 loss: nan
second_0:                 episode reward: -30.4500,                 loss: 0.0162
Episode: 481/10000 (4.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 108.3503s / 2337.1603 s
first_0:                 episode reward: 8.6000,                 loss: nan
second_0:                 episode reward: -8.6000,                 loss: 0.0160
Episode: 501/10000 (5.0100%),                 avg. length: 295.9,                last time consumption/overall running time: 107.5684s / 2444.7287 s
first_0:                 episode reward: 22.4500,                 loss: nan
second_0:                 episode reward: -22.4500,                 loss: 0.0157
Episode: 521/10000 (5.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 108.6396s / 2553.3684 s
first_0:                 episode reward: 6.1500,                 loss: nan
second_0:                 episode reward: -6.1500,                 loss: 0.0155
Episode: 541/10000 (5.4100%),                 avg. length: 292.75,                last time consumption/overall running time: 106.5477s / 2659.9160 s
first_0:                 episode reward: 24.3000,                 loss: nan
second_0:                 episode reward: -24.3000,                 loss: 0.0151
Episode: 561/10000 (5.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 109.1842s / 2769.1003 s
first_0:                 episode reward: 13.9000,                 loss: nan
second_0:                 episode reward: -13.9000,                 loss: 0.0148
Episode: 581/10000 (5.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 109.5002s / 2878.6004 s
first_0:                 episode reward: 7.4500,                 loss: nan
second_0:                 episode reward: -7.4500,                 loss: 0.0149
Episode: 601/10000 (6.0100%),                 avg. length: 291.75,                last time consumption/overall running time: 106.7387s / 2985.3391 s
first_0:                 episode reward: 17.3000,                 loss: nan
second_0:                 episode reward: -17.3000,                 loss: 0.0151
Episode: 621/10000 (6.2100%),                 avg. length: 295.5,                last time consumption/overall running time: 107.8160s / 3093.1551 s
first_0:                 episode reward: 29.1000,                 loss: nan
second_0:                 episode reward: -29.1000,                 loss: 0.0150
Episode: 641/10000 (6.4100%),                 avg. length: 294.15,                last time consumption/overall running time: 107.1879s / 3200.3430 s
first_0:                 episode reward: 13.1500,                 loss: nan
second_0:                 episode reward: -13.1500,                 loss: 0.0151
Episode: 661/10000 (6.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 109.3328s / 3309.6758 s
first_0:                 episode reward: 15.6500,                 loss: nan
second_0:                 episode reward: -15.6500,                 loss: 0.0161
Episode: 681/10000 (6.8100%),                 avg. length: 295.65,                last time consumption/overall running time: 108.1443s / 3417.8201 s
first_0:                 episode reward: 11.9000,                 loss: nan
second_0:                 episode reward: -11.9000,                 loss: 0.0162
Episode: 701/10000 (7.0100%),                 avg. length: 297.55,                last time consumption/overall running time: 108.9621s / 3526.7821 s
first_0:                 episode reward: 18.2000,                 loss: nan
second_0:                 episode reward: -18.2000,                 loss: 0.0167
Episode: 721/10000 (7.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 110.0034s / 3636.7855 s
first_0:                 episode reward: 3.8500,                 loss: nan
second_0:                 episode reward: -3.8500,                 loss: 0.0168
Episode: 741/10000 (7.4100%),                 avg. length: 296.35,                last time consumption/overall running time: 108.6974s / 3745.4829 s
first_0:                 episode reward: 11.6000,                 loss: nan
second_0:                 episode reward: -11.6000,                 loss: 0.0178
Episode: 761/10000 (7.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 109.8725s / 3855.3554 s
first_0:                 episode reward: 11.1500,                 loss: nan
second_0:                 episode reward: -11.1500,                 loss: 0.0188
Episode: 781/10000 (7.8100%),                 avg. length: 294.35,                last time consumption/overall running time: 107.8393s / 3963.1947 s
first_0:                 episode reward: 13.5500,                 loss: nan
second_0:                 episode reward: -13.5500,                 loss: 0.0197
Episode: 801/10000 (8.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 109.7608s / 4072.9555 s
first_0:                 episode reward: 10.3000,                 loss: nan
second_0:                 episode reward: -10.3000,                 loss: 0.0190
Episode: 821/10000 (8.2100%),                 avg. length: 295.2,                last time consumption/overall running time: 108.6790s / 4181.6345 s
first_0:                 episode reward: 13.4000,                 loss: nan
second_0:                 episode reward: -13.4000,                 loss: 0.0195
Episode: 841/10000 (8.4100%),                 avg. length: 295.6,                last time consumption/overall running time: 108.6458s / 4290.2803 s
first_0:                 episode reward: 22.2500,                 loss: nan
second_0:                 episode reward: -22.2500,                 loss: 0.0199
Episode: 861/10000 (8.6100%),                 avg. length: 295.55,                last time consumption/overall running time: 108.4631s / 4398.7434 s
first_0:                 episode reward: 10.4500,                 loss: nan
second_0:                 episode reward: -10.4500,                 loss: 0.0196
Episode: 881/10000 (8.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 109.4054s / 4508.1488 s
first_0:                 episode reward: 5.3000,                 loss: nan
second_0:                 episode reward: -5.3000,                 loss: 0.0196
Episode: 901/10000 (9.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 109.6802s / 4617.8290 s
first_0:                 episode reward: 4.3500,                 loss: nan
second_0:                 episode reward: -4.3500,                 loss: 0.0203
Episode: 921/10000 (9.2100%),                 avg. length: 298.15,                last time consumption/overall running time: 110.2172s / 4728.0462 s
first_0:                 episode reward: 9.0500,                 loss: nan
second_0:                 episode reward: -9.0500,                 loss: 0.0204
Episode: 941/10000 (9.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 109.9513s / 4837.9975 s
first_0:                 episode reward: 8.4000,                 loss: nan
second_0:                 episode reward: -8.4000,                 loss: 0.0212
Episode: 961/10000 (9.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 109.9046s / 4947.9021 s
first_0:                 episode reward: 5.6500,                 loss: nan
second_0:                 episode reward: -5.6500,                 loss: 0.0216
Episode: 981/10000 (9.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 110.1143s / 5058.0164 s
first_0:                 episode reward: 2.8000,                 loss: nan
second_0:                 episode reward: -2.8000,                 loss: 0.0223
Episode: 1001/10000 (10.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 109.7348s / 5167.7512 s
first_0:                 episode reward: 15.9500,                 loss: nan
second_0:                 episode reward: -15.9500,                 loss: 0.0227
Episode: 1021/10000 (10.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 110.0079s / 5277.7591 s
first_0:                 episode reward: 7.7000,                 loss: nan
second_0:                 episode reward: -7.7000,                 loss: 0.0218
Episode: 1041/10000 (10.4100%),                 avg. length: 297.05,                last time consumption/overall running time: 109.3876s / 5387.1467 s
first_0:                 episode reward: 21.4000,                 loss: nan
second_0:                 episode reward: -21.4000,                 loss: 0.0219
Episode: 1061/10000 (10.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 109.7914s / 5496.9381 s
first_0:                 episode reward: 4.8500,                 loss: nan
second_0:                 episode reward: -4.8500,                 loss: 0.0217
Episode: 1081/10000 (10.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 110.5750s / 5607.5131 s
first_0:                 episode reward: 1.5500,                 loss: nan
second_0:                 episode reward: -1.5500,                 loss: 0.0223
Episode: 1101/10000 (11.0100%),                 avg. length: 295.25,                last time consumption/overall running time: 108.8862s / 5716.3993 s
first_0:                 episode reward: 11.5500,                 loss: nan
second_0:                 episode reward: -11.5500,                 loss: 0.0227
Episode: 1121/10000 (11.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 110.4126s / 5826.8119 s
first_0:                 episode reward: 1.1500,                 loss: nan
second_0:                 episode reward: -1.1500,                 loss: 0.0229
Episode: 1141/10000 (11.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 110.6085s / 5937.4204 s
first_0:                 episode reward: 5.3000,                 loss: nan
second_0:                 episode reward: -5.3000,                 loss: 0.0236
Episode: 1161/10000 (11.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 109.7715s / 6047.1919 s
first_0:                 episode reward: 10.7500,                 loss: nan
second_0:                 episode reward: -10.7500,                 loss: 0.0236
Episode: 1181/10000 (11.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 110.3472s / 6157.5391 s
first_0:                 episode reward: 4.4500,                 loss: nan
second_0:                 episode reward: -4.4500,                 loss: 0.0245
Episode: 1201/10000 (12.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 110.4589s / 6267.9979 s
first_0:                 episode reward: 3.3500,                 loss: nan
second_0:                 episode reward: -3.3500,                 loss: 0.0253
Episode: 1221/10000 (12.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 110.7056s / 6378.7036 s
first_0:                 episode reward: 5.3500,                 loss: nan
second_0:                 episode reward: -5.3500,                 loss: 0.0256
Episode: 1241/10000 (12.4100%),                 avg. length: 292.25,                last time consumption/overall running time: 108.0542s / 6486.7578 s
first_0:                 episode reward: 12.2000,                 loss: nan
second_0:                 episode reward: -12.2000,                 loss: 0.0255
Episode: 1261/10000 (12.6100%),                 avg. length: 295.75,                last time consumption/overall running time: 109.4210s / 6596.1788 s
first_0:                 episode reward: 10.9500,                 loss: nan
second_0:                 episode reward: -10.9500,                 loss: 0.0250
Episode: 1281/10000 (12.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 110.8241s / 6707.0029 s
first_0:                 episode reward: 6.3500,                 loss: nan
second_0:                 episode reward: -6.3500,                 loss: 0.0241
Episode: 1301/10000 (13.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 110.3428s / 6817.3457 s
first_0:                 episode reward: 11.2000,                 loss: nan
second_0:                 episode reward: -11.2000,                 loss: 0.0248
Episode: 1321/10000 (13.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 110.7946s / 6928.1403 s
first_0:                 episode reward: 8.1000,                 loss: nan
second_0:                 episode reward: -8.1000,                 loss: 0.0234
Episode: 1341/10000 (13.4100%),                 avg. length: 294.95,                last time consumption/overall running time: 109.5599s / 7037.7002 s
first_0:                 episode reward: 22.3500,                 loss: nan
second_0:                 episode reward: -22.3500,                 loss: 0.0232
Episode: 1361/10000 (13.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 110.2996s / 7147.9998 s
first_0:                 episode reward: 6.1000,                 loss: nan
second_0:                 episode reward: -6.1000,                 loss: 0.0226
Episode: 1381/10000 (13.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 110.8846s / 7258.8844 s
first_0:                 episode reward: 6.0500,                 loss: nan
second_0:                 episode reward: -6.0500,                 loss: 0.0238
Episode: 1401/10000 (14.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 110.6105s / 7369.4950 s
first_0:                 episode reward: 1.7000,                 loss: nan
second_0:                 episode reward: -1.7000,                 loss: 0.0244
Episode: 1421/10000 (14.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 110.5279s / 7480.0228 s