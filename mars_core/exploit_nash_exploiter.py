from utils.func import LoadYAML2Dict
from env.import_env import make_env
from rollout import rollout
from rl.algorithm import *

### Load configurations
# yaml_file = 'confs/gym_cartpolev1_dqn'
# yaml_file = 'confs/gym_cartpolev1_ppo'
# yaml_file = 'confs/pettingzoo_boxingv1_dqn'
yaml_file = 'confs/pettingzoo_boxingv1_nash_dqn_exploiter'
# yaml_file = 'confs/slimevolley_slimevolleyv0_dqn'
# yaml_file = 'confs/slimevolley_slimevolleyv0_ppo'
# yaml_file = 'confs/slimevolley_slimevolleyv0_nash_dqn_exploiter'


args = LoadYAML2Dict(yaml_file, toAttr=True)
print(args)

## Change/specify some arguments if necessary
args.against_baseline = False
args.test = False
args.exploit = True
args.load_model_full_path = '../model/pettingzoo_boxing_v1_nash_NashDQNExploiter_20210819160038/_0-0'
# args.load_model_full_path = '../model/slimevolley_SlimeVolley-v0_nash_NashDQNExploiter_0/-2'
args.num_envs = 1
args.seed = 1

### Create env
env = make_env(args)
print(env)

### Specify models for each agent
trained_model = eval(args.algorithm)(env, args)
args.net_architecture['hidden_dim_list'] = [64, 64, 64]
exploiter = DQN(env, args)
trained_model.fix()

model = MultiAgent(env, [trained_model, exploiter], args)

### Rollout
rollout(env, model, args)