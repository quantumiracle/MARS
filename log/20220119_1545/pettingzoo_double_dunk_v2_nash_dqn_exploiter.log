pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
double_dunk_v2 pettingzoo
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
random seed: [91, 69]
<SubprocVectorEnv instance>
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
No agent are not learnable.
Arguments:  {'env_name': 'double_dunk_v2', 'env_type': 'pettingzoo', 'num_envs': 2, 'ram': True, 'seed': 'random', 'algorithm': 'NashDQNExploiter', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000, 'exploiter_update_itr': 3}, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 0.1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn_exploiter', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}}
Save models to : /home/zihan/research/MARS/data/model/20220119_1545/pettingzoo_double_dunk_v2_nash_dqn_exploiter. 
 Save logs to: /home/zihan/research/MARS/data/log/20220119_1545/pettingzoo_double_dunk_v2_nash_dqn_exploiter.
Episode: 1/10000 (0.0100%),                 avg. length: 4694.0,                last time consumption/overall running time: 199.5304s / 199.5304 s
env0_first_0:                 episode reward: -24.0000,                 loss: 0.0161
env0_second_0:                 episode reward: 24.0000,                 loss: 0.0149
env1_first_0:                 episode reward: -37.0000,                 loss: nan
env1_second_0:                 episode reward: 37.0000,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 3876.1,                last time consumption/overall running time: 4799.6342s / 4999.1646 s
env0_first_0:                 episode reward: -13.5500,                 loss: 0.0153
env0_second_0:                 episode reward: 13.5500,                 loss: 0.0153
env1_first_0:                 episode reward: -12.7000,                 loss: nan
env1_second_0:                 episode reward: 12.7000,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 3951.3,                last time consumption/overall running time: 5522.6648s / 10521.8295 s
env0_first_0:                 episode reward: 34.2000,                 loss: 0.0140
env0_second_0:                 episode reward: -34.2000,                 loss: 0.0144
env1_first_0:                 episode reward: 36.6000,                 loss: nan
env1_second_0:                 episode reward: -36.6000,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 5052.15,                last time consumption/overall running time: 7105.7672s / 17627.5966 s
env0_first_0:                 episode reward: 50.9500,                 loss: 0.0182
env0_second_0:                 episode reward: -50.9500,                 loss: 0.0176
env1_first_0:                 episode reward: 55.4000,                 loss: nan
env1_second_0:                 episode reward: -55.4000,                 loss: nan
Episode: 81/10000 (0.8100%),                 avg. length: 3480.8,                last time consumption/overall running time: 4910.0140s / 22537.6106 s
env0_first_0:                 episode reward: 9.0000,                 loss: 0.0107
env0_second_0:                 episode reward: -9.0000,                 loss: 0.0097
env1_first_0:                 episode reward: 6.8000,                 loss: nan
env1_second_0:                 episode reward: -6.8000,                 loss: nan
Episode: 101/10000 (1.0100%),                 avg. length: 3641.35,                last time consumption/overall running time: 5142.5003s / 27680.1109 s
env0_first_0:                 episode reward: 10.7500,                 loss: 0.0093
env0_second_0:                 episode reward: -10.7500,                 loss: 0.0071
env1_first_0:                 episode reward: 12.6500,                 loss: nan
env1_second_0:                 episode reward: -12.6500,                 loss: nan
Episode: 121/10000 (1.2100%),                 avg. length: 3008.5,                last time consumption/overall running time: 4243.7314s / 31923.8424 s
env0_first_0:                 episode reward: 10.0000,                 loss: 0.0107
env0_second_0:                 episode reward: -10.0000,                 loss: 0.0071
env1_first_0:                 episode reward: 13.0500,                 loss: nan
env1_second_0:                 episode reward: -13.0500,                 loss: nan
Episode: 141/10000 (1.4100%),                 avg. length: 3467.95,                last time consumption/overall running time: 4908.8276s / 36832.6700 s
env0_first_0:                 episode reward: 12.3000,                 loss: 0.0110
env0_second_0:                 episode reward: -12.3000,                 loss: 0.0083
env1_first_0:                 episode reward: 11.1500,                 loss: nan
env1_second_0:                 episode reward: -11.1500,                 loss: nan
Episode: 161/10000 (1.6100%),                 avg. length: 2854.55,                last time consumption/overall running time: 4058.6198s / 40891.2898 s
env0_first_0:                 episode reward: 10.2000,                 loss: 0.0126
env0_second_0:                 episode reward: -10.2000,                 loss: 0.0114
env1_first_0:                 episode reward: 14.8000,                 loss: nan
env1_second_0:                 episode reward: -14.8000,                 loss: nan
Episode: 181/10000 (1.8100%),                 avg. length: 3502.7,                last time consumption/overall running time: 4945.3755s / 45836.6653 s
env0_first_0:                 episode reward: 13.4000,                 loss: 0.0103
env0_second_0:                 episode reward: -13.4000,                 loss: 0.0104
env1_first_0:                 episode reward: 10.0500,                 loss: nan
env1_second_0:                 episode reward: -10.0500,                 loss: nan
Episode: 201/10000 (2.0100%),                 avg. length: 4024.1,                last time consumption/overall running time: 5686.2098s / 51522.8751 s
env0_first_0:                 episode reward: 7.1000,                 loss: 0.0115
env0_second_0:                 episode reward: -7.1000,                 loss: 0.0127
env1_first_0:                 episode reward: 8.9000,                 loss: nan
env1_second_0:                 episode reward: -8.9000,                 loss: nan
Episode: 221/10000 (2.2100%),                 avg. length: 3843.55,                last time consumption/overall running time: 5423.6450s / 56946.5201 s
env0_first_0:                 episode reward: -5.1500,                 loss: 0.0120
env0_second_0:                 episode reward: 5.1500,                 loss: 0.0127
env1_first_0:                 episode reward: -5.5000,                 loss: nan
env1_second_0:                 episode reward: 5.5000,                 loss: nan
Episode: 241/10000 (2.4100%),                 avg. length: 3873.35,                last time consumption/overall running time: 5393.7561s / 62340.2762 s
env0_first_0:                 episode reward: -8.1000,                 loss: 0.0142
env0_second_0:                 episode reward: 8.1000,                 loss: 0.0142
env1_first_0:                 episode reward: -7.2000,                 loss: nan
env1_second_0:                 episode reward: 7.2000,                 loss: nan
Episode: 261/10000 (2.6100%),                 avg. length: 3897.6,                last time consumption/overall running time: 5401.6422s / 67741.9184 s
env0_first_0:                 episode reward: -9.0500,                 loss: 0.0138
env0_second_0:                 episode reward: 9.0500,                 loss: 0.0139
env1_first_0:                 episode reward: -5.6500,                 loss: nan
env1_second_0:                 episode reward: 5.6500,                 loss: nan
Episode: 281/10000 (2.8100%),                 avg. length: 3866.0,                last time consumption/overall running time: 5365.1091s / 73107.0275 s
env0_first_0:                 episode reward: -7.4000,                 loss: 0.0136
env0_second_0:                 episode reward: 7.4000,                 loss: 0.0135
env1_first_0:                 episode reward: -5.7000,                 loss: nan
env1_second_0:                 episode reward: 5.7000,                 loss: nan
Episode: 301/10000 (3.0100%),                 avg. length: 3575.1,                last time consumption/overall running time: 4959.9253s / 78066.9529 s
env0_first_0:                 episode reward: -6.6500,                 loss: 0.0152
env0_second_0:                 episode reward: 6.6500,                 loss: 0.0143
env1_first_0:                 episode reward: -5.5500,                 loss: nan
env1_second_0:                 episode reward: 5.5500,                 loss: nan
Episode: 321/10000 (3.2100%),                 avg. length: 4226.5,                last time consumption/overall running time: 5864.9441s / 83931.8969 s
env0_first_0:                 episode reward: -11.2500,                 loss: 0.0137
env0_second_0:                 episode reward: 11.2500,                 loss: 0.0160
env1_first_0:                 episode reward: -10.6500,                 loss: nan
env1_second_0:                 episode reward: 10.6500,                 loss: nan
Episode: 341/10000 (3.4100%),                 avg. length: 3803.1,                last time consumption/overall running time: 5278.1899s / 89210.0868 s
env0_first_0:                 episode reward: -13.1500,                 loss: 0.0134
env0_second_0:                 episode reward: 13.1500,                 loss: 0.0160
env1_first_0:                 episode reward: -10.7500,                 loss: nan
env1_second_0:                 episode reward: 10.7500,                 loss: nan
Episode: 361/10000 (3.6100%),                 avg. length: 3824.9,                last time consumption/overall running time: 5299.5300s / 94509.6168 s
env0_first_0:                 episode reward: -12.2000,                 loss: 0.0140
env0_second_0:                 episode reward: 12.2000,                 loss: 0.0148
env1_first_0:                 episode reward: -14.1500,                 loss: nan
env1_second_0:                 episode reward: 14.1500,                 loss: nan
Episode: 381/10000 (3.8100%),                 avg. length: 4310.05,                last time consumption/overall running time: 5987.8994s / 100497.5162 s
env0_first_0:                 episode reward: -14.3000,                 loss: 0.0140
env0_second_0:                 episode reward: 14.3000,                 loss: 0.0135
env1_first_0:                 episode reward: -18.3500,                 loss: nan
env1_second_0:                 episode reward: 18.3500,                 loss: nan
Episode: 401/10000 (4.0100%),                 avg. length: 4472.2,                last time consumption/overall running time: 6206.9692s / 106704.4854 s
env0_first_0:                 episode reward: -17.7000,                 loss: 0.0149
env0_second_0:                 episode reward: 17.7000,                 loss: 0.0146
env1_first_0:                 episode reward: -17.9500,                 loss: nan
env1_second_0:                 episode reward: 17.9500,                 loss: nan
Episode: 421/10000 (4.2100%),                 avg. length: 3590.5,                last time consumption/overall running time: 4895.8001s / 111600.2855 s
env0_first_0:                 episode reward: -16.9500,                 loss: 0.0155
env0_second_0:                 episode reward: 16.9500,                 loss: 0.0153
env1_first_0:                 episode reward: -15.0500,                 loss: nan
env1_second_0:                 episode reward: 15.0500,                 loss: nan
Episode: 441/10000 (4.4100%),                 avg. length: 3838.05,                last time consumption/overall running time: 5193.9750s / 116794.2605 s
env0_first_0:                 episode reward: -18.0500,                 loss: 0.0142
env0_second_0:                 episode reward: 18.0500,                 loss: 0.0149
env1_first_0:                 episode reward: -19.5000,                 loss: nan
env1_second_0:                 episode reward: 19.5000,                 loss: nan
Episode: 461/10000 (4.6100%),                 avg. length: 3293.0,                last time consumption/overall running time: 4450.1114s / 121244.3719 s
env0_first_0:                 episode reward: -19.4000,                 loss: 0.0143
env0_second_0:                 episode reward: 19.4000,                 loss: 0.0154
env1_first_0:                 episode reward: -20.7000,                 loss: nan
env1_second_0:                 episode reward: 20.7000,                 loss: nan
Episode: 481/10000 (4.8100%),                 avg. length: 3025.75,                last time consumption/overall running time: 4092.4882s / 125336.8601 s
env0_first_0:                 episode reward: -15.7000,                 loss: 0.0133
env0_second_0:                 episode reward: 15.7000,                 loss: 0.0142
env1_first_0:                 episode reward: -14.8500,                 loss: nan
env1_second_0:                 episode reward: 14.8500,                 loss: nan
Episode: 501/10000 (5.0100%),                 avg. length: 3571.6,                last time consumption/overall running time: 4828.0542s / 130164.9143 s
env0_first_0:                 episode reward: -19.8500,                 loss: 0.0134
env0_second_0:                 episode reward: 19.8500,                 loss: 0.0143
env1_first_0:                 episode reward: -18.9500,                 loss: nan
env1_second_0:                 episode reward: 18.9500,                 loss: nan
Episode: 521/10000 (5.2100%),                 avg. length: 3399.35,                last time consumption/overall running time: 4574.8835s / 134739.7979 s
env0_first_0:                 episode reward: -17.0000,                 loss: 0.0140
env0_second_0:                 episode reward: 17.0000,                 loss: 0.0135
env1_first_0:                 episode reward: -16.2500,                 loss: nan
env1_second_0:                 episode reward: 16.2500,                 loss: nan
Episode: 541/10000 (5.4100%),                 avg. length: 3224.7,                last time consumption/overall running time: 4343.2557s / 139083.0536 s
env0_first_0:                 episode reward: -19.3000,                 loss: 0.0131
env0_second_0:                 episode reward: 19.3000,                 loss: 0.0135
env1_first_0:                 episode reward: -20.5000,                 loss: nan
env1_second_0:                 episode reward: 20.5000,                 loss: nan
Episode: 561/10000 (5.6100%),                 avg. length: 3618.05,                last time consumption/overall running time: 4835.1035s / 143918.1571 s
env0_first_0:                 episode reward: -22.7000,                 loss: 0.0133
env0_second_0:                 episode reward: 22.7000,                 loss: 0.0149
env1_first_0:                 episode reward: -23.4000,                 loss: nan
env1_second_0:                 episode reward: 23.4000,                 loss: nan
Episode: 581/10000 (5.8100%),                 avg. length: 3629.8,                last time consumption/overall running time: 4863.7488s / 148781.9059 s
env0_first_0:                 episode reward: -25.7000,                 loss: 0.0136
env0_second_0:                 episode reward: 25.7000,                 loss: 0.0132
env1_first_0:                 episode reward: -24.0500,                 loss: nan
env1_second_0:                 episode reward: 24.0500,                 loss: nan
Episode: 601/10000 (6.0100%),                 avg. length: 3286.15,                last time consumption/overall running time: 4373.0785s / 153154.9844 s
env0_first_0:                 episode reward: -22.8500,                 loss: 0.0137
env0_second_0:                 episode reward: 22.8500,                 loss: 0.0122
env1_first_0:                 episode reward: -21.1500,                 loss: nan
env1_second_0:                 episode reward: 21.1500,                 loss: nan
Episode: 621/10000 (6.2100%),                 avg. length: 3517.3,                last time consumption/overall running time: 4608.3187s / 157763.3030 s
env0_first_0:                 episode reward: -26.6000,                 loss: 0.0130
env0_second_0:                 episode reward: 26.6000,                 loss: 0.0134
env1_first_0:                 episode reward: -24.4000,                 loss: nan
env1_second_0:                 episode reward: 24.4000,                 loss: nan
Episode: 641/10000 (6.4100%),                 avg. length: 2392.25,                last time consumption/overall running time: 3102.8917s / 160866.1947 s
env0_first_0:                 episode reward: -21.5500,                 loss: 0.0130
env0_second_0:                 episode reward: 21.5500,                 loss: 0.0122
env1_first_0:                 episode reward: -19.8000,                 loss: nan
env1_second_0:                 episode reward: 19.8000,                 loss: nan
Episode: 661/10000 (6.6100%),                 avg. length: 2770.8,                last time consumption/overall running time: 3554.3227s / 164420.5174 s
env0_first_0:                 episode reward: -19.5500,                 loss: 0.0127
env0_second_0:                 episode reward: 19.5500,                 loss: 0.0114
env1_first_0:                 episode reward: -23.8000,                 loss: nan
env1_second_0:                 episode reward: 23.8000,                 loss: nan
Episode: 681/10000 (6.8100%),                 avg. length: 3071.0,                last time consumption/overall running time: 3880.2226s / 168300.7400 s
env0_first_0:                 episode reward: -19.4500,                 loss: 0.0147
env0_second_0:                 episode reward: 19.4500,                 loss: 0.0140
env1_first_0:                 episode reward: -22.8000,                 loss: nan
env1_second_0:                 episode reward: 22.8000,                 loss: nan
Episode: 701/10000 (7.0100%),                 avg. length: 2414.45,                last time consumption/overall running time: 3040.2780s / 171341.0181 s
env0_first_0:                 episode reward: -22.7000,                 loss: 0.0143
env0_second_0:                 episode reward: 22.7000,                 loss: 0.0142
env1_first_0:                 episode reward: -22.4500,                 loss: nan
env1_second_0:                 episode reward: 22.4500,                 loss: nan
Episode: 721/10000 (7.2100%),                 avg. length: 2391.4,                last time consumption/overall running time: 2991.9398s / 174332.9579 s
env0_first_0:                 episode reward: -21.4500,                 loss: 0.0137
env0_second_0:                 episode reward: 21.4500,                 loss: 0.0151
env1_first_0:                 episode reward: -21.1500,                 loss: nan
env1_second_0:                 episode reward: 21.1500,                 loss: nan
Episode: 741/10000 (7.4100%),                 avg. length: 2336.25,                last time consumption/overall running time: 2921.0347s / 177253.9926 s
env0_first_0:                 episode reward: -20.1500,                 loss: 0.0152
env0_second_0:                 episode reward: 20.1500,                 loss: 0.0156
env1_first_0:                 episode reward: -20.2000,                 loss: nan
env1_second_0:                 episode reward: 20.2000,                 loss: nan
Episode: 761/10000 (7.6100%),                 avg. length: 2296.15,                last time consumption/overall running time: 2846.5397s / 180100.5323 s
env0_first_0:                 episode reward: -19.1000,                 loss: 0.0157
env0_second_0:                 episode reward: 19.1000,                 loss: 0.0156
env1_first_0:                 episode reward: -21.1500,                 loss: nan
env1_second_0:                 episode reward: 21.1500,                 loss: nan
Episode: 781/10000 (7.8100%),                 avg. length: 2525.8,                last time consumption/overall running time: 3100.0161s / 183200.5484 s
env0_first_0:                 episode reward: -19.0000,                 loss: 0.0153
env0_second_0:                 episode reward: 19.0000,                 loss: 0.0149
env1_first_0:                 episode reward: -16.2000,                 loss: nan
env1_second_0:                 episode reward: 16.2000,                 loss: nan
Episode: 801/10000 (8.0100%),                 avg. length: 2722.4,                last time consumption/overall running time: 3360.9189s / 186561.4673 s
env0_first_0:                 episode reward: -17.6000,                 loss: 0.0164
env0_second_0:                 episode reward: 17.6000,                 loss: 0.0152
env1_first_0:                 episode reward: -19.3500,                 loss: nan
env1_second_0:                 episode reward: 19.3500,                 loss: nan
Episode: 821/10000 (8.2100%),                 avg. length: 2260.9,                last time consumption/overall running time: 2781.7292s / 189343.1966 s
env0_first_0:                 episode reward: -18.7000,                 loss: 0.0153
env0_second_0:                 episode reward: 18.7000,                 loss: 0.0138
env1_first_0:                 episode reward: -20.2500,                 loss: nan
env1_second_0:                 episode reward: 20.2500,                 loss: nan
Episode: 841/10000 (8.4100%),                 avg. length: 2375.45,                last time consumption/overall running time: 2898.6216s / 192241.8182 s
env0_first_0:                 episode reward: -19.1500,                 loss: 0.0150
env0_second_0:                 episode reward: 19.1500,                 loss: 0.0132
env1_first_0:                 episode reward: -19.0000,                 loss: nan
env1_second_0:                 episode reward: 19.0000,                 loss: nan
Episode: 861/10000 (8.6100%),                 avg. length: 1930.25,                last time consumption/overall running time: 2323.9416s / 194565.7598 s
env0_first_0:                 episode reward: -19.0500,                 loss: 0.0149
env0_second_0:                 episode reward: 19.0500,                 loss: 0.0129
env1_first_0:                 episode reward: -15.2000,                 loss: nan
env1_second_0:                 episode reward: 15.2000,                 loss: nan
Episode: 881/10000 (8.8100%),                 avg. length: 2339.35,                last time consumption/overall running time: 2828.1179s / 197393.8777 s
env0_first_0:                 episode reward: -18.4000,                 loss: 0.0142
env0_second_0:                 episode reward: 18.4000,                 loss: 0.0123
env1_first_0:                 episode reward: -18.1000,                 loss: nan
env1_second_0:                 episode reward: 18.1000,                 loss: nan
Episode: 901/10000 (9.0100%),                 avg. length: 2102.45,                last time consumption/overall running time: 2546.4399s / 199940.3176 s
env0_first_0:                 episode reward: -17.0000,                 loss: 0.0139
env0_second_0:                 episode reward: 17.0000,                 loss: 0.0120
env1_first_0:                 episode reward: -18.6500,                 loss: nan
env1_second_0:                 episode reward: 18.6500,                 loss: nan
Episode: 921/10000 (9.2100%),                 avg. length: 2175.6,                last time consumption/overall running time: 2621.5369s / 202561.8545 s
env0_first_0:                 episode reward: -17.4500,                 loss: 0.0131
env0_second_0:                 episode reward: 17.4500,                 loss: 0.0116
env1_first_0:                 episode reward: -16.1000,                 loss: nan
env1_second_0:                 episode reward: 16.1000,                 loss: nan
Episode: 941/10000 (9.4100%),                 avg. length: 2204.1,                last time consumption/overall running time: 2655.3710s / 205217.2256 s
env0_first_0:                 episode reward: -16.5000,                 loss: 0.0135
env0_second_0:                 episode reward: 16.5000,                 loss: 0.0118
env1_first_0:                 episode reward: -17.6000,                 loss: nan
env1_second_0:                 episode reward: 17.6000,                 loss: nan
Episode: 961/10000 (9.6100%),                 avg. length: 2219.35,                last time consumption/overall running time: 2682.9130s / 207900.1385 s
env0_first_0:                 episode reward: -18.2000,                 loss: 0.0134
env0_second_0:                 episode reward: 18.2000,                 loss: 0.0118
env1_first_0:                 episode reward: -19.1000,                 loss: nan
env1_second_0:                 episode reward: 19.1000,                 loss: nan
Episode: 981/10000 (9.8100%),                 avg. length: 2165.9,                last time consumption/overall running time: 2610.5930s / 210510.7315 s
env0_first_0:                 episode reward: -17.8500,                 loss: 0.0134
env0_second_0:                 episode reward: 17.8500,                 loss: 0.0119
env1_first_0:                 episode reward: -19.6500,                 loss: nan
env1_second_0:                 episode reward: 19.6500,                 loss: nan
Episode: 1001/10000 (10.0100%),                 avg. length: 2142.55,                last time consumption/overall running time: 2566.0924s / 213076.8239 s
env0_first_0:                 episode reward: -19.0000,                 loss: 0.0125
env0_second_0:                 episode reward: 19.0000,                 loss: 0.0115
env1_first_0:                 episode reward: -19.0500,                 loss: nan
env1_second_0:                 episode reward: 19.0500,                 loss: nan
Episode: 1021/10000 (10.2100%),                 avg. length: 2012.15,                last time consumption/overall running time: 2424.0408s / 215500.8647 s
env0_first_0:                 episode reward: -17.3500,                 loss: 0.0121
env0_second_0:                 episode reward: 17.3500,                 loss: 0.0117
env1_first_0:                 episode reward: -17.6000,                 loss: nan
env1_second_0:                 episode reward: 17.6000,                 loss: nan
Episode: 1041/10000 (10.4100%),                 avg. length: 1986.4,                last time consumption/overall running time: 2367.0998s / 217867.9645 s
env0_first_0:                 episode reward: -18.7000,                 loss: 0.0122
env0_second_0:                 episode reward: 18.7000,                 loss: 0.0112
env1_first_0:                 episode reward: -16.4500,                 loss: nan
env1_second_0:                 episode reward: 16.4500,                 loss: nan
Episode: 1061/10000 (10.6100%),                 avg. length: 2135.25,                last time consumption/overall running time: 2552.1452s / 220420.1097 s
env0_first_0:                 episode reward: -18.2000,                 loss: 0.0130
env0_second_0:                 episode reward: 18.2000,                 loss: 0.0121
env1_first_0:                 episode reward: -18.8500,                 loss: nan
env1_second_0:                 episode reward: 18.8500,                 loss: nan
Episode: 1081/10000 (10.8100%),                 avg. length: 2042.95,                last time consumption/overall running time: 2417.8764s / 222837.9861 s
env0_first_0:                 episode reward: -18.1500,                 loss: 0.0122
env0_second_0:                 episode reward: 18.1500,                 loss: 0.0109
env1_first_0:                 episode reward: -15.0500,                 loss: nan
env1_second_0:                 episode reward: 15.0500,                 loss: nan
Episode: 1101/10000 (11.0100%),                 avg. length: 2248.6,                last time consumption/overall running time: 2663.2419s / 225501.2280 s
env0_first_0:                 episode reward: -17.8500,                 loss: 0.0125
env0_second_0:                 episode reward: 17.8500,                 loss: 0.0111
env1_first_0:                 episode reward: -18.6000,                 loss: nan
env1_second_0:                 episode reward: 18.6000,                 loss: nan
Episode: 1121/10000 (11.2100%),                 avg. length: 2340.2,                last time consumption/overall running time: 2753.8265s / 228255.0544 s
env0_first_0:                 episode reward: -19.4000,                 loss: 0.0135
env0_second_0:                 episode reward: 19.4000,                 loss: 0.0131
env1_first_0:                 episode reward: -19.9000,                 loss: nan
env1_second_0:                 episode reward: 19.9000,                 loss: nan
Episode: 1141/10000 (11.4100%),                 avg. length: 2374.2,                last time consumption/overall running time: 2818.1052s / 231073.1596 s
env0_first_0:                 episode reward: -19.8000,                 loss: 0.0132
env0_second_0:                 episode reward: 19.8000,                 loss: 0.0123
env1_first_0:                 episode reward: -19.8000,                 loss: nan
env1_second_0:                 episode reward: 19.8000,                 loss: nan
Episode: 1161/10000 (11.6100%),                 avg. length: 2359.15,                last time consumption/overall running time: 2792.3824s / 233865.5420 s
env0_first_0:                 episode reward: -19.1500,                 loss: 0.0144
env0_second_0:                 episode reward: 19.1500,                 loss: 0.0130
env1_first_0:                 episode reward: -19.6000,                 loss: nan
env1_second_0:                 episode reward: 19.6000,                 loss: nan
Episode: 1181/10000 (11.8100%),                 avg. length: 2106.2,                last time consumption/overall running time: 2486.0826s / 236351.6246 s
env0_first_0:                 episode reward: -14.8500,                 loss: 0.0143
env0_second_0:                 episode reward: 14.8500,                 loss: 0.0133
env1_first_0:                 episode reward: -17.4500,                 loss: nan
env1_second_0:                 episode reward: 17.4500,                 loss: nan
Episode: 1201/10000 (12.0100%),                 avg. length: 2433.25,                last time consumption/overall running time: 2869.9481s / 239221.5727 s
env0_first_0:                 episode reward: -20.1500,                 loss: 0.0135
env0_second_0:                 episode reward: 20.1500,                 loss: 0.0138
env1_first_0:                 episode reward: -20.9000,                 loss: nan
env1_second_0:                 episode reward: 20.9000,                 loss: nan
Episode: 1221/10000 (12.2100%),                 avg. length: 2237.4,                last time consumption/overall running time: 2635.8179s / 241857.3907 s
env0_first_0:                 episode reward: -18.1000,                 loss: 0.0137
env0_second_0:                 episode reward: 18.1000,                 loss: 0.0125
env1_first_0:                 episode reward: -19.9500,                 loss: nan
env1_second_0:                 episode reward: 19.9500,                 loss: nan
Episode: 1241/10000 (12.4100%),                 avg. length: 2188.65,                last time consumption/overall running time: 2569.6202s / 244427.0109 s
env0_first_0:                 episode reward: -17.6000,                 loss: 0.0140
env0_second_0:                 episode reward: 17.6000,                 loss: 0.0122
env1_first_0:                 episode reward: -20.0000,                 loss: nan
env1_second_0:                 episode reward: 20.0000,                 loss: nan
Episode: 1261/10000 (12.6100%),                 avg. length: 2118.9,                last time consumption/overall running time: 2475.5668s / 246902.5776 s
env0_first_0:                 episode reward: -16.2500,                 loss: 0.0131
env0_second_0:                 episode reward: 16.2500,                 loss: 0.0108
env1_first_0:                 episode reward: -16.4500,                 loss: nan
env1_second_0:                 episode reward: 16.4500,                 loss: nan
Episode: 1281/10000 (12.8100%),                 avg. length: 2158.4,                last time consumption/overall running time: 2535.1844s / 249437.7621 s
env0_first_0:                 episode reward: -17.4000,                 loss: 0.0128
env0_second_0:                 episode reward: 17.4000,                 loss: 0.0111
env1_first_0:                 episode reward: -17.5000,                 loss: nan
env1_second_0:                 episode reward: 17.5000,                 loss: nan
Episode: 1301/10000 (13.0100%),                 avg. length: 2129.95,                last time consumption/overall running time: 2491.2855s / 251929.0476 s
env0_first_0:                 episode reward: -17.4500,                 loss: 0.0125
env0_second_0:                 episode reward: 17.4500,                 loss: 0.0109
env1_first_0:                 episode reward: -15.3500,                 loss: nan
env1_second_0:                 episode reward: 15.3500,                 loss: nan
Episode: 1321/10000 (13.2100%),                 avg. length: 2197.65,                last time consumption/overall running time: 2557.6569s / 254486.7045 s
env0_first_0:                 episode reward: -18.6000,                 loss: 0.0113
env0_second_0:                 episode reward: 18.6000,                 loss: 0.0114
env1_first_0:                 episode reward: -17.5000,                 loss: nan
env1_second_0:                 episode reward: 17.5000,                 loss: nan
Episode: 1341/10000 (13.4100%),                 avg. length: 1987.05,                last time consumption/overall running time: 2293.9561s / 256780.6606 s
env0_first_0:                 episode reward: -16.1500,                 loss: 0.0106
env0_second_0:                 episode reward: 16.1500,                 loss: 0.0110
env1_first_0:                 episode reward: -18.9000,                 loss: nan
env1_second_0:                 episode reward: 18.9000,                 loss: nan
Episode: 1361/10000 (13.6100%),                 avg. length: 2089.65,                last time consumption/overall running time: 2373.8580s / 259154.5187 s
env0_first_0:                 episode reward: -18.2000,                 loss: 0.0106
env0_second_0:                 episode reward: 18.2000,                 loss: 0.0110
env1_first_0:                 episode reward: -18.5000,                 loss: nan
env1_second_0:                 episode reward: 18.5000,                 loss: nan
Episode: 1381/10000 (13.8100%),                 avg. length: 1976.75,                last time consumption/overall running time: 2243.7175s / 261398.2362 s
env0_first_0:                 episode reward: -18.2000,                 loss: 0.0110
env0_second_0:                 episode reward: 18.2000,                 loss: 0.0121
env1_first_0:                 episode reward: -17.6000,                 loss: nan
env1_second_0:                 episode reward: 17.6000,                 loss: nan
Episode: 1401/10000 (14.0100%),                 avg. length: 2191.15,                last time consumption/overall running time: 2479.3038s / 263877.5399 s
env0_first_0:                 episode reward: -17.8500,                 loss: 0.0110
env0_second_0:                 episode reward: 17.8500,                 loss: 0.0121
env1_first_0:                 episode reward: -19.5500,                 loss: nan
env1_second_0:                 episode reward: 19.5500,                 loss: nan
Episode: 1421/10000 (14.2100%),                 avg. length: 2368.7,                last time consumption/overall running time: 2672.7087s / 266550.2486 s
env0_first_0:                 episode reward: -20.9000,                 loss: 0.0114
env0_second_0:                 episode reward: 20.9000,                 loss: 0.0120
env1_first_0:                 episode reward: -19.9500,                 loss: nan
env1_second_0:                 episode reward: 19.9500,                 loss: nan
Episode: 1441/10000 (14.4100%),                 avg. length: 2083.2,                last time consumption/overall running time: 2332.7017s / 268882.9503 s
env0_first_0:                 episode reward: -19.1000,                 loss: 0.0110
env0_second_0:                 episode reward: 19.1000,                 loss: 0.0121
env1_first_0:                 episode reward: -18.3500,                 loss: nan
env1_second_0:                 episode reward: 18.3500,                 loss: nan
Episode: 1461/10000 (14.6100%),                 avg. length: 2099.55,                last time consumption/overall running time: 2341.1376s / 271224.0880 s
env0_first_0:                 episode reward: -19.2000,                 loss: 0.0103
env0_second_0:                 episode reward: 19.2000,                 loss: 0.0116
env1_first_0:                 episode reward: -19.2500,                 loss: nan
env1_second_0:                 episode reward: 19.2500,                 loss: nan
Episode: 1481/10000 (14.8100%),                 avg. length: 2084.4,                last time consumption/overall running time: 2300.3169s / 273524.4049 s
env0_first_0:                 episode reward: -16.9000,                 loss: 0.0106
env0_second_0:                 episode reward: 16.9000,                 loss: 0.0116
env1_first_0:                 episode reward: -18.0000,                 loss: nan
env1_second_0:                 episode reward: 18.0000,                 loss: nan
Episode: 1501/10000 (15.0100%),                 avg. length: 2256.7,                last time consumption/overall running time: 2482.5046s / 276006.9095 s
env0_first_0:                 episode reward: -18.9000,                 loss: 0.0106
env0_second_0:                 episode reward: 18.9000,                 loss: 0.0114
env1_first_0:                 episode reward: -16.4000,                 loss: nan
env1_second_0:                 episode reward: 16.4000,                 loss: nan
Episode: 1521/10000 (15.2100%),                 avg. length: 2067.3,                last time consumption/overall running time: 2270.1235s / 278277.0330 s
env0_first_0:                 episode reward: -16.3500,                 loss: 0.0103
env0_second_0:                 episode reward: 16.3500,                 loss: 0.0113
env1_first_0:                 episode reward: -17.5000,                 loss: nan
env1_second_0:                 episode reward: 17.5000,                 loss: nan
Episode: 1541/10000 (15.4100%),                 avg. length: 2100.0,                last time consumption/overall running time: 2289.3452s / 280566.3782 s
env0_first_0:                 episode reward: -16.8500,                 loss: 0.0104
env0_second_0:                 episode reward: 16.8500,                 loss: 0.0112
env1_first_0:                 episode reward: -18.1500,                 loss: nan
env1_second_0:                 episode reward: 18.1500,                 loss: nan
Episode: 1561/10000 (15.6100%),                 avg. length: 2104.9,                last time consumption/overall running time: 2285.1212s / 282851.4994 s
env0_first_0:                 episode reward: -17.5000,                 loss: 0.0100
env0_second_0:                 episode reward: 17.5000,                 loss: 0.0108
env1_first_0:                 episode reward: -18.3500,                 loss: nan
env1_second_0:                 episode reward: 18.3500,                 loss: nan
Episode: 1581/10000 (15.8100%),                 avg. length: 2125.2,                last time consumption/overall running time: 2303.9074s / 285155.4068 s
env0_first_0:                 episode reward: -15.8500,                 loss: 0.0100
env0_second_0:                 episode reward: 15.8500,                 loss: 0.0113
env1_first_0:                 episode reward: -17.9500,                 loss: nan
env1_second_0:                 episode reward: 17.9500,                 loss: nan
Episode: 1601/10000 (16.0100%),                 avg. length: 2048.05,                last time consumption/overall running time: 2189.1512s / 287344.5580 s
env0_first_0:                 episode reward: -16.5500,                 loss: 0.0097
env0_second_0:                 episode reward: 16.5500,                 loss: 0.0114
env1_first_0:                 episode reward: -17.4500,                 loss: nan
env1_second_0:                 episode reward: 17.4500,                 loss: nan
Episode: 1621/10000 (16.2100%),                 avg. length: 2122.3,                last time consumption/overall running time: 2257.6024s / 289602.1604 s
env0_first_0:                 episode reward: -16.2500,                 loss: 0.0088
env0_second_0:                 episode reward: 16.2500,                 loss: 0.0103
env1_first_0:                 episode reward: -15.9000,                 loss: nan
env1_second_0:                 episode reward: 15.9000,                 loss: nan
Episode: 1641/10000 (16.4100%),                 avg. length: 1944.65,                last time consumption/overall running time: 2074.9640s / 291677.1244 s
env0_first_0:                 episode reward: -16.2000,                 loss: 0.0099
env0_second_0:                 episode reward: 16.2000,                 loss: 0.0112
env1_first_0:                 episode reward: -15.8500,                 loss: nan
env1_second_0:                 episode reward: 15.8500,                 loss: nan
Episode: 1661/10000 (16.6100%),                 avg. length: 2103.55,                last time consumption/overall running time: 2242.3809s / 293919.5053 s
env0_first_0:                 episode reward: -18.5000,                 loss: 0.0092
env0_second_0:                 episode reward: 18.5000,                 loss: 0.0106
env1_first_0:                 episode reward: -17.7500,                 loss: nan
env1_second_0:                 episode reward: 17.7500,                 loss: nan
Episode: 1681/10000 (16.8100%),                 avg. length: 2179.85,                last time consumption/overall running time: 2303.2460s / 296222.7513 s
env0_first_0:                 episode reward: -17.7000,                 loss: 0.0094
env0_second_0:                 episode reward: 17.7000,                 loss: 0.0109
env1_first_0:                 episode reward: -20.3000,                 loss: nan
env1_second_0:                 episode reward: 20.3000,                 loss: nan
Episode: 1701/10000 (17.0100%),                 avg. length: 2125.45,                last time consumption/overall running time: 2231.8464s / 298454.5978 s
env0_first_0:                 episode reward: -17.8000,                 loss: 0.0090
env0_second_0:                 episode reward: 17.8000,                 loss: 0.0103
env1_first_0:                 episode reward: -19.4500,                 loss: nan
env1_second_0:                 episode reward: 19.4500,                 loss: nan
Episode: 1721/10000 (17.2100%),                 avg. length: 2250.95,                last time consumption/overall running time: 2377.0900s / 300831.6878 s
env0_first_0:                 episode reward: -18.7000,                 loss: 0.0091
env0_second_0:                 episode reward: 18.7000,                 loss: 0.0109
env1_first_0:                 episode reward: -19.3000,                 loss: nan
env1_second_0:                 episode reward: 19.3000,                 loss: nan
Episode: 1741/10000 (17.4100%),                 avg. length: 2411.7,                last time consumption/overall running time: 2528.4368s / 303360.1246 s
env0_first_0:                 episode reward: -18.6000,                 loss: 0.0089
env0_second_0:                 episode reward: 18.6000,                 loss: 0.0111
env1_first_0:                 episode reward: -20.1000,                 loss: nan
env1_second_0:                 episode reward: 20.1000,                 loss: nan
Episode: 1761/10000 (17.6100%),                 avg. length: 2057.15,                last time consumption/overall running time: 2146.6381s / 305506.7626 s
env0_first_0:                 episode reward: -18.4500,                 loss: 0.0089
env0_second_0:                 episode reward: 18.4500,                 loss: 0.0114
env1_first_0:                 episode reward: -18.2000,                 loss: nan
env1_second_0:                 episode reward: 18.2000,                 loss: nan
Episode: 1781/10000 (17.8100%),                 avg. length: 2111.95,                last time consumption/overall running time: 2201.0796s / 307707.8422 s
env0_first_0:                 episode reward: -19.7500,                 loss: 0.0091
env0_second_0:                 episode reward: 19.7500,                 loss: 0.0113
env1_first_0:                 episode reward: -20.5000,                 loss: nan
env1_second_0:                 episode reward: 20.5000,                 loss: nan
Episode: 1801/10000 (18.0100%),                 avg. length: 2086.65,                last time consumption/overall running time: 2161.2175s / 309869.0597 s
env0_first_0:                 episode reward: -18.8500,                 loss: 0.0096
env0_second_0:                 episode reward: 18.8500,                 loss: 0.0108
env1_first_0:                 episode reward: -18.5000,                 loss: nan
env1_second_0:                 episode reward: 18.5000,                 loss: nan
Episode: 1821/10000 (18.2100%),                 avg. length: 2085.05,                last time consumption/overall running time: 2153.9569s / 312023.0165 s
env0_first_0:                 episode reward: -17.7000,                 loss: 0.0094
env0_second_0:                 episode reward: 17.7000,                 loss: 0.0109
env1_first_0:                 episode reward: -19.1000,                 loss: nan
env1_second_0:                 episode reward: 19.1000,                 loss: nan
Episode: 1841/10000 (18.4100%),                 avg. length: 2093.6,                last time consumption/overall running time: 2173.0077s / 314196.0242 s
env0_first_0:                 episode reward: -20.4500,                 loss: 0.0095
env0_second_0:                 episode reward: 20.4500,                 loss: 0.0107
env1_first_0:                 episode reward: -18.0500,                 loss: nan
env1_second_0:                 episode reward: 18.0500,                 loss: nan
Episode: 1861/10000 (18.6100%),                 avg. length: 2296.05,                last time consumption/overall running time: 2360.5126s / 316556.5368 s
env0_first_0:                 episode reward: -18.4000,                 loss: 0.0096
env0_second_0:                 episode reward: 18.4000,                 loss: 0.0107
env1_first_0:                 episode reward: -20.1000,                 loss: nan
env1_second_0:                 episode reward: 20.1000,                 loss: nan
Episode: 1881/10000 (18.8100%),                 avg. length: 2294.25,                last time consumption/overall running time: 2370.0426s / 318926.5794 s
env0_first_0:                 episode reward: -20.8500,                 loss: 0.0096
env0_second_0:                 episode reward: 20.8500,                 loss: 0.0112
env1_first_0:                 episode reward: -23.0500,                 loss: nan
env1_second_0:                 episode reward: 23.0500,                 loss: nan
Episode: 1901/10000 (19.0100%),                 avg. length: 2145.25,                last time consumption/overall running time: 2172.3043s / 321098.8837 s
env0_first_0:                 episode reward: -18.2000,                 loss: 0.0096
env0_second_0:                 episode reward: 18.2000,                 loss: 0.0106
env1_first_0:                 episode reward: -18.3500,                 loss: nan
env1_second_0:                 episode reward: 18.3500,                 loss: nan
Episode: 1921/10000 (19.2100%),                 avg. length: 2219.15,                last time consumption/overall running time: 2262.8639s / 323361.7476 s
env0_first_0:                 episode reward: -18.2000,                 loss: 0.0093
env0_second_0:                 episode reward: 18.2000,                 loss: 0.0100
env1_first_0:                 episode reward: -17.7500,                 loss: nan
env1_second_0:                 episode reward: 17.7500,                 loss: nan
Episode: 1941/10000 (19.4100%),                 avg. length: 2141.75,                last time consumption/overall running time: 2172.8310s / 325534.5787 s
env0_first_0:                 episode reward: -17.7000,                 loss: 0.0091
env0_second_0:                 episode reward: 17.7000,                 loss: 0.0094
env1_first_0:                 episode reward: -19.4500,                 loss: nan
env1_second_0:                 episode reward: 19.4500,                 loss: nan
Episode: 1961/10000 (19.6100%),                 avg. length: 2006.1,                last time consumption/overall running time: 2025.2126s / 327559.7913 s
env0_first_0:                 episode reward: -17.1000,                 loss: 0.0090
env0_second_0:                 episode reward: 17.1000,                 loss: 0.0101
env1_first_0:                 episode reward: -17.1500,                 loss: nan
env1_second_0:                 episode reward: 17.1500,                 loss: nan
Episode: 1981/10000 (19.8100%),                 avg. length: 2172.15,                last time consumption/overall running time: 2207.5151s / 329767.3064 s
env0_first_0:                 episode reward: -16.1000,                 loss: 0.0086
env0_second_0:                 episode reward: 16.1000,                 loss: 0.0098
env1_first_0:                 episode reward: -16.9000,                 loss: nan
env1_second_0:                 episode reward: 16.9000,                 loss: nan
Episode: 2001/10000 (20.0100%),                 avg. length: 2122.65,                last time consumption/overall running time: 2133.3051s / 331900.6115 s
env0_first_0:                 episode reward: -16.0500,                 loss: 0.0086
env0_second_0:                 episode reward: 16.0500,                 loss: 0.0095
env1_first_0:                 episode reward: -14.7000,                 loss: nan
env1_second_0:                 episode reward: 14.7000,                 loss: nan
Episode: 2021/10000 (20.2100%),                 avg. length: 1983.5,                last time consumption/overall running time: 1976.3349s / 333876.9464 s
env0_first_0:                 episode reward: -14.8500,                 loss: 0.0082
env0_second_0:                 episode reward: 14.8500,                 loss: 0.0089
env1_first_0:                 episode reward: -15.6000,                 loss: nan
env1_second_0:                 episode reward: 15.6000,                 loss: nan
Episode: 2041/10000 (20.4100%),                 avg. length: 1999.55,                last time consumption/overall running time: 2002.3064s / 335879.2528 s
env0_first_0:                 episode reward: -14.8000,                 loss: 0.0084
env0_second_0:                 episode reward: 14.8000,                 loss: 0.0089
env1_first_0:                 episode reward: -12.7500,                 loss: nan
env1_second_0:                 episode reward: 12.7500,                 loss: nan
Episode: 2061/10000 (20.6100%),                 avg. length: 1987.95,                last time consumption/overall running time: 1973.8678s / 337853.1206 s
env0_first_0:                 episode reward: -12.9000,                 loss: 0.0079
env0_second_0:                 episode reward: 12.9000,                 loss: 0.0085
env1_first_0:                 episode reward: -12.6500,                 loss: nan
env1_second_0:                 episode reward: 12.6500,                 loss: nan
Episode: 2081/10000 (20.8100%),                 avg. length: 2087.55,                last time consumption/overall running time: 2058.9048s / 339912.0254 s
env0_first_0:                 episode reward: -12.2500,                 loss: 0.0079
env0_second_0:                 episode reward: 12.2500,                 loss: 0.0081
env1_first_0:                 episode reward: -11.5000,                 loss: nan
env1_second_0:                 episode reward: 11.5000,                 loss: nan
Episode: 2101/10000 (21.0100%),                 avg. length: 2091.25,                last time consumption/overall running time: 2073.0806s / 341985.1060 s
env0_first_0:                 episode reward: -14.1000,                 loss: 0.0081
env0_second_0:                 episode reward: 14.1000,                 loss: 0.0093
env1_first_0:                 episode reward: -14.0000,                 loss: nan
env1_second_0:                 episode reward: 14.0000,                 loss: nan
Episode: 2121/10000 (21.2100%),                 avg. length: 2305.35,                last time consumption/overall running time: 2293.5689s / 344278.6749 s
env0_first_0:                 episode reward: -14.1000,                 loss: 0.0093
env0_second_0:                 episode reward: 14.1000,                 loss: 0.0099
env1_first_0:                 episode reward: -16.4500,                 loss: nan
env1_second_0:                 episode reward: 16.4500,                 loss: nan
Episode: 2141/10000 (21.4100%),                 avg. length: 2356.45,                last time consumption/overall running time: 2337.3663s / 346616.0412 s
env0_first_0:                 episode reward: -14.0000,                 loss: 0.0099
env0_second_0:                 episode reward: 14.0000,                 loss: 0.0106
env1_first_0:                 episode reward: -14.8500,                 loss: nan
env1_second_0:                 episode reward: 14.8500,                 loss: nan
Episode: 2161/10000 (21.6100%),                 avg. length: 2268.55,                last time consumption/overall running time: 2367.8418s / 348983.8830 s
env0_first_0:                 episode reward: -14.4000,                 loss: 0.0092
env0_second_0:                 episode reward: 14.4000,                 loss: 0.0099
env1_first_0:                 episode reward: -12.9000,                 loss: nan
env1_second_0:                 episode reward: 12.9000,                 loss: nan
Episode: 2181/10000 (21.8100%),                 avg. length: 2323.95,                last time consumption/overall running time: 2641.2622s / 351625.1452 s
env0_first_0:                 episode reward: -15.7500,                 loss: 0.0096
env0_second_0:                 episode reward: 15.7500,                 loss: 0.0107
env1_first_0:                 episode reward: -17.3500,                 loss: nan
env1_second_0:                 episode reward: 17.3500,                 loss: nan
Episode: 2201/10000 (22.0100%),                 avg. length: 2011.4,                last time consumption/overall running time: 2293.6817s / 353918.8269 s
env0_first_0:                 episode reward: -15.6000,                 loss: 0.0097
env0_second_0:                 episode reward: 15.6000,                 loss: 0.0108
env1_first_0:                 episode reward: -14.9000,                 loss: nan
env1_second_0:                 episode reward: 14.9000,                 loss: nan
Episode: 2221/10000 (22.2100%),                 avg. length: 2079.2,                last time consumption/overall running time: 2355.8998s / 356274.7267 s
env0_first_0:                 episode reward: -16.3500,                 loss: 0.0104
env0_second_0:                 episode reward: 16.3500,                 loss: 0.0108
env1_first_0:                 episode reward: -15.2000,                 loss: nan
env1_second_0:                 episode reward: 15.2000,                 loss: nan
Episode: 2241/10000 (22.4100%),                 avg. length: 2268.05,                last time consumption/overall running time: 2560.2448s / 358834.9715 s
env0_first_0:                 episode reward: -15.4000,                 loss: 0.0114
env0_second_0:                 episode reward: 15.4000,                 loss: 0.0110
env1_first_0:                 episode reward: -16.2000,                 loss: nan
env1_second_0:                 episode reward: 16.2000,                 loss: nan
Episode: 2261/10000 (22.6100%),                 avg. length: 2081.3,                last time consumption/overall running time: 2332.6952s / 361167.6667 s
env0_first_0:                 episode reward: -13.7500,                 loss: 0.0108
env0_second_0:                 episode reward: 13.7500,                 loss: 0.0111
env1_first_0:                 episode reward: -14.9500,                 loss: nan
env1_second_0:                 episode reward: 14.9500,                 loss: nan
Episode: 2281/10000 (22.8100%),                 avg. length: 2097.5,                last time consumption/overall running time: 2336.5489s / 363504.2156 s
env0_first_0:                 episode reward: -16.6000,                 loss: 0.0108
env0_second_0:                 episode reward: 16.6000,                 loss: 0.0106
env1_first_0:                 episode reward: -14.9000,                 loss: nan
env1_second_0:                 episode reward: 14.9000,                 loss: nan
Episode: 2301/10000 (23.0100%),                 avg. length: 2169.9,                last time consumption/overall running time: 2405.3815s / 365909.5971 s
env0_first_0:                 episode reward: -13.0500,                 loss: 0.0100
env0_second_0:                 episode reward: 13.0500,                 loss: 0.0101
env1_first_0:                 episode reward: -16.2000,                 loss: nan
env1_second_0:                 episode reward: 16.2000,                 loss: nan
Episode: 2321/10000 (23.2100%),                 avg. length: 2091.7,                last time consumption/overall running time: 2314.3660s / 368223.9631 s
env0_first_0:                 episode reward: -16.0500,                 loss: 0.0096
env0_second_0:                 episode reward: 16.0500,                 loss: 0.0105
env1_first_0:                 episode reward: -15.4000,                 loss: nan
env1_second_0:                 episode reward: 15.4000,                 loss: nan
Episode: 2341/10000 (23.4100%),                 avg. length: 2127.7,                last time consumption/overall running time: 2356.7326s / 370580.6957 s
env0_first_0:                 episode reward: -15.2500,                 loss: 0.0096
env0_second_0:                 episode reward: 15.2500,                 loss: 0.0094
env1_first_0:                 episode reward: -12.7000,                 loss: nan
env1_second_0:                 episode reward: 12.7000,                 loss: nan
Episode: 2361/10000 (23.6100%),                 avg. length: 2088.05,                last time consumption/overall running time: 2313.5653s / 372894.2610 s
env0_first_0:                 episode reward: -14.5500,                 loss: 0.0090
env0_second_0:                 episode reward: 14.5500,                 loss: 0.0085
env1_first_0:                 episode reward: -14.6000,                 loss: nan
env1_second_0:                 episode reward: 14.6000,                 loss: nan
Episode: 2381/10000 (23.8100%),                 avg. length: 2251.2,                last time consumption/overall running time: 2461.5764s / 375355.8374 s
env0_first_0:                 episode reward: -13.1000,                 loss: 0.0099
env0_second_0:                 episode reward: 13.1000,                 loss: 0.0096
env1_first_0:                 episode reward: -15.6500,                 loss: nan
env1_second_0:                 episode reward: 15.6500,                 loss: nan
Episode: 2401/10000 (24.0100%),                 avg. length: 2064.25,                last time consumption/overall running time: 2262.4323s / 377618.2697 s
env0_first_0:                 episode reward: -11.8000,                 loss: 0.0098
env0_second_0:                 episode reward: 11.8000,                 loss: 0.0096
env1_first_0:                 episode reward: -14.0000,                 loss: nan
env1_second_0:                 episode reward: 14.0000,                 loss: nan
Episode: 2421/10000 (24.2100%),                 avg. length: 2109.75,                last time consumption/overall running time: 2317.3870s / 379935.6567 s
env0_first_0:                 episode reward: -11.7000,                 loss: 0.0091
env0_second_0:                 episode reward: 11.7000,                 loss: 0.0086
env1_first_0:                 episode reward: -12.0500,                 loss: nan
env1_second_0:                 episode reward: 12.0500,                 loss: nan
Episode: 2441/10000 (24.4100%),                 avg. length: 2131.55,                last time consumption/overall running time: 2364.9938s / 382300.6504 s
env0_first_0:                 episode reward: -16.0000,                 loss: 0.0084
env0_second_0:                 episode reward: 16.0000,                 loss: 0.0081
env1_first_0:                 episode reward: -13.9000,                 loss: nan
env1_second_0:                 episode reward: 13.9000,                 loss: nan
Episode: 2461/10000 (24.6100%),                 avg. length: 2261.45,                last time consumption/overall running time: 2489.5665s / 384790.2169 s
env0_first_0:                 episode reward: -14.6000,                 loss: 0.0093
env0_second_0:                 episode reward: 14.6000,                 loss: 0.0089
env1_first_0:                 episode reward: -15.6500,                 loss: nan
env1_second_0:                 episode reward: 15.6500,                 loss: nan
Episode: 2481/10000 (24.8100%),                 avg. length: 2171.0,                last time consumption/overall running time: 2339.7766s / 387129.9935 s
env0_first_0:                 episode reward: -12.7000,                 loss: 0.0095
env0_second_0:                 episode reward: 12.7000,                 loss: 0.0091
env1_first_0:                 episode reward: -14.8000,                 loss: nan
env1_second_0:                 episode reward: 14.8000,                 loss: nan
Episode: 2501/10000 (25.0100%),                 avg. length: 2124.15,                last time consumption/overall running time: 2297.8982s / 389427.8916 s
env0_first_0:                 episode reward: -15.4000,                 loss: 0.0091
env0_second_0:                 episode reward: 15.4000,                 loss: 0.0087
env1_first_0:                 episode reward: -11.7500,                 loss: nan
env1_second_0:                 episode reward: 11.7500,                 loss: nan
Episode: 2521/10000 (25.2100%),                 avg. length: 2262.3,                last time consumption/overall running time: 2439.3541s / 391867.2458 s
env0_first_0:                 episode reward: -15.5000,                 loss: 0.0085
env0_second_0:                 episode reward: 15.5000,                 loss: 0.0088
env1_first_0:                 episode reward: -14.9500,                 loss: nan
env1_second_0:                 episode reward: 14.9500,                 loss: nan
Episode: 2541/10000 (25.4100%),                 avg. length: 2055.3,                last time consumption/overall running time: 2224.6215s / 394091.8673 s
env0_first_0:                 episode reward: -12.1500,                 loss: 0.0082
env0_second_0:                 episode reward: 12.1500,                 loss: 0.0084
env1_first_0:                 episode reward: -12.1500,                 loss: nan
env1_second_0:                 episode reward: 12.1500,                 loss: nan
Episode: 2561/10000 (25.6100%),                 avg. length: 1918.4,                last time consumption/overall running time: 2079.8991s / 396171.7664 s
env0_first_0:                 episode reward: -10.1500,                 loss: 0.0082
env0_second_0:                 episode reward: 10.1500,                 loss: 0.0085
env1_first_0:                 episode reward: -12.9500,                 loss: nan
env1_second_0:                 episode reward: 12.9500,                 loss: nan
Episode: 2581/10000 (25.8100%),                 avg. length: 2054.2,                last time consumption/overall running time: 2222.6884s / 398394.4548 s
env0_first_0:                 episode reward: -11.2000,                 loss: 0.0087
env0_second_0:                 episode reward: 11.2000,                 loss: 0.0082
env1_first_0:                 episode reward: -12.0500,                 loss: nan
env1_second_0:                 episode reward: 12.0500,                 loss: nan
Episode: 2601/10000 (26.0100%),                 avg. length: 2028.85,                last time consumption/overall running time: 2193.8796s / 400588.3344 s
env0_first_0:                 episode reward: -12.6000,                 loss: 0.0094
env0_second_0:                 episode reward: 12.6000,                 loss: 0.0087
env1_first_0:                 episode reward: -14.2500,                 loss: nan
env1_second_0:                 episode reward: 14.2500,                 loss: nan
Episode: 2621/10000 (26.2100%),                 avg. length: 2008.1,                last time consumption/overall running time: 2152.9298s / 402741.2642 s
env0_first_0:                 episode reward: -11.5000,                 loss: 0.0087
env0_second_0:                 episode reward: 11.5000,                 loss: 0.0087
env1_first_0:                 episode reward: -12.2500,                 loss: nan
env1_second_0:                 episode reward: 12.2500,                 loss: nan
Episode: 2641/10000 (26.4100%),                 avg. length: 2186.0,                last time consumption/overall running time: 2343.7700s / 405085.0342 s
env0_first_0:                 episode reward: -9.0000,                 loss: 0.0080
env0_second_0:                 episode reward: 9.0000,                 loss: 0.0081
env1_first_0:                 episode reward: -9.2500,                 loss: nan
env1_second_0:                 episode reward: 9.2500,                 loss: nan
Episode: 2661/10000 (26.6100%),                 avg. length: 2094.25,                last time consumption/overall running time: 2233.7797s / 407318.8139 s
env0_first_0:                 episode reward: -12.3000,                 loss: 0.0093
env0_second_0:                 episode reward: 12.3000,                 loss: 0.0093
env1_first_0:                 episode reward: -10.8000,                 loss: nan
env1_second_0:                 episode reward: 10.8000,                 loss: nan
Episode: 2681/10000 (26.8100%),                 avg. length: 2257.35,                last time consumption/overall running time: 2371.4404s / 409690.2543 s
env0_first_0:                 episode reward: -9.7500,                 loss: 0.0093
env0_second_0:                 episode reward: 9.7500,                 loss: 0.0092
env1_first_0:                 episode reward: -10.1000,                 loss: nan
env1_second_0:                 episode reward: 10.1000,                 loss: nan
Episode: 2701/10000 (27.0100%),                 avg. length: 2319.55,                last time consumption/overall running time: 2355.5423s / 412045.7966 s
env0_first_0:                 episode reward: -12.3500,                 loss: 0.0093
env0_second_0:                 episode reward: 12.3500,                 loss: 0.0091
env1_first_0:                 episode reward: -11.3500,                 loss: nan
env1_second_0:                 episode reward: 11.3500,                 loss: nan
Episode: 2721/10000 (27.2100%),                 avg. length: 1767.8,                last time consumption/overall running time: 1765.3082s / 413811.1048 s
env0_first_0:                 episode reward: -12.6500,                 loss: 0.0092
env0_second_0:                 episode reward: 12.6500,                 loss: 0.0090
env1_first_0:                 episode reward: -11.1000,                 loss: nan
env1_second_0:                 episode reward: 11.1000,                 loss: nan
Episode: 2741/10000 (27.4100%),                 avg. length: 1910.5,                last time consumption/overall running time: 1918.4217s / 415729.5265 s
env0_first_0:                 episode reward: -12.7000,                 loss: 0.0096
env0_second_0:                 episode reward: 12.7000,                 loss: 0.0084
env1_first_0:                 episode reward: -14.5000,                 loss: nan
env1_second_0:                 episode reward: 14.5000,                 loss: nan
Episode: 2761/10000 (27.6100%),                 avg. length: 2044.5,                last time consumption/overall running time: 2044.2659s / 417773.7923 s
env0_first_0:                 episode reward: -11.1000,                 loss: 0.0086
env0_second_0:                 episode reward: 11.1000,                 loss: 0.0088
env1_first_0:                 episode reward: -12.1000,                 loss: nan
env1_second_0:                 episode reward: 12.1000,                 loss: nan
Episode: 2781/10000 (27.8100%),                 avg. length: 1889.9,                last time consumption/overall running time: 1837.4116s / 419611.2040 s
env0_first_0:                 episode reward: -10.8500,                 loss: 0.0080
env0_second_0:                 episode reward: 10.8500,                 loss: 0.0087
env1_first_0:                 episode reward: -10.9000,                 loss: nan
env1_second_0:                 episode reward: 10.9000,                 loss: nan
Episode: 2801/10000 (28.0100%),                 avg. length: 2137.35,                last time consumption/overall running time: 2074.2838s / 421685.4878 s
env0_first_0:                 episode reward: -10.2000,                 loss: 0.0077
env0_second_0:                 episode reward: 10.2000,                 loss: 0.0087
env1_first_0:                 episode reward: -12.1500,                 loss: nan
env1_second_0:                 episode reward: 12.1500,                 loss: nan
Episode: 2821/10000 (28.2100%),                 avg. length: 2217.15,                last time consumption/overall running time: 2148.9655s / 423834.4533 s
env0_first_0:                 episode reward: -13.6000,                 loss: 0.0080
env0_second_0:                 episode reward: 13.6000,                 loss: 0.0090
env1_first_0:                 episode reward: -13.0500,                 loss: nan
env1_second_0:                 episode reward: 13.0500,                 loss: nan
Episode: 2841/10000 (28.4100%),                 avg. length: 2123.7,                last time consumption/overall running time: 2059.0532s / 425893.5065 s
env0_first_0:                 episode reward: -14.7500,                 loss: 0.0083
env0_second_0:                 episode reward: 14.7500,                 loss: 0.0089
env1_first_0:                 episode reward: -13.2500,                 loss: nan
env1_second_0:                 episode reward: 13.2500,                 loss: nan
Episode: 2861/10000 (28.6100%),                 avg. length: 1891.5,                last time consumption/overall running time: 1834.5024s / 427728.0088 s
env0_first_0:                 episode reward: -13.2500,                 loss: 0.0087
env0_second_0:                 episode reward: 13.2500,                 loss: 0.0085
env1_first_0:                 episode reward: -13.3000,                 loss: nan
env1_second_0:                 episode reward: 13.3000,                 loss: nan
Episode: 2881/10000 (28.8100%),                 avg. length: 1837.15,                last time consumption/overall running time: 1824.1071s / 429552.1160 s
env0_first_0:                 episode reward: -13.9500,                 loss: 0.0085
env0_second_0:                 episode reward: 13.9500,                 loss: 0.0083
env1_first_0:                 episode reward: -11.5500,                 loss: nan
env1_second_0:                 episode reward: 11.5500,                 loss: nan
Episode: 2901/10000 (29.0100%),                 avg. length: 2066.6,                last time consumption/overall running time: 2289.2164s / 431841.3324 s
env0_first_0:                 episode reward: -12.3000,                 loss: 0.0084
env0_second_0:                 episode reward: 12.3000,                 loss: 0.0084
env1_first_0:                 episode reward: -13.9500,                 loss: nan
env1_second_0:                 episode reward: 13.9500,                 loss: nan
Episode: 2921/10000 (29.2100%),                 avg. length: 2129.55,                last time consumption/overall running time: 2345.9625s / 434187.2949 s
env0_first_0:                 episode reward: -10.6000,                 loss: 0.0087
env0_second_0:                 episode reward: 10.6000,                 loss: 0.0085
env1_first_0:                 episode reward: -12.3000,                 loss: nan
env1_second_0:                 episode reward: 12.3000,                 loss: nan
Episode: 2941/10000 (29.4100%),                 avg. length: 2016.1,                last time consumption/overall running time: 2223.4040s / 436410.6989 s
env0_first_0:                 episode reward: -13.3000,                 loss: 0.0092
env0_second_0:                 episode reward: 13.3000,                 loss: 0.0086
env1_first_0:                 episode reward: -11.4500,                 loss: nan
env1_second_0:                 episode reward: 11.4500,                 loss: nan
Episode: 2961/10000 (29.6100%),                 avg. length: 2001.3,                last time consumption/overall running time: 2211.6506s / 438622.3494 s
env0_first_0:                 episode reward: -8.5500,                 loss: 0.0086
env0_second_0:                 episode reward: 8.5500,                 loss: 0.0078
env1_first_0:                 episode reward: -10.0500,                 loss: nan
env1_second_0:                 episode reward: 10.0500,                 loss: nan
Episode: 2981/10000 (29.8100%),                 avg. length: 1971.6,                last time consumption/overall running time: 2174.2683s / 440796.6177 s
env0_first_0:                 episode reward: -13.6000,                 loss: 0.0089
env0_second_0:                 episode reward: 13.6000,                 loss: 0.0077
env1_first_0:                 episode reward: -12.8000,                 loss: nan
env1_second_0:                 episode reward: 12.8000,                 loss: nan
Episode: 3001/10000 (30.0100%),                 avg. length: 1891.25,                last time consumption/overall running time: 2068.6831s / 442865.3008 s
env0_first_0:                 episode reward: -12.0500,                 loss: 0.0088
env0_second_0:                 episode reward: 12.0500,                 loss: 0.0080
env1_first_0:                 episode reward: -11.1500,                 loss: nan
env1_second_0:                 episode reward: 11.1500,                 loss: nan
Episode: 3021/10000 (30.2100%),                 avg. length: 1891.75,                last time consumption/overall running time: 2085.1339s / 444950.4348 s
env0_first_0:                 episode reward: -11.3500,                 loss: 0.0081
env0_second_0:                 episode reward: 11.3500,                 loss: 0.0075
env1_first_0:                 episode reward: -10.5000,                 loss: nan
env1_second_0:                 episode reward: 10.5000,                 loss: nan
Episode: 3041/10000 (30.4100%),                 avg. length: 1893.1,                last time consumption/overall running time: 2077.9253s / 447028.3601 s
env0_first_0:                 episode reward: -9.8000,                 loss: 0.0082
env0_second_0:                 episode reward: 9.8000,                 loss: 0.0075
env1_first_0:                 episode reward: -10.7500,                 loss: nan
env1_second_0:                 episode reward: 10.7500,                 loss: nan
Episode: 3061/10000 (30.6100%),                 avg. length: 1930.5,                last time consumption/overall running time: 2123.1317s / 449151.4918 s
env0_first_0:                 episode reward: -9.7500,                 loss: 0.0084
env0_second_0:                 episode reward: 9.7500,                 loss: 0.0079
env1_first_0:                 episode reward: -10.2500,                 loss: nan
env1_second_0:                 episode reward: 10.2500,                 loss: nan
Episode: 3081/10000 (30.8100%),                 avg. length: 1786.2,                last time consumption/overall running time: 1971.9840s / 451123.4759 s
env0_first_0:                 episode reward: -10.9000,                 loss: 0.0087
env0_second_0:                 episode reward: 10.9000,                 loss: 0.0082
env1_first_0:                 episode reward: -9.9000,                 loss: nan
env1_second_0:                 episode reward: 9.9000,                 loss: nan
Episode: 3101/10000 (31.0100%),                 avg. length: 1698.95,                last time consumption/overall running time: 1861.3324s / 452984.8083 s
env0_first_0:                 episode reward: -9.8000,                 loss: 0.0087
env0_second_0:                 episode reward: 9.8000,                 loss: 0.0080
env1_first_0:                 episode reward: -11.9000,                 loss: nan
env1_second_0:                 episode reward: 11.9000,                 loss: nan
Episode: 3121/10000 (31.2100%),                 avg. length: 1737.6,                last time consumption/overall running time: 1905.9115s / 454890.7198 s
env0_first_0:                 episode reward: -12.7500,                 loss: 0.0084
env0_second_0:                 episode reward: 12.7500,                 loss: 0.0080
env1_first_0:                 episode reward: -12.2000,                 loss: nan
env1_second_0:                 episode reward: 12.2000,                 loss: nan
Episode: 3141/10000 (31.4100%),                 avg. length: 1817.45,                last time consumption/overall running time: 2004.7456s / 456895.4653 s
env0_first_0:                 episode reward: -12.3000,                 loss: 0.0088
env0_second_0:                 episode reward: 12.3000,                 loss: 0.0087
env1_first_0:                 episode reward: -15.0500,                 loss: nan
env1_second_0:                 episode reward: 15.0500,                 loss: nan
Episode: 3161/10000 (31.6100%),                 avg. length: 1876.45,                last time consumption/overall running time: 2064.2414s / 458959.7067 s
env0_first_0:                 episode reward: -10.1500,                 loss: 0.0095
env0_second_0:                 episode reward: 10.1500,                 loss: 0.0092
env1_first_0:                 episode reward: -10.7000,                 loss: nan
env1_second_0:                 episode reward: 10.7000,                 loss: nan
Episode: 3181/10000 (31.8100%),                 avg. length: 1883.7,                last time consumption/overall running time: 2061.8463s / 461021.5530 s
env0_first_0:                 episode reward: -10.6500,                 loss: 0.0084
env0_second_0:                 episode reward: 10.6500,                 loss: 0.0086
env1_first_0:                 episode reward: -10.5000,                 loss: nan
env1_second_0:                 episode reward: 10.5000,                 loss: nan
Episode: 3201/10000 (32.0100%),                 avg. length: 2207.5,                last time consumption/overall running time: 2429.3747s / 463450.9277 s
env0_first_0:                 episode reward: -9.3500,                 loss: 0.0092
env0_second_0:                 episode reward: 9.3500,                 loss: 0.0093
env1_first_0:                 episode reward: -10.2500,                 loss: nan
env1_second_0:                 episode reward: 10.2500,                 loss: nan
Episode: 3221/10000 (32.2100%),                 avg. length: 1900.0,                last time consumption/overall running time: 2093.5830s / 465544.5107 s
env0_first_0:                 episode reward: -11.6000,                 loss: 0.0092
env0_second_0:                 episode reward: 11.6000,                 loss: 0.0092
env1_first_0:                 episode reward: -12.4000,                 loss: nan
env1_second_0:                 episode reward: 12.4000,                 loss: nan
Episode: 3241/10000 (32.4100%),                 avg. length: 1810.05,                last time consumption/overall running time: 2001.9624s / 467546.4731 s
env0_first_0:                 episode reward: -11.1500,                 loss: 0.0084
env0_second_0:                 episode reward: 11.1500,                 loss: 0.0084
env1_first_0:                 episode reward: -11.9000,                 loss: nan
env1_second_0:                 episode reward: 11.9000,                 loss: nan
Episode: 3261/10000 (32.6100%),                 avg. length: 1793.55,                last time consumption/overall running time: 1966.4772s / 469512.9502 s
env0_first_0:                 episode reward: -10.6500,                 loss: 0.0086
env0_second_0:                 episode reward: 10.6500,                 loss: 0.0084
env1_first_0:                 episode reward: -12.6000,                 loss: nan
env1_second_0:                 episode reward: 12.6000,                 loss: nan
Episode: 3281/10000 (32.8100%),                 avg. length: 1843.7,                last time consumption/overall running time: 2005.1158s / 471518.0661 s
env0_first_0:                 episode reward: -9.9500,                 loss: 0.0077
env0_second_0:                 episode reward: 9.9500,                 loss: 0.0080
env1_first_0:                 episode reward: -10.2000,                 loss: nan
env1_second_0:                 episode reward: 10.2000,                 loss: nan
Episode: 3301/10000 (33.0100%),                 avg. length: 2046.15,                last time consumption/overall running time: 3032.8136s / 474550.8797 s
env0_first_0:                 episode reward: -11.1000,                 loss: 0.0086
env0_second_0:                 episode reward: 11.1000,                 loss: 0.0093
env1_first_0:                 episode reward: -13.3000,                 loss: nan
env1_second_0:                 episode reward: 13.3000,                 loss: nan
Episode: 3321/10000 (33.2100%),                 avg. length: 1861.4,                last time consumption/overall running time: 2785.1182s / 477335.9979 s
env0_first_0:                 episode reward: -12.6500,                 loss: 0.0090
env0_second_0:                 episode reward: 12.6500,                 loss: 0.0102
env1_first_0:                 episode reward: -12.5500,                 loss: nan
env1_second_0:                 episode reward: 12.5500,                 loss: nan
Episode: 3341/10000 (33.4100%),                 avg. length: 1785.6,                last time consumption/overall running time: 2637.3551s / 479973.3530 s
env0_first_0:                 episode reward: -15.8000,                 loss: 0.0082
env0_second_0:                 episode reward: 15.8000,                 loss: 0.0091
env1_first_0:                 episode reward: -14.2500,                 loss: nan
env1_second_0:                 episode reward: 14.2500,                 loss: nan
Episode: 3361/10000 (33.6100%),                 avg. length: 1645.15,                last time consumption/overall running time: 2417.7446s / 482391.0976 s
env0_first_0:                 episode reward: -14.4000,                 loss: 0.0077
env0_second_0:                 episode reward: 14.4000,                 loss: 0.0081
env1_first_0:                 episode reward: -12.6500,                 loss: nan
env1_second_0:                 episode reward: 12.6500,                 loss: nan
Episode: 3381/10000 (33.8100%),                 avg. length: 1647.3,                last time consumption/overall running time: 2421.6387s / 484812.7362 s
env0_first_0:                 episode reward: -13.7000,                 loss: 0.0072
env0_second_0:                 episode reward: 13.7000,                 loss: 0.0073
env1_first_0:                 episode reward: -12.5500,                 loss: nan
env1_second_0:                 episode reward: 12.5500,                 loss: nan
Episode: 3401/10000 (34.0100%),                 avg. length: 1702.3,                last time consumption/overall running time: 2461.2491s / 487273.9853 s
env0_first_0:                 episode reward: -12.3500,                 loss: 0.0074
env0_second_0:                 episode reward: 12.3500,                 loss: 0.0077
env1_first_0:                 episode reward: -14.0500,                 loss: nan
env1_second_0:                 episode reward: 14.0500,                 loss: nan
Episode: 3421/10000 (34.2100%),                 avg. length: 1605.55,                last time consumption/overall running time: 2331.7981s / 489605.7835 s
env0_first_0:                 episode reward: -15.3000,                 loss: 0.0075
env0_second_0:                 episode reward: 15.3000,                 loss: 0.0076
env1_first_0:                 episode reward: -12.6500,                 loss: nan
env1_second_0:                 episode reward: 12.6500,                 loss: nan
Episode: 3441/10000 (34.4100%),                 avg. length: 1646.45,                last time consumption/overall running time: 2390.5283s / 491996.3118 s
env0_first_0:                 episode reward: -13.6000,                 loss: 0.0074
env0_second_0:                 episode reward: 13.6000,                 loss: 0.0075
env1_first_0:                 episode reward: -14.3500,                 loss: nan
env1_second_0:                 episode reward: 14.3500,                 loss: nan
Episode: 3461/10000 (34.6100%),                 avg. length: 1569.2,                last time consumption/overall running time: 2288.8966s / 494285.2084 s
env0_first_0:                 episode reward: -11.6500,                 loss: 0.0068
env0_second_0:                 episode reward: 11.6500,                 loss: 0.0072
env1_first_0:                 episode reward: -12.4000,                 loss: nan
env1_second_0:                 episode reward: 12.4000,                 loss: nan
Episode: 3481/10000 (34.8100%),                 avg. length: 1773.45,                last time consumption/overall running time: 2548.0854s / 496833.2938 s
env0_first_0:                 episode reward: -11.8000,                 loss: 0.0083
env0_second_0:                 episode reward: 11.8000,                 loss: 0.0062
env1_first_0:                 episode reward: -14.2000,                 loss: nan
env1_second_0:                 episode reward: 14.2000,                 loss: nan
Episode: 3501/10000 (35.0100%),                 avg. length: 1853.1,                last time consumption/overall running time: 2647.6021s / 499480.8959 s
env0_first_0:                 episode reward: -13.3500,                 loss: 0.0083
env0_second_0:                 episode reward: 13.3500,                 loss: 0.0072
env1_first_0:                 episode reward: -15.0500,                 loss: nan
env1_second_0:                 episode reward: 15.0500,                 loss: nan
Episode: 3521/10000 (35.2100%),                 avg. length: 1544.6,                last time consumption/overall running time: 2208.3794s / 501689.2753 s
env0_first_0:                 episode reward: -14.8500,                 loss: 0.0070
env0_second_0:                 episode reward: 14.8500,                 loss: 0.0074
env1_first_0:                 episode reward: -14.5500,                 loss: nan
env1_second_0:                 episode reward: 14.5500,                 loss: nan
Episode: 3541/10000 (35.4100%),                 avg. length: 1563.85,                last time consumption/overall running time: 2238.9856s / 503928.2609 s
env0_first_0:                 episode reward: -11.3000,                 loss: 0.0068
env0_second_0:                 episode reward: 11.3000,                 loss: 0.0069
env1_first_0:                 episode reward: -12.2500,                 loss: nan
env1_second_0:                 episode reward: 12.2500,                 loss: nan
Episode: 3561/10000 (35.6100%),                 avg. length: 1680.05,                last time consumption/overall running time: 2395.3999s / 506323.6608 s
env0_first_0:                 episode reward: -10.2000,                 loss: 0.0072
env0_second_0:                 episode reward: 10.2000,                 loss: 0.0069
env1_first_0:                 episode reward: -10.1500,                 loss: nan
env1_second_0:                 episode reward: 10.1500,                 loss: nan
Episode: 3581/10000 (35.8100%),                 avg. length: 1565.65,                last time consumption/overall running time: 2195.4632s / 508519.1240 s
env0_first_0:                 episode reward: -12.3000,                 loss: 0.0065
env0_second_0:                 episode reward: 12.3000,                 loss: 0.0065
env1_first_0:                 episode reward: -10.6000,                 loss: nan
env1_second_0:                 episode reward: 10.6000,                 loss: nan
Episode: 3601/10000 (36.0100%),                 avg. length: 1612.1,                last time consumption/overall running time: 2260.4454s / 510779.5694 s
env0_first_0:                 episode reward: -10.2500,                 loss: 0.0066
env0_second_0:                 episode reward: 10.2500,                 loss: 0.0062
env1_first_0:                 episode reward: -12.0000,                 loss: nan
env1_second_0:                 episode reward: 12.0000,                 loss: nan
Episode: 3621/10000 (36.2100%),                 avg. length: 1824.35,                last time consumption/overall running time: 2538.9177s / 513318.4871 s
env0_first_0:                 episode reward: -11.1500,                 loss: 0.0078
env0_second_0:                 episode reward: 11.1500,                 loss: 0.0076
env1_first_0:                 episode reward: -10.0500,                 loss: nan
env1_second_0:                 episode reward: 10.0500,                 loss: nan
Episode: 3641/10000 (36.4100%),                 avg. length: 1843.35,                last time consumption/overall running time: 2586.1847s / 515904.6717 s
env0_first_0:                 episode reward: -11.6500,                 loss: 0.0092
env0_second_0:                 episode reward: 11.6500,                 loss: 0.0083
env1_first_0:                 episode reward: -11.5000,                 loss: nan
env1_second_0:                 episode reward: 11.5000,                 loss: nan
Episode: 3661/10000 (36.6100%),                 avg. length: 1609.75,                last time consumption/overall running time: 2275.0008s / 518179.6725 s
env0_first_0:                 episode reward: -11.4000,                 loss: 0.0087
env0_second_0:                 episode reward: 11.4000,                 loss: 0.0079
env1_first_0:                 episode reward: -11.9500,                 loss: nan
env1_second_0:                 episode reward: 11.9500,                 loss: nan
Episode: 3681/10000 (36.8100%),                 avg. length: 1666.45,                last time consumption/overall running time: 2326.7791s / 520506.4517 s
env0_first_0:                 episode reward: -11.9500,                 loss: 0.0077
env0_second_0:                 episode reward: 11.9500,                 loss: 0.0071
env1_first_0:                 episode reward: -9.6000,                 loss: nan
env1_second_0:                 episode reward: 9.6000,                 loss: nan
Episode: 3701/10000 (37.0100%),                 avg. length: 1907.75,                last time consumption/overall running time: 2643.1402s / 523149.5919 s
env0_first_0:                 episode reward: -11.2000,                 loss: 0.0086
env0_second_0:                 episode reward: 11.2000,                 loss: 0.0086
env1_first_0:                 episode reward: -12.0500,                 loss: nan
env1_second_0:                 episode reward: 12.0500,                 loss: nan
Episode: 3721/10000 (37.2100%),                 avg. length: 1912.85,                last time consumption/overall running time: 2583.7217s / 525733.3135 s
env0_first_0:                 episode reward: -12.0500,                 loss: 0.0100
env0_second_0:                 episode reward: 12.0500,                 loss: 0.0096
env1_first_0:                 episode reward: -10.8000,                 loss: nan
env1_second_0:                 episode reward: 10.8000,                 loss: nan
Episode: 3741/10000 (37.4100%),                 avg. length: 1804.15,                last time consumption/overall running time: 2422.5295s / 528155.8431 s
env0_first_0:                 episode reward: -12.9000,                 loss: 0.0093
env0_second_0:                 episode reward: 12.9000,                 loss: 0.0088
env1_first_0:                 episode reward: -13.9500,                 loss: nan
env1_second_0:                 episode reward: 13.9500,                 loss: nan
Episode: 3761/10000 (37.6100%),                 avg. length: 1761.55,                last time consumption/overall running time: 2364.5461s / 530520.3891 s
env0_first_0:                 episode reward: -11.8000,                 loss: 0.0086
env0_second_0:                 episode reward: 11.8000,                 loss: 0.0081
env1_first_0:                 episode reward: -9.5500,                 loss: nan
env1_second_0:                 episode reward: 9.5500,                 loss: nan
Episode: 3781/10000 (37.8100%),                 avg. length: 2027.9,                last time consumption/overall running time: 2741.6532s / 533262.0423 s
env0_first_0:                 episode reward: -11.6500,                 loss: 0.0089
env0_second_0:                 episode reward: 11.6500,                 loss: 0.0086
env1_first_0:                 episode reward: -11.1000,                 loss: nan
env1_second_0:                 episode reward: 11.1000,                 loss: nan
Episode: 3801/10000 (38.0100%),                 avg. length: 1961.0,                last time consumption/overall running time: 2666.1040s / 535928.1463 s
env0_first_0:                 episode reward: -12.9000,                 loss: 0.0098
env0_second_0:                 episode reward: 12.9000,                 loss: 0.0093
env1_first_0:                 episode reward: -14.5000,                 loss: nan
env1_second_0:                 episode reward: 14.5000,                 loss: nan
Episode: 3821/10000 (38.2100%),                 avg. length: 1644.65,                last time consumption/overall running time: 2205.1127s / 538133.2589 s
env0_first_0:                 episode reward: -10.8000,                 loss: 0.0099
env0_second_0:                 episode reward: 10.8000,                 loss: 0.0091
env1_first_0:                 episode reward: -12.5500,                 loss: nan
env1_second_0:                 episode reward: 12.5500,                 loss: nan
Episode: 3841/10000 (38.4100%),                 avg. length: 1620.9,                last time consumption/overall running time: 2171.7462s / 540305.0052 s
env0_first_0:                 episode reward: -13.0000,                 loss: 0.0089
env0_second_0:                 episode reward: 13.0000,                 loss: 0.0085
env1_first_0:                 episode reward: -11.6000,                 loss: nan
env1_second_0:                 episode reward: 11.6000,                 loss: nan
Episode: 3861/10000 (38.6100%),                 avg. length: 1672.35,                last time consumption/overall running time: 2235.6113s / 542540.6165 s
env0_first_0:                 episode reward: -11.6000,                 loss: 0.0081
env0_second_0:                 episode reward: 11.6000,                 loss: 0.0080
env1_first_0:                 episode reward: -14.2000,                 loss: nan
env1_second_0:                 episode reward: 14.2000,                 loss: nan
Episode: 3881/10000 (38.8100%),                 avg. length: 1880.8,                last time consumption/overall running time: 2517.5258s / 545058.1423 s
env0_first_0:                 episode reward: -14.6500,                 loss: 0.0086
env0_second_0:                 episode reward: 14.6500,                 loss: 0.0083
env1_first_0:                 episode reward: -14.2500,                 loss: nan
env1_second_0:                 episode reward: 14.2500,                 loss: nan
Episode: 3901/10000 (39.0100%),                 avg. length: 1799.95,                last time consumption/overall running time: 2363.9297s / 547422.0720 s
env0_first_0:                 episode reward: -18.0500,                 loss: 0.0093
env0_second_0:                 episode reward: 18.0500,                 loss: 0.0084
env1_first_0:                 episode reward: -13.6500,                 loss: nan
env1_second_0:                 episode reward: 13.6500,                 loss: nan
Episode: 3921/10000 (39.2100%),                 avg. length: 1641.2,                last time consumption/overall running time: 2118.6808s / 549540.7528 s
env0_first_0:                 episode reward: -13.5000,                 loss: 0.0088
env0_second_0:                 episode reward: 13.5000,                 loss: 0.0082
env1_first_0:                 episode reward: -14.4500,                 loss: nan
env1_second_0:                 episode reward: 14.4500,                 loss: nan
Episode: 3941/10000 (39.4100%),                 avg. length: 1665.55,                last time consumption/overall running time: 2163.6847s / 551704.4376 s
env0_first_0:                 episode reward: -12.3000,                 loss: 0.0078
env0_second_0:                 episode reward: 12.3000,                 loss: 0.0074
env1_first_0:                 episode reward: -14.6500,                 loss: nan
env1_second_0:                 episode reward: 14.6500,                 loss: nan
Episode: 3961/10000 (39.6100%),                 avg. length: 1735.9,                last time consumption/overall running time: 2235.0350s / 553939.4725 s
env0_first_0:                 episode reward: -11.3500,                 loss: 0.0075
env0_second_0:                 episode reward: 11.3500,                 loss: 0.0071
env1_first_0:                 episode reward: -11.3500,                 loss: nan
env1_second_0:                 episode reward: 11.3500,                 loss: nan
Episode: 3981/10000 (39.8100%),                 avg. length: 1739.7,                last time consumption/overall running time: 2234.9912s / 556174.4637 s
env0_first_0:                 episode reward: -13.8000,                 loss: 0.0077
env0_second_0:                 episode reward: 13.8000,                 loss: 0.0074
env1_first_0:                 episode reward: -13.4000,                 loss: nan
env1_second_0:                 episode reward: 13.4000,                 loss: nan
Episode: 4001/10000 (40.0100%),                 avg. length: 1659.75,                last time consumption/overall running time: 2119.7953s / 558294.2590 s
env0_first_0:                 episode reward: -14.3500,                 loss: 0.0080
env0_second_0:                 episode reward: 14.3500,                 loss: 0.0081
env1_first_0:                 episode reward: -14.9500,                 loss: nan
env1_second_0:                 episode reward: 14.9500,                 loss: nan
Episode: 4021/10000 (40.2100%),                 avg. length: 1700.85,                last time consumption/overall running time: 2165.6272s / 560459.8862 s
env0_first_0:                 episode reward: -15.4000,                 loss: 0.0073
env0_second_0:                 episode reward: 15.4000,                 loss: 0.0077
env1_first_0:                 episode reward: -14.5000,                 loss: nan
env1_second_0:                 episode reward: 14.5000,                 loss: nan
Episode: 4041/10000 (40.4100%),                 avg. length: 1773.75,                last time consumption/overall running time: 2236.3096s / 562696.1958 s
env0_first_0:                 episode reward: -13.1000,                 loss: 0.0076
env0_second_0:                 episode reward: 13.1000,                 loss: 0.0080
env1_first_0:                 episode reward: -11.1500,                 loss: nan
env1_second_0:                 episode reward: 11.1500,                 loss: nan
Episode: 4061/10000 (40.6100%),                 avg. length: 1743.3,                last time consumption/overall running time: 2210.2295s / 564906.4253 s
env0_first_0:                 episode reward: -14.0000,                 loss: 0.0079
env0_second_0:                 episode reward: 14.0000,                 loss: 0.0080
env1_first_0:                 episode reward: -13.3500,                 loss: nan
env1_second_0:                 episode reward: 13.3500,                 loss: nan
Episode: 4081/10000 (40.8100%),                 avg. length: 1688.5,                last time consumption/overall running time: 2111.9985s / 567018.4238 s
env0_first_0:                 episode reward: -14.6500,                 loss: 0.0080
env0_second_0:                 episode reward: 14.6500,                 loss: 0.0083
env1_first_0:                 episode reward: -12.7500,                 loss: nan
env1_second_0:                 episode reward: 12.7500,                 loss: nan
Episode: 4101/10000 (41.0100%),                 avg. length: 1862.1,                last time consumption/overall running time: 2341.8913s / 569360.3151 s
env0_first_0:                 episode reward: -13.5500,                 loss: 0.0080
env0_second_0:                 episode reward: 13.5500,                 loss: 0.0086
env1_first_0:                 episode reward: -12.8000,                 loss: nan
env1_second_0:                 episode reward: 12.8000,                 loss: nan
Episode: 4121/10000 (41.2100%),                 avg. length: 1717.6,                last time consumption/overall running time: 2158.5785s / 571518.8936 s
env0_first_0:                 episode reward: -12.3000,                 loss: 0.0079
env0_second_0:                 episode reward: 12.3000,                 loss: 0.0088
env1_first_0:                 episode reward: -12.3000,                 loss: nan
env1_second_0:                 episode reward: 12.3000,                 loss: nan
Episode: 4141/10000 (41.4100%),                 avg. length: 1783.55,                last time consumption/overall running time: 2239.7052s / 573758.5988 s
env0_first_0:                 episode reward: -12.5000,                 loss: 0.0082
env0_second_0:                 episode reward: 12.5000,                 loss: 0.0087
env1_first_0:                 episode reward: -11.3000,                 loss: nan
env1_second_0:                 episode reward: 11.3000,                 loss: nan
Episode: 4161/10000 (41.6100%),                 avg. length: 1654.35,                last time consumption/overall running time: 2059.7825s / 575818.3813 s
env0_first_0:                 episode reward: -14.3000,                 loss: 0.0080
env0_second_0:                 episode reward: 14.3000,                 loss: 0.0086
env1_first_0:                 episode reward: -13.4500,                 loss: nan
env1_second_0:                 episode reward: 13.4500,                 loss: nan
Episode: 4181/10000 (41.8100%),                 avg. length: 1756.4,                last time consumption/overall running time: 2186.6272s / 578005.0085 s
env0_first_0:                 episode reward: -11.9000,                 loss: 0.0076
env0_second_0:                 episode reward: 11.9000,                 loss: 0.0088
env1_first_0:                 episode reward: -12.7500,                 loss: nan
env1_second_0:                 episode reward: 12.7500,                 loss: nan
Episode: 4201/10000 (42.0100%),                 avg. length: 1762.0,                last time consumption/overall running time: 2176.8124s / 580181.8209 s
env0_first_0:                 episode reward: -11.6000,                 loss: 0.0083
env0_second_0:                 episode reward: 11.6000,                 loss: 0.0096
env1_first_0:                 episode reward: -11.6500,                 loss: nan
env1_second_0:                 episode reward: 11.6500,                 loss: nan
Episode: 4221/10000 (42.2100%),                 avg. length: 1909.25,                last time consumption/overall running time: 2304.1255s / 582485.9464 s
env0_first_0:                 episode reward: -10.7500,                 loss: 0.0089
env0_second_0:                 episode reward: 10.7500,                 loss: 0.0102
env1_first_0:                 episode reward: -11.5500,                 loss: nan
env1_second_0:                 episode reward: 11.5500,                 loss: nan
Episode: 4241/10000 (42.4100%),                 avg. length: 1798.7,                last time consumption/overall running time: 2164.3775s / 584650.3239 s
env0_first_0:                 episode reward: -12.3000,                 loss: 0.0093
env0_second_0:                 episode reward: 12.3000,                 loss: 0.0101
env1_first_0:                 episode reward: -12.6500,                 loss: nan
env1_second_0:                 episode reward: 12.6500,                 loss: nan
Episode: 4261/10000 (42.6100%),                 avg. length: 1761.1,                last time consumption/overall running time: 2130.5753s / 586780.8992 s
env0_first_0:                 episode reward: -12.5000,                 loss: 0.0095
env0_second_0:                 episode reward: 12.5000,                 loss: 0.0105
env1_first_0:                 episode reward: -13.3000,                 loss: nan
env1_second_0:                 episode reward: 13.3000,                 loss: nan
Episode: 4281/10000 (42.8100%),                 avg. length: 1664.15,                last time consumption/overall running time: 1975.1408s / 588756.0401 s
env0_first_0:                 episode reward: -11.9500,                 loss: 0.0089
env0_second_0:                 episode reward: 11.9500,                 loss: 0.0092
env1_first_0:                 episode reward: -14.0000,                 loss: nan
env1_second_0:                 episode reward: 14.0000,                 loss: nan
Episode: 4301/10000 (43.0100%),                 avg. length: 1740.55,                last time consumption/overall running time: 2079.7886s / 590835.8287 s
env0_first_0:                 episode reward: -13.1000,                 loss: 0.0086
env0_second_0:                 episode reward: 13.1000,                 loss: 0.0083
env1_first_0:                 episode reward: -14.2000,                 loss: nan
env1_second_0:                 episode reward: 14.2000,                 loss: nan
Episode: 4321/10000 (43.2100%),                 avg. length: 1670.45,                last time consumption/overall running time: 1989.9129s / 592825.7416 s
env0_first_0:                 episode reward: -13.0000,                 loss: 0.0084
env0_second_0:                 episode reward: 13.0000,                 loss: 0.0089
env1_first_0:                 episode reward: -14.7000,                 loss: nan
env1_second_0:                 episode reward: 14.7000,                 loss: nan
Episode: 4341/10000 (43.4100%),                 avg. length: 1821.55,                last time consumption/overall running time: 2119.3284s / 594945.0700 s
env0_first_0:                 episode reward: -13.6000,                 loss: 0.0086
env0_second_0:                 episode reward: 13.6000,                 loss: 0.0092
env1_first_0:                 episode reward: -14.0000,                 loss: nan
env1_second_0:                 episode reward: 14.0000,                 loss: nan
Episode: 4361/10000 (43.6100%),                 avg. length: 1690.0,                last time consumption/overall running time: 1935.4469s / 596880.5169 s
env0_first_0:                 episode reward: -11.3500,                 loss: 0.0085
env0_second_0:                 episode reward: 11.3500,                 loss: 0.0094
env1_first_0:                 episode reward: -14.8000,                 loss: nan
env1_second_0:                 episode reward: 14.8000,                 loss: nan
Episode: 4381/10000 (43.8100%),                 avg. length: 1670.6,                last time consumption/overall running time: 1890.0219s / 598770.5388 s
env0_first_0:                 episode reward: -12.4500,                 loss: 0.0080
env0_second_0:                 episode reward: 12.4500,                 loss: 0.0086
env1_first_0:                 episode reward: -13.1000,                 loss: nan
env1_second_0:                 episode reward: 13.1000,                 loss: nan
Episode: 4401/10000 (44.0100%),                 avg. length: 1903.6,                last time consumption/overall running time: 2153.6010s / 600924.1398 s
env0_first_0:                 episode reward: -12.9000,                 loss: 0.0082
env0_second_0:                 episode reward: 12.9000,                 loss: 0.0091
env1_first_0:                 episode reward: -12.8500,                 loss: nan
env1_second_0:                 episode reward: 12.8500,                 loss: nan
Episode: 4421/10000 (44.2100%),                 avg. length: 1728.6,                last time consumption/overall running time: 1965.1226s / 602889.2624 s
env0_first_0:                 episode reward: -14.0500,                 loss: 0.0097
env0_second_0:                 episode reward: 14.0500,                 loss: 0.0104
env1_first_0:                 episode reward: -13.0500,                 loss: nan
env1_second_0:                 episode reward: 13.0500,                 loss: nan
Episode: 4441/10000 (44.4100%),                 avg. length: 1743.2,                last time consumption/overall running time: 1958.5540s / 604847.8164 s
env0_first_0:                 episode reward: -10.4000,                 loss: 0.0094
env0_second_0:                 episode reward: 10.4000,                 loss: 0.0099
env1_first_0:                 episode reward: -12.4500,                 loss: nan
env1_second_0:                 episode reward: 12.4500,                 loss: nan
Episode: 4461/10000 (44.6100%),                 avg. length: 1625.4,                last time consumption/overall running time: 1816.0247s / 606663.8411 s
env0_first_0:                 episode reward: -12.0500,                 loss: 0.0090
env0_second_0:                 episode reward: 12.0500,                 loss: 0.0094
env1_first_0:                 episode reward: -13.4500,                 loss: nan
env1_second_0:                 episode reward: 13.4500,                 loss: nan
Episode: 4481/10000 (44.8100%),                 avg. length: 1709.1,                last time consumption/overall running time: 1885.8605s / 608549.7015 s
env0_first_0:                 episode reward: -13.1500,                 loss: 0.0088
env0_second_0:                 episode reward: 13.1500,                 loss: 0.0089
env1_first_0:                 episode reward: -12.5500,                 loss: nan
env1_second_0:                 episode reward: 12.5500,                 loss: nan
Episode: 4501/10000 (45.0100%),                 avg. length: 1852.7,                last time consumption/overall running time: 2005.4876s / 610555.1891 s
env0_first_0:                 episode reward: -11.4500,                 loss: 0.0090
env0_second_0:                 episode reward: 11.4500,                 loss: 0.0092
env1_first_0:                 episode reward: -10.6500,                 loss: nan
env1_second_0:                 episode reward: 10.6500,                 loss: nan
Episode: 4521/10000 (45.2100%),                 avg. length: 1768.45,                last time consumption/overall running time: 1908.0480s / 612463.2371 s
env0_first_0:                 episode reward: -13.1000,                 loss: 0.0095
env0_second_0:                 episode reward: 13.1000,                 loss: 0.0100
env1_first_0:                 episode reward: -9.5000,                 loss: nan
env1_second_0:                 episode reward: 9.5000,                 loss: nan
Episode: 4541/10000 (45.4100%),                 avg. length: 1758.65,                last time consumption/overall running time: 1901.9016s / 614365.1387 s
env0_first_0:                 episode reward: -12.3000,                 loss: 0.0096
env0_second_0:                 episode reward: 12.3000,                 loss: 0.0096
env1_first_0:                 episode reward: -10.8000,                 loss: nan
env1_second_0:                 episode reward: 10.8000,                 loss: nan
Episode: 4561/10000 (45.6100%),                 avg. length: 1736.3,                last time consumption/overall running time: 1922.2981s / 616287.4368 s
env0_first_0:                 episode reward: -14.2500,                 loss: 0.0095
env0_second_0:                 episode reward: 14.2500,                 loss: 0.0093
env1_first_0:                 episode reward: -13.7000,                 loss: nan
env1_second_0:                 episode reward: 13.7000,                 loss: nan
Episode: 4581/10000 (45.8100%),                 avg. length: 1820.1,                last time consumption/overall running time: 2033.6100s / 618321.0468 s
env0_first_0:                 episode reward: -13.2000,                 loss: 0.0103
env0_second_0:                 episode reward: 13.2000,                 loss: 0.0104
env1_first_0:                 episode reward: -14.8500,                 loss: nan
env1_second_0:                 episode reward: 14.8500,                 loss: nan
Episode: 4601/10000 (46.0100%),                 avg. length: 1780.1,                last time consumption/overall running time: 1969.0764s / 620290.1231 s
env0_first_0:                 episode reward: -13.5500,                 loss: 0.0106
env0_second_0:                 episode reward: 13.5500,                 loss: 0.0116
env1_first_0:                 episode reward: -13.6000,                 loss: nan
env1_second_0:                 episode reward: 13.6000,                 loss: nan
Episode: 4621/10000 (46.2100%),                 avg. length: 1743.55,                last time consumption/overall running time: 1912.3619s / 622202.4851 s
env0_first_0:                 episode reward: -13.1000,                 loss: 0.0103
env0_second_0:                 episode reward: 13.1000,                 loss: 0.0106
env1_first_0:                 episode reward: -12.1500,                 loss: nan
env1_second_0:                 episode reward: 12.1500,                 loss: nan
Episode: 4641/10000 (46.4100%),                 avg. length: 1681.85,                last time consumption/overall running time: 1782.8293s / 623985.3144 s
env0_first_0:                 episode reward: -12.0500,                 loss: 0.0094
env0_second_0:                 episode reward: 12.0500,                 loss: 0.0103
env1_first_0:                 episode reward: -11.9500,                 loss: nan
env1_second_0:                 episode reward: 11.9500,                 loss: nan
Episode: 4661/10000 (46.6100%),                 avg. length: 1764.25,                last time consumption/overall running time: 1875.8720s / 625861.1864 s
env0_first_0:                 episode reward: -13.0500,                 loss: 0.0085
env0_second_0:                 episode reward: 13.0500,                 loss: 0.0093
env1_first_0:                 episode reward: -12.4500,                 loss: nan
env1_second_0:                 episode reward: 12.4500,                 loss: nan
Episode: 4681/10000 (46.8100%),                 avg. length: 1640.95,                last time consumption/overall running time: 1751.5476s / 627612.7340 s
env0_first_0:                 episode reward: -10.8500,                 loss: 0.0080
env0_second_0:                 episode reward: 10.8500,                 loss: 0.0089
env1_first_0:                 episode reward: -13.6000,                 loss: nan
env1_second_0:                 episode reward: 13.6000,                 loss: nan
Episode: 4701/10000 (47.0100%),                 avg. length: 1774.0,                last time consumption/overall running time: 1879.6366s / 629492.3706 s
env0_first_0:                 episode reward: -13.4000,                 loss: 0.0080
env0_second_0:                 episode reward: 13.4000,                 loss: 0.0088
env1_first_0:                 episode reward: -12.3500,                 loss: nan
env1_second_0:                 episode reward: 12.3500,                 loss: nan
Episode: 4721/10000 (47.2100%),                 avg. length: 1716.5,                last time consumption/overall running time: 1819.1562s / 631311.5268 s
env0_first_0:                 episode reward: -14.3500,                 loss: 0.0082
env0_second_0:                 episode reward: 14.3500,                 loss: 0.0089
env1_first_0:                 episode reward: -12.2500,                 loss: nan
env1_second_0:                 episode reward: 12.2500,                 loss: nan
Episode: 4741/10000 (47.4100%),                 avg. length: 1798.0,                last time consumption/overall running time: 1897.2986s / 633208.8254 s
env0_first_0:                 episode reward: -12.6500,                 loss: 0.0084
env0_second_0:                 episode reward: 12.6500,                 loss: 0.0089
env1_first_0:                 episode reward: -13.7500,                 loss: nan
env1_second_0:                 episode reward: 13.7500,                 loss: nan
Episode: 4761/10000 (47.6100%),                 avg. length: 1836.3,                last time consumption/overall running time: 1922.9349s / 635131.7603 s
env0_first_0:                 episode reward: -16.7000,                 loss: 0.0090
env0_second_0:                 episode reward: 16.7000,                 loss: 0.0091
env1_first_0:                 episode reward: -16.2000,                 loss: nan
env1_second_0:                 episode reward: 16.2000,                 loss: nan
Episode: 4781/10000 (47.8100%),                 avg. length: 1845.35,                last time consumption/overall running time: 1924.1747s / 637055.9350 s
env0_first_0:                 episode reward: -12.1500,                 loss: 0.0088
env0_second_0:                 episode reward: 12.1500,                 loss: 0.0098
env1_first_0:                 episode reward: -15.6000,                 loss: nan
env1_second_0:                 episode reward: 15.6000,                 loss: nan
Episode: 4801/10000 (48.0100%),                 avg. length: 1962.1,                last time consumption/overall running time: 2010.1635s / 639066.0986 s
env0_first_0:                 episode reward: -12.6500,                 loss: 0.0093
env0_second_0:                 episode reward: 12.6500,                 loss: 0.0099
env1_first_0:                 episode reward: -10.7000,                 loss: nan
env1_second_0:                 episode reward: 10.7000,                 loss: nan
Episode: 4821/10000 (48.2100%),                 avg. length: 1885.05,                last time consumption/overall running time: 1923.6217s / 640989.7202 s
env0_first_0:                 episode reward: -14.1000,                 loss: 0.0095
env0_second_0:                 episode reward: 14.1000,                 loss: 0.0100
env1_first_0:                 episode reward: -11.1500,                 loss: nan
env1_second_0:                 episode reward: 11.1500,                 loss: nan
Episode: 4841/10000 (48.4100%),                 avg. length: 1961.2,                last time consumption/overall running time: 1981.4485s / 642971.1687 s
env0_first_0:                 episode reward: -12.6500,                 loss: 0.0094
env0_second_0:                 episode reward: 12.6500,                 loss: 0.0099
env1_first_0:                 episode reward: -11.2000,                 loss: nan
env1_second_0:                 episode reward: 11.2000,                 loss: nan
Episode: 4861/10000 (48.6100%),                 avg. length: 1811.85,                last time consumption/overall running time: 1833.6220s / 644804.7908 s
env0_first_0:                 episode reward: -13.2500,                 loss: 0.0089
env0_second_0:                 episode reward: 13.2500,                 loss: 0.0097
env1_first_0:                 episode reward: -11.6000,                 loss: nan
env1_second_0:                 episode reward: 11.6000,                 loss: nan
Episode: 4881/10000 (48.8100%),                 avg. length: 1734.4,                last time consumption/overall running time: 1757.0426s / 646561.8334 s
env0_first_0:                 episode reward: -13.5000,                 loss: 0.0081
env0_second_0:                 episode reward: 13.5000,                 loss: 0.0087
env1_first_0:                 episode reward: -14.5500,                 loss: nan
env1_second_0:                 episode reward: 14.5500,                 loss: nan
Episode: 4901/10000 (49.0100%),                 avg. length: 1861.95,                last time consumption/overall running time: 1864.1429s / 648425.9763 s
env0_first_0:                 episode reward: -16.8500,                 loss: 0.0078
env0_second_0:                 episode reward: 16.8500,                 loss: 0.0086
env1_first_0:                 episode reward: -14.5000,                 loss: nan
env1_second_0:                 episode reward: 14.5000,                 loss: nan
Episode: 4921/10000 (49.2100%),                 avg. length: 1727.3,                last time consumption/overall running time: 1737.9880s / 650163.9643 s
env0_first_0:                 episode reward: -14.8000,                 loss: 0.0077
env0_second_0:                 episode reward: 14.8000,                 loss: 0.0085
env1_first_0:                 episode reward: -14.9000,                 loss: nan
env1_second_0:                 episode reward: 14.9000,                 loss: nan
Episode: 4941/10000 (49.4100%),                 avg. length: 1733.95,                last time consumption/overall running time: 1726.1947s / 651890.1590 s
env0_first_0:                 episode reward: -14.6000,                 loss: 0.0077
env0_second_0:                 episode reward: 14.6000,                 loss: 0.0084
env1_first_0:                 episode reward: -13.7000,                 loss: nan
env1_second_0:                 episode reward: 13.7000,                 loss: nan
Episode: 4961/10000 (49.6100%),                 avg. length: 1759.9,                last time consumption/overall running time: 1751.3800s / 653641.5390 s
env0_first_0:                 episode reward: -14.1000,                 loss: 0.0085
env0_second_0:                 episode reward: 14.1000,                 loss: 0.0087
env1_first_0:                 episode reward: -13.4000,                 loss: nan
env1_second_0:                 episode reward: 13.4000,                 loss: nan
Episode: 4981/10000 (49.8100%),                 avg. length: 1642.75,                last time consumption/overall running time: 1639.3503s / 655280.8893 s
env0_first_0:                 episode reward: -15.9500,                 loss: 0.0085
env0_second_0:                 episode reward: 15.9500,                 loss: 0.0089
env1_first_0:                 episode reward: -14.5500,                 loss: nan
env1_second_0:                 episode reward: 14.5500,                 loss: nan
Episode: 5001/10000 (50.0100%),                 avg. length: 1691.55,                last time consumption/overall running time: 1687.3462s / 656968.2355 s
env0_first_0:                 episode reward: -13.5000,                 loss: 0.0082
env0_second_0:                 episode reward: 13.5000,                 loss: 0.0085
env1_first_0:                 episode reward: -15.4000,                 loss: nan
env1_second_0:                 episode reward: 15.4000,                 loss: nan
Episode: 5021/10000 (50.2100%),                 avg. length: 1635.8,                last time consumption/overall running time: 1632.2141s / 658600.4496 s
env0_first_0:                 episode reward: -12.1500,                 loss: 0.0075
env0_second_0:                 episode reward: 12.1500,                 loss: 0.0078
env1_first_0:                 episode reward: -13.3500,                 loss: nan
env1_second_0:                 episode reward: 13.3500,                 loss: nan
Episode: 5041/10000 (50.4100%),                 avg. length: 1616.95,                last time consumption/overall running time: 1612.6593s / 660213.1089 s
env0_first_0:                 episode reward: -14.0000,                 loss: 0.0073
env0_second_0:                 episode reward: 14.0000,                 loss: 0.0077
env1_first_0:                 episode reward: -14.0000,                 loss: nan
env1_second_0:                 episode reward: 14.0000,                 loss: nan
Episode: 5061/10000 (50.6100%),                 avg. length: 1528.45,                last time consumption/overall running time: 1507.1373s / 661720.2463 s
env0_first_0:                 episode reward: -14.4000,                 loss: 0.0072
env0_second_0:                 episode reward: 14.4000,                 loss: 0.0078
env1_first_0:                 episode reward: -13.4500,                 loss: nan
env1_second_0:                 episode reward: 13.4500,                 loss: nan
Episode: 5081/10000 (50.8100%),                 avg. length: 1658.45,                last time consumption/overall running time: 1650.3635s / 663370.6098 s
env0_first_0:                 episode reward: -13.7500,                 loss: 0.0072
env0_second_0:                 episode reward: 13.7500,                 loss: 0.0082
env1_first_0:                 episode reward: -13.7500,                 loss: nan
env1_second_0:                 episode reward: 13.7500,                 loss: nan
Episode: 5101/10000 (51.0100%),                 avg. length: 1598.35,                last time consumption/overall running time: 1573.3311s / 664943.9409 s
env0_first_0:                 episode reward: -11.2000,                 loss: 0.0073
env0_second_0:                 episode reward: 11.2000,                 loss: 0.0084
env1_first_0:                 episode reward: -13.7000,                 loss: nan
env1_second_0:                 episode reward: 13.7000,                 loss: nan
Episode: 5121/10000 (51.2100%),                 avg. length: 1632.4,                last time consumption/overall running time: 1596.9624s / 666540.9033 s
env0_first_0:                 episode reward: -14.6500,                 loss: 0.0076
env0_second_0:                 episode reward: 14.6500,                 loss: 0.0084
env1_first_0:                 episode reward: -15.9500,                 loss: nan
env1_second_0:                 episode reward: 15.9500,                 loss: nan
Episode: 5141/10000 (51.4100%),                 avg. length: 1667.15,                last time consumption/overall running time: 1630.0618s / 668170.9651 s
env0_first_0:                 episode reward: -12.9500,                 loss: 0.0078
env0_second_0:                 episode reward: 12.9500,                 loss: 0.0083
env1_first_0:                 episode reward: -12.9000,                 loss: nan
env1_second_0:                 episode reward: 12.9000,                 loss: nan
Episode: 5161/10000 (51.6100%),                 avg. length: 1712.95,                last time consumption/overall running time: 1645.6238s / 669816.5889 s
env0_first_0:                 episode reward: -13.5500,                 loss: 0.0075
env0_second_0:                 episode reward: 13.5500,                 loss: 0.0082
env1_first_0:                 episode reward: -13.6000,                 loss: nan
env1_second_0:                 episode reward: 13.6000,                 loss: nan
Episode: 5181/10000 (51.8100%),                 avg. length: 1685.6,                last time consumption/overall running time: 1633.4232s / 671450.0121 s
env0_first_0:                 episode reward: -13.8000,                 loss: 0.0080
env0_second_0:                 episode reward: 13.8000,                 loss: 0.0084
env1_first_0:                 episode reward: -15.9500,                 loss: nan
env1_second_0:                 episode reward: 15.9500,                 loss: nan
Episode: 5201/10000 (52.0100%),                 avg. length: 1561.7,                last time consumption/overall running time: 1513.8014s / 672963.8135 s
env0_first_0:                 episode reward: -13.8000,                 loss: 0.0080
env0_second_0:                 episode reward: 13.8000,                 loss: 0.0088
env1_first_0:                 episode reward: -13.7000,                 loss: nan
env1_second_0:                 episode reward: 13.7000,                 loss: nan
Episode: 5221/10000 (52.2100%),                 avg. length: 1669.4,                last time consumption/overall running time: 1609.0428s / 674572.8563 s
env0_first_0:                 episode reward: -12.4000,                 loss: 0.0079
env0_second_0:                 episode reward: 12.4000,                 loss: 0.0078
env1_first_0:                 episode reward: -11.1500,                 loss: nan
env1_second_0:                 episode reward: 11.1500,                 loss: nan
Episode: 5241/10000 (52.4100%),                 avg. length: 1772.05,                last time consumption/overall running time: 1699.6642s / 676272.5204 s
env0_first_0:                 episode reward: -15.0000,                 loss: 0.0075
env0_second_0:                 episode reward: 15.0000,                 loss: 0.0076
env1_first_0:                 episode reward: -15.3500,                 loss: nan
env1_second_0:                 episode reward: 15.3500,                 loss: nan
Episode: 5261/10000 (52.6100%),                 avg. length: 1599.35,                last time consumption/overall running time: 1533.0780s / 677805.5985 s
env0_first_0:                 episode reward: -12.0500,                 loss: 0.0075
env0_second_0:                 episode reward: 12.0500,                 loss: 0.0073
env1_first_0:                 episode reward: -13.6000,                 loss: nan
env1_second_0:                 episode reward: 13.6000,                 loss: nan
Episode: 5281/10000 (52.8100%),                 avg. length: 1691.0,                last time consumption/overall running time: 1605.0359s / 679410.6344 s
env0_first_0:                 episode reward: -13.9000,                 loss: 0.0072
env0_second_0:                 episode reward: 13.9000,                 loss: 0.0077
env1_first_0:                 episode reward: -14.0500,                 loss: nan
env1_second_0:                 episode reward: 14.0500,                 loss: nan
Episode: 5301/10000 (53.0100%),                 avg. length: 1781.5,                last time consumption/overall running time: 1684.8435s / 681095.4779 s
env0_first_0:                 episode reward: -14.7500,                 loss: 0.0076
env0_second_0:                 episode reward: 14.7500,                 loss: 0.0082
env1_first_0:                 episode reward: -13.7500,                 loss: nan
env1_second_0:                 episode reward: 13.7500,                 loss: nan
Episode: 5321/10000 (53.2100%),                 avg. length: 1755.45,                last time consumption/overall running time: 1674.9184s / 682770.3963 s
env0_first_0:                 episode reward: -14.5500,                 loss: 0.0076
env0_second_0:                 episode reward: 14.5500,                 loss: 0.0085
env1_first_0:                 episode reward: -14.8500,                 loss: nan
env1_second_0:                 episode reward: 14.8500,                 loss: nan
Episode: 5341/10000 (53.4100%),                 avg. length: 1702.05,                last time consumption/overall running time: 1623.9357s / 684394.3320 s
env0_first_0:                 episode reward: -17.4000,                 loss: 0.0071
env0_second_0:                 episode reward: 17.4000,                 loss: 0.0078
env1_first_0:                 episode reward: -15.0500,                 loss: nan
env1_second_0:                 episode reward: 15.0500,                 loss: nan
Episode: 5361/10000 (53.6100%),                 avg. length: 1664.25,                last time consumption/overall running time: 1565.6501s / 685959.9821 s
env0_first_0:                 episode reward: -13.9000,                 loss: 0.0073
env0_second_0:                 episode reward: 13.9000,                 loss: 0.0080
env1_first_0:                 episode reward: -13.3500,                 loss: nan
env1_second_0:                 episode reward: 13.3500,                 loss: nan
Episode: 5381/10000 (53.8100%),                 avg. length: 1706.95,                last time consumption/overall running time: 1609.2107s / 687569.1928 s
env0_first_0:                 episode reward: -15.4000,                 loss: 0.0077
env0_second_0:                 episode reward: 15.4000,                 loss: 0.0081
env1_first_0:                 episode reward: -15.1000,                 loss: nan
env1_second_0:                 episode reward: 15.1000,                 loss: nan
Episode: 5401/10000 (54.0100%),                 avg. length: 1646.4,                last time consumption/overall running time: 1566.6857s / 689135.8785 s
env0_first_0:                 episode reward: -13.3000,                 loss: 0.0074
env0_second_0:                 episode reward: 13.3000,                 loss: 0.0076
env1_first_0:                 episode reward: -11.9000,                 loss: nan
env1_second_0:                 episode reward: 11.9000,                 loss: nan
Episode: 5421/10000 (54.2100%),                 avg. length: 1659.85,                last time consumption/overall running time: 1575.6052s / 690711.4837 s
env0_first_0:                 episode reward: -14.0000,                 loss: 0.0072
env0_second_0:                 episode reward: 14.0000,                 loss: 0.0077
env1_first_0:                 episode reward: -15.1000,                 loss: nan
env1_second_0:                 episode reward: 15.1000,                 loss: nan
Episode: 5441/10000 (54.4100%),                 avg. length: 1849.5,                last time consumption/overall running time: 1742.8884s / 692454.3721 s
env0_first_0:                 episode reward: -16.5000,                 loss: 0.0079
env0_second_0:                 episode reward: 16.5000,                 loss: 0.0087
env1_first_0:                 episode reward: -15.8500,                 loss: nan
env1_second_0:                 episode reward: 15.8500,                 loss: nan
Episode: 5461/10000 (54.6100%),                 avg. length: 1863.05,                last time consumption/overall running time: 1751.3056s / 694205.6777 s
env0_first_0:                 episode reward: -13.7000,                 loss: 0.0083
env0_second_0:                 episode reward: 13.7000,                 loss: 0.0088
env1_first_0:                 episode reward: -14.4500,                 loss: nan
env1_second_0:                 episode reward: 14.4500,                 loss: nan
Episode: 5481/10000 (54.8100%),                 avg. length: 1793.6,                last time consumption/overall running time: 1688.3467s / 695894.0244 s
env0_first_0:                 episode reward: -13.5000,                 loss: 0.0081
env0_second_0:                 episode reward: 13.5000,                 loss: 0.0090
env1_first_0:                 episode reward: -12.8500,                 loss: nan
env1_second_0:                 episode reward: 12.8500,                 loss: nan
Episode: 5501/10000 (55.0100%),                 avg. length: 1877.25,                last time consumption/overall running time: 1742.4043s / 697636.4287 s
env0_first_0:                 episode reward: -14.7000,                 loss: 0.0081
env0_second_0:                 episode reward: 14.7000,                 loss: 0.0087
env1_first_0:                 episode reward: -15.4500,                 loss: nan
env1_second_0:                 episode reward: 15.4500,                 loss: nan
Episode: 5521/10000 (55.2100%),                 avg. length: 1822.95,                last time consumption/overall running time: 1688.3023s / 699324.7310 s
env0_first_0:                 episode reward: -14.9000,                 loss: 0.0094
env0_second_0:                 episode reward: 14.9000,                 loss: 0.0101
env1_first_0:                 episode reward: -13.6000,                 loss: nan
env1_second_0:                 episode reward: 13.6000,                 loss: nan
Episode: 5541/10000 (55.4100%),                 avg. length: 1806.65,                last time consumption/overall running time: 1659.0662s / 700983.7972 s
env0_first_0:                 episode reward: -12.4500,                 loss: 0.0095
env0_second_0:                 episode reward: 12.4500,                 loss: 0.0098
env1_first_0:                 episode reward: -11.7500,                 loss: nan
env1_second_0:                 episode reward: 11.7500,                 loss: nan
Episode: 5561/10000 (55.6100%),                 avg. length: 1766.0,                last time consumption/overall running time: 1608.0866s / 702591.8838 s
env0_first_0:                 episode reward: -14.8500,                 loss: 0.0082
env0_second_0:                 episode reward: 14.8500,                 loss: 0.0083
env1_first_0:                 episode reward: -13.4000,                 loss: nan
env1_second_0:                 episode reward: 13.4000,                 loss: nan
Episode: 5581/10000 (55.8100%),                 avg. length: 1558.55,                last time consumption/overall running time: 1409.2520s / 704001.1358 s
env0_first_0:                 episode reward: -17.8000,                 loss: 0.0082
env0_second_0:                 episode reward: 17.8000,                 loss: 0.0078
env1_first_0:                 episode reward: -16.1500,                 loss: nan
env1_second_0:                 episode reward: 16.1500,                 loss: nan
Episode: 5601/10000 (56.0100%),                 avg. length: 1609.95,                last time consumption/overall running time: 1444.7717s / 705445.9075 s
env0_first_0:                 episode reward: -14.9500,                 loss: 0.0085
env0_second_0:                 episode reward: 14.9500,                 loss: 0.0078
env1_first_0:                 episode reward: -13.4000,                 loss: nan
env1_second_0:                 episode reward: 13.4000,                 loss: nan
Episode: 5621/10000 (56.2100%),                 avg. length: 1578.05,                last time consumption/overall running time: 1425.3141s / 706871.2216 s
env0_first_0:                 episode reward: -12.9000,                 loss: 0.0080
env0_second_0:                 episode reward: 12.9000,                 loss: 0.0079
env1_first_0:                 episode reward: -13.8500,                 loss: nan
env1_second_0:                 episode reward: 13.8500,                 loss: nan
Episode: 5641/10000 (56.4100%),                 avg. length: 1697.55,                last time consumption/overall running time: 1534.8197s / 708406.0413 s
env0_first_0:                 episode reward: -14.5000,                 loss: 0.0078
env0_second_0:                 episode reward: 14.5000,                 loss: 0.0075
env1_first_0:                 episode reward: -15.4500,                 loss: nan
env1_second_0:                 episode reward: 15.4500,                 loss: nan
Episode: 5661/10000 (56.6100%),                 avg. length: 1582.5,                last time consumption/overall running time: 1425.4820s / 709831.5233 s
env0_first_0:                 episode reward: -13.9500,                 loss: 0.0079
env0_second_0:                 episode reward: 13.9500,                 loss: 0.0075
env1_first_0:                 episode reward: -14.7000,                 loss: nan
env1_second_0:                 episode reward: 14.7000,                 loss: nan
Episode: 5681/10000 (56.8100%),                 avg. length: 1513.5,                last time consumption/overall running time: 1361.0580s / 711192.5814 s
env0_first_0:                 episode reward: -11.9000,                 loss: 0.0072
env0_second_0:                 episode reward: 11.9000,                 loss: 0.0070
env1_first_0:                 episode reward: -15.2000,                 loss: nan
env1_second_0:                 episode reward: 15.2000,                 loss: nan
Episode: 5701/10000 (57.0100%),                 avg. length: 1505.15,                last time consumption/overall running time: 1361.5308s / 712554.1122 s
env0_first_0:                 episode reward: -14.0500,                 loss: 0.0069
env0_second_0:                 episode reward: 14.0500,                 loss: 0.0067
env1_first_0:                 episode reward: -12.1000,                 loss: nan
env1_second_0:                 episode reward: 12.1000,                 loss: nan
Episode: 5721/10000 (57.2100%),                 avg. length: 1514.3,                last time consumption/overall running time: 1346.0430s / 713900.1551 s
env0_first_0:                 episode reward: -13.3500,                 loss: 0.0071
env0_second_0:                 episode reward: 13.3500,                 loss: 0.0068
env1_first_0:                 episode reward: -14.6000,                 loss: nan
env1_second_0:                 episode reward: 14.6000,                 loss: nan
Episode: 5741/10000 (57.4100%),                 avg. length: 1585.6,                last time consumption/overall running time: 1376.6221s / 715276.7773 s
env0_first_0:                 episode reward: -13.7500,                 loss: 0.0077
env0_second_0:                 episode reward: 13.7500,                 loss: 0.0069
env1_first_0:                 episode reward: -13.4500,                 loss: nan
env1_second_0:                 episode reward: 13.4500,                 loss: nan
Episode: 5761/10000 (57.6100%),                 avg. length: 1591.7,                last time consumption/overall running time: 1375.5704s / 716652.3476 s
env0_first_0:                 episode reward: -14.5000,                 loss: 0.0082
env0_second_0:                 episode reward: 14.5000,                 loss: 0.0073
env1_first_0:                 episode reward: -14.7000,                 loss: nan
env1_second_0:                 episode reward: 14.7000,                 loss: nan
Episode: 5781/10000 (57.8100%),                 avg. length: 1654.9,                last time consumption/overall running time: 1443.2354s / 718095.5830 s
env0_first_0:                 episode reward: -14.6000,                 loss: 0.0083
env0_second_0:                 episode reward: 14.6000,                 loss: 0.0074
env1_first_0:                 episode reward: -13.4500,                 loss: nan
env1_second_0:                 episode reward: 13.4500,                 loss: nan
Episode: 5801/10000 (58.0100%),                 avg. length: 1621.1,                last time consumption/overall running time: 1418.9847s / 719514.5677 s
env0_first_0:                 episode reward: -12.2500,                 loss: 0.0084
env0_second_0:                 episode reward: 12.2500,                 loss: 0.0075
env1_first_0:                 episode reward: -14.8500,                 loss: nan
env1_second_0:                 episode reward: 14.8500,                 loss: nan
Episode: 5821/10000 (58.2100%),                 avg. length: 1739.9,                last time consumption/overall running time: 1512.8587s / 721027.4264 s
env0_first_0:                 episode reward: -16.6000,                 loss: 0.0082
env0_second_0:                 episode reward: 16.6000,                 loss: 0.0076
env1_first_0:                 episode reward: -15.5500,                 loss: nan
env1_second_0:                 episode reward: 15.5500,                 loss: nan
Episode: 5841/10000 (58.4100%),                 avg. length: 1569.35,                last time consumption/overall running time: 1373.7730s / 722401.1994 s
env0_first_0:                 episode reward: -13.8000,                 loss: 0.0083
env0_second_0:                 episode reward: 13.8000,                 loss: 0.0077
env1_first_0:                 episode reward: -15.7500,                 loss: nan
env1_second_0:                 episode reward: 15.7500,                 loss: nan
Episode: 5861/10000 (58.6100%),                 avg. length: 1725.05,                last time consumption/overall running time: 1500.1354s / 723901.3348 s
env0_first_0:                 episode reward: -13.6000,                 loss: 0.0080
env0_second_0:                 episode reward: 13.6000,                 loss: 0.0079
env1_first_0:                 episode reward: -14.4500,                 loss: nan
env1_second_0:                 episode reward: 14.4500,                 loss: nan
Episode: 5881/10000 (58.8100%),                 avg. length: 1745.65,                last time consumption/overall running time: 1521.2611s / 725422.5960 s
env0_first_0:                 episode reward: -11.7000,                 loss: 0.0082
env0_second_0:                 episode reward: 11.7000,                 loss: 0.0083
env1_first_0:                 episode reward: -13.6500,                 loss: nan
env1_second_0:                 episode reward: 13.6500,                 loss: nan
Episode: 5901/10000 (59.0100%),                 avg. length: 1677.35,                last time consumption/overall running time: 1458.5225s / 726881.1185 s
env0_first_0:                 episode reward: -12.4000,                 loss: 0.0082
env0_second_0:                 episode reward: 12.4000,                 loss: 0.0080
env1_first_0:                 episode reward: -13.1000,                 loss: nan
env1_second_0:                 episode reward: 13.1000,                 loss: nan
Episode: 5921/10000 (59.2100%),                 avg. length: 1820.1,                last time consumption/overall running time: 1584.1461s / 728465.2646 s
env0_first_0:                 episode reward: -15.6000,                 loss: 0.0083
env0_second_0:                 episode reward: 15.6000,                 loss: 0.0081
env1_first_0:                 episode reward: -14.3500,                 loss: nan
env1_second_0:                 episode reward: 14.3500,                 loss: nan
Episode: 5941/10000 (59.4100%),                 avg. length: 1717.7,                last time consumption/overall running time: 1478.0592s / 729943.3237 s
env0_first_0:                 episode reward: -16.8000,                 loss: 0.0081
env0_second_0:                 episode reward: 16.8000,                 loss: 0.0083
env1_first_0:                 episode reward: -15.4500,                 loss: nan
env1_second_0:                 episode reward: 15.4500,                 loss: nan
Episode: 5961/10000 (59.6100%),                 avg. length: 1861.2,                last time consumption/overall running time: 1607.6463s / 731550.9700 s
env0_first_0:                 episode reward: -18.1000,                 loss: 0.0081
env0_second_0:                 episode reward: 18.1000,                 loss: 0.0088
env1_first_0:                 episode reward: -17.3500,                 loss: nan
env1_second_0:                 episode reward: 17.3500,                 loss: nan
Episode: 5981/10000 (59.8100%),                 avg. length: 1770.6,                last time consumption/overall running time: 1535.3501s / 733086.3201 s
env0_first_0:                 episode reward: -15.1500,                 loss: 0.0078
env0_second_0:                 episode reward: 15.1500,                 loss: 0.0084
env1_first_0:                 episode reward: -15.9500,                 loss: nan
env1_second_0:                 episode reward: 15.9500,                 loss: nan
Episode: 6001/10000 (60.0100%),                 avg. length: 1786.0,                last time consumption/overall running time: 1583.8359s / 734670.1560 s
env0_first_0:                 episode reward: -15.3000,                 loss: 0.0075
env0_second_0:                 episode reward: 15.3000,                 loss: 0.0080
env1_first_0:                 episode reward: -16.7500,                 loss: nan
env1_second_0:                 episode reward: 16.7500,                 loss: nan
Episode: 6021/10000 (60.2100%),                 avg. length: 1677.15,                last time consumption/overall running time: 1495.8949s / 736166.0508 s
env0_first_0:                 episode reward: -14.1000,                 loss: 0.0070
env0_second_0:                 episode reward: 14.1000,                 loss: 0.0074
env1_first_0:                 episode reward: -14.8500,                 loss: nan
env1_second_0:                 episode reward: 14.8500,                 loss: nan
Episode: 6041/10000 (60.4100%),                 avg. length: 1582.35,                last time consumption/overall running time: 1400.6136s / 737566.6645 s
env0_first_0:                 episode reward: -14.5500,                 loss: 0.0066
env0_second_0:                 episode reward: 14.5500,                 loss: 0.0071
env1_first_0:                 episode reward: -14.9500,                 loss: nan
env1_second_0:                 episode reward: 14.9500,                 loss: nan
Episode: 6061/10000 (60.6100%),                 avg. length: 1573.65,                last time consumption/overall running time: 1394.4125s / 738961.0770 s
env0_first_0:                 episode reward: -14.8500,                 loss: 0.0065
env0_second_0:                 episode reward: 14.8500,                 loss: 0.0073
env1_first_0:                 episode reward: -15.9500,                 loss: nan
env1_second_0:                 episode reward: 15.9500,                 loss: nan
Episode: 6081/10000 (60.8100%),                 avg. length: 1735.35,                last time consumption/overall running time: 1530.4708s / 740491.5478 s
env0_first_0:                 episode reward: -16.0000,                 loss: 0.0066
env0_second_0:                 episode reward: 16.0000,                 loss: 0.0074
env1_first_0:                 episode reward: -13.2000,                 loss: nan
env1_second_0:                 episode reward: 13.2000,                 loss: nan
Episode: 6101/10000 (61.0100%),                 avg. length: 1654.0,                last time consumption/overall running time: 1451.5405s / 741943.0883 s
env0_first_0:                 episode reward: -13.8500,                 loss: 0.0072
env0_second_0:                 episode reward: 13.8500,                 loss: 0.0079
env1_first_0:                 episode reward: -14.5000,                 loss: nan
env1_second_0:                 episode reward: 14.5000,                 loss: nan
Episode: 6121/10000 (61.2100%),                 avg. length: 1817.15,                last time consumption/overall running time: 1598.1543s / 743541.2426 s
env0_first_0:                 episode reward: -17.1000,                 loss: 0.0070
env0_second_0:                 episode reward: 17.1000,                 loss: 0.0078
env1_first_0:                 episode reward: -15.1000,                 loss: nan
env1_second_0:                 episode reward: 15.1000,                 loss: nan
Episode: 6141/10000 (61.4100%),                 avg. length: 1655.3,                last time consumption/overall running time: 1464.4191s / 745005.6618 s
env0_first_0:                 episode reward: -16.8500,                 loss: 0.0072
env0_second_0:                 episode reward: 16.8500,                 loss: 0.0080
env1_first_0:                 episode reward: -15.7000,                 loss: nan
env1_second_0:                 episode reward: 15.7000,                 loss: nan
Episode: 6161/10000 (61.6100%),                 avg. length: 1590.3,                last time consumption/overall running time: 1399.2993s / 746404.9611 s
env0_first_0:                 episode reward: -15.5000,                 loss: 0.0073
env0_second_0:                 episode reward: 15.5000,                 loss: 0.0073
env1_first_0:                 episode reward: -15.1000,                 loss: nan
env1_second_0:                 episode reward: 15.1000,                 loss: nan
Episode: 6181/10000 (61.8100%),                 avg. length: 1582.15,                last time consumption/overall running time: 1391.7127s / 747796.6737 s
env0_first_0:                 episode reward: -15.6000,                 loss: 0.0067
env0_second_0:                 episode reward: 15.6000,                 loss: 0.0070
env1_first_0:                 episode reward: -13.1500,                 loss: nan
env1_second_0:                 episode reward: 13.1500,                 loss: nan
Episode: 6201/10000 (62.0100%),                 avg. length: 1556.3,                last time consumption/overall running time: 1380.6884s / 749177.3621 s
env0_first_0:                 episode reward: -14.9000,                 loss: 0.0064
env0_second_0:                 episode reward: 14.9000,                 loss: 0.0069
env1_first_0:                 episode reward: -13.8000,                 loss: nan
env1_second_0:                 episode reward: 13.8000,                 loss: nan
Episode: 6221/10000 (62.2100%),                 avg. length: 1758.4,                last time consumption/overall running time: 1546.6923s / 750724.0545 s
env0_first_0:                 episode reward: -15.2500,                 loss: 0.0067
env0_second_0:                 episode reward: 15.2500,                 loss: 0.0068
env1_first_0:                 episode reward: -15.9500,                 loss: nan
env1_second_0:                 episode reward: 15.9500,                 loss: nan
Episode: 6241/10000 (62.4100%),                 avg. length: 1816.6,                last time consumption/overall running time: 1594.5906s / 752318.6451 s
env0_first_0:                 episode reward: -16.6500,                 loss: 0.0076
env0_second_0:                 episode reward: 16.6500,                 loss: 0.0078
env1_first_0:                 episode reward: -16.8500,                 loss: nan
env1_second_0:                 episode reward: 16.8500,                 loss: nan
Episode: 6261/10000 (62.6100%),                 avg. length: 1938.55,                last time consumption/overall running time: 1692.7725s / 754011.4175 s
env0_first_0:                 episode reward: -14.3000,                 loss: 0.0086
env0_second_0:                 episode reward: 14.3000,                 loss: 0.0087
env1_first_0:                 episode reward: -14.0000,                 loss: nan
env1_second_0:                 episode reward: 14.0000,                 loss: nan
Episode: 6281/10000 (62.8100%),                 avg. length: 2016.55,                last time consumption/overall running time: 1756.6140s / 755768.0316 s
env0_first_0:                 episode reward: -14.9500,                 loss: 0.0084
env0_second_0:                 episode reward: 14.9500,                 loss: 0.0082
env1_first_0:                 episode reward: -15.7500,                 loss: nan
env1_second_0:                 episode reward: 15.7500,                 loss: nan
Episode: 6301/10000 (63.0100%),                 avg. length: 1629.2,                last time consumption/overall running time: 1429.4338s / 757197.4654 s
env0_first_0:                 episode reward: -14.9500,                 loss: 0.0071
env0_second_0:                 episode reward: 14.9500,                 loss: 0.0074
env1_first_0:                 episode reward: -15.9000,                 loss: nan
env1_second_0:                 episode reward: 15.9000,                 loss: nan
Episode: 6321/10000 (63.2100%),                 avg. length: 1525.05,                last time consumption/overall running time: 1335.7142s / 758533.1796 s
env0_first_0:                 episode reward: -16.4000,                 loss: 0.0064
env0_second_0:                 episode reward: 16.4000,                 loss: 0.0065
env1_first_0:                 episode reward: -14.9500,                 loss: nan
env1_second_0:                 episode reward: 14.9500,                 loss: nan
Episode: 6341/10000 (63.4100%),                 avg. length: 1626.5,                last time consumption/overall running time: 1421.2880s / 759954.4675 s
env0_first_0:                 episode reward: -17.2500,                 loss: 0.0067
env0_second_0:                 episode reward: 17.2500,                 loss: 0.0068
env1_first_0:                 episode reward: -17.0000,                 loss: nan
env1_second_0:                 episode reward: 17.0000,                 loss: nan
Episode: 6361/10000 (63.6100%),                 avg. length: 1701.55,                last time consumption/overall running time: 1498.1898s / 761452.6573 s
env0_first_0:                 episode reward: -15.5500,                 loss: 0.0072
env0_second_0:                 episode reward: 15.5500,                 loss: 0.0074
env1_first_0:                 episode reward: -16.0500,                 loss: nan
env1_second_0:                 episode reward: 16.0500,                 loss: nan
Episode: 6381/10000 (63.8100%),                 avg. length: 1819.85,                last time consumption/overall running time: 1576.0725s / 763028.7298 s
env0_first_0:                 episode reward: -15.0000,                 loss: 0.0075
env0_second_0:                 episode reward: 15.0000,                 loss: 0.0078
env1_first_0:                 episode reward: -15.0500,                 loss: nan
env1_second_0:                 episode reward: 15.0500,                 loss: nan
Episode: 6401/10000 (64.0100%),                 avg. length: 1777.7,                last time consumption/overall running time: 1541.1305s / 764569.8602 s
env0_first_0:                 episode reward: -15.5500,                 loss: 0.0082
env0_second_0:                 episode reward: 15.5500,                 loss: 0.0081
env1_first_0:                 episode reward: -16.2500,                 loss: nan
env1_second_0:                 episode reward: 16.2500,                 loss: nan
Episode: 6421/10000 (64.2100%),                 avg. length: 1719.9,                last time consumption/overall running time: 1494.2226s / 766064.0829 s
env0_first_0:                 episode reward: -17.1000,                 loss: 0.0078
env0_second_0:                 episode reward: 17.1000,                 loss: 0.0078
env1_first_0:                 episode reward: -15.3000,                 loss: nan
env1_second_0:                 episode reward: 15.3000,                 loss: nan
Episode: 6441/10000 (64.4100%),                 avg. length: 1660.4,                last time consumption/overall running time: 1436.3554s / 767500.4383 s
env0_first_0:                 episode reward: -14.1000,                 loss: 0.0073
env0_second_0:                 episode reward: 14.1000,                 loss: 0.0074
env1_first_0:                 episode reward: -17.8500,                 loss: nan
env1_second_0:                 episode reward: 17.8500,                 loss: nan
Episode: 6461/10000 (64.6100%),                 avg. length: 1781.7,                last time consumption/overall running time: 1527.3750s / 769027.8133 s
env0_first_0:                 episode reward: -14.2500,                 loss: 0.0078
env0_second_0:                 episode reward: 14.2500,                 loss: 0.0075
env1_first_0:                 episode reward: -18.0000,                 loss: nan
env1_second_0:                 episode reward: 18.0000,                 loss: nan
Episode: 6481/10000 (64.8100%),                 avg. length: 1707.7,                last time consumption/overall running time: 1472.3110s / 770500.1243 s
env0_first_0:                 episode reward: -15.3000,                 loss: 0.0078
env0_second_0:                 episode reward: 15.3000,                 loss: 0.0081
env1_first_0:                 episode reward: -15.2500,                 loss: nan
env1_second_0:                 episode reward: 15.2500,                 loss: nan
Episode: 6501/10000 (65.0100%),                 avg. length: 1732.8,                last time consumption/overall running time: 1478.1578s / 771978.2821 s
env0_first_0:                 episode reward: -13.9000,                 loss: 0.0069
env0_second_0:                 episode reward: 13.9000,                 loss: 0.0072
env1_first_0:                 episode reward: -15.5000,                 loss: nan
env1_second_0:                 episode reward: 15.5000,                 loss: nan
Episode: 6521/10000 (65.2100%),                 avg. length: 1652.9,                last time consumption/overall running time: 1406.8759s / 773385.1581 s
env0_first_0:                 episode reward: -17.3000,                 loss: 0.0071
env0_second_0:                 episode reward: 17.3000,                 loss: 0.0072
env1_first_0:                 episode reward: -15.2000,                 loss: nan
env1_second_0:                 episode reward: 15.2000,                 loss: nan
Episode: 6541/10000 (65.4100%),                 avg. length: 1672.8,                last time consumption/overall running time: 1439.2155s / 774824.3735 s
env0_first_0:                 episode reward: -15.6000,                 loss: 0.0072
env0_second_0:                 episode reward: 15.6000,                 loss: 0.0078
env1_first_0:                 episode reward: -17.1500,                 loss: nan
env1_second_0:                 episode reward: 17.1500,                 loss: nan
Episode: 6561/10000 (65.6100%),                 avg. length: 1634.4,                last time consumption/overall running time: 1403.9073s / 776228.2809 s
env0_first_0:                 episode reward: -14.9000,                 loss: 0.0078
env0_second_0:                 episode reward: 14.9000,                 loss: 0.0079
env1_first_0:                 episode reward: -14.5000,                 loss: nan
env1_second_0:                 episode reward: 14.5000,                 loss: nan
Episode: 6581/10000 (65.8100%),                 avg. length: 1598.4,                last time consumption/overall running time: 1375.9189s / 777604.1997 s
env0_first_0:                 episode reward: -13.5500,                 loss: 0.0078
env0_second_0:                 episode reward: 13.5500,                 loss: 0.0079
env1_first_0:                 episode reward: -13.0000,                 loss: nan
env1_second_0:                 episode reward: 13.0000,                 loss: nan
Episode: 6601/10000 (66.0100%),                 avg. length: 1730.0,                last time consumption/overall running time: 1494.5247s / 779098.7244 s
env0_first_0:                 episode reward: -14.0000,                 loss: 0.0078
env0_second_0:                 episode reward: 14.0000,                 loss: 0.0078
env1_first_0:                 episode reward: -13.5500,                 loss: nan
env1_second_0:                 episode reward: 13.5500,                 loss: nan
Episode: 6621/10000 (66.2100%),                 avg. length: 1795.85,                last time consumption/overall running time: 1536.2575s / 780634.9819 s
env0_first_0:                 episode reward: -16.1000,                 loss: 0.0069
env0_second_0:                 episode reward: 16.1000,                 loss: 0.0072
env1_first_0:                 episode reward: -14.9500,                 loss: nan
env1_second_0:                 episode reward: 14.9500,                 loss: nan
Episode: 6641/10000 (66.4100%),                 avg. length: 1903.4,                last time consumption/overall running time: 1624.6091s / 782259.5910 s
env0_first_0:                 episode reward: -11.9500,                 loss: 0.0079
env0_second_0:                 episode reward: 11.9500,                 loss: 0.0084
env1_first_0:                 episode reward: -13.7000,                 loss: nan
env1_second_0:                 episode reward: 13.7000,                 loss: nan
Episode: 6661/10000 (66.6100%),                 avg. length: 1831.25,                last time consumption/overall running time: 1556.3989s / 783815.9899 s
env0_first_0:                 episode reward: -14.7500,                 loss: 0.0079
env0_second_0:                 episode reward: 14.7500,                 loss: 0.0085
env1_first_0:                 episode reward: -13.6000,                 loss: nan
env1_second_0:                 episode reward: 13.6000,                 loss: nan
Episode: 6681/10000 (66.8100%),                 avg. length: 1805.3,                last time consumption/overall running time: 1551.7809s / 785367.7708 s
env0_first_0:                 episode reward: -16.0500,                 loss: 0.0074
env0_second_0:                 episode reward: 16.0500,                 loss: 0.0081
env1_first_0:                 episode reward: -15.7000,                 loss: nan
env1_second_0:                 episode reward: 15.7000,                 loss: nan
Episode: 6701/10000 (67.0100%),                 avg. length: 1839.0,                last time consumption/overall running time: 1572.4042s / 786940.1750 s
env0_first_0:                 episode reward: -13.6000,                 loss: 0.0081
env0_second_0:                 episode reward: 13.6000,                 loss: 0.0085
env1_first_0:                 episode reward: -15.5000,                 loss: nan
env1_second_0:                 episode reward: 15.5000,                 loss: nan
Episode: 6721/10000 (67.2100%),                 avg. length: 1758.15,                last time consumption/overall running time: 1514.7686s / 788454.9437 s
env0_first_0:                 episode reward: -15.3500,                 loss: 0.0085
env0_second_0:                 episode reward: 15.3500,                 loss: 0.0091
env1_first_0:                 episode reward: -14.8000,                 loss: nan
env1_second_0:                 episode reward: 14.8000,                 loss: nan
Episode: 6741/10000 (67.4100%),                 avg. length: 1780.8,                last time consumption/overall running time: 1511.0769s / 789966.0205 s
env0_first_0:                 episode reward: -14.8500,                 loss: 0.0080
env0_second_0:                 episode reward: 14.8500,                 loss: 0.0089
env1_first_0:                 episode reward: -15.1500,                 loss: nan
env1_second_0:                 episode reward: 15.1500,                 loss: nan
Episode: 6761/10000 (67.6100%),                 avg. length: 2010.05,                last time consumption/overall running time: 1737.6420s / 791703.6625 s
env0_first_0:                 episode reward: -15.8500,                 loss: 0.0085
env0_second_0:                 episode reward: 15.8500,                 loss: 0.0092
env1_first_0:                 episode reward: -14.5500,                 loss: nan
env1_second_0:                 episode reward: 14.5500,                 loss: nan
Episode: 6781/10000 (67.8100%),                 avg. length: 1746.8,                last time consumption/overall running time: 1520.4704s / 793224.1329 s
env0_first_0:                 episode reward: -12.9500,                 loss: 0.0080
env0_second_0:                 episode reward: 12.9500,                 loss: 0.0083
env1_first_0:                 episode reward: -15.2000,                 loss: nan
env1_second_0:                 episode reward: 15.2000,                 loss: nan
Episode: 6801/10000 (68.0100%),                 avg. length: 2001.45,                last time consumption/overall running time: 1726.0858s / 794950.2187 s
env0_first_0:                 episode reward: -15.3500,                 loss: 0.0084
env0_second_0:                 episode reward: 15.3500,                 loss: 0.0082
env1_first_0:                 episode reward: -14.9500,                 loss: nan
env1_second_0:                 episode reward: 14.9500,                 loss: nan
Episode: 6821/10000 (68.2100%),                 avg. length: 1783.7,                last time consumption/overall running time: 1531.8067s / 796482.0254 s
env0_first_0:                 episode reward: -12.1500,                 loss: 0.0088
env0_second_0:                 episode reward: 12.1500,                 loss: 0.0091
env1_first_0:                 episode reward: -14.3000,                 loss: nan
env1_second_0:                 episode reward: 14.3000,                 loss: nan
Episode: 6841/10000 (68.4100%),                 avg. length: 1780.4,                last time consumption/overall running time: 1511.6332s / 797993.6586 s
env0_first_0:                 episode reward: -15.4500,                 loss: 0.0088
env0_second_0:                 episode reward: 15.4500,                 loss: 0.0088
env1_first_0:                 episode reward: -13.6500,                 loss: nan
env1_second_0:                 episode reward: 13.6500,                 loss: nan
Episode: 6861/10000 (68.6100%),                 avg. length: 1648.45,                last time consumption/overall running time: 1399.0397s / 799392.6983 s
env0_first_0:                 episode reward: -14.9500,                 loss: 0.0081
env0_second_0:                 episode reward: 14.9500,                 loss: 0.0084
env1_first_0:                 episode reward: -13.7000,                 loss: nan
env1_second_0:                 episode reward: 13.7000,                 loss: nan
Episode: 6881/10000 (68.8100%),                 avg. length: 1675.45,                last time consumption/overall running time: 1420.3674s / 800813.0656 s
env0_first_0:                 episode reward: -16.5500,                 loss: 0.0076
env0_second_0:                 episode reward: 16.5500,                 loss: 0.0077
env1_first_0:                 episode reward: -16.7500,                 loss: nan
env1_second_0:                 episode reward: 16.7500,                 loss: nan
Episode: 6901/10000 (69.0100%),                 avg. length: 1665.4,                last time consumption/overall running time: 1402.8805s / 802215.9462 s
env0_first_0:                 episode reward: -16.1000,                 loss: 0.0075
env0_second_0:                 episode reward: 16.1000,                 loss: 0.0075
env1_first_0:                 episode reward: -15.5500,                 loss: nan
env1_second_0:                 episode reward: 15.5500,                 loss: nan
Episode: 6921/10000 (69.2100%),                 avg. length: 1678.95,                last time consumption/overall running time: 1424.7562s / 803640.7023 s
env0_first_0:                 episode reward: -17.2000,                 loss: 0.0078
env0_second_0:                 episode reward: 17.2000,                 loss: 0.0074
env1_first_0:                 episode reward: -16.4500,                 loss: nan
env1_second_0:                 episode reward: 16.4500,                 loss: nan
Episode: 6941/10000 (69.4100%),                 avg. length: 1597.35,                last time consumption/overall running time: 1369.1820s / 805009.8844 s
env0_first_0:                 episode reward: -14.9000,                 loss: 0.0074
env0_second_0:                 episode reward: 14.9000,                 loss: 0.0072
env1_first_0:                 episode reward: -15.4000,                 loss: nan
env1_second_0:                 episode reward: 15.4000,                 loss: nan
Episode: 6961/10000 (69.6100%),                 avg. length: 1691.5,                last time consumption/overall running time: 1450.4904s / 806460.3748 s
env0_first_0:                 episode reward: -13.1500,                 loss: 0.0077
env0_second_0:                 episode reward: 13.1500,                 loss: 0.0077
env1_first_0:                 episode reward: -14.7000,                 loss: nan
env1_second_0:                 episode reward: 14.7000,                 loss: nan
Episode: 6981/10000 (69.8100%),                 avg. length: 1577.9,                last time consumption/overall running time: 1332.4670s / 807792.8417 s
env0_first_0:                 episode reward: -13.2000,                 loss: 0.0076
env0_second_0:                 episode reward: 13.2000,                 loss: 0.0079
env1_first_0:                 episode reward: -12.4000,                 loss: nan
env1_second_0:                 episode reward: 12.4000,                 loss: nan
Episode: 7001/10000 (70.0100%),                 avg. length: 1743.55,                last time consumption/overall running time: 1479.9944s / 809272.8361 s
env0_first_0:                 episode reward: -14.2000,                 loss: 0.0083
env0_second_0:                 episode reward: 14.2000,                 loss: 0.0080
env1_first_0:                 episode reward: -13.2000,                 loss: nan
env1_second_0:                 episode reward: 13.2000,                 loss: nan
Episode: 7021/10000 (70.2100%),                 avg. length: 1571.8,                last time consumption/overall running time: 1350.9554s / 810623.7916 s
env0_first_0:                 episode reward: -12.2500,                 loss: 0.0080
env0_second_0:                 episode reward: 12.2500,                 loss: 0.0083
env1_first_0:                 episode reward: -12.9000,                 loss: nan
env1_second_0:                 episode reward: 12.9000,                 loss: nan
Episode: 7041/10000 (70.4100%),                 avg. length: 1640.85,                last time consumption/overall running time: 1397.7072s / 812021.4988 s
env0_first_0:                 episode reward: -12.5000,                 loss: 0.0074
env0_second_0:                 episode reward: 12.5000,                 loss: 0.0078
env1_first_0:                 episode reward: -11.5500,                 loss: nan
env1_second_0:                 episode reward: 11.5500,                 loss: nan
Episode: 7061/10000 (70.6100%),                 avg. length: 1896.75,                last time consumption/overall running time: 1616.3146s / 813637.8134 s
env0_first_0:                 episode reward: -12.6000,                 loss: 0.0077
env0_second_0:                 episode reward: 12.6000,                 loss: 0.0079
env1_first_0:                 episode reward: -15.5000,                 loss: nan
env1_second_0:                 episode reward: 15.5000,                 loss: nan
Episode: 7081/10000 (70.8100%),                 avg. length: 1871.8,                last time consumption/overall running time: 1584.3648s / 815222.1782 s
env0_first_0:                 episode reward: -15.6000,                 loss: 0.0089
env0_second_0:                 episode reward: 15.6000,                 loss: 0.0092
env1_first_0:                 episode reward: -12.6500,                 loss: nan
env1_second_0:                 episode reward: 12.6500,                 loss: nan
Episode: 7101/10000 (71.0100%),                 avg. length: 1722.9,                last time consumption/overall running time: 1464.6830s / 816686.8611 s
env0_first_0:                 episode reward: -12.9500,                 loss: 0.0087
env0_second_0:                 episode reward: 12.9500,                 loss: 0.0090
env1_first_0:                 episode reward: -11.2000,                 loss: nan
env1_second_0:                 episode reward: 11.2000,                 loss: nan
Episode: 7121/10000 (71.2100%),                 avg. length: 1882.05,                last time consumption/overall running time: 1586.2853s / 818273.1464 s
env0_first_0:                 episode reward: -11.7000,                 loss: 0.0086
env0_second_0:                 episode reward: 11.7000,                 loss: 0.0087
env1_first_0:                 episode reward: -10.9500,                 loss: nan
env1_second_0:                 episode reward: 10.9500,                 loss: nan
Episode: 7141/10000 (71.4100%),                 avg. length: 1983.55,                last time consumption/overall running time: 1683.7412s / 819956.8876 s
env0_first_0:                 episode reward: -12.5500,                 loss: 0.0093
env0_second_0:                 episode reward: 12.5500,                 loss: 0.0085
env1_first_0:                 episode reward: -13.5500,                 loss: nan
env1_second_0:                 episode reward: 13.5500,                 loss: nan
Episode: 7161/10000 (71.6100%),                 avg. length: 1810.2,                last time consumption/overall running time: 1533.3988s / 821490.2864 s
env0_first_0:                 episode reward: -11.9000,                 loss: 0.0099
env0_second_0:                 episode reward: 11.9000,                 loss: 0.0094
env1_first_0:                 episode reward: -11.8000,                 loss: nan
env1_second_0:                 episode reward: 11.8000,                 loss: nan
Episode: 7181/10000 (71.8100%),                 avg. length: 2158.15,                last time consumption/overall running time: 1834.8438s / 823325.1302 s
env0_first_0:                 episode reward: -11.8000,                 loss: 0.0103
env0_second_0:                 episode reward: 11.8000,                 loss: 0.0097
env1_first_0:                 episode reward: -9.9500,                 loss: nan
env1_second_0:                 episode reward: 9.9500,                 loss: nan
Episode: 7201/10000 (72.0100%),                 avg. length: 1962.0,                last time consumption/overall running time: 1664.6032s / 824989.7334 s
env0_first_0:                 episode reward: -11.6000,                 loss: 0.0104
env0_second_0:                 episode reward: 11.6000,                 loss: 0.0092
env1_first_0:                 episode reward: -10.1500,                 loss: nan
env1_second_0:                 episode reward: 10.1500,                 loss: nan
Episode: 7221/10000 (72.2100%),                 avg. length: 1962.65,                last time consumption/overall running time: 1659.2312s / 826648.9646 s
env0_first_0:                 episode reward: -12.3000,                 loss: 0.0095
env0_second_0:                 episode reward: 12.3000,                 loss: 0.0086
env1_first_0:                 episode reward: -10.0000,                 loss: nan
env1_second_0:                 episode reward: 10.0000,                 loss: nan
Episode: 7241/10000 (72.4100%),                 avg. length: 1759.5,                last time consumption/overall running time: 1494.2572s / 828143.2218 s
env0_first_0:                 episode reward: -11.5500,                 loss: 0.0087
env0_second_0:                 episode reward: 11.5500,                 loss: 0.0077
env1_first_0:                 episode reward: -12.6000,                 loss: nan
env1_second_0:                 episode reward: 12.6000,                 loss: nan
Episode: 7261/10000 (72.6100%),                 avg. length: 1827.95,                last time consumption/overall running time: 1552.4757s / 829695.6975 s
env0_first_0:                 episode reward: -13.0500,                 loss: 0.0090
env0_second_0:                 episode reward: 13.0500,                 loss: 0.0078
env1_first_0:                 episode reward: -10.8500,                 loss: nan
env1_second_0:                 episode reward: 10.8500,                 loss: nan
Episode: 7281/10000 (72.8100%),                 avg. length: 1676.7,                last time consumption/overall running time: 1416.7271s / 831112.4246 s
env0_first_0:                 episode reward: -11.8500,                 loss: 0.0084
env0_second_0:                 episode reward: 11.8500,                 loss: 0.0076
env1_first_0:                 episode reward: -11.7000,                 loss: nan
env1_second_0:                 episode reward: 11.7000,                 loss: nan
Episode: 7301/10000 (73.0100%),                 avg. length: 1783.5,                last time consumption/overall running time: 1508.7624s / 832621.1870 s
env0_first_0:                 episode reward: -12.2500,                 loss: 0.0077
env0_second_0:                 episode reward: 12.2500,                 loss: 0.0071
env1_first_0:                 episode reward: -10.9000,                 loss: nan
env1_second_0:                 episode reward: 10.9000,                 loss: nan
Episode: 7321/10000 (73.2100%),                 avg. length: 2090.8,                last time consumption/overall running time: 1760.1210s / 834381.3080 s
env0_first_0:                 episode reward: -12.9500,                 loss: 0.0090
env0_second_0:                 episode reward: 12.9500,                 loss: 0.0084
env1_first_0:                 episode reward: -13.0000,                 loss: nan
env1_second_0:                 episode reward: 13.0000,                 loss: nan
Episode: 7341/10000 (73.4100%),                 avg. length: 1861.25,                last time consumption/overall running time: 1590.0331s / 835971.3411 s
env0_first_0:                 episode reward: -13.6500,                 loss: 0.0110
env0_second_0:                 episode reward: 13.6500,                 loss: 0.0090
env1_first_0:                 episode reward: -13.2000,                 loss: nan
env1_second_0:                 episode reward: 13.2000,                 loss: nan
Episode: 7361/10000 (73.6100%),                 avg. length: 1793.45,                last time consumption/overall running time: 1531.5391s / 837502.8803 s
env0_first_0:                 episode reward: -12.6500,                 loss: 0.0096
env0_second_0:                 episode reward: 12.6500,                 loss: 0.0082
env1_first_0:                 episode reward: -12.6000,                 loss: nan
env1_second_0:                 episode reward: 12.6000,                 loss: nan
Episode: 7381/10000 (73.8100%),                 avg. length: 1690.25,                last time consumption/overall running time: 1427.0917s / 838929.9720 s
env0_first_0:                 episode reward: -11.9500,                 loss: 0.0089
env0_second_0:                 episode reward: 11.9500,                 loss: 0.0075
env1_first_0:                 episode reward: -11.3500,                 loss: nan
env1_second_0:                 episode reward: 11.3500,                 loss: nan
Episode: 7401/10000 (74.0100%),                 avg. length: 1747.85,                last time consumption/overall running time: 1483.7558s / 840413.7278 s
env0_first_0:                 episode reward: -10.8500,                 loss: 0.0080
env0_second_0:                 episode reward: 10.8500,                 loss: 0.0066
env1_first_0:                 episode reward: -10.7000,                 loss: nan
env1_second_0:                 episode reward: 10.7000,                 loss: nan
Episode: 7421/10000 (74.2100%),                 avg. length: 1739.0,                last time consumption/overall running time: 1458.5669s / 841872.2946 s
env0_first_0:                 episode reward: -11.7000,                 loss: 0.0072
env0_second_0:                 episode reward: 11.7000,                 loss: 0.0061
env1_first_0:                 episode reward: -10.7500,                 loss: nan
env1_second_0:                 episode reward: 10.7500,                 loss: nan
Episode: 7441/10000 (74.4100%),                 avg. length: 1863.45,                last time consumption/overall running time: 1561.7765s / 843434.0711 s
env0_first_0:                 episode reward: -12.9500,                 loss: 0.0072
env0_second_0:                 episode reward: 12.9500,                 loss: 0.0066
env1_first_0:                 episode reward: -10.6000,                 loss: nan
env1_second_0:                 episode reward: 10.6000,                 loss: nan
Episode: 7461/10000 (74.6100%),                 avg. length: 2043.75,                last time consumption/overall running time: 1702.1393s / 845136.2104 s
env0_first_0:                 episode reward: -9.4000,                 loss: 0.0083
env0_second_0:                 episode reward: 9.4000,                 loss: 0.0078
env1_first_0:                 episode reward: -9.6000,                 loss: nan
env1_second_0:                 episode reward: 9.6000,                 loss: nan
Episode: 7481/10000 (74.8100%),                 avg. length: 2214.2,                last time consumption/overall running time: 1849.7767s / 846985.9872 s
env0_first_0:                 episode reward: -14.1000,                 loss: 0.0102
env0_second_0:                 episode reward: 14.1000,                 loss: 0.0090
env1_first_0:                 episode reward: -13.9000,                 loss: nan
env1_second_0:                 episode reward: 13.9000,                 loss: nan
Episode: 7501/10000 (75.0100%),                 avg. length: 1737.75,                last time consumption/overall running time: 1451.8369s / 848437.8241 s
env0_first_0:                 episode reward: -13.5500,                 loss: 0.0093
env0_second_0:                 episode reward: 13.5500,                 loss: 0.0089
env1_first_0:                 episode reward: -11.7000,                 loss: nan
env1_second_0:                 episode reward: 11.7000,                 loss: nan
Episode: 7521/10000 (75.2100%),                 avg. length: 1755.05,                last time consumption/overall running time: 1484.8084s / 849922.6325 s
env0_first_0:                 episode reward: -7.8000,                 loss: 0.0075
env0_second_0:                 episode reward: 7.8000,                 loss: 0.0080
env1_first_0:                 episode reward: -9.0500,                 loss: nan
env1_second_0:                 episode reward: 9.0500,                 loss: nan
Episode: 7541/10000 (75.4100%),                 avg. length: 1666.85,                last time consumption/overall running time: 1409.9350s / 851332.5676 s
env0_first_0:                 episode reward: -9.8500,                 loss: 0.0063
env0_second_0:                 episode reward: 9.8500,                 loss: 0.0070
env1_first_0:                 episode reward: -8.9000,                 loss: nan
env1_second_0:                 episode reward: 8.9000,                 loss: nan
Episode: 7561/10000 (75.6100%),                 avg. length: 1720.15,                last time consumption/overall running time: 1451.6830s / 852784.2506 s
env0_first_0:                 episode reward: -9.1500,                 loss: 0.0066
env0_second_0:                 episode reward: 9.1500,                 loss: 0.0072
env1_first_0:                 episode reward: -9.7000,                 loss: nan
env1_second_0:                 episode reward: 9.7000,                 loss: nan
Episode: 7581/10000 (75.8100%),                 avg. length: 1693.75,                last time consumption/overall running time: 1429.3900s / 854213.6406 s
env0_first_0:                 episode reward: -9.9000,                 loss: 0.0079
env0_second_0:                 episode reward: 9.9000,                 loss: 0.0082
env1_first_0:                 episode reward: -11.6000,                 loss: nan
env1_second_0:                 episode reward: 11.6000,                 loss: nan
Episode: 7601/10000 (76.0100%),                 avg. length: 1643.35,                last time consumption/overall running time: 1382.0012s / 855595.6418 s
env0_first_0:                 episode reward: -8.7000,                 loss: 0.0087
env0_second_0:                 episode reward: 8.7000,                 loss: 0.0086
env1_first_0:                 episode reward: -11.2000,                 loss: nan
env1_second_0:                 episode reward: 11.2000,                 loss: nan
Episode: 7621/10000 (76.2100%),                 avg. length: 1813.55,                last time consumption/overall running time: 1541.0657s / 857136.7075 s
env0_first_0:                 episode reward: -10.9000,                 loss: 0.0086
env0_second_0:                 episode reward: 10.9000,                 loss: 0.0082
env1_first_0:                 episode reward: -11.2500,                 loss: nan
env1_second_0:                 episode reward: 11.2500,                 loss: nan
Episode: 7641/10000 (76.4100%),                 avg. length: 1626.6,                last time consumption/overall running time: 1377.9643s / 858514.6717 s
env0_first_0:                 episode reward: -12.5000,                 loss: 0.0086
env0_second_0:                 episode reward: 12.5000,                 loss: 0.0079
env1_first_0:                 episode reward: -11.8000,                 loss: nan
env1_second_0:                 episode reward: 11.8000,                 loss: nan
Episode: 7661/10000 (76.6100%),                 avg. length: 1657.3,                last time consumption/overall running time: 1396.2749s / 859910.9466 s
env0_first_0:                 episode reward: -13.6000,                 loss: 0.0077
env0_second_0:                 episode reward: 13.6000,                 loss: 0.0080
env1_first_0:                 episode reward: -12.0000,                 loss: nan
env1_second_0:                 episode reward: 12.0000,                 loss: nan
Episode: 7681/10000 (76.8100%),                 avg. length: 1683.75,                last time consumption/overall running time: 1409.7926s / 861320.7391 s
env0_first_0:                 episode reward: -9.0500,                 loss: 0.0075
env0_second_0:                 episode reward: 9.0500,                 loss: 0.0074
env1_first_0:                 episode reward: -8.7000,                 loss: nan
env1_second_0:                 episode reward: 8.7000,                 loss: nan
Episode: 7701/10000 (77.0100%),                 avg. length: 1631.05,                last time consumption/overall running time: 1354.5361s / 862675.2753 s
env0_first_0:                 episode reward: -9.7500,                 loss: 0.0068
env0_second_0:                 episode reward: 9.7500,                 loss: 0.0068
env1_first_0:                 episode reward: -12.0500,                 loss: nan
env1_second_0:                 episode reward: 12.0500,                 loss: nan
Episode: 7721/10000 (77.2100%),                 avg. length: 1634.05,                last time consumption/overall running time: 1365.4507s / 864040.7259 s
env0_first_0:                 episode reward: -11.3000,                 loss: 0.0072
env0_second_0:                 episode reward: 11.3000,                 loss: 0.0075
env1_first_0:                 episode reward: -10.4000,                 loss: nan
env1_second_0:                 episode reward: 10.4000,                 loss: nan
Episode: 7741/10000 (77.4100%),                 avg. length: 1609.95,                last time consumption/overall running time: 1350.0535s / 865390.7794 s
env0_first_0:                 episode reward: -9.7500,                 loss: 0.0074
env0_second_0:                 episode reward: 9.7500,                 loss: 0.0071
env1_first_0:                 episode reward: -10.9500,                 loss: nan
env1_second_0:                 episode reward: 10.9500,                 loss: nan
Episode: 7761/10000 (77.6100%),                 avg. length: 1681.1,                last time consumption/overall running time: 1402.0932s / 866792.8726 s
env0_first_0:                 episode reward: -10.5000,                 loss: 0.0072
env0_second_0:                 episode reward: 10.5000,                 loss: 0.0073
env1_first_0:                 episode reward: -10.2500,                 loss: nan
env1_second_0:                 episode reward: 10.2500,                 loss: nan
Episode: 7781/10000 (77.8100%),                 avg. length: 1565.0,                last time consumption/overall running time: 1310.2891s / 868103.1617 s
env0_first_0:                 episode reward: -11.0500,                 loss: 0.0074
env0_second_0:                 episode reward: 11.0500,                 loss: 0.0076
env1_first_0:                 episode reward: -12.2000,                 loss: nan
env1_second_0:                 episode reward: 12.2000,                 loss: nan
Episode: 7801/10000 (78.0100%),                 avg. length: 1694.85,                last time consumption/overall running time: 1414.5915s / 869517.7533 s
env0_first_0:                 episode reward: -8.9500,                 loss: 0.0071
env0_second_0:                 episode reward: 8.9500,                 loss: 0.0071
env1_first_0:                 episode reward: -10.0000,                 loss: nan
env1_second_0:                 episode reward: 10.0000,                 loss: nan
Episode: 7821/10000 (78.2100%),                 avg. length: 1774.3,                last time consumption/overall running time: 1478.6592s / 870996.4125 s
env0_first_0:                 episode reward: -9.1000,                 loss: 0.0072
env0_second_0:                 episode reward: 9.1000,                 loss: 0.0070
env1_first_0:                 episode reward: -11.3500,                 loss: nan
env1_second_0:                 episode reward: 11.3500,                 loss: nan
Episode: 7841/10000 (78.4100%),                 avg. length: 1642.55,                last time consumption/overall running time: 1376.9038s / 872373.3163 s
env0_first_0:                 episode reward: -8.2000,                 loss: 0.0077
env0_second_0:                 episode reward: 8.2000,                 loss: 0.0076
env1_first_0:                 episode reward: -9.5500,                 loss: nan
env1_second_0:                 episode reward: 9.5500,                 loss: nan
Episode: 7861/10000 (78.6100%),                 avg. length: 1553.05,                last time consumption/overall running time: 1279.0886s / 873652.4049 s
env0_first_0:                 episode reward: -11.2500,                 loss: 0.0076
env0_second_0:                 episode reward: 11.2500,                 loss: 0.0072
env1_first_0:                 episode reward: -11.9000,                 loss: nan
env1_second_0:                 episode reward: 11.9000,                 loss: nan
Episode: 7881/10000 (78.8100%),                 avg. length: 1531.6,                last time consumption/overall running time: 1257.8969s / 874910.3019 s
env0_first_0:                 episode reward: -12.6500,                 loss: 0.0074
env0_second_0:                 episode reward: 12.6500,                 loss: 0.0070
env1_first_0:                 episode reward: -13.0000,                 loss: nan
env1_second_0:                 episode reward: 13.0000,                 loss: nan
Episode: 7901/10000 (79.0100%),                 avg. length: 1526.65,                last time consumption/overall running time: 1254.9628s / 876165.2646 s
env0_first_0:                 episode reward: -8.4500,                 loss: 0.0070
env0_second_0:                 episode reward: 8.4500,                 loss: 0.0066
env1_first_0:                 episode reward: -9.4000,                 loss: nan
env1_second_0:                 episode reward: 9.4000,                 loss: nan
Episode: 7921/10000 (79.2100%),                 avg. length: 1641.75,                last time consumption/overall running time: 1351.2878s / 877516.5524 s
env0_first_0:                 episode reward: -10.1500,                 loss: 0.0068
env0_second_0:                 episode reward: 10.1500,                 loss: 0.0067
env1_first_0:                 episode reward: -10.7000,                 loss: nan
env1_second_0:                 episode reward: 10.7000,                 loss: nan
Episode: 7941/10000 (79.4100%),                 avg. length: 1695.8,                last time consumption/overall running time: 1395.7409s / 878912.2934 s
env0_first_0:                 episode reward: -10.1000,                 loss: 0.0074
env0_second_0:                 episode reward: 10.1000,                 loss: 0.0070
env1_first_0:                 episode reward: -10.4500,                 loss: nan
env1_second_0:                 episode reward: 10.4500,                 loss: nan
Episode: 7961/10000 (79.6100%),                 avg. length: 1633.85,                last time consumption/overall running time: 1338.2907s / 880250.5841 s
env0_first_0:                 episode reward: -12.2500,                 loss: 0.0079
env0_second_0:                 episode reward: 12.2500,                 loss: 0.0073
env1_first_0:                 episode reward: -13.8500,                 loss: nan
env1_second_0:                 episode reward: 13.8500,                 loss: nan
Episode: 7981/10000 (79.8100%),                 avg. length: 1549.85,                last time consumption/overall running time: 1275.7008s / 881526.2849 s
env0_first_0:                 episode reward: -12.7000,                 loss: 0.0079
env0_second_0:                 episode reward: 12.7000,                 loss: 0.0077
env1_first_0:                 episode reward: -12.8500,                 loss: nan
env1_second_0:                 episode reward: 12.8500,                 loss: nan
Episode: 8001/10000 (80.0100%),                 avg. length: 1586.5,                last time consumption/overall running time: 1312.9503s / 882839.2352 s
env0_first_0:                 episode reward: -14.7000,                 loss: 0.0081
env0_second_0:                 episode reward: 14.7000,                 loss: 0.0080
env1_first_0:                 episode reward: -12.1000,                 loss: nan
env1_second_0:                 episode reward: 12.1000,                 loss: nan
Episode: 8021/10000 (80.2100%),                 avg. length: 1467.4,                last time consumption/overall running time: 1210.8882s / 884050.1234 s
env0_first_0:                 episode reward: -13.3500,                 loss: 0.0080
env0_second_0:                 episode reward: 13.3500,                 loss: 0.0078
env1_first_0:                 episode reward: -12.2000,                 loss: nan
env1_second_0:                 episode reward: 12.2000,                 loss: nan
Episode: 8041/10000 (80.4100%),                 avg. length: 1478.7,                last time consumption/overall running time: 1221.4208s / 885271.5442 s
env0_first_0:                 episode reward: -12.0000,                 loss: 0.0071
env0_second_0:                 episode reward: 12.0000,                 loss: 0.0074
env1_first_0:                 episode reward: -13.0500,                 loss: nan
env1_second_0:                 episode reward: 13.0500,                 loss: nan
Episode: 8061/10000 (80.6100%),                 avg. length: 1509.95,                last time consumption/overall running time: 1243.0483s / 886514.5925 s
env0_first_0:                 episode reward: -10.2000,                 loss: 0.0071
env0_second_0:                 episode reward: 10.2000,                 loss: 0.0072
env1_first_0:                 episode reward: -9.1500,                 loss: nan
env1_second_0:                 episode reward: 9.1500,                 loss: nan
Episode: 8081/10000 (80.8100%),                 avg. length: 1539.1,                last time consumption/overall running time: 1266.0306s / 887780.6231 s
env0_first_0:                 episode reward: -11.9000,                 loss: 0.0065
env0_second_0:                 episode reward: 11.9000,                 loss: 0.0061
env1_first_0:                 episode reward: -9.0500,                 loss: nan
env1_second_0:                 episode reward: 9.0500,                 loss: nan
Episode: 8101/10000 (81.0100%),                 avg. length: 1650.3,                last time consumption/overall running time: 1352.2899s / 889132.9131 s
env0_first_0:                 episode reward: -10.0500,                 loss: 0.0067
env0_second_0:                 episode reward: 10.0500,                 loss: 0.0065
env1_first_0:                 episode reward: -10.9500,                 loss: nan
env1_second_0:                 episode reward: 10.9500,                 loss: nan
Episode: 8121/10000 (81.2100%),                 avg. length: 1550.15,                last time consumption/overall running time: 1266.9418s / 890399.8549 s
env0_first_0:                 episode reward: -11.9500,                 loss: 0.0069
env0_second_0:                 episode reward: 11.9500,                 loss: 0.0074
env1_first_0:                 episode reward: -9.0500,                 loss: nan
env1_second_0:                 episode reward: 9.0500,                 loss: nan
Episode: 8141/10000 (81.4100%),                 avg. length: 1539.4,                last time consumption/overall running time: 1255.0350s / 891654.8899 s
env0_first_0:                 episode reward: -11.6000,                 loss: 0.0071
env0_second_0:                 episode reward: 11.6000,                 loss: 0.0073
env1_first_0:                 episode reward: -12.5500,                 loss: nan
env1_second_0:                 episode reward: 12.5500,                 loss: nan
Episode: 8161/10000 (81.6100%),                 avg. length: 1552.85,                last time consumption/overall running time: 1269.2880s / 892924.1779 s
env0_first_0:                 episode reward: -12.4000,                 loss: 0.0073
env0_second_0:                 episode reward: 12.4000,                 loss: 0.0073
env1_first_0:                 episode reward: -11.2500,                 loss: nan
env1_second_0:                 episode reward: 11.2500,                 loss: nan
Episode: 8181/10000 (81.8100%),                 avg. length: 1663.75,                last time consumption/overall running time: 1354.9662s / 894279.1441 s
env0_first_0:                 episode reward: -13.1500,                 loss: 0.0069
env0_second_0:                 episode reward: 13.1500,                 loss: 0.0074
env1_first_0:                 episode reward: -12.8500,                 loss: nan
env1_second_0:                 episode reward: 12.8500,                 loss: nan
Episode: 8201/10000 (82.0100%),                 avg. length: 1548.15,                last time consumption/overall running time: 1272.4868s / 895551.6309 s
env0_first_0:                 episode reward: -12.0000,                 loss: 0.0076
env0_second_0:                 episode reward: 12.0000,                 loss: 0.0074
env1_first_0:                 episode reward: -12.9000,                 loss: nan
env1_second_0:                 episode reward: 12.9000,                 loss: nan
Episode: 8221/10000 (82.2100%),                 avg. length: 1509.45,                last time consumption/overall running time: 1238.4232s / 896790.0541 s
env0_first_0:                 episode reward: -13.7500,                 loss: 0.0082
env0_second_0:                 episode reward: 13.7500,                 loss: 0.0075
env1_first_0:                 episode reward: -13.7000,                 loss: nan
env1_second_0:                 episode reward: 13.7000,                 loss: nan
Episode: 8241/10000 (82.4100%),                 avg. length: 1454.4,                last time consumption/overall running time: 1185.1876s / 897975.2418 s
env0_first_0:                 episode reward: -13.3500,                 loss: 0.0079
env0_second_0:                 episode reward: 13.3500,                 loss: 0.0073
env1_first_0:                 episode reward: -11.9000,                 loss: nan
env1_second_0:                 episode reward: 11.9000,                 loss: nan
Episode: 8261/10000 (82.6100%),                 avg. length: 1576.95,                last time consumption/overall running time: 1288.8387s / 899264.0805 s
env0_first_0:                 episode reward: -10.3500,                 loss: 0.0076
env0_second_0:                 episode reward: 10.3500,                 loss: 0.0078
env1_first_0:                 episode reward: -11.0000,                 loss: nan
env1_second_0:                 episode reward: 11.0000,                 loss: nan
Episode: 8281/10000 (82.8100%),                 avg. length: 1486.15,                last time consumption/overall running time: 1217.1680s / 900481.2484 s
env0_first_0:                 episode reward: -11.7500,                 loss: 0.0073
env0_second_0:                 episode reward: 11.7500,                 loss: 0.0071
env1_first_0:                 episode reward: -12.3000,                 loss: nan
env1_second_0:                 episode reward: 12.3000,                 loss: nan
Episode: 8301/10000 (83.0100%),                 avg. length: 1457.15,                last time consumption/overall running time: 1192.3704s / 901673.6189 s
env0_first_0:                 episode reward: -12.1000,                 loss: 0.0073
env0_second_0:                 episode reward: 12.1000,                 loss: 0.0066
env1_first_0:                 episode reward: -12.9500,                 loss: nan
env1_second_0:                 episode reward: 12.9500,                 loss: nan
Episode: 8321/10000 (83.2100%),                 avg. length: 1598.25,                last time consumption/overall running time: 1308.1452s / 902981.7641 s
env0_first_0:                 episode reward: -12.6500,                 loss: 0.0070
env0_second_0:                 episode reward: 12.6500,                 loss: 0.0062
env1_first_0:                 episode reward: -12.0500,                 loss: nan
env1_second_0:                 episode reward: 12.0500,                 loss: nan
Episode: 8341/10000 (83.4100%),                 avg. length: 1585.05,                last time consumption/overall running time: 1294.6748s / 904276.4388 s
env0_first_0:                 episode reward: -11.4500,                 loss: 0.0077
env0_second_0:                 episode reward: 11.4500,                 loss: 0.0069
env1_first_0:                 episode reward: -12.3500,                 loss: nan
env1_second_0:                 episode reward: 12.3500,                 loss: nan
Episode: 8361/10000 (83.6100%),                 avg. length: 1675.25,                last time consumption/overall running time: 1370.7154s / 905647.1542 s
env0_first_0:                 episode reward: -12.3500,                 loss: 0.0077
env0_second_0:                 episode reward: 12.3500,                 loss: 0.0070
env1_first_0:                 episode reward: -13.4500,                 loss: nan
env1_second_0:                 episode reward: 13.4500,                 loss: nan
Episode: 8381/10000 (83.8100%),                 avg. length: 1601.85,                last time consumption/overall running time: 1309.0298s / 906956.1840 s
env0_first_0:                 episode reward: -11.8000,                 loss: 0.0084
env0_second_0:                 episode reward: 11.8000,                 loss: 0.0078
env1_first_0:                 episode reward: -10.2500,                 loss: nan
env1_second_0:                 episode reward: 10.2500,                 loss: nan
Episode: 8401/10000 (84.0100%),                 avg. length: 1491.45,                last time consumption/overall running time: 1219.3326s / 908175.5167 s
env0_first_0:                 episode reward: -11.4000,                 loss: 0.0070
env0_second_0:                 episode reward: 11.4000,                 loss: 0.0067
env1_first_0:                 episode reward: -11.4500,                 loss: nan
env1_second_0:                 episode reward: 11.4500,                 loss: nan
Episode: 8421/10000 (84.2100%),                 avg. length: 1505.6,                last time consumption/overall running time: 1226.3085s / 909401.8252 s
env0_first_0:                 episode reward: -10.4000,                 loss: 0.0072
env0_second_0:                 episode reward: 10.4000,                 loss: 0.0066
env1_first_0:                 episode reward: -13.3500,                 loss: nan
env1_second_0:                 episode reward: 13.3500,                 loss: nan
Episode: 8441/10000 (84.4100%),                 avg. length: 1541.15,                last time consumption/overall running time: 1256.7802s / 910658.6054 s
env0_first_0:                 episode reward: -10.5500,                 loss: 0.0073
env0_second_0:                 episode reward: 10.5500,                 loss: 0.0067
env1_first_0:                 episode reward: -11.0000,                 loss: nan
env1_second_0:                 episode reward: 11.0000,                 loss: nan
Episode: 8461/10000 (84.6100%),                 avg. length: 1496.2,                last time consumption/overall running time: 1217.3447s / 911875.9501 s
env0_first_0:                 episode reward: -12.3000,                 loss: 0.0076
env0_second_0:                 episode reward: 12.3000,                 loss: 0.0070
env1_first_0:                 episode reward: -12.1500,                 loss: nan
env1_second_0:                 episode reward: 12.1500,                 loss: nan
Episode: 8481/10000 (84.8100%),                 avg. length: 1555.0,                last time consumption/overall running time: 1270.1963s / 913146.1464 s
env0_first_0:                 episode reward: -13.1500,                 loss: 0.0075
env0_second_0:                 episode reward: 13.1500,                 loss: 0.0069
env1_first_0:                 episode reward: -12.4500,                 loss: nan
env1_second_0:                 episode reward: 12.4500,                 loss: nan
Episode: 8501/10000 (85.0100%),                 avg. length: 1567.9,                last time consumption/overall running time: 1283.6041s / 914429.7505 s
env0_first_0:                 episode reward: -12.4000,                 loss: 0.0072
env0_second_0:                 episode reward: 12.4000,                 loss: 0.0065
env1_first_0:                 episode reward: -13.0500,                 loss: nan
env1_second_0:                 episode reward: 13.0500,                 loss: nan
Episode: 8521/10000 (85.2100%),                 avg. length: 1541.7,                last time consumption/overall running time: 1255.2261s / 915684.9767 s
env0_first_0:                 episode reward: -12.5000,                 loss: 0.0076
env0_second_0:                 episode reward: 12.5000,                 loss: 0.0073
env1_first_0:                 episode reward: -12.8500,                 loss: nan
env1_second_0:                 episode reward: 12.8500,                 loss: nan
Episode: 8541/10000 (85.4100%),                 avg. length: 1541.85,                last time consumption/overall running time: 1256.4401s / 916941.4168 s
env0_first_0:                 episode reward: -11.0500,                 loss: 0.0076
env0_second_0:                 episode reward: 11.0500,                 loss: 0.0075
env1_first_0:                 episode reward: -12.3500,                 loss: nan
env1_second_0:                 episode reward: 12.3500,                 loss: nan
Episode: 8561/10000 (85.6100%),                 avg. length: 1522.05,                last time consumption/overall running time: 1239.9350s / 918181.3518 s
env0_first_0:                 episode reward: -12.6500,                 loss: 0.0072
env0_second_0:                 episode reward: 12.6500,                 loss: 0.0077
env1_first_0:                 episode reward: -12.3000,                 loss: nan
env1_second_0:                 episode reward: 12.3000,                 loss: nan
Episode: 8581/10000 (85.8100%),                 avg. length: 1524.0,                last time consumption/overall running time: 1247.7457s / 919429.0975 s
env0_first_0:                 episode reward: -10.9500,                 loss: 0.0072
env0_second_0:                 episode reward: 10.9500,                 loss: 0.0080
env1_first_0:                 episode reward: -12.6000,                 loss: nan
env1_second_0:                 episode reward: 12.6000,                 loss: nan
Episode: 8601/10000 (86.0100%),                 avg. length: 1483.4,                last time consumption/overall running time: 1217.9258s / 920647.0233 s
env0_first_0:                 episode reward: -13.1500,                 loss: 0.0071
env0_second_0:                 episode reward: 13.1500,                 loss: 0.0074
env1_first_0:                 episode reward: -12.9000,                 loss: nan
env1_second_0:                 episode reward: 12.9000,                 loss: nan
Episode: 8621/10000 (86.2100%),                 avg. length: 1605.7,                last time consumption/overall running time: 1301.0707s / 921948.0941 s
env0_first_0:                 episode reward: -11.3500,                 loss: 0.0076
env0_second_0:                 episode reward: 11.3500,                 loss: 0.0071
env1_first_0:                 episode reward: -12.3500,                 loss: nan
env1_second_0:                 episode reward: 12.3500,                 loss: nan
Episode: 8641/10000 (86.4100%),                 avg. length: 1534.95,                last time consumption/overall running time: 1253.4385s / 923201.5325 s
env0_first_0:                 episode reward: -12.9000,                 loss: 0.0085
env0_second_0:                 episode reward: 12.9000,                 loss: 0.0081
env1_first_0:                 episode reward: -11.6500,                 loss: nan
env1_second_0:                 episode reward: 11.6500,                 loss: nan
Episode: 8661/10000 (86.6100%),                 avg. length: 1492.35,                last time consumption/overall running time: 1222.3342s / 924423.8667 s
env0_first_0:                 episode reward: -10.4500,                 loss: 0.0083
env0_second_0:                 episode reward: 10.4500,                 loss: 0.0086
env1_first_0:                 episode reward: -13.2500,                 loss: nan
env1_second_0:                 episode reward: 13.2500,                 loss: nan
Episode: 8681/10000 (86.8100%),                 avg. length: 1630.65,                last time consumption/overall running time: 1334.0665s / 925757.9332 s
env0_first_0:                 episode reward: -13.5000,                 loss: 0.0090
env0_second_0:                 episode reward: 13.5000,                 loss: 0.0090
env1_first_0:                 episode reward: -13.6000,                 loss: nan
env1_second_0:                 episode reward: 13.6000,                 loss: nan
Episode: 8701/10000 (87.0100%),                 avg. length: 1760.85,                last time consumption/overall running time: 1439.7247s / 927197.6579 s
env0_first_0:                 episode reward: -13.1500,                 loss: 0.0090
env0_second_0:                 episode reward: 13.1500,                 loss: 0.0083
env1_first_0:                 episode reward: -13.5000,                 loss: nan
env1_second_0:                 episode reward: 13.5000,                 loss: nan
Episode: 8721/10000 (87.2100%),                 avg. length: 1689.05,                last time consumption/overall running time: 1368.7005s / 928566.3585 s
env0_first_0:                 episode reward: -14.0500,                 loss: 0.0087
env0_second_0:                 episode reward: 14.0500,                 loss: 0.0083
env1_first_0:                 episode reward: -13.2000,                 loss: nan
env1_second_0:                 episode reward: 13.2000,                 loss: nan
Episode: 8741/10000 (87.4100%),                 avg. length: 1820.3,                last time consumption/overall running time: 1481.7523s / 930048.1108 s
env0_first_0:                 episode reward: -9.0500,                 loss: 0.0093
env0_second_0:                 episode reward: 9.0500,                 loss: 0.0089
env1_first_0:                 episode reward: -12.3500,                 loss: nan
env1_second_0:                 episode reward: 12.3500,                 loss: nan
Episode: 8761/10000 (87.6100%),                 avg. length: 1697.25,                last time consumption/overall running time: 1396.6792s / 931444.7899 s
env0_first_0:                 episode reward: -9.5000,                 loss: 0.0101
env0_second_0:                 episode reward: 9.5000,                 loss: 0.0100
env1_first_0:                 episode reward: -10.4500,                 loss: nan
env1_second_0:                 episode reward: 10.4500,                 loss: nan
Episode: 8781/10000 (87.8100%),                 avg. length: 1607.2,                last time consumption/overall running time: 1310.7108s / 932755.5007 s
env0_first_0:                 episode reward: -12.8000,                 loss: 0.0092
env0_second_0:                 episode reward: 12.8000,                 loss: 0.0094
env1_first_0:                 episode reward: -14.2500,                 loss: nan
env1_second_0:                 episode reward: 14.2500,                 loss: nan
Episode: 8801/10000 (88.0100%),                 avg. length: 1662.7,                last time consumption/overall running time: 1356.5043s / 934112.0049 s
env0_first_0:                 episode reward: -14.3000,                 loss: 0.0089
env0_second_0:                 episode reward: 14.3000,                 loss: 0.0090
env1_first_0:                 episode reward: -13.9000,                 loss: nan
env1_second_0:                 episode reward: 13.9000,                 loss: nan
Episode: 8821/10000 (88.2100%),                 avg. length: 1647.55,                last time consumption/overall running time: 1342.8513s / 935454.8562 s
env0_first_0:                 episode reward: -13.6000,                 loss: 0.0089
env0_second_0:                 episode reward: 13.6000,                 loss: 0.0083
env1_first_0:                 episode reward: -15.3500,                 loss: nan
env1_second_0:                 episode reward: 15.3500,                 loss: nan
Episode: 8841/10000 (88.4100%),                 avg. length: 1559.95,                last time consumption/overall running time: 1271.0194s / 936725.8756 s
env0_first_0:                 episode reward: -10.9500,                 loss: 0.0088
env0_second_0:                 episode reward: 10.9500,                 loss: 0.0085
env1_first_0:                 episode reward: -12.0500,                 loss: nan
env1_second_0:                 episode reward: 12.0500,                 loss: nan
Episode: 8861/10000 (88.6100%),                 avg. length: 1535.15,                last time consumption/overall running time: 1246.4203s / 937972.2959 s
env0_first_0:                 episode reward: -13.4500,                 loss: 0.0079
env0_second_0:                 episode reward: 13.4500,                 loss: 0.0078
env1_first_0:                 episode reward: -13.8500,                 loss: nan
env1_second_0:                 episode reward: 13.8500,                 loss: nan
Episode: 8881/10000 (88.8100%),                 avg. length: 1521.45,                last time consumption/overall running time: 1234.7343s / 939207.0302 s
env0_first_0:                 episode reward: -12.2000,                 loss: 0.0079
env0_second_0:                 episode reward: 12.2000,                 loss: 0.0077
env1_first_0:                 episode reward: -13.4500,                 loss: nan
env1_second_0:                 episode reward: 13.4500,                 loss: nan
Episode: 8901/10000 (89.0100%),                 avg. length: 1684.5,                last time consumption/overall running time: 1377.8789s / 940584.9091 s
env0_first_0:                 episode reward: -12.5500,                 loss: 0.0083
env0_second_0:                 episode reward: 12.5500,                 loss: 0.0085
env1_first_0:                 episode reward: -11.8500,                 loss: nan
env1_second_0:                 episode reward: 11.8500,                 loss: nan
Episode: 8921/10000 (89.2100%),                 avg. length: 1655.85,                last time consumption/overall running time: 1351.9637s / 941936.8728 s
env0_first_0:                 episode reward: -12.8000,                 loss: 0.0091
env0_second_0:                 episode reward: 12.8000,                 loss: 0.0088
env1_first_0:                 episode reward: -16.2500,                 loss: nan
env1_second_0:                 episode reward: 16.2500,                 loss: nan
Episode: 8941/10000 (89.4100%),                 avg. length: 1712.0,                last time consumption/overall running time: 1398.7178s / 943335.5906 s
env0_first_0:                 episode reward: -14.4500,                 loss: 0.0096
env0_second_0:                 episode reward: 14.4500,                 loss: 0.0093
env1_first_0:                 episode reward: -11.3500,                 loss: nan
env1_second_0:                 episode reward: 11.3500,                 loss: nan
Episode: 8961/10000 (89.6100%),                 avg. length: 1756.5,                last time consumption/overall running time: 1433.9813s / 944769.5719 s
env0_first_0:                 episode reward: -14.4500,                 loss: 0.0100
env0_second_0:                 episode reward: 14.4500,                 loss: 0.0091
env1_first_0:                 episode reward: -14.0000,                 loss: nan
env1_second_0:                 episode reward: 14.0000,                 loss: nan
Episode: 8981/10000 (89.8100%),                 avg. length: 1914.9,                last time consumption/overall running time: 1562.8744s / 946332.4464 s
env0_first_0:                 episode reward: -12.8000,                 loss: 0.0108
env0_second_0:                 episode reward: 12.8000,                 loss: 0.0102
env1_first_0:                 episode reward: -16.1000,                 loss: nan
env1_second_0:                 episode reward: 16.1000,                 loss: nan
Episode: 9001/10000 (90.0100%),                 avg. length: 1637.1,                last time consumption/overall running time: 1335.0796s / 947667.5260 s
env0_first_0:                 episode reward: -12.3000,                 loss: 0.0106
env0_second_0:                 episode reward: 12.3000,                 loss: 0.0100
env1_first_0:                 episode reward: -12.4000,                 loss: nan
env1_second_0:                 episode reward: 12.4000,                 loss: nan
Episode: 9021/10000 (90.2100%),                 avg. length: 1634.0,                last time consumption/overall running time: 1324.8349s / 948992.3609 s
env0_first_0:                 episode reward: -10.5500,                 loss: 0.0091
env0_second_0:                 episode reward: 10.5500,                 loss: 0.0089
env1_first_0:                 episode reward: -11.6500,                 loss: nan
env1_second_0:                 episode reward: 11.6500,                 loss: nan
Episode: 9041/10000 (90.4100%),                 avg. length: 1474.95,                last time consumption/overall running time: 1207.7190s / 950200.0799 s
env0_first_0:                 episode reward: -12.7500,                 loss: 0.0087
env0_second_0:                 episode reward: 12.7500,                 loss: 0.0081
env1_first_0:                 episode reward: -11.7000,                 loss: nan
env1_second_0:                 episode reward: 11.7000,                 loss: nan
Episode: 9061/10000 (90.6100%),                 avg. length: 1681.25,                last time consumption/overall running time: 1369.6859s / 951569.7658 s
env0_first_0:                 episode reward: -11.5000,                 loss: 0.0085
env0_second_0:                 episode reward: 11.5000,                 loss: 0.0077
env1_first_0:                 episode reward: -11.9000,                 loss: nan
env1_second_0:                 episode reward: 11.9000,                 loss: nan
Episode: 9081/10000 (90.8100%),                 avg. length: 1643.8,                last time consumption/overall running time: 1336.6711s / 952906.4369 s
env0_first_0:                 episode reward: -9.2500,                 loss: 0.0091
env0_second_0:                 episode reward: 9.2500,                 loss: 0.0083
env1_first_0:                 episode reward: -11.6500,                 loss: nan
env1_second_0:                 episode reward: 11.6500,                 loss: nan
Episode: 9101/10000 (91.0100%),                 avg. length: 1813.05,                last time consumption/overall running time: 1479.5140s / 954385.9509 s
env0_first_0:                 episode reward: -10.9500,                 loss: 0.0099
env0_second_0:                 episode reward: 10.9500,                 loss: 0.0089
env1_first_0:                 episode reward: -12.8500,                 loss: nan
env1_second_0:                 episode reward: 12.8500,                 loss: nan
Episode: 9121/10000 (91.2100%),                 avg. length: 1584.2,                last time consumption/overall running time: 1297.6112s / 955683.5621 s
env0_first_0:                 episode reward: -9.1500,                 loss: 0.0101
env0_second_0:                 episode reward: 9.1500,                 loss: 0.0085
env1_first_0:                 episode reward: -9.5500,                 loss: nan
env1_second_0:                 episode reward: 9.5500,                 loss: nan
Episode: 9141/10000 (91.4100%),                 avg. length: 1879.05,                last time consumption/overall running time: 1526.6981s / 957210.2602 s
env0_first_0:                 episode reward: -12.5500,                 loss: 0.0085
env0_second_0:                 episode reward: 12.5500,                 loss: 0.0080
env1_first_0:                 episode reward: -12.5000,                 loss: nan
env1_second_0:                 episode reward: 12.5000,                 loss: nan
Episode: 9161/10000 (91.6100%),                 avg. length: 1650.8,                last time consumption/overall running time: 1337.3080s / 958547.5682 s
env0_first_0:                 episode reward: -10.1000,                 loss: 0.0092
env0_second_0:                 episode reward: 10.1000,                 loss: 0.0084
env1_first_0:                 episode reward: -9.3500,                 loss: nan
env1_second_0:                 episode reward: 9.3500,                 loss: nan
Episode: 9181/10000 (91.8100%),                 avg. length: 1640.75,                last time consumption/overall running time: 1330.0477s / 959877.6160 s
env0_first_0:                 episode reward: -11.4500,                 loss: 0.0096
env0_second_0:                 episode reward: 11.4500,                 loss: 0.0082
env1_first_0:                 episode reward: -9.1000,                 loss: nan
env1_second_0:                 episode reward: 9.1000,                 loss: nan
Episode: 9201/10000 (92.0100%),                 avg. length: 1622.75,                last time consumption/overall running time: 1323.5794s / 961201.1953 s
env0_first_0:                 episode reward: -10.2500,                 loss: 0.0090
env0_second_0:                 episode reward: 10.2500,                 loss: 0.0075
env1_first_0:                 episode reward: -11.0500,                 loss: nan
env1_second_0:                 episode reward: 11.0500,                 loss: nan
Episode: 9221/10000 (92.2100%),                 avg. length: 1640.55,                last time consumption/overall running time: 1325.8231s / 962527.0185 s
env0_first_0:                 episode reward: -10.6500,                 loss: 0.0076
env0_second_0:                 episode reward: 10.6500,                 loss: 0.0071
env1_first_0:                 episode reward: -10.7000,                 loss: nan
env1_second_0:                 episode reward: 10.7000,                 loss: nan
Episode: 9241/10000 (92.4100%),                 avg. length: 1552.5,                last time consumption/overall running time: 1246.4372s / 963773.4557 s
env0_first_0:                 episode reward: -10.2500,                 loss: 0.0074
env0_second_0:                 episode reward: 10.2500,                 loss: 0.0072
env1_first_0:                 episode reward: -8.6000,                 loss: nan
env1_second_0:                 episode reward: 8.6000,                 loss: nan
Episode: 9261/10000 (92.6100%),                 avg. length: 1536.6,                last time consumption/overall running time: 1245.2625s / 965018.7182 s
env0_first_0:                 episode reward: -12.1000,                 loss: 0.0074
env0_second_0:                 episode reward: 12.1000,                 loss: 0.0069
env1_first_0:                 episode reward: -11.5000,                 loss: nan
env1_second_0:                 episode reward: 11.5000,                 loss: nan
Episode: 9281/10000 (92.8100%),                 avg. length: 1566.0,                last time consumption/overall running time: 1255.6489s / 966274.3671 s
env0_first_0:                 episode reward: -11.9000,                 loss: 0.0080
env0_second_0:                 episode reward: 11.9000,                 loss: 0.0071
env1_first_0:                 episode reward: -12.7000,                 loss: nan
env1_second_0:                 episode reward: 12.7000,                 loss: nan
Episode: 9301/10000 (93.0100%),                 avg. length: 1618.9,                last time consumption/overall running time: 1301.3487s / 967575.7158 s
env0_first_0:                 episode reward: -11.2500,                 loss: 0.0083
env0_second_0:                 episode reward: 11.2500,                 loss: 0.0077
env1_first_0:                 episode reward: -12.0000,                 loss: nan
env1_second_0:                 episode reward: 12.0000,                 loss: nan
Episode: 9321/10000 (93.2100%),                 avg. length: 1633.5,                last time consumption/overall running time: 1315.5464s / 968891.2622 s
env0_first_0:                 episode reward: -13.4000,                 loss: 0.0079
env0_second_0:                 episode reward: 13.4000,                 loss: 0.0080
env1_first_0:                 episode reward: -11.6500,                 loss: nan
env1_second_0:                 episode reward: 11.6500,                 loss: nan
Episode: 9341/10000 (93.4100%),                 avg. length: 1688.25,                last time consumption/overall running time: 1362.6799s / 970253.9421 s
env0_first_0:                 episode reward: -11.9000,                 loss: 0.0083
env0_second_0:                 episode reward: 11.9000,                 loss: 0.0082
env1_first_0:                 episode reward: -10.3500,                 loss: nan
env1_second_0:                 episode reward: 10.3500,                 loss: nan
Episode: 9361/10000 (93.6100%),                 avg. length: 1693.75,                last time consumption/overall running time: 1374.3595s / 971628.3017 s
env0_first_0:                 episode reward: -12.9500,                 loss: 0.0081
env0_second_0:                 episode reward: 12.9500,                 loss: 0.0080
env1_first_0:                 episode reward: -12.9500,                 loss: nan
env1_second_0:                 episode reward: 12.9500,                 loss: nan
Episode: 9381/10000 (93.8100%),                 avg. length: 1557.75,                last time consumption/overall running time: 1256.4719s / 972884.7735 s
env0_first_0:                 episode reward: -13.1000,                 loss: 0.0082
env0_second_0:                 episode reward: 13.1000,                 loss: 0.0078
env1_first_0:                 episode reward: -10.7500,                 loss: nan
env1_second_0:                 episode reward: 10.7500,                 loss: nan
Episode: 9401/10000 (94.0100%),                 avg. length: 1596.1,                last time consumption/overall running time: 1268.0240s / 974152.7976 s
env0_first_0:                 episode reward: -11.4000,                 loss: 0.0081
env0_second_0:                 episode reward: 11.4000,                 loss: 0.0079
env1_first_0:                 episode reward: -11.7000,                 loss: nan
env1_second_0:                 episode reward: 11.7000,                 loss: nan
Episode: 9421/10000 (94.2100%),                 avg. length: 1545.9,                last time consumption/overall running time: 1244.0811s / 975396.8787 s
env0_first_0:                 episode reward: -13.1500,                 loss: 0.0077
env0_second_0:                 episode reward: 13.1500,                 loss: 0.0078
env1_first_0:                 episode reward: -11.5500,                 loss: nan
env1_second_0:                 episode reward: 11.5500,                 loss: nan
Episode: 9441/10000 (94.4100%),                 avg. length: 1585.35,                last time consumption/overall running time: 1285.8817s / 976682.7603 s
env0_first_0:                 episode reward: -11.5000,                 loss: 0.0073
env0_second_0:                 episode reward: 11.5000,                 loss: 0.0074
env1_first_0:                 episode reward: -13.7000,                 loss: nan
env1_second_0:                 episode reward: 13.7000,                 loss: nan
Episode: 9461/10000 (94.6100%),                 avg. length: 1613.55,                last time consumption/overall running time: 1302.6636s / 977985.4239 s
env0_first_0:                 episode reward: -11.7000,                 loss: 0.0072
env0_second_0:                 episode reward: 11.7000,                 loss: 0.0072
env1_first_0:                 episode reward: -11.4000,                 loss: nan
env1_second_0:                 episode reward: 11.4000,                 loss: nan
Episode: 9481/10000 (94.8100%),                 avg. length: 1471.7,                last time consumption/overall running time: 1190.8003s / 979176.2242 s
env0_first_0:                 episode reward: -11.9500,                 loss: 0.0069
env0_second_0:                 episode reward: 11.9500,                 loss: 0.0073
env1_first_0:                 episode reward: -15.1500,                 loss: nan
env1_second_0:                 episode reward: 15.1500,                 loss: nan
Episode: 9501/10000 (95.0100%),                 avg. length: 1418.75,                last time consumption/overall running time: 1147.3704s / 980323.5947 s
env0_first_0:                 episode reward: -13.2000,                 loss: 0.0073
env0_second_0:                 episode reward: 13.2000,                 loss: 0.0073
env1_first_0:                 episode reward: -12.9500,                 loss: nan
env1_second_0:                 episode reward: 12.9500,                 loss: nan
Episode: 9521/10000 (95.2100%),                 avg. length: 1417.55,                last time consumption/overall running time: 1144.4069s / 981468.0016 s
env0_first_0:                 episode reward: -10.4500,                 loss: 0.0075
env0_second_0:                 episode reward: 10.4500,                 loss: 0.0076
env1_first_0:                 episode reward: -11.4000,                 loss: nan
env1_second_0:                 episode reward: 11.4000,                 loss: nan
Episode: 9541/10000 (95.4100%),                 avg. length: 1540.5,                last time consumption/overall running time: 1241.9489s / 982709.9504 s
env0_first_0:                 episode reward: -11.1500,                 loss: 0.0074
env0_second_0:                 episode reward: 11.1500,                 loss: 0.0081
env1_first_0:                 episode reward: -11.1000,                 loss: nan
env1_second_0:                 episode reward: 11.1000,                 loss: nan
Episode: 9561/10000 (95.6100%),                 avg. length: 1528.95,                last time consumption/overall running time: 1238.1093s / 983948.0597 s
env0_first_0:                 episode reward: -13.0500,                 loss: 0.0072
env0_second_0:                 episode reward: 13.0500,                 loss: 0.0080
env1_first_0:                 episode reward: -13.6500,                 loss: nan
env1_second_0:                 episode reward: 13.6500,                 loss: nan
Episode: 9581/10000 (95.8100%),                 avg. length: 1590.95,                last time consumption/overall running time: 1281.7810s / 985229.8407 s
env0_first_0:                 episode reward: -12.8000,                 loss: 0.0076
env0_second_0:                 episode reward: 12.8000,                 loss: 0.0083
env1_first_0:                 episode reward: -10.7500,                 loss: nan
env1_second_0:                 episode reward: 10.7500,                 loss: nan
Episode: 9601/10000 (96.0100%),                 avg. length: 1744.15,                last time consumption/overall running time: 1402.5598s / 986632.4005 s
env0_first_0:                 episode reward: -11.3500,                 loss: 0.0079
env0_second_0:                 episode reward: 11.3500,                 loss: 0.0083
env1_first_0:                 episode reward: -13.2000,                 loss: nan
env1_second_0:                 episode reward: 13.2000,                 loss: nan
Episode: 9621/10000 (96.2100%),                 avg. length: 1658.55,                last time consumption/overall running time: 1334.4624s / 987966.8629 s
env0_first_0:                 episode reward: -11.7500,                 loss: 0.0080
env0_second_0:                 episode reward: 11.7500,                 loss: 0.0087
env1_first_0:                 episode reward: -11.9500,                 loss: nan
env1_second_0:                 episode reward: 11.9500,                 loss: nan
Episode: 9641/10000 (96.4100%),                 avg. length: 1507.5,                last time consumption/overall running time: 1214.2952s / 989181.1581 s
env0_first_0:                 episode reward: -12.6500,                 loss: 0.0078
env0_second_0:                 episode reward: 12.6500,                 loss: 0.0089
env1_first_0:                 episode reward: -13.9000,                 loss: nan
env1_second_0:                 episode reward: 13.9000,                 loss: nan
Episode: 9661/10000 (96.6100%),                 avg. length: 1618.95,                last time consumption/overall running time: 1303.4434s / 990484.6015 s
env0_first_0:                 episode reward: -10.6500,                 loss: 0.0078
env0_second_0:                 episode reward: 10.6500,                 loss: 0.0087
env1_first_0:                 episode reward: -11.8000,                 loss: nan
env1_second_0:                 episode reward: 11.8000,                 loss: nan
Episode: 9681/10000 (96.8100%),                 avg. length: 1761.85,                last time consumption/overall running time: 1423.7209s / 991908.3223 s
env0_first_0:                 episode reward: -11.3500,                 loss: 0.0083
env0_second_0:                 episode reward: 11.3500,                 loss: 0.0083
env1_first_0:                 episode reward: -10.9000,                 loss: nan
env1_second_0:                 episode reward: 10.9000,                 loss: nan
Episode: 9701/10000 (97.0100%),                 avg. length: 1655.65,                last time consumption/overall running time: 1337.9664s / 993246.2887 s
env0_first_0:                 episode reward: -9.5000,                 loss: 0.0078
env0_second_0:                 episode reward: 9.5000,                 loss: 0.0079
env1_first_0:                 episode reward: -11.1000,                 loss: nan
env1_second_0:                 episode reward: 11.1000,                 loss: nan
Episode: 9721/10000 (97.2100%),                 avg. length: 1715.15,                last time consumption/overall running time: 1383.1443s / 994629.4330 s
env0_first_0:                 episode reward: -10.4500,                 loss: 0.0077
env0_second_0:                 episode reward: 10.4500,                 loss: 0.0078
env1_first_0:                 episode reward: -9.8000,                 loss: nan
env1_second_0:                 episode reward: 9.8000,                 loss: nan
Episode: 9741/10000 (97.4100%),                 avg. length: 1625.65,                last time consumption/overall running time: 1312.7739s / 995942.2069 s
env0_first_0:                 episode reward: -10.7000,                 loss: 0.0077
env0_second_0:                 episode reward: 10.7000,                 loss: 0.0080
env1_first_0:                 episode reward: -10.8000,                 loss: nan
env1_second_0:                 episode reward: 10.8000,                 loss: nan
Episode: 9761/10000 (97.6100%),                 avg. length: 1639.45,                last time consumption/overall running time: 1318.8166s / 997261.0236 sLoad double_dunk_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
Load double_dunk_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
/home/zihan/research/MARS/mars/rl/agents/nash_dqn_exploiter.py:174: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1641801999604/work/torch/csrc/utils/tensor_new.cpp:210.)
  action = torch.LongTensor(action).to(self.device)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

env0_first_0:                 episode reward: -13.4500,                 loss: 0.0084
env0_second_0:                 episode reward: 13.4500,                 loss: 0.0087
env1_first_0:                 episode reward: -14.1000,                 loss: nan
env1_second_0:                 episode reward: 14.1000,                 loss: nan
Episode: 9781/10000 (97.8100%),                 avg. length: 1613.6,                last time consumption/overall running time: 1296.0176s / 998557.0412 s
env0_first_0:                 episode reward: -13.8500,                 loss: 0.0077
env0_second_0:                 episode reward: 13.8500,                 loss: 0.0078
env1_first_0:                 episode reward: -12.6500,                 loss: nan
env1_second_0:                 episode reward: 12.6500,                 loss: nan
Episode: 9801/10000 (98.0100%),                 avg. length: 1591.15,                last time consumption/overall running time: 1270.2521s / 999827.2933 s
env0_first_0:                 episode reward: -13.0500,                 loss: 0.0082
env0_second_0:                 episode reward: 13.0500,                 loss: 0.0078
env1_first_0:                 episode reward: -13.0500,                 loss: nan
env1_second_0:                 episode reward: 13.0500,                 loss: nan
Episode: 9821/10000 (98.2100%),                 avg. length: 1613.75,                last time consumption/overall running time: 1294.8758s / 1001122.1691 s
env0_first_0:                 episode reward: -10.2500,                 loss: 0.0084
env0_second_0:                 episode reward: 10.2500,                 loss: 0.0082
env1_first_0:                 episode reward: -10.6500,                 loss: nan
env1_second_0:                 episode reward: 10.6500,                 loss: nan
Episode: 9841/10000 (98.4100%),                 avg. length: 1528.55,                last time consumption/overall running time: 1229.7611s / 1002351.9301 s
env0_first_0:                 episode reward: -12.3000,                 loss: 0.0084
env0_second_0:                 episode reward: 12.3000,                 loss: 0.0076
env1_first_0:                 episode reward: -13.5500,                 loss: nan
env1_second_0:                 episode reward: 13.5500,                 loss: nan
Episode: 9861/10000 (98.6100%),                 avg. length: 1519.75,                last time consumption/overall running time: 1227.4896s / 1003579.4197 s
env0_first_0:                 episode reward: -11.3500,                 loss: 0.0075
env0_second_0:                 episode reward: 11.3500,                 loss: 0.0073
env1_first_0:                 episode reward: -11.6000,                 loss: nan
env1_second_0:                 episode reward: 11.6000,                 loss: nan
Episode: 9881/10000 (98.8100%),                 avg. length: 1486.25,                last time consumption/overall running time: 1199.5266s / 1004778.9464 s
env0_first_0:                 episode reward: -12.6000,                 loss: 0.0077
env0_second_0:                 episode reward: 12.6000,                 loss: 0.0073
env1_first_0:                 episode reward: -12.5500,                 loss: nan
env1_second_0:                 episode reward: 12.5500,                 loss: nan
Episode: 9901/10000 (99.0100%),                 avg. length: 1525.1,                last time consumption/overall running time: 1231.4285s / 1006010.3748 s
env0_first_0:                 episode reward: -10.3000,                 loss: 0.0080
env0_second_0:                 episode reward: 10.3000,                 loss: 0.0075
env1_first_0:                 episode reward: -11.4000,                 loss: nan
env1_second_0:                 episode reward: 11.4000,                 loss: nan
Episode: 9921/10000 (99.2100%),                 avg. length: 1608.75,                last time consumption/overall running time: 1297.7748s / 1007308.1496 s
env0_first_0:                 episode reward: -9.9500,                 loss: 0.0077
env0_second_0:                 episode reward: 9.9500,                 loss: 0.0077
env1_first_0:                 episode reward: -12.2000,                 loss: nan
env1_second_0:                 episode reward: 12.2000,                 loss: nan
Episode: 9941/10000 (99.4100%),                 avg. length: 1697.05,                last time consumption/overall running time: 1379.1241s / 1008687.2737 s
env0_first_0:                 episode reward: -11.7000,                 loss: 0.0086
env0_second_0:                 episode reward: 11.7000,                 loss: 0.0084
env1_first_0:                 episode reward: -11.7000,                 loss: nan
env1_second_0:                 episode reward: 11.7000,                 loss: nan
Episode: 9961/10000 (99.6100%),                 avg. length: 1623.65,                last time consumption/overall running time: 1310.0273s / 1009997.3010 s
env0_first_0:                 episode reward: -11.2500,                 loss: 0.0080
env0_second_0:                 episode reward: 11.2500,                 loss: 0.0079
env1_first_0:                 episode reward: -11.4500,                 loss: nan
env1_second_0:                 episode reward: 11.4500,                 loss: nan
Episode: 9981/10000 (99.8100%),                 avg. length: 1617.6,                last time consumption/overall running time: 1301.4044s / 1011298.7055 s
env0_first_0:                 episode reward: -11.5500,                 loss: 0.0073
env0_second_0:                 episode reward: 11.5500,                 loss: 0.0074
env1_first_0:                 episode reward: -13.2000,                 loss: nan
env1_second_0:                 episode reward: 13.2000,                 loss: nan
