pygame 2.0.0 (SDL 2.0.12, python 3.7.10)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 12.0, (1,), float32) action space: Discrete(3)
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7fbe9c83add0>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
Agents No. [0] (index starting from 0) are not learnable.
Load meta strategy:  [[0.01 0.01 0.01 ... 0.01 0.01 0.01]
 [0.01 0.01 0.01 ... 0.01 0.01 0.01]]
Load checkpoints (policy family):  [['50' '5253' '7615' ... '58686' '59037' '59319']
 ['193' '5289' '7712' ... '58826' '59185' '59425']]
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': 1, 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000, 'update_itr': 1}, 'batch_size': 640, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'cpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220117153310/epi_60000/', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'fictitious_selfplay2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'selfplay_score_delta': 1.5, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'against_baseline': False}
Save models to : /home/zihan/research/MARS/data/model/20220117153310_exploit_60000/mdp_arbitrary_mdp_fictitious_selfplay2. 
 Save logs to: /home/zihan/research/MARS/data/log/20220117153310_exploit_60000/mdp_arbitrary_mdp_fictitious_selfplay2.
Episode: 1/30000 (0.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 5.4602s / 5.4602 s
agent0:                 episode reward: -1.6958,                 loss: nan
agent1:                 episode reward: 1.6958,                 loss: nan
Episode: 21/30000 (0.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 6.8367s / 12.2969 s
agent0:                 episode reward: 0.0561,                 loss: nan
agent1:                 episode reward: -0.0561,                 loss: nan
Episode: 41/30000 (0.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 6.4299s / 18.7268 s
agent0:                 episode reward: -0.0892,                 loss: nan
agent1:                 episode reward: 0.0892,                 loss: nan
Episode: 61/30000 (0.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 6.2239s / 24.9507 s
agent0:                 episode reward: 0.3302,                 loss: nan
agent1:                 episode reward: -0.3302,                 loss: nan
Episode: 81/30000 (0.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 6.1279s / 31.0786 s
agent0:                 episode reward: -0.2355,                 loss: nan
agent1:                 episode reward: 0.2355,                 loss: nan
Episode: 101/30000 (0.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 7.1913s / 38.2699 s
agent0:                 episode reward: -0.3083,                 loss: nan
agent1:                 episode reward: 0.3083,                 loss: nan
Episode: 121/30000 (0.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 7.0548s / 45.3247 s
agent0:                 episode reward: 0.0128,                 loss: nan
agent1:                 episode reward: -0.0128,                 loss: nan
Episode: 141/30000 (0.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 7.5005s / 52.8252 s
agent0:                 episode reward: -0.1602,                 loss: nan
agent1:                 episode reward: 0.1602,                 loss: nan
Episode: 161/30000 (0.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 7.2800s / 60.1052 s
agent0:                 episode reward: 0.0930,                 loss: nan
agent1:                 episode reward: -0.0930,                 loss: nan
Episode: 181/30000 (0.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 7.6647s / 67.7699 s
agent0:                 episode reward: 0.2745,                 loss: nan
agent1:                 episode reward: -0.2745,                 loss: nan
Episode: 201/30000 (0.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 6.9507s / 74.7206 s
agent0:                 episode reward: 0.3474,                 loss: nan
agent1:                 episode reward: -0.3474,                 loss: nan
Episode: 221/30000 (0.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 96.4758s / 171.1965 s
agent0:                 episode reward: 0.4612,                 loss: nan
agent1:                 episode reward: -0.4612,                 loss: 0.1806
Episode: 241/30000 (0.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 240.9590s / 412.1554 s
agent0:                 episode reward: -0.2442,                 loss: nan
agent1:                 episode reward: 0.2442,                 loss: 0.1748
Episode: 261/30000 (0.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.9403s / 655.0958 s
agent0:                 episode reward: -0.3335,                 loss: nan
agent1:                 episode reward: 0.3335,                 loss: 0.1688
Episode: 281/30000 (0.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 241.1168s / 896.2125 s
agent0:                 episode reward: 0.2389,                 loss: nan
agent1:                 episode reward: -0.2389,                 loss: 0.1651
Episode: 301/30000 (1.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.7384s / 1138.9509 s
agent0:                 episode reward: 0.1247,                 loss: nan
agent1:                 episode reward: -0.1247,                 loss: 0.1622
Episode: 321/30000 (1.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.6485s / 1389.5994 s
agent0:                 episode reward: 0.0349,                 loss: nan
agent1:                 episode reward: -0.0349,                 loss: 0.1587
Episode: 341/30000 (1.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 239.3044s / 1628.9038 s
agent0:                 episode reward: 0.0158,                 loss: nan
agent1:                 episode reward: -0.0158,                 loss: 0.1563
Episode: 361/30000 (1.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.8103s / 1872.7141 s
agent0:                 episode reward: -0.1236,                 loss: nan
agent1:                 episode reward: 0.1236,                 loss: 0.1540
Episode: 381/30000 (1.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.8099s / 2115.5240 s
agent0:                 episode reward: -0.1121,                 loss: nan
agent1:                 episode reward: 0.1121,                 loss: 0.1537
Episode: 401/30000 (1.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.0686s / 2358.5926 s
agent0:                 episode reward: -0.1542,                 loss: nan
agent1:                 episode reward: 0.1542,                 loss: 0.1547
Episode: 421/30000 (1.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.7808s / 2603.3734 s
agent0:                 episode reward: 0.3092,                 loss: nan
agent1:                 episode reward: -0.3092,                 loss: 0.1527
Episode: 441/30000 (1.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.9592s / 2849.3326 s
agent0:                 episode reward: 0.1535,                 loss: nan
agent1:                 episode reward: -0.1535,                 loss: 0.1518
Episode: 461/30000 (1.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.6982s / 3101.0308 s
agent0:                 episode reward: 0.4208,                 loss: nan
agent1:                 episode reward: -0.4208,                 loss: 0.1515
Episode: 481/30000 (1.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 237.2961s / 3338.3269 s
agent0:                 episode reward: 0.4079,                 loss: nan
agent1:                 episode reward: -0.4079,                 loss: 0.1517
Episode: 501/30000 (1.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.2550s / 3579.5819 s
agent0:                 episode reward: 0.1429,                 loss: nan
agent1:                 episode reward: -0.1429,                 loss: 0.1496
Episode: 521/30000 (1.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.9325s / 3824.5144 s
agent0:                 episode reward: -0.1268,                 loss: nan
agent1:                 episode reward: 0.1268,                 loss: 0.1482
Episode: 541/30000 (1.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.0942s / 4074.6087 s
agent0:                 episode reward: -0.4935,                 loss: nan
agent1:                 episode reward: 0.4935,                 loss: 0.1470
Episode: 561/30000 (1.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.7446s / 4324.3532 s
agent0:                 episode reward: 0.1521,                 loss: nan
agent1:                 episode reward: -0.1521,                 loss: 0.1593
Episode: 581/30000 (1.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.7968s / 4568.1501 s
agent0:                 episode reward: 0.0073,                 loss: nan
agent1:                 episode reward: -0.0073,                 loss: 0.1591
Episode: 601/30000 (2.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.5103s / 4812.6603 s
agent0:                 episode reward: 0.1368,                 loss: nan
agent1:                 episode reward: -0.1368,                 loss: 0.1596
Episode: 621/30000 (2.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.8612s / 5060.5215 s
agent0:                 episode reward: -0.0970,                 loss: nan
agent1:                 episode reward: 0.0970,                 loss: 0.1579
Episode: 641/30000 (2.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.7013s / 5305.2229 s
agent0:                 episode reward: -0.3485,                 loss: nan
agent1:                 episode reward: 0.3485,                 loss: 0.1563
Episode: 661/30000 (2.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.2715s / 5553.4944 s
agent0:                 episode reward: -0.1304,                 loss: nan
agent1:                 episode reward: 0.1304,                 loss: 0.1563
Episode: 681/30000 (2.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.2064s / 5804.7008 s
agent0:                 episode reward: -0.1165,                 loss: nan
agent1:                 episode reward: 0.1165,                 loss: 0.1555
Episode: 701/30000 (2.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.3856s / 6055.0864 s
agent0:                 episode reward: 0.0224,                 loss: nan
agent1:                 episode reward: -0.0224,                 loss: 0.1549
Episode: 721/30000 (2.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.3584s / 6301.4448 s
agent0:                 episode reward: -0.0407,                 loss: nan
agent1:                 episode reward: 0.0407,                 loss: 0.1544
Episode: 741/30000 (2.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.0969s / 6548.5417 s
agent0:                 episode reward: 0.2505,                 loss: nan
agent1:                 episode reward: -0.2505,                 loss: 0.1543
Episode: 761/30000 (2.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.2816s / 6793.8233 s
agent0:                 episode reward: -0.0747,                 loss: nan
agent1:                 episode reward: 0.0747,                 loss: 0.1525
Episode: 781/30000 (2.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.5295s / 7042.3528 s
agent0:                 episode reward: -0.1216,                 loss: nan
agent1:                 episode reward: 0.1216,                 loss: 0.1530
Episode: 801/30000 (2.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 238.5035s / 7280.8562 s
agent0:                 episode reward: -0.3136,                 loss: nan
agent1:                 episode reward: 0.3136,                 loss: 0.1522
Episode: 821/30000 (2.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.2236s / 7525.0798 s
agent0:                 episode reward: -0.2833,                 loss: nan
agent1:                 episode reward: 0.2833,                 loss: 0.1495
Episode: 841/30000 (2.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.5769s / 7775.6567 s
agent0:                 episode reward: -0.1594,                 loss: nan
agent1:                 episode reward: 0.1594,                 loss: 0.1505
Episode: 861/30000 (2.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 233.1252s / 8008.7820 s
agent0:                 episode reward: 0.0083,                 loss: nan
agent1:                 episode reward: -0.0083,                 loss: 0.1505
Episode: 881/30000 (2.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.9051s / 8252.6871 s
agent0:                 episode reward: -0.0690,                 loss: nan
agent1:                 episode reward: 0.0690,                 loss: 0.1501
Episode: 901/30000 (3.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.1963s / 8495.8833 s
agent0:                 episode reward: -0.2205,                 loss: nan
agent1:                 episode reward: 0.2205,                 loss: 0.1450
Episode: 921/30000 (3.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.6265s / 8740.5098 s
agent0:                 episode reward: 0.0848,                 loss: nan
agent1:                 episode reward: -0.0848,                 loss: 0.1443
Episode: 941/30000 (3.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.3030s / 8985.8128 s
agent0:                 episode reward: -0.2579,                 loss: nan
agent1:                 episode reward: 0.2579,                 loss: 0.1451
Episode: 961/30000 (3.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.0548s / 9227.8676 s
agent0:                 episode reward: 0.1261,                 loss: nan
agent1:                 episode reward: -0.1261,                 loss: 0.1436
Episode: 981/30000 (3.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.1527s / 9476.0202 s
agent0:                 episode reward: -0.1057,                 loss: nan
agent1:                 episode reward: 0.1057,                 loss: 0.1421
Episode: 1001/30000 (3.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.1205s / 9721.1408 s
agent0:                 episode reward: -0.2787,                 loss: nan
agent1:                 episode reward: 0.2787,                 loss: 0.1439
Episode: 1021/30000 (3.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.5596s / 9966.7004 s
agent0:                 episode reward: 0.2799,                 loss: nan
agent1:                 episode reward: -0.2799,                 loss: 0.1418
Episode: 1041/30000 (3.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.2115s / 10208.9119 s
agent0:                 episode reward: 0.1561,                 loss: nan
agent1:                 episode reward: -0.1561,                 loss: 0.1407
Episode: 1061/30000 (3.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.2850s / 10451.1969 s
agent0:                 episode reward: -0.4633,                 loss: nan
agent1:                 episode reward: 0.4633,                 loss: 0.1427
Episode: 1081/30000 (3.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 254.3049s / 10705.5019 s
agent0:                 episode reward: -0.0413,                 loss: nan
agent1:                 episode reward: 0.0413,                 loss: 0.1403
Episode: 1101/30000 (3.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 236.5095s / 10942.0114 s
agent0:                 episode reward: 0.1807,                 loss: nan
agent1:                 episode reward: -0.1807,                 loss: 0.1403
Episode: 1121/30000 (3.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.4028s / 11192.4142 s
agent0:                 episode reward: 0.3805,                 loss: nan
agent1:                 episode reward: -0.3805,                 loss: 0.1395
Episode: 1141/30000 (3.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 239.5422s / 11431.9564 s
agent0:                 episode reward: -0.0124,                 loss: nan
agent1:                 episode reward: 0.0124,                 loss: 0.1400
Episode: 1161/30000 (3.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.6922s / 11679.6486 s
agent0:                 episode reward: 0.3111,                 loss: nan
agent1:                 episode reward: -0.3111,                 loss: 0.1397
Episode: 1181/30000 (3.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.8397s / 11925.4883 s
agent0:                 episode reward: -0.1955,                 loss: nan
agent1:                 episode reward: 0.1955,                 loss: 0.1395
Episode: 1201/30000 (4.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.3358s / 12170.8241 s
agent0:                 episode reward: 0.1984,                 loss: nan
agent1:                 episode reward: -0.1984,                 loss: 0.1357
Episode: 1221/30000 (4.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.0160s / 12414.8401 s
agent0:                 episode reward: 0.0257,                 loss: nan
agent1:                 episode reward: -0.0257,                 loss: 0.1381
Episode: 1241/30000 (4.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 241.2581s / 12656.0982 s
agent0:                 episode reward: -0.0144,                 loss: nan
agent1:                 episode reward: 0.0144,                 loss: 0.1368
Episode: 1261/30000 (4.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.2542s / 12903.3524 s
agent0:                 episode reward: 0.3920,                 loss: nan
agent1:                 episode reward: -0.3920,                 loss: 0.1363
Episode: 1281/30000 (4.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.6550s / 13152.0074 s
agent0:                 episode reward: 0.2362,                 loss: nan
agent1:                 episode reward: -0.2362,                 loss: 0.1373
Episode: 1301/30000 (4.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.4520s / 13397.4594 s
agent0:                 episode reward: -0.3826,                 loss: nan
agent1:                 episode reward: 0.3826,                 loss: 0.1374
Episode: 1321/30000 (4.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 255.3550s / 13652.8144 s
agent0:                 episode reward: 0.0957,                 loss: nan
agent1:                 episode reward: -0.0957,                 loss: 0.1361
Episode: 1341/30000 (4.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.7694s / 13898.5838 s
agent0:                 episode reward: -0.0441,                 loss: nan
agent1:                 episode reward: 0.0441,                 loss: 0.1359
Episode: 1361/30000 (4.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.2457s / 14145.8295 s
agent0:                 episode reward: 0.1302,                 loss: nan
agent1:                 episode reward: -0.1302,                 loss: 0.1363
Episode: 1381/30000 (4.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.9956s / 14393.8251 s
agent0:                 episode reward: -0.0154,                 loss: nan
agent1:                 episode reward: 0.0154,                 loss: 0.1353
Episode: 1401/30000 (4.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.9427s / 14642.7678 s
agent0:                 episode reward: -0.1003,                 loss: nan
agent1:                 episode reward: 0.1003,                 loss: 0.1364
Episode: 1421/30000 (4.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.5741s / 14888.3420 s
agent0:                 episode reward: -0.0430,                 loss: nan
agent1:                 episode reward: 0.0430,                 loss: 0.1335
Episode: 1441/30000 (4.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.3515s / 15131.6934 s
agent0:                 episode reward: -0.4229,                 loss: nan
agent1:                 episode reward: 0.4229,                 loss: 0.1352
Episode: 1461/30000 (4.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.2846s / 15381.9780 s
agent0:                 episode reward: 0.5562,                 loss: nan
agent1:                 episode reward: -0.5562,                 loss: 0.1346
Episode: 1481/30000 (4.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 237.7977s / 15619.7757 s
agent0:                 episode reward: -0.0291,                 loss: nan
agent1:                 episode reward: 0.0291,                 loss: 0.1338
Episode: 1501/30000 (5.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.8181s / 15863.5938 s
agent0:                 episode reward: -0.3010,                 loss: nan
agent1:                 episode reward: 0.3010,                 loss: 0.1343
Episode: 1521/30000 (5.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.4920s / 16109.0858 s
agent0:                 episode reward: 0.2807,                 loss: nan
agent1:                 episode reward: -0.2807,                 loss: 0.1339
Episode: 1541/30000 (5.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.7642s / 16356.8500 s
agent0:                 episode reward: -0.0341,                 loss: nan
agent1:                 episode reward: 0.0341,                 loss: 0.1333
Episode: 1561/30000 (5.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.3827s / 16603.2327 s
agent0:                 episode reward: 0.1447,                 loss: nan
agent1:                 episode reward: -0.1447,                 loss: 0.1338
Episode: 1581/30000 (5.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.7332s / 16854.9658 s
agent0:                 episode reward: -0.1552,                 loss: nan
agent1:                 episode reward: 0.1552,                 loss: 0.1328
Episode: 1601/30000 (5.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.2613s / 17097.2271 s
agent0:                 episode reward: -0.3034,                 loss: nan
agent1:                 episode reward: 0.3034,                 loss: 0.1323
Episode: 1621/30000 (5.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.6974s / 17347.9245 s
agent0:                 episode reward: -0.1824,                 loss: nan
agent1:                 episode reward: 0.1824,                 loss: 0.1319
Episode: 1641/30000 (5.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.5687s / 17591.4932 s
agent0:                 episode reward: -0.2274,                 loss: nan
agent1:                 episode reward: 0.2274,                 loss: 0.1321
Episode: 1661/30000 (5.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.3411s / 17834.8343 s
agent0:                 episode reward: -0.4638,                 loss: nan
agent1:                 episode reward: 0.4638,                 loss: 0.1320
Episode: 1681/30000 (5.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.4803s / 18082.3146 s
agent0:                 episode reward: 0.5427,                 loss: nan
agent1:                 episode reward: -0.5427,                 loss: 0.1320
Episode: 1701/30000 (5.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.0857s / 18332.4004 s
agent0:                 episode reward: -0.0140,                 loss: nan
agent1:                 episode reward: 0.0140,                 loss: 0.1329
Episode: 1721/30000 (5.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 239.2162s / 18571.6166 s
agent0:                 episode reward: 0.1280,                 loss: nan
agent1:                 episode reward: -0.1280,                 loss: 0.1313
Episode: 1741/30000 (5.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.4950s / 18813.1116 s
agent0:                 episode reward: -0.3200,                 loss: nan
agent1:                 episode reward: 0.3200,                 loss: 0.1307
Episode: 1761/30000 (5.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.4965s / 19054.6081 s
agent0:                 episode reward: -0.3783,                 loss: nan
agent1:                 episode reward: 0.3783,                 loss: 0.1322
Episode: 1781/30000 (5.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.2897s / 19298.8978 s
agent0:                 episode reward: -0.0548,                 loss: nan
agent1:                 episode reward: 0.0548,                 loss: 0.1311
Episode: 1801/30000 (6.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.9632s / 19542.8610 s
agent0:                 episode reward: -0.2800,                 loss: nan
agent1:                 episode reward: 0.2800,                 loss: 0.1312
Episode: 1821/30000 (6.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.2162s / 19786.0773 s
agent0:                 episode reward: 0.0224,                 loss: nan
agent1:                 episode reward: -0.0224,                 loss: 0.1326
Episode: 1841/30000 (6.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.2331s / 20034.3103 s
agent0:                 episode reward: -0.3822,                 loss: nan
agent1:                 episode reward: 0.3822,                 loss: 0.1327
Episode: 1861/30000 (6.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 238.7018s / 20273.0122 s
agent0:                 episode reward: -0.0746,                 loss: nan
agent1:                 episode reward: 0.0746,                 loss: 0.1309
Episode: 1881/30000 (6.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.2677s / 20520.2798 s
agent0:                 episode reward: -0.1672,                 loss: nan
agent1:                 episode reward: 0.1672,                 loss: 0.1319
Episode: 1901/30000 (6.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 258.1937s / 20778.4736 s
agent0:                 episode reward: -0.1273,                 loss: nan
agent1:                 episode reward: 0.1273,                 loss: 0.1335
Episode: 1921/30000 (6.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.4236s / 21027.8972 s
agent0:                 episode reward: -0.1293,                 loss: nan
agent1:                 episode reward: 0.1293,                 loss: 0.1326
Episode: 1941/30000 (6.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.1929s / 21275.0901 s
agent0:                 episode reward: -0.3215,                 loss: nan
agent1:                 episode reward: 0.3215,                 loss: 0.1323
Episode: 1961/30000 (6.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 235.9848s / 21511.0748 s
agent0:                 episode reward: -0.1573,                 loss: nan
agent1:                 episode reward: 0.1573,                 loss: 0.1324
Episode: 1981/30000 (6.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.2564s / 21754.3313 s
agent0:                 episode reward: -0.2167,                 loss: nan
agent1:                 episode reward: 0.2167,                 loss: 0.1324
Episode: 2001/30000 (6.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 254.3726s / 22008.7038 s
agent0:                 episode reward: -0.2658,                 loss: nan
agent1:                 episode reward: 0.2658,                 loss: 0.1321
Episode: 2021/30000 (6.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.0929s / 22252.7967 s
agent0:                 episode reward: -0.5083,                 loss: nan
agent1:                 episode reward: 0.5083,                 loss: 0.1328
Episode: 2041/30000 (6.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 238.5013s / 22491.2980 s
agent0:                 episode reward: -0.3416,                 loss: nan
agent1:                 episode reward: 0.3416,                 loss: 0.1331
Episode: 2061/30000 (6.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.9556s / 22740.2536 s
agent0:                 episode reward: -0.4324,                 loss: nan
agent1:                 episode reward: 0.4324,                 loss: 0.1322
Episode: 2081/30000 (6.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.0669s / 22983.3205 s
agent0:                 episode reward: 0.0043,                 loss: nan
agent1:                 episode reward: -0.0043,                 loss: 0.1318
Episode: 2101/30000 (7.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 240.2347s / 23223.5552 s
agent0:                 episode reward: -0.2048,                 loss: nan
agent1:                 episode reward: 0.2048,                 loss: 0.1320
Episode: 2121/30000 (7.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.9236s / 23465.4788 s
agent0:                 episode reward: -0.2607,                 loss: nan
agent1:                 episode reward: 0.2607,                 loss: 0.1330
Episode: 2141/30000 (7.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.4381s / 23707.9169 s
agent0:                 episode reward: -0.2658,                 loss: nan
agent1:                 episode reward: 0.2658,                 loss: 0.1332
Episode: 2161/30000 (7.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.9629s / 23955.8798 s
agent0:                 episode reward: 0.2655,                 loss: nan
agent1:                 episode reward: -0.2655,                 loss: 0.1326
Episode: 2181/30000 (7.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.2117s / 24197.0915 s
agent0:                 episode reward: -0.2354,                 loss: nan
agent1:                 episode reward: 0.2354,                 loss: 0.1320
Episode: 2201/30000 (7.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.4197s / 24442.5112 s
agent0:                 episode reward: -0.1980,                 loss: nan
agent1:                 episode reward: 0.1980,                 loss: 0.1327
Episode: 2221/30000 (7.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.9171s / 24684.4283 s
agent0:                 episode reward: 0.3100,                 loss: nan
agent1:                 episode reward: -0.3100,                 loss: 0.1345
Episode: 2241/30000 (7.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.7953s / 24935.2236 s
agent0:                 episode reward: -0.3524,                 loss: nan
agent1:                 episode reward: 0.3524,                 loss: 0.1376
Episode: 2261/30000 (7.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.6050s / 25185.8286 s
agent0:                 episode reward: -0.0913,                 loss: nan
agent1:                 episode reward: 0.0913,                 loss: 0.1376
Episode: 2281/30000 (7.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.3635s / 25432.1921 s
agent0:                 episode reward: -0.0427,                 loss: nan
agent1:                 episode reward: 0.0427,                 loss: 0.1374
Episode: 2301/30000 (7.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 255.0587s / 25687.2507 s
agent0:                 episode reward: -0.1168,                 loss: nan
agent1:                 episode reward: 0.1168,                 loss: 0.1375
Episode: 2321/30000 (7.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.0500s / 25938.3008 s
agent0:                 episode reward: -0.1871,                 loss: nan
agent1:                 episode reward: 0.1871,                 loss: 0.1376
Episode: 2341/30000 (7.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.5341s / 26181.8349 s
agent0:                 episode reward: -0.2268,                 loss: nan
agent1:                 episode reward: 0.2268,                 loss: 0.1368
Episode: 2361/30000 (7.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.8033s / 26425.6382 s
agent0:                 episode reward: -0.2869,                 loss: nan
agent1:                 episode reward: 0.2869,                 loss: 0.1366
Episode: 2381/30000 (7.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 241.9712s / 26667.6094 s
agent0:                 episode reward: -0.2470,                 loss: nan
agent1:                 episode reward: 0.2470,                 loss: 0.1369
Episode: 2401/30000 (8.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 240.6010s / 26908.2104 s
agent0:                 episode reward: -0.1408,                 loss: nan
agent1:                 episode reward: 0.1408,                 loss: 0.1379
Episode: 2421/30000 (8.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.3171s / 27149.5274 s
agent0:                 episode reward: 0.1736,                 loss: nan
agent1:                 episode reward: -0.1736,                 loss: 0.1367
Episode: 2441/30000 (8.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.2395s / 27400.7670 s
agent0:                 episode reward: -0.0768,                 loss: nan
agent1:                 episode reward: 0.0768,                 loss: 0.1384
Episode: 2461/30000 (8.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 253.5838s / 27654.3507 s
agent0:                 episode reward: -0.3888,                 loss: nan
agent1:                 episode reward: 0.3888,                 loss: 0.1340
Episode: 2481/30000 (8.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.8726s / 27907.2233 s
agent0:                 episode reward: 0.0844,                 loss: nan
agent1:                 episode reward: -0.0844,                 loss: 0.1372
Episode: 2501/30000 (8.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.8240s / 28160.0473 s
agent0:                 episode reward: -0.4856,                 loss: nan
agent1:                 episode reward: 0.4856,                 loss: 0.1362
Episode: 2521/30000 (8.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.9525s / 28412.9999 s
agent0:                 episode reward: -0.0244,                 loss: nan
agent1:                 episode reward: 0.0244,                 loss: 0.1373
Episode: 2541/30000 (8.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.5269s / 28657.5268 s
agent0:                 episode reward: -0.0463,                 loss: nan
agent1:                 episode reward: 0.0463,                 loss: 0.1365
Episode: 2561/30000 (8.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 240.8610s / 28898.3878 s
agent0:                 episode reward: -0.0598,                 loss: nan
agent1:                 episode reward: 0.0598,                 loss: 0.1357
Episode: 2581/30000 (8.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.3547s / 29145.7426 s
agent0:                 episode reward: -0.1067,                 loss: nan
agent1:                 episode reward: 0.1067,                 loss: 0.1375
Episode: 2601/30000 (8.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 254.3991s / 29400.1417 s
agent0:                 episode reward: 0.0863,                 loss: nan
agent1:                 episode reward: -0.0863,                 loss: 0.1373
Episode: 2621/30000 (8.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.9242s / 29643.0660 s
agent0:                 episode reward: -0.3080,                 loss: nan
agent1:                 episode reward: 0.3080,                 loss: 0.1364
Episode: 2641/30000 (8.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.7033s / 29885.7693 s
agent0:                 episode reward: -0.0792,                 loss: nan
agent1:                 episode reward: 0.0792,                 loss: 0.1375
Episode: 2661/30000 (8.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.0191s / 30127.7883 s
agent0:                 episode reward: -0.2576,                 loss: nan
agent1:                 episode reward: 0.2576,                 loss: 0.1362
Episode: 2681/30000 (8.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 255.3089s / 30383.0973 s
agent0:                 episode reward: -0.2127,                 loss: nan
agent1:                 episode reward: 0.2127,                 loss: 0.1382
Episode: 2701/30000 (9.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.2649s / 30632.3622 s
agent0:                 episode reward: 0.0731,                 loss: nan
agent1:                 episode reward: -0.0731,                 loss: 0.1374
Episode: 2721/30000 (9.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.5916s / 30881.9538 s
agent0:                 episode reward: 0.0573,                 loss: nan
agent1:                 episode reward: -0.0573,                 loss: 0.1366
Episode: 2741/30000 (9.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.1875s / 31130.1413 s
agent0:                 episode reward: -0.1312,                 loss: nan
agent1:                 episode reward: 0.1312,                 loss: 0.1371
Episode: 2761/30000 (9.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 240.1942s / 31370.3355 s
agent0:                 episode reward: -0.0511,                 loss: nan
agent1:                 episode reward: 0.0511,                 loss: 0.1364
Episode: 2781/30000 (9.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.9030s / 31618.2385 s
agent0:                 episode reward: 0.2992,                 loss: nan
agent1:                 episode reward: -0.2992,                 loss: 0.1359
Episode: 2801/30000 (9.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 256.0761s / 31874.3146 s
agent0:                 episode reward: -0.2586,                 loss: nan
agent1:                 episode reward: 0.2586,                 loss: 0.1368
Episode: 2821/30000 (9.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.5058s / 32120.8204 s
agent0:                 episode reward: 0.2982,                 loss: nan
agent1:                 episode reward: -0.2982,                 loss: 0.1367
Episode: 2841/30000 (9.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.0527s / 32369.8730 s
agent0:                 episode reward: -0.0688,                 loss: nan
agent1:                 episode reward: 0.0688,                 loss: 0.1353
Episode: 2861/30000 (9.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.1738s / 32622.0468 s
agent0:                 episode reward: 0.2574,                 loss: nan
agent1:                 episode reward: -0.2574,                 loss: 0.1365
Episode: 2881/30000 (9.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.3546s / 32867.4014 s
agent0:                 episode reward: 0.0241,                 loss: nan
agent1:                 episode reward: -0.0241,                 loss: 0.1362
Episode: 2901/30000 (9.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.9680s / 33114.3694 s
agent0:                 episode reward: -0.5902,                 loss: nan
agent1:                 episode reward: 0.5902,                 loss: 0.1346
Episode: 2921/30000 (9.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.8358s / 33361.2052 s
agent0:                 episode reward: -0.0408,                 loss: nan
agent1:                 episode reward: 0.0408,                 loss: 0.1358
Episode: 2941/30000 (9.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 256.0245s / 33617.2298 s
agent0:                 episode reward: -0.3013,                 loss: nan
agent1:                 episode reward: 0.3013,                 loss: 0.1363
Episode: 2961/30000 (9.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.9614s / 33864.1912 s
agent0:                 episode reward: -0.1133,                 loss: nan
agent1:                 episode reward: 0.1133,                 loss: 0.1340
Episode: 2981/30000 (9.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.1662s / 34112.3574 s
agent0:                 episode reward: 0.2770,                 loss: nan
agent1:                 episode reward: -0.2770,                 loss: 0.1348
Episode: 3001/30000 (10.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.1000s / 34359.4574 s
agent0:                 episode reward: -0.3495,                 loss: nan
agent1:                 episode reward: 0.3495,                 loss: 0.1358
Episode: 3021/30000 (10.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 260.6550s / 34620.1124 s
agent0:                 episode reward: 0.0925,                 loss: nan
agent1:                 episode reward: -0.0925,                 loss: 0.1345
Episode: 3041/30000 (10.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.3943s / 34865.5067 s
agent0:                 episode reward: -0.5334,                 loss: nan
agent1:                 episode reward: 0.5334,                 loss: 0.1334
Episode: 3061/30000 (10.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.5206s / 35111.0273 s
agent0:                 episode reward: 0.2372,                 loss: nan
agent1:                 episode reward: -0.2372,                 loss: 0.1347
Episode: 3081/30000 (10.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.1294s / 35356.1567 s
agent0:                 episode reward: -0.0349,                 loss: nan
agent1:                 episode reward: 0.0349,                 loss: 0.1346
Episode: 3101/30000 (10.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.5988s / 35603.7555 s
agent0:                 episode reward: -0.3838,                 loss: nan
agent1:                 episode reward: 0.3838,                 loss: 0.1352
Episode: 3121/30000 (10.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.4157s / 35845.1712 s
agent0:                 episode reward: -0.2028,                 loss: nan
agent1:                 episode reward: 0.2028,                 loss: 0.1363
Episode: 3141/30000 (10.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.4882s / 36092.6594 s
agent0:                 episode reward: -0.6345,                 loss: nan
agent1:                 episode reward: 0.6345,                 loss: 0.1344
Episode: 3161/30000 (10.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.8423s / 36344.5017 s
agent0:                 episode reward: -0.4235,                 loss: nan
agent1:                 episode reward: 0.4235,                 loss: 0.1328
Episode: 3181/30000 (10.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.8605s / 36588.3622 s
agent0:                 episode reward: 0.1481,                 loss: nan
agent1:                 episode reward: -0.1481,                 loss: 0.1335
Episode: 3201/30000 (10.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.1189s / 36837.4812 s
agent0:                 episode reward: -0.6370,                 loss: nan
agent1:                 episode reward: 0.6370,                 loss: 0.1346
Episode: 3221/30000 (10.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.9829s / 37084.4640 s
agent0:                 episode reward: -0.1592,                 loss: nan
agent1:                 episode reward: 0.1592,                 loss: 0.1336
Episode: 3241/30000 (10.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.6946s / 37332.1586 s
agent0:                 episode reward: -0.3905,                 loss: nan
agent1:                 episode reward: 0.3905,                 loss: 0.1330
Episode: 3261/30000 (10.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.5148s / 37577.6734 s
agent0:                 episode reward: -0.4207,                 loss: nan
agent1:                 episode reward: 0.4207,                 loss: 0.1325
Episode: 3281/30000 (10.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.0586s / 37823.7320 s
agent0:                 episode reward: -0.0505,                 loss: nan
agent1:                 episode reward: 0.0505,                 loss: 0.1329
Episode: 3301/30000 (11.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.9860s / 38073.7180 s
agent0:                 episode reward: -0.6194,                 loss: nan
agent1:                 episode reward: 0.6194,                 loss: 0.1322
Episode: 3321/30000 (11.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 240.1515s / 38313.8695 s
agent0:                 episode reward: 0.0212,                 loss: nan
agent1:                 episode reward: -0.0212,                 loss: 0.1315
Episode: 3341/30000 (11.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.9680s / 38560.8376 s
agent0:                 episode reward: -0.1000,                 loss: nan
agent1:                 episode reward: 0.1000,                 loss: 0.1318
Episode: 3361/30000 (11.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.2979s / 38807.1355 s
agent0:                 episode reward: -0.3957,                 loss: nan
agent1:                 episode reward: 0.3957,                 loss: 0.1314
Episode: 3381/30000 (11.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.0327s / 39055.1682 s
agent0:                 episode reward: 0.2998,                 loss: nan
agent1:                 episode reward: -0.2998,                 loss: 0.1315
Episode: 3401/30000 (11.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 240.8855s / 39296.0536 s
agent0:                 episode reward: -0.2183,                 loss: nan
agent1:                 episode reward: 0.2183,                 loss: 0.1330
Episode: 3421/30000 (11.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 256.4917s / 39552.5453 s
agent0:                 episode reward: -0.4528,                 loss: nan
agent1:                 episode reward: 0.4528,                 loss: 0.1324
Episode: 3441/30000 (11.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.6795s / 39794.2248 s
agent0:                 episode reward: -0.1095,                 loss: nan
agent1:                 episode reward: 0.1095,                 loss: 0.1314
Episode: 3461/30000 (11.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.6278s / 40041.8526 s
agent0:                 episode reward: -0.2770,                 loss: nan
agent1:                 episode reward: 0.2770,                 loss: 0.1309
Episode: 3481/30000 (11.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.5459s / 40290.3985 s
agent0:                 episode reward: 0.0917,                 loss: nan
agent1:                 episode reward: -0.0917,                 loss: 0.1311
Episode: 3501/30000 (11.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 253.8159s / 40544.2144 s
agent0:                 episode reward: -0.1564,                 loss: nan
agent1:                 episode reward: 0.1564,                 loss: 0.1321
Episode: 3521/30000 (11.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.3670s / 40792.5815 s
agent0:                 episode reward: -0.3137,                 loss: nan
agent1:                 episode reward: 0.3137,                 loss: 0.1328
Episode: 3541/30000 (11.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.7345s / 41038.3160 s
agent0:                 episode reward: 0.2442,                 loss: nan
agent1:                 episode reward: -0.2442,                 loss: 0.1324
Episode: 3561/30000 (11.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.9117s / 41286.2276 s
agent0:                 episode reward: -0.2704,                 loss: nan
agent1:                 episode reward: 0.2704,                 loss: 0.1330
Episode: 3581/30000 (11.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 239.2419s / 41525.4695 s
agent0:                 episode reward: -0.0670,                 loss: nan
agent1:                 episode reward: 0.0670,                 loss: 0.1330
Episode: 3601/30000 (12.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 237.8912s / 41763.3607 s
agent0:                 episode reward: -0.3034,                 loss: nan
agent1:                 episode reward: 0.3034,                 loss: 0.1342
Episode: 3621/30000 (12.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 239.6703s / 42003.0310 s
agent0:                 episode reward: -0.2517,                 loss: nan
agent1:                 episode reward: 0.2517,                 loss: 0.1336
Episode: 3641/30000 (12.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.5982s / 42246.6292 s
agent0:                 episode reward: 0.2170,                 loss: nan
agent1:                 episode reward: -0.2170,                 loss: 0.1345
Episode: 3661/30000 (12.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 236.5884s / 42483.2176 s
agent0:                 episode reward: 0.0495,                 loss: nan
agent1:                 episode reward: -0.0495,                 loss: 0.1324
Episode: 3681/30000 (12.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.1985s / 42734.4161 s
agent0:                 episode reward: -0.2708,                 loss: nan
agent1:                 episode reward: 0.2708,                 loss: 0.1328
Episode: 3701/30000 (12.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.2964s / 42980.7126 s
agent0:                 episode reward: -0.3846,                 loss: nan
agent1:                 episode reward: 0.3846,                 loss: 0.1342
Episode: 3721/30000 (12.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.5158s / 43224.2283 s
agent0:                 episode reward: 0.1260,                 loss: nan
agent1:                 episode reward: -0.1260,                 loss: 0.1330
Episode: 3741/30000 (12.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 257.8125s / 43482.0408 s
agent0:                 episode reward: -0.1922,                 loss: nan
agent1:                 episode reward: 0.1922,                 loss: 0.1327
Episode: 3761/30000 (12.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.9700s / 43729.0107 s
agent0:                 episode reward: 0.0770,                 loss: nan
agent1:                 episode reward: -0.0770,                 loss: 0.1312
Episode: 3781/30000 (12.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.8871s / 43975.8979 s
agent0:                 episode reward: 0.0335,                 loss: nan
agent1:                 episode reward: -0.0335,                 loss: 0.1321
Episode: 3801/30000 (12.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 234.9354s / 44210.8332 s
agent0:                 episode reward: 0.1152,                 loss: nan
agent1:                 episode reward: -0.1152,                 loss: 0.1342
Episode: 3821/30000 (12.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.7510s / 44461.5842 s
agent0:                 episode reward: 0.2155,                 loss: nan
agent1:                 episode reward: -0.2155,                 loss: 0.1325
Episode: 3841/30000 (12.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.2478s / 44709.8320 s
agent0:                 episode reward: 0.0984,                 loss: nan
agent1:                 episode reward: -0.0984,                 loss: 0.1326
Episode: 3861/30000 (12.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 253.2928s / 44963.1249 s
agent0:                 episode reward: -0.4170,                 loss: nan
agent1:                 episode reward: 0.4170,                 loss: 0.1326
Episode: 3881/30000 (12.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.6848s / 45212.8097 s
agent0:                 episode reward: -0.4767,                 loss: nan
agent1:                 episode reward: 0.4767,                 loss: 0.1329
Episode: 3901/30000 (13.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.3497s / 45459.1594 s
agent0:                 episode reward: -0.0625,                 loss: nan
agent1:                 episode reward: 0.0625,                 loss: 0.1348
Episode: 3921/30000 (13.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.9519s / 45706.1112 s
agent0:                 episode reward: -0.3870,                 loss: nan
agent1:                 episode reward: 0.3870,                 loss: 0.1354
Episode: 3941/30000 (13.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.7568s / 45956.8681 s
agent0:                 episode reward: -0.1663,                 loss: nan
agent1:                 episode reward: 0.1663,                 loss: 0.1352
Episode: 3961/30000 (13.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.3843s / 46201.2523 s
agent0:                 episode reward: -0.0993,                 loss: nan
agent1:                 episode reward: 0.0993,                 loss: 0.1347
Episode: 3981/30000 (13.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.7564s / 46446.0087 s
agent0:                 episode reward: 0.1525,                 loss: nan
agent1:                 episode reward: -0.1525,                 loss: 0.1332
Episode: 4001/30000 (13.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.8696s / 46691.8783 s
agent0:                 episode reward: -0.2284,                 loss: nan
agent1:                 episode reward: 0.2284,                 loss: 0.1346
Episode: 4021/30000 (13.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.8249s / 46937.7032 s
agent0:                 episode reward: -0.1780,                 loss: nan
agent1:                 episode reward: 0.1780,                 loss: 0.1344
Episode: 4041/30000 (13.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.3742s / 47181.0774 s
agent0:                 episode reward: -0.1063,                 loss: nan
agent1:                 episode reward: 0.1063,                 loss: 0.1328
Episode: 4061/30000 (13.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.6611s / 47430.7385 s
agent0:                 episode reward: -0.3267,                 loss: nan
agent1:                 episode reward: 0.3267,                 loss: 0.1333
Episode: 4081/30000 (13.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.5971s / 47683.3356 s
agent0:                 episode reward: 0.0253,                 loss: nan
agent1:                 episode reward: -0.0253,                 loss: 0.1340
Episode: 4101/30000 (13.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.3160s / 47935.6516 s
agent0:                 episode reward: 0.3608,                 loss: nan
agent1:                 episode reward: -0.3608,                 loss: 0.1341
Episode: 4121/30000 (13.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.9562s / 48181.6078 s
agent0:                 episode reward: -0.6114,                 loss: nan
agent1:                 episode reward: 0.6114,                 loss: 0.1341
Episode: 4141/30000 (13.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.3382s / 48429.9460 s
agent0:                 episode reward: 0.0562,                 loss: nan
agent1:                 episode reward: -0.0562,                 loss: 0.1340
Episode: 4161/30000 (13.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 257.8212s / 48687.7671 s
agent0:                 episode reward: -0.2317,                 loss: nan
agent1:                 episode reward: 0.2317,                 loss: 0.1349
Episode: 4181/30000 (13.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 241.6970s / 48929.4642 s
agent0:                 episode reward: -0.3119,                 loss: nan
agent1:                 episode reward: 0.3119,                 loss: 0.1349
Episode: 4201/30000 (14.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 255.9142s / 49185.3784 s
agent0:                 episode reward: -0.6568,                 loss: nan
agent1:                 episode reward: 0.6568,                 loss: 0.1343
Episode: 4221/30000 (14.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 253.7798s / 49439.1582 s
agent0:                 episode reward: -0.0321,                 loss: nan
agent1:                 episode reward: 0.0321,                 loss: 0.1311
Episode: 4241/30000 (14.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.0940s / 49689.2522 s
agent0:                 episode reward: 0.0992,                 loss: nan
agent1:                 episode reward: -0.0992,                 loss: 0.1287
Episode: 4261/30000 (14.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.3781s / 49938.6303 s
agent0:                 episode reward: -0.1772,                 loss: nan
agent1:                 episode reward: 0.1772,                 loss: 0.1280
Episode: 4281/30000 (14.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.6045s / 50187.2347 s
agent0:                 episode reward: -0.1761,                 loss: nan
agent1:                 episode reward: 0.1761,                 loss: 0.1279
Episode: 4301/30000 (14.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.2391s / 50438.4738 s
agent0:                 episode reward: -0.4570,                 loss: nan
agent1:                 episode reward: 0.4570,                 loss: 0.1287
Episode: 4321/30000 (14.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.0548s / 50689.5286 s
agent0:                 episode reward: 0.2188,                 loss: nan
agent1:                 episode reward: -0.2188,                 loss: 0.1289
Episode: 4341/30000 (14.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 254.2005s / 50943.7291 s
agent0:                 episode reward: 0.0509,                 loss: nan
agent1:                 episode reward: -0.0509,                 loss: 0.1275
Episode: 4361/30000 (14.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.2364s / 51195.9655 s
agent0:                 episode reward: -0.1962,                 loss: nan
agent1:                 episode reward: 0.1962,                 loss: 0.1302
Episode: 4381/30000 (14.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.8162s / 51448.7817 s
agent0:                 episode reward: -0.2688,                 loss: nan
agent1:                 episode reward: 0.2688,                 loss: 0.1288
Episode: 4401/30000 (14.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 240.9123s / 51689.6940 s
agent0:                 episode reward: -0.4494,                 loss: nan
agent1:                 episode reward: 0.4494,                 loss: 0.1292
Episode: 4421/30000 (14.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.8347s / 51940.5288 s
agent0:                 episode reward: -0.1898,                 loss: nan
agent1:                 episode reward: 0.1898,                 loss: 0.1283
Episode: 4441/30000 (14.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.0375s / 52189.5662 s
agent0:                 episode reward: -0.0960,                 loss: nan
agent1:                 episode reward: 0.0960,                 loss: 0.1290
Episode: 4461/30000 (14.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.8463s / 52441.4125 s
agent0:                 episode reward: -0.2377,                 loss: nan
agent1:                 episode reward: 0.2377,                 loss: 0.1275
Episode: 4481/30000 (14.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 257.6863s / 52699.0988 s
agent0:                 episode reward: -0.2744,                 loss: nan
agent1:                 episode reward: 0.2744,                 loss: 0.1282
Episode: 4501/30000 (15.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.4546s / 52944.5534 s
agent0:                 episode reward: -0.2162,                 loss: nan
agent1:                 episode reward: 0.2162,                 loss: 0.1280
Episode: 4521/30000 (15.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 240.7244s / 53185.2779 s
agent0:                 episode reward: -0.2220,                 loss: nan
agent1:                 episode reward: 0.2220,                 loss: 0.1290
Episode: 4541/30000 (15.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 241.2976s / 53426.5754 s
agent0:                 episode reward: -0.0871,                 loss: nan
agent1:                 episode reward: 0.0871,                 loss: 0.1282
Episode: 4561/30000 (15.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.7649s / 53679.3404 s
agent0:                 episode reward: -0.2090,                 loss: nan
agent1:                 episode reward: 0.2090,                 loss: 0.1340
Episode: 4581/30000 (15.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.4141s / 53925.7545 s
agent0:                 episode reward: -0.0807,                 loss: nan
agent1:                 episode reward: 0.0807,                 loss: 0.1357
Episode: 4601/30000 (15.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 253.2711s / 54179.0256 s
agent0:                 episode reward: -0.1749,                 loss: nan
agent1:                 episode reward: 0.1749,                 loss: 0.1344
Episode: 4621/30000 (15.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.6768s / 54431.7023 s
agent0:                 episode reward: 0.4092,                 loss: nan
agent1:                 episode reward: -0.4092,                 loss: 0.1341
Episode: 4641/30000 (15.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.2662s / 54683.9686 s
agent0:                 episode reward: -0.1616,                 loss: nan
agent1:                 episode reward: 0.1616,                 loss: 0.1348
Episode: 4661/30000 (15.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.7578s / 54929.7263 s
agent0:                 episode reward: -0.1425,                 loss: nan
agent1:                 episode reward: 0.1425,                 loss: 0.1344
Episode: 4681/30000 (15.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.2819s / 55175.0082 s
agent0:                 episode reward: -0.0774,                 loss: nan
agent1:                 episode reward: 0.0774,                 loss: 0.1359
Episode: 4701/30000 (15.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.7168s / 55426.7251 s
agent0:                 episode reward: 0.0315,                 loss: nan
agent1:                 episode reward: -0.0315,                 loss: 0.1345
Episode: 4721/30000 (15.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 253.0846s / 55679.8096 s
agent0:                 episode reward: -0.4880,                 loss: nan
agent1:                 episode reward: 0.4880,                 loss: 0.1349
Episode: 4741/30000 (15.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.3755s / 55926.1852 s
agent0:                 episode reward: -0.1761,                 loss: nan
agent1:                 episode reward: 0.1761,                 loss: 0.1339
Episode: 4761/30000 (15.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.2982s / 56178.4834 s
agent0:                 episode reward: -0.0583,                 loss: nan
agent1:                 episode reward: 0.0583,                 loss: 0.1343
Episode: 4781/30000 (15.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.8176s / 56426.3010 s
agent0:                 episode reward: -0.0175,                 loss: nan
agent1:                 episode reward: 0.0175,                 loss: 0.1343
Episode: 4801/30000 (16.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.7515s / 56672.0525 s
agent0:                 episode reward: -0.0987,                 loss: nan
agent1:                 episode reward: 0.0987,                 loss: 0.1338
Episode: 4821/30000 (16.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.6024s / 56921.6548 s
agent0:                 episode reward: -0.2131,                 loss: nan
agent1:                 episode reward: 0.2131,                 loss: 0.1341
Episode: 4841/30000 (16.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.5262s / 57171.1811 s
agent0:                 episode reward: 0.0031,                 loss: nan
agent1:                 episode reward: -0.0031,                 loss: 0.1335
Episode: 4861/30000 (16.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 258.4527s / 57429.6338 s
agent0:                 episode reward: -0.4562,                 loss: nan
agent1:                 episode reward: 0.4562,                 loss: 0.1340
Episode: 4881/30000 (16.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.4036s / 57678.0374 s
agent0:                 episode reward: -0.0495,                 loss: nan
agent1:                 episode reward: 0.0495,                 loss: 0.1336
Episode: 4901/30000 (16.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 237.0014s / 57915.0388 s
agent0:                 episode reward: -0.2727,                 loss: nan
agent1:                 episode reward: 0.2727,                 loss: 0.1308
Episode: 4921/30000 (16.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.8658s / 58164.9046 s
agent0:                 episode reward: -0.7386,                 loss: nan
agent1:                 episode reward: 0.7386,                 loss: 0.1301
Episode: 4941/30000 (16.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.3372s / 58407.2418 s
agent0:                 episode reward: -0.0613,                 loss: nan
agent1:                 episode reward: 0.0613,                 loss: 0.1300
Episode: 4961/30000 (16.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.0720s / 58655.3138 s
agent0:                 episode reward: -0.2156,                 loss: nan
agent1:                 episode reward: 0.2156,                 loss: 0.1303
Episode: 4981/30000 (16.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.1363s / 58902.4501 s
agent0:                 episode reward: -0.1571,                 loss: nan
agent1:                 episode reward: 0.1571,                 loss: 0.1305
Episode: 5001/30000 (16.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.2187s / 59151.6688 s
agent0:                 episode reward: -0.2279,                 loss: nan
agent1:                 episode reward: 0.2279,                 loss: 0.1310
Episode: 5021/30000 (16.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 255.0577s / 59406.7264 s
agent0:                 episode reward: -0.2699,                 loss: nan
agent1:                 episode reward: 0.2699,                 loss: 0.1306
Episode: 5041/30000 (16.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.3362s / 59653.0626 s
agent0:                 episode reward: -0.1142,                 loss: nan
agent1:                 episode reward: 0.1142,                 loss: 0.1298
Episode: 5061/30000 (16.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.4649s / 59902.5275 s
agent0:                 episode reward: -0.4041,                 loss: nan
agent1:                 episode reward: 0.4041,                 loss: 0.1295
Episode: 5081/30000 (16.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.9904s / 60149.5179 s
agent0:                 episode reward: -0.5343,                 loss: nan
agent1:                 episode reward: 0.5343,                 loss: 0.1302
Episode: 5101/30000 (17.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.5138s / 60393.0317 s
agent0:                 episode reward: -0.0275,                 loss: nan
agent1:                 episode reward: 0.0275,                 loss: 0.1290
Episode: 5121/30000 (17.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.6302s / 60638.6619 s
agent0:                 episode reward: -0.1256,                 loss: nan
agent1:                 episode reward: 0.1256,                 loss: 0.1306
Episode: 5141/30000 (17.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.9583s / 60890.6202 s
agent0:                 episode reward: -0.2936,                 loss: nan
agent1:                 episode reward: 0.2936,                 loss: 0.1295
Episode: 5161/30000 (17.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.2037s / 61138.8239 s
agent0:                 episode reward: -0.3681,                 loss: nan
agent1:                 episode reward: 0.3681,                 loss: 0.1284
Episode: 5181/30000 (17.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.9132s / 61386.7371 s
agent0:                 episode reward: 0.1326,                 loss: nan
agent1:                 episode reward: -0.1326,                 loss: 0.1300
Episode: 5201/30000 (17.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.1521s / 61637.8892 s
agent0:                 episode reward: -0.2543,                 loss: nan
agent1:                 episode reward: 0.2543,                 loss: 0.1290
Episode: 5221/30000 (17.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.1546s / 61884.0437 s
agent0:                 episode reward: -0.2479,                 loss: nan
agent1:                 episode reward: 0.2479,                 loss: 0.1301
Episode: 5241/30000 (17.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.0896s / 62134.1333 s
agent0:                 episode reward: 0.0672,                 loss: nan
agent1:                 episode reward: -0.0672,                 loss: 0.1298
Episode: 5261/30000 (17.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.6900s / 62377.8234 s
agent0:                 episode reward: -0.4892,                 loss: nan
agent1:                 episode reward: 0.4892,                 loss: 0.1297
Episode: 5281/30000 (17.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.3293s / 62624.1527 s
agent0:                 episode reward: -0.5714,                 loss: nan
agent1:                 episode reward: 0.5714,                 loss: 0.1300
Episode: 5301/30000 (17.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.6000s / 62874.7526 s
agent0:                 episode reward: -0.5592,                 loss: nan
agent1:                 episode reward: 0.5592,                 loss: 0.1301
Episode: 5321/30000 (17.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.3256s / 63122.0782 s
agent0:                 episode reward: -0.0265,                 loss: nan
agent1:                 episode reward: 0.0265,                 loss: 0.1286
Episode: 5341/30000 (17.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.1138s / 63373.1920 s
agent0:                 episode reward: -0.2773,                 loss: nan
agent1:                 episode reward: 0.2773,                 loss: 0.1298
Episode: 5361/30000 (17.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 236.5395s / 63609.7314 s
agent0:                 episode reward: -0.3239,                 loss: nan
agent1:                 episode reward: 0.3239,                 loss: 0.1309
Episode: 5381/30000 (17.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.3600s / 63852.0915 s
agent0:                 episode reward: -0.3463,                 loss: nan
agent1:                 episode reward: 0.3463,                 loss: 0.1315
Episode: 5401/30000 (18.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.9606s / 64100.0520 s
agent0:                 episode reward: -0.1142,                 loss: nan
agent1:                 episode reward: 0.1142,                 loss: 0.1305
Episode: 5421/30000 (18.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.8398s / 64345.8918 s
agent0:                 episode reward: -0.7008,                 loss: nan
agent1:                 episode reward: 0.7008,                 loss: 0.1300
Episode: 5441/30000 (18.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.2573s / 64590.1491 s
agent0:                 episode reward: -0.2841,                 loss: nan
agent1:                 episode reward: 0.2841,                 loss: 0.1308
Episode: 5461/30000 (18.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.3649s / 64838.5140 s
agent0:                 episode reward: 0.2162,                 loss: nan
agent1:                 episode reward: -0.2162,                 loss: 0.1309
Episode: 5481/30000 (18.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.6776s / 65084.1916 s
agent0:                 episode reward: 0.0812,                 loss: nan
agent1:                 episode reward: -0.0812,                 loss: 0.1299
Episode: 5501/30000 (18.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.5915s / 65331.7830 s
agent0:                 episode reward: -0.2258,                 loss: nan
agent1:                 episode reward: 0.2258,                 loss: 0.1312
Episode: 5521/30000 (18.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.4086s / 65574.1916 s
agent0:                 episode reward: -0.3245,                 loss: nan
agent1:                 episode reward: 0.3245,                 loss: 0.1300
Episode: 5541/30000 (18.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.5699s / 65822.7615 s
agent0:                 episode reward: -0.5753,                 loss: nan
agent1:                 episode reward: 0.5753,                 loss: 0.1310
Episode: 5561/30000 (18.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 241.0881s / 66063.8496 s
agent0:                 episode reward: 0.1325,                 loss: nan
agent1:                 episode reward: -0.1325,                 loss: 0.1284
Episode: 5581/30000 (18.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.9065s / 66311.7561 s
agent0:                 episode reward: -0.5369,                 loss: nan
agent1:                 episode reward: 0.5369,                 loss: 0.1300
Episode: 5601/30000 (18.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.5789s / 66558.3350 s
agent0:                 episode reward: -0.2789,                 loss: nan
agent1:                 episode reward: 0.2789,                 loss: 0.1286
Episode: 5621/30000 (18.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.6873s / 66807.0223 s
agent0:                 episode reward: -0.3364,                 loss: nan
agent1:                 episode reward: 0.3364,                 loss: 0.1293
Episode: 5641/30000 (18.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.5166s / 67051.5390 s
agent0:                 episode reward: -0.1724,                 loss: nan
agent1:                 episode reward: 0.1724,                 loss: 0.1293
Episode: 5661/30000 (18.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.0739s / 67297.6128 s
agent0:                 episode reward: 0.0512,                 loss: nan
agent1:                 episode reward: -0.0512,                 loss: 0.1293
Episode: 5681/30000 (18.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.0104s / 67547.6232 s
agent0:                 episode reward: -0.4908,                 loss: nan
agent1:                 episode reward: 0.4908,                 loss: 0.1293
Episode: 5701/30000 (19.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.3635s / 67793.9868 s
agent0:                 episode reward: -0.4048,                 loss: nan
agent1:                 episode reward: 0.4048,                 loss: 0.1279
Episode: 5721/30000 (19.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.2381s / 68043.2249 s
agent0:                 episode reward: -0.0408,                 loss: nan
agent1:                 episode reward: 0.0408,                 loss: 0.1286
Episode: 5741/30000 (19.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 255.9503s / 68299.1752 s
agent0:                 episode reward: -0.2318,                 loss: nan
agent1:                 episode reward: 0.2318,                 loss: 0.1282
Episode: 5761/30000 (19.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.5604s / 68547.7356 s
agent0:                 episode reward: -0.5765,                 loss: nan
agent1:                 episode reward: 0.5765,                 loss: 0.1294
Episode: 5781/30000 (19.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.9052s / 68795.6408 s
agent0:                 episode reward: -0.1858,                 loss: nan
agent1:                 episode reward: 0.1858,                 loss: 0.1287
Episode: 5801/30000 (19.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.7951s / 69048.4359 s
agent0:                 episode reward: -0.2322,                 loss: nan
agent1:                 episode reward: 0.2322,                 loss: 0.1286
Episode: 5821/30000 (19.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.7176s / 69297.1535 s
agent0:                 episode reward: -0.1739,                 loss: nan
agent1:                 episode reward: 0.1739,                 loss: 0.1274
Episode: 5841/30000 (19.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.4628s / 69546.6162 s
agent0:                 episode reward: -0.0907,                 loss: nan
agent1:                 episode reward: 0.0907,                 loss: 0.1295
Episode: 5861/30000 (19.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 253.0516s / 69799.6678 s
agent0:                 episode reward: -0.3902,                 loss: nan
agent1:                 episode reward: 0.3902,                 loss: 0.1285
Episode: 5881/30000 (19.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 255.0077s / 70054.6755 s
agent0:                 episode reward: -0.2142,                 loss: nan
agent1:                 episode reward: 0.2142,                 loss: 0.1278
Episode: 5901/30000 (19.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 253.4818s / 70308.1573 s
agent0:                 episode reward: -0.4069,                 loss: nan
agent1:                 episode reward: 0.4069,                 loss: 0.1296
Episode: 5921/30000 (19.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.5353s / 70554.6926 s
agent0:                 episode reward: -0.4599,                 loss: nan
agent1:                 episode reward: 0.4599,                 loss: 0.1295
Episode: 5941/30000 (19.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.4656s / 70803.1582 s
agent0:                 episode reward: -0.6499,                 loss: nan
agent1:                 episode reward: 0.6499,                 loss: 0.1309
Episode: 5961/30000 (19.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.1894s / 71045.3476 s
agent0:                 episode reward: -0.4085,                 loss: nan
agent1:                 episode reward: 0.4085,                 loss: 0.1301
Episode: 5981/30000 (19.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.0954s / 71296.4430 s
agent0:                 episode reward: -0.3397,                 loss: nan
agent1:                 episode reward: 0.3397,                 loss: 0.1295
Episode: 6001/30000 (20.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.0348s / 71548.4777 s
agent0:                 episode reward: -0.3235,                 loss: nan
agent1:                 episode reward: 0.3235,                 loss: 0.1308
Episode: 6021/30000 (20.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.7373s / 71796.2151 s
agent0:                 episode reward: -0.6271,                 loss: nan
agent1:                 episode reward: 0.6271,                 loss: 0.1296
Episode: 6041/30000 (20.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 238.6324s / 72034.8475 s
agent0:                 episode reward: -0.1928,                 loss: nan
agent1:                 episode reward: 0.1928,                 loss: 0.1303
Episode: 6061/30000 (20.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.8175s / 72285.6650 s
agent0:                 episode reward: -0.2472,                 loss: nan
agent1:                 episode reward: 0.2472,                 loss: 0.1293
Episode: 6081/30000 (20.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.4205s / 72533.0855 s
agent0:                 episode reward: -0.2020,                 loss: nan
agent1:                 episode reward: 0.2020,                 loss: 0.1293
Episode: 6101/30000 (20.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.5343s / 72781.6198 s
agent0:                 episode reward: -0.4947,                 loss: nan
agent1:                 episode reward: 0.4947,                 loss: 0.1303
Episode: 6121/30000 (20.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 254.7816s / 73036.4014 s
agent0:                 episode reward: -0.2604,                 loss: nan
agent1:                 episode reward: 0.2604,                 loss: 0.1302
Episode: 6141/30000 (20.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.3022s / 73282.7036 s
agent0:                 episode reward: -0.2458,                 loss: nan
agent1:                 episode reward: 0.2458,                 loss: 0.1278
Episode: 6161/30000 (20.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.2300s / 73528.9336 s
agent0:                 episode reward: -0.2892,                 loss: nan
agent1:                 episode reward: 0.2892,                 loss: 0.1304
Episode: 6181/30000 (20.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 238.6060s / 73767.5396 s
agent0:                 episode reward: -0.3161,                 loss: nan
agent1:                 episode reward: 0.3161,                 loss: 0.1293
Episode: 6201/30000 (20.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 256.4476s / 74023.9872 s
agent0:                 episode reward: -0.2837,                 loss: nan
agent1:                 episode reward: 0.2837,                 loss: 0.1311
Episode: 6221/30000 (20.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.5392s / 74267.5264 s
agent0:                 episode reward: -0.2516,                 loss: nan
agent1:                 episode reward: 0.2516,                 loss: 0.1302
Episode: 6241/30000 (20.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.8624s / 74516.3888 s
agent0:                 episode reward: 0.0694,                 loss: nan
agent1:                 episode reward: -0.0694,                 loss: 0.1289
Episode: 6261/30000 (20.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.6614s / 74761.0502 s
agent0:                 episode reward: -0.6425,                 loss: nan
agent1:                 episode reward: 0.6425,                 loss: 0.1314
Episode: 6281/30000 (20.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.3357s / 75009.3859 s
agent0:                 episode reward: -0.0362,                 loss: nan
agent1:                 episode reward: 0.0362,                 loss: 0.1312
Episode: 6301/30000 (21.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.9844s / 75251.3704 s
agent0:                 episode reward: 0.1286,                 loss: nan
agent1:                 episode reward: -0.1286,                 loss: 0.1298
Episode: 6321/30000 (21.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 254.5314s / 75505.9018 s
agent0:                 episode reward: -0.3687,                 loss: nan
agent1:                 episode reward: 0.3687,                 loss: 0.1308
Episode: 6341/30000 (21.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.5400s / 75753.4418 s
agent0:                 episode reward: -0.2749,                 loss: nan
agent1:                 episode reward: 0.2749,                 loss: 0.1315
Episode: 6361/30000 (21.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.8536s / 76003.2954 s
agent0:                 episode reward: -0.3181,                 loss: nan
agent1:                 episode reward: 0.3181,                 loss: 0.1310
Episode: 6381/30000 (21.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.1966s / 76247.4919 s
agent0:                 episode reward: -0.2055,                 loss: nan
agent1:                 episode reward: 0.2055,                 loss: 0.1299
Episode: 6401/30000 (21.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.3524s / 76492.8443 s
agent0:                 episode reward: -0.5026,                 loss: nan
agent1:                 episode reward: 0.5026,                 loss: 0.1308
Episode: 6421/30000 (21.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 255.2948s / 76748.1390 s
agent0:                 episode reward: 0.1441,                 loss: nan
agent1:                 episode reward: -0.1441,                 loss: 0.1303
Episode: 6441/30000 (21.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.3730s / 76996.5120 s
agent0:                 episode reward: -0.2868,                 loss: nan
agent1:                 episode reward: 0.2868,                 loss: 0.1302
Episode: 6461/30000 (21.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 239.0780s / 77235.5900 s
agent0:                 episode reward: -0.2925,                 loss: nan
agent1:                 episode reward: 0.2925,                 loss: 0.1311
Episode: 6481/30000 (21.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.2853s / 77487.8753 s
agent0:                 episode reward: -0.1645,                 loss: nan
agent1:                 episode reward: 0.1645,                 loss: 0.1299
Episode: 6501/30000 (21.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.4058s / 77729.2811 s
agent0:                 episode reward: -0.6797,                 loss: nan
agent1:                 episode reward: 0.6797,                 loss: 0.1301
Episode: 6521/30000 (21.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.9468s / 77973.2279 s
agent0:                 episode reward: -0.4539,                 loss: nan
agent1:                 episode reward: 0.4539,                 loss: 0.1309
Episode: 6541/30000 (21.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.1915s / 78224.4195 s
agent0:                 episode reward: -0.6219,                 loss: nan
agent1:                 episode reward: 0.6219,                 loss: 0.1292
Episode: 6561/30000 (21.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.6788s / 78469.0983 s
agent0:                 episode reward: -0.2220,                 loss: nan
agent1:                 episode reward: 0.2220,                 loss: 0.1290
Episode: 6581/30000 (21.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.1501s / 78714.2484 s
agent0:                 episode reward: -0.2526,                 loss: nan
agent1:                 episode reward: 0.2526,                 loss: 0.1284
Episode: 6601/30000 (22.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.3730s / 78964.6214 s
agent0:                 episode reward: 0.0492,                 loss: nan
agent1:                 episode reward: -0.0492,                 loss: 0.1282
Episode: 6621/30000 (22.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.7549s / 79206.3763 s
agent0:                 episode reward: -0.3367,                 loss: nan
agent1:                 episode reward: 0.3367,                 loss: 0.1292
Episode: 6641/30000 (22.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 253.8793s / 79460.2556 s
agent0:                 episode reward: -0.3369,                 loss: nan
agent1:                 episode reward: 0.3369,                 loss: 0.1296
Episode: 6661/30000 (22.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 255.7359s / 79715.9915 s
agent0:                 episode reward: -0.4052,                 loss: nan
agent1:                 episode reward: 0.4052,                 loss: 0.1293
Episode: 6681/30000 (22.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.2968s / 79964.2883 s
agent0:                 episode reward: -0.4937,                 loss: nan
agent1:                 episode reward: 0.4937,                 loss: 0.1300
Episode: 6701/30000 (22.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.9544s / 80211.2427 s
agent0:                 episode reward: -0.6771,                 loss: nan
agent1:                 episode reward: 0.6771,                 loss: 0.1283
Episode: 6721/30000 (22.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 253.6404s / 80464.8831 s
agent0:                 episode reward: -0.1895,                 loss: nan
agent1:                 episode reward: 0.1895,                 loss: 0.1284
Episode: 6741/30000 (22.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 240.4126s / 80705.2957 s
agent0:                 episode reward: -0.3369,                 loss: nan
agent1:                 episode reward: 0.3369,                 loss: 0.1280
Episode: 6761/30000 (22.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.8202s / 80956.1159 s
agent0:                 episode reward: -0.0071,                 loss: nan
agent1:                 episode reward: 0.0071,                 loss: 0.1276
Episode: 6781/30000 (22.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.4030s / 81207.5189 s
agent0:                 episode reward: -0.4040,                 loss: nan
agent1:                 episode reward: 0.4040,                 loss: 0.1278
Episode: 6801/30000 (22.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 257.1061s / 81464.6250 s
agent0:                 episode reward: 0.2380,                 loss: nan
agent1:                 episode reward: -0.2380,                 loss: 0.1278
Episode: 6821/30000 (22.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.3710s / 81710.9960 s
agent0:                 episode reward: -0.1588,                 loss: nan
agent1:                 episode reward: 0.1588,                 loss: 0.1288
Episode: 6841/30000 (22.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.4519s / 81959.4479 s
agent0:                 episode reward: -0.6606,                 loss: nan
agent1:                 episode reward: 0.6606,                 loss: 0.1296
Episode: 6861/30000 (22.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 253.1238s / 82212.5717 s
agent0:                 episode reward: -0.5314,                 loss: nan
agent1:                 episode reward: 0.5314,                 loss: 0.1282
Episode: 6881/30000 (22.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.5677s / 82457.1394 s
agent0:                 episode reward: -0.4791,                 loss: nan
agent1:                 episode reward: 0.4791,                 loss: 0.1296
Episode: 6901/30000 (23.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.0335s / 82700.1729 s
agent0:                 episode reward: -0.4308,                 loss: nan
agent1:                 episode reward: 0.4308,                 loss: 0.1297
Episode: 6921/30000 (23.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.2101s / 82946.3830 s
agent0:                 episode reward: -0.7514,                 loss: nan
agent1:                 episode reward: 0.7514,                 loss: 0.1286
Episode: 6941/30000 (23.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.5868s / 83192.9698 s
agent0:                 episode reward: -0.1237,                 loss: nan
agent1:                 episode reward: 0.1237,                 loss: 0.1297
Episode: 6961/30000 (23.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.6991s / 83441.6690 s
agent0:                 episode reward: -0.2969,                 loss: nan
agent1:                 episode reward: 0.2969,                 loss: 0.1297
Episode: 6981/30000 (23.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 258.7516s / 83700.4205 s
agent0:                 episode reward: -0.3687,                 loss: nan
agent1:                 episode reward: 0.3687,                 loss: 0.1293
Episode: 7001/30000 (23.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.0041s / 83951.4246 s
agent0:                 episode reward: -0.3710,                 loss: nan
agent1:                 episode reward: 0.3710,                 loss: 0.1283
Episode: 7021/30000 (23.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.5124s / 84192.9370 s
agent0:                 episode reward: -0.2018,                 loss: nan
agent1:                 episode reward: 0.2018,                 loss: 0.1297
Episode: 7041/30000 (23.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.6182s / 84444.5552 s
agent0:                 episode reward: 0.0434,                 loss: nan
agent1:                 episode reward: -0.0434,                 loss: 0.1295
Episode: 7061/30000 (23.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.9377s / 84697.4928 s
agent0:                 episode reward: 0.1567,                 loss: nan
agent1:                 episode reward: -0.1567,                 loss: 0.1302
Episode: 7081/30000 (23.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.1143s / 84945.6071 s
agent0:                 episode reward: -0.2102,                 loss: nan
agent1:                 episode reward: 0.2102,                 loss: 0.1276
Episode: 7101/30000 (23.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.1488s / 85192.7559 s
agent0:                 episode reward: -0.1412,                 loss: nan
agent1:                 episode reward: 0.1412,                 loss: 0.1297
Episode: 7121/30000 (23.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.8702s / 85443.6262 s
agent0:                 episode reward: -0.3220,                 loss: nan
agent1:                 episode reward: 0.3220,                 loss: 0.1296
Episode: 7141/30000 (23.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.3916s / 85687.0178 s
agent0:                 episode reward: -0.0480,                 loss: nan
agent1:                 episode reward: 0.0480,                 loss: 0.1292
Episode: 7161/30000 (23.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 255.8334s / 85942.8512 s
agent0:                 episode reward: 0.0076,                 loss: nan
agent1:                 episode reward: -0.0076,                 loss: 0.1282
Episode: 7181/30000 (23.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.6409s / 86194.4921 s
agent0:                 episode reward: -0.2387,                 loss: nan
agent1:                 episode reward: 0.2387,                 loss: 0.1287
Episode: 7201/30000 (24.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.7751s / 86442.2671 s
agent0:                 episode reward: -0.1927,                 loss: nan
agent1:                 episode reward: 0.1927,                 loss: 0.1281
Episode: 7221/30000 (24.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.1377s / 86692.4048 s
agent0:                 episode reward: -0.2338,                 loss: nan
agent1:                 episode reward: 0.2338,                 loss: 0.1274
Episode: 7241/30000 (24.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.9892s / 86941.3941 s
agent0:                 episode reward: -0.2904,                 loss: nan
agent1:                 episode reward: 0.2904,                 loss: 0.1296
Episode: 7261/30000 (24.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 259.9074s / 87201.3015 s
agent0:                 episode reward: -0.2631,                 loss: nan
agent1:                 episode reward: 0.2631,                 loss: 0.1270
Episode: 7281/30000 (24.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.8363s / 87454.1378 s
agent0:                 episode reward: -0.3203,                 loss: nan
agent1:                 episode reward: 0.3203,                 loss: 0.1281
Episode: 7301/30000 (24.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.2749s / 87701.4127 s
agent0:                 episode reward: -0.2220,                 loss: nan
agent1:                 episode reward: 0.2220,                 loss: 0.1283
Episode: 7321/30000 (24.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.7595s / 87948.1722 s
agent0:                 episode reward: -0.4297,                 loss: nan
agent1:                 episode reward: 0.4297,                 loss: 0.1279
Episode: 7341/30000 (24.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.4247s / 88199.5969 s
agent0:                 episode reward: -0.5539,                 loss: nan
agent1:                 episode reward: 0.5539,                 loss: 0.1274
Episode: 7361/30000 (24.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 254.1712s / 88453.7681 s
agent0:                 episode reward: 0.0571,                 loss: nan
agent1:                 episode reward: -0.0571,                 loss: 0.1275
Episode: 7381/30000 (24.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.3532s / 88700.1213 s
agent0:                 episode reward: -0.4275,                 loss: nan
agent1:                 episode reward: 0.4275,                 loss: 0.1260
Episode: 7401/30000 (24.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 254.1670s / 88954.2883 s
agent0:                 episode reward: -0.4546,                 loss: nan
agent1:                 episode reward: 0.4546,                 loss: 0.1288
Episode: 7421/30000 (24.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.9729s / 89206.2612 s
agent0:                 episode reward: -0.4673,                 loss: nan
agent1:                 episode reward: 0.4673,                 loss: 0.1290
Episode: 7441/30000 (24.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 255.4173s / 89461.6785 s
agent0:                 episode reward: -0.2366,                 loss: nan
agent1:                 episode reward: 0.2366,                 loss: 0.1294
Episode: 7461/30000 (24.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 254.6191s / 89716.2976 s
agent0:                 episode reward: -0.1190,                 loss: nan
agent1:                 episode reward: 0.1190,                 loss: 0.1282
Episode: 7481/30000 (24.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.2766s / 89967.5742 s