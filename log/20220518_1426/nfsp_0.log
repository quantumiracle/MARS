pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 12.0, (1,), float32) action space: Discrete(3)
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7f996d425cf8>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
Error: no exploited model index given!
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  data/model/20220518033032/mdp_arbitrary_mdp_nfsp/0_0
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': '1i', 'algorithm': 'NFSP', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.0, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 640, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 10000, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220518033032/mdp_arbitrary_mdp_nfsp/0_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False, 'policy': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': 'Softmax'}}, 'marl_method': 'nfsp', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'eta': 0.1}, 'against_baseline': False}
Save models to : /home/zihan/research/MARS/data/model/20220518033032_exploit_0/mdp_arbitrary_mdp_nfsp. 
 Save logs to: /home/zihan/research/MARS/data/log/20220518033032_exploit_0/mdp_arbitrary_mdp_nfsp.
Episode: 1/30000 (0.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6817s / 0.6817 s
agent0:                 episode reward: -0.0866,                 loss: nan
agent1:                 episode reward: 0.0866,                 loss: nan
Episode: 21/30000 (0.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1999s / 0.8816 s
agent0:                 episode reward: -0.4026,                 loss: nan
agent1:                 episode reward: 0.4026,                 loss: nan
Episode: 41/30000 (0.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1986s / 1.0803 s
agent0:                 episode reward: -0.6306,                 loss: nan
agent1:                 episode reward: 0.6306,                 loss: nan
Episode: 61/30000 (0.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1993s / 1.2796 s
agent0:                 episode reward: -0.6244,                 loss: nan
agent1:                 episode reward: 0.6244,                 loss: nan
Episode: 81/30000 (0.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1958s / 1.4754 s
agent0:                 episode reward: -0.4707,                 loss: nan
agent1:                 episode reward: 0.4707,                 loss: nan
Episode: 101/30000 (0.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2000s / 1.6754 s
agent0:                 episode reward: -0.7135,                 loss: nan
agent1:                 episode reward: 0.7135,                 loss: nan
Episode: 121/30000 (0.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1980s / 1.8734 s
agent0:                 episode reward: -0.5701,                 loss: nan
agent1:                 episode reward: 0.5701,                 loss: nan
Episode: 141/30000 (0.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1964s / 2.0698 s
agent0:                 episode reward: -0.2737,                 loss: nan
agent1:                 episode reward: 0.2737,                 loss: nan
Episode: 161/30000 (0.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1971s / 2.2669 s
agent0:                 episode reward: -0.0670,                 loss: nan
agent1:                 episode reward: 0.0670,                 loss: nan
Episode: 181/30000 (0.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1977s / 2.4646 s
agent0:                 episode reward: -0.3923,                 loss: nan
agent1:                 episode reward: 0.3923,                 loss: nan
Episode: 201/30000 (0.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1977s / 2.6623 s
agent0:                 episode reward: -0.3889,                 loss: nan
agent1:                 episode reward: 0.3889,                 loss: nan
Episode: 221/30000 (0.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1955s / 2.8578 s
agent0:                 episode reward: -0.7238,                 loss: nan
agent1:                 episode reward: 0.7238,                 loss: nan
Episode: 241/30000 (0.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2020s / 3.0598 s
agent0:                 episode reward: -0.5860,                 loss: nan
agent1:                 episode reward: 0.5860,                 loss: nan
Episode: 261/30000 (0.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1997s / 3.2595 s
agent0:                 episode reward: -0.0203,                 loss: nan
agent1:                 episode reward: 0.0203,                 loss: nan
Episode: 281/30000 (0.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2009s / 3.4603 s
agent0:                 episode reward: -0.4311,                 loss: nan
agent1:                 episode reward: 0.4311,                 loss: nan
Episode: 301/30000 (1.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1984s / 3.6587 s
agent0:                 episode reward: -0.4983,                 loss: nan
agent1:                 episode reward: 0.4983,                 loss: nan
Episode: 321/30000 (1.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1991s / 3.8579 s
agent0:                 episode reward: -0.2133,                 loss: nan
agent1:                 episode reward: 0.2133,                 loss: nan
Episode: 341/30000 (1.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2026s / 4.0604 s
agent0:                 episode reward: -0.1378,                 loss: nan
agent1:                 episode reward: 0.1378,                 loss: nan
Episode: 361/30000 (1.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1990s / 4.2594 s
agent0:                 episode reward: -0.5586,                 loss: nan
agent1:                 episode reward: 0.5586,                 loss: nan
Episode: 381/30000 (1.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1989s / 4.4583 s
agent0:                 episode reward: -0.2648,                 loss: nan
agent1:                 episode reward: 0.2648,                 loss: nan
Episode: 401/30000 (1.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1987s / 4.6570 s
agent0:                 episode reward: -0.4996,                 loss: nan
agent1:                 episode reward: 0.4996,                 loss: nan
Episode: 421/30000 (1.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2030s / 4.8600 s
agent0:                 episode reward: -0.3205,                 loss: nan
agent1:                 episode reward: 0.3205,                 loss: nan
Episode: 441/30000 (1.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1980s / 5.0580 s
agent0:                 episode reward: -0.3222,                 loss: nan
agent1:                 episode reward: 0.3222,                 loss: nan
Episode: 461/30000 (1.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1980s / 5.2560 s
agent0:                 episode reward: -0.4738,                 loss: nan
agent1:                 episode reward: 0.4738,                 loss: nan
Episode: 481/30000 (1.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1928s / 5.4488 s
agent0:                 episode reward: -0.2774,                 loss: nan
agent1:                 episode reward: 0.2774,                 loss: nan
Episode: 501/30000 (1.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2006s / 5.6494 s
agent0:                 episode reward: -0.3907,                 loss: nan
agent1:                 episode reward: 0.3907,                 loss: nan
Episode: 521/30000 (1.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1970s / 5.8464 s
agent0:                 episode reward: -0.4034,                 loss: nan
agent1:                 episode reward: 0.4034,                 loss: nan
Episode: 541/30000 (1.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1995s / 6.0459 s
agent0:                 episode reward: -0.7386,                 loss: nan
agent1:                 episode reward: 0.7386,                 loss: nan
Episode: 561/30000 (1.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2033s / 6.2492 s
agent0:                 episode reward: -0.2521,                 loss: nan
agent1:                 episode reward: 0.2521,                 loss: nan
Episode: 581/30000 (1.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2020s / 6.4512 s
agent0:                 episode reward: -0.8324,                 loss: nan
agent1:                 episode reward: 0.8324,                 loss: nan
Episode: 601/30000 (2.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1999s / 6.6511 s
agent0:                 episode reward: -0.6580,                 loss: nan
agent1:                 episode reward: 0.6580,                 loss: nan
Episode: 621/30000 (2.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1952s / 6.8463 s
agent0:                 episode reward: -0.3891,                 loss: nan
agent1:                 episode reward: 0.3891,                 loss: nan
Episode: 641/30000 (2.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1963s / 7.0426 s
agent0:                 episode reward: -0.6155,                 loss: nan
agent1:                 episode reward: 0.6155,                 loss: nan
Episode: 661/30000 (2.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2013s / 7.2439 s
agent0:                 episode reward: -0.2259,                 loss: nan
agent1:                 episode reward: 0.2259,                 loss: nan
Episode: 681/30000 (2.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1965s / 7.4404 s
agent0:                 episode reward: -0.5294,                 loss: nan
agent1:                 episode reward: 0.5294,                 loss: nan
Episode: 701/30000 (2.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2022s / 7.6425 s
agent0:                 episode reward: -0.5638,                 loss: nan
agent1:                 episode reward: 0.5638,                 loss: nan
Episode: 721/30000 (2.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1984s / 7.8410 s
agent0:                 episode reward: -0.3615,                 loss: nan
agent1:                 episode reward: 0.3615,                 loss: nan
Episode: 741/30000 (2.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1929s / 8.0339 s
agent0:                 episode reward: -0.3980,                 loss: nan
agent1:                 episode reward: 0.3980,                 loss: nan
Episode: 761/30000 (2.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1932s / 8.2270 s
agent0:                 episode reward: -0.3628,                 loss: nan
agent1:                 episode reward: 0.3628,                 loss: nan
Episode: 781/30000 (2.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2016s / 8.4286 s
agent0:                 episode reward: -0.4379,                 loss: nan
agent1:                 episode reward: 0.4379,                 loss: nan
Episode: 801/30000 (2.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2015s / 8.6301 s
agent0:                 episode reward: -0.6642,                 loss: nan
agent1:                 episode reward: 0.6642,                 loss: nan
Episode: 821/30000 (2.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1984s / 8.8284 s
agent0:                 episode reward: -0.4507,                 loss: nan
agent1:                 episode reward: 0.4507,                 loss: nan
Episode: 841/30000 (2.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2045s / 9.0330 s
agent0:                 episode reward: -0.3853,                 loss: nan
agent1:                 episode reward: 0.3853,                 loss: nan
Episode: 861/30000 (2.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1985s / 9.2315 s
agent0:                 episode reward: -0.2113,                 loss: nan
agent1:                 episode reward: 0.2113,                 loss: nan
Episode: 881/30000 (2.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1976s / 9.4291 s
agent0:                 episode reward: -0.5913,                 loss: nan
agent1:                 episode reward: 0.5913,                 loss: nan
Episode: 901/30000 (3.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1954s / 9.6246 s
agent0:                 episode reward: -0.2091,                 loss: nan
agent1:                 episode reward: 0.2091,                 loss: nan
Episode: 921/30000 (3.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1985s / 9.8230 s
agent0:                 episode reward: -0.8278,                 loss: nan
agent1:                 episode reward: 0.8278,                 loss: nan
Episode: 941/30000 (3.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1914s / 10.0145 s
agent0:                 episode reward: -0.5499,                 loss: nan
agent1:                 episode reward: 0.5499,                 loss: nan
Episode: 961/30000 (3.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2022s / 10.2166 s
agent0:                 episode reward: -0.5355,                 loss: nan
agent1:                 episode reward: 0.5355,                 loss: nan
Episode: 981/30000 (3.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2005s / 10.4171 s
agent0:                 episode reward: -0.1703,                 loss: nan
agent1:                 episode reward: 0.1703,                 loss: nan
Episode: 1001/30000 (3.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1969s / 10.6140 s
agent0:                 episode reward: -0.5863,                 loss: nan
agent1:                 episode reward: 0.5863,                 loss: nan
Episode: 1021/30000 (3.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1969s / 10.8109 s
agent0:                 episode reward: -0.5569,                 loss: nan
agent1:                 episode reward: 0.5569,                 loss: nan
Episode: 1041/30000 (3.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1970s / 11.0079 s
agent0:                 episode reward: -0.3202,                 loss: nan
agent1:                 episode reward: 0.3202,                 loss: nan
Episode: 1061/30000 (3.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1981s / 11.2060 s
agent0:                 episode reward: -0.3319,                 loss: nan
agent1:                 episode reward: 0.3319,                 loss: nan
Episode: 1081/30000 (3.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2122s / 11.4182 s
agent0:                 episode reward: -0.1130,                 loss: nan
agent1:                 episode reward: 0.1130,                 loss: nan
Episode: 1101/30000 (3.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2036s / 11.6218 s
agent0:                 episode reward: -0.1682,                 loss: nan
agent1:                 episode reward: 0.1682,                 loss: nan
Episode: 1121/30000 (3.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1974s / 11.8192 s
agent0:                 episode reward: -0.5883,                 loss: nan
agent1:                 episode reward: 0.5883,                 loss: nan
Episode: 1141/30000 (3.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2013s / 12.0206 s
agent0:                 episode reward: -0.6164,                 loss: nan
agent1:                 episode reward: 0.6164,                 loss: nan
Episode: 1161/30000 (3.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1985s / 12.2191 s
agent0:                 episode reward: -0.4407,                 loss: nan
agent1:                 episode reward: 0.4407,                 loss: nan
Episode: 1181/30000 (3.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1984s / 12.4176 s
agent0:                 episode reward: -0.4161,                 loss: nan
agent1:                 episode reward: 0.4161,                 loss: nan
Episode: 1201/30000 (4.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1954s / 12.6130 s
agent0:                 episode reward: -0.5939,                 loss: nan
agent1:                 episode reward: 0.5939,                 loss: nan
Episode: 1221/30000 (4.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1977s / 12.8107 s
agent0:                 episode reward: -0.1059,                 loss: nan
agent1:                 episode reward: 0.1059,                 loss: nan
Episode: 1241/30000 (4.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1989s / 13.0096 s
agent0:                 episode reward: -0.4622,                 loss: nan
agent1:                 episode reward: 0.4622,                 loss: nan
Episode: 1261/30000 (4.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1953s / 13.2049 s
agent0:                 episode reward: -0.0603,                 loss: nan
agent1:                 episode reward: 0.0603,                 loss: nan
Episode: 1281/30000 (4.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2036s / 13.4086 s
agent0:                 episode reward: -0.5533,                 loss: nan
agent1:                 episode reward: 0.5533,                 loss: nan
Episode: 1301/30000 (4.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1974s / 13.6059 s
agent0:                 episode reward: -0.2316,                 loss: nan
agent1:                 episode reward: 0.2316,                 loss: nan
Episode: 1321/30000 (4.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1977s / 13.8036 s
agent0:                 episode reward: -0.1132,                 loss: nan
agent1:                 episode reward: 0.1132,                 loss: nan
Episode: 1341/30000 (4.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1962s / 13.9998 s
agent0:                 episode reward: -0.3661,                 loss: nan
agent1:                 episode reward: 0.3661,                 loss: nan
Episode: 1361/30000 (4.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1965s / 14.1964 s
agent0:                 episode reward: -0.4480,                 loss: nan
agent1:                 episode reward: 0.4480,                 loss: nan
Episode: 1381/30000 (4.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1987s / 14.3951 s
agent0:                 episode reward: -0.2427,                 loss: nan
agent1:                 episode reward: 0.2427,                 loss: nan
Episode: 1401/30000 (4.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2025s / 14.5975 s
agent0:                 episode reward: -0.1579,                 loss: nan
agent1:                 episode reward: 0.1579,                 loss: nan
Episode: 1421/30000 (4.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1979s / 14.7955 s
agent0:                 episode reward: 0.0453,                 loss: nan
agent1:                 episode reward: -0.0453,                 loss: nan
Episode: 1441/30000 (4.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1939s / 14.9894 s
agent0:                 episode reward: -0.2473,                 loss: nan
agent1:                 episode reward: 0.2473,                 loss: nan
Episode: 1461/30000 (4.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1982s / 15.1876 s
agent0:                 episode reward: -0.6953,                 loss: nan
agent1:                 episode reward: 0.6953,                 loss: nan
Episode: 1481/30000 (4.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2008s / 15.3883 s
agent0:                 episode reward: -0.2237,                 loss: nan
agent1:                 episode reward: 0.2237,                 loss: nan
Episode: 1501/30000 (5.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1971s / 15.5854 s
agent0:                 episode reward: -0.8227,                 loss: nan
agent1:                 episode reward: 0.8227,                 loss: nan
Episode: 1521/30000 (5.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1981s / 15.7835 s
agent0:                 episode reward: -0.2212,                 loss: nan
agent1:                 episode reward: 0.2212,                 loss: nan
Episode: 1541/30000 (5.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1996s / 15.9832 s
agent0:                 episode reward: -0.4822,                 loss: nan
agent1:                 episode reward: 0.4822,                 loss: nan
Episode: 1561/30000 (5.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2002s / 16.1833 s
agent0:                 episode reward: -0.2881,                 loss: nan
agent1:                 episode reward: 0.2881,                 loss: nan
Episode: 1581/30000 (5.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2022s / 16.3855 s
agent0:                 episode reward: -0.2008,                 loss: nan
agent1:                 episode reward: 0.2008,                 loss: nan
Episode: 1601/30000 (5.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1973s / 16.5828 s
agent0:                 episode reward: -0.5301,                 loss: nan
agent1:                 episode reward: 0.5301,                 loss: nan
Episode: 1621/30000 (5.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1962s / 16.7790 s
agent0:                 episode reward: -0.2841,                 loss: nan
agent1:                 episode reward: 0.2841,                 loss: nan
Episode: 1641/30000 (5.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2018s / 16.9807 s
agent0:                 episode reward: -0.5575,                 loss: nan
agent1:                 episode reward: 0.5575,                 loss: nan
Episode: 1661/30000 (5.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1953s / 17.1760 s
agent0:                 episode reward: -0.1677,                 loss: nan
agent1:                 episode reward: 0.1677,                 loss: nan
Episode: 1681/30000 (5.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2019s / 17.3779 s
agent0:                 episode reward: -0.1830,                 loss: nan
agent1:                 episode reward: 0.1830,                 loss: nan
Episode: 1701/30000 (5.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1986s / 17.5765 s
agent0:                 episode reward: -0.6703,                 loss: nan
agent1:                 episode reward: 0.6703,                 loss: nan
Episode: 1721/30000 (5.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1975s / 17.7740 s
agent0:                 episode reward: -0.2390,                 loss: nan
agent1:                 episode reward: 0.2390,                 loss: nan
Episode: 1741/30000 (5.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1995s / 17.9735 s
agent0:                 episode reward: -0.4232,                 loss: nan
agent1:                 episode reward: 0.4232,                 loss: nan
Episode: 1761/30000 (5.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1943s / 18.1678 s
agent0:                 episode reward: -0.3334,                 loss: nan
agent1:                 episode reward: 0.3334,                 loss: nan
Episode: 1781/30000 (5.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1982s / 18.3660 s
agent0:                 episode reward: -0.7960,                 loss: nan
agent1:                 episode reward: 0.7960,                 loss: nan
Episode: 1801/30000 (6.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2010s / 18.5670 s
agent0:                 episode reward: -0.4163,                 loss: nan
agent1:                 episode reward: 0.4163,                 loss: nan
Episode: 1821/30000 (6.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2006s / 18.7675 s
agent0:                 episode reward: -0.0464,                 loss: nan
agent1:                 episode reward: 0.0464,                 loss: nan
Episode: 1841/30000 (6.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1978s / 18.9653 s
agent0:                 episode reward: -0.6029,                 loss: nan
agent1:                 episode reward: 0.6029,                 loss: nan
Episode: 1861/30000 (6.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1992s / 19.1645 s
agent0:                 episode reward: 0.0040,                 loss: nan
agent1:                 episode reward: -0.0040,                 loss: nan
Episode: 1881/30000 (6.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2027s / 19.3672 s
agent0:                 episode reward: -0.4745,                 loss: nan
agent1:                 episode reward: 0.4745,                 loss: nan
Episode: 1901/30000 (6.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1994s / 19.5666 s
agent0:                 episode reward: -0.1623,                 loss: nan
agent1:                 episode reward: 0.1623,                 loss: nan
Episode: 1921/30000 (6.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1996s / 19.7662 s
agent0:                 episode reward: -0.6035,                 loss: nan
agent1:                 episode reward: 0.6035,                 loss: nan
Episode: 1941/30000 (6.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1937s / 19.9599 s
agent0:                 episode reward: -0.5829,                 loss: nan
agent1:                 episode reward: 0.5829,                 loss: nan
Episode: 1961/30000 (6.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1997s / 20.1596 s
agent0:                 episode reward: -0.2951,                 loss: nan
agent1:                 episode reward: 0.2951,                 loss: nan
Episode: 1981/30000 (6.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1965s / 20.3561 s
agent0:                 episode reward: -0.3015,                 loss: nan
agent1:                 episode reward: 0.3015,                 loss: nan
Episode: 2001/30000 (6.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1947s / 20.5509 s
agent0:                 episode reward: -0.6338,                 loss: nan
agent1:                 episode reward: 0.6338,                 loss: nan
Episode: 2021/30000 (6.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2053s / 20.7562 s
agent0:                 episode reward: -0.2692,                 loss: nan
agent1:                 episode reward: 0.2692,                 loss: nan
Episode: 2041/30000 (6.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1989s / 20.9551 s
agent0:                 episode reward: -0.4078,                 loss: nan
agent1:                 episode reward: 0.4078,                 loss: nan
Episode: 2061/30000 (6.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1978s / 21.1529 s
agent0:                 episode reward: -0.4690,                 loss: nan
agent1:                 episode reward: 0.4690,                 loss: nan
Episode: 2081/30000 (6.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2014s / 21.3543 s
agent0:                 episode reward: -0.4175,                 loss: nan
agent1:                 episode reward: 0.4175,                 loss: nan
Episode: 2101/30000 (7.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1997s / 21.5540 s
agent0:                 episode reward: -0.5541,                 loss: nan
agent1:                 episode reward: 0.5541,                 loss: nan
Episode: 2121/30000 (7.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1987s / 21.7527 s
agent0:                 episode reward: -0.1008,                 loss: nan
agent1:                 episode reward: 0.1008,                 loss: nan
Episode: 2141/30000 (7.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2005s / 21.9532 s
agent0:                 episode reward: -0.8415,                 loss: nan
agent1:                 episode reward: 0.8415,                 loss: nan
Episode: 2161/30000 (7.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1982s / 22.1514 s
agent0:                 episode reward: -0.3766,                 loss: nan
agent1:                 episode reward: 0.3766,                 loss: nan
Episode: 2181/30000 (7.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1971s / 22.3485 s
agent0:                 episode reward: -0.0690,                 loss: nan
agent1:                 episode reward: 0.0690,                 loss: nan
Episode: 2201/30000 (7.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1970s / 22.5455 s
agent0:                 episode reward: -0.6205,                 loss: nan
agent1:                 episode reward: 0.6205,                 loss: nan
Episode: 2221/30000 (7.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1970s / 22.7425 s
agent0:                 episode reward: -0.5356,                 loss: nan
agent1:                 episode reward: 0.5356,                 loss: nan
Episode: 2241/30000 (7.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2006s / 22.9431 s
agent0:                 episode reward: -0.5515,                 loss: nan
agent1:                 episode reward: 0.5515,                 loss: nan
Episode: 2261/30000 (7.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1936s / 23.1368 s
agent0:                 episode reward: -0.5673,                 loss: nan
agent1:                 episode reward: 0.5673,                 loss: nan
Episode: 2281/30000 (7.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1963s / 23.3331 s
agent0:                 episode reward: -0.9062,                 loss: nan
agent1:                 episode reward: 0.9062,                 loss: nan
Episode: 2301/30000 (7.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1939s / 23.5270 s
agent0:                 episode reward: -0.2355,                 loss: nan
agent1:                 episode reward: 0.2355,                 loss: nan
Episode: 2321/30000 (7.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1978s / 23.7248 s
agent0:                 episode reward: -0.3925,                 loss: nan
agent1:                 episode reward: 0.3925,                 loss: nan
Episode: 2341/30000 (7.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1964s / 23.9212 s
agent0:                 episode reward: -0.2886,                 loss: nan
agent1:                 episode reward: 0.2886,                 loss: nan
Episode: 2361/30000 (7.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1950s / 24.1162 s
agent0:                 episode reward: -0.3980,                 loss: nan
agent1:                 episode reward: 0.3980,                 loss: nan
Episode: 2381/30000 (7.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1965s / 24.3127 s
agent0:                 episode reward: -0.3212,                 loss: nan
agent1:                 episode reward: 0.3212,                 loss: nan
Episode: 2401/30000 (8.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1980s / 24.5107 s
agent0:                 episode reward: -0.5130,                 loss: nan
agent1:                 episode reward: 0.5130,                 loss: nan
Episode: 2421/30000 (8.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1977s / 24.7084 s
agent0:                 episode reward: -0.5638,                 loss: nan
agent1:                 episode reward: 0.5638,                 loss: nan
Episode: 2441/30000 (8.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2015s / 24.9100 s
agent0:                 episode reward: -0.4930,                 loss: nan
agent1:                 episode reward: 0.4930,                 loss: nan
Episode: 2461/30000 (8.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1966s / 25.1066 s
agent0:                 episode reward: -0.2717,                 loss: nan
agent1:                 episode reward: 0.2717,                 loss: nan
Episode: 2481/30000 (8.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1967s / 25.3033 s
agent0:                 episode reward: -0.2769,                 loss: nan
agent1:                 episode reward: 0.2769,                 loss: nan
Episode: 2501/30000 (8.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2014s / 25.5047 s
agent0:                 episode reward: -0.5970,                 loss: nan
agent1:                 episode reward: 0.5970,                 loss: nan
Episode: 2521/30000 (8.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1955s / 25.7002 s
agent0:                 episode reward: -0.6090,                 loss: nan
agent1:                 episode reward: 0.6090,                 loss: nan
Episode: 2541/30000 (8.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1970s / 25.8971 s
agent0:                 episode reward: -0.7379,                 loss: nan
agent1:                 episode reward: 0.7379,                 loss: nan
Episode: 2561/30000 (8.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2009s / 26.0980 s
agent0:                 episode reward: 0.1263,                 loss: nan
agent1:                 episode reward: -0.1263,                 loss: nan
Episode: 2581/30000 (8.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2016s / 26.2997 s
agent0:                 episode reward: -0.1941,                 loss: nan
agent1:                 episode reward: 0.1941,                 loss: nan
Episode: 2601/30000 (8.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1994s / 26.4991 s
agent0:                 episode reward: -0.6751,                 loss: nan
agent1:                 episode reward: 0.6751,                 loss: nan
Episode: 2621/30000 (8.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1975s / 26.6966 s
agent0:                 episode reward: -0.2623,                 loss: nan
agent1:                 episode reward: 0.2623,                 loss: nan
Episode: 2641/30000 (8.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1971s / 26.8937 s
agent0:                 episode reward: -0.2689,                 loss: nan
agent1:                 episode reward: 0.2689,                 loss: nan
Episode: 2661/30000 (8.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1763s / 27.0700 s
agent0:                 episode reward: -0.3867,                 loss: nan
agent1:                 episode reward: 0.3867,                 loss: nan
Episode: 2681/30000 (8.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1950s / 27.2649 s
agent0:                 episode reward: -0.3254,                 loss: nan
agent1:                 episode reward: 0.3254,                 loss: nan
Episode: 2701/30000 (9.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1971s / 27.4621 s
agent0:                 episode reward: -0.4809,                 loss: nan
agent1:                 episode reward: 0.4809,                 loss: nan
Episode: 2721/30000 (9.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1992s / 27.6613 s
agent0:                 episode reward: -0.1501,                 loss: nan
agent1:                 episode reward: 0.1501,                 loss: nan
Episode: 2741/30000 (9.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1935s / 27.8549 s
agent0:                 episode reward: -0.5714,                 loss: nan
agent1:                 episode reward: 0.5714,                 loss: nan
Episode: 2761/30000 (9.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2344s / 28.0893 s
agent0:                 episode reward: -0.4030,                 loss: nan
agent1:                 episode reward: 0.4030,                 loss: nan
Episode: 2781/30000 (9.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1994s / 28.2887 s
agent0:                 episode reward: -0.4924,                 loss: nan
agent1:                 episode reward: 0.4924,                 loss: nan
Episode: 2801/30000 (9.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1994s / 28.4880 s
agent0:                 episode reward: -0.5483,                 loss: nan
agent1:                 episode reward: 0.5483,                 loss: nan
Episode: 2821/30000 (9.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1980s / 28.6860 s
agent0:                 episode reward: -0.4940,                 loss: nan
agent1:                 episode reward: 0.4940,                 loss: nan
Episode: 2841/30000 (9.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2037s / 28.8897 s
agent0:                 episode reward: -0.5689,                 loss: nan
agent1:                 episode reward: 0.5689,                 loss: nan
Episode: 2861/30000 (9.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1987s / 29.0884 s
agent0:                 episode reward: -0.4781,                 loss: nan
agent1:                 episode reward: 0.4781,                 loss: nan
Episode: 2881/30000 (9.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2044s / 29.2928 s
agent0:                 episode reward: -0.2771,                 loss: nan
agent1:                 episode reward: 0.2771,                 loss: nan
Episode: 2901/30000 (9.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1974s / 29.4902 s
agent0:                 episode reward: -0.1496,                 loss: nan
agent1:                 episode reward: 0.1496,                 loss: nan
Episode: 2921/30000 (9.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1957s / 29.6859 s
agent0:                 episode reward: -0.4534,                 loss: nan
agent1:                 episode reward: 0.4534,                 loss: nan
Episode: 2941/30000 (9.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1968s / 29.8827 s
agent0:                 episode reward: -0.4170,                 loss: nan
agent1:                 episode reward: 0.4170,                 loss: nan
Episode: 2961/30000 (9.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1937s / 30.0764 s
agent0:                 episode reward: -0.3516,                 loss: nan
agent1:                 episode reward: 0.3516,                 loss: nan
Episode: 2981/30000 (9.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1990s / 30.2754 s
agent0:                 episode reward: -0.3621,                 loss: nan
agent1:                 episode reward: 0.3621,                 loss: nan
Episode: 3001/30000 (10.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1995s / 30.4749 s
agent0:                 episode reward: 0.0528,                 loss: nan
agent1:                 episode reward: -0.0528,                 loss: nan
Episode: 3021/30000 (10.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2030s / 30.6779 s
agent0:                 episode reward: -0.5440,                 loss: nan
agent1:                 episode reward: 0.5440,                 loss: nan
Episode: 3041/30000 (10.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1988s / 30.8767 s
agent0:                 episode reward: -0.0282,                 loss: nan
agent1:                 episode reward: 0.0282,                 loss: nan
Episode: 3061/30000 (10.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2001s / 31.0768 s
agent0:                 episode reward: -0.1118,                 loss: nan
agent1:                 episode reward: 0.1118,                 loss: nan
Episode: 3081/30000 (10.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2001s / 31.2769 s
agent0:                 episode reward: -0.4451,                 loss: nan
agent1:                 episode reward: 0.4451,                 loss: nan
Episode: 3101/30000 (10.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2018s / 31.4788 s
agent0:                 episode reward: -0.2633,                 loss: nan
agent1:                 episode reward: 0.2633,                 loss: nan
Episode: 3121/30000 (10.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1972s / 31.6760 s
agent0:                 episode reward: -0.4029,                 loss: nan
agent1:                 episode reward: 0.4029,                 loss: nan
Episode: 3141/30000 (10.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1998s / 31.8757 s
agent0:                 episode reward: -0.2606,                 loss: nan
agent1:                 episode reward: 0.2606,                 loss: nan
Episode: 3161/30000 (10.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1987s / 32.0744 s
agent0:                 episode reward: -0.3281,                 loss: nan
agent1:                 episode reward: 0.3281,                 loss: nan
Episode: 3181/30000 (10.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1992s / 32.2737 s
agent0:                 episode reward: -0.5379,                 loss: nan
agent1:                 episode reward: 0.5379,                 loss: nan
Episode: 3201/30000 (10.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1995s / 32.4732 s
agent0:                 episode reward: -0.3703,                 loss: nan
agent1:                 episode reward: 0.3703,                 loss: nan
Episode: 3221/30000 (10.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1976s / 32.6708 s
agent0:                 episode reward: -0.3797,                 loss: nan
agent1:                 episode reward: 0.3797,                 loss: nan
Episode: 3241/30000 (10.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1897s / 32.8605 s
agent0:                 episode reward: -0.3432,                 loss: nan
agent1:                 episode reward: 0.3432,                 loss: nan
Episode: 3261/30000 (10.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1932s / 33.0537 s
agent0:                 episode reward: -0.3137,                 loss: nan
agent1:                 episode reward: 0.3137,                 loss: nan
Episode: 3281/30000 (10.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1885s / 33.2423 s
agent0:                 episode reward: -0.5189,                 loss: nan
agent1:                 episode reward: 0.5189,                 loss: nan
Episode: 3301/30000 (11.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1909s / 33.4332 s
agent0:                 episode reward: -0.5464,                 loss: nan
agent1:                 episode reward: 0.5464,                 loss: nan
Episode: 3321/30000 (11.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1954s / 33.6286 s
agent0:                 episode reward: -0.3690,                 loss: nan
agent1:                 episode reward: 0.3690,                 loss: nan
Episode: 3341/30000 (11.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3538s / 33.9824 s
agent0:                 episode reward: -0.6387,                 loss: nan
agent1:                 episode reward: 0.6387,                 loss: 0.4336
Episode: 3361/30000 (11.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5947s / 34.5770 s
agent0:                 episode reward: -0.4835,                 loss: nan
agent1:                 episode reward: 0.4835,                 loss: 0.4209
Episode: 3381/30000 (11.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5858s / 35.1629 s
agent0:                 episode reward: -0.5252,                 loss: nan
agent1:                 episode reward: 0.5252,                 loss: 0.4079
Episode: 3401/30000 (11.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5805s / 35.7434 s
agent0:                 episode reward: -0.7399,                 loss: nan
agent1:                 episode reward: 0.7399,                 loss: 0.3920
Episode: 3421/30000 (11.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5958s / 36.3391 s
agent0:                 episode reward: -0.8394,                 loss: nan
agent1:                 episode reward: 0.8394,                 loss: 0.3751
Episode: 3441/30000 (11.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5875s / 36.9267 s
agent0:                 episode reward: -0.2836,                 loss: nan
agent1:                 episode reward: 0.2836,                 loss: 0.3632
Episode: 3461/30000 (11.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5831s / 37.5098 s
agent0:                 episode reward: -0.4370,                 loss: nan
agent1:                 episode reward: 0.4370,                 loss: 0.3543
Episode: 3481/30000 (11.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5812s / 38.0910 s
agent0:                 episode reward: -0.5432,                 loss: nan
agent1:                 episode reward: 0.5432,                 loss: 0.3541
Episode: 3501/30000 (11.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5989s / 38.6898 s
agent0:                 episode reward: -0.6421,                 loss: nan
agent1:                 episode reward: 0.6421,                 loss: 0.3487
Episode: 3521/30000 (11.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5853s / 39.2752 s
agent0:                 episode reward: -0.5859,                 loss: nan
agent1:                 episode reward: 0.5859,                 loss: 0.3490
Episode: 3541/30000 (11.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5923s / 39.8674 s
agent0:                 episode reward: -0.5752,                 loss: nan
agent1:                 episode reward: 0.5752,                 loss: 0.3501
Episode: 3561/30000 (11.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5878s / 40.4553 s
agent0:                 episode reward: -0.5541,                 loss: nan
agent1:                 episode reward: 0.5541,                 loss: 0.3493
Episode: 3581/30000 (11.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5922s / 41.0474 s
agent0:                 episode reward: -0.5482,                 loss: nan
agent1:                 episode reward: 0.5482,                 loss: 0.3459
Episode: 3601/30000 (12.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5839s / 41.6313 s
agent0:                 episode reward: -0.3504,                 loss: nan
agent1:                 episode reward: 0.3504,                 loss: 0.3465
Episode: 3621/30000 (12.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5894s / 42.2207 s
agent0:                 episode reward: -0.5811,                 loss: nan
agent1:                 episode reward: 0.5811,                 loss: 0.3438
Episode: 3641/30000 (12.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5861s / 42.8068 s
agent0:                 episode reward: -0.6702,                 loss: nan
agent1:                 episode reward: 0.6702,                 loss: 0.3450
Episode: 3661/30000 (12.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5930s / 43.3998 s
agent0:                 episode reward: -0.8482,                 loss: nan
agent1:                 episode reward: 0.8482,                 loss: 0.3444
Episode: 3681/30000 (12.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5858s / 43.9856 s
agent0:                 episode reward: -0.6610,                 loss: nan
agent1:                 episode reward: 0.6610,                 loss: 0.3914
Episode: 3701/30000 (12.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5894s / 44.5750 s
agent0:                 episode reward: -0.4154,                 loss: nan
agent1:                 episode reward: 0.4154,                 loss: 0.3728
Episode: 3721/30000 (12.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5879s / 45.1629 s
agent0:                 episode reward: -0.8241,                 loss: nan
agent1:                 episode reward: 0.8241,                 loss: 0.3665
Episode: 3741/30000 (12.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5871s / 45.7500 s
agent0:                 episode reward: -0.6865,                 loss: nan
agent1:                 episode reward: 0.6865,                 loss: 0.3600
Episode: 3761/30000 (12.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5899s / 46.3398 s
agent0:                 episode reward: -0.6291,                 loss: nan
agent1:                 episode reward: 0.6291,                 loss: 0.3575
Episode: 3781/30000 (12.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5933s / 46.9331 s
agent0:                 episode reward: -0.6788,                 loss: nan
agent1:                 episode reward: 0.6788,                 loss: 0.3553
Episode: 3801/30000 (12.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5860s / 47.5191 s
agent0:                 episode reward: -0.7329,                 loss: nan
agent1:                 episode reward: 0.7329,                 loss: 0.3505
Episode: 3821/30000 (12.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5851s / 48.1042 s
agent0:                 episode reward: -1.1264,                 loss: nan
agent1:                 episode reward: 1.1264,                 loss: 0.3519
Episode: 3841/30000 (12.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5877s / 48.6919 s
agent0:                 episode reward: -0.6575,                 loss: nan
agent1:                 episode reward: 0.6575,                 loss: 0.3513
Episode: 3861/30000 (12.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5912s / 49.2831 s
agent0:                 episode reward: -0.6458,                 loss: nan
agent1:                 episode reward: 0.6458,                 loss: 0.3498
Episode: 3881/30000 (12.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5975s / 49.8806 s
agent0:                 episode reward: -0.6066,                 loss: nan
agent1:                 episode reward: 0.6066,                 loss: 0.3480
Episode: 3901/30000 (13.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5921s / 50.4727 s
agent0:                 episode reward: -0.6778,                 loss: nan
agent1:                 episode reward: 0.6778,                 loss: 0.3500
Episode: 3921/30000 (13.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5890s / 51.0617 s
agent0:                 episode reward: -1.1051,                 loss: nan
agent1:                 episode reward: 1.1051,                 loss: 0.3486
Episode: 3941/30000 (13.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5887s / 51.6505 s
agent0:                 episode reward: -1.0865,                 loss: nan
agent1:                 episode reward: 1.0865,                 loss: 0.3458
Episode: 3961/30000 (13.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5873s / 52.2377 s
agent0:                 episode reward: -1.1326,                 loss: nan
agent1:                 episode reward: 1.1326,                 loss: 0.3477
Episode: 3981/30000 (13.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5832s / 52.8209 s
agent0:                 episode reward: -0.6265,                 loss: nan
agent1:                 episode reward: 0.6265,                 loss: 0.3454
Episode: 4001/30000 (13.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5917s / 53.4126 s
agent0:                 episode reward: -0.7289,                 loss: nan
agent1:                 episode reward: 0.7289,                 loss: 0.3504
Episode: 4021/30000 (13.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5849s / 53.9975 s
agent0:                 episode reward: -0.4609,                 loss: nan
agent1:                 episode reward: 0.4609,                 loss: 0.3990
Episode: 4041/30000 (13.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5823s / 54.5798 s
agent0:                 episode reward: -0.9816,                 loss: nan
agent1:                 episode reward: 0.9816,                 loss: 0.3864
Episode: 4061/30000 (13.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5883s / 55.1681 s
agent0:                 episode reward: -0.4883,                 loss: nan
agent1:                 episode reward: 0.4883,                 loss: 0.3880
Episode: 4081/30000 (13.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5852s / 55.7534 s
agent0:                 episode reward: -0.5185,                 loss: nan
agent1:                 episode reward: 0.5185,                 loss: 0.3863
Episode: 4101/30000 (13.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5862s / 56.3395 s
agent0:                 episode reward: -0.9095,                 loss: nan
agent1:                 episode reward: 0.9095,                 loss: 0.3841
Episode: 4121/30000 (13.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5819s / 56.9214 s
agent0:                 episode reward: -0.4982,                 loss: nan
agent1:                 episode reward: 0.4982,                 loss: 0.3864
Episode: 4141/30000 (13.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5863s / 57.5077 s
agent0:                 episode reward: -0.6484,                 loss: nan
agent1:                 episode reward: 0.6484,                 loss: 0.3840
Episode: 4161/30000 (13.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5927s / 58.1004 s
agent0:                 episode reward: -0.9325,                 loss: nan
agent1:                 episode reward: 0.9325,                 loss: 0.3838
Episode: 4181/30000 (13.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5872s / 58.6875 s
agent0:                 episode reward: -0.9208,                 loss: nan
agent1:                 episode reward: 0.9208,                 loss: 0.3845
Episode: 4201/30000 (14.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5896s / 59.2771 s
agent0:                 episode reward: -0.7308,                 loss: nan
agent1:                 episode reward: 0.7308,                 loss: 0.3845
Episode: 4221/30000 (14.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5813s / 59.8584 s
agent0:                 episode reward: -0.4689,                 loss: nan
agent1:                 episode reward: 0.4689,                 loss: 0.3851
Episode: 4241/30000 (14.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5946s / 60.4530 s
agent0:                 episode reward: -0.8768,                 loss: nan
agent1:                 episode reward: 0.8768,                 loss: 0.3840
Episode: 4261/30000 (14.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6020s / 61.0550 s
agent0:                 episode reward: -0.3135,                 loss: nan
agent1:                 episode reward: 0.3135,                 loss: 0.3860
Episode: 4281/30000 (14.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5914s / 61.6465 s
agent0:                 episode reward: -0.7212,                 loss: nan
agent1:                 episode reward: 0.7212,                 loss: 0.3854
Episode: 4301/30000 (14.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5885s / 62.2350 s
agent0:                 episode reward: -0.4172,                 loss: nan
agent1:                 episode reward: 0.4172,                 loss: 0.3870
Episode: 4321/30000 (14.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5921s / 62.8271 s
agent0:                 episode reward: -0.5839,                 loss: nan
agent1:                 episode reward: 0.5839,                 loss: 0.3838
Episode: 4341/30000 (14.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5886s / 63.4157 s
agent0:                 episode reward: -0.6558,                 loss: nan
agent1:                 episode reward: 0.6558,                 loss: 0.3850
Episode: 4361/30000 (14.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5878s / 64.0034 s
agent0:                 episode reward: -0.7777,                 loss: nan
agent1:                 episode reward: 0.7777,                 loss: 0.3786
Episode: 4381/30000 (14.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5844s / 64.5878 s
agent0:                 episode reward: -0.5792,                 loss: nan
agent1:                 episode reward: 0.5792,                 loss: 0.3742
Episode: 4401/30000 (14.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5812s / 65.1690 s
agent0:                 episode reward: -0.5595,                 loss: nan
agent1:                 episode reward: 0.5595,                 loss: 0.3725
Episode: 4421/30000 (14.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5886s / 65.7576 s
agent0:                 episode reward: -0.5607,                 loss: nan
agent1:                 episode reward: 0.5607,                 loss: 0.3736
Episode: 4441/30000 (14.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5903s / 66.3480 s
agent0:                 episode reward: -0.9140,                 loss: nan
agent1:                 episode reward: 0.9140,                 loss: 0.3717
Episode: 4461/30000 (14.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5960s / 66.9440 s
agent0:                 episode reward: -0.4082,                 loss: nan
agent1:                 episode reward: 0.4082,                 loss: 0.3737
Episode: 4481/30000 (14.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5935s / 67.5375 s
agent0:                 episode reward: -0.4841,                 loss: nan
agent1:                 episode reward: 0.4841,                 loss: 0.3755
Episode: 4501/30000 (15.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5968s / 68.1343 s
agent0:                 episode reward: -0.5716,                 loss: nan
agent1:                 episode reward: 0.5716,                 loss: 0.3738
Episode: 4521/30000 (15.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5901s / 68.7244 s
agent0:                 episode reward: -0.7231,                 loss: nan
agent1:                 episode reward: 0.7231,                 loss: 0.3740
Episode: 4541/30000 (15.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5864s / 69.3108 s
agent0:                 episode reward: -0.8287,                 loss: nan
agent1:                 episode reward: 0.8287,                 loss: 0.3731
Episode: 4561/30000 (15.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5876s / 69.8984 s
agent0:                 episode reward: -0.8329,                 loss: nan
agent1:                 episode reward: 0.8329,                 loss: 0.3724
Episode: 4581/30000 (15.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5901s / 70.4885 s
agent0:                 episode reward: -0.6712,                 loss: nan
agent1:                 episode reward: 0.6712,                 loss: 0.3706
Episode: 4601/30000 (15.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5906s / 71.0791 s
agent0:                 episode reward: -0.7612,                 loss: nan
agent1:                 episode reward: 0.7612,                 loss: 0.3706
Episode: 4621/30000 (15.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5908s / 71.6698 s
agent0:                 episode reward: -0.4351,                 loss: nan
agent1:                 episode reward: 0.4351,                 loss: 0.3697
Episode: 4641/30000 (15.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5881s / 72.2580 s
agent0:                 episode reward: -0.9059,                 loss: nan
agent1:                 episode reward: 0.9059,                 loss: 0.3713
Episode: 4661/30000 (15.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5858s / 72.8438 s
agent0:                 episode reward: -0.7695,                 loss: nan
agent1:                 episode reward: 0.7695,                 loss: 0.3693
Episode: 4681/30000 (15.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5864s / 73.4302 s
agent0:                 episode reward: -1.0935,                 loss: nan
agent1:                 episode reward: 1.0935,                 loss: 0.3793
Episode: 4701/30000 (15.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5918s / 74.0220 s
agent0:                 episode reward: -1.1785,                 loss: nan
agent1:                 episode reward: 1.1785,                 loss: 0.3680
Episode: 4721/30000 (15.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5907s / 74.6127 s
agent0:                 episode reward: -0.8552,                 loss: nan
agent1:                 episode reward: 0.8552,                 loss: 0.3671
Episode: 4741/30000 (15.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5907s / 75.2035 s
agent0:                 episode reward: -1.2146,                 loss: nan
agent1:                 episode reward: 1.2146,                 loss: 0.3651
Episode: 4761/30000 (15.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5854s / 75.7888 s
agent0:                 episode reward: -0.5831,                 loss: nan
agent1:                 episode reward: 0.5831,                 loss: 0.3637
Episode: 4781/30000 (15.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5864s / 76.3752 s
agent0:                 episode reward: -0.3548,                 loss: nan
agent1:                 episode reward: 0.3548,                 loss: 0.3636
Episode: 4801/30000 (16.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5899s / 76.9651 s
agent0:                 episode reward: -0.7328,                 loss: nan
agent1:                 episode reward: 0.7328,                 loss: 0.3641
Episode: 4821/30000 (16.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5776s / 77.5427 s
agent0:                 episode reward: -0.3700,                 loss: nan
agent1:                 episode reward: 0.3700,                 loss: 0.3618
Episode: 4841/30000 (16.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5869s / 78.1296 s
agent0:                 episode reward: -0.6437,                 loss: nan
agent1:                 episode reward: 0.6437,                 loss: 0.3621
Episode: 4861/30000 (16.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5784s / 78.7080 s
agent0:                 episode reward: -0.7833,                 loss: nan
agent1:                 episode reward: 0.7833,                 loss: 0.3643
Episode: 4881/30000 (16.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5883s / 79.2963 s
agent0:                 episode reward: -0.3640,                 loss: nan
agent1:                 episode reward: 0.3640,                 loss: 0.3636
Episode: 4901/30000 (16.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5906s / 79.8870 s
agent0:                 episode reward: -0.5389,                 loss: nan
agent1:                 episode reward: 0.5389,                 loss: 0.3620
Episode: 4921/30000 (16.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5897s / 80.4766 s
agent0:                 episode reward: -0.7357,                 loss: nan
agent1:                 episode reward: 0.7357,                 loss: 0.3642
Episode: 4941/30000 (16.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5846s / 81.0612 s
agent0:                 episode reward: -0.6586,                 loss: nan
agent1:                 episode reward: 0.6586,                 loss: 0.3635
Episode: 4961/30000 (16.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5951s / 81.6563 s
agent0:                 episode reward: -0.3568,                 loss: nan
agent1:                 episode reward: 0.3568,                 loss: 0.3627
Episode: 4981/30000 (16.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5925s / 82.2488 s
agent0:                 episode reward: -0.8055,                 loss: nan
agent1:                 episode reward: 0.8055,                 loss: 0.3650
Episode: 5001/30000 (16.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5877s / 82.8365 s
agent0:                 episode reward: -1.0617,                 loss: nan
agent1:                 episode reward: 1.0617,                 loss: 0.3685
Episode: 5021/30000 (16.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5879s / 83.4244 s
agent0:                 episode reward: -0.6144,                 loss: nan
agent1:                 episode reward: 0.6144,                 loss: 0.3874
Episode: 5041/30000 (16.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5898s / 84.0142 s
agent0:                 episode reward: -0.4395,                 loss: nan
agent1:                 episode reward: 0.4395,                 loss: 0.3740
Episode: 5061/30000 (16.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5859s / 84.6001 s
agent0:                 episode reward: -0.5341,                 loss: nan
agent1:                 episode reward: 0.5341,                 loss: 0.3737
Episode: 5081/30000 (16.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5920s / 85.1921 s
agent0:                 episode reward: -0.5080,                 loss: nan
agent1:                 episode reward: 0.5080,                 loss: 0.3766
Episode: 5101/30000 (17.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5848s / 85.7769 s
agent0:                 episode reward: -0.5058,                 loss: nan
agent1:                 episode reward: 0.5058,                 loss: 0.3714
Episode: 5121/30000 (17.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5936s / 86.3705 s
agent0:                 episode reward: -0.7643,                 loss: nan
agent1:                 episode reward: 0.7643,                 loss: 0.3726
Episode: 5141/30000 (17.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6028s / 86.9733 s
agent0:                 episode reward: -0.8158,                 loss: nan
agent1:                 episode reward: 0.8158,                 loss: 0.3740
Episode: 5161/30000 (17.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5940s / 87.5673 s
agent0:                 episode reward: -0.7263,                 loss: nan
agent1:                 episode reward: 0.7263,                 loss: 0.3713
Episode: 5181/30000 (17.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5907s / 88.1580 s
agent0:                 episode reward: -0.7233,                 loss: nan
agent1:                 episode reward: 0.7233,                 loss: 0.3716
Episode: 5201/30000 (17.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5880s / 88.7460 s
agent0:                 episode reward: -0.5853,                 loss: nan
agent1:                 episode reward: 0.5853,                 loss: 0.3728
Episode: 5221/30000 (17.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5934s / 89.3394 s
agent0:                 episode reward: -0.8162,                 loss: nan
agent1:                 episode reward: 0.8162,                 loss: 0.3729
Episode: 5241/30000 (17.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5889s / 89.9283 s
agent0:                 episode reward: -0.6560,                 loss: nan
agent1:                 episode reward: 0.6560,                 loss: 0.3746
Episode: 5261/30000 (17.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5892s / 90.5176 s
agent0:                 episode reward: -0.8267,                 loss: nan
agent1:                 episode reward: 0.8267,                 loss: 0.3745
Episode: 5281/30000 (17.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5842s / 91.1018 s
agent0:                 episode reward: -0.6885,                 loss: nan
agent1:                 episode reward: 0.6885,                 loss: 0.3716
Episode: 5301/30000 (17.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5858s / 91.6876 s
agent0:                 episode reward: -0.6454,                 loss: nan
agent1:                 episode reward: 0.6454,                 loss: 0.3726
Episode: 5321/30000 (17.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5961s / 92.2837 s
agent0:                 episode reward: -0.8681,                 loss: nan
agent1:                 episode reward: 0.8681,                 loss: 0.3730
Episode: 5341/30000 (17.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5915s / 92.8752 s
agent0:                 episode reward: -0.6444,                 loss: nan
agent1:                 episode reward: 0.6444,                 loss: 0.3792
Episode: 5361/30000 (17.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5914s / 93.4666 s
agent0:                 episode reward: -0.6445,                 loss: nan
agent1:                 episode reward: 0.6445,                 loss: 0.3661
Episode: 5381/30000 (17.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5869s / 94.0535 s
agent0:                 episode reward: -0.3785,                 loss: nan
agent1:                 episode reward: 0.3785,                 loss: 0.3637
Episode: 5401/30000 (18.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5817s / 94.6352 s
agent0:                 episode reward: -0.8360,                 loss: nan
agent1:                 episode reward: 0.8360,                 loss: 0.3618
Episode: 5421/30000 (18.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5920s / 95.2272 s
agent0:                 episode reward: -0.8284,                 loss: nan
agent1:                 episode reward: 0.8284,                 loss: 0.3658
Episode: 5441/30000 (18.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5916s / 95.8188 s
agent0:                 episode reward: -0.5790,                 loss: nan
agent1:                 episode reward: 0.5790,                 loss: 0.3653
Episode: 5461/30000 (18.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5927s / 96.4115 s
agent0:                 episode reward: -0.6230,                 loss: nan
agent1:                 episode reward: 0.6230,                 loss: 0.3616
Episode: 5481/30000 (18.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5848s / 96.9962 s
agent0:                 episode reward: -0.4209,                 loss: nan
agent1:                 episode reward: 0.4209,                 loss: 0.3638
Episode: 5501/30000 (18.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5844s / 97.5806 s
agent0:                 episode reward: -0.4085,                 loss: nan
agent1:                 episode reward: 0.4085,                 loss: 0.3614
Episode: 5521/30000 (18.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5891s / 98.1697 s
agent0:                 episode reward: -0.4226,                 loss: nan
agent1:                 episode reward: 0.4226,                 loss: 0.3625
Episode: 5541/30000 (18.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5895s / 98.7592 s
agent0:                 episode reward: -0.6318,                 loss: nan
agent1:                 episode reward: 0.6318,                 loss: 0.3635
Episode: 5561/30000 (18.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5910s / 99.3502 s
agent0:                 episode reward: -0.4597,                 loss: nan
agent1:                 episode reward: 0.4597,                 loss: 0.3648
Episode: 5581/30000 (18.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5961s / 99.9463 s
agent0:                 episode reward: -0.1359,                 loss: nan
agent1:                 episode reward: 0.1359,                 loss: 0.3604
Episode: 5601/30000 (18.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6031s / 100.5494 s
agent0:                 episode reward: -0.8168,                 loss: nan
agent1:                 episode reward: 0.8168,                 loss: 0.3623
Episode: 5621/30000 (18.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5925s / 101.1419 s
agent0:                 episode reward: -0.8394,                 loss: nan
agent1:                 episode reward: 0.8394,                 loss: 0.3617
Episode: 5641/30000 (18.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5870s / 101.7289 s
agent0:                 episode reward: -0.6782,                 loss: nan
agent1:                 episode reward: 0.6782,                 loss: 0.3623
Episode: 5661/30000 (18.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5945s / 102.3234 s
agent0:                 episode reward: -0.6869,                 loss: nan
agent1:                 episode reward: 0.6869,                 loss: 0.3623
Episode: 5681/30000 (18.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5832s / 102.9066 s
agent0:                 episode reward: -0.5987,                 loss: nan
agent1:                 episode reward: 0.5987,                 loss: 0.3694
Episode: 5701/30000 (19.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6002s / 103.5068 s
agent0:                 episode reward: -0.8926,                 loss: nan
agent1:                 episode reward: 0.8926,                 loss: 0.3648
Episode: 5721/30000 (19.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5921s / 104.0988 s
agent0:                 episode reward: -0.8316,                 loss: nan
agent1:                 episode reward: 0.8316,                 loss: 0.3630
Episode: 5741/30000 (19.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5942s / 104.6931 s
agent0:                 episode reward: -0.6071,                 loss: nan
agent1:                 episode reward: 0.6071,                 loss: 0.3649
Episode: 5761/30000 (19.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5976s / 105.2906 s
agent0:                 episode reward: -0.9936,                 loss: nan
agent1:                 episode reward: 0.9936,                 loss: 0.3689
Episode: 5781/30000 (19.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5914s / 105.8821 s
agent0:                 episode reward: -0.1568,                 loss: nan
agent1:                 episode reward: 0.1568,                 loss: 0.3649
Episode: 5801/30000 (19.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6054s / 106.4874 s
agent0:                 episode reward: -0.5638,                 loss: nan
agent1:                 episode reward: 0.5638,                 loss: 0.3687
Episode: 5821/30000 (19.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5958s / 107.0833 s
agent0:                 episode reward: -0.8699,                 loss: nan
agent1:                 episode reward: 0.8699,                 loss: 0.3660
Episode: 5841/30000 (19.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5880s / 107.6712 s
agent0:                 episode reward: -0.7699,                 loss: nan
agent1:                 episode reward: 0.7699,                 loss: 0.3670
Episode: 5861/30000 (19.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6055s / 108.2767 s
agent0:                 episode reward: -0.5179,                 loss: nan
agent1:                 episode reward: 0.5179,                 loss: 0.3658
Episode: 5881/30000 (19.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5883s / 108.8651 s
agent0:                 episode reward: -0.5444,                 loss: nan
agent1:                 episode reward: 0.5444,                 loss: 0.3672
Episode: 5901/30000 (19.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5985s / 109.4636 s
agent0:                 episode reward: -0.7486,                 loss: nan
agent1:                 episode reward: 0.7486,                 loss: 0.3658
Episode: 5921/30000 (19.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6038s / 110.0674 s
agent0:                 episode reward: -0.9949,                 loss: nan
agent1:                 episode reward: 0.9949,                 loss: 0.3629
Episode: 5941/30000 (19.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5875s / 110.6549 s
agent0:                 episode reward: -0.6037,                 loss: nan
agent1:                 episode reward: 0.6037,                 loss: 0.3675
Episode: 5961/30000 (19.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5936s / 111.2485 s
agent0:                 episode reward: -0.3910,                 loss: nan
agent1:                 episode reward: 0.3910,                 loss: 0.3685
Episode: 5981/30000 (19.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5889s / 111.8374 s
agent0:                 episode reward: -1.0440,                 loss: nan
agent1:                 episode reward: 1.0440,                 loss: 0.3656
Episode: 6001/30000 (20.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6028s / 112.4403 s
agent0:                 episode reward: -0.1515,                 loss: nan
agent1:                 episode reward: 0.1515,                 loss: 0.3695
Episode: 6021/30000 (20.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5925s / 113.0328 s
agent0:                 episode reward: -0.9496,                 loss: nan
agent1:                 episode reward: 0.9496,                 loss: 0.3766
Episode: 6041/30000 (20.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5975s / 113.6303 s
agent0:                 episode reward: -0.6256,                 loss: nan
agent1:                 episode reward: 0.6256,                 loss: 0.3703
Episode: 6061/30000 (20.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5919s / 114.2222 s
agent0:                 episode reward: -0.8284,                 loss: nan
agent1:                 episode reward: 0.8284,                 loss: 0.3713
Episode: 6081/30000 (20.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6034s / 114.8256 s
agent0:                 episode reward: -0.7882,                 loss: nan
agent1:                 episode reward: 0.7882,                 loss: 0.3717
Episode: 6101/30000 (20.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5975s / 115.4231 s
agent0:                 episode reward: -0.6727,                 loss: nan
agent1:                 episode reward: 0.6727,                 loss: 0.3717
Episode: 6121/30000 (20.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5914s / 116.0145 s
agent0:                 episode reward: -0.8796,                 loss: nan
agent1:                 episode reward: 0.8796,                 loss: 0.3661
Episode: 6141/30000 (20.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6017s / 116.6162 s
agent0:                 episode reward: -0.5952,                 loss: nan
agent1:                 episode reward: 0.5952,                 loss: 0.3724
Episode: 6161/30000 (20.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5967s / 117.2128 s
agent0:                 episode reward: -0.3617,                 loss: nan
agent1:                 episode reward: 0.3617,                 loss: 0.3693
Episode: 6181/30000 (20.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5996s / 117.8124 s
agent0:                 episode reward: -0.5671,                 loss: nan
agent1:                 episode reward: 0.5671,                 loss: 0.3718
Episode: 6201/30000 (20.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5944s / 118.4069 s
agent0:                 episode reward: -0.6707,                 loss: nan
agent1:                 episode reward: 0.6707,                 loss: 0.3709
Episode: 6221/30000 (20.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5910s / 118.9978 s
agent0:                 episode reward: -0.5355,                 loss: nan
agent1:                 episode reward: 0.5355,                 loss: 0.3663
Episode: 6241/30000 (20.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6002s / 119.5980 s
agent0:                 episode reward: -0.7508,                 loss: nan
agent1:                 episode reward: 0.7508,                 loss: 0.3722
Episode: 6261/30000 (20.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5931s / 120.1911 s
agent0:                 episode reward: -1.0018,                 loss: nan
agent1:                 episode reward: 1.0018,                 loss: 0.3683
Episode: 6281/30000 (20.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5935s / 120.7846 s
agent0:                 episode reward: -0.5965,                 loss: nan
agent1:                 episode reward: 0.5965,                 loss: 0.3702
Episode: 6301/30000 (21.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5902s / 121.3748 s
agent0:                 episode reward: -0.5570,                 loss: nan
agent1:                 episode reward: 0.5570,                 loss: 0.3687
Episode: 6321/30000 (21.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6057s / 121.9805 s
agent0:                 episode reward: -0.5796,                 loss: nan
agent1:                 episode reward: 0.5796,                 loss: 0.3681
Episode: 6341/30000 (21.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6107s / 122.5912 s
agent0:                 episode reward: -0.7961,                 loss: nan
agent1:                 episode reward: 0.7961,                 loss: 0.3741
Episode: 6361/30000 (21.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6012s / 123.1924 s
agent0:                 episode reward: -0.7609,                 loss: nan
agent1:                 episode reward: 0.7609,                 loss: 0.3618
Episode: 6381/30000 (21.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6066s / 123.7990 s
agent0:                 episode reward: -1.0793,                 loss: nan
agent1:                 episode reward: 1.0793,                 loss: 0.3585
Episode: 6401/30000 (21.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6050s / 124.4040 s
agent0:                 episode reward: -0.4496,                 loss: nan
agent1:                 episode reward: 0.4496,                 loss: 0.3609
Episode: 6421/30000 (21.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6019s / 125.0059 s
agent0:                 episode reward: -0.8973,                 loss: nan
agent1:                 episode reward: 0.8973,                 loss: 0.3614
Episode: 6441/30000 (21.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5975s / 125.6034 s
agent0:                 episode reward: -0.6937,                 loss: nan
agent1:                 episode reward: 0.6937,                 loss: 0.3592
Episode: 6461/30000 (21.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6074s / 126.2108 s
agent0:                 episode reward: -0.7028,                 loss: nan
agent1:                 episode reward: 0.7028,                 loss: 0.3598
Episode: 6481/30000 (21.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6036s / 126.8144 s
agent0:                 episode reward: -0.4997,                 loss: nan
agent1:                 episode reward: 0.4997,                 loss: 0.3563
Episode: 6501/30000 (21.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5997s / 127.4141 s
agent0:                 episode reward: -0.7624,                 loss: nan
agent1:                 episode reward: 0.7624,                 loss: 0.3586
Episode: 6521/30000 (21.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6086s / 128.0227 s
agent0:                 episode reward: -0.2566,                 loss: nan
agent1:                 episode reward: 0.2566,                 loss: 0.3608
Episode: 6541/30000 (21.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5955s / 128.6182 s
agent0:                 episode reward: -0.4822,                 loss: nan
agent1:                 episode reward: 0.4822,                 loss: 0.3616
Episode: 6561/30000 (21.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6050s / 129.2231 s
agent0:                 episode reward: -0.6892,                 loss: nan
agent1:                 episode reward: 0.6892,                 loss: 0.3584
Episode: 6581/30000 (21.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6193s / 129.8424 s
agent0:                 episode reward: -0.8209,                 loss: nan
agent1:                 episode reward: 0.8209,                 loss: 0.3569
Episode: 6601/30000 (22.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6136s / 130.4560 s
agent0:                 episode reward: -0.3622,                 loss: nan
agent1:                 episode reward: 0.3622,                 loss: 0.3575
Episode: 6621/30000 (22.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6130s / 131.0690 s
agent0:                 episode reward: -0.6717,                 loss: nan
agent1:                 episode reward: 0.6717,                 loss: 0.3611
Episode: 6641/30000 (22.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6096s / 131.6786 s
agent0:                 episode reward: -0.9200,                 loss: nan
agent1:                 episode reward: 0.9200,                 loss: 0.3597
Episode: 6661/30000 (22.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6137s / 132.2922 s
agent0:                 episode reward: -0.8321,                 loss: nan
agent1:                 episode reward: 0.8321,                 loss: 0.3578
Episode: 6681/30000 (22.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6130s / 132.9052 s
agent0:                 episode reward: -0.4168,                 loss: nan
agent1:                 episode reward: 0.4168,                 loss: 0.3786
Episode: 6701/30000 (22.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6105s / 133.5157 s
agent0:                 episode reward: -0.7895,                 loss: nan
agent1:                 episode reward: 0.7895,                 loss: 0.3810
Episode: 6721/30000 (22.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6067s / 134.1224 s
agent0:                 episode reward: -0.4237,                 loss: nan
agent1:                 episode reward: 0.4237,                 loss: 0.3800
Episode: 6741/30000 (22.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6114s / 134.7338 s
agent0:                 episode reward: -0.6733,                 loss: nan
agent1:                 episode reward: 0.6733,                 loss: 0.3798
Episode: 6761/30000 (22.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6136s / 135.3474 s
agent0:                 episode reward: -0.4483,                 loss: nan
agent1:                 episode reward: 0.4483,                 loss: 0.3787
Episode: 6781/30000 (22.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6131s / 135.9605 s
agent0:                 episode reward: -0.6047,                 loss: nan
agent1:                 episode reward: 0.6047,                 loss: 0.3793
Episode: 6801/30000 (22.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6157s / 136.5762 s
agent0:                 episode reward: -0.9007,                 loss: nan
agent1:                 episode reward: 0.9007,                 loss: 0.3789
Episode: 6821/30000 (22.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6129s / 137.1891 s
agent0:                 episode reward: -0.7540,                 loss: nan
agent1:                 episode reward: 0.7540,                 loss: 0.3812
Episode: 6841/30000 (22.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6168s / 137.8059 s
agent0:                 episode reward: -0.9042,                 loss: nan
agent1:                 episode reward: 0.9042,                 loss: 0.3810
Episode: 6861/30000 (22.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6152s / 138.4211 s
agent0:                 episode reward: -0.7887,                 loss: nan
agent1:                 episode reward: 0.7887,                 loss: 0.3758
Episode: 6881/30000 (22.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6121s / 139.0332 s
agent0:                 episode reward: -0.7901,                 loss: nan
agent1:                 episode reward: 0.7901,                 loss: 0.3791
Episode: 6901/30000 (23.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6177s / 139.6509 s
agent0:                 episode reward: -0.5813,                 loss: nan
agent1:                 episode reward: 0.5813,                 loss: 0.3787
Episode: 6921/30000 (23.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6096s / 140.2605 s
agent0:                 episode reward: -1.0016,                 loss: nan
agent1:                 episode reward: 1.0016,                 loss: 0.3767
Episode: 6941/30000 (23.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6164s / 140.8769 s
agent0:                 episode reward: -0.5038,                 loss: nan
agent1:                 episode reward: 0.5038,                 loss: 0.3794
Episode: 6961/30000 (23.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6057s / 141.4826 s
agent0:                 episode reward: -1.0057,                 loss: nan
agent1:                 episode reward: 1.0057,                 loss: 0.3789
Episode: 6981/30000 (23.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6156s / 142.0982 s
agent0:                 episode reward: -0.5049,                 loss: nan
agent1:                 episode reward: 0.5049,                 loss: 0.3817
Episode: 7001/30000 (23.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6128s / 142.7110 s
agent0:                 episode reward: -0.6892,                 loss: nan
agent1:                 episode reward: 0.6892,                 loss: 0.3830
Episode: 7021/30000 (23.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6019s / 143.3130 s
agent0:                 episode reward: -0.6736,                 loss: nan
agent1:                 episode reward: 0.6736,                 loss: 0.3605
Episode: 7041/30000 (23.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5977s / 143.9107 s
agent0:                 episode reward: -0.9508,                 loss: nan
agent1:                 episode reward: 0.9508,                 loss: 0.3504
Episode: 7061/30000 (23.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5953s / 144.5061 s
agent0:                 episode reward: -0.5632,                 loss: nan
agent1:                 episode reward: 0.5632,                 loss: 0.3553
Episode: 7081/30000 (23.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6025s / 145.1086 s
agent0:                 episode reward: -0.6518,                 loss: nan
agent1:                 episode reward: 0.6518,                 loss: 0.3520
Episode: 7101/30000 (23.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6011s / 145.7097 s
agent0:                 episode reward: -0.3331,                 loss: nan
agent1:                 episode reward: 0.3331,                 loss: 0.3533
Episode: 7121/30000 (23.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6086s / 146.3182 s
agent0:                 episode reward: -0.8822,                 loss: nan
agent1:                 episode reward: 0.8822,                 loss: 0.3502
Episode: 7141/30000 (23.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6025s / 146.9208 s
agent0:                 episode reward: -1.0147,                 loss: nan
agent1:                 episode reward: 1.0147,                 loss: 0.3529
Episode: 7161/30000 (23.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6083s / 147.5291 s
agent0:                 episode reward: -0.8961,                 loss: nan
agent1:                 episode reward: 0.8961,                 loss: 0.3521
Episode: 7181/30000 (23.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6034s / 148.1325 s
agent0:                 episode reward: -0.8189,                 loss: nan
agent1:                 episode reward: 0.8189,                 loss: 0.3511
Episode: 7201/30000 (24.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6086s / 148.7412 s
agent0:                 episode reward: -0.3255,                 loss: nan
agent1:                 episode reward: 0.3255,                 loss: 0.3496
Episode: 7221/30000 (24.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6088s / 149.3499 s
agent0:                 episode reward: -0.7720,                 loss: nan
agent1:                 episode reward: 0.7720,                 loss: 0.3518
Episode: 7241/30000 (24.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6096s / 149.9595 s
agent0:                 episode reward: -1.2820,                 loss: nan
agent1:                 episode reward: 1.2820,                 loss: 0.3500
Episode: 7261/30000 (24.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5952s / 150.5547 s
agent0:                 episode reward: -1.0977,                 loss: nan
agent1:                 episode reward: 1.0977,                 loss: 0.3492
Episode: 7281/30000 (24.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5971s / 151.1518 s
agent0:                 episode reward: -0.9227,                 loss: nan
agent1:                 episode reward: 0.9227,                 loss: 0.3519
Episode: 7301/30000 (24.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6042s / 151.7560 s
agent0:                 episode reward: -0.9448,                 loss: nan
agent1:                 episode reward: 0.9448,                 loss: 0.3510
Episode: 7321/30000 (24.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5949s / 152.3509 s
agent0:                 episode reward: -1.2092,                 loss: nan
agent1:                 episode reward: 1.2092,                 loss: 0.3495
Episode: 7341/30000 (24.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5998s / 152.9506 s
agent0:                 episode reward: -0.3006,                 loss: nan
agent1:                 episode reward: 0.3006,                 loss: 0.3637
Episode: 7361/30000 (24.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6112s / 153.5618 s
agent0:                 episode reward: -0.1001,                 loss: nan
agent1:                 episode reward: 0.1001,                 loss: 0.3404
Episode: 7381/30000 (24.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5999s / 154.1617 s
agent0:                 episode reward: -0.9116,                 loss: nan
agent1:                 episode reward: 0.9116,                 loss: 0.3373
Episode: 7401/30000 (24.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5986s / 154.7603 s
agent0:                 episode reward: -0.8418,                 loss: nan
agent1:                 episode reward: 0.8418,                 loss: 0.3371
Episode: 7421/30000 (24.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6166s / 155.3769 s
agent0:                 episode reward: -0.7996,                 loss: nan
agent1:                 episode reward: 0.7996,                 loss: 0.3381
Episode: 7441/30000 (24.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6058s / 155.9827 s
agent0:                 episode reward: -0.7585,                 loss: nan
agent1:                 episode reward: 0.7585,                 loss: 0.3379
Episode: 7461/30000 (24.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5981s / 156.5808 s
agent0:                 episode reward: -0.6583,                 loss: nan
agent1:                 episode reward: 0.6583,                 loss: 0.3374
Episode: 7481/30000 (24.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6093s / 157.1901 s
agent0:                 episode reward: -0.6420,                 loss: nan
agent1:                 episode reward: 0.6420,                 loss: 0.3360
Episode: 7501/30000 (25.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6131s / 157.8032 s
agent0:                 episode reward: -0.6325,                 loss: nan
agent1:                 episode reward: 0.6325,                 loss: 0.3383
Episode: 7521/30000 (25.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6090s / 158.4122 s
agent0:                 episode reward: -0.5546,                 loss: nan
agent1:                 episode reward: 0.5546,                 loss: 0.3352
Episode: 7541/30000 (25.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6035s / 159.0157 s
agent0:                 episode reward: -0.6679,                 loss: nan
agent1:                 episode reward: 0.6679,                 loss: 0.3391
Episode: 7561/30000 (25.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6011s / 159.6168 s
agent0:                 episode reward: -0.8824,                 loss: nan
agent1:                 episode reward: 0.8824,                 loss: 0.3372
Episode: 7581/30000 (25.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6091s / 160.2259 s
agent0:                 episode reward: -1.1767,                 loss: nan
agent1:                 episode reward: 1.1767,                 loss: 0.3353
Episode: 7601/30000 (25.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6008s / 160.8267 s
agent0:                 episode reward: -0.4290,                 loss: nan
agent1:                 episode reward: 0.4290,                 loss: 0.3368
Episode: 7621/30000 (25.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6132s / 161.4400 s
agent0:                 episode reward: -0.7500,                 loss: nan
agent1:                 episode reward: 0.7500,                 loss: 0.3371