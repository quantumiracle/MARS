pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
pong_v2 pettingzoo
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
random seed: [91, 69]
<SubprocVectorEnv instance>
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
No agent are not learnable.
Arguments:  {'env_name': 'pong_v2', 'env_type': 'pettingzoo', 'num_envs': 2, 'ram': True, 'seed': 'random', 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 10000, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nfsp', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'eta': 0.1}}
Save models to : /home/zihan/research/MARS/data/model/20220119_0524/pettingzoo_pong_v2_nfsp. 
 Save logs to: /home/zihan/research/MARS/data/log/20220119_0524/pettingzoo_pong_v2_nfsp.
Episode: 1/10000 (0.0100%),                 avg. length: 1111.0,                last time consumption/overall running time: 5.9331s / 5.9331 s
env0_first_0:                 episode reward: 17.0000,                 loss: nan
env0_second_0:                 episode reward: -17.0000,                 loss: nan
env1_first_0:                 episode reward: -6.0000,                 loss: nan
env1_second_0:                 episode reward: 6.0000,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 1145.25,                last time consumption/overall running time: 473.7646s / 479.6977 s
env0_first_0:                 episode reward: 8.2500,                 loss: 0.0038
env0_second_0:                 episode reward: -8.2500,                 loss: 0.0040
env1_first_0:                 episode reward: 8.8500,                 loss: nan
env1_second_0:                 episode reward: -8.8500,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 1101.5,                last time consumption/overall running time: 797.3421s / 1277.0397 s
env0_first_0:                 episode reward: -7.0000,                 loss: 0.0031
env0_second_0:                 episode reward: 7.0000,                 loss: 0.0031
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 1229.3,                last time consumption/overall running time: 908.1579s / 2185.1976 s
env0_first_0:                 episode reward: -11.5000,                 loss: 0.0089
env0_second_0:                 episode reward: 11.5000,                 loss: 0.0073
env1_first_0:                 episode reward: -15.9000,                 loss: nan
env1_second_0:                 episode reward: 15.9000,                 loss: nan
Episode: 81/10000 (0.8100%),                 avg. length: 1778.55,                last time consumption/overall running time: 1330.4168s / 3515.6144 s
env0_first_0:                 episode reward: -13.4000,                 loss: 0.0157
env0_second_0:                 episode reward: 13.4000,                 loss: 0.0109
env1_first_0:                 episode reward: -13.7500,                 loss: nan
env1_second_0:                 episode reward: 13.7500,                 loss: nan
Episode: 101/10000 (1.0100%),                 avg. length: 2461.85,                last time consumption/overall running time: 1851.8925s / 5367.5069 s
env0_first_0:                 episode reward: -12.7500,                 loss: 0.0109
env0_second_0:                 episode reward: 12.7500,                 loss: 0.0071
env1_first_0:                 episode reward: -11.6500,                 loss: nan
env1_second_0:                 episode reward: 11.6500,                 loss: nan
Episode: 121/10000 (1.2100%),                 avg. length: 2641.15,                last time consumption/overall running time: 1991.7026s / 7359.2096 s
env0_first_0:                 episode reward: -8.1000,                 loss: 0.0057
env0_second_0:                 episode reward: 8.1000,                 loss: 0.0048
env1_first_0:                 episode reward: -8.6000,                 loss: nan
env1_second_0:                 episode reward: 8.6000,                 loss: nan
Episode: 141/10000 (1.4100%),                 avg. length: 3595.5,                last time consumption/overall running time: 2707.4370s / 10066.6466 s
env0_first_0:                 episode reward: -5.2500,                 loss: 0.0060
env0_second_0:                 episode reward: 5.2500,                 loss: 0.0047
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 161/10000 (1.6100%),                 avg. length: 3329.8,                last time consumption/overall running time: 2511.3589s / 12578.0055 s
env0_first_0:                 episode reward: -6.5500,                 loss: 0.0053
env0_second_0:                 episode reward: 6.5500,                 loss: 0.0044
env1_first_0:                 episode reward: -5.7500,                 loss: nan
env1_second_0:                 episode reward: 5.7500,                 loss: nan
Episode: 181/10000 (1.8100%),                 avg. length: 3302.05,                last time consumption/overall running time: 2487.4094s / 15065.4149 s
env0_first_0:                 episode reward: -6.2500,                 loss: 0.0048
env0_second_0:                 episode reward: 6.2500,                 loss: 0.0046
env1_first_0:                 episode reward: -5.9500,                 loss: nan
env1_second_0:                 episode reward: 5.9500,                 loss: nan
Episode: 201/10000 (2.0100%),                 avg. length: 3620.35,                last time consumption/overall running time: 2726.6933s / 17792.1082 s
env0_first_0:                 episode reward: -7.3000,                 loss: 0.0046
env0_second_0:                 episode reward: 7.3000,                 loss: 0.0040
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 221/10000 (2.2100%),                 avg. length: 3677.8,                last time consumption/overall running time: 2776.6586s / 20568.7668 s
env0_first_0:                 episode reward: -6.4000,                 loss: 0.0045
env0_second_0:                 episode reward: 6.4000,                 loss: 0.0039
env1_first_0:                 episode reward: -5.9000,                 loss: nan
env1_second_0:                 episode reward: 5.9000,                 loss: nan
Episode: 241/10000 (2.4100%),                 avg. length: 3379.25,                last time consumption/overall running time: 2545.1028s / 23113.8696 s
env0_first_0:                 episode reward: -8.9000,                 loss: 0.0047
env0_second_0:                 episode reward: 8.9000,                 loss: 0.0038
env1_first_0:                 episode reward: -6.9000,                 loss: nan
env1_second_0:                 episode reward: 6.9000,                 loss: nan
Episode: 261/10000 (2.6100%),                 avg. length: 3512.45,                last time consumption/overall running time: 2646.3969s / 25760.2665 s
env0_first_0:                 episode reward: -6.8000,                 loss: 0.0038
env0_second_0:                 episode reward: 6.8000,                 loss: 0.0035
env1_first_0:                 episode reward: -7.9000,                 loss: nan
env1_second_0:                 episode reward: 7.9000,                 loss: nan
Episode: 281/10000 (2.8100%),                 avg. length: 3564.9,                last time consumption/overall running time: 2686.7344s / 28447.0009 s
env0_first_0:                 episode reward: -7.9500,                 loss: 0.0041
env0_second_0:                 episode reward: 7.9500,                 loss: 0.0032
env1_first_0:                 episode reward: -8.9500,                 loss: nan
env1_second_0:                 episode reward: 8.9500,                 loss: nan
Episode: 301/10000 (3.0100%),                 avg. length: 3609.8,                last time consumption/overall running time: 2720.9824s / 31167.9833 s
env0_first_0:                 episode reward: -8.6500,                 loss: 0.0041
env0_second_0:                 episode reward: 8.6500,                 loss: 0.0034
env1_first_0:                 episode reward: -5.3000,                 loss: nan
env1_second_0:                 episode reward: 5.3000,                 loss: nan
Episode: 321/10000 (3.2100%),                 avg. length: 3341.55,                last time consumption/overall running time: 2522.0208s / 33690.0042 s
env0_first_0:                 episode reward: -8.8000,                 loss: 0.0041
env0_second_0:                 episode reward: 8.8000,                 loss: 0.0035
env1_first_0:                 episode reward: -8.8000,                 loss: nan
env1_second_0:                 episode reward: 8.8000,                 loss: nan
Episode: 341/10000 (3.4100%),                 avg. length: 3344.1,                last time consumption/overall running time: 2519.7723s / 36209.7765 s
env0_first_0:                 episode reward: -8.6500,                 loss: 0.0044
env0_second_0:                 episode reward: 8.6500,                 loss: 0.0038
env1_first_0:                 episode reward: -9.6500,                 loss: nan
env1_second_0:                 episode reward: 9.6500,                 loss: nan
Episode: 361/10000 (3.6100%),                 avg. length: 3206.6,                last time consumption/overall running time: 2671.2304s / 38881.0069 s
env0_first_0:                 episode reward: -9.1500,                 loss: 0.0041
env0_second_0:                 episode reward: 9.1500,                 loss: 0.0034
env1_first_0:                 episode reward: -10.1000,                 loss: nan
env1_second_0:                 episode reward: 10.1000,                 loss: nan
Episode: 381/10000 (3.8100%),                 avg. length: 3620.15,                last time consumption/overall running time: 3257.8253s / 42138.8322 s
env0_first_0:                 episode reward: -6.9500,                 loss: 0.0041
env0_second_0:                 episode reward: 6.9500,                 loss: 0.0033
env1_first_0:                 episode reward: -8.2500,                 loss: nan
env1_second_0:                 episode reward: 8.2500,                 loss: nan
Episode: 401/10000 (4.0100%),                 avg. length: 3321.45,                last time consumption/overall running time: 2994.9335s / 45133.7657 s
env0_first_0:                 episode reward: -8.2000,                 loss: 0.0041
env0_second_0:                 episode reward: 8.2000,                 loss: 0.0030
env1_first_0:                 episode reward: -7.7000,                 loss: nan
env1_second_0:                 episode reward: 7.7000,                 loss: nan
Episode: 421/10000 (4.2100%),                 avg. length: 3284.9,                last time consumption/overall running time: 2953.5900s / 48087.3558 s
env0_first_0:                 episode reward: -9.6500,                 loss: 0.0042
env0_second_0:                 episode reward: 9.6500,                 loss: 0.0034
env1_first_0:                 episode reward: -10.4500,                 loss: nan
env1_second_0:                 episode reward: 10.4500,                 loss: nan
Episode: 441/10000 (4.4100%),                 avg. length: 3015.05,                last time consumption/overall running time: 2712.5651s / 50799.9208 s
env0_first_0:                 episode reward: -13.6000,                 loss: 0.0040
env0_second_0:                 episode reward: 13.6000,                 loss: 0.0033
env1_first_0:                 episode reward: -9.9500,                 loss: nan
env1_second_0:                 episode reward: 9.9500,                 loss: nan
Episode: 461/10000 (4.6100%),                 avg. length: 3287.25,                last time consumption/overall running time: 2958.4312s / 53758.3521 s
env0_first_0:                 episode reward: -9.8000,                 loss: 0.0040
env0_second_0:                 episode reward: 9.8000,                 loss: 0.0030
env1_first_0:                 episode reward: -10.0500,                 loss: nan
env1_second_0:                 episode reward: 10.0500,                 loss: nan
Episode: 481/10000 (4.8100%),                 avg. length: 3218.45,                last time consumption/overall running time: 2895.4430s / 56653.7951 s
env0_first_0:                 episode reward: -13.1000,                 loss: 0.0040
env0_second_0:                 episode reward: 13.1000,                 loss: 0.0030
env1_first_0:                 episode reward: -10.2500,                 loss: nan
env1_second_0:                 episode reward: 10.2500,                 loss: nan
Episode: 501/10000 (5.0100%),                 avg. length: 3161.7,                last time consumption/overall running time: 2841.8570s / 59495.6521 s
env0_first_0:                 episode reward: -8.8000,                 loss: 0.0038
env0_second_0:                 episode reward: 8.8000,                 loss: 0.0030
env1_first_0:                 episode reward: -9.9500,                 loss: nan
env1_second_0:                 episode reward: 9.9500,                 loss: nan
Episode: 521/10000 (5.2100%),                 avg. length: 3599.65,                last time consumption/overall running time: 3232.7594s / 62728.4115 s
env0_first_0:                 episode reward: -7.8500,                 loss: 0.0038
env0_second_0:                 episode reward: 7.8500,                 loss: 0.0030
env1_first_0:                 episode reward: -8.7000,                 loss: nan
env1_second_0:                 episode reward: 8.7000,                 loss: nan
Episode: 541/10000 (5.4100%),                 avg. length: 3572.1,                last time consumption/overall running time: 3211.7351s / 65940.1466 s
env0_first_0:                 episode reward: -8.8000,                 loss: 0.0036
env0_second_0:                 episode reward: 8.8000,                 loss: 0.0025
env1_first_0:                 episode reward: -10.0500,                 loss: nan
env1_second_0:                 episode reward: 10.0500,                 loss: nan
Episode: 561/10000 (5.6100%),                 avg. length: 3556.2,                last time consumption/overall running time: 3194.9011s / 69135.0477 s
env0_first_0:                 episode reward: -8.4500,                 loss: 0.0038
env0_second_0:                 episode reward: 8.4500,                 loss: 0.0029
env1_first_0:                 episode reward: -10.6000,                 loss: nan
env1_second_0:                 episode reward: 10.6000,                 loss: nan
Episode: 581/10000 (5.8100%),                 avg. length: 3366.5,                last time consumption/overall running time: 3025.7473s / 72160.7950 s
env0_first_0:                 episode reward: -12.3500,                 loss: 0.0038
env0_second_0:                 episode reward: 12.3500,                 loss: 0.0024
env1_first_0:                 episode reward: -9.2500,                 loss: nan
env1_second_0:                 episode reward: 9.2500,                 loss: nan
Episode: 601/10000 (6.0100%),                 avg. length: 3416.75,                last time consumption/overall running time: 3072.1412s / 75232.9362 s
env0_first_0:                 episode reward: -9.8000,                 loss: 0.0036
env0_second_0:                 episode reward: 9.8000,                 loss: 0.0026
env1_first_0:                 episode reward: -11.0000,                 loss: nan
env1_second_0:                 episode reward: 11.0000,                 loss: nan
Episode: 621/10000 (6.2100%),                 avg. length: 3207.6,                last time consumption/overall running time: 2884.2298s / 78117.1660 s
env0_first_0:                 episode reward: -11.7500,                 loss: 0.0039
env0_second_0:                 episode reward: 11.7500,                 loss: 0.0027
env1_first_0:                 episode reward: -9.0500,                 loss: nan
env1_second_0:                 episode reward: 9.0500,                 loss: nan
Episode: 641/10000 (6.4100%),                 avg. length: 2852.7,                last time consumption/overall running time: 2567.0809s / 80684.2469 s
env0_first_0:                 episode reward: -11.6500,                 loss: 0.0040
env0_second_0:                 episode reward: 11.6500,                 loss: 0.0026
env1_first_0:                 episode reward: -13.1500,                 loss: nan
env1_second_0:                 episode reward: 13.1500,                 loss: nan
Episode: 661/10000 (6.6100%),                 avg. length: 3409.3,                last time consumption/overall running time: 3064.4433s / 83748.6902 s
env0_first_0:                 episode reward: -9.7000,                 loss: 0.0039
env0_second_0:                 episode reward: 9.7000,                 loss: 0.0026
env1_first_0:                 episode reward: -10.9000,                 loss: nan
env1_second_0:                 episode reward: 10.9000,                 loss: nan
Episode: 681/10000 (6.8100%),                 avg. length: 3210.95,                last time consumption/overall running time: 2886.7207s / 86635.4109 s
env0_first_0:                 episode reward: -11.6500,                 loss: 0.0038
env0_second_0:                 episode reward: 11.6500,                 loss: 0.0026
env1_first_0:                 episode reward: -9.1500,                 loss: nan
env1_second_0:                 episode reward: 9.1500,                 loss: nan
Episode: 701/10000 (7.0100%),                 avg. length: 3024.05,                last time consumption/overall running time: 2719.1082s / 89354.5191 s
env0_first_0:                 episode reward: -11.4500,                 loss: 0.0038
env0_second_0:                 episode reward: 11.4500,                 loss: 0.0026
env1_first_0:                 episode reward: -12.4500,                 loss: nan
env1_second_0:                 episode reward: 12.4500,                 loss: nan
Episode: 721/10000 (7.2100%),                 avg. length: 3280.15,                last time consumption/overall running time: 2946.1650s / 92300.6841 s
env0_first_0:                 episode reward: -11.2000,                 loss: 0.0042
env0_second_0:                 episode reward: 11.2000,                 loss: 0.0025
env1_first_0:                 episode reward: -11.0500,                 loss: nan
env1_second_0:                 episode reward: 11.0500,                 loss: nan
Episode: 741/10000 (7.4100%),                 avg. length: 3069.3,                last time consumption/overall running time: 2754.2467s / 95054.9308 s
env0_first_0:                 episode reward: -13.6000,                 loss: 0.0038
env0_second_0:                 episode reward: 13.6000,                 loss: 0.0023
env1_first_0:                 episode reward: -14.0500,                 loss: nan
env1_second_0:                 episode reward: 14.0500,                 loss: nan
Episode: 761/10000 (7.6100%),                 avg. length: 3117.6,                last time consumption/overall running time: 2791.2988s / 97846.2296 s
env0_first_0:                 episode reward: -11.7500,                 loss: 0.0036
env0_second_0:                 episode reward: 11.7500,                 loss: 0.0024
env1_first_0:                 episode reward: -12.9000,                 loss: nan
env1_second_0:                 episode reward: 12.9000,                 loss: nan
Episode: 781/10000 (7.8100%),                 avg. length: 3122.75,                last time consumption/overall running time: 2788.7533s / 100634.9829 s
env0_first_0:                 episode reward: -12.3500,                 loss: 0.0036
env0_second_0:                 episode reward: 12.3500,                 loss: 0.0024
env1_first_0:                 episode reward: -11.7000,                 loss: nan
env1_second_0:                 episode reward: 11.7000,                 loss: nan
Episode: 801/10000 (8.0100%),                 avg. length: 2968.25,                last time consumption/overall running time: 2657.9446s / 103292.9275 s
env0_first_0:                 episode reward: -11.3000,                 loss: 0.0039
env0_second_0:                 episode reward: 11.3000,                 loss: 0.0026
env1_first_0:                 episode reward: -12.1500,                 loss: nan
env1_second_0:                 episode reward: 12.1500,                 loss: nan
Episode: 821/10000 (8.2100%),                 avg. length: 3002.45,                last time consumption/overall running time: 2684.8814s / 105977.8089 s
env0_first_0:                 episode reward: -13.5000,                 loss: 0.0037
env0_second_0:                 episode reward: 13.5000,                 loss: 0.0024
env1_first_0:                 episode reward: -12.1500,                 loss: nan
env1_second_0:                 episode reward: 12.1500,                 loss: nan
Episode: 841/10000 (8.4100%),                 avg. length: 2966.7,                last time consumption/overall running time: 2653.9158s / 108631.7247 s
env0_first_0:                 episode reward: -12.1500,                 loss: 0.0037
env0_second_0:                 episode reward: 12.1500,                 loss: 0.0024
env1_first_0:                 episode reward: -13.2500,                 loss: nan
env1_second_0:                 episode reward: 13.2500,                 loss: nan
Episode: 861/10000 (8.6100%),                 avg. length: 2849.45,                last time consumption/overall running time: 2549.8304s / 111181.5551 s
env0_first_0:                 episode reward: -13.2500,                 loss: 0.0035
env0_second_0:                 episode reward: 13.2500,                 loss: 0.0024
env1_first_0:                 episode reward: -12.7000,                 loss: nan
env1_second_0:                 episode reward: 12.7000,                 loss: nan
Episode: 881/10000 (8.8100%),                 avg. length: 2991.9,                last time consumption/overall running time: 2678.6085s / 113860.1635 s
env0_first_0:                 episode reward: -13.6000,                 loss: 0.0039
env0_second_0:                 episode reward: 13.6000,                 loss: 0.0024
env1_first_0:                 episode reward: -10.7000,                 loss: nan
env1_second_0:                 episode reward: 10.7000,                 loss: nan
Episode: 901/10000 (9.0100%),                 avg. length: 3172.3,                last time consumption/overall running time: 2841.2709s / 116701.4345 s
env0_first_0:                 episode reward: -14.0500,                 loss: 0.0039
env0_second_0:                 episode reward: 14.0500,                 loss: 0.0025
env1_first_0:                 episode reward: -10.9500,                 loss: nan
env1_second_0:                 episode reward: 10.9500,                 loss: nan
Episode: 921/10000 (9.2100%),                 avg. length: 3082.5,                last time consumption/overall running time: 2760.8534s / 119462.2878 s
env0_first_0:                 episode reward: -12.7000,                 loss: 0.0039
env0_second_0:                 episode reward: 12.7000,                 loss: 0.0027
env1_first_0:                 episode reward: -10.8000,                 loss: nan
env1_second_0:                 episode reward: 10.8000,                 loss: nan
Episode: 941/10000 (9.4100%),                 avg. length: 3339.55,                last time consumption/overall running time: 2988.1024s / 122450.3903 s
env0_first_0:                 episode reward: -10.5500,                 loss: 0.0038
env0_second_0:                 episode reward: 10.5500,                 loss: 0.0029
env1_first_0:                 episode reward: -10.8500,                 loss: nan
env1_second_0:                 episode reward: 10.8500,                 loss: nan
Episode: 961/10000 (9.6100%),                 avg. length: 3153.95,                last time consumption/overall running time: 2821.1385s / 125271.5288 s
env0_first_0:                 episode reward: -12.3500,                 loss: 0.0037
env0_second_0:                 episode reward: 12.3500,                 loss: 0.0025
env1_first_0:                 episode reward: -12.4000,                 loss: nan
env1_second_0:                 episode reward: 12.4000,                 loss: nan
Episode: 981/10000 (9.8100%),                 avg. length: 3024.15,                last time consumption/overall running time: 2703.7442s / 127975.2730 s
env0_first_0:                 episode reward: -12.1000,                 loss: 0.0038
env0_second_0:                 episode reward: 12.1000,                 loss: 0.0025
env1_first_0:                 episode reward: -13.5000,                 loss: nan
env1_second_0:                 episode reward: 13.5000,                 loss: nan
Episode: 1001/10000 (10.0100%),                 avg. length: 2850.7,                last time consumption/overall running time: 2545.3641s / 130520.6371 s
env0_first_0:                 episode reward: -12.6500,                 loss: 0.0041
env0_second_0:                 episode reward: 12.6500,                 loss: 0.0022
env1_first_0:                 episode reward: -13.0000,                 loss: nan
env1_second_0:                 episode reward: 13.0000,                 loss: nan
Episode: 1021/10000 (10.2100%),                 avg. length: 3431.55,                last time consumption/overall running time: 3064.5651s / 133585.2022 s
env0_first_0:                 episode reward: -11.9500,                 loss: 0.0040
env0_second_0:                 episode reward: 11.9500,                 loss: 0.0025
env1_first_0:                 episode reward: -11.9500,                 loss: nan
env1_second_0:                 episode reward: 11.9500,                 loss: nan
Episode: 1041/10000 (10.4100%),                 avg. length: 3286.25,                last time consumption/overall running time: 2937.0693s / 136522.2716 s
env0_first_0:                 episode reward: -11.3500,                 loss: 0.0036
env0_second_0:                 episode reward: 11.3500,                 loss: 0.0023
env1_first_0:                 episode reward: -12.8000,                 loss: nan
env1_second_0:                 episode reward: 12.8000,                 loss: nan
Episode: 1061/10000 (10.6100%),                 avg. length: 3481.75,                last time consumption/overall running time: 3115.6601s / 139637.9316 s
env0_first_0:                 episode reward: -11.1000,                 loss: 0.0036
env0_second_0:                 episode reward: 11.1000,                 loss: 0.0023
env1_first_0:                 episode reward: -11.1500,                 loss: nan
env1_second_0:                 episode reward: 11.1500,                 loss: nan
Episode: 1081/10000 (10.8100%),                 avg. length: 3828.1,                last time consumption/overall running time: 3421.4438s / 143059.3755 s
env0_first_0:                 episode reward: -9.5000,                 loss: 0.0038
env0_second_0:                 episode reward: 9.5000,                 loss: 0.0022
env1_first_0:                 episode reward: -10.7000,                 loss: nan
env1_second_0:                 episode reward: 10.7000,                 loss: nan
Episode: 1101/10000 (11.0100%),                 avg. length: 3317.8,                last time consumption/overall running time: 2831.7683s / 145891.1438 s
env0_first_0:                 episode reward: -11.1500,                 loss: 0.0035
env0_second_0:                 episode reward: 11.1500,                 loss: 0.0021
env1_first_0:                 episode reward: -11.9500,                 loss: nan
env1_second_0:                 episode reward: 11.9500,                 loss: nan
Episode: 1121/10000 (11.2100%),                 avg. length: 3359.85,                last time consumption/overall running time: 2638.2630s / 148529.4068 s
env0_first_0:                 episode reward: -10.9500,                 loss: 0.0036
env0_second_0:                 episode reward: 10.9500,                 loss: 0.0024
env1_first_0:                 episode reward: -12.2000,                 loss: nan
env1_second_0:                 episode reward: 12.2000,                 loss: nan
Episode: 1141/10000 (11.4100%),                 avg. length: 3427.6,                last time consumption/overall running time: 2624.8816s / 151154.2885 s
env0_first_0:                 episode reward: -11.9000,                 loss: 0.0036
env0_second_0:                 episode reward: 11.9000,                 loss: 0.0022
env1_first_0:                 episode reward: -11.5000,                 loss: nan
env1_second_0:                 episode reward: 11.5000,                 loss: nan
Episode: 1161/10000 (11.6100%),                 avg. length: 2789.4,                last time consumption/overall running time: 2137.6398s / 153291.9283 s
env0_first_0:                 episode reward: -12.6500,                 loss: 0.0037
env0_second_0:                 episode reward: 12.6500,                 loss: 0.0024
env1_first_0:                 episode reward: -13.8000,                 loss: nan
env1_second_0:                 episode reward: 13.8000,                 loss: nan
Episode: 1181/10000 (11.8100%),                 avg. length: 3095.75,                last time consumption/overall running time: 2371.7867s / 155663.7149 s
env0_first_0:                 episode reward: -13.3500,                 loss: 0.0037
env0_second_0:                 episode reward: 13.3500,                 loss: 0.0023
env1_first_0:                 episode reward: -11.7500,                 loss: nan
env1_second_0:                 episode reward: 11.7500,                 loss: nan
Episode: 1201/10000 (12.0100%),                 avg. length: 3100.8,                last time consumption/overall running time: 2373.9352s / 158037.6501 s
env0_first_0:                 episode reward: -9.9500,                 loss: 0.0040
env0_second_0:                 episode reward: 9.9500,                 loss: 0.0024
env1_first_0:                 episode reward: -13.9500,                 loss: nan
env1_second_0:                 episode reward: 13.9500,                 loss: nan
Episode: 1221/10000 (12.2100%),                 avg. length: 2767.3,                last time consumption/overall running time: 2123.0534s / 160160.7036 s
env0_first_0:                 episode reward: -12.9500,                 loss: 0.0040
env0_second_0:                 episode reward: 12.9500,                 loss: 0.0026
env1_first_0:                 episode reward: -13.7000,                 loss: nan
env1_second_0:                 episode reward: 13.7000,                 loss: nan
Episode: 1241/10000 (12.4100%),                 avg. length: 2964.85,                last time consumption/overall running time: 2268.7770s / 162429.4806 s
env0_first_0:                 episode reward: -13.4500,                 loss: 0.0038
env0_second_0:                 episode reward: 13.4500,                 loss: 0.0026
env1_first_0:                 episode reward: -14.3500,                 loss: nan
env1_second_0:                 episode reward: 14.3500,                 loss: nan
Episode: 1261/10000 (12.6100%),                 avg. length: 2930.85,                last time consumption/overall running time: 2245.2018s / 164674.6824 s
env0_first_0:                 episode reward: -12.9000,                 loss: 0.0042
env0_second_0:                 episode reward: 12.9000,                 loss: 0.0024
env1_first_0:                 episode reward: -13.8000,                 loss: nan
env1_second_0:                 episode reward: 13.8000,                 loss: nan
Episode: 1281/10000 (12.8100%),                 avg. length: 2918.3,                last time consumption/overall running time: 2238.1423s / 166912.8247 s
env0_first_0:                 episode reward: -13.1500,                 loss: 0.0041
env0_second_0:                 episode reward: 13.1500,                 loss: 0.0022
env1_first_0:                 episode reward: -13.0500,                 loss: nan
env1_second_0:                 episode reward: 13.0500,                 loss: nan
Episode: 1301/10000 (13.0100%),                 avg. length: 2774.1,                last time consumption/overall running time: 2128.4559s / 169041.2806 s
env0_first_0:                 episode reward: -13.7000,                 loss: 0.0039
env0_second_0:                 episode reward: 13.7000,                 loss: 0.0024
env1_first_0:                 episode reward: -13.2500,                 loss: nan
env1_second_0:                 episode reward: 13.2500,                 loss: nan
Episode: 1321/10000 (13.2100%),                 avg. length: 2633.25,                last time consumption/overall running time: 2016.1896s / 171057.4701 s
env0_first_0:                 episode reward: -15.5000,                 loss: 0.0040
env0_second_0:                 episode reward: 15.5000,                 loss: 0.0024
env1_first_0:                 episode reward: -13.4500,                 loss: nan
env1_second_0:                 episode reward: 13.4500,                 loss: nan
Episode: 1341/10000 (13.4100%),                 avg. length: 2933.9,                last time consumption/overall running time: 2244.6480s / 173302.1181 s
env0_first_0:                 episode reward: -12.5500,                 loss: 0.0039
env0_second_0:                 episode reward: 12.5500,                 loss: 0.0027
env1_first_0:                 episode reward: -13.1500,                 loss: nan
env1_second_0:                 episode reward: 13.1500,                 loss: nan
Episode: 1361/10000 (13.6100%),                 avg. length: 2770.15,                last time consumption/overall running time: 2125.9093s / 175428.0274 s
env0_first_0:                 episode reward: -11.8500,                 loss: 0.0040
env0_second_0:                 episode reward: 11.8500,                 loss: 0.0024
env1_first_0:                 episode reward: -14.9000,                 loss: nan
env1_second_0:                 episode reward: 14.9000,                 loss: nan
Episode: 1381/10000 (13.8100%),                 avg. length: 2668.35,                last time consumption/overall running time: 2044.4371s / 177472.4646 s
env0_first_0:                 episode reward: -13.9500,                 loss: 0.0043
env0_second_0:                 episode reward: 13.9500,                 loss: 0.0023
env1_first_0:                 episode reward: -13.4500,                 loss: nan
env1_second_0:                 episode reward: 13.4500,                 loss: nan
Episode: 1401/10000 (14.0100%),                 avg. length: 2894.55,                last time consumption/overall running time: 2216.6917s / 179689.1563 s
env0_first_0:                 episode reward: -12.7500,                 loss: 0.0045
env0_second_0:                 episode reward: 12.7500,                 loss: 0.0024
env1_first_0:                 episode reward: -13.1000,                 loss: nan
env1_second_0:                 episode reward: 13.1000,                 loss: nan
Episode: 1421/10000 (14.2100%),                 avg. length: 3113.2,                last time consumption/overall running time: 2385.2445s / 182074.4008 s
env0_first_0:                 episode reward: -12.3500,                 loss: 0.0042
env0_second_0:                 episode reward: 12.3500,                 loss: 0.0026
env1_first_0:                 episode reward: -11.4500,                 loss: nan
env1_second_0:                 episode reward: 11.4500,                 loss: nan
Episode: 1441/10000 (14.4100%),                 avg. length: 2603.35,                last time consumption/overall running time: 1995.1945s / 184069.5953 s
env0_first_0:                 episode reward: -13.0500,                 loss: 0.0039
env0_second_0:                 episode reward: 13.0500,                 loss: 0.0029
env1_first_0:                 episode reward: -12.6500,                 loss: nan
env1_second_0:                 episode reward: 12.6500,                 loss: nan
Episode: 1461/10000 (14.6100%),                 avg. length: 3060.05,                last time consumption/overall running time: 2343.7404s / 186413.3357 s
env0_first_0:                 episode reward: -14.1500,                 loss: 0.0042
env0_second_0:                 episode reward: 14.1500,                 loss: 0.0028
env1_first_0:                 episode reward: -12.1500,                 loss: nan
env1_second_0:                 episode reward: 12.1500,                 loss: nan
Episode: 1481/10000 (14.8100%),                 avg. length: 2930.65,                last time consumption/overall running time: 2242.4973s / 188655.8330 s
env0_first_0:                 episode reward: -15.5500,                 loss: 0.0038
env0_second_0:                 episode reward: 15.5500,                 loss: 0.0026
env1_first_0:                 episode reward: -12.8500,                 loss: nan
env1_second_0:                 episode reward: 12.8500,                 loss: nan
Episode: 1501/10000 (15.0100%),                 avg. length: 2946.25,                last time consumption/overall running time: 2252.7881s / 190908.6211 s
env0_first_0:                 episode reward: -13.6000,                 loss: 0.0035
env0_second_0:                 episode reward: 13.6000,                 loss: 0.0022
env1_first_0:                 episode reward: -13.8000,                 loss: nan
env1_second_0:                 episode reward: 13.8000,                 loss: nan
Episode: 1521/10000 (15.2100%),                 avg. length: 3084.2,                last time consumption/overall running time: 2354.4587s / 193263.0798 s
env0_first_0:                 episode reward: -12.1500,                 loss: 0.0041
env0_second_0:                 episode reward: 12.1500,                 loss: 0.0028
env1_first_0:                 episode reward: -13.4000,                 loss: nan
env1_second_0:                 episode reward: 13.4000,                 loss: nan
Episode: 1541/10000 (15.4100%),                 avg. length: 3087.8,                last time consumption/overall running time: 2358.0359s / 195621.1156 s
env0_first_0:                 episode reward: -12.7500,                 loss: 0.0039
env0_second_0:                 episode reward: 12.7500,                 loss: 0.0026
env1_first_0:                 episode reward: -14.2500,                 loss: nan
env1_second_0:                 episode reward: 14.2500,                 loss: nan
Episode: 1561/10000 (15.6100%),                 avg. length: 3557.95,                last time consumption/overall running time: 2710.5236s / 198331.6393 s
env0_first_0:                 episode reward: -11.3500,                 loss: 0.0036
env0_second_0:                 episode reward: 11.3500,                 loss: 0.0024
env1_first_0:                 episode reward: -12.1000,                 loss: nan
env1_second_0:                 episode reward: 12.1000,                 loss: nan
Episode: 1581/10000 (15.8100%),                 avg. length: 3143.2,                last time consumption/overall running time: 2395.2688s / 200726.9080 s
env0_first_0:                 episode reward: -14.2500,                 loss: 0.0039
env0_second_0:                 episode reward: 14.2500,                 loss: 0.0024
env1_first_0:                 episode reward: -11.4000,                 loss: nan
env1_second_0:                 episode reward: 11.4000,                 loss: nan
Episode: 1601/10000 (16.0100%),                 avg. length: 3098.5,                last time consumption/overall running time: 2347.4851s / 203074.3931 s
env0_first_0:                 episode reward: -11.9000,                 loss: 0.0041
env0_second_0:                 episode reward: 11.9000,                 loss: 0.0024
env1_first_0:                 episode reward: -13.2000,                 loss: nan
env1_second_0:                 episode reward: 13.2000,                 loss: nan
Episode: 1621/10000 (16.2100%),                 avg. length: 3491.3,                last time consumption/overall running time: 2648.8889s / 205723.2821 s
env0_first_0:                 episode reward: -12.7000,                 loss: 0.0036
env0_second_0:                 episode reward: 12.7000,                 loss: 0.0021
env1_first_0:                 episode reward: -12.5500,                 loss: nan
env1_second_0:                 episode reward: 12.5500,                 loss: nan
Episode: 1641/10000 (16.4100%),                 avg. length: 3482.4,                last time consumption/overall running time: 2640.6097s / 208363.8918 s
env0_first_0:                 episode reward: -11.5500,                 loss: 0.0034
env0_second_0:                 episode reward: 11.5500,                 loss: 0.0022
env1_first_0:                 episode reward: -11.4500,                 loss: nan
env1_second_0:                 episode reward: 11.4500,                 loss: nan
Episode: 1661/10000 (16.6100%),                 avg. length: 3447.05,                last time consumption/overall running time: 2611.2754s / 210975.1671 s
env0_first_0:                 episode reward: -12.9000,                 loss: 0.0035
env0_second_0:                 episode reward: 12.9000,                 loss: 0.0022
env1_first_0:                 episode reward: -11.1000,                 loss: nan
env1_second_0:                 episode reward: 11.1000,                 loss: nan
Episode: 1681/10000 (16.8100%),                 avg. length: 3170.2,                last time consumption/overall running time: 2404.2486s / 213379.4157 s
env0_first_0:                 episode reward: -13.0000,                 loss: 0.0037
env0_second_0:                 episode reward: 13.0000,                 loss: 0.0022
env1_first_0:                 episode reward: -12.3500,                 loss: nan
env1_second_0:                 episode reward: 12.3500,                 loss: nan
Episode: 1701/10000 (17.0100%),                 avg. length: 3416.9,                last time consumption/overall running time: 2590.0829s / 215969.4986 s
env0_first_0:                 episode reward: -12.0500,                 loss: 0.0036
env0_second_0:                 episode reward: 12.0500,                 loss: 0.0024
env1_first_0:                 episode reward: -12.6000,                 loss: nan
env1_second_0:                 episode reward: 12.6000,                 loss: nan
Episode: 1721/10000 (17.2100%),                 avg. length: 3309.0,                last time consumption/overall running time: 2507.9047s / 218477.4033 s
env0_first_0:                 episode reward: -12.6000,                 loss: 0.0037
env0_second_0:                 episode reward: 12.6000,                 loss: 0.0025
env1_first_0:                 episode reward: -10.3000,                 loss: nan
env1_second_0:                 episode reward: 10.3000,                 loss: nan
Episode: 1741/10000 (17.4100%),                 avg. length: 3507.5,                last time consumption/overall running time: 2658.0066s / 221135.4099 s
env0_first_0:                 episode reward: -10.3500,                 loss: 0.0040
env0_second_0:                 episode reward: 10.3500,                 loss: 0.0027
env1_first_0:                 episode reward: -10.8500,                 loss: nan
env1_second_0:                 episode reward: 10.8500,                 loss: nan
Episode: 1761/10000 (17.6100%),                 avg. length: 3271.05,                last time consumption/overall running time: 2476.4629s / 223611.8728 s
env0_first_0:                 episode reward: -13.1000,                 loss: 0.0042
env0_second_0:                 episode reward: 13.1000,                 loss: 0.0023
env1_first_0:                 episode reward: -11.7500,                 loss: nan
env1_second_0:                 episode reward: 11.7500,                 loss: nan
Episode: 1781/10000 (17.8100%),                 avg. length: 2985.8,                last time consumption/overall running time: 2265.2346s / 225877.1074 s
env0_first_0:                 episode reward: -13.6500,                 loss: 0.0042
env0_second_0:                 episode reward: 13.6500,                 loss: 0.0023
env1_first_0:                 episode reward: -11.5500,                 loss: nan
env1_second_0:                 episode reward: 11.5500,                 loss: nan
Episode: 1801/10000 (18.0100%),                 avg. length: 3461.2,                last time consumption/overall running time: 2626.3057s / 228503.4131 s
env0_first_0:                 episode reward: -11.2000,                 loss: 0.0041
env0_second_0:                 episode reward: 11.2000,                 loss: 0.0025
env1_first_0:                 episode reward: -14.4000,                 loss: nan
env1_second_0:                 episode reward: 14.4000,                 loss: nan
Episode: 1821/10000 (18.2100%),                 avg. length: 3682.4,                last time consumption/overall running time: 2785.4526s / 231288.8656 s
env0_first_0:                 episode reward: -13.1500,                 loss: 0.0036
env0_second_0:                 episode reward: 13.1500,                 loss: 0.0022
env1_first_0:                 episode reward: -9.0500,                 loss: nan
env1_second_0:                 episode reward: 9.0500,                 loss: nan
Episode: 1841/10000 (18.4100%),                 avg. length: 3325.8,                last time consumption/overall running time: 2512.6906s / 233801.5562 s
env0_first_0:                 episode reward: -12.2000,                 loss: 0.0036
env0_second_0:                 episode reward: 12.2000,                 loss: 0.0023
env1_first_0:                 episode reward: -12.8500,                 loss: nan
env1_second_0:                 episode reward: 12.8500,                 loss: nan
Episode: 1861/10000 (18.6100%),                 avg. length: 3617.3,                last time consumption/overall running time: 2737.7142s / 236539.2704 s
env0_first_0:                 episode reward: -11.7500,                 loss: 0.0035
env0_second_0:                 episode reward: 11.7500,                 loss: 0.0023
env1_first_0:                 episode reward: -11.5500,                 loss: nan
env1_second_0:                 episode reward: 11.5500,                 loss: nan
Episode: 1881/10000 (18.8100%),                 avg. length: 3605.05,                last time consumption/overall running time: 2729.4016s / 239268.6720 s
env0_first_0:                 episode reward: -9.8500,                 loss: 0.0037
env0_second_0:                 episode reward: 9.8500,                 loss: 0.0022
env1_first_0:                 episode reward: -9.3500,                 loss: nan
env1_second_0:                 episode reward: 9.3500,                 loss: nan
Episode: 1901/10000 (19.0100%),                 avg. length: 3812.85,                last time consumption/overall running time: 2884.2439s / 242152.9159 s
env0_first_0:                 episode reward: -8.4000,                 loss: 0.0043
env0_second_0:                 episode reward: 8.4000,                 loss: 0.0025
env1_first_0:                 episode reward: -8.8000,                 loss: nan
env1_second_0:                 episode reward: 8.8000,                 loss: nan
Episode: 1921/10000 (19.2100%),                 avg. length: 3377.3,                last time consumption/overall running time: 2557.6200s / 244710.5359 s
env0_first_0:                 episode reward: -10.4500,                 loss: 0.0039
env0_second_0:                 episode reward: 10.4500,                 loss: 0.0023
env1_first_0:                 episode reward: -12.4500,                 loss: nan
env1_second_0:                 episode reward: 12.4500,                 loss: nan
Episode: 1941/10000 (19.4100%),                 avg. length: 3366.85,                last time consumption/overall running time: 2544.5615s / 247255.0974 s
env0_first_0:                 episode reward: -11.3000,                 loss: 0.0041
env0_second_0:                 episode reward: 11.3000,                 loss: 0.0025
env1_first_0:                 episode reward: -12.0000,                 loss: nan
env1_second_0:                 episode reward: 12.0000,                 loss: nan
Episode: 1961/10000 (19.6100%),                 avg. length: 3116.0,                last time consumption/overall running time: 2356.1586s / 249611.2560 s
env0_first_0:                 episode reward: -11.0000,                 loss: 0.0041
env0_second_0:                 episode reward: 11.0000,                 loss: 0.0025
env1_first_0:                 episode reward: -11.2000,                 loss: nan
env1_second_0:                 episode reward: 11.2000,                 loss: nan
Episode: 1981/10000 (19.8100%),                 avg. length: 3296.6,                last time consumption/overall running time: 2491.7775s / 252103.0335 s
env0_first_0:                 episode reward: -10.7500,                 loss: 0.0041
env0_second_0:                 episode reward: 10.7500,                 loss: 0.0024
env1_first_0:                 episode reward: -11.3500,                 loss: nan
env1_second_0:                 episode reward: 11.3500,                 loss: nan
Episode: 2001/10000 (20.0100%),                 avg. length: 2966.3,                last time consumption/overall running time: 2239.2082s / 254342.2417 s
env0_first_0:                 episode reward: -13.8000,                 loss: 0.0043
env0_second_0:                 episode reward: 13.8000,                 loss: 0.0025
env1_first_0:                 episode reward: -12.0000,                 loss: nan
env1_second_0:                 episode reward: 12.0000,                 loss: nan
Episode: 2021/10000 (20.2100%),                 avg. length: 3042.4,                last time consumption/overall running time: 2301.5607s / 256643.8024 s
env0_first_0:                 episode reward: -11.6500,                 loss: 0.0039
env0_second_0:                 episode reward: 11.6500,                 loss: 0.0022
env1_first_0:                 episode reward: -12.5000,                 loss: nan
env1_second_0:                 episode reward: 12.5000,                 loss: nan
Episode: 2041/10000 (20.4100%),                 avg. length: 3366.6,                last time consumption/overall running time: 2540.4070s / 259184.2094 s
env0_first_0:                 episode reward: -10.0500,                 loss: 0.0045
env0_second_0:                 episode reward: 10.0500,                 loss: 0.0027
env1_first_0:                 episode reward: -8.7500,                 loss: nan
env1_second_0:                 episode reward: 8.7500,                 loss: nan
Episode: 2061/10000 (20.6100%),                 avg. length: 3389.45,                last time consumption/overall running time: 2554.3813s / 261738.5906 s
env0_first_0:                 episode reward: -12.1500,                 loss: 0.0042
env0_second_0:                 episode reward: 12.1500,                 loss: 0.0024
env1_first_0:                 episode reward: -11.6000,                 loss: nan
env1_second_0:                 episode reward: 11.6000,                 loss: nan
Episode: 2081/10000 (20.8100%),                 avg. length: 3186.45,                last time consumption/overall running time: 2404.5530s / 264143.1437 s
env0_first_0:                 episode reward: -13.4500,                 loss: 0.0041
env0_second_0:                 episode reward: 13.4500,                 loss: 0.0022
env1_first_0:                 episode reward: -13.5000,                 loss: nan
env1_second_0:                 episode reward: 13.5000,                 loss: nan
Episode: 2101/10000 (21.0100%),                 avg. length: 3140.8,                last time consumption/overall running time: 2367.1219s / 266510.2655 s
env0_first_0:                 episode reward: -12.6500,                 loss: 0.0041
env0_second_0:                 episode reward: 12.6500,                 loss: 0.0023
env1_first_0:                 episode reward: -12.0000,                 loss: nan
env1_second_0:                 episode reward: 12.0000,                 loss: nan
Episode: 2121/10000 (21.2100%),                 avg. length: 3074.2,                last time consumption/overall running time: 2325.1005s / 268835.3661 s
env0_first_0:                 episode reward: -12.6500,                 loss: 0.0042
env0_second_0:                 episode reward: 12.6500,                 loss: 0.0028
env1_first_0:                 episode reward: -12.2500,                 loss: nan
env1_second_0:                 episode reward: 12.2500,                 loss: nan
Episode: 2141/10000 (21.4100%),                 avg. length: 3069.05,                last time consumption/overall running time: 2318.0372s / 271153.4033 s
env0_first_0:                 episode reward: -11.1000,                 loss: 0.0041
env0_second_0:                 episode reward: 11.1000,                 loss: 0.0026
env1_first_0:                 episode reward: -10.7000,                 loss: nan
env1_second_0:                 episode reward: 10.7000,                 loss: nan
Episode: 2161/10000 (21.6100%),                 avg. length: 3112.1,                last time consumption/overall running time: 2349.2069s / 273502.6102 s
env0_first_0:                 episode reward: -12.4000,                 loss: 0.0037
env0_second_0:                 episode reward: 12.4000,                 loss: 0.0025
env1_first_0:                 episode reward: -12.1000,                 loss: nan
env1_second_0:                 episode reward: 12.1000,                 loss: nan
Episode: 2181/10000 (21.8100%),                 avg. length: 2956.15,                last time consumption/overall running time: 2229.5036s / 275732.1138 s
env0_first_0:                 episode reward: -15.0000,                 loss: 0.0036
env0_second_0:                 episode reward: 15.0000,                 loss: 0.0022
env1_first_0:                 episode reward: -12.7000,                 loss: nan
env1_second_0:                 episode reward: 12.7000,                 loss: nan
Episode: 2201/10000 (22.0100%),                 avg. length: 3158.25,                last time consumption/overall running time: 2384.2869s / 278116.4007 s
env0_first_0:                 episode reward: -11.8000,                 loss: 0.0036
env0_second_0:                 episode reward: 11.8000,                 loss: 0.0022
env1_first_0:                 episode reward: -15.4000,                 loss: nan
env1_second_0:                 episode reward: 15.4000,                 loss: nan
Episode: 2221/10000 (22.2100%),                 avg. length: 3260.25,                last time consumption/overall running time: 2459.0175s / 280575.4181 s
env0_first_0:                 episode reward: -9.4000,                 loss: 0.0041
env0_second_0:                 episode reward: 9.4000,                 loss: 0.0026
env1_first_0:                 episode reward: -9.8500,                 loss: nan
env1_second_0:                 episode reward: 9.8500,                 loss: nan
Episode: 2241/10000 (22.4100%),                 avg. length: 3222.35,                last time consumption/overall running time: 2427.5616s / 283002.9797 s
env0_first_0:                 episode reward: -12.2500,                 loss: 0.0040
env0_second_0:                 episode reward: 12.2500,                 loss: 0.0025
env1_first_0:                 episode reward: -11.1500,                 loss: nan
env1_second_0:                 episode reward: 11.1500,                 loss: nan
Episode: 2261/10000 (22.6100%),                 avg. length: 3107.6,                last time consumption/overall running time: 2342.5918s / 285345.5715 s
env0_first_0:                 episode reward: -10.2500,                 loss: 0.0039
env0_second_0:                 episode reward: 10.2500,                 loss: 0.0026
env1_first_0:                 episode reward: -12.5500,                 loss: nan
env1_second_0:                 episode reward: 12.5500,                 loss: nan
Episode: 2281/10000 (22.8100%),                 avg. length: 3471.7,                last time consumption/overall running time: 2618.7803s / 287964.3518 s
env0_first_0:                 episode reward: -8.2500,                 loss: 0.0038
env0_second_0:                 episode reward: 8.2500,                 loss: 0.0025
env1_first_0:                 episode reward: -11.1500,                 loss: nan
env1_second_0:                 episode reward: 11.1500,                 loss: nan
Episode: 2301/10000 (23.0100%),                 avg. length: 3511.1,                last time consumption/overall running time: 2644.6649s / 290609.0167 s
env0_first_0:                 episode reward: -13.1500,                 loss: 0.0041
env0_second_0:                 episode reward: 13.1500,                 loss: 0.0025
env1_first_0:                 episode reward: -11.4000,                 loss: nan
env1_second_0:                 episode reward: 11.4000,                 loss: nan
Episode: 2321/10000 (23.2100%),                 avg. length: 3407.55,                last time consumption/overall running time: 2568.6900s / 293177.7068 s
env0_first_0:                 episode reward: -10.1000,                 loss: 0.0038
env0_second_0:                 episode reward: 10.1000,                 loss: 0.0026
env1_first_0:                 episode reward: -9.7000,                 loss: nan
env1_second_0:                 episode reward: 9.7000,                 loss: nan
Episode: 2341/10000 (23.4100%),                 avg. length: 3312.25,                last time consumption/overall running time: 2489.5942s / 295667.3009 s
env0_first_0:                 episode reward: -12.7500,                 loss: 0.0039
env0_second_0:                 episode reward: 12.7500,                 loss: 0.0022
env1_first_0:                 episode reward: -12.0500,                 loss: nan
env1_second_0:                 episode reward: 12.0500,                 loss: nan
Episode: 2361/10000 (23.6100%),                 avg. length: 3250.15,                last time consumption/overall running time: 2445.6282s / 298112.9291 s
env0_first_0:                 episode reward: -12.9000,                 loss: 0.0040
env0_second_0:                 episode reward: 12.9000,                 loss: 0.0024
env1_first_0:                 episode reward: -12.1500,                 loss: nan
env1_second_0:                 episode reward: 12.1500,                 loss: nan
Episode: 2381/10000 (23.8100%),                 avg. length: 3236.2,                last time consumption/overall running time: 2428.7932s / 300541.7224 s
env0_first_0:                 episode reward: -12.0000,                 loss: 0.0042
env0_second_0:                 episode reward: 12.0000,                 loss: 0.0024
env1_first_0:                 episode reward: -11.9500,                 loss: nan
env1_second_0:                 episode reward: 11.9500,                 loss: nan
Episode: 2401/10000 (24.0100%),                 avg. length: 3303.9,                last time consumption/overall running time: 2478.9500s / 303020.6724 s
env0_first_0:                 episode reward: -11.2000,                 loss: 0.0039
env0_second_0:                 episode reward: 11.2000,                 loss: 0.0025
env1_first_0:                 episode reward: -12.1000,                 loss: nan
env1_second_0:                 episode reward: 12.1000,                 loss: nan
Episode: 2421/10000 (24.2100%),                 avg. length: 3139.0,                last time consumption/overall running time: 2354.9859s / 305375.6583 s
env0_first_0:                 episode reward: -11.3500,                 loss: 0.0038
env0_second_0:                 episode reward: 11.3500,                 loss: 0.0024
env1_first_0:                 episode reward: -12.4000,                 loss: nan
env1_second_0:                 episode reward: 12.4000,                 loss: nan
Episode: 2441/10000 (24.4100%),                 avg. length: 3329.05,                last time consumption/overall running time: 2496.6665s / 307872.3248 s
env0_first_0:                 episode reward: -10.2500,                 loss: 0.0042
env0_second_0:                 episode reward: 10.2500,                 loss: 0.0027
env1_first_0:                 episode reward: -11.1500,                 loss: nan
env1_second_0:                 episode reward: 11.1500,                 loss: nan
Episode: 2461/10000 (24.6100%),                 avg. length: 3584.55,                last time consumption/overall running time: 2682.7648s / 310555.0896 s
env0_first_0:                 episode reward: -10.6500,                 loss: 0.0042
env0_second_0:                 episode reward: 10.6500,                 loss: 0.0027
env1_first_0:                 episode reward: -10.0500,                 loss: nan
env1_second_0:                 episode reward: 10.0500,                 loss: nan
Episode: 2481/10000 (24.8100%),                 avg. length: 3713.1,                last time consumption/overall running time: 2777.9833s / 313333.0729 s
env0_first_0:                 episode reward: -8.9000,                 loss: 0.0036
env0_second_0:                 episode reward: 8.9000,                 loss: 0.0025
env1_first_0:                 episode reward: -9.5500,                 loss: nan
env1_second_0:                 episode reward: 9.5500,                 loss: nan
Episode: 2501/10000 (25.0100%),                 avg. length: 3599.8,                last time consumption/overall running time: 2692.4336s / 316025.5065 s
env0_first_0:                 episode reward: -9.1000,                 loss: 0.0043
env0_second_0:                 episode reward: 9.1000,                 loss: 0.0028
env1_first_0:                 episode reward: -8.8000,                 loss: nan
env1_second_0:                 episode reward: 8.8000,                 loss: nan
Episode: 2521/10000 (25.2100%),                 avg. length: 3185.9,                last time consumption/overall running time: 2380.3340s / 318405.8405 s
env0_first_0:                 episode reward: -10.8500,                 loss: 0.0044
env0_second_0:                 episode reward: 10.8500,                 loss: 0.0027
env1_first_0:                 episode reward: -11.7500,                 loss: nan
env1_second_0:                 episode reward: 11.7500,                 loss: nan
Episode: 2541/10000 (25.4100%),                 avg. length: 3269.9,                last time consumption/overall running time: 2440.2022s / 320846.0427 s
env0_first_0:                 episode reward: -11.0000,                 loss: 0.0044
env0_second_0:                 episode reward: 11.0000,                 loss: 0.0029
env1_first_0:                 episode reward: -12.0500,                 loss: nan
env1_second_0:                 episode reward: 12.0500,                 loss: nan
Episode: 2561/10000 (25.6100%),                 avg. length: 3396.2,                last time consumption/overall running time: 2532.5515s / 323378.5943 s
env0_first_0:                 episode reward: -10.3000,                 loss: 0.0042
env0_second_0:                 episode reward: 10.3000,                 loss: 0.0027
env1_first_0:                 episode reward: -10.9000,                 loss: nan
env1_second_0:                 episode reward: 10.9000,                 loss: nan
Episode: 2581/10000 (25.8100%),                 avg. length: 3584.2,                last time consumption/overall running time: 2667.8752s / 326046.4694 s
env0_first_0:                 episode reward: -11.2500,                 loss: 0.0042
env0_second_0:                 episode reward: 11.2500,                 loss: 0.0025
env1_first_0:                 episode reward: -11.5000,                 loss: nan
env1_second_0:                 episode reward: 11.5000,                 loss: nan
Episode: 2601/10000 (26.0100%),                 avg. length: 3251.65,                last time consumption/overall running time: 2420.2529s / 328466.7223 s
env0_first_0:                 episode reward: -10.4500,                 loss: 0.0039
env0_second_0:                 episode reward: 10.4500,                 loss: 0.0025
env1_first_0:                 episode reward: -13.0500,                 loss: nan
env1_second_0:                 episode reward: 13.0500,                 loss: nan
Episode: 2621/10000 (26.2100%),                 avg. length: 3271.55,                last time consumption/overall running time: 2436.0097s / 330902.7320 s
env0_first_0:                 episode reward: -10.6500,                 loss: 0.0039
env0_second_0:                 episode reward: 10.6500,                 loss: 0.0024
env1_first_0:                 episode reward: -14.0500,                 loss: nan
env1_second_0:                 episode reward: 14.0500,                 loss: nan
Episode: 2641/10000 (26.4100%),                 avg. length: 3380.6,                last time consumption/overall running time: 2514.6884s / 333417.4204 s
env0_first_0:                 episode reward: -8.3000,                 loss: 0.0036
env0_second_0:                 episode reward: 8.3000,                 loss: 0.0024
env1_first_0:                 episode reward: -11.6500,                 loss: nan
env1_second_0:                 episode reward: 11.6500,                 loss: nan
Episode: 2661/10000 (26.6100%),                 avg. length: 3133.75,                last time consumption/overall running time: 2329.5610s / 335746.9814 s
env0_first_0:                 episode reward: -12.7000,                 loss: 0.0039
env0_second_0:                 episode reward: 12.7000,                 loss: 0.0025
env1_first_0:                 episode reward: -11.4000,                 loss: nan
env1_second_0:                 episode reward: 11.4000,                 loss: nan
Episode: 2681/10000 (26.8100%),                 avg. length: 3095.75,                last time consumption/overall running time: 2299.6969s / 338046.6782 s
env0_first_0:                 episode reward: -10.8500,                 loss: 0.0040
env0_second_0:                 episode reward: 10.8500,                 loss: 0.0024
env1_first_0:                 episode reward: -12.8500,                 loss: nan
env1_second_0:                 episode reward: 12.8500,                 loss: nan
Episode: 2701/10000 (27.0100%),                 avg. length: 3480.55,                last time consumption/overall running time: 2583.0102s / 340629.6884 s
env0_first_0:                 episode reward: -10.7000,                 loss: 0.0042
env0_second_0:                 episode reward: 10.7000,                 loss: 0.0026
env1_first_0:                 episode reward: -11.2500,                 loss: nan
env1_second_0:                 episode reward: 11.2500,                 loss: nan
Episode: 2721/10000 (27.2100%),                 avg. length: 3191.15,                last time consumption/overall running time: 2370.2553s / 342999.9438 s
env0_first_0:                 episode reward: -9.0000,                 loss: 0.0042
env0_second_0:                 episode reward: 9.0000,                 loss: 0.0028
env1_first_0:                 episode reward: -12.0000,                 loss: nan
env1_second_0:                 episode reward: 12.0000,                 loss: nan
Episode: 2741/10000 (27.4100%),                 avg. length: 3049.05,                last time consumption/overall running time: 2264.4831s / 345264.4268 s
env0_first_0:                 episode reward: -9.9500,                 loss: 0.0043
env0_second_0:                 episode reward: 9.9500,                 loss: 0.0030
env1_first_0:                 episode reward: -11.1500,                 loss: nan
env1_second_0:                 episode reward: 11.1500,                 loss: nan
Episode: 2761/10000 (27.6100%),                 avg. length: 3483.7,                last time consumption/overall running time: 2585.4021s / 347849.8289 s
env0_first_0:                 episode reward: -11.3000,                 loss: 0.0040
env0_second_0:                 episode reward: 11.3000,                 loss: 0.0024
env1_first_0:                 episode reward: -10.9500,                 loss: nan
env1_second_0:                 episode reward: 10.9500,                 loss: nan
Episode: 2781/10000 (27.8100%),                 avg. length: 3402.55,                last time consumption/overall running time: 2521.3759s / 350371.2048 s
env0_first_0:                 episode reward: -11.2000,                 loss: 0.0038
env0_second_0:                 episode reward: 11.2000,                 loss: 0.0023
env1_first_0:                 episode reward: -10.9500,                 loss: nan
env1_second_0:                 episode reward: 10.9500,                 loss: nan
Episode: 2801/10000 (28.0100%),                 avg. length: 3336.1,                last time consumption/overall running time: 2475.1701s / 352846.3748 s
env0_first_0:                 episode reward: -11.6000,                 loss: 0.0039
env0_second_0:                 episode reward: 11.6000,                 loss: 0.0025
env1_first_0:                 episode reward: -11.7500,                 loss: nan
env1_second_0:                 episode reward: 11.7500,                 loss: nan
Episode: 2821/10000 (28.2100%),                 avg. length: 3678.15,                last time consumption/overall running time: 2729.4965s / 355575.8714 s
env0_first_0:                 episode reward: -10.1000,                 loss: 0.0040
env0_second_0:                 episode reward: 10.1000,                 loss: 0.0026
env1_first_0:                 episode reward: -9.1500,                 loss: nan
env1_second_0:                 episode reward: 9.1500,                 loss: nan
Episode: 2841/10000 (28.4100%),                 avg. length: 3648.55,                last time consumption/overall running time: 2706.3606s / 358282.2320 s
env0_first_0:                 episode reward: -10.0500,                 loss: 0.0037
env0_second_0:                 episode reward: 10.0500,                 loss: 0.0022
env1_first_0:                 episode reward: -11.0000,                 loss: nan
env1_second_0:                 episode reward: 11.0000,                 loss: nan
Episode: 2861/10000 (28.6100%),                 avg. length: 3345.05,                last time consumption/overall running time: 2478.6046s / 360760.8366 s
env0_first_0:                 episode reward: -10.0000,                 loss: 0.0040
env0_second_0:                 episode reward: 10.0000,                 loss: 0.0023
env1_first_0:                 episode reward: -8.9500,                 loss: nan
env1_second_0:                 episode reward: 8.9500,                 loss: nan
Episode: 2881/10000 (28.8100%),                 avg. length: 3593.45,                last time consumption/overall running time: 2663.2699s / 363424.1066 s
env0_first_0:                 episode reward: -8.4500,                 loss: 0.0038
env0_second_0:                 episode reward: 8.4500,                 loss: 0.0023
env1_first_0:                 episode reward: -11.0500,                 loss: nan
env1_second_0:                 episode reward: 11.0500,                 loss: nan
Episode: 2901/10000 (29.0100%),                 avg. length: 3239.8,                last time consumption/overall running time: 2401.8084s / 365825.9150 s
env0_first_0:                 episode reward: -10.7500,                 loss: 0.0041
env0_second_0:                 episode reward: 10.7500,                 loss: 0.0028
env1_first_0:                 episode reward: -9.5500,                 loss: nan
env1_second_0:                 episode reward: 9.5500,                 loss: nan
Episode: 2921/10000 (29.2100%),                 avg. length: 3084.05,                last time consumption/overall running time: 2285.8985s / 368111.8135 s
env0_first_0:                 episode reward: -13.5000,                 loss: 0.0042
env0_second_0:                 episode reward: 13.5000,                 loss: 0.0027
env1_first_0:                 episode reward: -11.6000,                 loss: nan
env1_second_0:                 episode reward: 11.6000,                 loss: nan
Episode: 2941/10000 (29.4100%),                 avg. length: 3323.7,                last time consumption/overall running time: 2460.6325s / 370572.4460 s
env0_first_0:                 episode reward: -9.2000,                 loss: 0.0042
env0_second_0:                 episode reward: 9.2000,                 loss: 0.0026
env1_first_0:                 episode reward: -11.6500,                 loss: nan
env1_second_0:                 episode reward: 11.6500,                 loss: nan
Episode: 2961/10000 (29.6100%),                 avg. length: 3418.45,                last time consumption/overall running time: 2532.7285s / 373105.1745 s
env0_first_0:                 episode reward: -10.8500,                 loss: 0.0044
env0_second_0:                 episode reward: 10.8500,                 loss: 0.0024
env1_first_0:                 episode reward: -10.8500,                 loss: nan
env1_second_0:                 episode reward: 10.8500,                 loss: nan
Episode: 2981/10000 (29.8100%),                 avg. length: 3692.55,                last time consumption/overall running time: 2732.3004s / 375837.4749 s
env0_first_0:                 episode reward: -9.6000,                 loss: 0.0041
env0_second_0:                 episode reward: 9.6000,                 loss: 0.0023
env1_first_0:                 episode reward: -10.3000,                 loss: nan
env1_second_0:                 episode reward: 10.3000,                 loss: nan
Episode: 3001/10000 (30.0100%),                 avg. length: 3522.2,                last time consumption/overall running time: 2606.4775s / 378443.9524 s
env0_first_0:                 episode reward: -10.1000,                 loss: 0.0044
env0_second_0:                 episode reward: 10.1000,                 loss: 0.0025
env1_first_0:                 episode reward: -9.2500,                 loss: nan
env1_second_0:                 episode reward: 9.2500,                 loss: nan
Episode: 3021/10000 (30.2100%),                 avg. length: 3502.45,                last time consumption/overall running time: 2591.4525s / 381035.4049 s
env0_first_0:                 episode reward: -9.3500,                 loss: 0.0044
env0_second_0:                 episode reward: 9.3500,                 loss: 0.0027
env1_first_0:                 episode reward: -10.0000,                 loss: nan
env1_second_0:                 episode reward: 10.0000,                 loss: nan
Episode: 3041/10000 (30.4100%),                 avg. length: 3516.65,                last time consumption/overall running time: 2602.3393s / 383637.7442 s
env0_first_0:                 episode reward: -11.2000,                 loss: 0.0042
env0_second_0:                 episode reward: 11.2000,                 loss: 0.0024
env1_first_0:                 episode reward: -11.4500,                 loss: nan
env1_second_0:                 episode reward: 11.4500,                 loss: nan
Episode: 3061/10000 (30.6100%),                 avg. length: 3411.95,                last time consumption/overall running time: 2715.6416s / 386353.3858 s
env0_first_0:                 episode reward: -12.3000,                 loss: 0.0041
env0_second_0:                 episode reward: 12.3000,                 loss: 0.0023
env1_first_0:                 episode reward: -12.3000,                 loss: nan
env1_second_0:                 episode reward: 12.3000,                 loss: nan
Episode: 3081/10000 (30.8100%),                 avg. length: 3372.45,                last time consumption/overall running time: 3036.4927s / 389389.8785 s
env0_first_0:                 episode reward: -11.5500,                 loss: 0.0038
env0_second_0:                 episode reward: 11.5500,                 loss: 0.0023
env1_first_0:                 episode reward: -11.4500,                 loss: nan
env1_second_0:                 episode reward: 11.4500,                 loss: nan
Episode: 3101/10000 (31.0100%),                 avg. length: 3359.1,                last time consumption/overall running time: 3030.1840s / 392420.0625 s
env0_first_0:                 episode reward: -13.1000,                 loss: 0.0040
env0_second_0:                 episode reward: 13.1000,                 loss: 0.0023
env1_first_0:                 episode reward: -11.0000,                 loss: nan
env1_second_0:                 episode reward: 11.0000,                 loss: nan
Episode: 3121/10000 (31.2100%),                 avg. length: 3299.45,                last time consumption/overall running time: 2971.8434s / 395391.9059 s
env0_first_0:                 episode reward: -10.5000,                 loss: 0.0040
env0_second_0:                 episode reward: 10.5000,                 loss: 0.0023
env1_first_0:                 episode reward: -9.6500,                 loss: nan
env1_second_0:                 episode reward: 9.6500,                 loss: nan
Episode: 3141/10000 (31.4100%),                 avg. length: 3569.95,                last time consumption/overall running time: 3212.5550s / 398604.4609 s
env0_first_0:                 episode reward: -10.6500,                 loss: 0.0042
env0_second_0:                 episode reward: 10.6500,                 loss: 0.0023
env1_first_0:                 episode reward: -12.1500,                 loss: nan
env1_second_0:                 episode reward: 12.1500,                 loss: nan
Episode: 3161/10000 (31.6100%),                 avg. length: 3151.6,                last time consumption/overall running time: 2833.7521s / 401438.2130 s
env0_first_0:                 episode reward: -10.9000,                 loss: 0.0037
env0_second_0:                 episode reward: 10.9000,                 loss: 0.0024
env1_first_0:                 episode reward: -12.2000,                 loss: nan
env1_second_0:                 episode reward: 12.2000,                 loss: nan
Episode: 3181/10000 (31.8100%),                 avg. length: 3663.0,                last time consumption/overall running time: 3292.5294s / 404730.7424 s
env0_first_0:                 episode reward: -10.5000,                 loss: 0.0039
env0_second_0:                 episode reward: 10.5000,                 loss: 0.0024
env1_first_0:                 episode reward: -10.4500,                 loss: nan
env1_second_0:                 episode reward: 10.4500,                 loss: nan
Episode: 3201/10000 (32.0100%),                 avg. length: 3515.35,                last time consumption/overall running time: 3159.6497s / 407890.3921 s
env0_first_0:                 episode reward: -8.7000,                 loss: 0.0040
env0_second_0:                 episode reward: 8.7000,                 loss: 0.0025
env1_first_0:                 episode reward: -10.9500,                 loss: nan
env1_second_0:                 episode reward: 10.9500,                 loss: nan
Episode: 3221/10000 (32.2100%),                 avg. length: 3246.35,                last time consumption/overall running time: 2916.5469s / 410806.9390 s
env0_first_0:                 episode reward: -11.7500,                 loss: 0.0040
env0_second_0:                 episode reward: 11.7500,                 loss: 0.0025
env1_first_0:                 episode reward: -10.2000,                 loss: nan
env1_second_0:                 episode reward: 10.2000,                 loss: nan
Episode: 3241/10000 (32.4100%),                 avg. length: 3629.0,                last time consumption/overall running time: 3257.2535s / 414064.1926 s
env0_first_0:                 episode reward: -9.9500,                 loss: 0.0039
env0_second_0:                 episode reward: 9.9500,                 loss: 0.0026
env1_first_0:                 episode reward: -9.6500,                 loss: nan
env1_second_0:                 episode reward: 9.6500,                 loss: nan
Episode: 3261/10000 (32.6100%),                 avg. length: 3233.85,                last time consumption/overall running time: 2898.4114s / 416962.6039 s
env0_first_0:                 episode reward: -12.7000,                 loss: 0.0038
env0_second_0:                 episode reward: 12.7000,                 loss: 0.0022
env1_first_0:                 episode reward: -9.2000,                 loss: nan
env1_second_0:                 episode reward: 9.2000,                 loss: nan
Episode: 3281/10000 (32.8100%),                 avg. length: 3469.4,                last time consumption/overall running time: 3113.5057s / 420076.1096 s
env0_first_0:                 episode reward: -14.2000,                 loss: 0.0040
env0_second_0:                 episode reward: 14.2000,                 loss: 0.0026
env1_first_0:                 episode reward: -10.5000,                 loss: nan
env1_second_0:                 episode reward: 10.5000,                 loss: nan
Episode: 3301/10000 (33.0100%),                 avg. length: 3088.5,                last time consumption/overall running time: 2769.4681s / 422845.5777 s
env0_first_0:                 episode reward: -10.6000,                 loss: 0.0041
env0_second_0:                 episode reward: 10.6000,                 loss: 0.0025
env1_first_0:                 episode reward: -9.7000,                 loss: nan
env1_second_0:                 episode reward: 9.7000,                 loss: nan
Episode: 3321/10000 (33.2100%),                 avg. length: 3399.4,                last time consumption/overall running time: 3048.8164s / 425894.3941 s
env0_first_0:                 episode reward: -9.9000,                 loss: 0.0042
env0_second_0:                 episode reward: 9.9000,                 loss: 0.0025
env1_first_0:                 episode reward: -8.1000,                 loss: nan
env1_second_0:                 episode reward: 8.1000,                 loss: nan
Episode: 3341/10000 (33.4100%),                 avg. length: 3138.2,                last time consumption/overall running time: 2812.8810s / 428707.2751 s
env0_first_0:                 episode reward: -12.8000,                 loss: 0.0050
env0_second_0:                 episode reward: 12.8000,                 loss: 0.0029
env1_first_0:                 episode reward: -13.4000,                 loss: nan
env1_second_0:                 episode reward: 13.4000,                 loss: nan
Episode: 3361/10000 (33.6100%),                 avg. length: 3344.9,                last time consumption/overall running time: 2998.9092s / 431706.1843 s
env0_first_0:                 episode reward: -10.8000,                 loss: 0.0043
env0_second_0:                 episode reward: 10.8000,                 loss: 0.0027
env1_first_0:                 episode reward: -10.2000,                 loss: nan
env1_second_0:                 episode reward: 10.2000,                 loss: nan
Episode: 3381/10000 (33.8100%),                 avg. length: 3769.05,                last time consumption/overall running time: 3379.0225s / 435085.2068 s
env0_first_0:                 episode reward: -7.5500,                 loss: 0.0042
env0_second_0:                 episode reward: 7.5500,                 loss: 0.0025
env1_first_0:                 episode reward: -8.2500,                 loss: nan
env1_second_0:                 episode reward: 8.2500,                 loss: nan
Episode: 3401/10000 (34.0100%),                 avg. length: 3486.05,                last time consumption/overall running time: 3122.9906s / 438208.1974 s
env0_first_0:                 episode reward: -11.2500,                 loss: 0.0042
env0_second_0:                 episode reward: 11.2500,                 loss: 0.0025
env1_first_0:                 episode reward: -8.8000,                 loss: nan
env1_second_0:                 episode reward: 8.8000,                 loss: nan
Episode: 3421/10000 (34.2100%),                 avg. length: 3351.45,                last time consumption/overall running time: 2998.7043s / 441206.9017 s
env0_first_0:                 episode reward: -10.7500,                 loss: 0.0040
env0_second_0:                 episode reward: 10.7500,                 loss: 0.0024
env1_first_0:                 episode reward: -10.7000,                 loss: nan
env1_second_0:                 episode reward: 10.7000,                 loss: nan
Episode: 3441/10000 (34.4100%),                 avg. length: 3281.6,                last time consumption/overall running time: 2934.1596s / 444141.0613 s
env0_first_0:                 episode reward: -10.0000,                 loss: 0.0043
env0_second_0:                 episode reward: 10.0000,                 loss: 0.0025
env1_first_0:                 episode reward: -9.4000,                 loss: nan
env1_second_0:                 episode reward: 9.4000,                 loss: nan
Episode: 3461/10000 (34.6100%),                 avg. length: 3275.1,                last time consumption/overall running time: 2924.6731s / 447065.7344 s
env0_first_0:                 episode reward: -10.4000,                 loss: 0.0044
env0_second_0:                 episode reward: 10.4000,                 loss: 0.0026
env1_first_0:                 episode reward: -10.7500,                 loss: nan
env1_second_0:                 episode reward: 10.7500,                 loss: nan
Episode: 3481/10000 (34.8100%),                 avg. length: 3554.15,                last time consumption/overall running time: 3167.5367s / 450233.2712 s
env0_first_0:                 episode reward: -10.4500,                 loss: 0.0041
env0_second_0:                 episode reward: 10.4500,                 loss: 0.0027
env1_first_0:                 episode reward: -8.5500,                 loss: nan
env1_second_0:                 episode reward: 8.5500,                 loss: nan
Episode: 3501/10000 (35.0100%),                 avg. length: 3583.0,                last time consumption/overall running time: 3188.1792s / 453421.4503 s
env0_first_0:                 episode reward: -8.4500,                 loss: 0.0043
env0_second_0:                 episode reward: 8.4500,                 loss: 0.0025
env1_first_0:                 episode reward: -9.3500,                 loss: nan
env1_second_0:                 episode reward: 9.3500,                 loss: nan
Episode: 3521/10000 (35.2100%),                 avg. length: 3444.2,                last time consumption/overall running time: 3062.5311s / 456483.9815 s
env0_first_0:                 episode reward: -10.6000,                 loss: 0.0048
env0_second_0:                 episode reward: 10.6000,                 loss: 0.0026
env1_first_0:                 episode reward: -10.3500,                 loss: nan
env1_second_0:                 episode reward: 10.3500,                 loss: nan
Episode: 3541/10000 (35.4100%),                 avg. length: 3787.6,                last time consumption/overall running time: 3370.0015s / 459853.9830 s
env0_first_0:                 episode reward: -7.3000,                 loss: 0.0043
env0_second_0:                 episode reward: 7.3000,                 loss: 0.0026
env1_first_0:                 episode reward: -7.7500,                 loss: nan
env1_second_0:                 episode reward: 7.7500,                 loss: nan
Episode: 3561/10000 (35.6100%),                 avg. length: 3905.15,                last time consumption/overall running time: 3478.5294s / 463332.5124 s
env0_first_0:                 episode reward: -8.3000,                 loss: 0.0040
env0_second_0:                 episode reward: 8.3000,                 loss: 0.0025
env1_first_0:                 episode reward: -6.0500,                 loss: nan
env1_second_0:                 episode reward: 6.0500,                 loss: nan
Episode: 3581/10000 (35.8100%),                 avg. length: 3409.55,                last time consumption/overall running time: 3034.3506s / 466366.8630 s
env0_first_0:                 episode reward: -12.5500,                 loss: 0.0042
env0_second_0:                 episode reward: 12.5500,                 loss: 0.0026
env1_first_0:                 episode reward: -9.2000,                 loss: nan
env1_second_0:                 episode reward: 9.2000,                 loss: nan
Episode: 3601/10000 (36.0100%),                 avg. length: 3667.75,                last time consumption/overall running time: 3715.2590s / 470082.1221 s
env0_first_0:                 episode reward: -8.5000,                 loss: 0.0041
env0_second_0:                 episode reward: 8.5000,                 loss: 0.0026
env1_first_0:                 episode reward: -11.0000,                 loss: nan
env1_second_0:                 episode reward: 11.0000,                 loss: nan
Episode: 3621/10000 (36.2100%),                 avg. length: 3879.4,                last time consumption/overall running time: 3949.6492s / 474031.7713 s
env0_first_0:                 episode reward: -7.7000,                 loss: 0.0036
env0_second_0:                 episode reward: 7.7000,                 loss: 0.0024
env1_first_0:                 episode reward: -8.8500,                 loss: nan
env1_second_0:                 episode reward: 8.8500,                 loss: nan
Episode: 3641/10000 (36.4100%),                 avg. length: 3962.35,                last time consumption/overall running time: 4038.6388s / 478070.4101 s
env0_first_0:                 episode reward: -9.1500,                 loss: 0.0037
env0_second_0:                 episode reward: 9.1500,                 loss: 0.0027
env1_first_0:                 episode reward: -8.8000,                 loss: nan
env1_second_0:                 episode reward: 8.8000,                 loss: nan
Episode: 3661/10000 (36.6100%),                 avg. length: 3460.4,                last time consumption/overall running time: 3523.1709s / 481593.5810 s
env0_first_0:                 episode reward: -9.3500,                 loss: 0.0040
env0_second_0:                 episode reward: 9.3500,                 loss: 0.0028
env1_first_0:                 episode reward: -9.4500,                 loss: nan
env1_second_0:                 episode reward: 9.4500,                 loss: nan
Episode: 3681/10000 (36.8100%),                 avg. length: 3465.75,                last time consumption/overall running time: 3532.8552s / 485126.4362 s
env0_first_0:                 episode reward: -10.5500,                 loss: 0.0038
env0_second_0:                 episode reward: 10.5500,                 loss: 0.0027
env1_first_0:                 episode reward: -8.7000,                 loss: nan
env1_second_0:                 episode reward: 8.7000,                 loss: nan
Episode: 3701/10000 (37.0100%),                 avg. length: 3514.0,                last time consumption/overall running time: 3584.9678s / 488711.4041 s
env0_first_0:                 episode reward: -8.9500,                 loss: 0.0038
env0_second_0:                 episode reward: 8.9500,                 loss: 0.0028
env1_first_0:                 episode reward: -8.9000,                 loss: nan
env1_second_0:                 episode reward: 8.9000,                 loss: nan
Episode: 3721/10000 (37.2100%),                 avg. length: 3139.05,                last time consumption/overall running time: 3201.1852s / 491912.5893 s
env0_first_0:                 episode reward: -11.9000,                 loss: 0.0041
env0_second_0:                 episode reward: 11.9000,                 loss: 0.0030
env1_first_0:                 episode reward: -12.7500,                 loss: nan
env1_second_0:                 episode reward: 12.7500,                 loss: nan
Episode: 3741/10000 (37.4100%),                 avg. length: 3238.35,                last time consumption/overall running time: 3301.4366s / 495214.0259 s
env0_first_0:                 episode reward: -13.1500,                 loss: 0.0039
env0_second_0:                 episode reward: 13.1500,                 loss: 0.0027
env1_first_0:                 episode reward: -12.4500,                 loss: nan
env1_second_0:                 episode reward: 12.4500,                 loss: nan
Episode: 3761/10000 (37.6100%),                 avg. length: 3329.05,                last time consumption/overall running time: 3395.2926s / 498609.3184 s
env0_first_0:                 episode reward: -10.7000,                 loss: 0.0039
env0_second_0:                 episode reward: 10.7000,                 loss: 0.0026
env1_first_0:                 episode reward: -11.3500,                 loss: nan
env1_second_0:                 episode reward: 11.3500,                 loss: nan
Episode: 3781/10000 (37.8100%),                 avg. length: 3454.05,                last time consumption/overall running time: 3526.8491s / 502136.1675 s
env0_first_0:                 episode reward: -10.9000,                 loss: 0.0040
env0_second_0:                 episode reward: 10.9000,                 loss: 0.0027
env1_first_0:                 episode reward: -12.1000,                 loss: nan
env1_second_0:                 episode reward: 12.1000,                 loss: nan
Episode: 3801/10000 (38.0100%),                 avg. length: 3160.2,                last time consumption/overall running time: 3225.1015s / 505361.2690 s
env0_first_0:                 episode reward: -9.4000,                 loss: 0.0040
env0_second_0:                 episode reward: 9.4000,                 loss: 0.0027
env1_first_0:                 episode reward: -10.8500,                 loss: nan
env1_second_0:                 episode reward: 10.8500,                 loss: nan
Episode: 3821/10000 (38.2100%),                 avg. length: 3348.45,                last time consumption/overall running time: 3409.4815s / 508770.7505 s
env0_first_0:                 episode reward: -9.1000,                 loss: 0.0040
env0_second_0:                 episode reward: 9.1000,                 loss: 0.0030
env1_first_0:                 episode reward: -10.5500,                 loss: nan
env1_second_0:                 episode reward: 10.5500,                 loss: nan
Episode: 3841/10000 (38.4100%),                 avg. length: 3134.8,                last time consumption/overall running time: 3285.5753s / 512056.3258 s
env0_first_0:                 episode reward: -11.0500,                 loss: 0.0038
env0_second_0:                 episode reward: 11.0500,                 loss: 0.0028
env1_first_0:                 episode reward: -10.9500,                 loss: nan
env1_second_0:                 episode reward: 10.9500,                 loss: nan
Episode: 3861/10000 (38.6100%),                 avg. length: 3319.0,                last time consumption/overall running time: 3480.9008s / 515537.2265 s
env0_first_0:                 episode reward: -8.3000,                 loss: 0.0040
env0_second_0:                 episode reward: 8.3000,                 loss: 0.0030
env1_first_0:                 episode reward: -9.3000,                 loss: nan
env1_second_0:                 episode reward: 9.3000,                 loss: nan
Episode: 3881/10000 (38.8100%),                 avg. length: 3089.5,                last time consumption/overall running time: 3235.8560s / 518773.0825 s
env0_first_0:                 episode reward: -10.7500,                 loss: 0.0041
env0_second_0:                 episode reward: 10.7500,                 loss: 0.0032
env1_first_0:                 episode reward: -10.3500,                 loss: nan
env1_second_0:                 episode reward: 10.3500,                 loss: nan
Episode: 3901/10000 (39.0100%),                 avg. length: 3439.0,                last time consumption/overall running time: 3595.7560s / 522368.8385 s
env0_first_0:                 episode reward: -10.6000,                 loss: 0.0042
env0_second_0:                 episode reward: 10.6000,                 loss: 0.0030
env1_first_0:                 episode reward: -9.2500,                 loss: nan
env1_second_0:                 episode reward: 9.2500,                 loss: nan
Episode: 3921/10000 (39.2100%),                 avg. length: 3694.6,                last time consumption/overall running time: 3788.7579s / 526157.5965 s
env0_first_0:                 episode reward: -8.8500,                 loss: 0.0038
env0_second_0:                 episode reward: 8.8500,                 loss: 0.0028
env1_first_0:                 episode reward: -8.3000,                 loss: nan
env1_second_0:                 episode reward: 8.3000,                 loss: nan
Episode: 3941/10000 (39.4100%),                 avg. length: 3979.65,                last time consumption/overall running time: 3936.0466s / 530093.6430 s
env0_first_0:                 episode reward: -6.7500,                 loss: 0.0038
env0_second_0:                 episode reward: 6.7500,                 loss: 0.0028
env1_first_0:                 episode reward: -6.8500,                 loss: nan
env1_second_0:                 episode reward: 6.8500,                 loss: nan
Episode: 3961/10000 (39.6100%),                 avg. length: 4119.25,                last time consumption/overall running time: 4071.7216s / 534165.3646 s
env0_first_0:                 episode reward: -8.3500,                 loss: 0.0038
env0_second_0:                 episode reward: 8.3500,                 loss: 0.0026
env1_first_0:                 episode reward: -6.5500,                 loss: nan
env1_second_0:                 episode reward: 6.5500,                 loss: nan
Episode: 3981/10000 (39.8100%),                 avg. length: 3676.7,                last time consumption/overall running time: 3633.8733s / 537799.2380 s
env0_first_0:                 episode reward: -8.5000,                 loss: 0.0040
env0_second_0:                 episode reward: 8.5000,                 loss: 0.0027
env1_first_0:                 episode reward: -9.2000,                 loss: nan
env1_second_0:                 episode reward: 9.2000,                 loss: nan
Episode: 4001/10000 (40.0100%),                 avg. length: 3813.3,                last time consumption/overall running time: 3772.8140s / 541572.0520 s
env0_first_0:                 episode reward: -7.8500,                 loss: 0.0041
env0_second_0:                 episode reward: 7.8500,                 loss: 0.0028
env1_first_0:                 episode reward: -7.8000,                 loss: nan
env1_second_0:                 episode reward: 7.8000,                 loss: nan
Episode: 4021/10000 (40.2100%),                 avg. length: 4020.2,                last time consumption/overall running time: 3978.9176s / 545550.9695 s
env0_first_0:                 episode reward: -7.1000,                 loss: 0.0041
env0_second_0:                 episode reward: 7.1000,                 loss: 0.0028
env1_first_0:                 episode reward: -5.9500,                 loss: nan
env1_second_0:                 episode reward: 5.9500,                 loss: nan
Episode: 4041/10000 (40.4100%),                 avg. length: 3774.35,                last time consumption/overall running time: 3738.3252s / 549289.2947 s
env0_first_0:                 episode reward: -6.8500,                 loss: 0.0038
env0_second_0:                 episode reward: 6.8500,                 loss: 0.0027
env1_first_0:                 episode reward: -6.1500,                 loss: nan
env1_second_0:                 episode reward: 6.1500,                 loss: nan
Episode: 4061/10000 (40.6100%),                 avg. length: 3686.45,                last time consumption/overall running time: 3649.4005s / 552938.6953 s
env0_first_0:                 episode reward: -6.8500,                 loss: 0.0036
env0_second_0:                 episode reward: 6.8500,                 loss: 0.0028
env1_first_0:                 episode reward: -7.5000,                 loss: nan
env1_second_0:                 episode reward: 7.5000,                 loss: nan
Episode: 4081/10000 (40.8100%),                 avg. length: 3624.5,                last time consumption/overall running time: 3591.7590s / 556530.4543 s
env0_first_0:                 episode reward: -9.4500,                 loss: 0.0041
env0_second_0:                 episode reward: 9.4500,                 loss: 0.0030
env1_first_0:                 episode reward: -8.7500,                 loss: nan
env1_second_0:                 episode reward: 8.7500,                 loss: nan
Episode: 4101/10000 (41.0100%),                 avg. length: 3430.9,                last time consumption/overall running time: 3399.5083s / 559929.9625 s
env0_first_0:                 episode reward: -8.5500,                 loss: 0.0042
env0_second_0:                 episode reward: 8.5500,                 loss: 0.0030
env1_first_0:                 episode reward: -7.0000,                 loss: nan
env1_second_0:                 episode reward: 7.0000,                 loss: nan
Episode: 4121/10000 (41.2100%),                 avg. length: 3541.0,                last time consumption/overall running time: 3495.4971s / 563425.4596 s
env0_first_0:                 episode reward: -7.6000,                 loss: 0.0042
env0_second_0:                 episode reward: 7.6000,                 loss: 0.0031
env1_first_0:                 episode reward: -6.6000,                 loss: nan
env1_second_0:                 episode reward: 6.6000,                 loss: nan
Episode: 4141/10000 (41.4100%),                 avg. length: 3460.15,                last time consumption/overall running time: 3413.1475s / 566838.6071 s
env0_first_0:                 episode reward: -6.2500,                 loss: 0.0039
env0_second_0:                 episode reward: 6.2500,                 loss: 0.0028
env1_first_0:                 episode reward: -8.9000,                 loss: nan
env1_second_0:                 episode reward: 8.9000,                 loss: nan
Episode: 4161/10000 (41.6100%),                 avg. length: 3593.1,                last time consumption/overall running time: 3543.2234s / 570381.8305 s
env0_first_0:                 episode reward: -7.9500,                 loss: 0.0041
env0_second_0:                 episode reward: 7.9500,                 loss: 0.0033
env1_first_0:                 episode reward: -8.9500,                 loss: nan
env1_second_0:                 episode reward: 8.9500,                 loss: nan
Episode: 4181/10000 (41.8100%),                 avg. length: 3226.05,                last time consumption/overall running time: 3182.1153s / 573563.9458 s
env0_first_0:                 episode reward: -9.0500,                 loss: 0.0045
env0_second_0:                 episode reward: 9.0500,                 loss: 0.0032
env1_first_0:                 episode reward: -8.3000,                 loss: nan
env1_second_0:                 episode reward: 8.3000,                 loss: nan
Episode: 4201/10000 (42.0100%),                 avg. length: 3414.0,                last time consumption/overall running time: 3363.6394s / 576927.5852 s
env0_first_0:                 episode reward: -6.9500,                 loss: 0.0042
env0_second_0:                 episode reward: 6.9500,                 loss: 0.0031
env1_first_0:                 episode reward: -9.3000,                 loss: nan
env1_second_0:                 episode reward: 9.3000,                 loss: nan
Episode: 4221/10000 (42.2100%),                 avg. length: 3493.7,                last time consumption/overall running time: 3449.7187s / 580377.3039 s
env0_first_0:                 episode reward: -9.3000,                 loss: 0.0040
env0_second_0:                 episode reward: 9.3000,                 loss: 0.0031
env1_first_0:                 episode reward: -9.3000,                 loss: nan
env1_second_0:                 episode reward: 9.3000,                 loss: nan
Episode: 4241/10000 (42.4100%),                 avg. length: 3463.35,                last time consumption/overall running time: 3251.3423s / 583628.6462 s
env0_first_0:                 episode reward: -10.1000,                 loss: 0.0039
env0_second_0:                 episode reward: 10.1000,                 loss: 0.0029
env1_first_0:                 episode reward: -7.7000,                 loss: nan
env1_second_0:                 episode reward: 7.7000,                 loss: nan
Episode: 4261/10000 (42.6100%),                 avg. length: 3256.2,                last time consumption/overall running time: 2873.9476s / 586502.5938 s
env0_first_0:                 episode reward: -10.7500,                 loss: 0.0039
env0_second_0:                 episode reward: 10.7500,                 loss: 0.0026
env1_first_0:                 episode reward: -9.5000,                 loss: nan
env1_second_0:                 episode reward: 9.5000,                 loss: nan
Episode: 4281/10000 (42.8100%),                 avg. length: 3111.5,                last time consumption/overall running time: 2728.7350s / 589231.3288 s
env0_first_0:                 episode reward: -9.8500,                 loss: 0.0039
env0_second_0:                 episode reward: 9.8500,                 loss: 0.0027
env1_first_0:                 episode reward: -10.8000,                 loss: nan
env1_second_0:                 episode reward: 10.8000,                 loss: nan
Episode: 4301/10000 (43.0100%),                 avg. length: 3426.9,                last time consumption/overall running time: 3002.7032s / 592234.0321 s
env0_first_0:                 episode reward: -7.2000,                 loss: 0.0041
env0_second_0:                 episode reward: 7.2000,                 loss: 0.0030
env1_first_0:                 episode reward: -8.1500,                 loss: nan
env1_second_0:                 episode reward: 8.1500,                 loss: nan
Episode: 4321/10000 (43.2100%),                 avg. length: 3657.35,                last time consumption/overall running time: 3200.9656s / 595434.9977 s
env0_first_0:                 episode reward: -8.6500,                 loss: 0.0042
env0_second_0:                 episode reward: 8.6500,                 loss: 0.0028
env1_first_0:                 episode reward: -10.3000,                 loss: nan
env1_second_0:                 episode reward: 10.3000,                 loss: nan
Episode: 4341/10000 (43.4100%),                 avg. length: 3673.0,                last time consumption/overall running time: 3222.5926s / 598657.5902 s
env0_first_0:                 episode reward: -9.7000,                 loss: 0.0037
env0_second_0:                 episode reward: 9.7000,                 loss: 0.0024
env1_first_0:                 episode reward: -7.0000,                 loss: nan
env1_second_0:                 episode reward: 7.0000,                 loss: nan
Episode: 4361/10000 (43.6100%),                 avg. length: 3232.2,                last time consumption/overall running time: 2834.7936s / 601492.3838 s
env0_first_0:                 episode reward: -9.3000,                 loss: 0.0041
env0_second_0:                 episode reward: 9.3000,                 loss: 0.0029
env1_first_0:                 episode reward: -8.6000,                 loss: nan
env1_second_0:                 episode reward: 8.6000,                 loss: nan
Episode: 4381/10000 (43.8100%),                 avg. length: 3580.75,                last time consumption/overall running time: 3140.2318s / 604632.6156 s
env0_first_0:                 episode reward: -8.3500,                 loss: 0.0043
env0_second_0:                 episode reward: 8.3500,                 loss: 0.0030
env1_first_0:                 episode reward: -6.5500,                 loss: nan
env1_second_0:                 episode reward: 6.5500,                 loss: nan
Episode: 4401/10000 (44.0100%),                 avg. length: 3526.5,                last time consumption/overall running time: 3057.4297s / 607690.0453 s
env0_first_0:                 episode reward: -9.1500,                 loss: 0.0042
env0_second_0:                 episode reward: 9.1500,                 loss: 0.0028
env1_first_0:                 episode reward: -7.6500,                 loss: nan
env1_second_0:                 episode reward: 7.6500,                 loss: nan
Episode: 4421/10000 (44.2100%),                 avg. length: 3289.2,                last time consumption/overall running time: 2705.7712s / 610395.8165 s
env0_first_0:                 episode reward: -8.2000,                 loss: 0.0041
env0_second_0:                 episode reward: 8.2000,                 loss: 0.0028
env1_first_0:                 episode reward: -8.4000,                 loss: nan
env1_second_0:                 episode reward: 8.4000,                 loss: nan
Episode: 4441/10000 (44.4100%),                 avg. length: 3244.2,                last time consumption/overall running time: 2668.0724s / 613063.8889 s
env0_first_0:                 episode reward: -9.9500,                 loss: 0.0040
env0_second_0:                 episode reward: 9.9500,                 loss: 0.0029
env1_first_0:                 episode reward: -8.4500,                 loss: nan
env1_second_0:                 episode reward: 8.4500,                 loss: nan
Episode: 4461/10000 (44.6100%),                 avg. length: 3059.7,                last time consumption/overall running time: 2519.0293s / 615582.9182 s
env0_first_0:                 episode reward: -11.0000,                 loss: 0.0040
env0_second_0:                 episode reward: 11.0000,                 loss: 0.0027
env1_first_0:                 episode reward: -10.9500,                 loss: nan
env1_second_0:                 episode reward: 10.9500,                 loss: nan
Episode: 4481/10000 (44.8100%),                 avg. length: 3191.15,                last time consumption/overall running time: 2622.1954s / 618205.1136 s
env0_first_0:                 episode reward: -6.0000,                 loss: 0.0043
env0_second_0:                 episode reward: 6.0000,                 loss: 0.0028
env1_first_0:                 episode reward: -7.5000,                 loss: nan
env1_second_0:                 episode reward: 7.5000,                 loss: nan
Episode: 4501/10000 (45.0100%),                 avg. length: 3569.95,                last time consumption/overall running time: 2937.1077s / 621142.2213 s
env0_first_0:                 episode reward: -8.4500,                 loss: 0.0047
env0_second_0:                 episode reward: 8.4500,                 loss: 0.0029
env1_first_0:                 episode reward: -8.9500,                 loss: nan
env1_second_0:                 episode reward: 8.9500,                 loss: nan
Episode: 4521/10000 (45.2100%),                 avg. length: 2952.8,                last time consumption/overall running time: 2428.5800s / 623570.8013 s
env0_first_0:                 episode reward: -9.7500,                 loss: 0.0044
env0_second_0:                 episode reward: 9.7500,                 loss: 0.0029
env1_first_0:                 episode reward: -8.3500,                 loss: nan
env1_second_0:                 episode reward: 8.3500,                 loss: nan
Episode: 4541/10000 (45.4100%),                 avg. length: 3364.65,                last time consumption/overall running time: 2764.2938s / 626335.0951 s
env0_first_0:                 episode reward: -9.5000,                 loss: 0.0041
env0_second_0:                 episode reward: 9.5000,                 loss: 0.0029
env1_first_0:                 episode reward: -10.9000,                 loss: nan
env1_second_0:                 episode reward: 10.9000,                 loss: nan
Episode: 4561/10000 (45.6100%),                 avg. length: 3285.1,                last time consumption/overall running time: 2693.7413s / 629028.8364 s
env0_first_0:                 episode reward: -9.3000,                 loss: 0.0038
env0_second_0:                 episode reward: 9.3000,                 loss: 0.0026
env1_first_0:                 episode reward: -9.2500,                 loss: nan
env1_second_0:                 episode reward: 9.2500,                 loss: nan
Episode: 4581/10000 (45.8100%),                 avg. length: 3684.7,                last time consumption/overall running time: 3018.1669s / 632047.0033 s
env0_first_0:                 episode reward: -7.5000,                 loss: 0.0039
env0_second_0:                 episode reward: 7.5000,                 loss: 0.0025
env1_first_0:                 episode reward: -7.8500,                 loss: nan
env1_second_0:                 episode reward: 7.8500,                 loss: nan
Episode: 4601/10000 (46.0100%),                 avg. length: 3489.05,                last time consumption/overall running time: 2613.3461s / 634660.3494 s
env0_first_0:                 episode reward: -10.5500,                 loss: 0.0038
env0_second_0:                 episode reward: 10.5500,                 loss: 0.0024
env1_first_0:                 episode reward: -8.1500,                 loss: nan
env1_second_0:                 episode reward: 8.1500,                 loss: nan
Episode: 4621/10000 (46.2100%),                 avg. length: 3477.5,                last time consumption/overall running time: 2527.1471s / 637187.4965 s
env0_first_0:                 episode reward: -9.7000,                 loss: 0.0039
env0_second_0:                 episode reward: 9.7000,                 loss: 0.0026
env1_first_0:                 episode reward: -8.2500,                 loss: nan
env1_second_0:                 episode reward: 8.2500,                 loss: nan
Episode: 4641/10000 (46.4100%),                 avg. length: 3124.0,                last time consumption/overall running time: 2271.6455s / 639459.1421 s
env0_first_0:                 episode reward: -11.1000,                 loss: 0.0038
env0_second_0:                 episode reward: 11.1000,                 loss: 0.0024
env1_first_0:                 episode reward: -11.7000,                 loss: nan
env1_second_0:                 episode reward: 11.7000,                 loss: nan
Episode: 4661/10000 (46.6100%),                 avg. length: 3224.4,                last time consumption/overall running time: 2344.3101s / 641803.4522 s
env0_first_0:                 episode reward: -11.9500,                 loss: 0.0041
env0_second_0:                 episode reward: 11.9500,                 loss: 0.0026
env1_first_0:                 episode reward: -10.8500,                 loss: nan
env1_second_0:                 episode reward: 10.8500,                 loss: nan
Episode: 4681/10000 (46.8100%),                 avg. length: 3031.0,                last time consumption/overall running time: 2199.4332s / 644002.8854 s
env0_first_0:                 episode reward: -10.1500,                 loss: 0.0042
env0_second_0:                 episode reward: 10.1500,                 loss: 0.0029
env1_first_0:                 episode reward: -11.1000,                 loss: nan
env1_second_0:                 episode reward: 11.1000,                 loss: nan
Episode: 4701/10000 (47.0100%),                 avg. length: 3300.9,                last time consumption/overall running time: 2230.8947s / 646233.7801 s
env0_first_0:                 episode reward: -9.1500,                 loss: 0.0038
env0_second_0:                 episode reward: 9.1500,                 loss: 0.0028
env1_first_0:                 episode reward: -10.7000,                 loss: nan
env1_second_0:                 episode reward: 10.7000,                 loss: nan
Episode: 4721/10000 (47.2100%),                 avg. length: 3106.85,                last time consumption/overall running time: 1950.8301s / 648184.6101 s
env0_first_0:                 episode reward: -9.7000,                 loss: 0.0042
env0_second_0:                 episode reward: 9.7000,                 loss: 0.0028
env1_first_0:                 episode reward: -11.1000,                 loss: nan
env1_second_0:                 episode reward: 11.1000,                 loss: nan
Episode: 4741/10000 (47.4100%),                 avg. length: 3451.45,                last time consumption/overall running time: 2164.6296s / 650349.2398 s
env0_first_0:                 episode reward: -10.2500,                 loss: 0.0040
env0_second_0:                 episode reward: 10.2500,                 loss: 0.0033
env1_first_0:                 episode reward: -8.0500,                 loss: nan
env1_second_0:                 episode reward: 8.0500,                 loss: nan
Episode: 4761/10000 (47.6100%),                 avg. length: 3485.4,                last time consumption/overall running time: 2182.0896s / 652531.3294 s
env0_first_0:                 episode reward: -7.4500,                 loss: 0.0040
env0_second_0:                 episode reward: 7.4500,                 loss: 0.0025
env1_first_0:                 episode reward: -7.2000,                 loss: nan
env1_second_0:                 episode reward: 7.2000,                 loss: nan
Episode: 4781/10000 (47.8100%),                 avg. length: 3462.6,                last time consumption/overall running time: 2164.6006s / 654695.9300 s
env0_first_0:                 episode reward: -9.1000,                 loss: 0.0036
env0_second_0:                 episode reward: 9.1000,                 loss: 0.0024
env1_first_0:                 episode reward: -10.8000,                 loss: nan
env1_second_0:                 episode reward: 10.8000,                 loss: nan
Episode: 4801/10000 (48.0100%),                 avg. length: 3331.3,                last time consumption/overall running time: 2084.8331s / 656780.7631 s
env0_first_0:                 episode reward: -11.2500,                 loss: 0.0034
env0_second_0:                 episode reward: 11.2500,                 loss: 0.0021
env1_first_0:                 episode reward: -12.0000,                 loss: nan
env1_second_0:                 episode reward: 12.0000,                 loss: nan
Episode: 4821/10000 (48.2100%),                 avg. length: 3602.8,                last time consumption/overall running time: 2156.8494s / 658937.6126 s
env0_first_0:                 episode reward: -10.4500,                 loss: 0.0036
env0_second_0:                 episode reward: 10.4500,                 loss: 0.0022
env1_first_0:                 episode reward: -11.0000,                 loss: nan
env1_second_0:                 episode reward: 11.0000,                 loss: nan
Episode: 4841/10000 (48.4100%),                 avg. length: 3579.8,                last time consumption/overall running time: 2095.6475s / 661033.2600 s
env0_first_0:                 episode reward: -12.2000,                 loss: 0.0037
env0_second_0:                 episode reward: 12.2000,                 loss: 0.0024
env1_first_0:                 episode reward: -11.7500,                 loss: nan
env1_second_0:                 episode reward: 11.7500,                 loss: nan
Episode: 4861/10000 (48.6100%),                 avg. length: 3091.2,                last time consumption/overall running time: 1810.6737s / 662843.9338 s
env0_first_0:                 episode reward: -12.1500,                 loss: 0.0040
env0_second_0:                 episode reward: 12.1500,                 loss: 0.0026
env1_first_0:                 episode reward: -11.2500,                 loss: nan
env1_second_0:                 episode reward: 11.2500,                 loss: nan
Episode: 4881/10000 (48.8100%),                 avg. length: 3473.65,                last time consumption/overall running time: 2037.4042s / 664881.3380 s
env0_first_0:                 episode reward: -8.8500,                 loss: 0.0040
env0_second_0:                 episode reward: 8.8500,                 loss: 0.0025
env1_first_0:                 episode reward: -9.5500,                 loss: nan
env1_second_0:                 episode reward: 9.5500,                 loss: nan
Episode: 4901/10000 (49.0100%),                 avg. length: 3128.45,                last time consumption/overall running time: 1833.2369s / 666714.5749 s
env0_first_0:                 episode reward: -9.2000,                 loss: 0.0041
env0_second_0:                 episode reward: 9.2000,                 loss: 0.0027
env1_first_0:                 episode reward: -11.9000,                 loss: nan
env1_second_0:                 episode reward: 11.9000,                 loss: nan
Episode: 4921/10000 (49.2100%),                 avg. length: 3264.15,                last time consumption/overall running time: 1909.8424s / 668624.4173 s
env0_first_0:                 episode reward: -10.0000,                 loss: 0.0038
env0_second_0:                 episode reward: 10.0000,                 loss: 0.0026
env1_first_0:                 episode reward: -11.0500,                 loss: nan
env1_second_0:                 episode reward: 11.0500,                 loss: nan
Episode: 4941/10000 (49.4100%),                 avg. length: 3487.1,                last time consumption/overall running time: 1955.3466s / 670579.7640 s
env0_first_0:                 episode reward: -10.9000,                 loss: 0.0040
env0_second_0:                 episode reward: 10.9000,                 loss: 0.0026
env1_first_0:                 episode reward: -9.0000,                 loss: nan
env1_second_0:                 episode reward: 9.0000,                 loss: nan
Episode: 4961/10000 (49.6100%),                 avg. length: 3396.35,                last time consumption/overall running time: 1850.7890s / 672430.5530 s
env0_first_0:                 episode reward: -12.9500,                 loss: 0.0036
env0_second_0:                 episode reward: 12.9500,                 loss: 0.0026
env1_first_0:                 episode reward: -9.1500,                 loss: nan
env1_second_0:                 episode reward: 9.1500,                 loss: nan
Episode: 4981/10000 (49.8100%),                 avg. length: 3169.95,                last time consumption/overall running time: 1724.5619s / 674155.1149 s
env0_first_0:                 episode reward: -10.3000,                 loss: 0.0035
env0_second_0:                 episode reward: 10.3000,                 loss: 0.0023
env1_first_0:                 episode reward: -9.7000,                 loss: nan
env1_second_0:                 episode reward: 9.7000,                 loss: nan
Episode: 5001/10000 (50.0100%),                 avg. length: 3151.95,                last time consumption/overall running time: 1642.0262s / 675797.1411 s
env0_first_0:                 episode reward: -12.9000,                 loss: 0.0040
env0_second_0:                 episode reward: 12.9000,                 loss: 0.0026
env1_first_0:                 episode reward: -9.8000,                 loss: nan
env1_second_0:                 episode reward: 9.8000,                 loss: nan
Episode: 5021/10000 (50.2100%),                 avg. length: 3122.15,                last time consumption/overall running time: 1578.5704s / 677375.7115 s
env0_first_0:                 episode reward: -13.6500,                 loss: 0.0042
env0_second_0:                 episode reward: 13.6500,                 loss: 0.0025
env1_first_0:                 episode reward: -10.9000,                 loss: nan
env1_second_0:                 episode reward: 10.9000,                 loss: nan
Episode: 5041/10000 (50.4100%),                 avg. length: 3381.75,                last time consumption/overall running time: 1703.0184s / 679078.7299 s
env0_first_0:                 episode reward: -10.3500,                 loss: 0.0039
env0_second_0:                 episode reward: 10.3500,                 loss: 0.0024
env1_first_0:                 episode reward: -10.2500,                 loss: nan
env1_second_0:                 episode reward: 10.2500,                 loss: nan
Episode: 5061/10000 (50.6100%),                 avg. length: 3437.4,                last time consumption/overall running time: 1731.5518s / 680810.2817 s
env0_first_0:                 episode reward: -9.9000,                 loss: 0.0039
env0_second_0:                 episode reward: 9.9000,                 loss: 0.0025
env1_first_0:                 episode reward: -11.7500,                 loss: nan
env1_second_0:                 episode reward: 11.7500,                 loss: nan
Episode: 5081/10000 (50.8100%),                 avg. length: 3295.45,                last time consumption/overall running time: 1655.6306s / 682465.9123 s
env0_first_0:                 episode reward: -11.9500,                 loss: 0.0036
env0_second_0:                 episode reward: 11.9500,                 loss: 0.0023
env1_first_0:                 episode reward: -9.1500,                 loss: nan
env1_second_0:                 episode reward: 9.1500,                 loss: nan
Episode: 5101/10000 (51.0100%),                 avg. length: 3028.95,                last time consumption/overall running time: 1519.7698s / 683985.6821 s
env0_first_0:                 episode reward: -11.5500,                 loss: 0.0040
env0_second_0:                 episode reward: 11.5500,                 loss: 0.0026
env1_first_0:                 episode reward: -11.8500,                 loss: nan
env1_second_0:                 episode reward: 11.8500,                 loss: nan
Episode: 5121/10000 (51.2100%),                 avg. length: 3110.25,                last time consumption/overall running time: 1557.2193s / 685542.9014 s
env0_first_0:                 episode reward: -11.7500,                 loss: 0.0040
env0_second_0:                 episode reward: 11.7500,                 loss: 0.0028
env1_first_0:                 episode reward: -11.5500,                 loss: nan
env1_second_0:                 episode reward: 11.5500,                 loss: nan
Episode: 5141/10000 (51.4100%),                 avg. length: 3495.1,                last time consumption/overall running time: 1747.6846s / 687290.5860 s
env0_first_0:                 episode reward: -8.5500,                 loss: 0.0038
env0_second_0:                 episode reward: 8.5500,                 loss: 0.0027
env1_first_0:                 episode reward: -10.2500,                 loss: nan
env1_second_0:                 episode reward: 10.2500,                 loss: nan
Episode: 5161/10000 (51.6100%),                 avg. length: 3232.7,                last time consumption/overall running time: 1619.1875s / 688909.7735 s
env0_first_0:                 episode reward: -10.1500,                 loss: 0.0039
env0_second_0:                 episode reward: 10.1500,                 loss: 0.0025
env1_first_0:                 episode reward: -9.0500,                 loss: nan
env1_second_0:                 episode reward: 9.0500,                 loss: nan
Episode: 5181/10000 (51.8100%),                 avg. length: 3411.15,                last time consumption/overall running time: 1704.5342s / 690614.3076 s
env0_first_0:                 episode reward: -10.4500,                 loss: 0.0039
env0_second_0:                 episode reward: 10.4500,                 loss: 0.0025
env1_first_0:                 episode reward: -11.0500,                 loss: nan
env1_second_0:                 episode reward: 11.0500,                 loss: nan
Episode: 5201/10000 (52.0100%),                 avg. length: 3285.1,                last time consumption/overall running time: 1643.4904s / 692257.7980 s
env0_first_0:                 episode reward: -8.6000,                 loss: 0.0038
env0_second_0:                 episode reward: 8.6000,                 loss: 0.0025
env1_first_0:                 episode reward: -9.5500,                 loss: nan
env1_second_0:                 episode reward: 9.5500,                 loss: nan
Episode: 5221/10000 (52.2100%),                 avg. length: 3603.6,                last time consumption/overall running time: 1803.2504s / 694061.0485 s
env0_first_0:                 episode reward: -7.6500,                 loss: 0.0040
env0_second_0:                 episode reward: 7.6500,                 loss: 0.0026
env1_first_0:                 episode reward: -6.0500,                 loss: nan
env1_second_0:                 episode reward: 6.0500,                 loss: nan
Episode: 5241/10000 (52.4100%),                 avg. length: 3402.25,                last time consumption/overall running time: 1701.6312s / 695762.6797 s
env0_first_0:                 episode reward: -9.4500,                 loss: 0.0038
env0_second_0:                 episode reward: 9.4500,                 loss: 0.0024
env1_first_0:                 episode reward: -8.9000,                 loss: nan
env1_second_0:                 episode reward: 8.9000,                 loss: nan
Episode: 5261/10000 (52.6100%),                 avg. length: 3376.05,                last time consumption/overall running time: 1689.1536s / 697451.8333 s
env0_first_0:                 episode reward: -8.0000,                 loss: 0.0041
env0_second_0:                 episode reward: 8.0000,                 loss: 0.0027
env1_first_0:                 episode reward: -6.8000,                 loss: nan
env1_second_0:                 episode reward: 6.8000,                 loss: nan
Episode: 5281/10000 (52.8100%),                 avg. length: 3898.4,                last time consumption/overall running time: 1949.3075s / 699401.1408 s
env0_first_0:                 episode reward: -6.1500,                 loss: 0.0042
env0_second_0:                 episode reward: 6.1500,                 loss: 0.0036
env1_first_0:                 episode reward: -5.1500,                 loss: nan
env1_second_0:                 episode reward: 5.1500,                 loss: nan
Episode: 5301/10000 (53.0100%),                 avg. length: 3837.9,                last time consumption/overall running time: 1915.5030s / 701316.6438 s
env0_first_0:                 episode reward: -7.6000,                 loss: 0.0037
env0_second_0:                 episode reward: 7.6000,                 loss: 0.0026
env1_first_0:                 episode reward: -8.9500,                 loss: nan
env1_second_0:                 episode reward: 8.9500,                 loss: nan
Episode: 5321/10000 (53.2100%),                 avg. length: 3756.45,                last time consumption/overall running time: 1875.0709s / 703191.7147 s
env0_first_0:                 episode reward: -7.2000,                 loss: 0.0036
env0_second_0:                 episode reward: 7.2000,                 loss: 0.0025
env1_first_0:                 episode reward: -8.7500,                 loss: nan
env1_second_0:                 episode reward: 8.7500,                 loss: nan
Episode: 5341/10000 (53.4100%),                 avg. length: 3921.7,                last time consumption/overall running time: 1959.5552s / 705151.2699 s
env0_first_0:                 episode reward: -6.2500,                 loss: 0.0037
env0_second_0:                 episode reward: 6.2500,                 loss: 0.0025
env1_first_0:                 episode reward: -6.4000,                 loss: nan
env1_second_0:                 episode reward: 6.4000,                 loss: nan
Episode: 5361/10000 (53.6100%),                 avg. length: 3734.95,                last time consumption/overall running time: 1864.7920s / 707016.0619 s
env0_first_0:                 episode reward: -7.9000,                 loss: 0.0037
env0_second_0:                 episode reward: 7.9000,                 loss: 0.0025
env1_first_0:                 episode reward: -8.5500,                 loss: nan
env1_second_0:                 episode reward: 8.5500,                 loss: nan
Episode: 5381/10000 (53.8100%),                 avg. length: 3535.35,                last time consumption/overall running time: 1764.2148s / 708780.2767 s
env0_first_0:                 episode reward: -7.5000,                 loss: 0.0042
env0_second_0:                 episode reward: 7.5000,                 loss: 0.0028
env1_first_0:                 episode reward: -6.6500,                 loss: nan
env1_second_0:                 episode reward: 6.6500,                 loss: nan
Episode: 5401/10000 (54.0100%),                 avg. length: 3299.8,                last time consumption/overall running time: 1644.5452s / 710424.8218 s
env0_first_0:                 episode reward: -5.7000,                 loss: 0.0041
env0_second_0:                 episode reward: 5.7000,                 loss: 0.0030
env1_first_0:                 episode reward: -8.9000,                 loss: nan
env1_second_0:                 episode reward: 8.9000,                 loss: nan
Episode: 5421/10000 (54.2100%),                 avg. length: 3686.2,                last time consumption/overall running time: 1837.1448s / 712261.9666 s
env0_first_0:                 episode reward: -8.0500,                 loss: 0.0041
env0_second_0:                 episode reward: 8.0500,                 loss: 0.0029
env1_first_0:                 episode reward: -9.2500,                 loss: nan
env1_second_0:                 episode reward: 9.2500,                 loss: nan
Episode: 5441/10000 (54.4100%),                 avg. length: 3481.45,                last time consumption/overall running time: 1739.3470s / 714001.3136 s
env0_first_0:                 episode reward: -7.2500,                 loss: 0.0041
env0_second_0:                 episode reward: 7.2500,                 loss: 0.0029
env1_first_0:                 episode reward: -8.3500,                 loss: nan
env1_second_0:                 episode reward: 8.3500,                 loss: nan
Episode: 5461/10000 (54.6100%),                 avg. length: 3079.05,                last time consumption/overall running time: 1537.7384s / 715539.0520 s
env0_first_0:                 episode reward: -10.8500,                 loss: 0.0042
env0_second_0:                 episode reward: 10.8500,                 loss: 0.0030
env1_first_0:                 episode reward: -9.0500,                 loss: nan
env1_second_0:                 episode reward: 9.0500,                 loss: nan
Episode: 5481/10000 (54.8100%),                 avg. length: 2944.65,                last time consumption/overall running time: 1471.0463s / 717010.0983 s
env0_first_0:                 episode reward: -9.2500,                 loss: 0.0041
env0_second_0:                 episode reward: 9.2500,                 loss: 0.0031
env1_first_0:                 episode reward: -8.0500,                 loss: nan
env1_second_0:                 episode reward: 8.0500,                 loss: nan
Episode: 5501/10000 (55.0100%),                 avg. length: 3220.5,                last time consumption/overall running time: 1606.9845s / 718617.0828 s
env0_first_0:                 episode reward: -10.1000,                 loss: 0.0045
env0_second_0:                 episode reward: 10.1000,                 loss: 0.0034
env1_first_0:                 episode reward: -8.3500,                 loss: nan
env1_second_0:                 episode reward: 8.3500,                 loss: nan
Episode: 5521/10000 (55.2100%),                 avg. length: 3589.05,                last time consumption/overall running time: 1789.1480s / 720406.2308 s
env0_first_0:                 episode reward: -9.1500,                 loss: 0.0042
env0_second_0:                 episode reward: 9.1500,                 loss: 0.0030
env1_first_0:                 episode reward: -5.1500,                 loss: nan
env1_second_0:                 episode reward: 5.1500,                 loss: nan
Episode: 5541/10000 (55.4100%),                 avg. length: 3293.3,                last time consumption/overall running time: 1641.0161s / 722047.2469 s
env0_first_0:                 episode reward: -10.0500,                 loss: 0.0040
env0_second_0:                 episode reward: 10.0500,                 loss: 0.0028
env1_first_0:                 episode reward: -10.8500,                 loss: nan
env1_second_0:                 episode reward: 10.8500,                 loss: nan
Episode: 5561/10000 (55.6100%),                 avg. length: 3337.65,                last time consumption/overall running time: 1665.4108s / 723712.6577 s
env0_first_0:                 episode reward: -8.3000,                 loss: 0.0040
env0_second_0:                 episode reward: 8.3000,                 loss: 0.0028
env1_first_0:                 episode reward: -8.7500,                 loss: nan
env1_second_0:                 episode reward: 8.7500,                 loss: nan
Episode: 5581/10000 (55.8100%),                 avg. length: 3402.5,                last time consumption/overall running time: 1701.8709s / 725414.5286 s
env0_first_0:                 episode reward: -7.6000,                 loss: 0.0038
env0_second_0:                 episode reward: 7.6000,                 loss: 0.0026
env1_first_0:                 episode reward: -10.5500,                 loss: nan
env1_second_0:                 episode reward: 10.5500,                 loss: nan
Episode: 5601/10000 (56.0100%),                 avg. length: 3284.9,                last time consumption/overall running time: 1635.0217s / 727049.5503 s
env0_first_0:                 episode reward: -10.3000,                 loss: 0.0039
env0_second_0:                 episode reward: 10.3000,                 loss: 0.0027
env1_first_0:                 episode reward: -9.7000,                 loss: nan
env1_second_0:                 episode reward: 9.7000,                 loss: nan
Episode: 5621/10000 (56.2100%),                 avg. length: 3292.8,                last time consumption/overall running time: 1638.3686s / 728687.9189 s
env0_first_0:                 episode reward: -8.9500,                 loss: 0.0037
env0_second_0:                 episode reward: 8.9500,                 loss: 0.0024
env1_first_0:                 episode reward: -10.9000,                 loss: nan
env1_second_0:                 episode reward: 10.9000,                 loss: nan
Episode: 5641/10000 (56.4100%),                 avg. length: 3393.35,                last time consumption/overall running time: 1688.4783s / 730376.3971 s
env0_first_0:                 episode reward: -5.8000,                 loss: 0.0039
env0_second_0:                 episode reward: 5.8000,                 loss: 0.0027
env1_first_0:                 episode reward: -7.0000,                 loss: nan
env1_second_0:                 episode reward: 7.0000,                 loss: nan
Episode: 5661/10000 (56.6100%),                 avg. length: 3380.55,                last time consumption/overall running time: 1680.7254s / 732057.1226 s
env0_first_0:                 episode reward: -9.2500,                 loss: 0.0041
env0_second_0:                 episode reward: 9.2500,                 loss: 0.0028
env1_first_0:                 episode reward: -8.8500,                 loss: nan
env1_second_0:                 episode reward: 8.8500,                 loss: nan
Episode: 5681/10000 (56.8100%),                 avg. length: 3190.05,                last time consumption/overall running time: 1580.1935s / 733637.3160 s
env0_first_0:                 episode reward: -11.8500,                 loss: 0.0040
env0_second_0:                 episode reward: 11.8500,                 loss: 0.0028
env1_first_0:                 episode reward: -10.0000,                 loss: nan
env1_second_0:                 episode reward: 10.0000,                 loss: nan
Episode: 5701/10000 (57.0100%),                 avg. length: 3386.8,                last time consumption/overall running time: 1678.7773s / 735316.0933 s
env0_first_0:                 episode reward: -10.5000,                 loss: 0.0037
env0_second_0:                 episode reward: 10.5000,                 loss: 0.0023
env1_first_0:                 episode reward: -10.0000,                 loss: nan
env1_second_0:                 episode reward: 10.0000,                 loss: nan
Episode: 5721/10000 (57.2100%),                 avg. length: 3293.65,                last time consumption/overall running time: 1630.1921s / 736946.2854 s
env0_first_0:                 episode reward: -9.6000,                 loss: 0.0038
env0_second_0:                 episode reward: 9.6000,                 loss: 0.0025
env1_first_0:                 episode reward: -8.9500,                 loss: nan
env1_second_0:                 episode reward: 8.9500,                 loss: nan
Episode: 5741/10000 (57.4100%),                 avg. length: 3683.25,                last time consumption/overall running time: 1824.7347s / 738771.0201 s
env0_first_0:                 episode reward: -7.4000,                 loss: 0.0037
env0_second_0:                 episode reward: 7.4000,                 loss: 0.0026
env1_first_0:                 episode reward: -8.9000,                 loss: nan
env1_second_0:                 episode reward: 8.9000,                 loss: nan
Episode: 5761/10000 (57.6100%),                 avg. length: 3586.55,                last time consumption/overall running time: 1773.7032s / 740544.7232 s
env0_first_0:                 episode reward: -7.6000,                 loss: 0.0041
env0_second_0:                 episode reward: 7.6000,                 loss: 0.0028
env1_first_0:                 episode reward: -6.7500,                 loss: nan
env1_second_0:                 episode reward: 6.7500,                 loss: nan
Episode: 5781/10000 (57.8100%),                 avg. length: 3439.05,                last time consumption/overall running time: 1701.9918s / 742246.7150 s
env0_first_0:                 episode reward: -9.6500,                 loss: 0.0040
env0_second_0:                 episode reward: 9.6500,                 loss: 0.0027
env1_first_0:                 episode reward: -9.1500,                 loss: nan
env1_second_0:                 episode reward: 9.1500,                 loss: nan
Episode: 5801/10000 (58.0100%),                 avg. length: 3702.75,                last time consumption/overall running time: 1832.6383s / 744079.3534 s
env0_first_0:                 episode reward: -7.4000,                 loss: 0.0039
env0_second_0:                 episode reward: 7.4000,                 loss: 0.0027
env1_first_0:                 episode reward: -7.3000,                 loss: nan
env1_second_0:                 episode reward: 7.3000,                 loss: nan
Episode: 5821/10000 (58.2100%),                 avg. length: 3811.0,                last time consumption/overall running time: 1883.6815s / 745963.0348 s
env0_first_0:                 episode reward: -5.9000,                 loss: 0.0036
env0_second_0:                 episode reward: 5.9000,                 loss: 0.0022
env1_first_0:                 episode reward: -7.5500,                 loss: nan
env1_second_0:                 episode reward: 7.5500,                 loss: nan
Episode: 5841/10000 (58.4100%),                 avg. length: 3656.25,                last time consumption/overall running time: 1808.0972s / 747771.1320 s
env0_first_0:                 episode reward: -8.4000,                 loss: 0.0037
env0_second_0:                 episode reward: 8.4000,                 loss: 0.0026
env1_first_0:                 episode reward: -8.3000,                 loss: nan
env1_second_0:                 episode reward: 8.3000,                 loss: nan
Episode: 5861/10000 (58.6100%),                 avg. length: 3572.7,                last time consumption/overall running time: 1756.2137s / 749527.3457 s
env0_first_0:                 episode reward: -6.5000,                 loss: 0.0045
env0_second_0:                 episode reward: 6.5000,                 loss: 0.0029
env1_first_0:                 episode reward: -6.2000,                 loss: nan
env1_second_0:                 episode reward: 6.2000,                 loss: nan
Episode: 5881/10000 (58.8100%),                 avg. length: 3663.2,                last time consumption/overall running time: 1610.5768s / 751137.9225 s
env0_first_0:                 episode reward: -10.2000,                 loss: 0.0039
env0_second_0:                 episode reward: 10.2000,                 loss: 0.0027
env1_first_0:                 episode reward: -9.4000,                 loss: nan
env1_second_0:                 episode reward: 9.4000,                 loss: nan
Episode: 5901/10000 (59.0100%),                 avg. length: 3477.1,                last time consumption/overall running time: 1528.9761s / 752666.8986 s
env0_first_0:                 episode reward: -12.0000,                 loss: 0.0035
env0_second_0:                 episode reward: 12.0000,                 loss: 0.0024
env1_first_0:                 episode reward: -10.7000,                 loss: nan
env1_second_0:                 episode reward: 10.7000,                 loss: nan
Episode: 5921/10000 (59.2100%),                 avg. length: 3707.95,                last time consumption/overall running time: 1626.7889s / 754293.6875 s
env0_first_0:                 episode reward: -10.6000,                 loss: 0.0034
env0_second_0:                 episode reward: 10.6000,                 loss: 0.0023
env1_first_0:                 episode reward: -9.2000,                 loss: nan
env1_second_0:                 episode reward: 9.2000,                 loss: nan
Episode: 5941/10000 (59.4100%),                 avg. length: 3452.6,                last time consumption/overall running time: 1521.2430s / 755814.9305 s
env0_first_0:                 episode reward: -7.9500,                 loss: 0.0037
env0_second_0:                 episode reward: 7.9500,                 loss: 0.0023
env1_first_0:                 episode reward: -10.9000,                 loss: nan
env1_second_0:                 episode reward: 10.9000,                 loss: nan
Episode: 5961/10000 (59.6100%),                 avg. length: 3252.7,                last time consumption/overall running time: 1433.9906s / 757248.9211 s
env0_first_0:                 episode reward: -10.8000,                 loss: 0.0039
env0_second_0:                 episode reward: 10.8000,                 loss: 0.0027
env1_first_0:                 episode reward: -10.7500,                 loss: nan
env1_second_0:                 episode reward: 10.7500,                 loss: nan
Episode: 5981/10000 (59.8100%),                 avg. length: 3306.35,                last time consumption/overall running time: 1458.4907s / 758707.4118 s
env0_first_0:                 episode reward: -8.3500,                 loss: 0.0038
env0_second_0:                 episode reward: 8.3500,                 loss: 0.0024
env1_first_0:                 episode reward: -7.9500,                 loss: nan
env1_second_0:                 episode reward: 7.9500,                 loss: nan
Episode: 6001/10000 (60.0100%),                 avg. length: 3667.6,                last time consumption/overall running time: 1616.9247s / 760324.3365 s
env0_first_0:                 episode reward: -7.3000,                 loss: 0.0044
env0_second_0:                 episode reward: 7.3000,                 loss: 0.0027
env1_first_0:                 episode reward: -8.3500,                 loss: nan
env1_second_0:                 episode reward: 8.3500,                 loss: nan
Episode: 6021/10000 (60.2100%),                 avg. length: 3648.9,                last time consumption/overall running time: 1607.3897s / 761931.7262 s
env0_first_0:                 episode reward: -6.5500,                 loss: 0.0047
env0_second_0:                 episode reward: 6.5500,                 loss: 0.0026
env1_first_0:                 episode reward: -7.3500,                 loss: nan
env1_second_0:                 episode reward: 7.3500,                 loss: nan
Episode: 6041/10000 (60.4100%),                 avg. length: 3380.65,                last time consumption/overall running time: 1494.5076s / 763426.2338 s
env0_first_0:                 episode reward: -8.9000,                 loss: 0.0042
env0_second_0:                 episode reward: 8.9000,                 loss: 0.0026
env1_first_0:                 episode reward: -8.0000,                 loss: nan
env1_second_0:                 episode reward: 8.0000,                 loss: nan
Episode: 6061/10000 (60.6100%),                 avg. length: 3293.9,                last time consumption/overall running time: 1449.3568s / 764875.5906 s
env0_first_0:                 episode reward: -10.6000,                 loss: 0.0039
env0_second_0:                 episode reward: 10.6000,                 loss: 0.0024
env1_first_0:                 episode reward: -6.6500,                 loss: nan
env1_second_0:                 episode reward: 6.6500,                 loss: nan
Episode: 6081/10000 (60.8100%),                 avg. length: 3544.95,                last time consumption/overall running time: 1558.9079s / 766434.4984 s
env0_first_0:                 episode reward: -8.4000,                 loss: 0.0040
env0_second_0:                 episode reward: 8.4000,                 loss: 0.0025
env1_first_0:                 episode reward: -9.4500,                 loss: nan
env1_second_0:                 episode reward: 9.4500,                 loss: nan
Episode: 6101/10000 (61.0100%),                 avg. length: 3118.9,                last time consumption/overall running time: 1375.2347s / 767809.7332 s
env0_first_0:                 episode reward: -8.6000,                 loss: 0.0042
env0_second_0:                 episode reward: 8.6000,                 loss: 0.0026
env1_first_0:                 episode reward: -8.9000,                 loss: nan
env1_second_0:                 episode reward: 8.9000,                 loss: nan
Episode: 6121/10000 (61.2100%),                 avg. length: 3431.4,                last time consumption/overall running time: 1516.2351s / 769325.9683 s
env0_first_0:                 episode reward: -8.7500,                 loss: 0.0043
env0_second_0:                 episode reward: 8.7500,                 loss: 0.0026
env1_first_0:                 episode reward: -6.8500,                 loss: nan
env1_second_0:                 episode reward: 6.8500,                 loss: nan
Episode: 6141/10000 (61.4100%),                 avg. length: 3438.8,                last time consumption/overall running time: 1521.8323s / 770847.8006 s
env0_first_0:                 episode reward: -8.8000,                 loss: 0.0038
env0_second_0:                 episode reward: 8.8000,                 loss: 0.0026
env1_first_0:                 episode reward: -4.2000,                 loss: nan
env1_second_0:                 episode reward: 4.2000,                 loss: nan
Episode: 6161/10000 (61.6100%),                 avg. length: 3716.85,                last time consumption/overall running time: 1797.1255s / 772644.9261 s
env0_first_0:                 episode reward: -8.5500,                 loss: 0.0038
env0_second_0:                 episode reward: 8.5500,                 loss: 0.0025
env1_first_0:                 episode reward: -8.0000,                 loss: nan
env1_second_0:                 episode reward: 8.0000,                 loss: nan
Episode: 6181/10000 (61.8100%),                 avg. length: 3523.35,                last time consumption/overall running time: 1700.5235s / 774345.4495 s
env0_first_0:                 episode reward: -6.0500,                 loss: 0.0039
env0_second_0:                 episode reward: 6.0500,                 loss: 0.0026
env1_first_0:                 episode reward: -7.7000,                 loss: nan
env1_second_0:                 episode reward: 7.7000,                 loss: nan
Episode: 6201/10000 (62.0100%),                 avg. length: 3751.4,                last time consumption/overall running time: 1811.4787s / 776156.9283 s
env0_first_0:                 episode reward: -7.4500,                 loss: 0.0041
env0_second_0:                 episode reward: 7.4500,                 loss: 0.0026
env1_first_0:                 episode reward: -5.3500,                 loss: nan
env1_second_0:                 episode reward: 5.3500,                 loss: nan
Episode: 6221/10000 (62.2100%),                 avg. length: 3330.65,                last time consumption/overall running time: 1607.8578s / 777764.7861 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0045
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0039
env1_first_0:                 episode reward: 1.9000,                 loss: nan
env1_second_0:                 episode reward: -1.9000,                 loss: nan
Episode: 6241/10000 (62.4100%),                 avg. length: 3435.7,                last time consumption/overall running time: 1661.1850s / 779425.9711 s
env0_first_0:                 episode reward: -6.7500,                 loss: 0.0044
env0_second_0:                 episode reward: 6.7500,                 loss: 0.0030
env1_first_0:                 episode reward: -9.0000,                 loss: nan
env1_second_0:                 episode reward: 9.0000,                 loss: nan
Episode: 6261/10000 (62.6100%),                 avg. length: 3828.1,                last time consumption/overall running time: 1846.9927s / 781272.9638 s
env0_first_0:                 episode reward: -5.7000,                 loss: 0.0042
env0_second_0:                 episode reward: 5.7000,                 loss: 0.0027
env1_first_0:                 episode reward: -8.2000,                 loss: nan
env1_second_0:                 episode reward: 8.2000,                 loss: nan
Episode: 6281/10000 (62.8100%),                 avg. length: 3428.25,                last time consumption/overall running time: 1549.5084s / 782822.4722 s
env0_first_0:                 episode reward: -6.0500,                 loss: 0.0041
env0_second_0:                 episode reward: 6.0500,                 loss: 0.0027
env1_first_0:                 episode reward: -8.7000,                 loss: nan
env1_second_0:                 episode reward: 8.7000,                 loss: nan
Episode: 6301/10000 (63.0100%),                 avg. length: 3589.7,                last time consumption/overall running time: 1578.1158s / 784400.5880 s
env0_first_0:                 episode reward: -7.4000,                 loss: 0.0039
env0_second_0:                 episode reward: 7.4000,                 loss: 0.0026
env1_first_0:                 episode reward: -9.9500,                 loss: nan
env1_second_0:                 episode reward: 9.9500,                 loss: nan
Episode: 6321/10000 (63.2100%),                 avg. length: 3876.95,                last time consumption/overall running time: 1704.9139s / 786105.5019 s
env0_first_0:                 episode reward: -6.3000,                 loss: 0.0041
env0_second_0:                 episode reward: 6.3000,                 loss: 0.0027
env1_first_0:                 episode reward: -7.6000,                 loss: nan
env1_second_0:                 episode reward: 7.6000,                 loss: nan
Episode: 6341/10000 (63.4100%),                 avg. length: 3395.95,                last time consumption/overall running time: 1494.6833s / 787600.1853 s
env0_first_0:                 episode reward: -7.3500,                 loss: 0.0042
env0_second_0:                 episode reward: 7.3500,                 loss: 0.0026
env1_first_0:                 episode reward: -7.8500,                 loss: nan
env1_second_0:                 episode reward: 7.8500,                 loss: nan
Episode: 6361/10000 (63.6100%),                 avg. length: 3247.4,                last time consumption/overall running time: 1417.3313s / 789017.5166 s
env0_first_0:                 episode reward: -9.8000,                 loss: 0.0039
env0_second_0:                 episode reward: 9.8000,                 loss: 0.0026
env1_first_0:                 episode reward: -8.0000,                 loss: nan
env1_second_0:                 episode reward: 8.0000,                 loss: nan
Episode: 6381/10000 (63.8100%),                 avg. length: 3485.85,                last time consumption/overall running time: 1394.4481s / 790411.9647 s
env0_first_0:                 episode reward: -9.0000,                 loss: 0.0040
env0_second_0:                 episode reward: 9.0000,                 loss: 0.0028
env1_first_0:                 episode reward: -9.0500,                 loss: nan
env1_second_0:                 episode reward: 9.0500,                 loss: nan
Episode: 6401/10000 (64.0100%),                 avg. length: 3409.35,                last time consumption/overall running time: 1362.6535s / 791774.6182 s
env0_first_0:                 episode reward: -7.4000,                 loss: 0.0041
env0_second_0:                 episode reward: 7.4000,                 loss: 0.0026
env1_first_0:                 episode reward: -8.2500,                 loss: nan
env1_second_0:                 episode reward: 8.2500,                 loss: nan
Episode: 6421/10000 (64.2100%),                 avg. length: 3382.75,                last time consumption/overall running time: 1349.6583s / 793124.2764 s
env0_first_0:                 episode reward: -9.2000,                 loss: 0.0038
env0_second_0:                 episode reward: 9.2000,                 loss: 0.0024
env1_first_0:                 episode reward: -10.4500,                 loss: nan
env1_second_0:                 episode reward: 10.4500,                 loss: nan
Episode: 6441/10000 (64.4100%),                 avg. length: 3401.65,                last time consumption/overall running time: 1354.1534s / 794478.4298 s
env0_first_0:                 episode reward: -10.3500,                 loss: 0.0038
env0_second_0:                 episode reward: 10.3500,                 loss: 0.0025
env1_first_0:                 episode reward: -9.9000,                 loss: nan
env1_second_0:                 episode reward: 9.9000,                 loss: nan
Episode: 6461/10000 (64.6100%),                 avg. length: 3259.6,                last time consumption/overall running time: 1302.0399s / 795780.4697 s
env0_first_0:                 episode reward: -11.3000,                 loss: 0.0039
env0_second_0:                 episode reward: 11.3000,                 loss: 0.0026
env1_first_0:                 episode reward: -9.4500,                 loss: nan
env1_second_0:                 episode reward: 9.4500,                 loss: nan
Episode: 6481/10000 (64.8100%),                 avg. length: 3535.95,                last time consumption/overall running time: 1414.9169s / 797195.3865 s
env0_first_0:                 episode reward: -11.3000,                 loss: 0.0038
env0_second_0:                 episode reward: 11.3000,                 loss: 0.0028
env1_first_0:                 episode reward: -6.6000,                 loss: nan
env1_second_0:                 episode reward: 6.6000,                 loss: nan
Episode: 6501/10000 (65.0100%),                 avg. length: 3399.15,                last time consumption/overall running time: 1361.6276s / 798557.0141 s
env0_first_0:                 episode reward: -10.0500,                 loss: 0.0039
env0_second_0:                 episode reward: 10.0500,                 loss: 0.0026
env1_first_0:                 episode reward: -9.4500,                 loss: nan
env1_second_0:                 episode reward: 9.4500,                 loss: nan
Episode: 6521/10000 (65.2100%),                 avg. length: 3424.35,                last time consumption/overall running time: 1366.4648s / 799923.4789 s
env0_first_0:                 episode reward: -9.7000,                 loss: 0.0038
env0_second_0:                 episode reward: 9.7000,                 loss: 0.0024
env1_first_0:                 episode reward: -10.5000,                 loss: nan
env1_second_0:                 episode reward: 10.5000,                 loss: nan
Episode: 6541/10000 (65.4100%),                 avg. length: 3090.9,                last time consumption/overall running time: 1234.6954s / 801158.1743 s
env0_first_0:                 episode reward: -8.2500,                 loss: 0.0042
env0_second_0:                 episode reward: 8.2500,                 loss: 0.0028
env1_first_0:                 episode reward: -9.4000,                 loss: nan
env1_second_0:                 episode reward: 9.4000,                 loss: nan
Episode: 6561/10000 (65.6100%),                 avg. length: 3642.45,                last time consumption/overall running time: 1429.4984s / 802587.6728 s
env0_first_0:                 episode reward: -7.1500,                 loss: 0.0044
env0_second_0:                 episode reward: 7.1500,                 loss: 0.0028
env1_first_0:                 episode reward: -9.6500,                 loss: nan
env1_second_0:                 episode reward: 9.6500,                 loss: nan
Episode: 6581/10000 (65.8100%),                 avg. length: 3389.25,                last time consumption/overall running time: 1220.8326s / 803808.5054 s
env0_first_0:                 episode reward: -10.2500,                 loss: 0.0038
env0_second_0:                 episode reward: 10.2500,                 loss: 0.0023
env1_first_0:                 episode reward: -10.5500,                 loss: nan
env1_second_0:                 episode reward: 10.5500,                 loss: nan
Episode: 6601/10000 (66.0100%),                 avg. length: 3663.35,                last time consumption/overall running time: 1322.5534s / 805131.0588 s
env0_first_0:                 episode reward: -10.9500,                 loss: 0.0037
env0_second_0:                 episode reward: 10.9500,                 loss: 0.0024
env1_first_0:                 episode reward: -9.6000,                 loss: nan
env1_second_0:                 episode reward: 9.6000,                 loss: nan
Episode: 6621/10000 (66.2100%),                 avg. length: 3598.95,                last time consumption/overall running time: 1302.2352s / 806433.2940 s
env0_first_0:                 episode reward: -10.3500,                 loss: 0.0035
env0_second_0:                 episode reward: 10.3500,                 loss: 0.0023
env1_first_0:                 episode reward: -10.7500,                 loss: nan
env1_second_0:                 episode reward: 10.7500,                 loss: nan
Episode: 6641/10000 (66.4100%),                 avg. length: 3051.8,                last time consumption/overall running time: 1104.4029s / 807537.6969 s
env0_first_0:                 episode reward: -9.6500,                 loss: 0.0040
env0_second_0:                 episode reward: 9.6500,                 loss: 0.0025
env1_first_0:                 episode reward: -11.6500,                 loss: nan
env1_second_0:                 episode reward: 11.6500,                 loss: nan
Episode: 6661/10000 (66.6100%),                 avg. length: 3635.5,                last time consumption/overall running time: 1305.3226s / 808843.0195 s
env0_first_0:                 episode reward: -7.9000,                 loss: 0.0039
env0_second_0:                 episode reward: 7.9000,                 loss: 0.0026
env1_first_0:                 episode reward: -8.6000,                 loss: nan
env1_second_0:                 episode reward: 8.6000,                 loss: nan
Episode: 6681/10000 (66.8100%),                 avg. length: 3403.75,                last time consumption/overall running time: 1225.0713s / 810068.0907 s
env0_first_0:                 episode reward: -12.0000,                 loss: 0.0038
env0_second_0:                 episode reward: 12.0000,                 loss: 0.0023
env1_first_0:                 episode reward: -12.4500,                 loss: nan
env1_second_0:                 episode reward: 12.4500,                 loss: nan
Episode: 6701/10000 (67.0100%),                 avg. length: 3453.25,                last time consumption/overall running time: 1242.6053s / 811310.6960 s
env0_first_0:                 episode reward: -9.7500,                 loss: 0.0034
env0_second_0:                 episode reward: 9.7500,                 loss: 0.0021
env1_first_0:                 episode reward: -12.5500,                 loss: nan
env1_second_0:                 episode reward: 12.5500,                 loss: nan
Episode: 6721/10000 (67.2100%),                 avg. length: 3186.25,                last time consumption/overall running time: 1139.5290s / 812450.2250 s
env0_first_0:                 episode reward: -11.5000,                 loss: 0.0037
env0_second_0:                 episode reward: 11.5000,                 loss: 0.0025
env1_first_0:                 episode reward: -10.6500,                 loss: nan
env1_second_0:                 episode reward: 10.6500,                 loss: nan
Episode: 6741/10000 (67.4100%),                 avg. length: 3291.05,                last time consumption/overall running time: 1178.7793s / 813629.0043 s
env0_first_0:                 episode reward: -11.9000,                 loss: 0.0039
env0_second_0:                 episode reward: 11.9000,                 loss: 0.0024
env1_first_0:                 episode reward: -8.0000,                 loss: nan
env1_second_0:                 episode reward: 8.0000,                 loss: nan
Episode: 6761/10000 (67.6100%),                 avg. length: 3526.85,                last time consumption/overall running time: 1265.3016s / 814894.3058 s
env0_first_0:                 episode reward: -9.9500,                 loss: 0.0041
env0_second_0:                 episode reward: 9.9500,                 loss: 0.0025
env1_first_0:                 episode reward: -8.6500,                 loss: nan
env1_second_0:                 episode reward: 8.6500,                 loss: nan
Episode: 6781/10000 (67.8100%),                 avg. length: 2996.05,                last time consumption/overall running time: 1069.5965s / 815963.9023 s
env0_first_0:                 episode reward: -10.5000,                 loss: 0.0043
env0_second_0:                 episode reward: 10.5000,                 loss: 0.0027
env1_first_0:                 episode reward: -10.4000,                 loss: nan
env1_second_0:                 episode reward: 10.4000,                 loss: nan
Episode: 6801/10000 (68.0100%),                 avg. length: 3060.9,                last time consumption/overall running time: 1096.2535s / 817060.1558 s
env0_first_0:                 episode reward: -13.4500,                 loss: 0.0041
env0_second_0:                 episode reward: 13.4500,                 loss: 0.0029
env1_first_0:                 episode reward: -13.3500,                 loss: nan
env1_second_0:                 episode reward: 13.3500,                 loss: nan
Episode: 6821/10000 (68.2100%),                 avg. length: 2924.6,                last time consumption/overall running time: 1046.1918s / 818106.3475 s
env0_first_0:                 episode reward: -10.8000,                 loss: 0.0038
env0_second_0:                 episode reward: 10.8000,                 loss: 0.0025
env1_first_0:                 episode reward: -13.4500,                 loss: nan
env1_second_0:                 episode reward: 13.4500,                 loss: nan
Episode: 6841/10000 (68.4100%),                 avg. length: 3417.8,                last time consumption/overall running time: 1221.0444s / 819327.3919 s
env0_first_0:                 episode reward: -10.9000,                 loss: 0.0041
env0_second_0:                 episode reward: 10.9000,                 loss: 0.0028
env1_first_0:                 episode reward: -8.7500,                 loss: nan
env1_second_0:                 episode reward: 8.7500,                 loss: nan
Episode: 6861/10000 (68.6100%),                 avg. length: 3449.3,                last time consumption/overall running time: 1242.9439s / 820570.3358 s
env0_first_0:                 episode reward: -9.1000,                 loss: 0.0041
env0_second_0:                 episode reward: 9.1000,                 loss: 0.0026
env1_first_0:                 episode reward: -9.1500,                 loss: nan
env1_second_0:                 episode reward: 9.1500,                 loss: nan
Episode: 6881/10000 (68.8100%),                 avg. length: 3438.85,                last time consumption/overall running time: 1230.9941s / 821801.3299 s
env0_first_0:                 episode reward: -9.5500,                 loss: 0.0040
env0_second_0:                 episode reward: 9.5500,                 loss: 0.0027
env1_first_0:                 episode reward: -9.6000,                 loss: nan
env1_second_0:                 episode reward: 9.6000,                 loss: nan
Episode: 6901/10000 (69.0100%),                 avg. length: 3692.7,                last time consumption/overall running time: 1326.3683s / 823127.6983 s
env0_first_0:                 episode reward: -9.6500,                 loss: 0.0035
env0_second_0:                 episode reward: 9.6500,                 loss: 0.0024
env1_first_0:                 episode reward: -8.1000,                 loss: nan
env1_second_0:                 episode reward: 8.1000,                 loss: nan
Episode: 6921/10000 (69.2100%),                 avg. length: 3703.6,                last time consumption/overall running time: 1327.9503s / 824455.6486 s
env0_first_0:                 episode reward: -8.2000,                 loss: 0.0038
env0_second_0:                 episode reward: 8.2000,                 loss: 0.0024
env1_first_0:                 episode reward: -7.6000,                 loss: nan
env1_second_0:                 episode reward: 7.6000,                 loss: nan
Episode: 6941/10000 (69.4100%),                 avg. length: 3318.15,                last time consumption/overall running time: 1191.5307s / 825647.1793 s
env0_first_0:                 episode reward: -9.9500,                 loss: 0.0042
env0_second_0:                 episode reward: 9.9500,                 loss: 0.0025
env1_first_0:                 episode reward: -8.2500,                 loss: nan
env1_second_0:                 episode reward: 8.2500,                 loss: nan
Episode: 6961/10000 (69.6100%),                 avg. length: 3330.5,                last time consumption/overall running time: 1195.5894s / 826842.7687 s
env0_first_0:                 episode reward: -9.9500,                 loss: 0.0041
env0_second_0:                 episode reward: 9.9500,                 loss: 0.0026
env1_first_0:                 episode reward: -9.1000,                 loss: nan
env1_second_0:                 episode reward: 9.1000,                 loss: nan
Episode: 6981/10000 (69.8100%),                 avg. length: 3438.7,                last time consumption/overall running time: 1229.7323s / 828072.5010 s
env0_first_0:                 episode reward: -10.0000,                 loss: 0.0039
env0_second_0:                 episode reward: 10.0000,                 loss: 0.0024
env1_first_0:                 episode reward: -7.6000,                 loss: nan
env1_second_0:                 episode reward: 7.6000,                 loss: nan
Episode: 7001/10000 (70.0100%),                 avg. length: 3204.15,                last time consumption/overall running time: 1142.6043s / 829215.1053 s
env0_first_0:                 episode reward: -10.7000,                 loss: 0.0041
env0_second_0:                 episode reward: 10.7000,                 loss: 0.0027
env1_first_0:                 episode reward: -9.7500,                 loss: nan
env1_second_0:                 episode reward: 9.7500,                 loss: nan
Episode: 7021/10000 (70.2100%),                 avg. length: 3207.25,                last time consumption/overall running time: 1147.5164s / 830362.6217 s
env0_first_0:                 episode reward: -8.0000,                 loss: 0.0041
env0_second_0:                 episode reward: 8.0000,                 loss: 0.0026
env1_first_0:                 episode reward: -7.3500,                 loss: nan
env1_second_0:                 episode reward: 7.3500,                 loss: nan
Episode: 7041/10000 (70.4100%),                 avg. length: 2998.25,                last time consumption/overall running time: 1069.8580s / 831432.4797 s
env0_first_0:                 episode reward: -11.7000,                 loss: 0.0040
env0_second_0:                 episode reward: 11.7000,                 loss: 0.0027
env1_first_0:                 episode reward: -11.2000,                 loss: nan
env1_second_0:                 episode reward: 11.2000,                 loss: nan
Episode: 7061/10000 (70.6100%),                 avg. length: 3237.95,                last time consumption/overall running time: 1158.3754s / 832590.8551 s
env0_first_0:                 episode reward: -9.0000,                 loss: 0.0042
env0_second_0:                 episode reward: 9.0000,                 loss: 0.0027
env1_first_0:                 episode reward: -9.3000,                 loss: nan
env1_second_0:                 episode reward: 9.3000,                 loss: nan
Episode: 7081/10000 (70.8100%),                 avg. length: 3504.9,                last time consumption/overall running time: 1254.3136s / 833845.1687 s
env0_first_0:                 episode reward: -10.2500,                 loss: 0.0037
env0_second_0:                 episode reward: 10.2500,                 loss: 0.0026
env1_first_0:                 episode reward: -10.2000,                 loss: nan
env1_second_0:                 episode reward: 10.2000,                 loss: nan
Episode: 7101/10000 (71.0100%),                 avg. length: 3475.4,                last time consumption/overall running time: 1237.9556s / 835083.1243 s
env0_first_0:                 episode reward: -8.2000,                 loss: 0.0040
env0_second_0:                 episode reward: 8.2000,                 loss: 0.0026
env1_first_0:                 episode reward: -8.0000,                 loss: nan
env1_second_0:                 episode reward: 8.0000,                 loss: nan
Episode: 7121/10000 (71.2100%),                 avg. length: 3332.9,                last time consumption/overall running time: 1195.0219s / 836278.1462 s
env0_first_0:                 episode reward: -9.1000,                 loss: 0.0038
env0_second_0:                 episode reward: 9.1000,                 loss: 0.0026
env1_first_0:                 episode reward: -9.5000,                 loss: nan
env1_second_0:                 episode reward: 9.5000,                 loss: nan
Episode: 7141/10000 (71.4100%),                 avg. length: 3052.85,                last time consumption/overall running time: 1088.3352s / 837366.4814 s
env0_first_0:                 episode reward: -12.3500,                 loss: 0.0037
env0_second_0:                 episode reward: 12.3500,                 loss: 0.0026
env1_first_0:                 episode reward: -10.5000,                 loss: nan
env1_second_0:                 episode reward: 10.5000,                 loss: nan
Episode: 7161/10000 (71.6100%),                 avg. length: 2992.65,                last time consumption/overall running time: 1066.5413s / 838433.0227 s
env0_first_0:                 episode reward: -9.4000,                 loss: 0.0040
env0_second_0:                 episode reward: 9.4000,                 loss: 0.0028
env1_first_0:                 episode reward: -11.3000,                 loss: nan
env1_second_0:                 episode reward: 11.3000,                 loss: nan
Episode: 7181/10000 (71.8100%),                 avg. length: 2952.7,                last time consumption/overall running time: 1053.2511s / 839486.2738 s
env0_first_0:                 episode reward: -9.4500,                 loss: 0.0042
env0_second_0:                 episode reward: 9.4500,                 loss: 0.0027
env1_first_0:                 episode reward: -11.7000,                 loss: nan
env1_second_0:                 episode reward: 11.7000,                 loss: nan
Episode: 7201/10000 (72.0100%),                 avg. length: 3215.1,                last time consumption/overall running time: 1147.3671s / 840633.6409 s
env0_first_0:                 episode reward: -10.3000,                 loss: 0.0038
env0_second_0:                 episode reward: 10.3000,                 loss: 0.0027
env1_first_0:                 episode reward: -10.0500,                 loss: nan
env1_second_0:                 episode reward: 10.0500,                 loss: nan
Episode: 7221/10000 (72.2100%),                 avg. length: 2890.0,                last time consumption/overall running time: 1031.2572s / 841664.8981 s
env0_first_0:                 episode reward: -11.5500,                 loss: 0.0041
env0_second_0:                 episode reward: 11.5500,                 loss: 0.0027
env1_first_0:                 episode reward: -10.3000,                 loss: nan
env1_second_0:                 episode reward: 10.3000,                 loss: nan
Episode: 7241/10000 (72.4100%),                 avg. length: 3007.4,                last time consumption/overall running time: 1071.1855s / 842736.0836 s
env0_first_0:                 episode reward: -11.7000,                 loss: 0.0043
env0_second_0:                 episode reward: 11.7000,                 loss: 0.0029
env1_first_0:                 episode reward: -11.9500,                 loss: nan
env1_second_0:                 episode reward: 11.9500,                 loss: nan
Episode: 7261/10000 (72.6100%),                 avg. length: 3394.0,                last time consumption/overall running time: 1208.7109s / 843944.7945 s
env0_first_0:                 episode reward: -9.3000,                 loss: 0.0037
env0_second_0:                 episode reward: 9.3000,                 loss: 0.0027
env1_first_0:                 episode reward: -10.4000,                 loss: nan
env1_second_0:                 episode reward: 10.4000,                 loss: nan
Episode: 7281/10000 (72.8100%),                 avg. length: 3193.2,                last time consumption/overall running time: 1138.1855s / 845082.9800 s
env0_first_0:                 episode reward: -11.2000,                 loss: 0.0039
env0_second_0:                 episode reward: 11.2000,                 loss: 0.0026
env1_first_0:                 episode reward: -11.9000,                 loss: nan
env1_second_0:                 episode reward: 11.9000,                 loss: nan
Episode: 7301/10000 (73.0100%),                 avg. length: 3094.6,                last time consumption/overall running time: 1097.7446s / 846180.7247 s
env0_first_0:                 episode reward: -10.1000,                 loss: 0.0038
env0_second_0:                 episode reward: 10.1000,                 loss: 0.0026
env1_first_0:                 episode reward: -11.1000,                 loss: nan
env1_second_0:                 episode reward: 11.1000,                 loss: nan
Episode: 7321/10000 (73.2100%),                 avg. length: 2949.6,                last time consumption/overall running time: 1047.7749s / 847228.4996 s
env0_first_0:                 episode reward: -9.9500,                 loss: 0.0041
env0_second_0:                 episode reward: 9.9500,                 loss: 0.0028
env1_first_0:                 episode reward: -7.5500,                 loss: nan
env1_second_0:                 episode reward: 7.5500,                 loss: nan
Episode: 7341/10000 (73.4100%),                 avg. length: 2851.1,                last time consumption/overall running time: 1019.1342s / 848247.6338 s
env0_first_0:                 episode reward: -13.0000,                 loss: 0.0044
env0_second_0:                 episode reward: 13.0000,                 loss: 0.0031
env1_first_0:                 episode reward: -11.9000,                 loss: nan
env1_second_0:                 episode reward: 11.9000,                 loss: nan
Episode: 7361/10000 (73.6100%),                 avg. length: 3443.65,                last time consumption/overall running time: 1222.5931s / 849470.2268 s
env0_first_0:                 episode reward: -8.6500,                 loss: 0.0041
env0_second_0:                 episode reward: 8.6500,                 loss: 0.0029
env1_first_0:                 episode reward: -7.4000,                 loss: nan
env1_second_0:                 episode reward: 7.4000,                 loss: nan
Episode: 7381/10000 (73.8100%),                 avg. length: 3506.65,                last time consumption/overall running time: 1245.9338s / 850716.1606 s
env0_first_0:                 episode reward: -9.5000,                 loss: 0.0040
env0_second_0:                 episode reward: 9.5000,                 loss: 0.0029
env1_first_0:                 episode reward: -8.9000,                 loss: nan
env1_second_0:                 episode reward: 8.9000,                 loss: nan
Episode: 7401/10000 (74.0100%),                 avg. length: 3263.15,                last time consumption/overall running time: 1156.4042s / 851872.5648 s
env0_first_0:                 episode reward: -10.1500,                 loss: 0.0040
env0_second_0:                 episode reward: 10.1500,                 loss: 0.0028
env1_first_0:                 episode reward: -10.0000,                 loss: nan
env1_second_0:                 episode reward: 10.0000,                 loss: nan
Episode: 7421/10000 (74.2100%),                 avg. length: 3124.35,                last time consumption/overall running time: 1115.7248s / 852988.2896 s
env0_first_0:                 episode reward: -11.8000,                 loss: 0.0039
env0_second_0:                 episode reward: 11.8000,                 loss: 0.0030
env1_first_0:                 episode reward: -11.4500,                 loss: nan
env1_second_0:                 episode reward: 11.4500,                 loss: nan
Episode: 7441/10000 (74.4100%),                 avg. length: 3120.65,                last time consumption/overall running time: 1107.1701s / 854095.4597 s
env0_first_0:                 episode reward: -11.1000,                 loss: 0.0040
env0_second_0:                 episode reward: 11.1000,                 loss: 0.0029
env1_first_0:                 episode reward: -10.0000,                 loss: nan
env1_second_0:                 episode reward: 10.0000,                 loss: nan
Episode: 7461/10000 (74.6100%),                 avg. length: 3178.8,                last time consumption/overall running time: 1128.7540s / 855224.2137 s
env0_first_0:                 episode reward: -9.1000,                 loss: 0.0038
env0_second_0:                 episode reward: 9.1000,                 loss: 0.0028
env1_first_0:                 episode reward: -9.8500,                 loss: nan
env1_second_0:                 episode reward: 9.8500,                 loss: nan
Episode: 7481/10000 (74.8100%),                 avg. length: 3291.5,                last time consumption/overall running time: 1175.5170s / 856399.7307 s
env0_first_0:                 episode reward: -8.5500,                 loss: 0.0040
env0_second_0:                 episode reward: 8.5500,                 loss: 0.0029
env1_first_0:                 episode reward: -11.4500,                 loss: nan
env1_second_0:                 episode reward: 11.4500,                 loss: nan
Episode: 7501/10000 (75.0100%),                 avg. length: 3487.1,                last time consumption/overall running time: 1236.4849s / 857636.2157 s
env0_first_0:                 episode reward: -10.3500,                 loss: 0.0039
env0_second_0:                 episode reward: 10.3500,                 loss: 0.0029
env1_first_0:                 episode reward: -6.4000,                 loss: nan
env1_second_0:                 episode reward: 6.4000,                 loss: nan
Episode: 7521/10000 (75.2100%),                 avg. length: 3416.5,                last time consumption/overall running time: 1215.3218s / 858851.5374 s
env0_first_0:                 episode reward: -10.3000,                 loss: 0.0040
env0_second_0:                 episode reward: 10.3000,                 loss: 0.0030
env1_first_0:                 episode reward: -12.2000,                 loss: nan
env1_second_0:                 episode reward: 12.2000,                 loss: nan
Episode: 7541/10000 (75.4100%),                 avg. length: 3279.5,                last time consumption/overall running time: 1173.6301s / 860025.1675 s
env0_first_0:                 episode reward: -8.9000,                 loss: 0.0043
env0_second_0:                 episode reward: 8.9000,                 loss: 0.0031
env1_first_0:                 episode reward: -8.0000,                 loss: nan
env1_second_0:                 episode reward: 8.0000,                 loss: nan
Episode: 7561/10000 (75.6100%),                 avg. length: 3257.8,                last time consumption/overall running time: 1159.4755s / 861184.6430 s
env0_first_0:                 episode reward: -11.8000,                 loss: 0.0040
env0_second_0:                 episode reward: 11.8000,                 loss: 0.0030
env1_first_0:                 episode reward: -9.1000,                 loss: nan
env1_second_0:                 episode reward: 9.1000,                 loss: nan
Episode: 7581/10000 (75.8100%),                 avg. length: 3411.05,                last time consumption/overall running time: 1216.6598s / 862401.3027 s
env0_first_0:                 episode reward: -6.9500,                 loss: 0.0040
env0_second_0:                 episode reward: 6.9500,                 loss: 0.0029
env1_first_0:                 episode reward: -9.1500,                 loss: nan
env1_second_0:                 episode reward: 9.1500,                 loss: nan
Episode: 7601/10000 (76.0100%),                 avg. length: 3111.65,                last time consumption/overall running time: 1106.5235s / 863507.8263 s
env0_first_0:                 episode reward: -11.0000,                 loss: 0.0042
env0_second_0:                 episode reward: 11.0000,                 loss: 0.0034
env1_first_0:                 episode reward: -10.4000,                 loss: nan
env1_second_0:                 episode reward: 10.4000,                 loss: nan
Episode: 7621/10000 (76.2100%),                 avg. length: 3397.85,                last time consumption/overall running time: 1212.2319s / 864720.0581 s
env0_first_0:                 episode reward: -10.0000,                 loss: 0.0038
env0_second_0:                 episode reward: 10.0000,                 loss: 0.0029
env1_first_0:                 episode reward: -9.4500,                 loss: nan
env1_second_0:                 episode reward: 9.4500,                 loss: nan
Episode: 7641/10000 (76.4100%),                 avg. length: 3340.85,                last time consumption/overall running time: 1188.8350s / 865908.8932 s
env0_first_0:                 episode reward: -9.8500,                 loss: 0.0039
env0_second_0:                 episode reward: 9.8500,                 loss: 0.0027
env1_first_0:                 episode reward: -8.2000,                 loss: nan
env1_second_0:                 episode reward: 8.2000,                 loss: nan
Episode: 7661/10000 (76.6100%),                 avg. length: 3259.65,                last time consumption/overall running time: 1162.0386s / 867070.9318 s
env0_first_0:                 episode reward: -9.9500,                 loss: 0.0044
env0_second_0:                 episode reward: 9.9500,                 loss: 0.0030
env1_first_0:                 episode reward: -8.4000,                 loss: nan
env1_second_0:                 episode reward: 8.4000,                 loss: nan
Episode: 7681/10000 (76.8100%),                 avg. length: 3530.25,                last time consumption/overall running time: 1263.3666s / 868334.2984 s
env0_first_0:                 episode reward: -5.4500,                 loss: 0.0040
env0_second_0:                 episode reward: 5.4500,                 loss: 0.0028
env1_first_0:                 episode reward: -6.7000,                 loss: nan
env1_second_0:                 episode reward: 6.7000,                 loss: nan
Episode: 7701/10000 (77.0100%),                 avg. length: 3378.25,                last time consumption/overall running time: 1207.5427s / 869541.8411 s
env0_first_0:                 episode reward: -7.8000,                 loss: 0.0043
env0_second_0:                 episode reward: 7.8000,                 loss: 0.0027
env1_first_0:                 episode reward: -9.2500,                 loss: nan
env1_second_0:                 episode reward: 9.2500,                 loss: nan
Episode: 7721/10000 (77.2100%),                 avg. length: 3380.1,                last time consumption/overall running time: 1211.6347s / 870753.4758 s
env0_first_0:                 episode reward: -10.7500,                 loss: 0.0038
env0_second_0:                 episode reward: 10.7500,                 loss: 0.0027
env1_first_0:                 episode reward: -10.3500,                 loss: nan
env1_second_0:                 episode reward: 10.3500,                 loss: nan
Episode: 7741/10000 (77.4100%),                 avg. length: 3233.7,                last time consumption/overall running time: 1152.4915s / 871905.9673 s
env0_first_0:                 episode reward: -9.4000,                 loss: 0.0038
env0_second_0:                 episode reward: 9.4000,                 loss: 0.0030
env1_first_0:                 episode reward: -10.1000,                 loss: nan
env1_second_0:                 episode reward: 10.1000,                 loss: nan
Episode: 7761/10000 (77.6100%),                 avg. length: 3518.65,                last time consumption/overall running time: 1257.5509s / 873163.5182 s
env0_first_0:                 episode reward: -5.4000,                 loss: 0.0045
env0_second_0:                 episode reward: 5.4000,                 loss: 0.0030
env1_first_0:                 episode reward: -8.3500,                 loss: nan
env1_second_0:                 episode reward: 8.3500,                 loss: nan
Episode: 7781/10000 (77.8100%),                 avg. length: 3488.2,                last time consumption/overall running time: 1248.5548s / 874412.0729 s
env0_first_0:                 episode reward: -7.9000,                 loss: 0.0041
env0_second_0:                 episode reward: 7.9000,                 loss: 0.0029
env1_first_0:                 episode reward: -8.9500,                 loss: nan
env1_second_0:                 episode reward: 8.9500,                 loss: nan
Episode: 7801/10000 (78.0100%),                 avg. length: 3358.0,                last time consumption/overall running time: 1201.0552s / 875613.1282 s
env0_first_0:                 episode reward: -9.6500,                 loss: 0.0041
env0_second_0:                 episode reward: 9.6500,                 loss: 0.0029
env1_first_0:                 episode reward: -8.0500,                 loss: nan
env1_second_0:                 episode reward: 8.0500,                 loss: nan
Episode: 7821/10000 (78.2100%),                 avg. length: 3692.55,                last time consumption/overall running time: 1322.9108s / 876936.0390 s
env0_first_0:                 episode reward: -9.3500,                 loss: 0.0040
env0_second_0:                 episode reward: 9.3500,                 loss: 0.0027
env1_first_0:                 episode reward: -7.7000,                 loss: nan
env1_second_0:                 episode reward: 7.7000,                 loss: nan
Episode: 7841/10000 (78.4100%),                 avg. length: 3090.0,                last time consumption/overall running time: 1098.6961s / 878034.7351 s
env0_first_0:                 episode reward: -11.2500,                 loss: 0.0040
env0_second_0:                 episode reward: 11.2500,                 loss: 0.0027
env1_first_0:                 episode reward: -11.8500,                 loss: nan
env1_second_0:                 episode reward: 11.8500,                 loss: nan
Episode: 7861/10000 (78.6100%),                 avg. length: 3251.3,                last time consumption/overall running time: 1169.5160s / 879204.2511 s
env0_first_0:                 episode reward: -9.4000,                 loss: 0.0039
env0_second_0:                 episode reward: 9.4000,                 loss: 0.0027
env1_first_0:                 episode reward: -9.3500,                 loss: nan
env1_second_0:                 episode reward: 9.3500,                 loss: nan
Episode: 7881/10000 (78.8100%),                 avg. length: 3450.7,                last time consumption/overall running time: 1235.6937s / 880439.9448 s
env0_first_0:                 episode reward: -8.2000,                 loss: 0.0039
env0_second_0:                 episode reward: 8.2000,                 loss: 0.0026
env1_first_0:                 episode reward: -8.2000,                 loss: nan
env1_second_0:                 episode reward: 8.2000,                 loss: nan
Episode: 7901/10000 (79.0100%),                 avg. length: 3695.45,                last time consumption/overall running time: 1327.5592s / 881767.5039 s
env0_first_0:                 episode reward: -4.7500,                 loss: 0.0041
env0_second_0:                 episode reward: 4.7500,                 loss: 0.0030
env1_first_0:                 episode reward: -4.8000,                 loss: nan
env1_second_0:                 episode reward: 4.8000,                 loss: nan
Episode: 7921/10000 (79.2100%),                 avg. length: 3219.9,                last time consumption/overall running time: 1159.4581s / 882926.9621 s
env0_first_0:                 episode reward: -7.1500,                 loss: 0.0045
env0_second_0:                 episode reward: 7.1500,                 loss: 0.0030
env1_first_0:                 episode reward: -9.0500,                 loss: nan
env1_second_0:                 episode reward: 9.0500,                 loss: nan
Episode: 7941/10000 (79.4100%),                 avg. length: 3059.1,                last time consumption/overall running time: 1096.5864s / 884023.5485 s
env0_first_0:                 episode reward: -10.2500,                 loss: 0.0046
env0_second_0:                 episode reward: 10.2500,                 loss: 0.0031
env1_first_0:                 episode reward: -7.8500,                 loss: nan
env1_second_0:                 episode reward: 7.8500,                 loss: nan
Episode: 7961/10000 (79.6100%),                 avg. length: 2861.75,                last time consumption/overall running time: 1025.0907s / 885048.6392 s
env0_first_0:                 episode reward: -11.4000,                 loss: 0.0042
env0_second_0:                 episode reward: 11.4000,                 loss: 0.0031
env1_first_0:                 episode reward: -10.1000,                 loss: nan
env1_second_0:                 episode reward: 10.1000,                 loss: nan
Episode: 7981/10000 (79.8100%),                 avg. length: 2574.85,                last time consumption/overall running time: 922.3460s / 885970.9852 s
env0_first_0:                 episode reward: -13.0500,                 loss: 0.0042
env0_second_0:                 episode reward: 13.0500,                 loss: 0.0028
env1_first_0:                 episode reward: -12.7500,                 loss: nan
env1_second_0:                 episode reward: 12.7500,                 loss: nan
Episode: 8001/10000 (80.0100%),                 avg. length: 2801.55,                last time consumption/overall running time: 1002.4395s / 886973.4247 s
env0_first_0:                 episode reward: -12.7500,                 loss: 0.0042
env0_second_0:                 episode reward: 12.7500,                 loss: 0.0028
env1_first_0:                 episode reward: -11.8500,                 loss: nan
env1_second_0:                 episode reward: 11.8500,                 loss: nan
Episode: 8021/10000 (80.2100%),                 avg. length: 3224.05,                last time consumption/overall running time: 1160.4187s / 888133.8434 s
env0_first_0:                 episode reward: -10.9500,                 loss: 0.0038
env0_second_0:                 episode reward: 10.9500,                 loss: 0.0028
env1_first_0:                 episode reward: -11.0000,                 loss: nan
env1_second_0:                 episode reward: 11.0000,                 loss: nan
Episode: 8041/10000 (80.4100%),                 avg. length: 3559.9,                last time consumption/overall running time: 1276.4504s / 889410.2938 s
env0_first_0:                 episode reward: -10.1500,                 loss: 0.0038
env0_second_0:                 episode reward: 10.1500,                 loss: 0.0027
env1_first_0:                 episode reward: -9.8000,                 loss: nan
env1_second_0:                 episode reward: 9.8000,                 loss: nan
Episode: 8061/10000 (80.6100%),                 avg. length: 3244.95,                last time consumption/overall running time: 1159.2215s / 890569.5152 s
env0_first_0:                 episode reward: -10.6000,                 loss: 0.0037
env0_second_0:                 episode reward: 10.6000,                 loss: 0.0026
env1_first_0:                 episode reward: -8.4000,                 loss: nan
env1_second_0:                 episode reward: 8.4000,                 loss: nan
Episode: 8081/10000 (80.8100%),                 avg. length: 3223.15,                last time consumption/overall running time: 1157.7674s / 891727.2827 s
env0_first_0:                 episode reward: -9.0000,                 loss: 0.0037
env0_second_0:                 episode reward: 9.0000,                 loss: 0.0027
env1_first_0:                 episode reward: -11.1500,                 loss: nan
env1_second_0:                 episode reward: 11.1500,                 loss: nan
Episode: 8101/10000 (81.0100%),                 avg. length: 3224.35,                last time consumption/overall running time: 1156.2786s / 892883.5613 s
env0_first_0:                 episode reward: -12.0000,                 loss: 0.0039
env0_second_0:                 episode reward: 12.0000,                 loss: 0.0027
env1_first_0:                 episode reward: -10.9000,                 loss: nan
env1_second_0:                 episode reward: 10.9000,                 loss: nan
Episode: 8121/10000 (81.2100%),                 avg. length: 3363.55,                last time consumption/overall running time: 1207.6187s / 894091.1800 s
env0_first_0:                 episode reward: -10.5000,                 loss: 0.0042
env0_second_0:                 episode reward: 10.5000,                 loss: 0.0030
env1_first_0:                 episode reward: -8.4500,                 loss: nan
env1_second_0:                 episode reward: 8.4500,                 loss: nan
Episode: 8141/10000 (81.4100%),                 avg. length: 3697.2,                last time consumption/overall running time: 1331.3678s / 895422.5478 s
env0_first_0:                 episode reward: -7.4000,                 loss: 0.0038
env0_second_0:                 episode reward: 7.4000,                 loss: 0.0028
env1_first_0:                 episode reward: -7.1000,                 loss: nan
env1_second_0:                 episode reward: 7.1000,                 loss: nan
Episode: 8161/10000 (81.6100%),                 avg. length: 3460.1,                last time consumption/overall running time: 1248.1075s / 896670.6553 s
env0_first_0:                 episode reward: -8.9000,                 loss: 0.0037
env0_second_0:                 episode reward: 8.9000,                 loss: 0.0026
env1_first_0:                 episode reward: -8.9000,                 loss: nan
env1_second_0:                 episode reward: 8.9000,                 loss: nan
Episode: 8181/10000 (81.8100%),                 avg. length: 3210.35,                last time consumption/overall running time: 1152.5433s / 897823.1986 s
env0_first_0:                 episode reward: -7.1000,                 loss: 0.0039
env0_second_0:                 episode reward: 7.1000,                 loss: 0.0028
env1_first_0:                 episode reward: -11.4000,                 loss: nan
env1_second_0:                 episode reward: 11.4000,                 loss: nan
Episode: 8201/10000 (82.0100%),                 avg. length: 3629.35,                last time consumption/overall running time: 1307.6606s / 899130.8592 s
env0_first_0:                 episode reward: -7.1000,                 loss: 0.0041
env0_second_0:                 episode reward: 7.1000,                 loss: 0.0029
env1_first_0:                 episode reward: -6.1500,                 loss: nan
env1_second_0:                 episode reward: 6.1500,                 loss: nan
Episode: 8221/10000 (82.2100%),                 avg. length: 3848.9,                last time consumption/overall running time: 1383.2022s / 900514.0615 s
env0_first_0:                 episode reward: -7.3500,                 loss: 0.0039
env0_second_0:                 episode reward: 7.3500,                 loss: 0.0029
env1_first_0:                 episode reward: -7.5000,                 loss: nan
env1_second_0:                 episode reward: 7.5000,                 loss: nan
Episode: 8241/10000 (82.4100%),                 avg. length: 3611.9,                last time consumption/overall running time: 1303.5507s / 901817.6122 s
env0_first_0:                 episode reward: -8.0000,                 loss: 0.0041
env0_second_0:                 episode reward: 8.0000,                 loss: 0.0033
env1_first_0:                 episode reward: -9.9000,                 loss: nan
env1_second_0:                 episode reward: 9.9000,                 loss: nan
Episode: 8261/10000 (82.6100%),                 avg. length: 3735.2,                last time consumption/overall running time: 1345.2930s / 903162.9052 s
env0_first_0:                 episode reward: -6.6500,                 loss: 0.0041
env0_second_0:                 episode reward: 6.6500,                 loss: 0.0029
env1_first_0:                 episode reward: -5.7500,                 loss: nan
env1_second_0:                 episode reward: 5.7500,                 loss: nan
Episode: 8281/10000 (82.8100%),                 avg. length: 3307.3,                last time consumption/overall running time: 1190.9952s / 904353.9004 s
env0_first_0:                 episode reward: -10.5000,                 loss: 0.0043
env0_second_0:                 episode reward: 10.5000,                 loss: 0.0029
env1_first_0:                 episode reward: -9.1500,                 loss: nan
env1_second_0:                 episode reward: 9.1500,                 loss: nan
Episode: 8301/10000 (83.0100%),                 avg. length: 3214.9,                last time consumption/overall running time: 1154.1683s / 905508.0687 s
env0_first_0:                 episode reward: -10.1000,                 loss: 0.0040
env0_second_0:                 episode reward: 10.1000,                 loss: 0.0027
env1_first_0:                 episode reward: -10.7500,                 loss: nan
env1_second_0:                 episode reward: 10.7500,                 loss: nan
Episode: 8321/10000 (83.2100%),                 avg. length: 3189.15,                last time consumption/overall running time: 1144.8258s / 906652.8945 s
env0_first_0:                 episode reward: -10.1000,                 loss: 0.0042
env0_second_0:                 episode reward: 10.1000,                 loss: 0.0030
env1_first_0:                 episode reward: -10.6500,                 loss: nan
env1_second_0:                 episode reward: 10.6500,                 loss: nan
Episode: 8341/10000 (83.4100%),                 avg. length: 3011.35,                last time consumption/overall running time: 1077.1060s / 907730.0005 s
env0_first_0:                 episode reward: -11.8000,                 loss: 0.0042
env0_second_0:                 episode reward: 11.8000,                 loss: 0.0035
env1_first_0:                 episode reward: -12.6500,                 loss: nan
env1_second_0:                 episode reward: 12.6500,                 loss: nan
Episode: 8361/10000 (83.6100%),                 avg. length: 3532.0,                last time consumption/overall running time: 1266.4032s / 908996.4037 s
env0_first_0:                 episode reward: -12.5500,                 loss: 0.0043
env0_second_0:                 episode reward: 12.5500,                 loss: 0.0030
env1_first_0:                 episode reward: -12.8500,                 loss: nan
env1_second_0:                 episode reward: 12.8500,                 loss: nan
Episode: 8381/10000 (83.8100%),                 avg. length: 3820.65,                last time consumption/overall running time: 1371.9531s / 910368.3568 s
env0_first_0:                 episode reward: -4.8000,                 loss: 0.0044
env0_second_0:                 episode reward: 4.8000,                 loss: 0.0035
env1_first_0:                 episode reward: -5.7000,                 loss: nan
env1_second_0:                 episode reward: 5.7000,                 loss: nan
Episode: 8401/10000 (84.0100%),                 avg. length: 3673.65,                last time consumption/overall running time: 1316.2325s / 911684.5893 s
env0_first_0:                 episode reward: -6.3500,                 loss: 0.0039
env0_second_0:                 episode reward: 6.3500,                 loss: 0.0028
env1_first_0:                 episode reward: -9.9500,                 loss: nan
env1_second_0:                 episode reward: 9.9500,                 loss: nan
Episode: 8421/10000 (84.2100%),                 avg. length: 3875.1,                last time consumption/overall running time: 1388.4275s / 913073.0168 s
env0_first_0:                 episode reward: -5.7500,                 loss: 0.0040
env0_second_0:                 episode reward: 5.7500,                 loss: 0.0042
env1_first_0:                 episode reward: -7.4000,                 loss: nan
env1_second_0:                 episode reward: 7.4000,                 loss: nan
Episode: 8441/10000 (84.4100%),                 avg. length: 3469.25,                last time consumption/overall running time: 1239.5572s / 914312.5740 s
env0_first_0:                 episode reward: -7.3500,                 loss: 0.0043
env0_second_0:                 episode reward: 7.3500,                 loss: 0.0058
env1_first_0:                 episode reward: -8.4500,                 loss: nan
env1_second_0:                 episode reward: 8.4500,                 loss: nan
Episode: 8461/10000 (84.6100%),                 avg. length: 3368.9,                last time consumption/overall running time: 1204.0647s / 915516.6387 s
env0_first_0:                 episode reward: -7.3000,                 loss: 0.0045
env0_second_0:                 episode reward: 7.3000,                 loss: 0.0055
env1_first_0:                 episode reward: -9.2500,                 loss: nan
env1_second_0:                 episode reward: 9.2500,                 loss: nan
Episode: 8481/10000 (84.8100%),                 avg. length: 3548.4,                last time consumption/overall running time: 1269.2179s / 916785.8566 s
env0_first_0:                 episode reward: -7.5000,                 loss: 0.0041
env0_second_0:                 episode reward: 7.5000,                 loss: 0.0030
env1_first_0:                 episode reward: -8.9000,                 loss: nan
env1_second_0:                 episode reward: 8.9000,                 loss: nan
Episode: 8501/10000 (85.0100%),                 avg. length: 3551.75,                last time consumption/overall running time: 1267.4366s / 918053.2932 s
env0_first_0:                 episode reward: -6.7500,                 loss: 0.0039
env0_second_0:                 episode reward: 6.7500,                 loss: 0.0028
env1_first_0:                 episode reward: -8.6500,                 loss: nan
env1_second_0:                 episode reward: 8.6500,                 loss: nan
Episode: 8521/10000 (85.2100%),                 avg. length: 3297.4,                last time consumption/overall running time: 1178.7848s / 919232.0781 s
env0_first_0:                 episode reward: -7.9000,                 loss: 0.0042
env0_second_0:                 episode reward: 7.9000,                 loss: 0.0031
env1_first_0:                 episode reward: -5.0500,                 loss: nan
env1_second_0:                 episode reward: 5.0500,                 loss: nan
Episode: 8541/10000 (85.4100%),                 avg. length: 3310.8,                last time consumption/overall running time: 1183.9937s / 920416.0718 s
env0_first_0:                 episode reward: -9.9000,                 loss: 0.0039
env0_second_0:                 episode reward: 9.9000,                 loss: 0.0030
env1_first_0:                 episode reward: -8.9500,                 loss: nan
env1_second_0:                 episode reward: 8.9500,                 loss: nan
Episode: 8561/10000 (85.6100%),                 avg. length: 3024.3,                last time consumption/overall running time: 1080.5934s / 921496.6651 s
env0_first_0:                 episode reward: -12.5500,                 loss: 0.0040
env0_second_0:                 episode reward: 12.5500,                 loss: 0.0027
env1_first_0:                 episode reward: -12.5500,                 loss: nan
env1_second_0:                 episode reward: 12.5500,                 loss: nan
Episode: 8581/10000 (85.8100%),                 avg. length: 3380.45,                last time consumption/overall running time: 1208.0125s / 922704.6776 s
env0_first_0:                 episode reward: -8.8500,                 loss: 0.0041
env0_second_0:                 episode reward: 8.8500,                 loss: 0.0029
env1_first_0:                 episode reward: -7.4000,                 loss: nan
env1_second_0:                 episode reward: 7.4000,                 loss: nan
Episode: 8601/10000 (86.0100%),                 avg. length: 3130.45,                last time consumption/overall running time: 1117.8474s / 923822.5250 s
env0_first_0:                 episode reward: -10.6500,                 loss: 0.0039
env0_second_0:                 episode reward: 10.6500,                 loss: 0.0027
env1_first_0:                 episode reward: -11.2500,                 loss: nan
env1_second_0:                 episode reward: 11.2500,                 loss: nan
Episode: 8621/10000 (86.2100%),                 avg. length: 3339.85,                last time consumption/overall running time: 1192.5650s / 925015.0901 s
env0_first_0:                 episode reward: -10.4500,                 loss: 0.0038
env0_second_0:                 episode reward: 10.4500,                 loss: 0.0028
env1_first_0:                 episode reward: -11.7500,                 loss: nan
env1_second_0:                 episode reward: 11.7500,                 loss: nan
Episode: 8641/10000 (86.4100%),                 avg. length: 3490.95,                last time consumption/overall running time: 1242.2299s / 926257.3199 s
env0_first_0:                 episode reward: -8.6000,                 loss: 0.0041
env0_second_0:                 episode reward: 8.6000,                 loss: 0.0026
env1_first_0:                 episode reward: -8.1500,                 loss: nan
env1_second_0:                 episode reward: 8.1500,                 loss: nan
Episode: 8661/10000 (86.6100%),                 avg. length: 3747.95,                last time consumption/overall running time: 1337.8276s / 927595.1475 s
env0_first_0:                 episode reward: -8.9000,                 loss: 0.0036
env0_second_0:                 episode reward: 8.9000,                 loss: 0.0026
env1_first_0:                 episode reward: -8.4000,                 loss: nan
env1_second_0:                 episode reward: 8.4000,                 loss: nan
Episode: 8681/10000 (86.8100%),                 avg. length: 3055.9,                last time consumption/overall running time: 1086.5710s / 928681.7185 s
env0_first_0:                 episode reward: -10.7000,                 loss: 0.0040
env0_second_0:                 episode reward: 10.7000,                 loss: 0.0027
env1_first_0:                 episode reward: -8.0500,                 loss: nan
env1_second_0:                 episode reward: 8.0500,                 loss: nan
Episode: 8701/10000 (87.0100%),                 avg. length: 3204.4,                last time consumption/overall running time: 1144.3739s / 929826.0924 s
env0_first_0:                 episode reward: -10.0000,                 loss: 0.0044
env0_second_0:                 episode reward: 10.0000,                 loss: 0.0031
env1_first_0:                 episode reward: -12.1500,                 loss: nan
env1_second_0:                 episode reward: 12.1500,                 loss: nan
Episode: 8721/10000 (87.2100%),                 avg. length: 2770.05,                last time consumption/overall running time: 986.2819s / 930812.3743 s
env0_first_0:                 episode reward: -12.2000,                 loss: 0.0047
env0_second_0:                 episode reward: 12.2000,                 loss: 0.0031
env1_first_0:                 episode reward: -11.2500,                 loss: nan
env1_second_0:                 episode reward: 11.2500,                 loss: nan
Episode: 8741/10000 (87.4100%),                 avg. length: 2677.4,                last time consumption/overall running time: 956.9427s / 931769.3170 s
env0_first_0:                 episode reward: -13.8000,                 loss: 0.0042
env0_second_0:                 episode reward: 13.8000,                 loss: 0.0027
env1_first_0:                 episode reward: -11.9000,                 loss: nan
env1_second_0:                 episode reward: 11.9000,                 loss: nan
Episode: 8761/10000 (87.6100%),                 avg. length: 2721.9,                last time consumption/overall running time: 971.7454s / 932741.0624 s
env0_first_0:                 episode reward: -11.1000,                 loss: 0.0044
env0_second_0:                 episode reward: 11.1000,                 loss: 0.0031
env1_first_0:                 episode reward: -13.2000,                 loss: nan
env1_second_0:                 episode reward: 13.2000,                 loss: nan
Episode: 8781/10000 (87.8100%),                 avg. length: 2825.35,                last time consumption/overall running time: 1007.7577s / 933748.8201 s
env0_first_0:                 episode reward: -10.5000,                 loss: 0.0044
env0_second_0:                 episode reward: 10.5000,                 loss: 0.0029
env1_first_0:                 episode reward: -12.7500,                 loss: nan
env1_second_0:                 episode reward: 12.7500,                 loss: nan
Episode: 8801/10000 (88.0100%),                 avg. length: 2906.1,                last time consumption/overall running time: 1038.4771s / 934787.2972 s
env0_first_0:                 episode reward: -12.2000,                 loss: 0.0042
env0_second_0:                 episode reward: 12.2000,                 loss: 0.0029
env1_first_0:                 episode reward: -13.4500,                 loss: nan
env1_second_0:                 episode reward: 13.4500,                 loss: nan
Episode: 8821/10000 (88.2100%),                 avg. length: 3025.05,                last time consumption/overall running time: 1080.2828s / 935867.5800 s
env0_first_0:                 episode reward: -11.2500,                 loss: 0.0043
env0_second_0:                 episode reward: 11.2500,                 loss: 0.0030
env1_first_0:                 episode reward: -11.2000,                 loss: nan
env1_second_0:                 episode reward: 11.2000,                 loss: nan
Episode: 8841/10000 (88.4100%),                 avg. length: 2888.9,                last time consumption/overall running time: 1031.8667s / 936899.4467 s
env0_first_0:                 episode reward: -11.7000,                 loss: 0.0043
env0_second_0:                 episode reward: 11.7000,                 loss: 0.0026
env1_first_0:                 episode reward: -12.3000,                 loss: nan
env1_second_0:                 episode reward: 12.3000,                 loss: nan
Episode: 8861/10000 (88.6100%),                 avg. length: 2713.9,                last time consumption/overall running time: 969.2276s / 937868.6743 s
env0_first_0:                 episode reward: -9.4500,                 loss: 0.0042
env0_second_0:                 episode reward: 9.4500,                 loss: 0.0035
env1_first_0:                 episode reward: -9.9500,                 loss: nan
env1_second_0:                 episode reward: 9.9500,                 loss: nan
Episode: 8881/10000 (88.8100%),                 avg. length: 3175.8,                last time consumption/overall running time: 1136.1992s / 939004.8735 s
env0_first_0:                 episode reward: -11.4000,                 loss: 0.0047
env0_second_0:                 episode reward: 11.4000,                 loss: 0.0039
env1_first_0:                 episode reward: -11.9000,                 loss: nan
env1_second_0:                 episode reward: 11.9000,                 loss: nan
Episode: 8901/10000 (89.0100%),                 avg. length: 3372.5,                last time consumption/overall running time: 1202.3466s / 940207.2201 s
env0_first_0:                 episode reward: -7.3000,                 loss: 0.0040
env0_second_0:                 episode reward: 7.3000,                 loss: 0.0025
env1_first_0:                 episode reward: -6.2500,                 loss: nan
env1_second_0:                 episode reward: 6.2500,                 loss: nan
Episode: 8921/10000 (89.2100%),                 avg. length: 3417.95,                last time consumption/overall running time: 1221.1960s / 941428.4161 s
env0_first_0:                 episode reward: -12.8500,                 loss: 0.0040
env0_second_0:                 episode reward: 12.8500,                 loss: 0.0025
env1_first_0:                 episode reward: -10.4000,                 loss: nan
env1_second_0:                 episode reward: 10.4000,                 loss: nan
Episode: 8941/10000 (89.4100%),                 avg. length: 3399.2,                last time consumption/overall running time: 1212.4963s / 942640.9125 s
env0_first_0:                 episode reward: -9.7500,                 loss: 0.0042
env0_second_0:                 episode reward: 9.7500,                 loss: 0.0026
env1_first_0:                 episode reward: -11.0500,                 loss: nan
env1_second_0:                 episode reward: 11.0500,                 loss: nan
Episode: 8961/10000 (89.6100%),                 avg. length: 3264.8,                last time consumption/overall running time: 1159.8086s / 943800.7211 s
env0_first_0:                 episode reward: -8.9000,                 loss: 0.0041
env0_second_0:                 episode reward: 8.9000,                 loss: 0.0026
env1_first_0:                 episode reward: -11.2000,                 loss: nan
env1_second_0:                 episode reward: 11.2000,                 loss: nan
Episode: 8981/10000 (89.8100%),                 avg. length: 3759.9,                last time consumption/overall running time: 1344.0502s / 945144.7713 s
env0_first_0:                 episode reward: -7.1500,                 loss: 0.0039
env0_second_0:                 episode reward: 7.1500,                 loss: 0.0026
env1_first_0:                 episode reward: -7.9500,                 loss: nan
env1_second_0:                 episode reward: 7.9500,                 loss: nan
Episode: 9001/10000 (90.0100%),                 avg. length: 3489.9,                last time consumption/overall running time: 1245.2132s / 946389.9845 s
env0_first_0:                 episode reward: -10.9000,                 loss: 0.0038
env0_second_0:                 episode reward: 10.9000,                 loss: 0.0027
env1_first_0:                 episode reward: -9.2500,                 loss: nan
env1_second_0:                 episode reward: 9.2500,                 loss: nan
Episode: 9021/10000 (90.2100%),                 avg. length: 3715.8,                last time consumption/overall running time: 1326.4982s / 947716.4827 s
env0_first_0:                 episode reward: -6.4000,                 loss: 0.0040
env0_second_0:                 episode reward: 6.4000,                 loss: 0.0027
env1_first_0:                 episode reward: -5.5000,                 loss: nan
env1_second_0:                 episode reward: 5.5000,                 loss: nan
Episode: 9041/10000 (90.4100%),                 avg. length: 3551.55,                last time consumption/overall running time: 1266.5687s / 948983.0514 s
env0_first_0:                 episode reward: -9.0000,                 loss: 0.0044
env0_second_0:                 episode reward: 9.0000,                 loss: 0.0030
env1_first_0:                 episode reward: -7.7000,                 loss: nan
env1_second_0:                 episode reward: 7.7000,                 loss: nan
Episode: 9061/10000 (90.6100%),                 avg. length: 3520.6,                last time consumption/overall running time: 1253.3250s / 950236.3764 s
env0_first_0:                 episode reward: -7.7000,                 loss: 0.0041
env0_second_0:                 episode reward: 7.7000,                 loss: 0.0028
env1_first_0:                 episode reward: -10.6000,                 loss: nan
env1_second_0:                 episode reward: 10.6000,                 loss: nan
Episode: 9081/10000 (90.8100%),                 avg. length: 3503.9,                last time consumption/overall running time: 1250.9305s / 951487.3069 s
env0_first_0:                 episode reward: -10.0000,                 loss: 0.0041
env0_second_0:                 episode reward: 10.0000,                 loss: 0.0027
env1_first_0:                 episode reward: -8.1000,                 loss: nan
env1_second_0:                 episode reward: 8.1000,                 loss: nan
Episode: 9101/10000 (91.0100%),                 avg. length: 3140.8,                last time consumption/overall running time: 1063.7858s / 952551.0927 s
env0_first_0:                 episode reward: -10.8000,                 loss: 0.0044
env0_second_0:                 episode reward: 10.8000,                 loss: 0.0028
env1_first_0:                 episode reward: -9.6000,                 loss: nan
env1_second_0:                 episode reward: 9.6000,                 loss: nan
Episode: 9121/10000 (91.2100%),                 avg. length: 3053.0,                last time consumption/overall running time: 977.2911s / 953528.3838 s
env0_first_0:                 episode reward: -13.4500,                 loss: 0.0043
env0_second_0:                 episode reward: 13.4500,                 loss: 0.0029
env1_first_0:                 episode reward: -11.0000,                 loss: nan
env1_second_0:                 episode reward: 11.0000,                 loss: nan
Episode: 9141/10000 (91.4100%),                 avg. length: 3300.4,                last time consumption/overall running time: 1055.0381s / 954583.4219 s
env0_first_0:                 episode reward: -11.4500,                 loss: 0.0041
env0_second_0:                 episode reward: 11.4500,                 loss: 0.0027
env1_first_0:                 episode reward: -10.6000,                 loss: nan
env1_second_0:                 episode reward: 10.6000,                 loss: nan
Episode: 9161/10000 (91.6100%),                 avg. length: 3249.8,                last time consumption/overall running time: 1039.7630s / 955623.1849 s
env0_first_0:                 episode reward: -7.4000,                 loss: 0.0043
env0_second_0:                 episode reward: 7.4000,                 loss: 0.0029
env1_first_0:                 episode reward: -10.5500,                 loss: nan
env1_second_0:                 episode reward: 10.5500,                 loss: nan
Episode: 9181/10000 (91.8100%),                 avg. length: 3240.8,                last time consumption/overall running time: 1040.4508s / 956663.6358 s
env0_first_0:                 episode reward: -10.6000,                 loss: 0.0040
env0_second_0:                 episode reward: 10.6000,                 loss: 0.0030
env1_first_0:                 episode reward: -11.9500,                 loss: nan
env1_second_0:                 episode reward: 11.9500,                 loss: nan
Episode: 9201/10000 (92.0100%),                 avg. length: 3324.05,                last time consumption/overall running time: 1068.1619s / 957731.7977 s
env0_first_0:                 episode reward: -12.4000,                 loss: 0.0040
env0_second_0:                 episode reward: 12.4000,                 loss: 0.0028
env1_first_0:                 episode reward: -11.0500,                 loss: nan
env1_second_0:                 episode reward: 11.0500,                 loss: nan
Episode: 9221/10000 (92.2100%),                 avg. length: 3830.7,                last time consumption/overall running time: 1226.0917s / 958957.8893 s
env0_first_0:                 episode reward: -7.5000,                 loss: 0.0040
env0_second_0:                 episode reward: 7.5000,                 loss: 0.0028
env1_first_0:                 episode reward: -7.6000,                 loss: nan
env1_second_0:                 episode reward: 7.6000,                 loss: nan
Episode: 9241/10000 (92.4100%),                 avg. length: 3336.55,                last time consumption/overall running time: 1066.9674s / 960024.8567 s
env0_first_0:                 episode reward: -10.5000,                 loss: 0.0042
env0_second_0:                 episode reward: 10.5000,                 loss: 0.0028
env1_first_0:                 episode reward: -9.2000,                 loss: nan
env1_second_0:                 episode reward: 9.2000,                 loss: nan
Episode: 9261/10000 (92.6100%),                 avg. length: 3580.35,                last time consumption/overall running time: 1145.4350s / 961170.2917 s
env0_first_0:                 episode reward: -8.3500,                 loss: 0.0039
env0_second_0:                 episode reward: 8.3500,                 loss: 0.0026
env1_first_0:                 episode reward: -8.7500,                 loss: nan
env1_second_0:                 episode reward: 8.7500,                 loss: nan
Episode: 9281/10000 (92.8100%),                 avg. length: 3338.15,                last time consumption/overall running time: 1068.2495s / 962238.5413 s
env0_first_0:                 episode reward: -11.3500,                 loss: 0.0040
env0_second_0:                 episode reward: 11.3500,                 loss: 0.0026
env1_first_0:                 episode reward: -10.0000,                 loss: nan
env1_second_0:                 episode reward: 10.0000,                 loss: nan
Episode: 9301/10000 (93.0100%),                 avg. length: 3168.1,                last time consumption/overall running time: 1012.3688s / 963250.9101 s
env0_first_0:                 episode reward: -10.1500,                 loss: 0.0038
env0_second_0:                 episode reward: 10.1500,                 loss: 0.0025
env1_first_0:                 episode reward: -13.7500,                 loss: nan
env1_second_0:                 episode reward: 13.7500,                 loss: nan
Episode: 9321/10000 (93.2100%),                 avg. length: 3427.65,                last time consumption/overall running time: 1100.4849s / 964351.3950 s
env0_first_0:                 episode reward: -7.1000,                 loss: 0.0042
env0_second_0:                 episode reward: 7.1000,                 loss: 0.0026
env1_first_0:                 episode reward: -9.5500,                 loss: nan
env1_second_0:                 episode reward: 9.5500,                 loss: nan
Episode: 9341/10000 (93.4100%),                 avg. length: 3377.85,                last time consumption/overall running time: 1080.4616s / 965431.8566 s
env0_first_0:                 episode reward: -10.0500,                 loss: 0.0043
env0_second_0:                 episode reward: 10.0500,                 loss: 0.0025
env1_first_0:                 episode reward: -9.7500,                 loss: nan
env1_second_0:                 episode reward: 9.7500,                 loss: nan
Episode: 9361/10000 (93.6100%),                 avg. length: 3384.6,                last time consumption/overall running time: 1084.3247s / 966516.1813 s
env0_first_0:                 episode reward: -7.8500,                 loss: 0.0045
env0_second_0:                 episode reward: 7.8500,                 loss: 0.0027
env1_first_0:                 episode reward: -10.3500,                 loss: nan
env1_second_0:                 episode reward: 10.3500,                 loss: nan
Episode: 9381/10000 (93.8100%),                 avg. length: 3396.8,                last time consumption/overall running time: 1088.0698s / 967604.2510 s
env0_first_0:                 episode reward: -9.7500,                 loss: 0.0043
env0_second_0:                 episode reward: 9.7500,                 loss: 0.0031
env1_first_0:                 episode reward: -11.3000,                 loss: nan
env1_second_0:                 episode reward: 11.3000,                 loss: nan
Episode: 9401/10000 (94.0100%),                 avg. length: 3022.0,                last time consumption/overall running time: 966.7001s / 968570.9511 s
env0_first_0:                 episode reward: -12.3500,                 loss: 0.0046
env0_second_0:                 episode reward: 12.3500,                 loss: 0.0033
env1_first_0:                 episode reward: -8.6500,                 loss: nan
env1_second_0:                 episode reward: 8.6500,                 loss: nan
Episode: 9421/10000 (94.2100%),                 avg. length: 3607.25,                last time consumption/overall running time: 1156.6548s / 969727.6059 s
env0_first_0:                 episode reward: -9.2500,                 loss: 0.0042
env0_second_0:                 episode reward: 9.2500,                 loss: 0.0029
env1_first_0:                 episode reward: -4.9500,                 loss: nan
env1_second_0:                 episode reward: 4.9500,                 loss: nan
Episode: 9441/10000 (94.4100%),                 avg. length: 2929.15,                last time consumption/overall running time: 937.9133s / 970665.5193 s
env0_first_0:                 episode reward: -12.5500,                 loss: 0.0043
env0_second_0:                 episode reward: 12.5500,                 loss: 0.0054
env1_first_0:                 episode reward: -11.4000,                 loss: nan
env1_second_0:                 episode reward: 11.4000,                 loss: nan
Episode: 9461/10000 (94.6100%),                 avg. length: 2862.65,                last time consumption/overall running time: 914.1576s / 971579.6769 s
env0_first_0:                 episode reward: -14.0000,                 loss: 0.0044
env0_second_0:                 episode reward: 14.0000,                 loss: 0.0032
env1_first_0:                 episode reward: -11.5000,                 loss: nan
env1_second_0:                 episode reward: 11.5000,                 loss: nan
Episode: 9481/10000 (94.8100%),                 avg. length: 2711.85,                last time consumption/overall running time: 865.4660s / 972445.1428 s
env0_first_0:                 episode reward: -12.1000,                 loss: 0.0048
env0_second_0:                 episode reward: 12.1000,                 loss: 0.0032
env1_first_0:                 episode reward: -11.0500,                 loss: nan
env1_second_0:                 episode reward: 11.0500,                 loss: nan
Episode: 9501/10000 (95.0100%),                 avg. length: 3064.55,                last time consumption/overall running time: 983.5533s / 973428.6962 s
env0_first_0:                 episode reward: -12.3000,                 loss: 0.0045
env0_second_0:                 episode reward: 12.3000,                 loss: 0.0030
env1_first_0:                 episode reward: -8.3000,                 loss: nan
env1_second_0:                 episode reward: 8.3000,                 loss: nan
Episode: 9521/10000 (95.2100%),                 avg. length: 2944.75,                last time consumption/overall running time: 945.6731s / 974374.3692 s
env0_first_0:                 episode reward: -9.6000,                 loss: 0.0046
env0_second_0:                 episode reward: 9.6000,                 loss: 0.0029
env1_first_0:                 episode reward: -12.5000,                 loss: nan
env1_second_0:                 episode reward: 12.5000,                 loss: nan
Episode: 9541/10000 (95.4100%),                 avg. length: 3048.55,                last time consumption/overall running time: 977.4097s / 975351.7789 s
env0_first_0:                 episode reward: -9.5500,                 loss: 0.0044
env0_second_0:                 episode reward: 9.5500,                 loss: 0.0030
env1_first_0:                 episode reward: -11.0000,                 loss: nan
env1_second_0:                 episode reward: 11.0000,                 loss: nan
Episode: 9561/10000 (95.6100%),                 avg. length: 3271.7,                last time consumption/overall running time: 1044.9224s / 976396.7013 s
env0_first_0:                 episode reward: -7.6000,                 loss: 0.0044
env0_second_0:                 episode reward: 7.6000,                 loss: 0.0028
env1_first_0:                 episode reward: -5.3500,                 loss: nan
env1_second_0:                 episode reward: 5.3500,                 loss: nan
Episode: 9581/10000 (95.8100%),                 avg. length: 3209.8,                last time consumption/overall running time: 1028.8235s / 977425.5248 s
env0_first_0:                 episode reward: -9.2500,                 loss: 0.0046
env0_second_0:                 episode reward: 9.2500,                 loss: 0.0030
env1_first_0:                 episode reward: -10.0000,                 loss: nan
env1_second_0:                 episode reward: 10.0000,                 loss: nan
Episode: 9601/10000 (96.0100%),                 avg. length: 3444.0,                last time consumption/overall running time: 1105.7919s / 978531.3167 s
env0_first_0:                 episode reward: -8.8000,                 loss: 0.0042
env0_second_0:                 episode reward: 8.8000,                 loss: 0.0030
env1_first_0:                 episode reward: -8.5500,                 loss: nan
env1_second_0:                 episode reward: 8.5500,                 loss: nan
Episode: 9621/10000 (96.2100%),                 avg. length: 3354.3,                last time consumption/overall running time: 1071.6902s / 979603.0069 s
env0_first_0:                 episode reward: -7.4500,                 loss: 0.0044
env0_second_0:                 episode reward: 7.4500,                 loss: 0.0031
env1_first_0:                 episode reward: -7.1500,                 loss: nan
env1_second_0:                 episode reward: 7.1500,                 loss: nan
Episode: 9641/10000 (96.4100%),                 avg. length: 3405.95,                last time consumption/overall running time: 1083.7347s / 980686.7416 s
env0_first_0:                 episode reward: -10.3500,                 loss: 0.0043
env0_second_0:                 episode reward: 10.3500,                 loss: 0.0029
env1_first_0:                 episode reward: -10.3000,                 loss: nan
env1_second_0:                 episode reward: 10.3000,                 loss: nan
Episode: 9661/10000 (96.6100%),                 avg. length: 3138.35,                last time consumption/overall running time: 1002.2184s / 981688.9600 s
env0_first_0:                 episode reward: -12.3000,                 loss: 0.0041
env0_second_0:                 episode reward: 12.3000,                 loss: 0.0028
env1_first_0:                 episode reward: -9.1500,                 loss: nan
env1_second_0:                 episode reward: 9.1500,                 loss: nan
Episode: 9681/10000 (96.8100%),                 avg. length: 3158.15,                last time consumption/overall running time: 1013.7693s / 982702.7293 s
env0_first_0:                 episode reward: -10.2000,                 loss: 0.0043
env0_second_0:                 episode reward: 10.2000,                 loss: 0.0027
env1_first_0:                 episode reward: -9.1500,                 loss: nan
env1_second_0:                 episode reward: 9.1500,                 loss: nan
Episode: 9701/10000 (97.0100%),                 avg. length: 3302.55,                last time consumption/overall running time: 1049.4481s / 983752.1774 s
env0_first_0:                 episode reward: -8.1000,                 loss: 0.0045
env0_second_0:                 episode reward: 8.1000,                 loss: 0.0030
env1_first_0:                 episode reward: -8.8000,                 loss: nan
env1_second_0:                 episode reward: 8.8000,                 loss: nan
Episode: 9721/10000 (97.2100%),                 avg. length: 3660.45,                last time consumption/overall running time: 1168.9349s / 984921.1122 s
env0_first_0:                 episode reward: -11.3000,                 loss: 0.0041
env0_second_0:                 episode reward: 11.3000,                 loss: 0.0029
env1_first_0:                 episode reward: -10.0500,                 loss: nan
env1_second_0:                 episode reward: 10.0500,                 loss: nan
Episode: 9741/10000 (97.4100%),                 avg. length: 3504.45,                last time consumption/overall running time: 1116.0248s / 986037.1370 s
env0_first_0:                 episode reward: -8.8000,                 loss: 0.0041
env0_second_0:                 episode reward: 8.8000,                 loss: 0.0028
env1_first_0:                 episode reward: -5.2500,                 loss: nan
env1_second_0:                 episode reward: 5.2500,                 loss: nan
Episode: 9761/10000 (97.6100%),                 avg. length: 3864.1,                last time consumption/overall running time: 1231.0131s / 987268.1501 sLoad pong_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(6)
Load pong_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(6)
/home/zihan/research/MARS/mars/rollout.py:21: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rollout_normal(env, model, save_id, args)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/shape_base.py:420: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arrays = [asanyarray(arr) for arr in arrays]
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

env0_first_0:                 episode reward: -9.5500,                 loss: 0.0039
env0_second_0:                 episode reward: 9.5500,                 loss: 0.0028
env1_first_0:                 episode reward: -5.8000,                 loss: nan
env1_second_0:                 episode reward: 5.8000,                 loss: nan
Episode: 9781/10000 (97.8100%),                 avg. length: 3369.9,                last time consumption/overall running time: 1079.5530s / 988347.7031 s
env0_first_0:                 episode reward: -7.8000,                 loss: 0.0037
env0_second_0:                 episode reward: 7.8000,                 loss: 0.0029
env1_first_0:                 episode reward: -9.1000,                 loss: nan
env1_second_0:                 episode reward: 9.1000,                 loss: nan
Episode: 9801/10000 (98.0100%),                 avg. length: 3069.1,                last time consumption/overall running time: 985.4601s / 989333.1632 s
env0_first_0:                 episode reward: -12.2500,                 loss: 0.0039
env0_second_0:                 episode reward: 12.2500,                 loss: 0.0028
env1_first_0:                 episode reward: -13.1500,                 loss: nan
env1_second_0:                 episode reward: 13.1500,                 loss: nan
Episode: 9821/10000 (98.2100%),                 avg. length: 2900.6,                last time consumption/overall running time: 932.8689s / 990266.0321 s
env0_first_0:                 episode reward: -11.2500,                 loss: 0.0042
env0_second_0:                 episode reward: 11.2500,                 loss: 0.0027
env1_first_0:                 episode reward: -12.7000,                 loss: nan
env1_second_0:                 episode reward: 12.7000,                 loss: nan
Episode: 9841/10000 (98.4100%),                 avg. length: 3260.45,                last time consumption/overall running time: 1044.0641s / 991310.0962 s
env0_first_0:                 episode reward: -11.2500,                 loss: 0.0039
env0_second_0:                 episode reward: 11.2500,                 loss: 0.0029
env1_first_0:                 episode reward: -9.1000,                 loss: nan
env1_second_0:                 episode reward: 9.1000,                 loss: nan
Episode: 9861/10000 (98.6100%),                 avg. length: 3588.95,                last time consumption/overall running time: 1144.3418s / 992454.4380 s
env0_first_0:                 episode reward: -8.2500,                 loss: 0.0038
env0_second_0:                 episode reward: 8.2500,                 loss: 0.0025
env1_first_0:                 episode reward: -9.0000,                 loss: nan
env1_second_0:                 episode reward: 9.0000,                 loss: nan
Episode: 9881/10000 (98.8100%),                 avg. length: 3114.5,                last time consumption/overall running time: 994.7443s / 993449.1823 s
env0_first_0:                 episode reward: -12.0500,                 loss: 0.0041
env0_second_0:                 episode reward: 12.0500,                 loss: 0.0028
env1_first_0:                 episode reward: -10.8500,                 loss: nan
env1_second_0:                 episode reward: 10.8500,                 loss: nan
Episode: 9901/10000 (99.0100%),                 avg. length: 3331.95,                last time consumption/overall running time: 1063.9710s / 994513.1533 s
env0_first_0:                 episode reward: -11.2000,                 loss: 0.0041
env0_second_0:                 episode reward: 11.2000,                 loss: 0.0030
env1_first_0:                 episode reward: -9.4000,                 loss: nan
env1_second_0:                 episode reward: 9.4000,                 loss: nan
Episode: 9921/10000 (99.2100%),                 avg. length: 3529.1,                last time consumption/overall running time: 1125.8590s / 995639.0123 s
env0_first_0:                 episode reward: -9.2000,                 loss: 0.0038
env0_second_0:                 episode reward: 9.2000,                 loss: 0.0028
env1_first_0:                 episode reward: -7.7500,                 loss: nan
env1_second_0:                 episode reward: 7.7500,                 loss: nan
Episode: 9941/10000 (99.4100%),                 avg. length: 3194.25,                last time consumption/overall running time: 965.5134s / 996604.5257 s
env0_first_0:                 episode reward: -6.5500,                 loss: 0.0043
env0_second_0:                 episode reward: 6.5500,                 loss: 0.0029
env1_first_0:                 episode reward: -6.2500,                 loss: nan
env1_second_0:                 episode reward: 6.2500,                 loss: nan
Episode: 9961/10000 (99.6100%),                 avg. length: 3385.35,                last time consumption/overall running time: 959.5451s / 997564.0708 s
env0_first_0:                 episode reward: -8.6500,                 loss: 0.0045
env0_second_0:                 episode reward: 8.6500,                 loss: 0.0027
env1_first_0:                 episode reward: -10.0000,                 loss: nan
env1_second_0:                 episode reward: 10.0000,                 loss: nan
Episode: 9981/10000 (99.8100%),                 avg. length: 3302.15,                last time consumption/overall running time: 933.4537s / 998497.5245 s
env0_first_0:                 episode reward: -8.5000,                 loss: 0.0040
env0_second_0:                 episode reward: 8.5000,                 loss: 0.0029
env1_first_0:                 episode reward: -9.2500,                 loss: nan
env1_second_0:                 episode reward: 9.2500,                 loss: nan
