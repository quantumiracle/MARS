2022-05-10 13:45:04.714154: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia:/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia
2022-05-10 13:45:04.714226: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia:/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia
2022-05-10 13:45:04.714231: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
pygame 2.0.1 (SDL 2.0.14, Python 3.6.13)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 33.0, (1,), float32) action space: Discrete(3)
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7f0d1b209550>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=32, bias=True)
      (3): ReLU()
      (4): Linear(in_features=32, out_features=32, bias=True)
      (5): ReLU()
      (6): Linear(in_features=32, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=32, bias=True)
      (3): ReLU()
      (4): Linear(in_features=32, out_features=32, bias=True)
      (5): ReLU()
      (6): Linear(in_features=32, out_features=3, bias=True)
    )
  )
)
Error: no exploited model index given!
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  data/model/20220510123946/mdp_arbitrary_mdp_selfplay2/10000_0
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': 1, 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 1.0, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 640, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220510123946/mdp_arbitrary_mdp_selfplay2/10000_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 1000, 'net_architecture': {'hidden_dim_list': [32, 32, 32], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'selfplay2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'selfplay_score_delta': 1.5, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'against_baseline': False}
Save models to : /home/quantumiracle/research/MARS/data/model/20220510123946_exploit_10000/mdp_arbitrary_mdp_selfplay2. 
 Save logs to: /home/quantumiracle/research/MARS/data/log/20220510123946_exploit_10000/mdp_arbitrary_mdp_selfplay2.
Episode: 1/10000 (0.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8157s / 0.8157 s
agent0:                 episode reward: -0.9245,                 loss: nan
agent1:                 episode reward: 0.9245,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.0846s / 0.9003 s
agent0:                 episode reward: 0.3289,                 loss: nan
agent1:                 episode reward: -0.3289,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.0775s / 0.9778 s
agent0:                 episode reward: -0.2031,                 loss: nan
agent1:                 episode reward: 0.2031,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.0796s / 1.0574 s
agent0:                 episode reward: 0.1547,                 loss: nan
agent1:                 episode reward: -0.1547,                 loss: nan
Episode: 81/10000 (0.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6476s / 1.7049 s
agent0:                 episode reward: 0.8635,                 loss: nan
agent1:                 episode reward: -0.8635,                 loss: 0.4230
Episode: 101/10000 (1.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7451s / 2.4500 s
agent0:                 episode reward: 0.1476,                 loss: nan
agent1:                 episode reward: -0.1476,                 loss: 0.4145
Episode: 121/10000 (1.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7492s / 3.1992 s
agent0:                 episode reward: 0.6119,                 loss: nan
agent1:                 episode reward: -0.6119,                 loss: 0.4148
Episode: 141/10000 (1.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8190s / 4.0183 s
agent0:                 episode reward: -0.2916,                 loss: nan
agent1:                 episode reward: 0.2916,                 loss: 0.4096
Episode: 161/10000 (1.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7803s / 4.7986 s
agent0:                 episode reward: -0.0795,                 loss: nan
agent1:                 episode reward: 0.0795,                 loss: 0.4083
Episode: 181/10000 (1.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7688s / 5.5674 s
agent0:                 episode reward: -0.2307,                 loss: nan
agent1:                 episode reward: 0.2307,                 loss: 0.4009
Episode: 201/10000 (2.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7880s / 6.3554 s
agent0:                 episode reward: -0.0056,                 loss: nan
agent1:                 episode reward: 0.0056,                 loss: 0.3951
Episode: 221/10000 (2.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7717s / 7.1271 s
agent0:                 episode reward: -0.3275,                 loss: nan
agent1:                 episode reward: 0.3275,                 loss: 0.3931
Episode: 241/10000 (2.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7936s / 7.9208 s
agent0:                 episode reward: 0.7534,                 loss: nan
agent1:                 episode reward: -0.7534,                 loss: 0.3869
Episode: 261/10000 (2.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7882s / 8.7090 s
agent0:                 episode reward: 0.2174,                 loss: nan
agent1:                 episode reward: -0.2174,                 loss: 0.3840
Episode: 281/10000 (2.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7739s / 9.4829 s
agent0:                 episode reward: 0.2168,                 loss: nan
agent1:                 episode reward: -0.2168,                 loss: 0.3727
Episode: 301/10000 (3.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7885s / 10.2714 s
agent0:                 episode reward: 0.4574,                 loss: nan
agent1:                 episode reward: -0.4574,                 loss: 0.3684
Episode: 321/10000 (3.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7871s / 11.0585 s
agent0:                 episode reward: 1.1800,                 loss: nan
agent1:                 episode reward: -1.1800,                 loss: 0.3656
Episode: 341/10000 (3.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7889s / 11.8474 s
agent0:                 episode reward: 0.6455,                 loss: nan
agent1:                 episode reward: -0.6455,                 loss: 0.3605
Episode: 361/10000 (3.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7988s / 12.6463 s
agent0:                 episode reward: 0.4159,                 loss: nan
agent1:                 episode reward: -0.4159,                 loss: 0.3585
Episode: 381/10000 (3.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8055s / 13.4518 s
agent0:                 episode reward: 1.0006,                 loss: nan
agent1:                 episode reward: -1.0006,                 loss: 0.3473
Episode: 401/10000 (4.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8511s / 14.3029 s
agent0:                 episode reward: -0.4320,                 loss: nan
agent1:                 episode reward: 0.4320,                 loss: 0.3448
Episode: 421/10000 (4.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8033s / 15.1062 s
agent0:                 episode reward: 0.5016,                 loss: nan
agent1:                 episode reward: -0.5016,                 loss: 0.3412
Episode: 441/10000 (4.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7968s / 15.9030 s
agent0:                 episode reward: -0.1497,                 loss: nan
agent1:                 episode reward: 0.1497,                 loss: 0.3355
Episode: 461/10000 (4.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8080s / 16.7111 s
agent0:                 episode reward: 0.2203,                 loss: nan
agent1:                 episode reward: -0.2203,                 loss: 0.3347
Episode: 481/10000 (4.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8252s / 17.5362 s
agent0:                 episode reward: 0.0955,                 loss: nan
agent1:                 episode reward: -0.0955,                 loss: 0.3262
Episode: 501/10000 (5.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8057s / 18.3420 s
agent0:                 episode reward: 0.2975,                 loss: nan
agent1:                 episode reward: -0.2975,                 loss: 0.3209
Episode: 521/10000 (5.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8215s / 19.1634 s
agent0:                 episode reward: 0.6404,                 loss: nan
agent1:                 episode reward: -0.6404,                 loss: 0.3179
Episode: 541/10000 (5.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8248s / 19.9882 s
agent0:                 episode reward: 0.3133,                 loss: nan
agent1:                 episode reward: -0.3133,                 loss: 0.3163
Episode: 561/10000 (5.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8239s / 20.8121 s
agent0:                 episode reward: 0.9104,                 loss: nan
agent1:                 episode reward: -0.9104,                 loss: 0.3138
Episode: 581/10000 (5.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8550s / 21.6671 s
agent0:                 episode reward: 0.4879,                 loss: nan
agent1:                 episode reward: -0.4879,                 loss: 0.3166
Episode: 601/10000 (6.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8401s / 22.5072 s
agent0:                 episode reward: -0.3095,                 loss: nan
agent1:                 episode reward: 0.3095,                 loss: 0.3153
Episode: 621/10000 (6.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8209s / 23.3281 s
agent0:                 episode reward: 0.2193,                 loss: nan
agent1:                 episode reward: -0.2193,                 loss: 0.3123
Episode: 641/10000 (6.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8716s / 24.1997 s
agent0:                 episode reward: -0.0019,                 loss: nan
agent1:                 episode reward: 0.0019,                 loss: 0.3070
Episode: 661/10000 (6.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8418s / 25.0415 s
agent0:                 episode reward: -0.4659,                 loss: nan
agent1:                 episode reward: 0.4659,                 loss: 0.3046
Episode: 681/10000 (6.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8500s / 25.8915 s
agent0:                 episode reward: -0.2426,                 loss: nan
agent1:                 episode reward: 0.2426,                 loss: 0.3100
Episode: 701/10000 (7.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8389s / 26.7304 s
agent0:                 episode reward: 0.5426,                 loss: nan
agent1:                 episode reward: -0.5426,                 loss: 0.3051
Episode: 721/10000 (7.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8755s / 27.6059 s
agent0:                 episode reward: 0.0189,                 loss: nan
agent1:                 episode reward: -0.0189,                 loss: 0.3027
Episode: 741/10000 (7.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8380s / 28.4439 s
agent0:                 episode reward: 0.4119,                 loss: nan
agent1:                 episode reward: -0.4119,                 loss: 0.3009
Episode: 761/10000 (7.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8779s / 29.3217 s
agent0:                 episode reward: -0.5357,                 loss: nan
agent1:                 episode reward: 0.5357,                 loss: 0.2997
Episode: 781/10000 (7.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8576s / 30.1793 s
agent0:                 episode reward: 0.6543,                 loss: nan
agent1:                 episode reward: -0.6543,                 loss: 0.2980
Episode: 801/10000 (8.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8540s / 31.0333 s
agent0:                 episode reward: -0.2838,                 loss: nan
agent1:                 episode reward: 0.2838,                 loss: 0.2928
Episode: 821/10000 (8.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8731s / 31.9063 s
agent0:                 episode reward: 0.1063,                 loss: nan
agent1:                 episode reward: -0.1063,                 loss: 0.2939
Episode: 841/10000 (8.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8591s / 32.7655 s
agent0:                 episode reward: 0.4418,                 loss: nan
agent1:                 episode reward: -0.4418,                 loss: 0.2893
Episode: 861/10000 (8.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8703s / 33.6358 s
agent0:                 episode reward: -0.4152,                 loss: nan
agent1:                 episode reward: 0.4152,                 loss: 0.2913
Episode: 881/10000 (8.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9174s / 34.5532 s
agent0:                 episode reward: -0.5758,                 loss: nan
agent1:                 episode reward: 0.5758,                 loss: 0.2800
Episode: 901/10000 (9.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8635s / 35.4167 s
agent0:                 episode reward: 0.6425,                 loss: nan
agent1:                 episode reward: -0.6425,                 loss: 0.2752
Episode: 921/10000 (9.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8861s / 36.3028 s
agent0:                 episode reward: -0.2740,                 loss: nan
agent1:                 episode reward: 0.2740,                 loss: 0.2742
Episode: 941/10000 (9.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8659s / 37.1687 s
agent0:                 episode reward: -0.0057,                 loss: nan
agent1:                 episode reward: 0.0057,                 loss: 0.2713
Episode: 961/10000 (9.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9048s / 38.0735 s
agent0:                 episode reward: 0.0267,                 loss: nan
agent1:                 episode reward: -0.0267,                 loss: 0.2699
Episode: 981/10000 (9.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8903s / 38.9638 s
agent0:                 episode reward: -0.2144,                 loss: nan
agent1:                 episode reward: 0.2144,                 loss: 0.2504
Episode: 1001/10000 (10.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8657s / 39.8295 s
agent0:                 episode reward: 0.2778,                 loss: nan
agent1:                 episode reward: -0.2778,                 loss: 0.2401
Episode: 1021/10000 (10.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8828s / 40.7124 s
agent0:                 episode reward: -0.4677,                 loss: nan
agent1:                 episode reward: 0.4677,                 loss: 0.2363
Episode: 1041/10000 (10.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8785s / 41.5909 s
agent0:                 episode reward: -0.4552,                 loss: nan
agent1:                 episode reward: 0.4552,                 loss: 0.2329
Episode: 1061/10000 (10.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8903s / 42.4812 s
agent0:                 episode reward: 0.0839,                 loss: nan
agent1:                 episode reward: -0.0839,                 loss: 0.2332
Episode: 1081/10000 (10.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8857s / 43.3669 s
agent0:                 episode reward: 0.3405,                 loss: nan
agent1:                 episode reward: -0.3405,                 loss: 0.2011
Episode: 1101/10000 (11.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8834s / 44.2503 s
agent0:                 episode reward: -0.1301,                 loss: nan
agent1:                 episode reward: 0.1301,                 loss: 0.1891
Episode: 1121/10000 (11.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9865s / 45.2368 s
agent0:                 episode reward: 0.4858,                 loss: nan
agent1:                 episode reward: -0.4858,                 loss: 0.1879
Episode: 1141/10000 (11.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9171s / 46.1538 s
agent0:                 episode reward: -0.1710,                 loss: nan
agent1:                 episode reward: 0.1710,                 loss: 0.1866
Episode: 1161/10000 (11.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9087s / 47.0625 s
agent0:                 episode reward: -0.1068,                 loss: nan
agent1:                 episode reward: 0.1068,                 loss: 0.1860
Episode: 1181/10000 (11.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9358s / 47.9983 s
agent0:                 episode reward: 0.6219,                 loss: nan
agent1:                 episode reward: -0.6219,                 loss: 0.1779
Episode: 1201/10000 (12.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8977s / 48.8960 s
agent0:                 episode reward: 0.3249,                 loss: nan
agent1:                 episode reward: -0.3249,                 loss: 0.1727
Episode: 1221/10000 (12.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9165s / 49.8125 s
agent0:                 episode reward: -0.3872,                 loss: nan
agent1:                 episode reward: 0.3872,                 loss: 0.1700
Episode: 1241/10000 (12.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9192s / 50.7317 s
agent0:                 episode reward: 0.4206,                 loss: nan
agent1:                 episode reward: -0.4206,                 loss: 0.1707
Episode: 1261/10000 (12.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9130s / 51.6447 s
agent0:                 episode reward: 0.4142,                 loss: nan
agent1:                 episode reward: -0.4142,                 loss: 0.1714
Episode: 1281/10000 (12.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9090s / 52.5537 s
agent0:                 episode reward: -0.2748,                 loss: nan
agent1:                 episode reward: 0.2748,                 loss: 0.1841
Episode: 1301/10000 (13.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9039s / 53.4577 s
agent0:                 episode reward: 0.8909,                 loss: nan
agent1:                 episode reward: -0.8909,                 loss: 0.1808
Episode: 1321/10000 (13.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9509s / 54.4086 s
agent0:                 episode reward: -0.3784,                 loss: nan
agent1:                 episode reward: 0.3784,                 loss: 0.1788
Episode: 1341/10000 (13.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9805s / 55.3890 s
agent0:                 episode reward: 0.0895,                 loss: nan
agent1:                 episode reward: -0.0895,                 loss: 0.1783
Episode: 1361/10000 (13.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9144s / 56.3034 s
agent0:                 episode reward: -0.3981,                 loss: nan
agent1:                 episode reward: 0.3981,                 loss: 0.1778
Episode: 1381/10000 (13.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9248s / 57.2282 s
agent0:                 episode reward: 0.0657,                 loss: nan
agent1:                 episode reward: -0.0657,                 loss: 0.2100
Episode: 1401/10000 (14.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9276s / 58.1558 s
agent0:                 episode reward: -0.0002,                 loss: nan
agent1:                 episode reward: 0.0002,                 loss: 0.2150
Episode: 1421/10000 (14.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9492s / 59.1050 s
agent0:                 episode reward: 0.4295,                 loss: nan
agent1:                 episode reward: -0.4295,                 loss: 0.2124
Episode: 1441/10000 (14.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9349s / 60.0399 s
agent0:                 episode reward: -0.2113,                 loss: nan
agent1:                 episode reward: 0.2113,                 loss: 0.2089
Episode: 1461/10000 (14.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9291s / 60.9690 s
agent0:                 episode reward: -0.5220,                 loss: nan
agent1:                 episode reward: 0.5220,                 loss: 0.2094
Episode: 1481/10000 (14.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9414s / 61.9105 s
agent0:                 episode reward: 0.3718,                 loss: nan
agent1:                 episode reward: -0.3718,                 loss: 0.2484
Episode: 1501/10000 (15.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9537s / 62.8642 s
agent0:                 episode reward: 0.5702,                 loss: nan
agent1:                 episode reward: -0.5702,                 loss: 0.2557
Episode: 1521/10000 (15.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9398s / 63.8040 s
agent0:                 episode reward: -0.0053,                 loss: nan
agent1:                 episode reward: 0.0053,                 loss: 0.2551
Episode: 1541/10000 (15.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9424s / 64.7464 s
agent0:                 episode reward: 0.3404,                 loss: nan
agent1:                 episode reward: -0.3404,                 loss: 0.2556
Episode: 1561/10000 (15.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9973s / 65.7437 s
agent0:                 episode reward: -0.7167,                 loss: nan
agent1:                 episode reward: 0.7167,                 loss: 0.2542
Episode: 1581/10000 (15.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9561s / 66.6998 s
agent0:                 episode reward: 0.5078,                 loss: nan
agent1:                 episode reward: -0.5078,                 loss: 0.2831
Episode: 1601/10000 (16.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9448s / 67.6446 s
agent0:                 episode reward: -0.2719,                 loss: nan
agent1:                 episode reward: 0.2719,                 loss: 0.2853
Episode: 1621/10000 (16.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9581s / 68.6026 s
agent0:                 episode reward: -0.3336,                 loss: nan
agent1:                 episode reward: 0.3336,                 loss: 0.2858
Episode: 1641/10000 (16.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9595s / 69.5621 s
agent0:                 episode reward: -0.1135,                 loss: nan
agent1:                 episode reward: 0.1135,                 loss: 0.2833
Episode: 1661/10000 (16.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9563s / 70.5184 s
agent0:                 episode reward: 0.3254,                 loss: nan
agent1:                 episode reward: -0.3254,                 loss: 0.2806
Episode: 1681/10000 (16.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9751s / 71.4935 s
agent0:                 episode reward: -0.1819,                 loss: nan
agent1:                 episode reward: 0.1819,                 loss: 0.3030
Episode: 1701/10000 (17.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9633s / 72.4568 s
agent0:                 episode reward: -0.2789,                 loss: nan
agent1:                 episode reward: 0.2789,                 loss: 0.3018
Episode: 1721/10000 (17.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9568s / 73.4137 s
agent0:                 episode reward: 0.0094,                 loss: nan
agent1:                 episode reward: -0.0094,                 loss: 0.2988
Episode: 1741/10000 (17.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9590s / 74.3727 s
agent0:                 episode reward: -0.1348,                 loss: nan
agent1:                 episode reward: 0.1348,                 loss: 0.2995
Episode: 1761/10000 (17.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9703s / 75.3430 s
agent0:                 episode reward: -0.1347,                 loss: nan
agent1:                 episode reward: 0.1347,                 loss: 0.2979
Episode: 1781/10000 (17.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0186s / 76.3616 s
agent0:                 episode reward: -0.7188,                 loss: nan
agent1:                 episode reward: 0.7188,                 loss: 0.3018
Episode: 1801/10000 (18.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9755s / 77.3371 s
agent0:                 episode reward: 0.9405,                 loss: nan
agent1:                 episode reward: -0.9405,                 loss: 0.2988
Episode: 1821/10000 (18.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9921s / 78.3292 s
agent0:                 episode reward: 0.1268,                 loss: nan
agent1:                 episode reward: -0.1268,                 loss: 0.2971
Episode: 1841/10000 (18.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9726s / 79.3018 s
agent0:                 episode reward: -0.2241,                 loss: nan
agent1:                 episode reward: 0.2241,                 loss: 0.2968
Episode: 1861/10000 (18.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9913s / 80.2931 s
agent0:                 episode reward: 0.2174,                 loss: nan
agent1:                 episode reward: -0.2174,                 loss: 0.2963
Episode: 1881/10000 (18.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9733s / 81.2663 s
agent0:                 episode reward: 0.0389,                 loss: nan
agent1:                 episode reward: -0.0389,                 loss: 0.2928
Episode: 1901/10000 (19.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9730s / 82.2394 s
agent0:                 episode reward: -0.8732,                 loss: nan
agent1:                 episode reward: 0.8732,                 loss: 0.2901
Episode: 1921/10000 (19.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9806s / 83.2200 s
agent0:                 episode reward: -0.0424,                 loss: nan
agent1:                 episode reward: 0.0424,                 loss: 0.2871
Episode: 1941/10000 (19.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9865s / 84.2065 s
agent0:                 episode reward: -0.5101,                 loss: nan
agent1:                 episode reward: 0.5101,                 loss: 0.2843
Episode: 1961/10000 (19.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9838s / 85.1903 s
agent0:                 episode reward: -0.0658,                 loss: nan
agent1:                 episode reward: 0.0658,                 loss: 0.2846
Episode: 1981/10000 (19.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0284s / 86.2187 s
agent0:                 episode reward: 0.4106,                 loss: nan
agent1:                 episode reward: -0.4106,                 loss: 0.2863
Episode: 2001/10000 (20.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0008s / 87.2196 s
agent0:                 episode reward: 0.2713,                 loss: nan
agent1:                 episode reward: -0.2713,                 loss: 0.2809
Episode: 2021/10000 (20.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0100s / 88.2296 s
agent0:                 episode reward: -0.4114,                 loss: nan
agent1:                 episode reward: 0.4114,                 loss: 0.2812
Episode: 2041/10000 (20.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0017s / 89.2312 s
agent0:                 episode reward: -0.6667,                 loss: nan
agent1:                 episode reward: 0.6667,                 loss: 0.2751
Episode: 2061/10000 (20.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0260s / 90.2572 s
agent0:                 episode reward: 0.6232,                 loss: nan
agent1:                 episode reward: -0.6232,                 loss: 0.2738
Episode: 2081/10000 (20.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0218s / 91.2790 s
agent0:                 episode reward: 0.2051,                 loss: nan
agent1:                 episode reward: -0.2051,                 loss: 0.2790
Episode: 2101/10000 (21.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0377s / 92.3167 s
agent0:                 episode reward: 0.7747,                 loss: nan
agent1:                 episode reward: -0.7747,                 loss: 0.2761
Episode: 2121/10000 (21.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0073s / 93.3240 s
agent0:                 episode reward: 0.0503,                 loss: nan
agent1:                 episode reward: -0.0503,                 loss: 0.2714
Episode: 2141/10000 (21.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0120s / 94.3359 s
agent0:                 episode reward: 0.1210,                 loss: nan
agent1:                 episode reward: -0.1210,                 loss: 0.2692
Episode: 2161/10000 (21.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0044s / 95.3403 s
agent0:                 episode reward: 0.5198,                 loss: nan
agent1:                 episode reward: -0.5198,                 loss: 0.2664
Episode: 2181/10000 (21.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0659s / 96.4062 s
agent0:                 episode reward: -0.3360,                 loss: nan
agent1:                 episode reward: 0.3360,                 loss: 0.2840
Episode: 2201/10000 (22.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0054s / 97.4115 s
agent0:                 episode reward: -0.0326,                 loss: nan
agent1:                 episode reward: 0.0326,                 loss: 0.2817
Episode: 2221/10000 (22.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0764s / 98.4879 s
agent0:                 episode reward: -1.2351,                 loss: nan
agent1:                 episode reward: 1.2351,                 loss: 0.2780
Episode: 2241/10000 (22.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0328s / 99.5207 s
agent0:                 episode reward: 0.0393,                 loss: nan
agent1:                 episode reward: -0.0393,                 loss: 0.2761
Episode: 2261/10000 (22.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0323s / 100.5530 s
agent0:                 episode reward: 0.4429,                 loss: nan
agent1:                 episode reward: -0.4429,                 loss: 0.2718
Episode: 2281/10000 (22.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0379s / 101.5910 s
agent0:                 episode reward: -0.0756,                 loss: nan
agent1:                 episode reward: 0.0756,                 loss: 0.2831
Episode: 2301/10000 (23.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0189s / 102.6099 s
agent0:                 episode reward: -0.1850,                 loss: nan
agent1:                 episode reward: 0.1850,                 loss: 0.2805
Episode: 2321/10000 (23.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0261s / 103.6360 s
agent0:                 episode reward: -0.2947,                 loss: nan
agent1:                 episode reward: 0.2947,                 loss: 0.2788
Episode: 2341/10000 (23.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0664s / 104.7024 s
agent0:                 episode reward: -0.5206,                 loss: nan
agent1:                 episode reward: 0.5206,                 loss: 0.2765
Episode: 2361/10000 (23.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0307s / 105.7332 s
agent0:                 episode reward: -0.6416,                 loss: nan
agent1:                 episode reward: 0.6416,                 loss: 0.2737
Episode: 2381/10000 (23.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0757s / 106.8089 s
agent0:                 episode reward: -0.9858,                 loss: nan
agent1:                 episode reward: 0.9858,                 loss: 0.2752
Episode: 2401/10000 (24.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0492s / 107.8581 s
agent0:                 episode reward: 0.1257,                 loss: nan
agent1:                 episode reward: -0.1257,                 loss: 0.2721
Episode: 2421/10000 (24.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0455s / 108.9036 s
agent0:                 episode reward: -0.2069,                 loss: nan
agent1:                 episode reward: 0.2069,                 loss: 0.2724
Episode: 2441/10000 (24.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0226s / 109.9262 s
agent0:                 episode reward: 0.1459,                 loss: nan
agent1:                 episode reward: -0.1459,                 loss: 0.2708
Episode: 2461/10000 (24.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0614s / 110.9877 s
agent0:                 episode reward: -0.6147,                 loss: nan
agent1:                 episode reward: 0.6147,                 loss: 0.2708
Episode: 2481/10000 (24.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0441s / 112.0318 s
agent0:                 episode reward: 0.0309,                 loss: nan
agent1:                 episode reward: -0.0309,                 loss: 0.2466
Episode: 2501/10000 (25.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0715s / 113.1033 s
agent0:                 episode reward: -0.1316,                 loss: nan
agent1:                 episode reward: 0.1316,                 loss: 0.2366
Episode: 2521/10000 (25.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0610s / 114.1643 s
agent0:                 episode reward: 0.2539,                 loss: nan
agent1:                 episode reward: -0.2539,                 loss: 0.2352
Episode: 2541/10000 (25.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0419s / 115.2062 s
agent0:                 episode reward: -0.5457,                 loss: nan
agent1:                 episode reward: 0.5457,                 loss: 0.2345
Episode: 2561/10000 (25.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0470s / 116.2532 s
agent0:                 episode reward: -0.9373,                 loss: nan
agent1:                 episode reward: 0.9373,                 loss: 0.2359
Episode: 2581/10000 (25.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1205s / 117.3737 s
agent0:                 episode reward: -0.7844,                 loss: nan
agent1:                 episode reward: 0.7844,                 loss: 0.2117
Episode: 2601/10000 (26.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0546s / 118.4283 s
agent0:                 episode reward: -0.5015,                 loss: nan
agent1:                 episode reward: 0.5015,                 loss: 0.1971
Episode: 2621/10000 (26.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0709s / 119.4992 s
agent0:                 episode reward: -0.9967,                 loss: nan
agent1:                 episode reward: 0.9967,                 loss: 0.1952
Episode: 2641/10000 (26.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0842s / 120.5834 s
agent0:                 episode reward: -0.6645,                 loss: nan
agent1:                 episode reward: 0.6645,                 loss: 0.1946
Episode: 2661/10000 (26.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0914s / 121.6749 s
agent0:                 episode reward: -0.2769,                 loss: nan
agent1:                 episode reward: 0.2769,                 loss: 0.1930
Episode: 2681/10000 (26.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0417s / 122.7165 s
agent0:                 episode reward: 0.4229,                 loss: nan
agent1:                 episode reward: -0.4229,                 loss: 0.1836
Episode: 2701/10000 (27.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0567s / 123.7732 s
agent0:                 episode reward: -0.1603,                 loss: nan
agent1:                 episode reward: 0.1603,                 loss: 0.1778
Episode: 2721/10000 (27.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0240s / 124.7972 s
agent0:                 episode reward: -0.4915,                 loss: nan
agent1:                 episode reward: 0.4915,                 loss: 0.1753
Episode: 2741/10000 (27.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0544s / 125.8515 s
agent0:                 episode reward: -0.3344,                 loss: nan
agent1:                 episode reward: 0.3344,                 loss: 0.1727
Episode: 2761/10000 (27.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0888s / 126.9403 s
agent0:                 episode reward: -0.2429,                 loss: nan
agent1:                 episode reward: 0.2429,                 loss: 0.1711
Episode: 2781/10000 (27.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0334s / 127.9737 s
agent0:                 episode reward: -0.7439,                 loss: nan
agent1:                 episode reward: 0.7439,                 loss: 0.1769
Episode: 2801/10000 (28.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0803s / 129.0540 s
agent0:                 episode reward: 0.0150,                 loss: nan
agent1:                 episode reward: -0.0150,                 loss: 0.1752
Episode: 2821/10000 (28.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0494s / 130.1034 s
agent0:                 episode reward: -0.4897,                 loss: nan
agent1:                 episode reward: 0.4897,                 loss: 0.1745
Episode: 2841/10000 (28.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0355s / 131.1389 s
agent0:                 episode reward: -0.2352,                 loss: nan
agent1:                 episode reward: 0.2352,                 loss: 0.1729
Episode: 2861/10000 (28.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0704s / 132.2093 s
agent0:                 episode reward: -0.6320,                 loss: nan
agent1:                 episode reward: 0.6320,                 loss: 0.1734
Episode: 2881/10000 (28.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0500s / 133.2593 s
agent0:                 episode reward: -0.8819,                 loss: nan
agent1:                 episode reward: 0.8819,                 loss: 0.1954
Episode: 2901/10000 (29.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0574s / 134.3167 s
agent0:                 episode reward: -0.3625,                 loss: nan
agent1:                 episode reward: 0.3625,                 loss: 0.1967
Episode: 2921/10000 (29.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0781s / 135.3948 s
agent0:                 episode reward: -0.3078,                 loss: nan
agent1:                 episode reward: 0.3078,                 loss: 0.1979
Episode: 2941/10000 (29.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0303s / 136.4250 s
agent0:                 episode reward: 0.1133,                 loss: nan
agent1:                 episode reward: -0.1133,                 loss: 0.1959
Episode: 2961/10000 (29.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1431s / 137.5681 s
agent0:                 episode reward: 0.7927,                 loss: nan
agent1:                 episode reward: -0.7927,                 loss: 0.1949
Episode: 2981/10000 (29.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0636s / 138.6317 s
agent0:                 episode reward: -0.1420,                 loss: nan
agent1:                 episode reward: 0.1420,                 loss: 0.2221
Episode: 3001/10000 (30.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0835s / 139.7151 s
agent0:                 episode reward: -0.4645,                 loss: nan
agent1:                 episode reward: 0.4645,                 loss: 0.2267
Episode: 3021/10000 (30.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0590s / 140.7742 s
agent0:                 episode reward: -0.2266,                 loss: nan
agent1:                 episode reward: 0.2266,                 loss: 0.2267
Episode: 3041/10000 (30.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0579s / 141.8321 s
agent0:                 episode reward: -0.3371,                 loss: nan
agent1:                 episode reward: 0.3371,                 loss: 0.2260
Episode: 3061/10000 (30.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0604s / 142.8925 s
agent0:                 episode reward: -0.3662,                 loss: nan
agent1:                 episode reward: 0.3662,                 loss: 0.2246
Episode: 3081/10000 (30.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0829s / 143.9754 s
agent0:                 episode reward: -0.5965,                 loss: nan
agent1:                 episode reward: 0.5965,                 loss: 0.2475
Episode: 3101/10000 (31.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0786s / 145.0540 s
agent0:                 episode reward: -0.0975,                 loss: nan
agent1:                 episode reward: 0.0975,                 loss: 0.2507
Episode: 3121/10000 (31.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0812s / 146.1352 s
agent0:                 episode reward: -0.8385,                 loss: nan
agent1:                 episode reward: 0.8385,                 loss: 0.2498
Episode: 3141/10000 (31.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1221s / 147.2573 s
agent0:                 episode reward: -0.5077,                 loss: nan
agent1:                 episode reward: 0.5077,                 loss: 0.2514
Episode: 3161/10000 (31.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0845s / 148.3418 s
agent0:                 episode reward: -0.3433,                 loss: nan
agent1:                 episode reward: 0.3433,                 loss: 0.2507
Episode: 3181/10000 (31.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0912s / 149.4330 s
agent0:                 episode reward: -0.2139,                 loss: nan
agent1:                 episode reward: 0.2139,                 loss: 0.2728
Episode: 3201/10000 (32.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1034s / 150.5365 s
agent0:                 episode reward: -0.5083,                 loss: nan
agent1:                 episode reward: 0.5083,                 loss: 0.2737
Episode: 3221/10000 (32.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0947s / 151.6312 s
agent0:                 episode reward: -0.2105,                 loss: nan
agent1:                 episode reward: 0.2105,                 loss: 0.2735
Episode: 3241/10000 (32.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0765s / 152.7077 s
agent0:                 episode reward: -1.1394,                 loss: nan
agent1:                 episode reward: 1.1394,                 loss: 0.2714
Episode: 3261/10000 (32.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0893s / 153.7970 s
agent0:                 episode reward: -0.2322,                 loss: nan
agent1:                 episode reward: 0.2322,                 loss: 0.2732
Episode: 3281/10000 (32.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1385s / 154.9355 s
agent0:                 episode reward: -0.4179,                 loss: nan
agent1:                 episode reward: 0.4179,                 loss: 0.2854
Episode: 3301/10000 (33.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1081s / 156.0436 s
agent0:                 episode reward: -0.3773,                 loss: nan
agent1:                 episode reward: 0.3773,                 loss: 0.2852
Episode: 3321/10000 (33.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1011s / 157.1447 s
agent0:                 episode reward: -0.2777,                 loss: nan
agent1:                 episode reward: 0.2777,                 loss: 0.2864
Episode: 3341/10000 (33.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1635s / 158.3082 s
agent0:                 episode reward: -0.5168,                 loss: nan
agent1:                 episode reward: 0.5168,                 loss: 0.2855
Episode: 3361/10000 (33.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1223s / 159.4305 s
agent0:                 episode reward: -0.8122,                 loss: nan
agent1:                 episode reward: 0.8122,                 loss: 0.2864
Episode: 3381/10000 (33.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1089s / 160.5394 s
agent0:                 episode reward: -0.7634,                 loss: nan
agent1:                 episode reward: 0.7634,                 loss: 0.2824
Episode: 3401/10000 (34.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1361s / 161.6755 s
agent0:                 episode reward: -0.5263,                 loss: nan
agent1:                 episode reward: 0.5263,                 loss: 0.2817
Episode: 3421/10000 (34.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1323s / 162.8077 s
agent0:                 episode reward: -0.2417,                 loss: nan
agent1:                 episode reward: 0.2417,                 loss: 0.2798
Episode: 3441/10000 (34.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1163s / 163.9241 s
agent0:                 episode reward: -1.2125,                 loss: nan
agent1:                 episode reward: 1.2125,                 loss: 0.2817
Episode: 3461/10000 (34.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1368s / 165.0608 s
agent0:                 episode reward: -0.2564,                 loss: nan
agent1:                 episode reward: 0.2564,                 loss: 0.2807
Episode: 3481/10000 (34.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1246s / 166.1855 s
agent0:                 episode reward: -0.5786,                 loss: nan
agent1:                 episode reward: 0.5786,                 loss: 0.2744
Episode: 3501/10000 (35.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1339s / 167.3193 s
agent0:                 episode reward: -1.1988,                 loss: nan
agent1:                 episode reward: 1.1988,                 loss: 0.2717
Episode: 3521/10000 (35.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1914s / 168.5108 s
agent0:                 episode reward: -0.3488,                 loss: nan
agent1:                 episode reward: 0.3488,                 loss: 0.2696
Episode: 3541/10000 (35.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1470s / 169.6578 s
agent0:                 episode reward: -0.3520,                 loss: nan
agent1:                 episode reward: 0.3520,                 loss: 0.2718
Episode: 3561/10000 (35.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1600s / 170.8178 s
agent0:                 episode reward: -0.8945,                 loss: nan
agent1:                 episode reward: 0.8945,                 loss: 0.2708
Episode: 3581/10000 (35.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1713s / 171.9891 s
agent0:                 episode reward: -0.5783,                 loss: nan
agent1:                 episode reward: 0.5783,                 loss: 0.2544
Episode: 3601/10000 (36.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1360s / 173.1251 s
agent0:                 episode reward: -0.7848,                 loss: nan
agent1:                 episode reward: 0.7848,                 loss: 0.2509
Episode: 3621/10000 (36.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1534s / 174.2785 s
agent0:                 episode reward: -0.0727,                 loss: nan
agent1:                 episode reward: 0.0727,                 loss: 0.2526
Episode: 3641/10000 (36.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1441s / 175.4226 s
agent0:                 episode reward: -0.4935,                 loss: nan
agent1:                 episode reward: 0.4935,                 loss: 0.2510
Episode: 3661/10000 (36.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1680s / 176.5906 s
agent0:                 episode reward: -0.3345,                 loss: nan
agent1:                 episode reward: 0.3345,                 loss: 0.2513
Episode: 3681/10000 (36.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1897s / 177.7803 s
agent0:                 episode reward: -0.6462,                 loss: nan
agent1:                 episode reward: 0.6462,                 loss: 0.2261
Episode: 3701/10000 (37.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2192s / 178.9995 s
agent0:                 episode reward: 0.3951,                 loss: nan
agent1:                 episode reward: -0.3951,                 loss: 0.2199
Episode: 3721/10000 (37.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1919s / 180.1914 s
agent0:                 episode reward: 0.0420,                 loss: nan
agent1:                 episode reward: -0.0420,                 loss: 0.2202
Episode: 3741/10000 (37.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1855s / 181.3769 s
agent0:                 episode reward: -0.2857,                 loss: nan
agent1:                 episode reward: 0.2857,                 loss: 0.2210
Episode: 3761/10000 (37.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1548s / 182.5317 s
agent0:                 episode reward: -0.6826,                 loss: nan
agent1:                 episode reward: 0.6826,                 loss: 0.2197
Episode: 3781/10000 (37.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1696s / 183.7013 s
agent0:                 episode reward: -1.2963,                 loss: nan
agent1:                 episode reward: 1.2963,                 loss: 0.2075
Episode: 3801/10000 (38.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1600s / 184.8612 s
agent0:                 episode reward: -0.7548,                 loss: nan
agent1:                 episode reward: 0.7548,                 loss: 0.2058
Episode: 3821/10000 (38.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1710s / 186.0322 s
agent0:                 episode reward: -1.2252,                 loss: nan
agent1:                 episode reward: 1.2252,                 loss: 0.2040
Episode: 3841/10000 (38.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1811s / 187.2134 s
agent0:                 episode reward: -0.8042,                 loss: nan
agent1:                 episode reward: 0.8042,                 loss: 0.2043
Episode: 3861/10000 (38.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2124s / 188.4258 s
agent0:                 episode reward: -1.3372,                 loss: nan
agent1:                 episode reward: 1.3372,                 loss: 0.2034
Episode: 3881/10000 (38.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1836s / 189.6094 s
agent0:                 episode reward: -1.0819,                 loss: nan
agent1:                 episode reward: 1.0819,                 loss: 0.2050
Episode: 3901/10000 (39.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1915s / 190.8009 s
agent0:                 episode reward: -0.9560,                 loss: nan
agent1:                 episode reward: 0.9560,                 loss: 0.2049
Episode: 3921/10000 (39.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1847s / 191.9855 s
agent0:                 episode reward: -0.3533,                 loss: nan
agent1:                 episode reward: 0.3533,                 loss: 0.2052
Episode: 3941/10000 (39.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1857s / 193.1712 s
agent0:                 episode reward: -0.3636,                 loss: nan
agent1:                 episode reward: 0.3636,                 loss: 0.2041
Episode: 3961/10000 (39.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1825s / 194.3537 s
agent0:                 episode reward: -1.0395,                 loss: nan
agent1:                 episode reward: 1.0395,                 loss: 0.2052
Episode: 3981/10000 (39.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2143s / 195.5680 s
agent0:                 episode reward: -1.2465,                 loss: nan
agent1:                 episode reward: 1.2465,                 loss: 0.2100
Episode: 4001/10000 (40.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1835s / 196.7515 s
agent0:                 episode reward: -0.5451,                 loss: nan
agent1:                 episode reward: 0.5451,                 loss: 0.2095
Episode: 4021/10000 (40.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2439s / 197.9954 s
agent0:                 episode reward: -0.6228,                 loss: nan
agent1:                 episode reward: 0.6228,                 loss: 0.2088
Episode: 4041/10000 (40.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2307s / 199.2261 s
agent0:                 episode reward: -0.6944,                 loss: nan
agent1:                 episode reward: 0.6944,                 loss: 0.2089
Episode: 4061/10000 (40.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2129s / 200.4390 s
agent0:                 episode reward: -0.4814,                 loss: nan
agent1:                 episode reward: 0.4814,                 loss: 0.2097
Episode: 4081/10000 (40.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2131s / 201.6521 s
agent0:                 episode reward: -1.3746,                 loss: nan
agent1:                 episode reward: 1.3746,                 loss: 0.2199
Episode: 4101/10000 (41.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2091s / 202.8612 s
agent0:                 episode reward: 0.1185,                 loss: nan
agent1:                 episode reward: -0.1185,                 loss: 0.2227
Episode: 4121/10000 (41.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2308s / 204.0920 s
agent0:                 episode reward: -0.3900,                 loss: nan
agent1:                 episode reward: 0.3900,                 loss: 0.2232
Episode: 4141/10000 (41.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2101s / 205.3021 s
agent0:                 episode reward: 0.2236,                 loss: nan
agent1:                 episode reward: -0.2236,                 loss: 0.2217
Episode: 4161/10000 (41.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2157s / 206.5178 s
agent0:                 episode reward: -1.1789,                 loss: nan
agent1:                 episode reward: 1.1789,                 loss: 0.2213
Episode: 4181/10000 (41.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2094s / 207.7272 s
agent0:                 episode reward: -0.9337,                 loss: nan
agent1:                 episode reward: 0.9337,                 loss: 0.2297
Episode: 4201/10000 (42.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2543s / 208.9815 s
agent0:                 episode reward: -0.3195,                 loss: nan
agent1:                 episode reward: 0.3195,                 loss: 0.2304
Episode: 4221/10000 (42.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2301s / 210.2116 s
agent0:                 episode reward: -0.1827,                 loss: nan
agent1:                 episode reward: 0.1827,                 loss: 0.2317
Episode: 4241/10000 (42.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2193s / 211.4309 s
agent0:                 episode reward: -0.7445,                 loss: nan
agent1:                 episode reward: 0.7445,                 loss: 0.2292
Episode: 4261/10000 (42.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2500s / 212.6808 s
agent0:                 episode reward: -0.2534,                 loss: nan
agent1:                 episode reward: 0.2534,                 loss: 0.2297
Episode: 4281/10000 (42.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2431s / 213.9239 s
agent0:                 episode reward: -0.1116,                 loss: nan
agent1:                 episode reward: 0.1116,                 loss: 0.2393
Episode: 4301/10000 (43.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2171s / 215.1410 s
agent0:                 episode reward: -0.7051,                 loss: nan
agent1:                 episode reward: 0.7051,                 loss: 0.2375
Episode: 4321/10000 (43.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2294s / 216.3704 s
agent0:                 episode reward: -0.0395,                 loss: nan
agent1:                 episode reward: 0.0395,                 loss: 0.2401
Episode: 4341/10000 (43.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2241s / 217.5944 s
agent0:                 episode reward: -1.5150,                 loss: nan
agent1:                 episode reward: 1.5150,                 loss: 0.2395
Episode: 4361/10000 (43.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2932s / 218.8877 s
agent0:                 episode reward: -0.2811,                 loss: nan
agent1:                 episode reward: 0.2811,                 loss: 0.2385
Episode: 4381/10000 (43.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2454s / 220.1331 s
agent0:                 episode reward: -0.5026,                 loss: nan
agent1:                 episode reward: 0.5026,                 loss: 0.2525
Episode: 4401/10000 (44.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2518s / 221.3849 s
agent0:                 episode reward: -0.3103,                 loss: nan
agent1:                 episode reward: 0.3103,                 loss: 0.2571
Episode: 4421/10000 (44.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2374s / 222.6223 s
agent0:                 episode reward: -0.9971,                 loss: nan
agent1:                 episode reward: 0.9971,                 loss: 0.2550
Episode: 4441/10000 (44.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2406s / 223.8629 s
agent0:                 episode reward: -1.7161,                 loss: nan
agent1:                 episode reward: 1.7161,                 loss: 0.2574
Episode: 4461/10000 (44.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2417s / 225.1046 s
agent0:                 episode reward: -1.2980,                 loss: nan
agent1:                 episode reward: 1.2980,                 loss: 0.2578
Episode: 4481/10000 (44.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2412s / 226.3458 s
agent0:                 episode reward: -1.1778,                 loss: nan
agent1:                 episode reward: 1.1778,                 loss: 0.2659
Episode: 4501/10000 (45.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2551s / 227.6010 s
agent0:                 episode reward: -1.3331,                 loss: nan
agent1:                 episode reward: 1.3331,                 loss: 0.2683
Episode: 4521/10000 (45.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2926s / 228.8935 s
agent0:                 episode reward: -0.2446,                 loss: nan
agent1:                 episode reward: 0.2446,                 loss: 0.2676
Episode: 4541/10000 (45.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3154s / 230.2089 s
agent0:                 episode reward: -0.7452,                 loss: nan
agent1:                 episode reward: 0.7452,                 loss: 0.2677
Episode: 4561/10000 (45.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2832s / 231.4922 s
agent0:                 episode reward: -1.3016,                 loss: nan
agent1:                 episode reward: 1.3016,                 loss: 0.2687
Episode: 4581/10000 (45.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2585s / 232.7507 s
agent0:                 episode reward: 0.1948,                 loss: nan
agent1:                 episode reward: -0.1948,                 loss: 0.2735
Episode: 4601/10000 (46.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2791s / 234.0297 s
agent0:                 episode reward: -0.8150,                 loss: nan
agent1:                 episode reward: 0.8150,                 loss: 0.2761
Episode: 4621/10000 (46.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2732s / 235.3029 s
agent0:                 episode reward: -0.8340,                 loss: nan
agent1:                 episode reward: 0.8340,                 loss: 0.2736
Episode: 4641/10000 (46.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2667s / 236.5696 s
agent0:                 episode reward: -0.6007,                 loss: nan
agent1:                 episode reward: 0.6007,                 loss: 0.2743
Episode: 4661/10000 (46.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2850s / 237.8546 s
agent0:                 episode reward: -0.6082,                 loss: nan
agent1:                 episode reward: 0.6082,                 loss: 0.2735
Episode: 4681/10000 (46.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2701s / 239.1247 s
agent0:                 episode reward: -0.8624,                 loss: nan
agent1:                 episode reward: 0.8624,                 loss: 0.2711
Episode: 4701/10000 (47.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3086s / 240.4333 s
agent0:                 episode reward: -0.7447,                 loss: nan
agent1:                 episode reward: 0.7447,                 loss: 0.2725
Episode: 4721/10000 (47.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2700s / 241.7033 s
agent0:                 episode reward: -1.5670,                 loss: nan
agent1:                 episode reward: 1.5670,                 loss: 0.2712
Episode: 4741/10000 (47.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2876s / 242.9909 s
agent0:                 episode reward: -0.9993,                 loss: nan
agent1:                 episode reward: 0.9993,                 loss: 0.2720
Episode: 4761/10000 (47.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2760s / 244.2669 s
agent0:                 episode reward: -0.2120,                 loss: nan
agent1:                 episode reward: 0.2120,                 loss: 0.2713
Episode: 4781/10000 (47.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2853s / 245.5522 s
agent0:                 episode reward: -1.1494,                 loss: nan
agent1:                 episode reward: 1.1494,                 loss: 0.2566
Episode: 4801/10000 (48.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2983s / 246.8505 s
agent0:                 episode reward: -1.5496,                 loss: nan
agent1:                 episode reward: 1.5496,                 loss: 0.2569
Episode: 4821/10000 (48.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3123s / 248.1628 s
agent0:                 episode reward: -0.2462,                 loss: nan
agent1:                 episode reward: 0.2462,                 loss: 0.2556
Episode: 4841/10000 (48.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3349s / 249.4977 s
agent0:                 episode reward: -0.3697,                 loss: nan
agent1:                 episode reward: 0.3697,                 loss: 0.2569
Episode: 4861/10000 (48.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2959s / 250.7936 s
agent0:                 episode reward: -0.6387,                 loss: nan
agent1:                 episode reward: 0.6387,                 loss: 0.2560
Episode: 4881/10000 (48.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2955s / 252.0891 s
agent0:                 episode reward: -0.7438,                 loss: nan
agent1:                 episode reward: 0.7438,                 loss: 0.2366
Episode: 4901/10000 (49.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3058s / 253.3949 s
agent0:                 episode reward: -0.5507,                 loss: nan
agent1:                 episode reward: 0.5507,                 loss: 0.2343
Episode: 4921/10000 (49.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2859s / 254.6808 s
agent0:                 episode reward: -0.4914,                 loss: nan
agent1:                 episode reward: 0.4914,                 loss: 0.2333
Episode: 4941/10000 (49.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2983s / 255.9791 s
agent0:                 episode reward: -0.9834,                 loss: nan
agent1:                 episode reward: 0.9834,                 loss: 0.2346
Episode: 4961/10000 (49.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2923s / 257.2714 s
agent0:                 episode reward: -0.4743,                 loss: nan
agent1:                 episode reward: 0.4743,                 loss: 0.2324
Episode: 4981/10000 (49.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2936s / 258.5650 s
agent0:                 episode reward: -0.7886,                 loss: nan
agent1:                 episode reward: 0.7886,                 loss: 0.2257
Episode: 5001/10000 (50.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3417s / 259.9067 s
agent0:                 episode reward: -0.8578,                 loss: nan
agent1:                 episode reward: 0.8578,                 loss: 0.2242
Episode: 5021/10000 (50.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3065s / 261.2133 s
agent0:                 episode reward: -1.2601,                 loss: nan
agent1:                 episode reward: 1.2601,                 loss: 0.2245
Episode: 5041/10000 (50.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3247s / 262.5380 s
agent0:                 episode reward: -2.3073,                 loss: nan
agent1:                 episode reward: 2.3073,                 loss: 0.2234
Episode: 5061/10000 (50.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2984s / 263.8364 s
agent0:                 episode reward: -0.1226,                 loss: nan
agent1:                 episode reward: 0.1226,                 loss: 0.2249
Episode: 5081/10000 (50.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3156s / 265.1520 s
agent0:                 episode reward: -0.8166,                 loss: nan
agent1:                 episode reward: 0.8166,                 loss: 0.2095
Episode: 5101/10000 (51.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3231s / 266.4751 s
agent0:                 episode reward: 0.1185,                 loss: nan
agent1:                 episode reward: -0.1185,                 loss: 0.2061
Episode: 5121/10000 (51.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3296s / 267.8047 s
agent0:                 episode reward: -0.8845,                 loss: nan
agent1:                 episode reward: 0.8845,                 loss: 0.2070
Episode: 5141/10000 (51.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3242s / 269.1289 s
agent0:                 episode reward: -0.9695,                 loss: nan
agent1:                 episode reward: 0.9695,                 loss: 0.2055
Episode: 5161/10000 (51.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3812s / 270.5101 s
agent0:                 episode reward: -0.8816,                 loss: nan
agent1:                 episode reward: 0.8816,                 loss: 0.2079
Episode: 5181/10000 (51.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3512s / 271.8612 s
agent0:                 episode reward: -0.5311,                 loss: nan
agent1:                 episode reward: 0.5311,                 loss: 0.2093
Episode: 5201/10000 (52.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3258s / 273.1871 s
agent0:                 episode reward: -0.5715,                 loss: nan
agent1:                 episode reward: 0.5715,                 loss: 0.2108
Episode: 5221/10000 (52.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3444s / 274.5315 s
agent0:                 episode reward: -0.7561,                 loss: nan
agent1:                 episode reward: 0.7561,                 loss: 0.2110
Episode: 5241/10000 (52.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3498s / 275.8812 s
agent0:                 episode reward: -1.1951,                 loss: nan
agent1:                 episode reward: 1.1951,                 loss: 0.2107
Episode: 5261/10000 (52.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3151s / 277.1963 s
agent0:                 episode reward: -0.3105,                 loss: nan
agent1:                 episode reward: 0.3105,                 loss: 0.2125
Episode: 5281/10000 (52.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3501s / 278.5465 s
agent0:                 episode reward: -0.7765,                 loss: nan
agent1:                 episode reward: 0.7765,                 loss: 0.2172
Episode: 5301/10000 (53.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3485s / 279.8949 s
agent0:                 episode reward: -0.6013,                 loss: nan
agent1:                 episode reward: 0.6013,                 loss: 0.2171
Episode: 5321/10000 (53.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3707s / 281.2656 s
agent0:                 episode reward: -0.0870,                 loss: nan
agent1:                 episode reward: 0.0870,                 loss: 0.2158
Episode: 5341/10000 (53.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3462s / 282.6118 s
agent0:                 episode reward: -0.3021,                 loss: nan
agent1:                 episode reward: 0.3021,                 loss: 0.2177
Episode: 5361/10000 (53.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3332s / 283.9450 s
agent0:                 episode reward: -0.4829,                 loss: nan
agent1:                 episode reward: 0.4829,                 loss: 0.2185
Episode: 5381/10000 (53.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3499s / 285.2950 s
agent0:                 episode reward: -0.9061,                 loss: nan
agent1:                 episode reward: 0.9061,                 loss: 0.2278
Episode: 5401/10000 (54.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3472s / 286.6422 s
agent0:                 episode reward: -0.2558,                 loss: nan
agent1:                 episode reward: 0.2558,                 loss: 0.2300
Episode: 5421/10000 (54.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3482s / 287.9904 s
agent0:                 episode reward: -0.8035,                 loss: nan
agent1:                 episode reward: 0.8035,                 loss: 0.2303
Episode: 5441/10000 (54.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3505s / 289.3410 s
agent0:                 episode reward: -0.6850,                 loss: nan
agent1:                 episode reward: 0.6850,                 loss: 0.2303
Episode: 5461/10000 (54.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4091s / 290.7501 s
agent0:                 episode reward: -1.3130,                 loss: nan
agent1:                 episode reward: 1.3130,                 loss: 0.2273
Episode: 5481/10000 (54.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3774s / 292.1275 s
agent0:                 episode reward: -1.2782,                 loss: nan
agent1:                 episode reward: 1.2782,                 loss: 0.2401
Episode: 5501/10000 (55.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3554s / 293.4829 s
agent0:                 episode reward: -0.9414,                 loss: nan
agent1:                 episode reward: 0.9414,                 loss: 0.2402
Episode: 5521/10000 (55.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3830s / 294.8658 s
agent0:                 episode reward: -1.5070,                 loss: nan
agent1:                 episode reward: 1.5070,                 loss: 0.2413
Episode: 5541/10000 (55.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3507s / 296.2166 s
agent0:                 episode reward: -0.6848,                 loss: nan
agent1:                 episode reward: 0.6848,                 loss: 0.2418
Episode: 5561/10000 (55.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3578s / 297.5744 s
agent0:                 episode reward: -0.9196,                 loss: nan
agent1:                 episode reward: 0.9196,                 loss: 0.2421
Episode: 5581/10000 (55.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3588s / 298.9332 s
agent0:                 episode reward: -0.8483,                 loss: nan
agent1:                 episode reward: 0.8483,                 loss: 0.2513
Episode: 5601/10000 (56.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3693s / 300.3026 s
agent0:                 episode reward: -0.3983,                 loss: nan
agent1:                 episode reward: 0.3983,                 loss: 0.2523
Episode: 5621/10000 (56.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4142s / 301.7167 s
agent0:                 episode reward: -1.7823,                 loss: nan
agent1:                 episode reward: 1.7823,                 loss: 0.2510
Episode: 5641/10000 (56.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3902s / 303.1070 s
agent0:                 episode reward: -0.8565,                 loss: nan
agent1:                 episode reward: 0.8565,                 loss: 0.2530
Episode: 5661/10000 (56.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3676s / 304.4745 s
agent0:                 episode reward: -0.8444,                 loss: nan
agent1:                 episode reward: 0.8444,                 loss: 0.2533
Episode: 5681/10000 (56.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3813s / 305.8558 s
agent0:                 episode reward: -0.3022,                 loss: nan
agent1:                 episode reward: 0.3022,                 loss: 0.2611
Episode: 5701/10000 (57.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3752s / 307.2310 s
agent0:                 episode reward: -0.6796,                 loss: nan
agent1:                 episode reward: 0.6796,                 loss: 0.2622
Episode: 5721/10000 (57.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3853s / 308.6163 s
agent0:                 episode reward: -1.2674,                 loss: nan
agent1:                 episode reward: 1.2674,                 loss: 0.2625
Episode: 5741/10000 (57.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3915s / 310.0078 s
agent0:                 episode reward: 0.0158,                 loss: nan
agent1:                 episode reward: -0.0158,                 loss: 0.2651
Episode: 5761/10000 (57.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4476s / 311.4555 s
agent0:                 episode reward: -0.9851,                 loss: nan
agent1:                 episode reward: 0.9851,                 loss: 0.2620
Episode: 5781/10000 (57.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4052s / 312.8607 s
agent0:                 episode reward: -0.5612,                 loss: nan
agent1:                 episode reward: 0.5612,                 loss: 0.2721
Episode: 5801/10000 (58.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3863s / 314.2469 s
agent0:                 episode reward: -1.3110,                 loss: nan
agent1:                 episode reward: 1.3110,                 loss: 0.2715
Episode: 5821/10000 (58.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3828s / 315.6298 s
agent0:                 episode reward: -1.0829,                 loss: nan
agent1:                 episode reward: 1.0829,                 loss: 0.2727
Episode: 5841/10000 (58.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3934s / 317.0232 s
agent0:                 episode reward: -0.7743,                 loss: nan
agent1:                 episode reward: 0.7743,                 loss: 0.2716
Episode: 5861/10000 (58.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4088s / 318.4319 s
agent0:                 episode reward: -0.9978,                 loss: nan
agent1:                 episode reward: 0.9978,                 loss: 0.2709
Episode: 5881/10000 (58.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4418s / 319.8737 s
agent0:                 episode reward: -1.4575,                 loss: nan
agent1:                 episode reward: 1.4575,                 loss: 0.2774
Episode: 5901/10000 (59.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4458s / 321.3195 s
agent0:                 episode reward: -1.0859,                 loss: nan
agent1:                 episode reward: 1.0859,                 loss: 0.2780
Episode: 5921/10000 (59.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4392s / 322.7587 s
agent0:                 episode reward: -0.4204,                 loss: nan
agent1:                 episode reward: 0.4204,                 loss: 0.2776
Episode: 5941/10000 (59.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4299s / 324.1887 s
agent0:                 episode reward: -1.0240,                 loss: nan
agent1:                 episode reward: 1.0240,                 loss: 0.2763
Episode: 5961/10000 (59.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4161s / 325.6047 s
agent0:                 episode reward: -1.3639,                 loss: nan
agent1:                 episode reward: 1.3639,                 loss: 0.2776
Episode: 5981/10000 (59.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4571s / 327.0618 s
agent0:                 episode reward: -0.2443,                 loss: nan
agent1:                 episode reward: 0.2443,                 loss: 0.2680
Episode: 6001/10000 (60.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4335s / 328.4953 s
agent0:                 episode reward: -0.9497,                 loss: nan
agent1:                 episode reward: 0.9497,                 loss: 0.2661
Episode: 6021/10000 (60.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4305s / 329.9257 s
agent0:                 episode reward: -1.2032,                 loss: nan
agent1:                 episode reward: 1.2032,                 loss: 0.2663
Episode: 6041/10000 (60.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4498s / 331.3756 s
agent0:                 episode reward: -0.5629,                 loss: nan
agent1:                 episode reward: 0.5629,                 loss: 0.2650
Episode: 6061/10000 (60.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4305s / 332.8061 s
agent0:                 episode reward: -0.8906,                 loss: nan
agent1:                 episode reward: 0.8906,                 loss: 0.2671
Episode: 6081/10000 (60.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4190s / 334.2251 s
agent0:                 episode reward: -1.4460,                 loss: nan
agent1:                 episode reward: 1.4460,                 loss: 0.2445
Episode: 6101/10000 (61.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4494s / 335.6745 s
agent0:                 episode reward: -0.8141,                 loss: nan
agent1:                 episode reward: 0.8141,                 loss: 0.2416
Episode: 6121/10000 (61.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4503s / 337.1248 s
agent0:                 episode reward: -1.2593,                 loss: nan
agent1:                 episode reward: 1.2593,                 loss: 0.2413
Episode: 6141/10000 (61.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4113s / 338.5361 s
agent0:                 episode reward: -0.8980,                 loss: nan
agent1:                 episode reward: 0.8980,                 loss: 0.2419
Episode: 6161/10000 (61.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4375s / 339.9736 s
agent0:                 episode reward: -0.1526,                 loss: nan
agent1:                 episode reward: 0.1526,                 loss: 0.2400
Episode: 6181/10000 (61.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4289s / 341.4024 s
agent0:                 episode reward: -1.7633,                 loss: nan
agent1:                 episode reward: 1.7633,                 loss: 0.2326
Episode: 6201/10000 (62.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4915s / 342.8940 s
agent0:                 episode reward: -1.3213,                 loss: nan
agent1:                 episode reward: 1.3213,                 loss: 0.2293
Episode: 6221/10000 (62.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4274s / 344.3214 s
agent0:                 episode reward: -1.3122,                 loss: nan
agent1:                 episode reward: 1.3122,                 loss: 0.2294
Episode: 6241/10000 (62.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4709s / 345.7923 s
agent0:                 episode reward: -1.5948,                 loss: nan
agent1:                 episode reward: 1.5948,                 loss: 0.2296
Episode: 6261/10000 (62.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4460s / 347.2383 s
agent0:                 episode reward: -1.0742,                 loss: nan
agent1:                 episode reward: 1.0742,                 loss: 0.2294
Episode: 6281/10000 (62.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4410s / 348.6793 s
agent0:                 episode reward: -1.1397,                 loss: nan
agent1:                 episode reward: 1.1397,                 loss: 0.2156
Episode: 6301/10000 (63.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5079s / 350.1873 s
agent0:                 episode reward: -1.5988,                 loss: nan
agent1:                 episode reward: 1.5988,                 loss: 0.2137
Episode: 6321/10000 (63.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4754s / 351.6626 s
agent0:                 episode reward: -1.1840,                 loss: nan
agent1:                 episode reward: 1.1840,                 loss: 0.2146
Episode: 6341/10000 (63.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4825s / 353.1451 s
agent0:                 episode reward: -0.4670,                 loss: nan
agent1:                 episode reward: 0.4670,                 loss: 0.2146
Episode: 6361/10000 (63.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4542s / 354.5993 s
agent0:                 episode reward: -0.7599,                 loss: nan
agent1:                 episode reward: 0.7599,                 loss: 0.2142
Episode: 6381/10000 (63.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4461s / 356.0453 s
agent0:                 episode reward: -0.8363,                 loss: nan
agent1:                 episode reward: 0.8363,                 loss: 0.2205
Episode: 6401/10000 (64.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4512s / 357.4966 s
agent0:                 episode reward: -0.1869,                 loss: nan
agent1:                 episode reward: 0.1869,                 loss: 0.2212
Episode: 6421/10000 (64.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4640s / 358.9606 s
agent0:                 episode reward: -1.4664,                 loss: nan
agent1:                 episode reward: 1.4664,                 loss: 0.2203
Episode: 6441/10000 (64.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4619s / 360.4224 s
agent0:                 episode reward: -0.6344,                 loss: nan
agent1:                 episode reward: 0.6344,                 loss: 0.2191
Episode: 6461/10000 (64.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5072s / 361.9296 s
agent0:                 episode reward: -0.6479,                 loss: nan
agent1:                 episode reward: 0.6479,                 loss: 0.2200
Episode: 6481/10000 (64.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4812s / 363.4109 s
agent0:                 episode reward: -1.1302,                 loss: nan
agent1:                 episode reward: 1.1302,                 loss: 0.2253
Episode: 6501/10000 (65.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4643s / 364.8752 s
agent0:                 episode reward: -1.4629,                 loss: nan
agent1:                 episode reward: 1.4629,                 loss: 0.2231
Episode: 6521/10000 (65.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4972s / 366.3723 s
agent0:                 episode reward: -0.5570,                 loss: nan
agent1:                 episode reward: 0.5570,                 loss: 0.2271
Episode: 6541/10000 (65.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4945s / 367.8669 s
agent0:                 episode reward: -0.6593,                 loss: nan
agent1:                 episode reward: 0.6593,                 loss: 0.2229
Episode: 6561/10000 (65.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4938s / 369.3606 s
agent0:                 episode reward: -1.0700,                 loss: nan
agent1:                 episode reward: 1.0700,                 loss: 0.2240
Episode: 6581/10000 (65.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4833s / 370.8439 s
agent0:                 episode reward: -0.9283,                 loss: nan
agent1:                 episode reward: 0.9283,                 loss: 0.2363
Episode: 6601/10000 (66.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5393s / 372.3832 s
agent0:                 episode reward: -1.0357,                 loss: nan
agent1:                 episode reward: 1.0357,                 loss: 0.2354
Episode: 6621/10000 (66.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4808s / 373.8640 s
agent0:                 episode reward: -1.0397,                 loss: nan
agent1:                 episode reward: 1.0397,                 loss: 0.2391
Episode: 6641/10000 (66.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4892s / 375.3533 s
agent0:                 episode reward: -1.0208,                 loss: nan
agent1:                 episode reward: 1.0208,                 loss: 0.2385
Episode: 6661/10000 (66.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4881s / 376.8413 s
agent0:                 episode reward: -1.0886,                 loss: nan
agent1:                 episode reward: 1.0886,                 loss: 0.2382
Episode: 6681/10000 (66.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5076s / 378.3489 s
agent0:                 episode reward: -0.7340,                 loss: nan
agent1:                 episode reward: 0.7340,                 loss: 0.2478
Episode: 6701/10000 (67.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4867s / 379.8356 s
agent0:                 episode reward: -0.6923,                 loss: nan
agent1:                 episode reward: 0.6923,                 loss: 0.2479
Episode: 6721/10000 (67.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5012s / 381.3367 s
agent0:                 episode reward: -0.9386,                 loss: nan
agent1:                 episode reward: 0.9386,                 loss: 0.2492
Episode: 6741/10000 (67.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5563s / 382.8930 s
agent0:                 episode reward: -0.6763,                 loss: nan
agent1:                 episode reward: 0.6763,                 loss: 0.2494
Episode: 6761/10000 (67.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5019s / 384.3949 s
agent0:                 episode reward: -1.0498,                 loss: nan
agent1:                 episode reward: 1.0498,                 loss: 0.2497
Episode: 6781/10000 (67.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5219s / 385.9167 s
agent0:                 episode reward: -1.0943,                 loss: nan
agent1:                 episode reward: 1.0943,                 loss: 0.2610
Episode: 6801/10000 (68.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5838s / 387.5005 s
agent0:                 episode reward: -1.8611,                 loss: nan
agent1:                 episode reward: 1.8611,                 loss: 0.2648
Episode: 6821/10000 (68.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5300s / 389.0305 s
agent0:                 episode reward: -1.2837,                 loss: nan
agent1:                 episode reward: 1.2837,                 loss: 0.2646
Episode: 6841/10000 (68.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5431s / 390.5736 s
agent0:                 episode reward: -1.6382,                 loss: nan
agent1:                 episode reward: 1.6382,                 loss: 0.2653
Episode: 6861/10000 (68.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5284s / 392.1020 s
agent0:                 episode reward: -0.9278,                 loss: nan
agent1:                 episode reward: 0.9278,                 loss: 0.2642
Episode: 6881/10000 (68.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5839s / 393.6859 s
agent0:                 episode reward: -0.7959,                 loss: nan
agent1:                 episode reward: 0.7959,                 loss: 0.2660
Episode: 6901/10000 (69.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5372s / 395.2231 s
agent0:                 episode reward: -1.1517,                 loss: nan
agent1:                 episode reward: 1.1517,                 loss: 0.2667
Episode: 6921/10000 (69.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5286s / 396.7517 s
agent0:                 episode reward: -1.3522,                 loss: nan
agent1:                 episode reward: 1.3522,                 loss: 0.2656
Episode: 6941/10000 (69.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5196s / 398.2713 s
agent0:                 episode reward: -0.9414,                 loss: nan
agent1:                 episode reward: 0.9414,                 loss: 0.2639
Episode: 6961/10000 (69.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5397s / 399.8110 s
agent0:                 episode reward: -0.6488,                 loss: nan
agent1:                 episode reward: 0.6488,                 loss: 0.2663
Episode: 6981/10000 (69.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5322s / 401.3432 s
agent0:                 episode reward: -1.7379,                 loss: nan
agent1:                 episode reward: 1.7379,                 loss: 0.2701
Episode: 7001/10000 (70.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6015s / 402.9447 s
agent0:                 episode reward: -0.3218,                 loss: nan
agent1:                 episode reward: 0.3218,                 loss: 0.2690
Episode: 7021/10000 (70.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5452s / 404.4899 s
agent0:                 episode reward: -0.7001,                 loss: nan
agent1:                 episode reward: 0.7001,                 loss: 0.2704
Episode: 7041/10000 (70.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5318s / 406.0217 s
agent0:                 episode reward: -1.4228,                 loss: nan
agent1:                 episode reward: 1.4228,                 loss: 0.2691
Episode: 7061/10000 (70.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5321s / 407.5538 s
agent0:                 episode reward: -0.7013,                 loss: nan
agent1:                 episode reward: 0.7013,                 loss: 0.2707
Episode: 7081/10000 (70.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5430s / 409.0968 s
agent0:                 episode reward: -0.8636,                 loss: nan
agent1:                 episode reward: 0.8636,                 loss: 0.2687
Episode: 7101/10000 (71.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5427s / 410.6394 s
agent0:                 episode reward: -0.7044,                 loss: nan
agent1:                 episode reward: 0.7044,                 loss: 0.2701
Episode: 7121/10000 (71.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5759s / 412.2154 s
agent0:                 episode reward: -1.1879,                 loss: nan
agent1:                 episode reward: 1.1879,                 loss: 0.2705
Episode: 7141/10000 (71.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6149s / 413.8303 s
agent0:                 episode reward: -0.8236,                 loss: nan
agent1:                 episode reward: 0.8236,                 loss: 0.2680
Episode: 7161/10000 (71.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5701s / 415.4004 s
agent0:                 episode reward: -0.9667,                 loss: nan
agent1:                 episode reward: 0.9667,                 loss: 0.2703
Episode: 7181/10000 (71.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5526s / 416.9530 s
agent0:                 episode reward: -1.0900,                 loss: nan
agent1:                 episode reward: 1.0900,                 loss: 0.2613
Episode: 7201/10000 (72.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5774s / 418.5304 s
agent0:                 episode reward: -0.9023,                 loss: nan
agent1:                 episode reward: 0.9023,                 loss: 0.2572
Episode: 7221/10000 (72.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6000s / 420.1304 s
agent0:                 episode reward: -1.0288,                 loss: nan
agent1:                 episode reward: 1.0288,                 loss: 0.2588
Episode: 7241/10000 (72.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6263s / 421.7567 s
agent0:                 episode reward: -1.4741,                 loss: nan
agent1:                 episode reward: 1.4741,                 loss: 0.2566
Episode: 7261/10000 (72.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6281s / 423.3848 s
agent0:                 episode reward: -1.2595,                 loss: nan
agent1:                 episode reward: 1.2595,                 loss: 0.2576
Episode: 7281/10000 (72.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6147s / 424.9995 s
agent0:                 episode reward: -1.2232,                 loss: nan
agent1:                 episode reward: 1.2232,                 loss: 0.2514
Episode: 7301/10000 (73.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5860s / 426.5855 s
agent0:                 episode reward: -1.1436,                 loss: nan
agent1:                 episode reward: 1.1436,                 loss: 0.2534
Episode: 7321/10000 (73.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5821s / 428.1676 s
agent0:                 episode reward: -0.6035,                 loss: nan
agent1:                 episode reward: 0.6035,                 loss: 0.2535
Episode: 7341/10000 (73.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6083s / 429.7759 s
agent0:                 episode reward: -0.9067,                 loss: nan
agent1:                 episode reward: 0.9067,                 loss: 0.2532
Episode: 7361/10000 (73.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5848s / 431.3608 s
agent0:                 episode reward: -1.6045,                 loss: nan
agent1:                 episode reward: 1.6045,                 loss: 0.2536
Episode: 7381/10000 (73.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6146s / 432.9754 s
agent0:                 episode reward: -1.3101,                 loss: nan
agent1:                 episode reward: 1.3101,                 loss: 0.2333
Episode: 7401/10000 (74.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6457s / 434.6211 s
agent0:                 episode reward: -1.4702,                 loss: nan
agent1:                 episode reward: 1.4702,                 loss: 0.2320
Episode: 7421/10000 (74.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6032s / 436.2243 s
agent0:                 episode reward: -1.6684,                 loss: nan
agent1:                 episode reward: 1.6684,                 loss: 0.2299
Episode: 7441/10000 (74.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5926s / 437.8169 s
agent0:                 episode reward: -1.4381,                 loss: nan
agent1:                 episode reward: 1.4381,                 loss: 0.2319
Episode: 7461/10000 (74.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6164s / 439.4333 s
agent0:                 episode reward: -0.9074,                 loss: nan
agent1:                 episode reward: 0.9074,                 loss: 0.2304
Episode: 7481/10000 (74.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6174s / 441.0507 s
agent0:                 episode reward: -0.9586,                 loss: nan
agent1:                 episode reward: 0.9586,                 loss: 0.2312
Episode: 7501/10000 (75.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6111s / 442.6618 s
agent0:                 episode reward: -1.4253,                 loss: nan
agent1:                 episode reward: 1.4253,                 loss: 0.2310
Episode: 7521/10000 (75.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6979s / 444.3597 s
agent0:                 episode reward: -1.1154,                 loss: nan
agent1:                 episode reward: 1.1154,                 loss: 0.2331
Episode: 7541/10000 (75.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6346s / 445.9944 s
agent0:                 episode reward: -1.3082,                 loss: nan
agent1:                 episode reward: 1.3082,                 loss: 0.2305
Episode: 7561/10000 (75.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6387s / 447.6330 s
agent0:                 episode reward: -0.8059,                 loss: nan
agent1:                 episode reward: 0.8059,                 loss: 0.2308
Episode: 7581/10000 (75.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6309s / 449.2639 s
agent0:                 episode reward: -0.8108,                 loss: nan
agent1:                 episode reward: 0.8108,                 loss: 0.2295
Episode: 7601/10000 (76.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6561s / 450.9200 s
agent0:                 episode reward: -0.5921,                 loss: nan
agent1:                 episode reward: 0.5921,                 loss: 0.2301
Episode: 7621/10000 (76.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6410s / 452.5610 s
agent0:                 episode reward: -1.6360,                 loss: nan
agent1:                 episode reward: 1.6360,                 loss: 0.2312
Episode: 7641/10000 (76.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6826s / 454.2435 s
agent0:                 episode reward: -1.1498,                 loss: nan
agent1:                 episode reward: 1.1498,                 loss: 0.2295
Episode: 7661/10000 (76.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6229s / 455.8664 s
agent0:                 episode reward: -0.9361,                 loss: nan
agent1:                 episode reward: 0.9361,                 loss: 0.2289
Episode: 7681/10000 (76.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6335s / 457.4999 s
agent0:                 episode reward: -1.3679,                 loss: nan
agent1:                 episode reward: 1.3679,                 loss: 0.2255
Episode: 7701/10000 (77.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6356s / 459.1355 s
agent0:                 episode reward: -0.6867,                 loss: nan
agent1:                 episode reward: 0.6867,                 loss: 0.2271
Episode: 7721/10000 (77.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6634s / 460.7989 s
agent0:                 episode reward: -1.4779,                 loss: nan
agent1:                 episode reward: 1.4779,                 loss: 0.2275
Episode: 7741/10000 (77.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6252s / 462.4242 s
agent0:                 episode reward: -1.3473,                 loss: nan
agent1:                 episode reward: 1.3473,                 loss: 0.2271
Episode: 7761/10000 (77.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6566s / 464.0807 s
agent0:                 episode reward: -1.1564,                 loss: nan
agent1:                 episode reward: 1.1564,                 loss: 0.2277
Episode: 7781/10000 (77.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7031s / 465.7839 s
agent0:                 episode reward: -1.8046,                 loss: nan
agent1:                 episode reward: 1.8046,                 loss: 0.2285
Episode: 7801/10000 (78.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6460s / 467.4299 s
agent0:                 episode reward: -0.6862,                 loss: nan
agent1:                 episode reward: 0.6862,                 loss: 0.2304
Episode: 7821/10000 (78.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6773s / 469.1072 s
agent0:                 episode reward: -0.6131,                 loss: nan
agent1:                 episode reward: 0.6131,                 loss: 0.2299
Episode: 7841/10000 (78.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6511s / 470.7583 s
agent0:                 episode reward: -0.7547,                 loss: nan
agent1:                 episode reward: 0.7547,                 loss: 0.2309
Episode: 7861/10000 (78.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6969s / 472.4552 s
agent0:                 episode reward: -1.2999,                 loss: nan
agent1:                 episode reward: 1.2999,                 loss: 0.2308
Episode: 7881/10000 (78.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6784s / 474.1336 s
agent0:                 episode reward: -1.3599,                 loss: nan
agent1:                 episode reward: 1.3599,                 loss: 0.2383
Episode: 7901/10000 (79.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7200s / 475.8535 s
agent0:                 episode reward: -1.1177,                 loss: nan
agent1:                 episode reward: 1.1177,                 loss: 0.2391
Episode: 7921/10000 (79.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7004s / 477.5539 s
agent0:                 episode reward: -1.5999,                 loss: nan
agent1:                 episode reward: 1.5999,                 loss: 0.2408
Episode: 7941/10000 (79.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6628s / 479.2168 s
agent0:                 episode reward: -1.1095,                 loss: nan
agent1:                 episode reward: 1.1095,                 loss: 0.2402
Episode: 7961/10000 (79.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6754s / 480.8921 s
agent0:                 episode reward: -0.4767,                 loss: nan
agent1:                 episode reward: 0.4767,                 loss: 0.2413
Episode: 7981/10000 (79.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6672s / 482.5593 s
agent0:                 episode reward: -1.4234,                 loss: nan
agent1:                 episode reward: 1.4234,                 loss: 0.2550
Episode: 8001/10000 (80.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6931s / 484.2524 s
agent0:                 episode reward: -1.2937,                 loss: nan
agent1:                 episode reward: 1.2937,                 loss: 0.2563
Episode: 8021/10000 (80.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7344s / 485.9869 s
agent0:                 episode reward: -0.7674,                 loss: nan
agent1:                 episode reward: 0.7674,                 loss: 0.2574
Episode: 8041/10000 (80.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6839s / 487.6708 s
agent0:                 episode reward: -1.1319,                 loss: nan
agent1:                 episode reward: 1.1319,                 loss: 0.2568
Episode: 8061/10000 (80.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6937s / 489.3644 s
agent0:                 episode reward: -0.9490,                 loss: nan
agent1:                 episode reward: 0.9490,                 loss: 0.2555
Episode: 8081/10000 (80.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6794s / 491.0439 s
agent0:                 episode reward: -1.5500,                 loss: nan
agent1:                 episode reward: 1.5500,                 loss: 0.2681
Episode: 8101/10000 (81.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6955s / 492.7394 s
agent0:                 episode reward: -0.8193,                 loss: nan
agent1:                 episode reward: 0.8193,                 loss: 0.2689
Episode: 8121/10000 (81.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7111s / 494.4505 s
agent0:                 episode reward: -1.4747,                 loss: nan
agent1:                 episode reward: 1.4747,                 loss: 0.2694
Episode: 8141/10000 (81.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7669s / 496.2174 s
agent0:                 episode reward: -1.5635,                 loss: nan
agent1:                 episode reward: 1.5635,                 loss: 0.2692
Episode: 8161/10000 (81.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7072s / 497.9247 s
agent0:                 episode reward: -1.5171,                 loss: nan
agent1:                 episode reward: 1.5171,                 loss: 0.2695
Episode: 8181/10000 (81.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7206s / 499.6453 s
agent0:                 episode reward: -0.6690,                 loss: nan
agent1:                 episode reward: 0.6690,                 loss: 0.2734
Episode: 8201/10000 (82.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6965s / 501.3418 s
agent0:                 episode reward: -0.8882,                 loss: nan
agent1:                 episode reward: 0.8882,                 loss: 0.2726
Episode: 8221/10000 (82.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7181s / 503.0598 s
agent0:                 episode reward: -1.1731,                 loss: nan
agent1:                 episode reward: 1.1731,                 loss: 0.2733
Episode: 8241/10000 (82.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7241s / 504.7840 s
agent0:                 episode reward: -1.7754,                 loss: nan
agent1:                 episode reward: 1.7754,                 loss: 0.2736
Episode: 8261/10000 (82.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7558s / 506.5397 s
agent0:                 episode reward: -0.9938,                 loss: nan
agent1:                 episode reward: 0.9938,                 loss: 0.2747
Episode: 8281/10000 (82.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7570s / 508.2968 s
agent0:                 episode reward: -1.4038,                 loss: nan
agent1:                 episode reward: 1.4038,                 loss: 0.2731
Episode: 8301/10000 (83.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7281s / 510.0248 s
agent0:                 episode reward: -1.3494,                 loss: nan
agent1:                 episode reward: 1.3494,                 loss: 0.2731
Episode: 8321/10000 (83.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7465s / 511.7713 s
agent0:                 episode reward: -1.0803,                 loss: nan
agent1:                 episode reward: 1.0803,                 loss: 0.2720
Episode: 8341/10000 (83.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7528s / 513.5241 s
agent0:                 episode reward: -0.9028,                 loss: nan
agent1:                 episode reward: 0.9028,                 loss: 0.2720
Episode: 8361/10000 (83.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7406s / 515.2647 s
agent0:                 episode reward: -1.1901,                 loss: nan
agent1:                 episode reward: 1.1901,                 loss: 0.2709
Episode: 8381/10000 (83.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7863s / 517.0510 s
agent0:                 episode reward: -1.5096,                 loss: nan
agent1:                 episode reward: 1.5096,                 loss: 0.2621
Episode: 8401/10000 (84.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7556s / 518.8066 s
agent0:                 episode reward: -1.1649,                 loss: nan
agent1:                 episode reward: 1.1649,                 loss: 0.2599
Episode: 8421/10000 (84.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7661s / 520.5727 s
agent0:                 episode reward: -1.1953,                 loss: nan
agent1:                 episode reward: 1.1953,                 loss: 0.2608
Episode: 8441/10000 (84.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7377s / 522.3103 s
agent0:                 episode reward: -1.2180,                 loss: nan
agent1:                 episode reward: 1.2180,                 loss: 0.2610
Episode: 8461/10000 (84.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7547s / 524.0650 s
agent0:                 episode reward: -1.7028,                 loss: nan
agent1:                 episode reward: 1.7028,                 loss: 0.2604
Episode: 8481/10000 (84.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8198s / 525.8848 s
agent0:                 episode reward: -1.4635,                 loss: nan
agent1:                 episode reward: 1.4635,                 loss: 0.2458
Episode: 8501/10000 (85.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7551s / 527.6399 s
agent0:                 episode reward: -1.0042,                 loss: nan
agent1:                 episode reward: 1.0042,                 loss: 0.2435
Episode: 8521/10000 (85.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7592s / 529.3991 s
agent0:                 episode reward: -1.2975,                 loss: nan
agent1:                 episode reward: 1.2975,                 loss: 0.2430
Episode: 8541/10000 (85.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7598s / 531.1589 s
agent0:                 episode reward: -0.9069,                 loss: nan
agent1:                 episode reward: 0.9069,                 loss: 0.2463
Episode: 8561/10000 (85.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7644s / 532.9233 s
agent0:                 episode reward: -0.9903,                 loss: nan
agent1:                 episode reward: 0.9903,                 loss: 0.2453
Episode: 8581/10000 (85.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7788s / 534.7021 s
agent0:                 episode reward: -1.5105,                 loss: nan
agent1:                 episode reward: 1.5105,                 loss: 0.2466
Episode: 8601/10000 (86.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8199s / 536.5220 s
agent0:                 episode reward: -1.3721,                 loss: nan
agent1:                 episode reward: 1.3721,                 loss: 0.2477
Episode: 8621/10000 (86.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7826s / 538.3046 s
agent0:                 episode reward: -1.5716,                 loss: nan
agent1:                 episode reward: 1.5716,                 loss: 0.2483
Episode: 8641/10000 (86.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7620s / 540.0666 s
agent0:                 episode reward: -1.5280,                 loss: nan
agent1:                 episode reward: 1.5280,                 loss: 0.2475
Episode: 8661/10000 (86.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7857s / 541.8523 s
agent0:                 episode reward: -1.6906,                 loss: nan
agent1:                 episode reward: 1.6906,                 loss: 0.2500
Episode: 8681/10000 (86.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8099s / 543.6623 s
agent0:                 episode reward: -1.4924,                 loss: nan
agent1:                 episode reward: 1.4924,                 loss: 0.2476
Episode: 8701/10000 (87.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8147s / 545.4770 s
agent0:                 episode reward: -1.0398,                 loss: nan
agent1:                 episode reward: 1.0398,                 loss: 0.2463
Episode: 8721/10000 (87.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8524s / 547.3293 s
agent0:                 episode reward: -0.9052,                 loss: nan
agent1:                 episode reward: 0.9052,                 loss: 0.2469
Episode: 8741/10000 (87.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7752s / 549.1046 s
agent0:                 episode reward: -0.9283,                 loss: nan
agent1:                 episode reward: 0.9283,                 loss: 0.2482
Episode: 8761/10000 (87.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7748s / 550.8794 s
agent0:                 episode reward: -0.7379,                 loss: nan
agent1:                 episode reward: 0.7379,                 loss: 0.2461
Episode: 8781/10000 (87.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8080s / 552.6874 s
agent0:                 episode reward: -1.2688,                 loss: nan
agent1:                 episode reward: 1.2688,                 loss: 0.2542
Episode: 8801/10000 (88.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8139s / 554.5013 s
agent0:                 episode reward: -1.0345,                 loss: nan
agent1:                 episode reward: 1.0345,                 loss: 0.2549
Episode: 8821/10000 (88.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8214s / 556.3228 s
agent0:                 episode reward: -1.0390,                 loss: nan
agent1:                 episode reward: 1.0390,                 loss: 0.2529
Episode: 8841/10000 (88.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8865s / 558.2092 s
agent0:                 episode reward: -1.4275,                 loss: nan
agent1:                 episode reward: 1.4275,                 loss: 0.2528
Episode: 8861/10000 (88.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8178s / 560.0271 s
agent0:                 episode reward: -1.1970,                 loss: nan
agent1:                 episode reward: 1.1970,                 loss: 0.2555
Episode: 8881/10000 (88.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8220s / 561.8490 s
agent0:                 episode reward: -0.8747,                 loss: nan
agent1:                 episode reward: 0.8747,                 loss: 0.2495
Episode: 8901/10000 (89.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8191s / 563.6681 s
agent0:                 episode reward: -1.3504,                 loss: nan
agent1:                 episode reward: 1.3504,                 loss: 0.2494
Episode: 8921/10000 (89.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8251s / 565.4932 s
agent0:                 episode reward: -1.1493,                 loss: nan
agent1:                 episode reward: 1.1493,                 loss: 0.2482
Episode: 8941/10000 (89.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8653s / 567.3585 s
agent0:                 episode reward: -1.4807,                 loss: nan
agent1:                 episode reward: 1.4807,                 loss: 0.2498
Episode: 8961/10000 (89.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8301s / 569.1886 s
agent0:                 episode reward: -1.5699,                 loss: nan
agent1:                 episode reward: 1.5699,                 loss: 0.2501
Episode: 8981/10000 (89.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8429s / 571.0315 s
agent0:                 episode reward: -1.6068,                 loss: nan
agent1:                 episode reward: 1.6068,                 loss: 0.2424
Episode: 9001/10000 (90.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8308s / 572.8622 s
agent0:                 episode reward: -1.5219,                 loss: nan
agent1:                 episode reward: 1.5219,                 loss: 0.2401
Episode: 9021/10000 (90.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9258s / 574.7880 s
agent0:                 episode reward: -1.2544,                 loss: nan
agent1:                 episode reward: 1.2544,                 loss: 0.2394
Episode: 9041/10000 (90.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9134s / 576.7015 s
agent0:                 episode reward: -1.3384,                 loss: nan
agent1:                 episode reward: 1.3384,                 loss: 0.2391
Episode: 9061/10000 (90.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8943s / 578.5958 s
agent0:                 episode reward: -1.3840,                 loss: nan
agent1:                 episode reward: 1.3840,                 loss: 0.2408
Episode: 9081/10000 (90.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8271s / 580.4229 s
agent0:                 episode reward: -1.0881,                 loss: nan
agent1:                 episode reward: 1.0881,                 loss: 0.2444
Episode: 9101/10000 (91.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8418s / 582.2648 s
agent0:                 episode reward: -1.7929,                 loss: nan
agent1:                 episode reward: 1.7929,                 loss: 0.2460
Episode: 9121/10000 (91.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8466s / 584.1113 s
agent0:                 episode reward: -1.8263,                 loss: nan
agent1:                 episode reward: 1.8263,                 loss: 0.2449
Episode: 9141/10000 (91.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8735s / 585.9848 s
agent0:                 episode reward: -1.3900,                 loss: nan
agent1:                 episode reward: 1.3900,                 loss: 0.2456
Episode: 9161/10000 (91.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9242s / 587.9090 s
agent0:                 episode reward: -1.4087,                 loss: nan
agent1:                 episode reward: 1.4087,                 loss: 0.2467
Episode: 9181/10000 (91.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8507s / 589.7597 s
agent0:                 episode reward: -1.1355,                 loss: nan
agent1:                 episode reward: 1.1355,                 loss: 0.2498
Episode: 9201/10000 (92.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8985s / 591.6582 s
agent0:                 episode reward: -1.4557,                 loss: nan
agent1:                 episode reward: 1.4557,                 loss: 0.2518
Episode: 9221/10000 (92.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9060s / 593.5642 s
agent0:                 episode reward: -1.4738,                 loss: nan
agent1:                 episode reward: 1.4738,                 loss: 0.2514
Episode: 9241/10000 (92.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8862s / 595.4504 s
agent0:                 episode reward: -1.2995,                 loss: nan
agent1:                 episode reward: 1.2995,                 loss: 0.2514
Episode: 9261/10000 (92.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8627s / 597.3131 s
agent0:                 episode reward: -1.6098,                 loss: nan
agent1:                 episode reward: 1.6098,                 loss: 0.2533
Episode: 9281/10000 (92.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9196s / 599.2326 s
agent0:                 episode reward: -1.5924,                 loss: nan
agent1:                 episode reward: 1.5924,                 loss: 0.2585
Episode: 9301/10000 (93.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8790s / 601.1116 s
agent0:                 episode reward: -1.5582,                 loss: nan
agent1:                 episode reward: 1.5582,                 loss: 0.2605
Episode: 9321/10000 (93.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8865s / 602.9981 s
agent0:                 episode reward: -1.2283,                 loss: nan
agent1:                 episode reward: 1.2283,                 loss: 0.2595
Episode: 9341/10000 (93.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9238s / 604.9219 s
agent0:                 episode reward: -0.7190,                 loss: nan
agent1:                 episode reward: 0.7190,                 loss: 0.2599
Episode: 9361/10000 (93.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8896s / 606.8115 s
agent0:                 episode reward: -0.7059,                 loss: nan
agent1:                 episode reward: 0.7059,                 loss: 0.2583
Episode: 9381/10000 (93.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9318s / 608.7433 s
agent0:                 episode reward: -1.1295,                 loss: nan
agent1:                 episode reward: 1.1295,                 loss: 0.2577
Episode: 9401/10000 (94.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9176s / 610.6609 s
agent0:                 episode reward: -0.9906,                 loss: nan
agent1:                 episode reward: 0.9906,                 loss: 0.2573
Episode: 9421/10000 (94.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8827s / 612.5436 s
agent0:                 episode reward: -0.8209,                 loss: nan
agent1:                 episode reward: 0.8209,                 loss: 0.2606
Episode: 9441/10000 (94.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8891s / 614.4327 s
agent0:                 episode reward: -1.4257,                 loss: nan
agent1:                 episode reward: 1.4257,                 loss: 0.2607
Episode: 9461/10000 (94.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9219s / 616.3546 s
agent0:                 episode reward: -1.8059,                 loss: nan
agent1:                 episode reward: 1.8059,                 loss: 0.2585
Episode: 9481/10000 (94.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9556s / 618.3102 s
agent0:                 episode reward: -1.4468,                 loss: nan
agent1:                 episode reward: 1.4468,                 loss: 0.2609
Episode: 9501/10000 (95.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9399s / 620.2501 s
agent0:                 episode reward: -1.4985,                 loss: nan
agent1:                 episode reward: 1.4985,                 loss: 0.2618
Episode: 9521/10000 (95.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9155s / 622.1656 s
agent0:                 episode reward: -1.6964,                 loss: nan
agent1:                 episode reward: 1.6964,                 loss: 0.2614
Episode: 9541/10000 (95.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9093s / 624.0749 s
agent0:                 episode reward: -1.1522,                 loss: nan
agent1:                 episode reward: 1.1522,                 loss: 0.2612
Episode: 9561/10000 (95.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9488s / 626.0237 s
agent0:                 episode reward: -1.3155,                 loss: nan
agent1:                 episode reward: 1.3155,                 loss: 0.2597
Episode: 9581/10000 (95.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9653s / 627.9890 s
agent0:                 episode reward: -1.6966,                 loss: nan
agent1:                 episode reward: 1.6966,                 loss: 0.2611
Episode: 9601/10000 (96.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0036s / 629.9926 s
agent0:                 episode reward: -1.4558,                 loss: nan
agent1:                 episode reward: 1.4558,                 loss: 0.2581
Episode: 9621/10000 (96.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9463s / 631.9389 s
agent0:                 episode reward: -0.8807,                 loss: nan
agent1:                 episode reward: 0.8807,                 loss: 0.2599
Episode: 9641/10000 (96.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9470s / 633.8859 s
agent0:                 episode reward: -0.8574,                 loss: nan
agent1:                 episode reward: 0.8574,                 loss: 0.2592
Episode: 9661/10000 (96.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9705s / 635.8564 s
agent0:                 episode reward: -1.1209,                 loss: nan
agent1:                 episode reward: 1.1209,                 loss: 0.2593
Episode: 9681/10000 (96.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9677s / 637.8240 s
agent0:                 episode reward: -1.6024,                 loss: nan
agent1:                 episode reward: 1.6024,                 loss: 0.2605
Episode: 9701/10000 (97.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9909s / 639.8149 s
agent0:                 episode reward: -1.7541,                 loss: nan
agent1:                 episode reward: 1.7541,                 loss: 0.2581
Episode: 9721/10000 (97.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9318s / 641.7468 s
agent0:                 episode reward: -0.8266,                 loss: nan
agent1:                 episode reward: 0.8266,                 loss: 0.2599
Episode: 9741/10000 (97.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9603s / 643.7070 s
agent0:                 episode reward: -1.6618,                 loss: nan
agent1:                 episode reward: 1.6618,                 loss: 0.2597
Episode: 9761/10000 (97.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9489s / 645.6559 s
agent0:                 episode reward: -1.7420,                 loss: nan
agent1:                 episode reward: 1.7420,                 loss: 0.2594/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

Episode: 9781/10000 (97.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9666s / 647.6225 s
agent0:                 episode reward: -2.1230,                 loss: nan
agent1:                 episode reward: 2.1230,                 loss: 0.2634
Episode: 9801/10000 (98.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0300s / 649.6525 s
agent0:                 episode reward: -1.6594,                 loss: nan
agent1:                 episode reward: 1.6594,                 loss: 0.2638
Episode: 9821/10000 (98.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9824s / 651.6349 s
agent0:                 episode reward: -1.5892,                 loss: nan
agent1:                 episode reward: 1.5892,                 loss: 0.2631
Episode: 9841/10000 (98.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9657s / 653.6006 s
agent0:                 episode reward: -1.5353,                 loss: nan
agent1:                 episode reward: 1.5353,                 loss: 0.2626
Episode: 9861/10000 (98.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9665s / 655.5671 s
agent0:                 episode reward: -1.6754,                 loss: nan
agent1:                 episode reward: 1.6754,                 loss: 0.2652
Episode: 9881/10000 (98.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9888s / 657.5558 s
agent0:                 episode reward: -1.8556,                 loss: nan
agent1:                 episode reward: 1.8556,                 loss: 0.2572
Episode: 9901/10000 (99.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0606s / 659.6165 s
agent0:                 episode reward: -1.4807,                 loss: nan
agent1:                 episode reward: 1.4807,                 loss: 0.2556
Episode: 9921/10000 (99.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9823s / 661.5988 s
agent0:                 episode reward: -1.3356,                 loss: nan
agent1:                 episode reward: 1.3356,                 loss: 0.2575
Episode: 9941/10000 (99.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9870s / 663.5858 s
agent0:                 episode reward: -0.8906,                 loss: nan
agent1:                 episode reward: 0.8906,                 loss: 0.2568
Episode: 9961/10000 (99.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9703s / 665.5561 s
agent0:                 episode reward: -1.9023,                 loss: nan
agent1:                 episode reward: 1.9023,                 loss: 0.2597
Episode: 9981/10000 (99.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9990s / 667.5551 s
agent0:                 episode reward: -1.4791,                 loss: nan
agent1:                 episode reward: 1.4791,                 loss: 0.2482
