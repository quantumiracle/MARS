pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
boxing_v1 pettingzoo
Load boxing_v1 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
random seed: 99
<mars.env.wrappers.mars_wrappers.Dict2TupleWrapper object at 0x7fa178ac9550>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
Agents No. [0] (index starting from 0) are not learnable.
Load meta strategy:  [[0.05  0.049 0.031 ... 0.    0.001 0.063]
 [0.    0.    0.    ... 0.    0.    1.   ]]
Load checkpoints (policy family):  [['522' '1121' '1601' ... '7184' '7562' '7943']
 ['810' '1443' '1639' ... '7205' '7583' '7964']]
Arguments:  {'env_name': 'boxing_v1', 'env_type': 'pettingzoo', 'num_envs': 1, 'ram': True, 'seed': 'random', 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': './data/model/20220429_0152/pettingzoo_boxing_v1_nxdo2/', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nxdo2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'selfplay_score_delta': 80, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'against_baseline': False, 'idx_exploited_model': 0}
Save models to : /home/zihan/research/MARS/data/model/20220429_0152_exploit_first_/pettingzoo_boxing_v1_nxdo2. 
 Save logs to: /home/zihan/research/MARS/data/log/20220429_0152_exploit_first_/pettingzoo_boxing_v1_nxdo2.
Episode: 1/10000 (0.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 9.7528s / 9.7528 s
first_0:                 episode reward: 0.0000,                 loss: nan
second_0:                 episode reward: 0.0000,                 loss: 0.3955
Episode: 21/10000 (0.2100%),                 avg. length: 286.1,                last time consumption/overall running time: 62.0679s / 71.8208 s
first_0:                 episode reward: 42.4000,                 loss: nan
second_0:                 episode reward: -42.4000,                 loss: 0.0936
Episode: 41/10000 (0.4100%),                 avg. length: 298.5,                last time consumption/overall running time: 64.3682s / 136.1890 s
first_0:                 episode reward: 35.5000,                 loss: nan
second_0:                 episode reward: -35.5000,                 loss: 0.0424
Episode: 61/10000 (0.6100%),                 avg. length: 286.75,                last time consumption/overall running time: 61.9282s / 198.1172 s
first_0:                 episode reward: 45.3000,                 loss: nan
second_0:                 episode reward: -45.3000,                 loss: 0.0409
Episode: 81/10000 (0.8100%),                 avg. length: 294.95,                last time consumption/overall running time: 64.2487s / 262.3659 s
first_0:                 episode reward: 37.7000,                 loss: nan
second_0:                 episode reward: -37.7000,                 loss: 0.0448
Episode: 101/10000 (1.0100%),                 avg. length: 295.5,                last time consumption/overall running time: 64.8868s / 327.2527 s
first_0:                 episode reward: 39.9500,                 loss: nan
second_0:                 episode reward: -39.9500,                 loss: 0.0477
Episode: 121/10000 (1.2100%),                 avg. length: 297.8,                last time consumption/overall running time: 65.9992s / 393.2520 s
first_0:                 episode reward: 31.6500,                 loss: nan
second_0:                 episode reward: -31.6500,                 loss: 0.0507
Episode: 141/10000 (1.4100%),                 avg. length: 298.15,                last time consumption/overall running time: 66.5499s / 459.8019 s
first_0:                 episode reward: 34.4000,                 loss: nan
second_0:                 episode reward: -34.4000,                 loss: 0.0510
Episode: 161/10000 (1.6100%),                 avg. length: 293.95,                last time consumption/overall running time: 66.7639s / 526.5658 s
first_0:                 episode reward: 34.4500,                 loss: nan
second_0:                 episode reward: -34.4500,                 loss: 0.0491
Episode: 181/10000 (1.8100%),                 avg. length: 290.3,                last time consumption/overall running time: 66.3494s / 592.9152 s
first_0:                 episode reward: 37.1500,                 loss: nan
second_0:                 episode reward: -37.1500,                 loss: 0.0484
Episode: 201/10000 (2.0100%),                 avg. length: 295.65,                last time consumption/overall running time: 68.2367s / 661.1519 s
first_0:                 episode reward: 27.6000,                 loss: nan
second_0:                 episode reward: -27.6000,                 loss: 0.0461
Episode: 221/10000 (2.2100%),                 avg. length: 295.1,                last time consumption/overall running time: 68.4210s / 729.5729 s
first_0:                 episode reward: 36.3000,                 loss: nan
second_0:                 episode reward: -36.3000,                 loss: 0.0439
Episode: 241/10000 (2.4100%),                 avg. length: 295.7,                last time consumption/overall running time: 68.9370s / 798.5099 s
first_0:                 episode reward: 28.8000,                 loss: nan
second_0:                 episode reward: -28.8000,                 loss: 0.0435
Episode: 261/10000 (2.6100%),                 avg. length: 294.9,                last time consumption/overall running time: 69.7181s / 868.2280 s
first_0:                 episode reward: 22.3000,                 loss: nan
second_0:                 episode reward: -22.3000,                 loss: 0.0430
Episode: 281/10000 (2.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 71.2433s / 939.4713 s
first_0:                 episode reward: 17.9000,                 loss: nan
second_0:                 episode reward: -17.9000,                 loss: 0.0426
Episode: 301/10000 (3.0100%),                 avg. length: 296.25,                last time consumption/overall running time: 71.0309s / 1010.5023 s
first_0:                 episode reward: 31.6000,                 loss: nan
second_0:                 episode reward: -31.6000,                 loss: 0.0433
Episode: 321/10000 (3.2100%),                 avg. length: 293.5,                last time consumption/overall running time: 71.9811s / 1082.4834 s
first_0:                 episode reward: 35.7000,                 loss: nan
second_0:                 episode reward: -35.7000,                 loss: 0.0417
Episode: 341/10000 (3.4100%),                 avg. length: 296.6,                last time consumption/overall running time: 74.0481s / 1156.5315 s
first_0:                 episode reward: 25.6500,                 loss: nan
second_0:                 episode reward: -25.6500,                 loss: 0.0433
Episode: 361/10000 (3.6100%),                 avg. length: 298.9,                last time consumption/overall running time: 75.0631s / 1231.5945 s
first_0:                 episode reward: 25.0000,                 loss: nan
second_0:                 episode reward: -25.0000,                 loss: 0.0438
Episode: 381/10000 (3.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.4363s / 1307.0308 s
first_0:                 episode reward: 14.4500,                 loss: nan
second_0:                 episode reward: -14.4500,                 loss: 0.0450
Episode: 401/10000 (4.0100%),                 avg. length: 298.15,                last time consumption/overall running time: 75.1660s / 1382.1968 s
first_0:                 episode reward: 14.1000,                 loss: nan
second_0:                 episode reward: -14.1000,                 loss: 0.0450
Episode: 421/10000 (4.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.2618s / 1457.4587 s
first_0:                 episode reward: 19.6500,                 loss: nan
second_0:                 episode reward: -19.6500,                 loss: 0.0447
Episode: 441/10000 (4.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 74.9364s / 1532.3951 s
first_0:                 episode reward: 17.7500,                 loss: nan
second_0:                 episode reward: -17.7500,                 loss: 0.0448
Episode: 461/10000 (4.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.0231s / 1607.4182 s
first_0:                 episode reward: 10.4500,                 loss: nan
second_0:                 episode reward: -10.4500,                 loss: 0.0437
Episode: 481/10000 (4.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.4313s / 1682.8495 s
first_0:                 episode reward: 4.0500,                 loss: nan
second_0:                 episode reward: -4.0500,                 loss: 0.0440
Episode: 501/10000 (5.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.1916s / 1758.0410 s
first_0:                 episode reward: 5.5500,                 loss: nan
second_0:                 episode reward: -5.5500,                 loss: 0.0450
Episode: 521/10000 (5.2100%),                 avg. length: 295.05,                last time consumption/overall running time: 74.0968s / 1832.1379 s
first_0:                 episode reward: 12.5500,                 loss: nan
second_0:                 episode reward: -12.5500,                 loss: 0.0460
Episode: 541/10000 (5.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.3297s / 1907.4675 s
first_0:                 episode reward: 15.3500,                 loss: nan
second_0:                 episode reward: -15.3500,                 loss: 0.0454
Episode: 561/10000 (5.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.0701s / 1982.5377 s
first_0:                 episode reward: 8.7500,                 loss: nan
second_0:                 episode reward: -8.7500,                 loss: 0.0482
Episode: 581/10000 (5.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.1634s / 2057.7010 s
first_0:                 episode reward: 11.2000,                 loss: nan
second_0:                 episode reward: -11.2000,                 loss: 0.0485
Episode: 601/10000 (6.0100%),                 avg. length: 297.2,                last time consumption/overall running time: 74.8420s / 2132.5430 s
first_0:                 episode reward: 17.6000,                 loss: nan
second_0:                 episode reward: -17.6000,                 loss: 0.0468
Episode: 621/10000 (6.2100%),                 avg. length: 296.1,                last time consumption/overall running time: 74.5061s / 2207.0491 s
first_0:                 episode reward: 23.4000,                 loss: nan
second_0:                 episode reward: -23.4000,                 loss: 0.0486
Episode: 641/10000 (6.4100%),                 avg. length: 297.4,                last time consumption/overall running time: 74.9375s / 2281.9867 s
first_0:                 episode reward: 10.5500,                 loss: nan
second_0:                 episode reward: -10.5500,                 loss: 0.0468
Episode: 661/10000 (6.6100%),                 avg. length: 293.95,                last time consumption/overall running time: 74.4077s / 2356.3944 s
first_0:                 episode reward: 20.3500,                 loss: nan
second_0:                 episode reward: -20.3500,                 loss: 0.0488
Episode: 681/10000 (6.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.8113s / 2432.2057 s
first_0:                 episode reward: 7.4500,                 loss: nan
second_0:                 episode reward: -7.4500,                 loss: 0.0487
Episode: 701/10000 (7.0100%),                 avg. length: 297.95,                last time consumption/overall running time: 75.0850s / 2507.2907 s
first_0:                 episode reward: 15.0500,                 loss: nan
second_0:                 episode reward: -15.0500,                 loss: 0.0493
Episode: 721/10000 (7.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.6848s / 2582.9755 s
first_0:                 episode reward: 17.7000,                 loss: nan
second_0:                 episode reward: -17.7000,                 loss: 0.0484
Episode: 741/10000 (7.4100%),                 avg. length: 296.5,                last time consumption/overall running time: 75.0108s / 2657.9863 s
first_0:                 episode reward: 24.1000,                 loss: nan
second_0:                 episode reward: -24.1000,                 loss: 0.0463
Episode: 761/10000 (7.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.3345s / 2733.3208 s
first_0:                 episode reward: 13.7500,                 loss: nan
second_0:                 episode reward: -13.7500,                 loss: 0.0453
Episode: 781/10000 (7.8100%),                 avg. length: 298.05,                last time consumption/overall running time: 75.8016s / 2809.1223 s
first_0:                 episode reward: 23.9000,                 loss: nan
second_0:                 episode reward: -23.9000,                 loss: 0.0446
Episode: 801/10000 (8.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.4805s / 2885.6029 s
first_0:                 episode reward: 14.2500,                 loss: nan
second_0:                 episode reward: -14.2500,                 loss: 0.0455
Episode: 821/10000 (8.2100%),                 avg. length: 293.85,                last time consumption/overall running time: 74.9670s / 2960.5698 s
first_0:                 episode reward: 15.6500,                 loss: nan
second_0:                 episode reward: -15.6500,                 loss: 0.0466
Episode: 841/10000 (8.4100%),                 avg. length: 298.55,                last time consumption/overall running time: 75.9479s / 3036.5177 s
first_0:                 episode reward: 8.4000,                 loss: nan
second_0:                 episode reward: -8.4000,                 loss: 0.0456
Episode: 861/10000 (8.6100%),                 avg. length: 296.65,                last time consumption/overall running time: 74.3833s / 3110.9010 s
first_0:                 episode reward: 25.6000,                 loss: nan
second_0:                 episode reward: -25.6000,                 loss: 0.0453
Episode: 881/10000 (8.8100%),                 avg. length: 286.6,                last time consumption/overall running time: 72.4515s / 3183.3525 s
first_0:                 episode reward: 18.9000,                 loss: nan
second_0:                 episode reward: -18.9000,                 loss: 0.0455
Episode: 901/10000 (9.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.8898s / 3259.2423 s
first_0:                 episode reward: 10.2000,                 loss: nan
second_0:                 episode reward: -10.2000,                 loss: 0.0437
Episode: 921/10000 (9.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.0360s / 3335.2783 s
first_0:                 episode reward: 4.0000,                 loss: nan
second_0:                 episode reward: -4.0000,                 loss: 0.0452
Episode: 941/10000 (9.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.5338s / 3410.8121 s
first_0:                 episode reward: 7.7000,                 loss: nan
second_0:                 episode reward: -7.7000,                 loss: 0.0470
Episode: 961/10000 (9.6100%),                 avg. length: 296.7,                last time consumption/overall running time: 75.1628s / 3485.9750 s
first_0:                 episode reward: 0.2000,                 loss: nan
second_0:                 episode reward: -0.2000,                 loss: 0.0469
Episode: 981/10000 (9.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.6604s / 3561.6354 s
first_0:                 episode reward: 6.3000,                 loss: nan
second_0:                 episode reward: -6.3000,                 loss: 0.0462
Episode: 1001/10000 (10.0100%),                 avg. length: 298.15,                last time consumption/overall running time: 75.7654s / 3637.4008 s
first_0:                 episode reward: -1.9500,                 loss: nan
second_0:                 episode reward: 1.9500,                 loss: 0.0489
Episode: 1021/10000 (10.2100%),                 avg. length: 298.1,                last time consumption/overall running time: 75.7517s / 3713.1525 s
first_0:                 episode reward: -2.8000,                 loss: nan
second_0:                 episode reward: 2.8000,                 loss: 0.0491
Episode: 1041/10000 (10.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.8966s / 3789.0491 s
first_0:                 episode reward: -21.2000,                 loss: nan
second_0:                 episode reward: 21.2000,                 loss: 0.0480
Episode: 1061/10000 (10.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.8373s / 3864.8864 s
first_0:                 episode reward: -16.1500,                 loss: nan
second_0:                 episode reward: 16.1500,                 loss: 0.0486
Episode: 1081/10000 (10.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.0303s / 3940.9167 s
first_0:                 episode reward: -17.2500,                 loss: nan
second_0:                 episode reward: 17.2500,                 loss: 0.0481
Episode: 1101/10000 (11.0100%),                 avg. length: 295.95,                last time consumption/overall running time: 75.5860s / 4016.5027 s
first_0:                 episode reward: 2.0500,                 loss: nan
second_0:                 episode reward: -2.0500,                 loss: 0.0479
Episode: 1121/10000 (11.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.3024s / 4092.8051 s
first_0:                 episode reward: -11.7500,                 loss: nan
second_0:                 episode reward: 11.7500,                 loss: 0.0484
Episode: 1141/10000 (11.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.8237s / 4168.6289 s
first_0:                 episode reward: -13.9000,                 loss: nan
second_0:                 episode reward: 13.9000,                 loss: 0.0479
Episode: 1161/10000 (11.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.5536s / 4244.1825 s
first_0:                 episode reward: -8.9000,                 loss: nan
second_0:                 episode reward: 8.9000,                 loss: 0.0467
Episode: 1181/10000 (11.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.7684s / 4319.9508 s
first_0:                 episode reward: -16.7500,                 loss: nan
second_0:                 episode reward: 16.7500,                 loss: 0.0461
Episode: 1201/10000 (12.0100%),                 avg. length: 298.45,                last time consumption/overall running time: 75.6738s / 4395.6247 s
first_0:                 episode reward: -8.6000,                 loss: nan
second_0:                 episode reward: 8.6000,                 loss: 0.0470
Episode: 1221/10000 (12.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.7590s / 4471.3837 s
first_0:                 episode reward: -18.1000,                 loss: nan
second_0:                 episode reward: 18.1000,                 loss: 0.0492
Episode: 1241/10000 (12.4100%),                 avg. length: 292.35,                last time consumption/overall running time: 73.4423s / 4544.8260 s
first_0:                 episode reward: -9.7000,                 loss: nan
second_0:                 episode reward: 9.7000,                 loss: 0.0479
Episode: 1261/10000 (12.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.8948s / 4620.7208 s
first_0:                 episode reward: -25.1500,                 loss: nan
second_0:                 episode reward: 25.1500,                 loss: 0.0452
Episode: 1281/10000 (12.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.1888s / 4696.9095 s
first_0:                 episode reward: -31.5500,                 loss: nan
second_0:                 episode reward: 31.5500,                 loss: 0.0446
Episode: 1301/10000 (13.0100%),                 avg. length: 297.55,                last time consumption/overall running time: 75.5587s / 4772.4682 s
first_0:                 episode reward: -22.7000,                 loss: nan
second_0:                 episode reward: 22.7000,                 loss: 0.0460
Episode: 1321/10000 (13.2100%),                 avg. length: 296.0,                last time consumption/overall running time: 75.1561s / 4847.6243 s
first_0:                 episode reward: -30.2500,                 loss: nan
second_0:                 episode reward: 30.2500,                 loss: 0.0446
Episode: 1341/10000 (13.4100%),                 avg. length: 295.1,                last time consumption/overall running time: 74.6127s / 4922.2370 s
first_0:                 episode reward: -22.5500,                 loss: nan
second_0:                 episode reward: 22.5500,                 loss: 0.0448
Episode: 1361/10000 (13.6100%),                 avg. length: 297.35,                last time consumption/overall running time: 75.1102s / 4997.3472 s
first_0:                 episode reward: -22.4500,                 loss: nan
second_0:                 episode reward: 22.4500,                 loss: 0.0460
Episode: 1381/10000 (13.8100%),                 avg. length: 295.7,                last time consumption/overall running time: 75.2313s / 5072.5785 s
first_0:                 episode reward: -16.0000,                 loss: nan
second_0:                 episode reward: 16.0000,                 loss: 0.0426
Episode: 1401/10000 (14.0100%),                 avg. length: 298.55,                last time consumption/overall running time: 76.0230s / 5148.6015 s
first_0:                 episode reward: -7.0500,                 loss: nan
second_0:                 episode reward: 7.0500,                 loss: 0.0415
Episode: 1421/10000 (14.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.7448s / 5224.3464 s
first_0:                 episode reward: -40.3500,                 loss: nan
second_0:                 episode reward: 40.3500,                 loss: 0.0410
Episode: 1441/10000 (14.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.6142s / 5299.9606 s
first_0:                 episode reward: -33.0500,                 loss: nan
second_0:                 episode reward: 33.0500,                 loss: 0.0415
Episode: 1461/10000 (14.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.7362s / 5375.6969 s
first_0:                 episode reward: -21.1000,                 loss: nan
second_0:                 episode reward: 21.1000,                 loss: 0.0410
Episode: 1481/10000 (14.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.0022s / 5451.6990 s
first_0:                 episode reward: -34.2000,                 loss: nan
second_0:                 episode reward: 34.2000,                 loss: 0.0411
Episode: 1501/10000 (15.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.0938s / 5527.7929 s
first_0:                 episode reward: -26.0500,                 loss: nan
second_0:                 episode reward: 26.0500,                 loss: 0.0409
Episode: 1521/10000 (15.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.3832s / 5604.1761 s
first_0:                 episode reward: -47.1000,                 loss: nan
second_0:                 episode reward: 47.1000,                 loss: 0.0403
Episode: 1541/10000 (15.4100%),                 avg. length: 295.35,                last time consumption/overall running time: 75.3540s / 5679.5301 s
first_0:                 episode reward: -42.6000,                 loss: nan
second_0:                 episode reward: 42.6000,                 loss: 0.0402
Episode: 1561/10000 (15.6100%),                 avg. length: 295.1,                last time consumption/overall running time: 74.9916s / 5754.5217 s
first_0:                 episode reward: -28.3000,                 loss: nan
second_0:                 episode reward: 28.3000,                 loss: 0.0393
Episode: 1581/10000 (15.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.2374s / 5830.7590 s
first_0:                 episode reward: -41.8500,                 loss: nan
second_0:                 episode reward: 41.8500,                 loss: 0.0408
Episode: 1601/10000 (16.0100%),                 avg. length: 296.8,                last time consumption/overall running time: 75.6181s / 5906.3771 s
first_0:                 episode reward: -55.3000,                 loss: nan
second_0:                 episode reward: 55.3000,                 loss: 0.0408
Episode: 1621/10000 (16.2100%),                 avg. length: 296.35,                last time consumption/overall running time: 75.0771s / 5981.4542 s
first_0:                 episode reward: -52.1000,                 loss: nan
second_0:                 episode reward: 52.1000,                 loss: 0.0395
Episode: 1641/10000 (16.4100%),                 avg. length: 293.75,                last time consumption/overall running time: 74.4731s / 6055.9273 s
first_0:                 episode reward: -63.1000,                 loss: nan
second_0:                 episode reward: 63.1000,                 loss: 0.0396
Episode: 1661/10000 (16.6100%),                 avg. length: 283.1,                last time consumption/overall running time: 71.6442s / 6127.5716 s
first_0:                 episode reward: -47.7000,                 loss: nan
second_0:                 episode reward: 47.7000,                 loss: 0.0383
Episode: 1681/10000 (16.8100%),                 avg. length: 281.3,                last time consumption/overall running time: 71.7079s / 6199.2795 s
first_0:                 episode reward: -47.0000,                 loss: nan
second_0:                 episode reward: 47.0000,                 loss: 0.0371
Episode: 1701/10000 (17.0100%),                 avg. length: 271.45,                last time consumption/overall running time: 69.2056s / 6268.4851 s
first_0:                 episode reward: -70.6500,                 loss: nan
second_0:                 episode reward: 70.6500,                 loss: 0.0366
Episode: 1721/10000 (17.2100%),                 avg. length: 279.6,                last time consumption/overall running time: 70.8743s / 6339.3594 s
first_0:                 episode reward: -68.9000,                 loss: nan
second_0:                 episode reward: 68.9000,                 loss: 0.0356
Episode: 1741/10000 (17.4100%),                 avg. length: 274.05,                last time consumption/overall running time: 70.1739s / 6409.5333 s
first_0:                 episode reward: -73.2500,                 loss: nan
second_0:                 episode reward: 73.2500,                 loss: 0.0348
Episode: 1761/10000 (17.6100%),                 avg. length: 272.65,                last time consumption/overall running time: 69.5712s / 6479.1045 s
first_0:                 episode reward: -69.8500,                 loss: nan
second_0:                 episode reward: 69.8500,                 loss: 0.0341
Episode: 1781/10000 (17.8100%),                 avg. length: 275.8,                last time consumption/overall running time: 70.7295s / 6549.8340 s
first_0:                 episode reward: -68.8500,                 loss: nan
second_0:                 episode reward: 68.8500,                 loss: 0.0327
Episode: 1801/10000 (18.0100%),                 avg. length: 264.0,                last time consumption/overall running time: 67.1461s / 6616.9801 s
first_0:                 episode reward: -51.2500,                 loss: nan
second_0:                 episode reward: 51.2500,                 loss: 0.0315
Episode: 1821/10000 (18.2100%),                 avg. length: 280.9,                last time consumption/overall running time: 71.6936s / 6688.6737 s
first_0:                 episode reward: -66.5500,                 loss: nan
second_0:                 episode reward: 66.5500,                 loss: 0.0302
Episode: 1841/10000 (18.4100%),                 avg. length: 270.65,                last time consumption/overall running time: 69.3779s / 6758.0516 s
first_0:                 episode reward: -76.5000,                 loss: nan
second_0:                 episode reward: 76.5000,                 loss: 0.0292
Episode: 1861/10000 (18.6100%),                 avg. length: 269.35,                last time consumption/overall running time: 68.4480s / 6826.4996 s
first_0:                 episode reward: -54.7500,                 loss: nan
second_0:                 episode reward: 54.7500,                 loss: 0.0279
Episode: 1881/10000 (18.8100%),                 avg. length: 269.35,                last time consumption/overall running time: 68.9319s / 6895.4315 s
first_0:                 episode reward: -61.3000,                 loss: nan
second_0:                 episode reward: 61.3000,                 loss: 0.0267
Episode: 1901/10000 (19.0100%),                 avg. length: 261.95,                last time consumption/overall running time: 66.9787s / 6962.4102 s
first_0:                 episode reward: -62.1000,                 loss: nan
second_0:                 episode reward: 62.1000,                 loss: 0.0258
Episode: 1921/10000 (19.2100%),                 avg. length: 273.4,                last time consumption/overall running time: 69.7558s / 7032.1660 s
first_0:                 episode reward: -58.2000,                 loss: nan
second_0:                 episode reward: 58.2000,                 loss: 0.0246
Episode: 1941/10000 (19.4100%),                 avg. length: 271.85,                last time consumption/overall running time: 69.4739s / 7101.6399 s
first_0:                 episode reward: -72.9000,                 loss: nan
second_0:                 episode reward: 72.9000,                 loss: 0.0234
Episode: 1961/10000 (19.6100%),                 avg. length: 267.55,                last time consumption/overall running time: 68.7743s / 7170.4142 s