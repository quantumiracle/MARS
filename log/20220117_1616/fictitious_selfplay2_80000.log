pygame 2.0.0 (SDL 2.0.12, python 3.7.10)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 12.0, (1,), float32) action space: Discrete(3)
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7f4e7eb76090>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
Agents No. [0] (index starting from 0) are not learnable.
Load meta strategy:  [[0.007 0.007 0.007 ... 0.007 0.007 0.007]
 [0.007 0.007 0.007 ... 0.007 0.007 0.007]]
Load checkpoints (policy family):  [['50' '5253' '7615' ... '78324' '78707' '79242']
 ['193' '5289' '7712' ... '78482' '78910' '79413']]
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': 1, 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000, 'update_itr': 1}, 'batch_size': 640, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'cpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220117153310/epi_80000/', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'fictitious_selfplay2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'selfplay_score_delta': 1.5, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'against_baseline': False}
Save models to : /home/zihan/research/MARS/data/model/20220117153310_exploit_80000/mdp_arbitrary_mdp_fictitious_selfplay2. 
 Save logs to: /home/zihan/research/MARS/data/log/20220117153310_exploit_80000/mdp_arbitrary_mdp_fictitious_selfplay2.
Episode: 1/30000 (0.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 5.0058s / 5.0058 s
agent0:                 episode reward: 0.1344,                 loss: nan
agent1:                 episode reward: -0.1344,                 loss: nan
Episode: 21/30000 (0.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 4.5712s / 9.5770 s
agent0:                 episode reward: -0.0221,                 loss: nan
agent1:                 episode reward: 0.0221,                 loss: nan
Episode: 41/30000 (0.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 4.8417s / 14.4188 s
agent0:                 episode reward: 0.0709,                 loss: nan
agent1:                 episode reward: -0.0709,                 loss: nan
Episode: 61/30000 (0.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 4.6134s / 19.0321 s
agent0:                 episode reward: 0.2649,                 loss: nan
agent1:                 episode reward: -0.2649,                 loss: nan
Episode: 81/30000 (0.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 4.6702s / 23.7023 s
agent0:                 episode reward: 0.1258,                 loss: nan
agent1:                 episode reward: -0.1258,                 loss: nan
Episode: 101/30000 (0.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 4.9726s / 28.6750 s
agent0:                 episode reward: 0.0422,                 loss: nan
agent1:                 episode reward: -0.0422,                 loss: nan
Episode: 121/30000 (0.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 5.3628s / 34.0377 s
agent0:                 episode reward: 0.7102,                 loss: nan
agent1:                 episode reward: -0.7102,                 loss: nan
Episode: 141/30000 (0.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 4.2314s / 38.2692 s
agent0:                 episode reward: -0.0818,                 loss: nan
agent1:                 episode reward: 0.0818,                 loss: nan
Episode: 161/30000 (0.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 4.8510s / 43.1202 s
agent0:                 episode reward: 0.1929,                 loss: nan
agent1:                 episode reward: -0.1929,                 loss: nan
Episode: 181/30000 (0.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 4.3025s / 47.4227 s
agent0:                 episode reward: 0.2424,                 loss: nan
agent1:                 episode reward: -0.2424,                 loss: nan
Episode: 201/30000 (0.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 4.2669s / 51.6896 s
agent0:                 episode reward: 0.1987,                 loss: nan
agent1:                 episode reward: -0.1987,                 loss: nan
Episode: 221/30000 (0.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 52.9983s / 104.6879 s
agent0:                 episode reward: -0.4513,                 loss: nan
agent1:                 episode reward: 0.4513,                 loss: 0.1975
Episode: 241/30000 (0.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.2231s / 241.9110 s
agent0:                 episode reward: -0.2121,                 loss: nan
agent1:                 episode reward: 0.2121,                 loss: 0.1821
Episode: 261/30000 (0.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 139.1871s / 381.0981 s
agent0:                 episode reward: -0.2297,                 loss: nan
agent1:                 episode reward: 0.2297,                 loss: 0.1720
Episode: 281/30000 (0.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2009s / 516.2990 s
agent0:                 episode reward: -0.1031,                 loss: nan
agent1:                 episode reward: 0.1031,                 loss: 0.1681
Episode: 301/30000 (1.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.4539s / 652.7529 s
agent0:                 episode reward: -0.0448,                 loss: nan
agent1:                 episode reward: 0.0448,                 loss: 0.1652
Episode: 321/30000 (1.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.3387s / 789.0916 s
agent0:                 episode reward: -0.0449,                 loss: nan
agent1:                 episode reward: 0.0449,                 loss: 0.1641
Episode: 341/30000 (1.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 138.3967s / 927.4883 s
agent0:                 episode reward: 0.2589,                 loss: nan
agent1:                 episode reward: -0.2589,                 loss: 0.1634
Episode: 361/30000 (1.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2069s / 1062.6952 s
agent0:                 episode reward: 0.3860,                 loss: nan
agent1:                 episode reward: -0.3860,                 loss: 0.1609
Episode: 381/30000 (1.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2339s / 1198.9292 s
agent0:                 episode reward: 0.1906,                 loss: nan
agent1:                 episode reward: -0.1906,                 loss: 0.1601
Episode: 401/30000 (1.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.8188s / 1335.7479 s
agent0:                 episode reward: 0.1262,                 loss: nan
agent1:                 episode reward: -0.1262,                 loss: 0.1599
Episode: 421/30000 (1.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.5573s / 1471.3053 s
agent0:                 episode reward: -0.0809,                 loss: nan
agent1:                 episode reward: 0.0809,                 loss: 0.1583
Episode: 441/30000 (1.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.5494s / 1606.8547 s
agent0:                 episode reward: 0.1470,                 loss: nan
agent1:                 episode reward: -0.1470,                 loss: 0.1566
Episode: 461/30000 (1.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0329s / 1742.8875 s
agent0:                 episode reward: 0.3399,                 loss: nan
agent1:                 episode reward: -0.3399,                 loss: 0.1578
Episode: 481/30000 (1.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.9139s / 1881.8014 s
agent0:                 episode reward: 0.3112,                 loss: nan
agent1:                 episode reward: -0.3112,                 loss: 0.1566
Episode: 501/30000 (1.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 141.6273s / 2023.4287 s
agent0:                 episode reward: 0.0517,                 loss: nan
agent1:                 episode reward: -0.0517,                 loss: 0.1551
Episode: 521/30000 (1.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 138.5261s / 2161.9549 s
agent0:                 episode reward: 0.1021,                 loss: nan
agent1:                 episode reward: -0.1021,                 loss: 0.1570
Episode: 541/30000 (1.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 142.6867s / 2304.6416 s
agent0:                 episode reward: -0.2154,                 loss: nan
agent1:                 episode reward: 0.2154,                 loss: 0.1551
Episode: 561/30000 (1.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 140.4639s / 2445.1054 s
agent0:                 episode reward: -0.0570,                 loss: nan
agent1:                 episode reward: 0.0570,                 loss: 0.1710
Episode: 581/30000 (1.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 139.5601s / 2584.6655 s
agent0:                 episode reward: 0.0287,                 loss: nan
agent1:                 episode reward: -0.0287,                 loss: 0.1633
Episode: 601/30000 (2.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.6368s / 2723.3023 s
agent0:                 episode reward: -0.2391,                 loss: nan
agent1:                 episode reward: 0.2391,                 loss: 0.1606
Episode: 621/30000 (2.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 139.5736s / 2862.8759 s
agent0:                 episode reward: -0.2291,                 loss: nan
agent1:                 episode reward: 0.2291,                 loss: 0.1597
Episode: 641/30000 (2.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 138.4715s / 3001.3474 s
agent0:                 episode reward: 0.0212,                 loss: nan
agent1:                 episode reward: -0.0212,                 loss: 0.1589
Episode: 661/30000 (2.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.0822s / 3139.4296 s
agent0:                 episode reward: -0.1457,                 loss: nan
agent1:                 episode reward: 0.1457,                 loss: 0.1604
Episode: 681/30000 (2.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.5187s / 3277.9483 s
agent0:                 episode reward: -0.1624,                 loss: nan
agent1:                 episode reward: 0.1624,                 loss: 0.1593
Episode: 701/30000 (2.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 139.1502s / 3417.0985 s
agent0:                 episode reward: -0.2566,                 loss: nan
agent1:                 episode reward: 0.2566,                 loss: 0.1587
Episode: 721/30000 (2.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.2326s / 3555.3311 s
agent0:                 episode reward: 0.3005,                 loss: nan
agent1:                 episode reward: -0.3005,                 loss: 0.1584
Episode: 741/30000 (2.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 140.5628s / 3695.8939 s
agent0:                 episode reward: 0.0529,                 loss: nan
agent1:                 episode reward: -0.0529,                 loss: 0.1567
Episode: 761/30000 (2.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2779s / 3832.1718 s
agent0:                 episode reward: 0.2950,                 loss: nan
agent1:                 episode reward: -0.2950,                 loss: 0.1570
Episode: 781/30000 (2.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.3030s / 3970.4748 s
agent0:                 episode reward: 0.3823,                 loss: nan
agent1:                 episode reward: -0.3823,                 loss: 0.1564
Episode: 801/30000 (2.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.7908s / 4109.2656 s
agent0:                 episode reward: 0.1324,                 loss: nan
agent1:                 episode reward: -0.1324,                 loss: 0.1540
Episode: 821/30000 (2.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 138.6267s / 4247.8922 s
agent0:                 episode reward: 0.1758,                 loss: nan
agent1:                 episode reward: -0.1758,                 loss: 0.1556
Episode: 841/30000 (2.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.5813s / 4387.4735 s
agent0:                 episode reward: 0.3519,                 loss: nan
agent1:                 episode reward: -0.3519,                 loss: 0.1535
Episode: 861/30000 (2.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.6928s / 4524.1664 s
agent0:                 episode reward: -0.0758,                 loss: nan
agent1:                 episode reward: 0.0758,                 loss: 0.1529
Episode: 881/30000 (2.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.4655s / 4661.6318 s
agent0:                 episode reward: -0.2261,                 loss: nan
agent1:                 episode reward: 0.2261,                 loss: 0.1520
Episode: 901/30000 (3.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 140.5991s / 4802.2309 s
agent0:                 episode reward: -0.4574,                 loss: nan
agent1:                 episode reward: 0.4574,                 loss: 0.1482
Episode: 921/30000 (3.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 140.8516s / 4943.0826 s
agent0:                 episode reward: 0.1683,                 loss: nan
agent1:                 episode reward: -0.1683,                 loss: 0.1478
Episode: 941/30000 (3.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.4975s / 5080.5800 s
agent0:                 episode reward: -0.4739,                 loss: nan
agent1:                 episode reward: 0.4739,                 loss: 0.1473
Episode: 961/30000 (3.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.5277s / 5220.1077 s
agent0:                 episode reward: 0.0612,                 loss: nan
agent1:                 episode reward: -0.0612,                 loss: 0.1465
Episode: 981/30000 (3.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 139.3073s / 5359.4151 s
agent0:                 episode reward: -0.2767,                 loss: nan
agent1:                 episode reward: 0.2767,                 loss: 0.1469
Episode: 1001/30000 (3.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 140.1096s / 5499.5247 s
agent0:                 episode reward: -0.0341,                 loss: nan
agent1:                 episode reward: 0.0341,                 loss: 0.1443
Episode: 1021/30000 (3.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.0871s / 5636.6118 s
agent0:                 episode reward: -0.0218,                 loss: nan
agent1:                 episode reward: 0.0218,                 loss: 0.1444
Episode: 1041/30000 (3.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.8440s / 5775.4558 s
agent0:                 episode reward: 0.1621,                 loss: nan
agent1:                 episode reward: -0.1621,                 loss: 0.1443
Episode: 1061/30000 (3.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.1115s / 5912.5673 s
agent0:                 episode reward: 0.1761,                 loss: nan
agent1:                 episode reward: -0.1761,                 loss: 0.1446
Episode: 1081/30000 (3.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.8530s / 6050.4203 s
agent0:                 episode reward: -0.0865,                 loss: nan
agent1:                 episode reward: 0.0865,                 loss: 0.1447
Episode: 1101/30000 (3.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3914s / 6185.8117 s
agent0:                 episode reward: 0.1494,                 loss: nan
agent1:                 episode reward: -0.1494,                 loss: 0.1441
Episode: 1121/30000 (3.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 138.9238s / 6324.7355 s
agent0:                 episode reward: -0.3996,                 loss: nan
agent1:                 episode reward: 0.3996,                 loss: 0.1421
Episode: 1141/30000 (3.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.9869s / 6464.7224 s
agent0:                 episode reward: 0.2406,                 loss: nan
agent1:                 episode reward: -0.2406,                 loss: 0.1441
Episode: 1161/30000 (3.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 139.8527s / 6604.5750 s
agent0:                 episode reward: -0.1193,                 loss: nan
agent1:                 episode reward: 0.1193,                 loss: 0.1443
Episode: 1181/30000 (3.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 142.5171s / 6747.0921 s
agent0:                 episode reward: -0.1235,                 loss: nan
agent1:                 episode reward: 0.1235,                 loss: 0.1421
Episode: 1201/30000 (4.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.4172s / 6883.5093 s
agent0:                 episode reward: -0.0420,                 loss: nan
agent1:                 episode reward: 0.0420,                 loss: 0.1420
Episode: 1221/30000 (4.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.4168s / 7020.9261 s
agent0:                 episode reward: -0.0705,                 loss: nan
agent1:                 episode reward: 0.0705,                 loss: 0.1442
Episode: 1241/30000 (4.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 138.9193s / 7159.8454 s
agent0:                 episode reward: -0.0042,                 loss: nan
agent1:                 episode reward: 0.0042,                 loss: 0.1471
Episode: 1261/30000 (4.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.4889s / 7297.3343 s
agent0:                 episode reward: -0.3208,                 loss: nan
agent1:                 episode reward: 0.3208,                 loss: 0.1475
Episode: 1281/30000 (4.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 139.9722s / 7437.3064 s
agent0:                 episode reward: -0.2893,                 loss: nan
agent1:                 episode reward: 0.2893,                 loss: 0.1460
Episode: 1301/30000 (4.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 140.7496s / 7578.0560 s
agent0:                 episode reward: 0.0154,                 loss: nan
agent1:                 episode reward: -0.0154,                 loss: 0.1452
Episode: 1321/30000 (4.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.9735s / 7714.0296 s
agent0:                 episode reward: -0.2588,                 loss: nan
agent1:                 episode reward: 0.2588,                 loss: 0.1457
Episode: 1341/30000 (4.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 141.4008s / 7855.4303 s
agent0:                 episode reward: -0.1760,                 loss: nan
agent1:                 episode reward: 0.1760,                 loss: 0.1465
Episode: 1361/30000 (4.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.5782s / 7993.0085 s
agent0:                 episode reward: -0.1871,                 loss: nan
agent1:                 episode reward: 0.1871,                 loss: 0.1465
Episode: 1381/30000 (4.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.0921s / 8130.1006 s
agent0:                 episode reward: -0.0567,                 loss: nan
agent1:                 episode reward: 0.0567,                 loss: 0.1465
Episode: 1401/30000 (4.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.0681s / 8268.1687 s
agent0:                 episode reward: 0.3925,                 loss: nan
agent1:                 episode reward: -0.3925,                 loss: 0.1447
Episode: 1421/30000 (4.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.7985s / 8405.9671 s
agent0:                 episode reward: -0.1522,                 loss: nan
agent1:                 episode reward: 0.1522,                 loss: 0.1455
Episode: 1441/30000 (4.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 140.6152s / 8546.5823 s
agent0:                 episode reward: -0.1892,                 loss: nan
agent1:                 episode reward: 0.1892,                 loss: 0.1443
Episode: 1461/30000 (4.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.7766s / 8683.3590 s
agent0:                 episode reward: -0.3093,                 loss: nan
agent1:                 episode reward: 0.3093,                 loss: 0.1435
Episode: 1481/30000 (4.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 140.6456s / 8824.0046 s
agent0:                 episode reward: 0.0226,                 loss: nan
agent1:                 episode reward: -0.0226,                 loss: 0.1467
Episode: 1501/30000 (5.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.5969s / 8962.6015 s
agent0:                 episode reward: -0.0222,                 loss: nan
agent1:                 episode reward: 0.0222,                 loss: 0.1428
Episode: 1521/30000 (5.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.2489s / 9100.8505 s
agent0:                 episode reward: 0.0295,                 loss: nan
agent1:                 episode reward: -0.0295,                 loss: 0.1431
Episode: 1541/30000 (5.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 138.8297s / 9239.6802 s
agent0:                 episode reward: -0.2660,                 loss: nan
agent1:                 episode reward: 0.2660,                 loss: 0.1444
Episode: 1561/30000 (5.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.9216s / 9373.6018 s
agent0:                 episode reward: -0.1293,                 loss: nan
agent1:                 episode reward: 0.1293,                 loss: 0.1421
Episode: 1581/30000 (5.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 139.2512s / 9512.8530 s
agent0:                 episode reward: -0.0400,                 loss: nan
agent1:                 episode reward: 0.0400,                 loss: 0.1409
Episode: 1601/30000 (5.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 140.7221s / 9653.5750 s
agent0:                 episode reward: -0.2325,                 loss: nan
agent1:                 episode reward: 0.2325,                 loss: 0.1412
Episode: 1621/30000 (5.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 144.0977s / 9797.6727 s
agent0:                 episode reward: -0.1582,                 loss: nan
agent1:                 episode reward: 0.1582,                 loss: 0.1412
Episode: 1641/30000 (5.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 140.6482s / 9938.3210 s
agent0:                 episode reward: 0.1266,                 loss: nan
agent1:                 episode reward: -0.1266,                 loss: 0.1407
Episode: 1661/30000 (5.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 143.1915s / 10081.5124 s
agent0:                 episode reward: 0.0925,                 loss: nan
agent1:                 episode reward: -0.0925,                 loss: 0.1397
Episode: 1681/30000 (5.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 141.9156s / 10223.4280 s
agent0:                 episode reward: -0.0161,                 loss: nan
agent1:                 episode reward: 0.0161,                 loss: 0.1406
Episode: 1701/30000 (5.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 141.9316s / 10365.3597 s
agent0:                 episode reward: -0.1557,                 loss: nan
agent1:                 episode reward: 0.1557,                 loss: 0.1413
Episode: 1721/30000 (5.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 141.7278s / 10507.0875 s
agent0:                 episode reward: 0.0736,                 loss: nan
agent1:                 episode reward: -0.0736,                 loss: 0.1394
Episode: 1741/30000 (5.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.9340s / 10647.0215 s
agent0:                 episode reward: -0.2175,                 loss: nan
agent1:                 episode reward: 0.2175,                 loss: 0.1404
Episode: 1761/30000 (5.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 140.3622s / 10787.3837 s
agent0:                 episode reward: -0.2816,                 loss: nan
agent1:                 episode reward: 0.2816,                 loss: 0.1398
Episode: 1781/30000 (5.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 140.6040s / 10927.9878 s
agent0:                 episode reward: 0.1766,                 loss: nan
agent1:                 episode reward: -0.1766,                 loss: 0.1401
Episode: 1801/30000 (6.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 141.4154s / 11069.4032 s
agent0:                 episode reward: 0.0468,                 loss: nan
agent1:                 episode reward: -0.0468,                 loss: 0.1401
Episode: 1821/30000 (6.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.6581s / 11208.0612 s
agent0:                 episode reward: 0.0582,                 loss: nan
agent1:                 episode reward: -0.0582,                 loss: 0.1385
Episode: 1841/30000 (6.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 143.9100s / 11351.9712 s
agent0:                 episode reward: 0.0266,                 loss: nan
agent1:                 episode reward: -0.0266,                 loss: 0.1404
Episode: 1861/30000 (6.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 142.2720s / 11494.2432 s
agent0:                 episode reward: -0.1687,                 loss: nan
agent1:                 episode reward: 0.1687,                 loss: 0.1389
Episode: 1881/30000 (6.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.8715s / 11633.1147 s
agent0:                 episode reward: -0.1996,                 loss: nan
agent1:                 episode reward: 0.1996,                 loss: 0.1397
Episode: 1901/30000 (6.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 139.7593s / 11772.8740 s
agent0:                 episode reward: -0.3703,                 loss: nan
agent1:                 episode reward: 0.3703,                 loss: 0.1469
Episode: 1921/30000 (6.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.0516s / 11911.9256 s
agent0:                 episode reward: 0.1355,                 loss: nan
agent1:                 episode reward: -0.1355,                 loss: 0.1461
Episode: 1941/30000 (6.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 143.5138s / 12055.4394 s
agent0:                 episode reward: 0.0372,                 loss: nan
agent1:                 episode reward: -0.0372,                 loss: 0.1453
Episode: 1961/30000 (6.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 139.4490s / 12194.8884 s
agent0:                 episode reward: -0.2626,                 loss: nan
agent1:                 episode reward: 0.2626,                 loss: 0.1462
Episode: 1981/30000 (6.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 141.8792s / 12336.7676 s
agent0:                 episode reward: -0.0964,                 loss: nan
agent1:                 episode reward: 0.0964,                 loss: 0.1467
Episode: 2001/30000 (6.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 141.4476s / 12478.2152 s
agent0:                 episode reward: 0.1011,                 loss: nan
agent1:                 episode reward: -0.1011,                 loss: 0.1474
Episode: 2021/30000 (6.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 140.2602s / 12618.4754 s
agent0:                 episode reward: 0.0151,                 loss: nan
agent1:                 episode reward: -0.0151,                 loss: 0.1457
Episode: 2041/30000 (6.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 141.2276s / 12759.7029 s
agent0:                 episode reward: -0.4463,                 loss: nan
agent1:                 episode reward: 0.4463,                 loss: 0.1463
Episode: 2061/30000 (6.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 141.6716s / 12901.3746 s
agent0:                 episode reward: -0.5743,                 loss: nan
agent1:                 episode reward: 0.5743,                 loss: 0.1464
Episode: 2081/30000 (6.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 144.7976s / 13046.1722 s
agent0:                 episode reward: -0.2912,                 loss: nan
agent1:                 episode reward: 0.2912,                 loss: 0.1474
Episode: 2101/30000 (7.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 141.9572s / 13188.1294 s
agent0:                 episode reward: -0.3568,                 loss: nan
agent1:                 episode reward: 0.3568,                 loss: 0.1463
Episode: 2121/30000 (7.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 142.5497s / 13330.6791 s
agent0:                 episode reward: 0.1493,                 loss: nan
agent1:                 episode reward: -0.1493,                 loss: 0.1450
Episode: 2141/30000 (7.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 143.4694s / 13474.1485 s
agent0:                 episode reward: 0.0571,                 loss: nan
agent1:                 episode reward: -0.0571,                 loss: 0.1462
Episode: 2161/30000 (7.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 140.4355s / 13614.5840 s
agent0:                 episode reward: 0.1574,                 loss: nan
agent1:                 episode reward: -0.1574,                 loss: 0.1472
Episode: 2181/30000 (7.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.2413s / 13752.8253 s
agent0:                 episode reward: 0.0040,                 loss: nan
agent1:                 episode reward: -0.0040,                 loss: 0.1440
Episode: 2201/30000 (7.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 141.7049s / 13894.5302 s
agent0:                 episode reward: -0.1079,                 loss: nan
agent1:                 episode reward: 0.1079,                 loss: 0.1462
Episode: 2221/30000 (7.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.1388s / 14032.6690 s
agent0:                 episode reward: -0.2496,                 loss: nan
agent1:                 episode reward: 0.2496,                 loss: 0.1464
Episode: 2241/30000 (7.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 142.3457s / 14175.0147 s
agent0:                 episode reward: -0.0475,                 loss: nan
agent1:                 episode reward: 0.0475,                 loss: 0.1459
Episode: 2261/30000 (7.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 139.0098s / 14314.0245 s
agent0:                 episode reward: -0.0435,                 loss: nan
agent1:                 episode reward: 0.0435,                 loss: 0.1456
Episode: 2281/30000 (7.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 140.4224s / 14454.4470 s
agent0:                 episode reward: -0.1253,                 loss: nan
agent1:                 episode reward: 0.1253,                 loss: 0.1439
Episode: 2301/30000 (7.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 140.2090s / 14594.6560 s
agent0:                 episode reward: 0.1309,                 loss: nan
agent1:                 episode reward: -0.1309,                 loss: 0.1451
Episode: 2321/30000 (7.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 141.2518s / 14735.9077 s
agent0:                 episode reward: 0.1405,                 loss: nan
agent1:                 episode reward: -0.1405,                 loss: 0.1448
Episode: 2341/30000 (7.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.3085s / 14875.2162 s
agent0:                 episode reward: -0.0950,                 loss: nan
agent1:                 episode reward: 0.0950,                 loss: 0.1444
Episode: 2361/30000 (7.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.8320s / 15013.0482 s
agent0:                 episode reward: 0.1500,                 loss: nan
agent1:                 episode reward: -0.1500,                 loss: 0.1438
Episode: 2381/30000 (7.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 142.4399s / 15155.4881 s
agent0:                 episode reward: -0.5387,                 loss: nan
agent1:                 episode reward: 0.5387,                 loss: 0.1455
Episode: 2401/30000 (8.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.8794s / 15294.3675 s
agent0:                 episode reward: 0.0794,                 loss: nan
agent1:                 episode reward: -0.0794,                 loss: 0.1442
Episode: 2421/30000 (8.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 142.1508s / 15436.5183 s
agent0:                 episode reward: -0.0625,                 loss: nan
agent1:                 episode reward: 0.0625,                 loss: 0.1463
Episode: 2441/30000 (8.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 141.0683s / 15577.5866 s
agent0:                 episode reward: -0.4663,                 loss: nan
agent1:                 episode reward: 0.4663,                 loss: 0.1463
Episode: 2461/30000 (8.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 141.7631s / 15719.3498 s
agent0:                 episode reward: -0.5288,                 loss: nan
agent1:                 episode reward: 0.5288,                 loss: 0.1449
Episode: 2481/30000 (8.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.6565s / 15858.0063 s
agent0:                 episode reward: 0.0024,                 loss: nan
agent1:                 episode reward: -0.0024,                 loss: 0.1467
Episode: 2501/30000 (8.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 140.2872s / 15998.2935 s
agent0:                 episode reward: -0.0886,                 loss: nan
agent1:                 episode reward: 0.0886,                 loss: 0.1465
Episode: 2521/30000 (8.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 144.0909s / 16142.3844 s
agent0:                 episode reward: -0.1915,                 loss: nan
agent1:                 episode reward: 0.1915,                 loss: 0.1441
Episode: 2541/30000 (8.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 143.6348s / 16286.0191 s
agent0:                 episode reward: -0.1359,                 loss: nan
agent1:                 episode reward: 0.1359,                 loss: 0.1443
Episode: 2561/30000 (8.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 139.8112s / 16425.8303 s
agent0:                 episode reward: -0.1531,                 loss: nan
agent1:                 episode reward: 0.1531,                 loss: 0.1430
Episode: 2581/30000 (8.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 140.9877s / 16566.8180 s
agent0:                 episode reward: 0.0700,                 loss: nan
agent1:                 episode reward: -0.0700,                 loss: 0.1441
Episode: 2601/30000 (8.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 144.2755s / 16711.0935 s
agent0:                 episode reward: -0.4178,                 loss: nan
agent1:                 episode reward: 0.4178,                 loss: 0.1442
Episode: 2621/30000 (8.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 144.7054s / 16855.7989 s
agent0:                 episode reward: -0.1764,                 loss: nan
agent1:                 episode reward: 0.1764,                 loss: 0.1428
Episode: 2641/30000 (8.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 142.8160s / 16998.6149 s
agent0:                 episode reward: -0.1152,                 loss: nan
agent1:                 episode reward: 0.1152,                 loss: 0.1438
Episode: 2661/30000 (8.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 141.7304s / 17140.3453 s
agent0:                 episode reward: -0.0545,                 loss: nan
agent1:                 episode reward: 0.0545,                 loss: 0.1429
Episode: 2681/30000 (8.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 139.5578s / 17279.9032 s
agent0:                 episode reward: -0.6602,                 loss: nan
agent1:                 episode reward: 0.6602,                 loss: 0.1429
Episode: 2701/30000 (9.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.4213s / 17419.3245 s
agent0:                 episode reward: -0.0979,                 loss: nan
agent1:                 episode reward: 0.0979,                 loss: 0.1425
Episode: 2721/30000 (9.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 140.6822s / 17560.0067 s
agent0:                 episode reward: 0.2706,                 loss: nan
agent1:                 episode reward: -0.2706,                 loss: 0.1421
Episode: 2741/30000 (9.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 144.0600s / 17704.0667 s
agent0:                 episode reward: 0.0635,                 loss: nan
agent1:                 episode reward: -0.0635,                 loss: 0.1437
Episode: 2761/30000 (9.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 142.6416s / 17846.7082 s
agent0:                 episode reward: 0.1978,                 loss: nan
agent1:                 episode reward: -0.1978,                 loss: 0.1419
Episode: 2781/30000 (9.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 139.2789s / 17985.9871 s
agent0:                 episode reward: 0.4326,                 loss: nan
agent1:                 episode reward: -0.4326,                 loss: 0.1434
Episode: 2801/30000 (9.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.6380s / 18123.6251 s
agent0:                 episode reward: -0.3385,                 loss: nan
agent1:                 episode reward: 0.3385,                 loss: 0.1440
Episode: 2821/30000 (9.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.2374s / 18256.8626 s
agent0:                 episode reward: -0.2617,                 loss: nan
agent1:                 episode reward: 0.2617,                 loss: 0.1435
Episode: 2841/30000 (9.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.4683s / 18390.3309 s
agent0:                 episode reward: -0.1624,                 loss: nan
agent1:                 episode reward: 0.1624,                 loss: 0.1418
Episode: 2861/30000 (9.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.6732s / 18523.0041 s
agent0:                 episode reward: -0.3117,                 loss: nan
agent1:                 episode reward: 0.3117,                 loss: 0.1425
Episode: 2881/30000 (9.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 141.0958s / 18664.0998 s
agent0:                 episode reward: -0.2868,                 loss: nan
agent1:                 episode reward: 0.2868,                 loss: 0.1429
Episode: 2901/30000 (9.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 143.0303s / 18807.1302 s
agent0:                 episode reward: -0.0218,                 loss: nan
agent1:                 episode reward: 0.0218,                 loss: 0.1444
Episode: 2921/30000 (9.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 142.8974s / 18950.0276 s
agent0:                 episode reward: -0.4955,                 loss: nan
agent1:                 episode reward: 0.4955,                 loss: 0.1427
Episode: 2941/30000 (9.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 142.2682s / 19092.2958 s
agent0:                 episode reward: -0.0664,                 loss: nan
agent1:                 episode reward: 0.0664,                 loss: 0.1446
Episode: 2961/30000 (9.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 144.3417s / 19236.6375 s
agent0:                 episode reward: -0.0980,                 loss: nan
agent1:                 episode reward: 0.0980,                 loss: 0.1454
Episode: 2981/30000 (9.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 141.1168s / 19377.7543 s
agent0:                 episode reward: -0.3172,                 loss: nan
agent1:                 episode reward: 0.3172,                 loss: 0.1439
Episode: 3001/30000 (10.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 142.8544s / 19520.6087 s
agent0:                 episode reward: -0.4575,                 loss: nan
agent1:                 episode reward: 0.4575,                 loss: 0.1442
Episode: 3021/30000 (10.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 144.8097s / 19665.4184 s
agent0:                 episode reward: -0.5023,                 loss: nan
agent1:                 episode reward: 0.5023,                 loss: 0.1443
Episode: 3041/30000 (10.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 141.4946s / 19806.9130 s
agent0:                 episode reward: 0.0852,                 loss: nan
agent1:                 episode reward: -0.0852,                 loss: 0.1440
Episode: 3061/30000 (10.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 143.8173s / 19950.7303 s
agent0:                 episode reward: 0.1015,                 loss: nan
agent1:                 episode reward: -0.1015,                 loss: 0.1442
Episode: 3081/30000 (10.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 143.4988s / 20094.2291 s
agent0:                 episode reward: 0.0686,                 loss: nan
agent1:                 episode reward: -0.0686,                 loss: 0.1443
Episode: 3101/30000 (10.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 143.9440s / 20238.1731 s
agent0:                 episode reward: -0.1670,                 loss: nan
agent1:                 episode reward: 0.1670,                 loss: 0.1429
Episode: 3121/30000 (10.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 143.7720s / 20381.9451 s
agent0:                 episode reward: -0.1565,                 loss: nan
agent1:                 episode reward: 0.1565,                 loss: 0.1455
Episode: 3141/30000 (10.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 141.3284s / 20523.2735 s
agent0:                 episode reward: 0.0512,                 loss: nan
agent1:                 episode reward: -0.0512,                 loss: 0.1445
Episode: 3161/30000 (10.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 140.9760s / 20664.2495 s
agent0:                 episode reward: -0.3303,                 loss: nan
agent1:                 episode reward: 0.3303,                 loss: 0.1444
Episode: 3181/30000 (10.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 140.9200s / 20805.1696 s
agent0:                 episode reward: 0.0323,                 loss: nan
agent1:                 episode reward: -0.0323,                 loss: 0.1427
Episode: 3201/30000 (10.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 142.2841s / 20947.4537 s
agent0:                 episode reward: 0.0591,                 loss: nan
agent1:                 episode reward: -0.0591,                 loss: 0.1445
Episode: 3221/30000 (10.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 144.5363s / 21091.9900 s
agent0:                 episode reward: 0.2247,                 loss: nan
agent1:                 episode reward: -0.2247,                 loss: 0.1452
Episode: 3241/30000 (10.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 141.8902s / 21233.8802 s
agent0:                 episode reward: -0.1753,                 loss: nan
agent1:                 episode reward: 0.1753,                 loss: 0.1449
Episode: 3261/30000 (10.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 145.3197s / 21379.1999 s
agent0:                 episode reward: -0.0551,                 loss: nan
agent1:                 episode reward: 0.0551,                 loss: 0.1463
Episode: 3281/30000 (10.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 144.3352s / 21523.5351 s
agent0:                 episode reward: -0.2604,                 loss: nan
agent1:                 episode reward: 0.2604,                 loss: 0.1466
Episode: 3301/30000 (11.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 141.7426s / 21665.2777 s
agent0:                 episode reward: 0.2650,                 loss: nan
agent1:                 episode reward: -0.2650,                 loss: 0.1470
Episode: 3321/30000 (11.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 143.4611s / 21808.7388 s
agent0:                 episode reward: -0.2929,                 loss: nan
agent1:                 episode reward: 0.2929,                 loss: 0.1470
Episode: 3341/30000 (11.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 144.3839s / 21953.1226 s
agent0:                 episode reward: -0.4224,                 loss: nan
agent1:                 episode reward: 0.4224,                 loss: 0.1461
Episode: 3361/30000 (11.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 144.3693s / 22097.4919 s
agent0:                 episode reward: 0.1250,                 loss: nan
agent1:                 episode reward: -0.1250,                 loss: 0.1467
Episode: 3381/30000 (11.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 144.7390s / 22242.2309 s
agent0:                 episode reward: -0.2004,                 loss: nan
agent1:                 episode reward: 0.2004,                 loss: 0.1448
Episode: 3401/30000 (11.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 144.2799s / 22386.5108 s
agent0:                 episode reward: -0.2298,                 loss: nan
agent1:                 episode reward: 0.2298,                 loss: 0.1464
Episode: 3421/30000 (11.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 143.6668s / 22530.1776 s
agent0:                 episode reward: -0.2398,                 loss: nan
agent1:                 episode reward: 0.2398,                 loss: 0.1457
Episode: 3441/30000 (11.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 144.2321s / 22674.4096 s
agent0:                 episode reward: 0.0086,                 loss: nan
agent1:                 episode reward: -0.0086,                 loss: 0.1450
Episode: 3461/30000 (11.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 141.6841s / 22816.0937 s
agent0:                 episode reward: 0.0604,                 loss: nan
agent1:                 episode reward: -0.0604,                 loss: 0.1454
Episode: 3481/30000 (11.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 145.6425s / 22961.7362 s
agent0:                 episode reward: -0.2299,                 loss: nan
agent1:                 episode reward: 0.2299,                 loss: 0.1458
Episode: 3501/30000 (11.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 142.4182s / 23104.1543 s
agent0:                 episode reward: -0.1079,                 loss: nan
agent1:                 episode reward: 0.1079,                 loss: 0.1455
Episode: 3521/30000 (11.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 145.5552s / 23249.7095 s
agent0:                 episode reward: 0.2781,                 loss: nan
agent1:                 episode reward: -0.2781,                 loss: 0.1457
Episode: 3541/30000 (11.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 143.1864s / 23392.8959 s
agent0:                 episode reward: 0.0518,                 loss: nan
agent1:                 episode reward: -0.0518,                 loss: 0.1453
Episode: 3561/30000 (11.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 140.9135s / 23533.8095 s
agent0:                 episode reward: -0.4290,                 loss: nan
agent1:                 episode reward: 0.4290,                 loss: 0.1431
Episode: 3581/30000 (11.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 143.4099s / 23677.2193 s
agent0:                 episode reward: 0.1678,                 loss: nan
agent1:                 episode reward: -0.1678,                 loss: 0.1433
Episode: 3601/30000 (12.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 145.6523s / 23822.8717 s
agent0:                 episode reward: -0.1522,                 loss: nan
agent1:                 episode reward: 0.1522,                 loss: 0.1425
Episode: 3621/30000 (12.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 142.4153s / 23965.2869 s
agent0:                 episode reward: -0.0788,                 loss: nan
agent1:                 episode reward: 0.0788,                 loss: 0.1427
Episode: 3641/30000 (12.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 143.7399s / 24109.0268 s
agent0:                 episode reward: 0.0787,                 loss: nan
agent1:                 episode reward: -0.0787,                 loss: 0.1421
Episode: 3661/30000 (12.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 146.3189s / 24255.3457 s
agent0:                 episode reward: -0.2443,                 loss: nan
agent1:                 episode reward: 0.2443,                 loss: 0.1424
Episode: 3681/30000 (12.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 142.1891s / 24397.5347 s
agent0:                 episode reward: -0.0693,                 loss: nan
agent1:                 episode reward: 0.0693,                 loss: 0.1418
Episode: 3701/30000 (12.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 146.4344s / 24543.9691 s
agent0:                 episode reward: -0.4529,                 loss: nan
agent1:                 episode reward: 0.4529,                 loss: 0.1420
Episode: 3721/30000 (12.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.0642s / 24681.0333 s
agent0:                 episode reward: -0.1307,                 loss: nan
agent1:                 episode reward: 0.1307,                 loss: 0.1418
Episode: 3741/30000 (12.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.8439s / 24813.8772 s
agent0:                 episode reward: -0.4203,                 loss: nan
agent1:                 episode reward: 0.4203,                 loss: 0.1421
Episode: 3761/30000 (12.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.6178s / 24950.4949 s
agent0:                 episode reward: -0.1232,                 loss: nan
agent1:                 episode reward: 0.1232,                 loss: 0.1418
Episode: 3781/30000 (12.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.8671s / 25083.3620 s
agent0:                 episode reward: -0.4232,                 loss: nan
agent1:                 episode reward: 0.4232,                 loss: 0.1419
Episode: 3801/30000 (12.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.5831s / 25216.9451 s
agent0:                 episode reward: -0.4441,                 loss: nan
agent1:                 episode reward: 0.4441,                 loss: 0.1424
Episode: 3821/30000 (12.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.3438s / 25353.2888 s
agent0:                 episode reward: -0.4209,                 loss: nan
agent1:                 episode reward: 0.4209,                 loss: 0.1420
Episode: 3841/30000 (12.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6405s / 25487.9294 s
agent0:                 episode reward: 0.1287,                 loss: nan
agent1:                 episode reward: -0.1287,                 loss: 0.1432
Episode: 3861/30000 (12.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.4629s / 25621.3923 s
agent0:                 episode reward: -0.1222,                 loss: nan
agent1:                 episode reward: 0.1222,                 loss: 0.1430
Episode: 3881/30000 (12.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.4333s / 25755.8256 s
agent0:                 episode reward: -0.7038,                 loss: nan
agent1:                 episode reward: 0.7038,                 loss: 0.1420
Episode: 3901/30000 (13.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.5209s / 25892.3466 s
agent0:                 episode reward: 0.1997,                 loss: nan
agent1:                 episode reward: -0.1997,                 loss: 0.1439
Episode: 3921/30000 (13.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.6405s / 26028.9871 s
agent0:                 episode reward: -0.1053,                 loss: nan
agent1:                 episode reward: 0.1053,                 loss: 0.1450
Episode: 3941/30000 (13.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.8841s / 26164.8712 s
agent0:                 episode reward: -0.0854,                 loss: nan
agent1:                 episode reward: 0.0854,                 loss: 0.1440
Episode: 3961/30000 (13.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.9433s / 26298.8144 s
agent0:                 episode reward: 0.0141,                 loss: nan
agent1:                 episode reward: -0.0141,                 loss: 0.1440
Episode: 3981/30000 (13.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.9394s / 26432.7538 s
agent0:                 episode reward: 0.2923,                 loss: nan
agent1:                 episode reward: -0.2923,                 loss: 0.1441
Episode: 4001/30000 (13.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 130.5358s / 26563.2896 s
agent0:                 episode reward: -0.2056,                 loss: nan
agent1:                 episode reward: 0.2056,                 loss: 0.1440
Episode: 4021/30000 (13.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 141.4629s / 26704.7525 s
agent0:                 episode reward: -0.2596,                 loss: nan
agent1:                 episode reward: 0.2596,                 loss: 0.1443
Episode: 4041/30000 (13.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.3233s / 26839.0758 s
agent0:                 episode reward: -0.5253,                 loss: nan
agent1:                 episode reward: 0.5253,                 loss: 0.1442
Episode: 4061/30000 (13.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1889s / 26973.2647 s
agent0:                 episode reward: -0.5210,                 loss: nan
agent1:                 episode reward: 0.5210,                 loss: 0.1438
Episode: 4081/30000 (13.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.7768s / 27106.0415 s
agent0:                 episode reward: -0.3285,                 loss: nan
agent1:                 episode reward: 0.3285,                 loss: 0.1436
Episode: 4101/30000 (13.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1389s / 27240.1804 s
agent0:                 episode reward: -0.2302,                 loss: nan
agent1:                 episode reward: 0.2302,                 loss: 0.1432
Episode: 4121/30000 (13.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4484s / 27375.6288 s
agent0:                 episode reward: -0.3025,                 loss: nan
agent1:                 episode reward: 0.3025,                 loss: 0.1435
Episode: 4141/30000 (13.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.8894s / 27509.5182 s
agent0:                 episode reward: -0.5320,                 loss: nan
agent1:                 episode reward: 0.5320,                 loss: 0.1455
Episode: 4161/30000 (13.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.6938s / 27643.2119 s
agent0:                 episode reward: -0.2313,                 loss: nan
agent1:                 episode reward: 0.2313,                 loss: 0.1446
Episode: 4181/30000 (13.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.6394s / 27776.8514 s
agent0:                 episode reward: -0.4027,                 loss: nan
agent1:                 episode reward: 0.4027,                 loss: 0.1452
Episode: 4201/30000 (14.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6166s / 27912.4680 s
agent0:                 episode reward: -0.6907,                 loss: nan
agent1:                 episode reward: 0.6907,                 loss: 0.1438
Episode: 4221/30000 (14.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.3521s / 28046.8201 s
agent0:                 episode reward: 0.0406,                 loss: nan
agent1:                 episode reward: -0.0406,                 loss: 0.1435
Episode: 4241/30000 (14.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5458s / 28181.3660 s
agent0:                 episode reward: 0.0624,                 loss: nan
agent1:                 episode reward: -0.0624,                 loss: 0.1438
Episode: 4261/30000 (14.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.5778s / 28314.9438 s
agent0:                 episode reward: -0.3838,                 loss: nan
agent1:                 episode reward: 0.3838,                 loss: 0.1453
Episode: 4281/30000 (14.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.4865s / 28448.4303 s
agent0:                 episode reward: 0.0786,                 loss: nan
agent1:                 episode reward: -0.0786,                 loss: 0.1449
Episode: 4301/30000 (14.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 139.6427s / 28588.0730 s
agent0:                 episode reward: -0.2570,                 loss: nan
agent1:                 episode reward: 0.2570,                 loss: 0.1453
Episode: 4321/30000 (14.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.6180s / 28721.6910 s
agent0:                 episode reward: -0.2849,                 loss: nan
agent1:                 episode reward: 0.2849,                 loss: 0.1434
Episode: 4341/30000 (14.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.5711s / 28860.2621 s
agent0:                 episode reward: -0.2526,                 loss: nan
agent1:                 episode reward: 0.2526,                 loss: 0.1434
Episode: 4361/30000 (14.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9697s / 28995.2318 s
agent0:                 episode reward: -0.4296,                 loss: nan
agent1:                 episode reward: 0.4296,                 loss: 0.1438
Episode: 4381/30000 (14.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 131.7016s / 29126.9334 s
agent0:                 episode reward: -0.1761,                 loss: nan
agent1:                 episode reward: 0.1761,                 loss: 0.1440
Episode: 4401/30000 (14.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.8011s / 29260.7345 s
agent0:                 episode reward: -0.4030,                 loss: nan
agent1:                 episode reward: 0.4030,                 loss: 0.1441
Episode: 4421/30000 (14.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.9945s / 29393.7290 s
agent0:                 episode reward: -0.3305,                 loss: nan
agent1:                 episode reward: 0.3305,                 loss: 0.1445
Episode: 4441/30000 (14.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.2541s / 29527.9831 s
agent0:                 episode reward: -0.1261,                 loss: nan
agent1:                 episode reward: 0.1261,                 loss: 0.1447
Episode: 4461/30000 (14.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.0437s / 29661.0269 s
agent0:                 episode reward: -0.2931,                 loss: nan
agent1:                 episode reward: 0.2931,                 loss: 0.1448
Episode: 4481/30000 (14.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.6074s / 29797.6343 s
agent0:                 episode reward: -0.2300,                 loss: nan
agent1:                 episode reward: 0.2300,                 loss: 0.1462
Episode: 4501/30000 (15.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2644s / 29932.8987 s
agent0:                 episode reward: -0.1549,                 loss: nan
agent1:                 episode reward: 0.1549,                 loss: 0.1445
Episode: 4521/30000 (15.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6249s / 30067.5236 s
agent0:                 episode reward: -0.4258,                 loss: nan
agent1:                 episode reward: 0.4258,                 loss: 0.1450
Episode: 4541/30000 (15.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.4957s / 30202.0193 s
agent0:                 episode reward: -0.2035,                 loss: nan
agent1:                 episode reward: 0.2035,                 loss: 0.1464
Episode: 4561/30000 (15.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 130.5630s / 30332.5823 s
agent0:                 episode reward: -0.0163,                 loss: nan
agent1:                 episode reward: 0.0163,                 loss: 0.1450
Episode: 4581/30000 (15.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.4487s / 30466.0310 s
agent0:                 episode reward: -0.2900,                 loss: nan
agent1:                 episode reward: 0.2900,                 loss: 0.1459
Episode: 4601/30000 (15.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.3443s / 30603.3753 s
agent0:                 episode reward: -0.5276,                 loss: nan
agent1:                 episode reward: 0.5276,                 loss: 0.1464
Episode: 4621/30000 (15.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.5171s / 30735.8924 s
agent0:                 episode reward: 0.0471,                 loss: nan
agent1:                 episode reward: -0.0471,                 loss: 0.1452
Episode: 4641/30000 (15.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.7805s / 30870.6729 s
agent0:                 episode reward: -0.0425,                 loss: nan
agent1:                 episode reward: 0.0425,                 loss: 0.1455
Episode: 4661/30000 (15.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1199s / 31005.7928 s
agent0:                 episode reward: -0.0535,                 loss: nan
agent1:                 episode reward: 0.0535,                 loss: 0.1458
Episode: 4681/30000 (15.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.1598s / 31138.9525 s
agent0:                 episode reward: 0.0764,                 loss: nan
agent1:                 episode reward: -0.0764,                 loss: 0.1474
Episode: 4701/30000 (15.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.5432s / 31274.4958 s
agent0:                 episode reward: 0.3135,                 loss: nan
agent1:                 episode reward: -0.3135,                 loss: 0.1438
Episode: 4721/30000 (15.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 139.9011s / 31414.3968 s
agent0:                 episode reward: -0.0667,                 loss: nan
agent1:                 episode reward: 0.0667,                 loss: 0.1469
Episode: 4741/30000 (15.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3275s / 31549.7244 s
agent0:                 episode reward: -0.1942,                 loss: nan
agent1:                 episode reward: 0.1942,                 loss: 0.1442
Episode: 4761/30000 (15.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.4900s / 31684.2144 s
agent0:                 episode reward: -0.2607,                 loss: nan
agent1:                 episode reward: 0.2607,                 loss: 0.1459
Episode: 4781/30000 (15.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.6446s / 31817.8590 s
agent0:                 episode reward: -0.5031,                 loss: nan
agent1:                 episode reward: 0.5031,                 loss: 0.1456
Episode: 4801/30000 (16.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0521s / 31951.9111 s
agent0:                 episode reward: 0.1145,                 loss: nan
agent1:                 episode reward: -0.1145,                 loss: 0.1459
Episode: 4821/30000 (16.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7326s / 32087.6437 s
agent0:                 episode reward: -0.4283,                 loss: nan
agent1:                 episode reward: 0.4283,                 loss: 0.1459
Episode: 4841/30000 (16.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.2997s / 32220.9434 s
agent0:                 episode reward: -0.1492,                 loss: nan
agent1:                 episode reward: 0.1492,                 loss: 0.1445
Episode: 4861/30000 (16.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.1152s / 32357.0586 s
agent0:                 episode reward: -0.2306,                 loss: nan
agent1:                 episode reward: 0.2306,                 loss: 0.1458
Episode: 4881/30000 (16.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.2576s / 32490.3162 s
agent0:                 episode reward: -0.0272,                 loss: nan
agent1:                 episode reward: 0.0272,                 loss: 0.1449
Episode: 4901/30000 (16.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.2627s / 32623.5789 s
agent0:                 episode reward: -0.7768,                 loss: nan
agent1:                 episode reward: 0.7768,                 loss: 0.1454
Episode: 4921/30000 (16.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1927s / 32758.7716 s
agent0:                 episode reward: -0.3983,                 loss: nan
agent1:                 episode reward: 0.3983,                 loss: 0.1465
Episode: 4941/30000 (16.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.2864s / 32893.0580 s
agent0:                 episode reward: -0.4622,                 loss: nan
agent1:                 episode reward: 0.4622,                 loss: 0.1458
Episode: 4961/30000 (16.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2413s / 33028.2993 s
agent0:                 episode reward: 0.0132,                 loss: nan
agent1:                 episode reward: -0.0132,                 loss: 0.1463
Episode: 4981/30000 (16.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 131.5519s / 33159.8512 s
agent0:                 episode reward: -0.0639,                 loss: nan
agent1:                 episode reward: 0.0639,                 loss: 0.1462
Episode: 5001/30000 (16.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.5411s / 33292.3923 s
agent0:                 episode reward: -0.4018,                 loss: nan
agent1:                 episode reward: 0.4018,                 loss: 0.1450
Episode: 5021/30000 (16.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.2397s / 33426.6320 s
agent0:                 episode reward: -0.5999,                 loss: nan
agent1:                 episode reward: 0.5999,                 loss: 0.1453
Episode: 5041/30000 (16.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5131s / 33561.1451 s
agent0:                 episode reward: -0.2668,                 loss: nan
agent1:                 episode reward: 0.2668,                 loss: 0.1451
Episode: 5061/30000 (16.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.6059s / 33694.7510 s
agent0:                 episode reward: -0.2817,                 loss: nan
agent1:                 episode reward: 0.2817,                 loss: 0.1456
Episode: 5081/30000 (16.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.3534s / 33832.1044 s
agent0:                 episode reward: -0.4159,                 loss: nan
agent1:                 episode reward: 0.4159,                 loss: 0.1448
Episode: 5101/30000 (17.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.4858s / 33966.5902 s
agent0:                 episode reward: -0.1532,                 loss: nan
agent1:                 episode reward: 0.1532,                 loss: 0.1444
Episode: 5121/30000 (17.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2450s / 34102.8352 s
agent0:                 episode reward: -0.0969,                 loss: nan
agent1:                 episode reward: 0.0969,                 loss: 0.1440
Episode: 5141/30000 (17.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6653s / 34238.5005 s
agent0:                 episode reward: -0.1997,                 loss: nan
agent1:                 episode reward: 0.1997,                 loss: 0.1432
Episode: 5161/30000 (17.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.4428s / 34374.9433 s
agent0:                 episode reward: 0.2351,                 loss: nan
agent1:                 episode reward: -0.2351,                 loss: 0.1453
Episode: 5181/30000 (17.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.5131s / 34508.4563 s
agent0:                 episode reward: -0.0534,                 loss: nan
agent1:                 episode reward: 0.0534,                 loss: 0.1455
Episode: 5201/30000 (17.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.4129s / 34641.8692 s
agent0:                 episode reward: -0.1916,                 loss: nan
agent1:                 episode reward: 0.1916,                 loss: 0.1458
Episode: 5221/30000 (17.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.8099s / 34780.6791 s
agent0:                 episode reward: -0.6018,                 loss: nan
agent1:                 episode reward: 0.6018,                 loss: 0.1450
Episode: 5241/30000 (17.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.8026s / 34916.4817 s
agent0:                 episode reward: -0.2872,                 loss: nan
agent1:                 episode reward: 0.2872,                 loss: 0.1432
Episode: 5261/30000 (17.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8562s / 35051.3379 s
agent0:                 episode reward: -0.3968,                 loss: nan
agent1:                 episode reward: 0.3968,                 loss: 0.1425
Episode: 5281/30000 (17.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.4442s / 35188.7821 s
agent0:                 episode reward: -0.5384,                 loss: nan
agent1:                 episode reward: 0.5384,                 loss: 0.1414
Episode: 5301/30000 (17.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.4236s / 35322.2057 s
agent0:                 episode reward: -0.5361,                 loss: nan
agent1:                 episode reward: 0.5361,                 loss: 0.1429
Episode: 5321/30000 (17.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 138.3115s / 35460.5172 s
agent0:                 episode reward: 0.0141,                 loss: nan
agent1:                 episode reward: -0.0141,                 loss: 0.1438
Episode: 5341/30000 (17.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.4566s / 35596.9738 s
agent0:                 episode reward: -0.2087,                 loss: nan
agent1:                 episode reward: 0.2087,                 loss: 0.1462
Episode: 5361/30000 (17.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.1702s / 35730.1440 s
agent0:                 episode reward: -0.2455,                 loss: nan
agent1:                 episode reward: 0.2455,                 loss: 0.1446
Episode: 5381/30000 (17.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.0071s / 35865.1511 s
agent0:                 episode reward: 0.0114,                 loss: nan
agent1:                 episode reward: -0.0114,                 loss: 0.1444
Episode: 5401/30000 (18.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.5572s / 36002.7082 s
agent0:                 episode reward: 0.1591,                 loss: nan
agent1:                 episode reward: -0.1591,                 loss: 0.1445
Episode: 5421/30000 (18.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.0798s / 36135.7881 s
agent0:                 episode reward: -0.0998,                 loss: nan
agent1:                 episode reward: 0.0998,                 loss: 0.1434
Episode: 5441/30000 (18.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.4782s / 36270.2663 s
agent0:                 episode reward: -0.3917,                 loss: nan
agent1:                 episode reward: 0.3917,                 loss: 0.1442
Episode: 5461/30000 (18.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.8437s / 36406.1100 s
agent0:                 episode reward: -0.3164,                 loss: nan
agent1:                 episode reward: 0.3164,                 loss: 0.1449
Episode: 5481/30000 (18.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.7753s / 36542.8853 s
agent0:                 episode reward: -0.4800,                 loss: nan
agent1:                 episode reward: 0.4800,                 loss: 0.1443
Episode: 5501/30000 (18.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.2125s / 36676.0979 s
agent0:                 episode reward: -0.4975,                 loss: nan
agent1:                 episode reward: 0.4975,                 loss: 0.1438
Episode: 5521/30000 (18.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.9829s / 36812.0807 s
agent0:                 episode reward: -0.1979,                 loss: nan
agent1:                 episode reward: 0.1979,                 loss: 0.1422
Episode: 5541/30000 (18.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.7206s / 36946.8014 s
agent0:                 episode reward: -0.3482,                 loss: nan
agent1:                 episode reward: 0.3482,                 loss: 0.1442
Episode: 5561/30000 (18.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.4725s / 37081.2738 s
agent0:                 episode reward: -0.1013,                 loss: nan
agent1:                 episode reward: 0.1013,                 loss: 0.1440
Episode: 5581/30000 (18.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.1516s / 37217.4255 s
agent0:                 episode reward: -0.5084,                 loss: nan
agent1:                 episode reward: 0.5084,                 loss: 0.1436
Episode: 5601/30000 (18.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0346s / 37351.4600 s
agent0:                 episode reward: -0.5918,                 loss: nan
agent1:                 episode reward: 0.5918,                 loss: 0.1435
Episode: 5621/30000 (18.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.3913s / 37484.8513 s
agent0:                 episode reward: -0.1351,                 loss: nan
agent1:                 episode reward: 0.1351,                 loss: 0.1440
Episode: 5641/30000 (18.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7900s / 37620.6413 s
agent0:                 episode reward: -0.6487,                 loss: nan
agent1:                 episode reward: 0.6487,                 loss: 0.1439
Episode: 5661/30000 (18.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.9434s / 37754.5847 s
agent0:                 episode reward: -0.2751,                 loss: nan
agent1:                 episode reward: 0.2751,                 loss: 0.1456
Episode: 5681/30000 (18.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7511s / 37890.3358 s
agent0:                 episode reward: -0.3374,                 loss: nan
agent1:                 episode reward: 0.3374,                 loss: 0.1459
Episode: 5701/30000 (19.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6244s / 38025.9602 s
agent0:                 episode reward: -0.1230,                 loss: nan
agent1:                 episode reward: 0.1230,                 loss: 0.1423
Episode: 5721/30000 (19.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6374s / 38161.5975 s
agent0:                 episode reward: -0.1631,                 loss: nan
agent1:                 episode reward: 0.1631,                 loss: 0.1446
Episode: 5741/30000 (19.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.2599s / 38295.8575 s
agent0:                 episode reward: -0.4338,                 loss: nan
agent1:                 episode reward: 0.4338,                 loss: 0.1457
Episode: 5761/30000 (19.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.3658s / 38430.2232 s
agent0:                 episode reward: -0.2980,                 loss: nan
agent1:                 episode reward: 0.2980,                 loss: 0.1454
Episode: 5781/30000 (19.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.3869s / 38564.6101 s
agent0:                 episode reward: -0.5402,                 loss: nan
agent1:                 episode reward: 0.5402,                 loss: 0.1437
Episode: 5801/30000 (19.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7056s / 38700.3157 s
agent0:                 episode reward: -0.1610,                 loss: nan
agent1:                 episode reward: 0.1610,                 loss: 0.1454
Episode: 5821/30000 (19.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.4220s / 38834.7377 s
agent0:                 episode reward: -0.4655,                 loss: nan
agent1:                 episode reward: 0.4655,                 loss: 0.1439
Episode: 5841/30000 (19.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7710s / 38970.5086 s
agent0:                 episode reward: -0.4089,                 loss: nan
agent1:                 episode reward: 0.4089,                 loss: 0.1445
Episode: 5861/30000 (19.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7990s / 39106.3076 s
agent0:                 episode reward: -0.0951,                 loss: nan
agent1:                 episode reward: 0.0951,                 loss: 0.1454
Episode: 5881/30000 (19.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.8370s / 39243.1446 s
agent0:                 episode reward: -0.1476,                 loss: nan
agent1:                 episode reward: 0.1476,                 loss: 0.1436
Episode: 5901/30000 (19.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.4216s / 39377.5663 s
agent0:                 episode reward: -0.4745,                 loss: nan
agent1:                 episode reward: 0.4745,                 loss: 0.1437
Episode: 5921/30000 (19.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.3723s / 39510.9385 s
agent0:                 episode reward: -0.2620,                 loss: nan
agent1:                 episode reward: 0.2620,                 loss: 0.1453
Episode: 5941/30000 (19.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.1158s / 39650.0544 s
agent0:                 episode reward: -0.0033,                 loss: nan
agent1:                 episode reward: 0.0033,                 loss: 0.1460
Episode: 5961/30000 (19.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3995s / 39785.4539 s
agent0:                 episode reward: -0.3319,                 loss: nan
agent1:                 episode reward: 0.3319,                 loss: 0.1457
Episode: 5981/30000 (19.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8769s / 39920.3308 s
agent0:                 episode reward: -0.6770,                 loss: nan
agent1:                 episode reward: 0.6770,                 loss: 0.1420
Episode: 6001/30000 (20.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5236s / 40054.8543 s
agent0:                 episode reward: -0.2562,                 loss: nan
agent1:                 episode reward: 0.2562,                 loss: 0.1451
Episode: 6021/30000 (20.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.7218s / 40188.5762 s
agent0:                 episode reward: -0.2585,                 loss: nan
agent1:                 episode reward: 0.2585,                 loss: 0.1441
Episode: 6041/30000 (20.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.1496s / 40320.7257 s
agent0:                 episode reward: 0.0758,                 loss: nan
agent1:                 episode reward: -0.0758,                 loss: 0.1439
Episode: 6061/30000 (20.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.8119s / 40453.5376 s
agent0:                 episode reward: -0.3486,                 loss: nan
agent1:                 episode reward: 0.3486,                 loss: 0.1448
Episode: 6081/30000 (20.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.3113s / 40586.8490 s
agent0:                 episode reward: -0.4173,                 loss: nan
agent1:                 episode reward: 0.4173,                 loss: 0.1450
Episode: 6101/30000 (20.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.7729s / 40721.6219 s
agent0:                 episode reward: -0.0689,                 loss: nan
agent1:                 episode reward: 0.0689,                 loss: 0.1448
Episode: 6121/30000 (20.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.7042s / 40856.3261 s
agent0:                 episode reward: -0.3890,                 loss: nan
agent1:                 episode reward: 0.3890,                 loss: 0.1435
Episode: 6141/30000 (20.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1740s / 40990.5001 s
agent0:                 episode reward: -0.7028,                 loss: nan
agent1:                 episode reward: 0.7028,                 loss: 0.1442
Episode: 6161/30000 (20.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5834s / 41125.0834 s
agent0:                 episode reward: -0.4809,                 loss: nan
agent1:                 episode reward: 0.4809,                 loss: 0.1432
Episode: 6181/30000 (20.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1693s / 41260.2527 s
agent0:                 episode reward: -0.5263,                 loss: nan
agent1:                 episode reward: 0.5263,                 loss: 0.1431
Episode: 6201/30000 (20.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.7268s / 41396.9795 s
agent0:                 episode reward: -0.3249,                 loss: nan
agent1:                 episode reward: 0.3249,                 loss: 0.1444
Episode: 6221/30000 (20.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.8976s / 41533.8771 s
agent0:                 episode reward: -0.4132,                 loss: nan
agent1:                 episode reward: 0.4132,                 loss: 0.1442
Episode: 6241/30000 (20.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.6598s / 41670.5369 s
agent0:                 episode reward: -0.1992,                 loss: nan
agent1:                 episode reward: 0.1992,                 loss: 0.1435
Episode: 6261/30000 (20.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2702s / 41806.8071 s
agent0:                 episode reward: -0.3117,                 loss: nan
agent1:                 episode reward: 0.3117,                 loss: 0.1437
Episode: 6281/30000 (20.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.2690s / 41941.0761 s
agent0:                 episode reward: -0.7428,                 loss: nan
agent1:                 episode reward: 0.7428,                 loss: 0.1425
Episode: 6301/30000 (21.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.5557s / 42074.6318 s
agent0:                 episode reward: -0.4491,                 loss: nan
agent1:                 episode reward: 0.4491,                 loss: 0.1437
Episode: 6321/30000 (21.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.8621s / 42210.4939 s
agent0:                 episode reward: -0.6249,                 loss: nan
agent1:                 episode reward: 0.6249,                 loss: 0.1420
Episode: 6341/30000 (21.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 138.4272s / 42348.9212 s
agent0:                 episode reward: 0.1287,                 loss: nan
agent1:                 episode reward: -0.1287,                 loss: 0.1430
Episode: 6361/30000 (21.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.5934s / 42488.5146 s
agent0:                 episode reward: -0.6599,                 loss: nan
agent1:                 episode reward: 0.6599,                 loss: 0.1430
Episode: 6381/30000 (21.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.5988s / 42622.1134 s
agent0:                 episode reward: -0.6083,                 loss: nan
agent1:                 episode reward: 0.6083,                 loss: 0.1429
Episode: 6401/30000 (21.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.5920s / 42758.7054 s
agent0:                 episode reward: 0.3730,                 loss: nan
agent1:                 episode reward: -0.3730,                 loss: 0.1431
Episode: 6421/30000 (21.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.6619s / 42896.3673 s
agent0:                 episode reward: -0.3125,                 loss: nan
agent1:                 episode reward: 0.3125,                 loss: 0.1443
Episode: 6441/30000 (21.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.2931s / 43030.6605 s
agent0:                 episode reward: -0.4187,                 loss: nan
agent1:                 episode reward: 0.4187,                 loss: 0.1423
Episode: 6461/30000 (21.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.9119s / 43167.5724 s
agent0:                 episode reward: 0.1836,                 loss: nan
agent1:                 episode reward: -0.1836,                 loss: 0.1427
Episode: 6481/30000 (21.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3362s / 43302.9085 s
agent0:                 episode reward: -0.2694,                 loss: nan
agent1:                 episode reward: 0.2694,                 loss: 0.1416
Episode: 6501/30000 (21.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 131.1042s / 43434.0128 s
agent0:                 episode reward: -0.4518,                 loss: nan
agent1:                 episode reward: 0.4518,                 loss: 0.1412
Episode: 6521/30000 (21.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0841s / 43570.0969 s
agent0:                 episode reward: -0.7781,                 loss: nan
agent1:                 episode reward: 0.7781,                 loss: 0.1420
Episode: 6541/30000 (21.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0690s / 43704.1659 s
agent0:                 episode reward: 0.2423,                 loss: nan
agent1:                 episode reward: -0.2423,                 loss: 0.1422
Episode: 6561/30000 (21.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.7927s / 43841.9586 s
agent0:                 episode reward: -0.5909,                 loss: nan
agent1:                 episode reward: 0.5909,                 loss: 0.1432
Episode: 6581/30000 (21.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.9137s / 43977.8723 s
agent0:                 episode reward: -0.3084,                 loss: nan
agent1:                 episode reward: 0.3084,                 loss: 0.1420
Episode: 6601/30000 (22.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.5650s / 44115.4373 s
agent0:                 episode reward: -0.4340,                 loss: nan
agent1:                 episode reward: 0.4340,                 loss: 0.1427
Episode: 6621/30000 (22.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.0085s / 44248.4458 s
agent0:                 episode reward: -0.1522,                 loss: nan
agent1:                 episode reward: 0.1522,                 loss: 0.1413
Episode: 6641/30000 (22.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.9547s / 44381.4006 s
agent0:                 episode reward: -0.7165,                 loss: nan
agent1:                 episode reward: 0.7165,                 loss: 0.1425
Episode: 6661/30000 (22.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.5543s / 44516.9549 s
agent0:                 episode reward: -0.2884,                 loss: nan
agent1:                 episode reward: 0.2884,                 loss: 0.1431
Episode: 6681/30000 (22.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.4105s / 44654.3654 s
agent0:                 episode reward: -0.2610,                 loss: nan
agent1:                 episode reward: 0.2610,                 loss: 0.1411
Episode: 6701/30000 (22.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0195s / 44788.3849 s
agent0:                 episode reward: -0.3103,                 loss: nan
agent1:                 episode reward: 0.3103,                 loss: 0.1429
Episode: 6721/30000 (22.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2942s / 44924.6791 s
agent0:                 episode reward: -0.3690,                 loss: nan
agent1:                 episode reward: 0.3690,                 loss: 0.1439
Episode: 6741/30000 (22.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.8181s / 45060.4972 s
agent0:                 episode reward: -0.1564,                 loss: nan
agent1:                 episode reward: 0.1564,                 loss: 0.1434
Episode: 6761/30000 (22.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.2891s / 45197.7863 s
agent0:                 episode reward: -0.5635,                 loss: nan
agent1:                 episode reward: 0.5635,                 loss: 0.1412
Episode: 6781/30000 (22.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.2825s / 45332.0687 s
agent0:                 episode reward: -0.1109,                 loss: nan
agent1:                 episode reward: 0.1109,                 loss: 0.1420
Episode: 6801/30000 (22.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7978s / 45467.8666 s
agent0:                 episode reward: -0.1671,                 loss: nan
agent1:                 episode reward: 0.1671,                 loss: 0.1427
Episode: 6821/30000 (22.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 138.7241s / 45606.5906 s
agent0:                 episode reward: -0.4070,                 loss: nan
agent1:                 episode reward: 0.4070,                 loss: 0.1429
Episode: 6841/30000 (22.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.3176s / 45739.9082 s
agent0:                 episode reward: -0.5156,                 loss: nan
agent1:                 episode reward: 0.5156,                 loss: 0.1425
Episode: 6861/30000 (22.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.7771s / 45872.6853 s
agent0:                 episode reward: -0.1537,                 loss: nan
agent1:                 episode reward: 0.1537,                 loss: 0.1429
Episode: 6881/30000 (22.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.5592s / 46006.2445 s
agent0:                 episode reward: -0.3338,                 loss: nan
agent1:                 episode reward: 0.3338,                 loss: 0.1423
Episode: 6901/30000 (23.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.1074s / 46143.3518 s
agent0:                 episode reward: -0.5138,                 loss: nan
agent1:                 episode reward: 0.5138,                 loss: 0.1416
Episode: 6921/30000 (23.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.0373s / 46280.3891 s
agent0:                 episode reward: 0.1910,                 loss: nan
agent1:                 episode reward: -0.1910,                 loss: 0.1398
Episode: 6941/30000 (23.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.8039s / 46416.1930 s
agent0:                 episode reward: -0.0233,                 loss: nan
agent1:                 episode reward: 0.0233,                 loss: 0.1408
Episode: 6961/30000 (23.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6177s / 46551.8108 s
agent0:                 episode reward: -0.4107,                 loss: nan
agent1:                 episode reward: 0.4107,                 loss: 0.1411
Episode: 6981/30000 (23.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.5018s / 46684.3125 s
agent0:                 episode reward: -0.3184,                 loss: nan
agent1:                 episode reward: 0.3184,                 loss: 0.1417
Episode: 7001/30000 (23.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3394s / 46819.6519 s
agent0:                 episode reward: -0.5121,                 loss: nan
agent1:                 episode reward: 0.5121,                 loss: 0.1408
Episode: 7021/30000 (23.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2616s / 46954.9135 s
agent0:                 episode reward: -0.1790,                 loss: nan
agent1:                 episode reward: 0.1790,                 loss: 0.1433
Episode: 7041/30000 (23.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9015s / 47089.8150 s
agent0:                 episode reward: -0.3720,                 loss: nan
agent1:                 episode reward: 0.3720,                 loss: 0.1414
Episode: 7061/30000 (23.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.9291s / 47225.7441 s
agent0:                 episode reward: -0.0316,                 loss: nan
agent1:                 episode reward: 0.0316,                 loss: 0.1416
Episode: 7081/30000 (23.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9207s / 47360.6648 s
agent0:                 episode reward: -0.6001,                 loss: nan
agent1:                 episode reward: 0.6001,                 loss: 0.1407
Episode: 7101/30000 (23.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2766s / 47496.9414 s
agent0:                 episode reward: -0.2383,                 loss: nan
agent1:                 episode reward: 0.2383,                 loss: 0.1423
Episode: 7121/30000 (23.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.7534s / 47631.6948 s
agent0:                 episode reward: -0.4559,                 loss: nan
agent1:                 episode reward: 0.4559,                 loss: 0.1414
Episode: 7141/30000 (23.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.2799s / 47765.9747 s
agent0:                 episode reward: -0.1160,                 loss: nan
agent1:                 episode reward: 0.1160,                 loss: 0.1415
Episode: 7161/30000 (23.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 139.9144s / 47905.8892 s
agent0:                 episode reward: -0.1412,                 loss: nan
agent1:                 episode reward: 0.1412,                 loss: 0.1424
Episode: 7181/30000 (23.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.6479s / 48038.5371 s
agent0:                 episode reward: 0.3533,                 loss: nan
agent1:                 episode reward: -0.3533,                 loss: 0.1416
Episode: 7201/30000 (24.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.9002s / 48175.4373 s
agent0:                 episode reward: -0.3159,                 loss: nan
agent1:                 episode reward: 0.3159,                 loss: 0.1420
Episode: 7221/30000 (24.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.4525s / 48307.8898 s
agent0:                 episode reward: -0.0134,                 loss: nan
agent1:                 episode reward: 0.0134,                 loss: 0.1421
Episode: 7241/30000 (24.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.2963s / 48441.1861 s
agent0:                 episode reward: -0.6223,                 loss: nan
agent1:                 episode reward: 0.6223,                 loss: 0.1460
Episode: 7261/30000 (24.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.7186s / 48574.9047 s
agent0:                 episode reward: -0.4739,                 loss: nan
agent1:                 episode reward: 0.4739,                 loss: 0.1443
Episode: 7281/30000 (24.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.9740s / 48708.8788 s
agent0:                 episode reward: -0.5149,                 loss: nan
agent1:                 episode reward: 0.5149,                 loss: 0.1437
Episode: 7301/30000 (24.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1551s / 48844.0339 s
agent0:                 episode reward: -0.8157,                 loss: nan
agent1:                 episode reward: 0.8157,                 loss: 0.1441
Episode: 7321/30000 (24.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.1822s / 48980.2160 s
agent0:                 episode reward: -0.5038,                 loss: nan
agent1:                 episode reward: 0.5038,                 loss: 0.1445
Episode: 7341/30000 (24.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.9660s / 49114.1820 s
agent0:                 episode reward: -0.1831,                 loss: nan
agent1:                 episode reward: 0.1831,                 loss: 0.1426
Episode: 7361/30000 (24.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.4102s / 49247.5922 s
agent0:                 episode reward: -0.2053,                 loss: nan
agent1:                 episode reward: 0.2053,                 loss: 0.1439
Episode: 7381/30000 (24.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 141.3685s / 49388.9607 s
agent0:                 episode reward: -0.0097,                 loss: nan
agent1:                 episode reward: 0.0097,                 loss: 0.1431
Episode: 7401/30000 (24.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.3822s / 49521.3430 s
agent0:                 episode reward: -0.3747,                 loss: nan
agent1:                 episode reward: 0.3747,                 loss: 0.1429
Episode: 7421/30000 (24.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.9295s / 49657.2725 s
agent0:                 episode reward: -0.6660,                 loss: nan
agent1:                 episode reward: 0.6660,                 loss: 0.1429
Episode: 7441/30000 (24.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.1205s / 49790.3930 s
agent0:                 episode reward: -0.0080,                 loss: nan
agent1:                 episode reward: 0.0080,                 loss: 0.1430
Episode: 7461/30000 (24.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.2528s / 49922.6459 s
agent0:                 episode reward: -0.6057,                 loss: nan
agent1:                 episode reward: 0.6057,                 loss: 0.1439
Episode: 7481/30000 (24.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3693s / 50058.0151 s
agent0:                 episode reward: -0.3074,                 loss: nan
agent1:                 episode reward: 0.3074,                 loss: 0.1426
Episode: 7501/30000 (25.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2710s / 50194.2862 s
agent0:                 episode reward: -0.3134,                 loss: nan
agent1:                 episode reward: 0.3134,                 loss: 0.1444
Episode: 7521/30000 (25.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.5810s / 50330.8671 s
agent0:                 episode reward: -0.1092,                 loss: nan
agent1:                 episode reward: 0.1092,                 loss: 0.1442
Episode: 7541/30000 (25.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3568s / 50466.2240 s
agent0:                 episode reward: -0.4954,                 loss: nan
agent1:                 episode reward: 0.4954,                 loss: 0.1439
Episode: 7561/30000 (25.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9099s / 50601.1338 s
agent0:                 episode reward: -0.4341,                 loss: nan
agent1:                 episode reward: 0.4341,                 loss: 0.1395
Episode: 7581/30000 (25.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.7178s / 50734.8516 s
agent0:                 episode reward: -0.4287,                 loss: nan
agent1:                 episode reward: 0.4287,                 loss: 0.1399
Episode: 7601/30000 (25.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 131.1774s / 50866.0290 s
agent0:                 episode reward: -0.2040,                 loss: nan
agent1:                 episode reward: 0.2040,                 loss: 0.1384
Episode: 7621/30000 (25.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 140.1949s / 51006.2239 s
agent0:                 episode reward: -0.2796,                 loss: nan
agent1:                 episode reward: 0.2796,                 loss: 0.1383
Episode: 7641/30000 (25.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3447s / 51141.5687 s
agent0:                 episode reward: -0.0444,                 loss: nan
agent1:                 episode reward: 0.0444,                 loss: 0.1382
Episode: 7661/30000 (25.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.7480s / 51278.3167 s
agent0:                 episode reward: -0.5468,                 loss: nan
agent1:                 episode reward: 0.5468,                 loss: 0.1375
Episode: 7681/30000 (25.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.3660s / 51415.6827 s
agent0:                 episode reward: -0.5411,                 loss: nan
agent1:                 episode reward: 0.5411,                 loss: 0.1401
Episode: 7701/30000 (25.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8820s / 51550.5648 s
agent0:                 episode reward: -0.1049,                 loss: nan
agent1:                 episode reward: 0.1049,                 loss: 0.1392
Episode: 7721/30000 (25.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1571s / 51684.7219 s
agent0:                 episode reward: 0.1088,                 loss: nan
agent1:                 episode reward: -0.1088,                 loss: 0.1393
Episode: 7741/30000 (25.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.5796s / 51822.3014 s
agent0:                 episode reward: -0.2004,                 loss: nan
agent1:                 episode reward: 0.2004,                 loss: 0.1390
Episode: 7761/30000 (25.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 131.9984s / 51954.2998 s
agent0:                 episode reward: -0.5039,                 loss: nan
agent1:                 episode reward: 0.5039,                 loss: 0.1382
Episode: 7781/30000 (25.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.2134s / 52091.5132 s
agent0:                 episode reward: -0.4615,                 loss: nan
agent1:                 episode reward: 0.4615,                 loss: 0.1395
Episode: 7801/30000 (26.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.5137s / 52227.0269 s
agent0:                 episode reward: -0.1564,                 loss: nan
agent1:                 episode reward: 0.1564,                 loss: 0.1376
Episode: 7821/30000 (26.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.3649s / 52363.3918 s
agent0:                 episode reward: -0.2690,                 loss: nan
agent1:                 episode reward: 0.2690,                 loss: 0.1394
Episode: 7841/30000 (26.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3559s / 52498.7477 s
agent0:                 episode reward: -0.2744,                 loss: nan
agent1:                 episode reward: 0.2744,                 loss: 0.1381
Episode: 7861/30000 (26.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.0419s / 52630.7896 s
agent0:                 episode reward: -0.2333,                 loss: nan
agent1:                 episode reward: 0.2333,                 loss: 0.1387
Episode: 7881/30000 (26.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.5546s / 52766.3442 s
agent0:                 episode reward: -0.1040,                 loss: nan
agent1:                 episode reward: 0.1040,                 loss: 0.1391
Episode: 7901/30000 (26.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.9421s / 52899.2863 s
agent0:                 episode reward: -0.2316,                 loss: nan
agent1:                 episode reward: 0.2316,                 loss: 0.1440
Episode: 7921/30000 (26.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.0857s / 53034.3721 s
agent0:                 episode reward: -0.5202,                 loss: nan
agent1:                 episode reward: 0.5202,                 loss: 0.1444
Episode: 7941/30000 (26.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.4378s / 53170.8098 s
agent0:                 episode reward: -0.5307,                 loss: nan
agent1:                 episode reward: 0.5307,                 loss: 0.1423
Episode: 7961/30000 (26.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.0212s / 53302.8311 s
agent0:                 episode reward: -0.2385,                 loss: nan
agent1:                 episode reward: 0.2385,                 loss: 0.1453
Episode: 7981/30000 (26.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.6566s / 53441.4876 s
agent0:                 episode reward: 0.0242,                 loss: nan
agent1:                 episode reward: -0.0242,                 loss: 0.1436
Episode: 8001/30000 (26.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.5353s / 53578.0229 s
agent0:                 episode reward: -0.4392,                 loss: nan
agent1:                 episode reward: 0.4392,                 loss: 0.1438
Episode: 8021/30000 (26.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.5657s / 53713.5887 s
agent0:                 episode reward: -0.3302,                 loss: nan
agent1:                 episode reward: 0.3302,                 loss: 0.1427
Episode: 8041/30000 (26.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3926s / 53848.9812 s
agent0:                 episode reward: -0.5944,                 loss: nan
agent1:                 episode reward: 0.5944,                 loss: 0.1442
Episode: 8061/30000 (26.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4430s / 53984.4242 s
agent0:                 episode reward: -0.4280,                 loss: nan
agent1:                 episode reward: 0.4280,                 loss: 0.1435
Episode: 8081/30000 (26.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.8570s / 54117.2812 s
agent0:                 episode reward: 0.3890,                 loss: nan
agent1:                 episode reward: -0.3890,                 loss: 0.1438
Episode: 8101/30000 (27.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.5296s / 54250.8108 s
agent0:                 episode reward: -0.5059,                 loss: nan
agent1:                 episode reward: 0.5059,                 loss: 0.1440
Episode: 8121/30000 (27.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8089s / 54385.6198 s
agent0:                 episode reward: 0.1160,                 loss: nan
agent1:                 episode reward: -0.1160,                 loss: 0.1433
Episode: 8141/30000 (27.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.7699s / 54522.3897 s
agent0:                 episode reward: -0.3731,                 loss: nan
agent1:                 episode reward: 0.3731,                 loss: 0.1430
Episode: 8161/30000 (27.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2840s / 54657.6737 s
agent0:                 episode reward: -0.1078,                 loss: nan
agent1:                 episode reward: 0.1078,                 loss: 0.1443
Episode: 8181/30000 (27.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.5958s / 54794.2695 s
agent0:                 episode reward: -0.6223,                 loss: nan
agent1:                 episode reward: 0.6223,                 loss: 0.1432
Episode: 8201/30000 (27.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.4532s / 54931.7227 s
agent0:                 episode reward: -0.3658,                 loss: nan
agent1:                 episode reward: 0.3658,                 loss: 0.1419
Episode: 8221/30000 (27.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4518s / 55067.1745 s
agent0:                 episode reward: -0.2868,                 loss: nan
agent1:                 episode reward: 0.2868,                 loss: 0.1442
Episode: 8241/30000 (27.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.6665s / 55203.8409 s
agent0:                 episode reward: -0.4237,                 loss: nan
agent1:                 episode reward: 0.4237,                 loss: 0.1455
Episode: 8261/30000 (27.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.2093s / 55341.0502 s
agent0:                 episode reward: -0.7571,                 loss: nan
agent1:                 episode reward: 0.7571,                 loss: 0.1419
Episode: 8281/30000 (27.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1660s / 55475.2162 s
agent0:                 episode reward: 0.0339,                 loss: nan
agent1:                 episode reward: -0.0339,                 loss: 0.1422
Episode: 8301/30000 (27.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.4707s / 55611.6868 s
agent0:                 episode reward: -0.6943,                 loss: nan
agent1:                 episode reward: 0.6943,                 loss: 0.1425
Episode: 8321/30000 (27.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4692s / 55747.1560 s
agent0:                 episode reward: -0.1454,                 loss: nan
agent1:                 episode reward: 0.1454,                 loss: 0.1430
Episode: 8341/30000 (27.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6020s / 55881.7581 s
agent0:                 episode reward: -0.5707,                 loss: nan
agent1:                 episode reward: 0.5707,                 loss: 0.1433
Episode: 8361/30000 (27.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1622s / 56015.9203 s
agent0:                 episode reward: 0.0028,                 loss: nan
agent1:                 episode reward: -0.0028,                 loss: 0.1433
Episode: 8381/30000 (27.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2973s / 56151.2176 s
agent0:                 episode reward: -0.3878,                 loss: nan
agent1:                 episode reward: 0.3878,                 loss: 0.1426
Episode: 8401/30000 (28.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3613s / 56286.5789 s
agent0:                 episode reward: -0.5466,                 loss: nan
agent1:                 episode reward: 0.5466,                 loss: 0.1446
Episode: 8421/30000 (28.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.7531s / 56423.3320 s
agent0:                 episode reward: -0.3639,                 loss: nan
agent1:                 episode reward: 0.3639,                 loss: 0.1429
Episode: 8441/30000 (28.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.0010s / 56555.3330 s
agent0:                 episode reward: -0.1591,                 loss: nan
agent1:                 episode reward: 0.1591,                 loss: 0.1432
Episode: 8461/30000 (28.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.4063s / 56692.7393 s
agent0:                 episode reward: -0.3391,                 loss: nan
agent1:                 episode reward: 0.3391,                 loss: 0.1420
Episode: 8481/30000 (28.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.9083s / 56831.6476 s
agent0:                 episode reward: -0.1436,                 loss: nan
agent1:                 episode reward: 0.1436,                 loss: 0.1423
Episode: 8501/30000 (28.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.7870s / 56964.4346 s
agent0:                 episode reward: -0.3339,                 loss: nan
agent1:                 episode reward: 0.3339,                 loss: 0.1425
Episode: 8521/30000 (28.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4852s / 57099.9198 s
agent0:                 episode reward: -0.1100,                 loss: nan
agent1:                 episode reward: 0.1100,                 loss: 0.1423
Episode: 8541/30000 (28.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.6594s / 57232.5792 s
agent0:                 episode reward: -0.3372,                 loss: nan
agent1:                 episode reward: 0.3372,                 loss: 0.1443
Episode: 8561/30000 (28.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.5302s / 57366.1094 s
agent0:                 episode reward: -0.2982,                 loss: nan
agent1:                 episode reward: 0.2982,                 loss: 0.1440
Episode: 8581/30000 (28.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1469s / 57501.2563 s
agent0:                 episode reward: -0.1412,                 loss: nan
agent1:                 episode reward: 0.1412,                 loss: 0.1459
Episode: 8601/30000 (28.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 131.6652s / 57632.9215 s
agent0:                 episode reward: -0.4966,                 loss: nan
agent1:                 episode reward: 0.4966,                 loss: 0.1429
Episode: 8621/30000 (28.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7007s / 57768.6222 s
agent0:                 episode reward: -0.2846,                 loss: nan
agent1:                 episode reward: 0.2846,                 loss: 0.1445
Episode: 8641/30000 (28.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.9817s / 57902.6040 s
agent0:                 episode reward: -0.6107,                 loss: nan
agent1:                 episode reward: 0.6107,                 loss: 0.1452
Episode: 8661/30000 (28.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.4705s / 58036.0745 s
agent0:                 episode reward: -0.4911,                 loss: nan
agent1:                 episode reward: 0.4911,                 loss: 0.1439
Episode: 8681/30000 (28.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0300s / 58172.1044 s
agent0:                 episode reward: -0.6667,                 loss: nan
agent1:                 episode reward: 0.6667,                 loss: 0.1442
Episode: 8701/30000 (29.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.6420s / 58305.7464 s
agent0:                 episode reward: -0.2245,                 loss: nan
agent1:                 episode reward: 0.2245,                 loss: 0.1438
Episode: 8721/30000 (29.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6821s / 58441.4285 s
agent0:                 episode reward: -0.1420,                 loss: nan
agent1:                 episode reward: 0.1420,                 loss: 0.1449
Episode: 8741/30000 (29.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.3623s / 58578.7908 s
agent0:                 episode reward: -0.3457,                 loss: nan
agent1:                 episode reward: 0.3457,                 loss: 0.1445
Episode: 8761/30000 (29.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2678s / 58714.0586 s
agent0:                 episode reward: -0.7216,                 loss: nan
agent1:                 episode reward: 0.7216,                 loss: 0.1440
Episode: 8781/30000 (29.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.8951s / 58852.9538 s
agent0:                 episode reward: -0.3806,                 loss: nan
agent1:                 episode reward: 0.3806,                 loss: 0.1437
Episode: 8801/30000 (29.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.3640s / 58990.3177 s
agent0:                 episode reward: -0.4410,                 loss: nan
agent1:                 episode reward: 0.4410,                 loss: 0.1447
Episode: 8821/30000 (29.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.2075s / 59127.5252 s
agent0:                 episode reward: -0.5469,                 loss: nan
agent1:                 episode reward: 0.5469,                 loss: 0.1436
Episode: 8841/30000 (29.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.1394s / 59260.6646 s
agent0:                 episode reward: -0.1973,                 loss: nan
agent1:                 episode reward: 0.1973,                 loss: 0.1441
Episode: 8861/30000 (29.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.9216s / 59393.5862 s
agent0:                 episode reward: -0.2211,                 loss: nan
agent1:                 episode reward: 0.2211,                 loss: 0.1454
Episode: 8881/30000 (29.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.7449s / 59532.3311 s
agent0:                 episode reward: -0.4869,                 loss: nan
agent1:                 episode reward: 0.4869,                 loss: 0.1443
Episode: 8901/30000 (29.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.3200s / 59669.6511 s
agent0:                 episode reward: -0.3547,                 loss: nan
agent1:                 episode reward: 0.3547,                 loss: 0.1398
Episode: 8921/30000 (29.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.1599s / 59802.8110 s
agent0:                 episode reward: -0.4590,                 loss: nan
agent1:                 episode reward: 0.4590,                 loss: 0.1413
Episode: 8941/30000 (29.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.1108s / 59938.9218 s
agent0:                 episode reward: -0.1925,                 loss: nan
agent1:                 episode reward: 0.1925,                 loss: 0.1414
Episode: 8961/30000 (29.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5478s / 60073.4696 s
agent0:                 episode reward: 0.0128,                 loss: nan
agent1:                 episode reward: -0.0128,                 loss: 0.1402
Episode: 8981/30000 (29.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4333s / 60208.9029 s
agent0:                 episode reward: -0.5219,                 loss: nan
agent1:                 episode reward: 0.5219,                 loss: 0.1400
Episode: 9001/30000 (30.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5488s / 60343.4517 s
agent0:                 episode reward: -0.6476,                 loss: nan
agent1:                 episode reward: 0.6476,                 loss: 0.1396
Episode: 9021/30000 (30.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.1567s / 60480.6084 s
agent0:                 episode reward: -0.6377,                 loss: nan
agent1:                 episode reward: 0.6377,                 loss: 0.1406
Episode: 9041/30000 (30.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2602s / 60615.8687 s
agent0:                 episode reward: -0.0822,                 loss: nan
agent1:                 episode reward: 0.0822,                 loss: 0.1396
Episode: 9061/30000 (30.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1118s / 60750.9804 s
agent0:                 episode reward: -0.5687,                 loss: nan
agent1:                 episode reward: 0.5687,                 loss: 0.1411
Episode: 9081/30000 (30.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0718s / 60887.0523 s
agent0:                 episode reward: -0.1583,                 loss: nan
agent1:                 episode reward: 0.1583,                 loss: 0.1396
Episode: 9101/30000 (30.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.5411s / 61023.5933 s
agent0:                 episode reward: -0.3331,                 loss: nan
agent1:                 episode reward: 0.3331,                 loss: 0.1404
Episode: 9121/30000 (30.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.7953s / 61160.3886 s
agent0:                 episode reward: -0.0572,                 loss: nan
agent1:                 episode reward: 0.0572,                 loss: 0.1402
Episode: 9141/30000 (30.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.7086s / 61294.0972 s
agent0:                 episode reward: -0.4767,                 loss: nan
agent1:                 episode reward: 0.4767,                 loss: 0.1397
Episode: 9161/30000 (30.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.1255s / 61431.2227 s
agent0:                 episode reward: -0.1817,                 loss: nan
agent1:                 episode reward: 0.1817,                 loss: 0.1409
Episode: 9181/30000 (30.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.8357s / 61565.0585 s
agent0:                 episode reward: -0.5681,                 loss: nan
agent1:                 episode reward: 0.5681,                 loss: 0.1407
Episode: 9201/30000 (30.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 140.8166s / 61705.8751 s
agent0:                 episode reward: -0.3347,                 loss: nan
agent1:                 episode reward: 0.3347,                 loss: 0.1404
Episode: 9221/30000 (30.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.7787s / 61842.6537 s
agent0:                 episode reward: -0.4088,                 loss: nan
agent1:                 episode reward: 0.4088,                 loss: 0.1419
Episode: 9241/30000 (30.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.4217s / 61976.0755 s
agent0:                 episode reward: -0.3334,                 loss: nan
agent1:                 episode reward: 0.3334,                 loss: 0.1427
Episode: 9261/30000 (30.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.8642s / 62109.9396 s
agent0:                 episode reward: -0.4238,                 loss: nan
agent1:                 episode reward: 0.4238,                 loss: 0.1427
Episode: 9281/30000 (30.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.2037s / 62247.1433 s
agent0:                 episode reward: -0.2668,                 loss: nan
agent1:                 episode reward: 0.2668,                 loss: 0.1410
Episode: 9301/30000 (31.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3288s / 62382.4721 s
agent0:                 episode reward: 0.3106,                 loss: nan
agent1:                 episode reward: -0.3106,                 loss: 0.1415
Episode: 9321/30000 (31.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.9275s / 62516.3996 s
agent0:                 episode reward: -0.2805,                 loss: nan
agent1:                 episode reward: 0.2805,                 loss: 0.1423
Episode: 9341/30000 (31.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.6522s / 62654.0518 s
agent0:                 episode reward: -0.3299,                 loss: nan
agent1:                 episode reward: 0.3299,                 loss: 0.1419
Episode: 9361/30000 (31.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0663s / 62788.1181 s
agent0:                 episode reward: -0.3219,                 loss: nan
agent1:                 episode reward: 0.3219,                 loss: 0.1419
Episode: 9381/30000 (31.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5223s / 62922.6405 s
agent0:                 episode reward: -0.5319,                 loss: nan
agent1:                 episode reward: 0.5319,                 loss: 0.1426
Episode: 9401/30000 (31.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.5480s / 63058.1885 s
agent0:                 episode reward: -0.3015,                 loss: nan
agent1:                 episode reward: 0.3015,                 loss: 0.1424
Episode: 9421/30000 (31.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.3653s / 63195.5539 s
agent0:                 episode reward: -0.4637,                 loss: nan
agent1:                 episode reward: 0.4637,                 loss: 0.1426
Episode: 9441/30000 (31.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.3991s / 63332.9529 s
agent0:                 episode reward: -0.4678,                 loss: nan
agent1:                 episode reward: 0.4678,                 loss: 0.1427
Episode: 9461/30000 (31.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 131.4264s / 63464.3793 s
agent0:                 episode reward: -0.5167,                 loss: nan
agent1:                 episode reward: 0.5167,                 loss: 0.1416
Episode: 9481/30000 (31.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2285s / 63600.6079 s
agent0:                 episode reward: -0.0867,                 loss: nan
agent1:                 episode reward: 0.0867,                 loss: 0.1432
Episode: 9501/30000 (31.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6627s / 63735.2705 s
agent0:                 episode reward: -0.5677,                 loss: nan
agent1:                 episode reward: 0.5677,                 loss: 0.1417
Episode: 9521/30000 (31.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.9589s / 63869.2294 s
agent0:                 episode reward: -0.3530,                 loss: nan
agent1:                 episode reward: 0.3530,                 loss: 0.1427
Episode: 9541/30000 (31.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.1316s / 64001.3610 s
agent0:                 episode reward: 0.0670,                 loss: nan
agent1:                 episode reward: -0.0670,                 loss: 0.1416
Episode: 9561/30000 (31.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.3976s / 64134.7586 s
agent0:                 episode reward: -0.4758,                 loss: nan
agent1:                 episode reward: 0.4758,                 loss: 0.1414
Episode: 9581/30000 (31.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 138.3424s / 64273.1009 s
agent0:                 episode reward: -0.6130,                 loss: nan
agent1:                 episode reward: 0.6130,                 loss: 0.1425
Episode: 9601/30000 (32.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6875s / 64407.7884 s
agent0:                 episode reward: -0.5971,                 loss: nan
agent1:                 episode reward: 0.5971,                 loss: 0.1437
Episode: 9621/30000 (32.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.4313s / 64540.2198 s
agent0:                 episode reward: -0.4031,                 loss: nan
agent1:                 episode reward: 0.4031,                 loss: 0.1433
Episode: 9641/30000 (32.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.2155s / 64674.4353 s
agent0:                 episode reward: -0.4376,                 loss: nan
agent1:                 episode reward: 0.4376,                 loss: 0.1417
Episode: 9661/30000 (32.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.0472s / 64812.4825 s
agent0:                 episode reward: -0.2323,                 loss: nan
agent1:                 episode reward: 0.2323,                 loss: 0.1425
Episode: 9681/30000 (32.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4457s / 64947.9282 s
agent0:                 episode reward: -0.7309,                 loss: nan
agent1:                 episode reward: 0.7309,                 loss: 0.1408
Episode: 9701/30000 (32.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.7934s / 65082.7216 s
agent0:                 episode reward: -0.6187,                 loss: nan
agent1:                 episode reward: 0.6187,                 loss: 0.1405
Episode: 9721/30000 (32.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.9392s / 65220.6608 s
agent0:                 episode reward: -0.1701,                 loss: nan
agent1:                 episode reward: 0.1701,                 loss: 0.1419
Episode: 9741/30000 (32.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.8721s / 65354.5330 s
agent0:                 episode reward: -0.4033,                 loss: nan
agent1:                 episode reward: 0.4033,                 loss: 0.1435
Episode: 9761/30000 (32.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.4534s / 65486.9863 s
agent0:                 episode reward: -0.1283,                 loss: nan
agent1:                 episode reward: 0.1283,                 loss: 0.1425
Episode: 9781/30000 (32.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4994s / 65622.4857 s
agent0:                 episode reward: -0.6410,                 loss: nan
agent1:                 episode reward: 0.6410,                 loss: 0.1422
Episode: 9801/30000 (32.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.4121s / 65758.8979 s
agent0:                 episode reward: -0.1381,                 loss: nan
agent1:                 episode reward: 0.1381,                 loss: 0.1415
Episode: 9821/30000 (32.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2128s / 65894.1107 s
agent0:                 episode reward: -0.2642,                 loss: nan
agent1:                 episode reward: 0.2642,                 loss: 0.1439
Episode: 9841/30000 (32.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.1095s / 66027.2202 s
agent0:                 episode reward: -0.6274,                 loss: nan
agent1:                 episode reward: 0.6274,                 loss: 0.1440
Episode: 9861/30000 (32.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.2617s / 66160.4819 s
agent0:                 episode reward: -0.2033,                 loss: nan
agent1:                 episode reward: 0.2033,                 loss: 0.1433
Episode: 9881/30000 (32.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0163s / 66294.4982 s
agent0:                 episode reward: -0.4640,                 loss: nan
agent1:                 episode reward: 0.4640,                 loss: 0.1428
Episode: 9901/30000 (33.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0016s / 66428.4998 s
agent0:                 episode reward: -0.3641,                 loss: nan
agent1:                 episode reward: 0.3641,                 loss: 0.1414
Episode: 9921/30000 (33.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.3403s / 66561.8401 s
agent0:                 episode reward: -0.2185,                 loss: nan
agent1:                 episode reward: 0.2185,                 loss: 0.1406
Episode: 9941/30000 (33.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.0261s / 66693.8662 s
agent0:                 episode reward: -0.6438,                 loss: nan
agent1:                 episode reward: 0.6438,                 loss: 0.1412
Episode: 9961/30000 (33.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.1842s / 66827.0505 s
agent0:                 episode reward: -0.3567,                 loss: nan
agent1:                 episode reward: 0.3567,                 loss: 0.1395
Episode: 9981/30000 (33.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6984s / 66962.7489 s
agent0:                 episode reward: -0.3470,                 loss: nan
agent1:                 episode reward: 0.3470,                 loss: 0.1416
Episode: 10001/30000 (33.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 130.8745s / 67093.6234 s
agent0:                 episode reward: -0.0716,                 loss: nan
agent1:                 episode reward: 0.0716,                 loss: 0.1424
Episode: 10021/30000 (33.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.5088s / 67232.1321 s
agent0:                 episode reward: -0.4251,                 loss: nan
agent1:                 episode reward: 0.4251,                 loss: 0.1409
Episode: 10041/30000 (33.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0822s / 67368.2144 s
agent0:                 episode reward: -0.4523,                 loss: nan
agent1:                 episode reward: 0.4523,                 loss: 0.1414
Episode: 10061/30000 (33.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8281s / 67503.0425 s
agent0:                 episode reward: -0.0980,                 loss: nan
agent1:                 episode reward: 0.0980,                 loss: 0.1415
Episode: 10081/30000 (33.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5402s / 67637.5827 s
agent0:                 episode reward: -0.4669,                 loss: nan
agent1:                 episode reward: 0.4669,                 loss: 0.1421
Episode: 10101/30000 (33.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.0586s / 67772.6413 s
agent0:                 episode reward: -0.2673,                 loss: nan
agent1:                 episode reward: 0.2673,                 loss: 0.1409
Episode: 10121/30000 (33.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.8319s / 67905.4733 s
agent0:                 episode reward: -0.5570,                 loss: nan
agent1:                 episode reward: 0.5570,                 loss: 0.1395
Episode: 10141/30000 (33.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.6901s / 68043.1634 s
agent0:                 episode reward: -0.1128,                 loss: nan
agent1:                 episode reward: 0.1128,                 loss: 0.1415
Episode: 10161/30000 (33.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5692s / 68177.7326 s
agent0:                 episode reward: -0.4337,                 loss: nan
agent1:                 episode reward: 0.4337,                 loss: 0.1412
Episode: 10181/30000 (33.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.3282s / 68314.0608 s
agent0:                 episode reward: -0.4286,                 loss: nan
agent1:                 episode reward: 0.4286,                 loss: 0.1411
Episode: 10201/30000 (34.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.9973s / 68451.0581 s
agent0:                 episode reward: -0.4108,                 loss: nan
agent1:                 episode reward: 0.4108,                 loss: 0.1428
Episode: 10221/30000 (34.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6366s / 68585.6947 s
agent0:                 episode reward: 0.0667,                 loss: nan
agent1:                 episode reward: -0.0667,                 loss: 0.1423
Episode: 10241/30000 (34.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2505s / 68720.9452 s
agent0:                 episode reward: -0.3538,                 loss: nan
agent1:                 episode reward: 0.3538,                 loss: 0.1436
Episode: 10261/30000 (34.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1876s / 68855.1328 s
agent0:                 episode reward: -0.4986,                 loss: nan
agent1:                 episode reward: 0.4986,                 loss: 0.1431
Episode: 10281/30000 (34.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.9078s / 68991.0406 s
agent0:                 episode reward: -0.3845,                 loss: nan
agent1:                 episode reward: 0.3845,                 loss: 0.1431
Episode: 10301/30000 (34.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1749s / 69126.2155 s
agent0:                 episode reward: -0.2431,                 loss: nan
agent1:                 episode reward: 0.2431,                 loss: 0.1430
Episode: 10321/30000 (34.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.4666s / 69260.6822 s
agent0:                 episode reward: -0.3491,                 loss: nan
agent1:                 episode reward: 0.3491,                 loss: 0.1436
Episode: 10341/30000 (34.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.6814s / 69397.3635 s
agent0:                 episode reward: -0.7269,                 loss: nan
agent1:                 episode reward: 0.7269,                 loss: 0.1440
Episode: 10361/30000 (34.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.1965s / 69530.5600 s
agent0:                 episode reward: -0.4068,                 loss: nan
agent1:                 episode reward: 0.4068,                 loss: 0.1427
Episode: 10381/30000 (34.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.2447s / 69664.8047 s
agent0:                 episode reward: -0.6367,                 loss: nan
agent1:                 episode reward: 0.6367,                 loss: 0.1442
Episode: 10401/30000 (34.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 130.6678s / 69795.4725 s
agent0:                 episode reward: -0.1625,                 loss: nan
agent1:                 episode reward: 0.1625,                 loss: 0.1431
Episode: 10421/30000 (34.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.0031s / 69928.4756 s
agent0:                 episode reward: -0.5717,                 loss: nan
agent1:                 episode reward: 0.5717,                 loss: 0.1426
Episode: 10441/30000 (34.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2525s / 70064.7282 s
agent0:                 episode reward: -0.3117,                 loss: nan
agent1:                 episode reward: 0.3117,                 loss: 0.1434
Episode: 10461/30000 (34.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5837s / 70199.3119 s
agent0:                 episode reward: -0.5319,                 loss: nan
agent1:                 episode reward: 0.5319,                 loss: 0.1447
Episode: 10481/30000 (34.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.3829s / 70333.6948 s
agent0:                 episode reward: -0.8710,                 loss: nan
agent1:                 episode reward: 0.8710,                 loss: 0.1431
Episode: 10501/30000 (35.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.3192s / 70471.0140 s
agent0:                 episode reward: -0.6275,                 loss: nan
agent1:                 episode reward: 0.6275,                 loss: 0.1432
Episode: 10521/30000 (35.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.3230s / 70608.3369 s
agent0:                 episode reward: -0.4250,                 loss: nan
agent1:                 episode reward: 0.4250,                 loss: 0.1430
Episode: 10541/30000 (35.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 131.4257s / 70739.7626 s
agent0:                 episode reward: -0.2266,                 loss: nan
agent1:                 episode reward: 0.2266,                 loss: 0.1432
Episode: 10561/30000 (35.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.0139s / 70877.7765 s
agent0:                 episode reward: -0.7821,                 loss: nan
agent1:                 episode reward: 0.7821,                 loss: 0.1418
Episode: 10581/30000 (35.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6805s / 71012.4570 s
agent0:                 episode reward: -0.5870,                 loss: nan
agent1:                 episode reward: 0.5870,                 loss: 0.1413
Episode: 10601/30000 (35.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 131.4553s / 71143.9123 s
agent0:                 episode reward: -0.3494,                 loss: nan
agent1:                 episode reward: 0.3494,                 loss: 0.1424
Episode: 10621/30000 (35.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.3231s / 71280.2354 s
agent0:                 episode reward: -0.0944,                 loss: nan
agent1:                 episode reward: 0.0944,                 loss: 0.1432
Episode: 10641/30000 (35.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 139.7013s / 71419.9368 s
agent0:                 episode reward: -0.6768,                 loss: nan
agent1:                 episode reward: 0.6768,                 loss: 0.1417
Episode: 10661/30000 (35.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.3464s / 71554.2831 s
agent0:                 episode reward: -0.4198,                 loss: nan
agent1:                 episode reward: 0.4198,                 loss: 0.1433
Episode: 10681/30000 (35.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1304s / 71688.4135 s
agent0:                 episode reward: -0.2491,                 loss: nan
agent1:                 episode reward: 0.2491,                 loss: 0.1426
Episode: 10701/30000 (35.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.3581s / 71822.7717 s
agent0:                 episode reward: -0.6093,                 loss: nan
agent1:                 episode reward: 0.6093,                 loss: 0.1427
Episode: 10721/30000 (35.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.0128s / 71957.7844 s
agent0:                 episode reward: -0.6369,                 loss: nan
agent1:                 episode reward: 0.6369,                 loss: 0.1420
Episode: 10741/30000 (35.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2315s / 72094.0159 s
agent0:                 episode reward: -0.6430,                 loss: nan
agent1:                 episode reward: 0.6430,                 loss: 0.1430
Episode: 10761/30000 (35.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.3548s / 72228.3707 s
agent0:                 episode reward: -0.5778,                 loss: nan
agent1:                 episode reward: 0.5778,                 loss: 0.1414
Episode: 10781/30000 (35.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2090s / 72363.5797 s
agent0:                 episode reward: -0.2926,                 loss: nan
agent1:                 episode reward: 0.2926,                 loss: 0.1417
Episode: 10801/30000 (36.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.5088s / 72501.0886 s
agent0:                 episode reward: -0.5180,                 loss: nan
agent1:                 episode reward: 0.5180,                 loss: 0.1422
Episode: 10821/30000 (36.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6871s / 72635.7757 s
agent0:                 episode reward: -0.5385,                 loss: nan
agent1:                 episode reward: 0.5385,                 loss: 0.1403
Episode: 10841/30000 (36.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 138.2298s / 72774.0055 s
agent0:                 episode reward: -1.0436,                 loss: nan
agent1:                 episode reward: 1.0436,                 loss: 0.1428
Episode: 10861/30000 (36.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 131.4377s / 72905.4432 s
agent0:                 episode reward: -0.2680,                 loss: nan
agent1:                 episode reward: 0.2680,                 loss: 0.1421
Episode: 10881/30000 (36.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1791s / 73040.6223 s
agent0:                 episode reward: -0.5250,                 loss: nan
agent1:                 episode reward: 0.5250,                 loss: 0.1408
Episode: 10901/30000 (36.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.4751s / 73174.0974 s
agent0:                 episode reward: -0.4313,                 loss: nan
agent1:                 episode reward: 0.4313,                 loss: 0.1399
Episode: 10921/30000 (36.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0650s / 73308.1624 s
agent0:                 episode reward: 0.1476,                 loss: nan
agent1:                 episode reward: -0.1476,                 loss: 0.1383
Episode: 10941/30000 (36.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.9018s / 73446.0642 s
agent0:                 episode reward: -0.0529,                 loss: nan
agent1:                 episode reward: 0.0529,                 loss: 0.1393
Episode: 10961/30000 (36.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.2758s / 73583.3400 s
agent0:                 episode reward: -0.1102,                 loss: nan
agent1:                 episode reward: 0.1102,                 loss: 0.1390
Episode: 10981/30000 (36.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.5657s / 73716.9057 s
agent0:                 episode reward: -0.1477,                 loss: nan
agent1:                 episode reward: 0.1477,                 loss: 0.1402
Episode: 11001/30000 (36.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1944s / 73852.1001 s
agent0:                 episode reward: -0.1666,                 loss: nan
agent1:                 episode reward: 0.1666,                 loss: 0.1401
Episode: 11021/30000 (36.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.3174s / 73986.4175 s
agent0:                 episode reward: -0.4943,                 loss: nan
agent1:                 episode reward: 0.4943,                 loss: 0.1401
Episode: 11041/30000 (36.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.9794s / 74123.3969 s
agent0:                 episode reward: -0.4963,                 loss: nan
agent1:                 episode reward: 0.4963,                 loss: 0.1400
Episode: 11061/30000 (36.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2681s / 74259.6650 s
agent0:                 episode reward: -0.9283,                 loss: nan
agent1:                 episode reward: 0.9283,                 loss: 0.1385
Episode: 11081/30000 (36.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.5098s / 74392.1748 s
agent0:                 episode reward: -0.2843,                 loss: nan
agent1:                 episode reward: 0.2843,                 loss: 0.1394
Episode: 11101/30000 (37.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.2416s / 74525.4164 s
agent0:                 episode reward: -0.3021,                 loss: nan
agent1:                 episode reward: 0.3021,                 loss: 0.1395
Episode: 11121/30000 (37.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.9929s / 74661.4093 s
agent0:                 episode reward: -0.4423,                 loss: nan
agent1:                 episode reward: 0.4423,                 loss: 0.1388
Episode: 11141/30000 (37.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.9926s / 74795.4019 s
agent0:                 episode reward: -0.2286,                 loss: nan
agent1:                 episode reward: 0.2286,                 loss: 0.1406
Episode: 11161/30000 (37.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.5501s / 74928.9520 s
agent0:                 episode reward: -0.1382,                 loss: nan
agent1:                 episode reward: 0.1382,                 loss: 0.1398
Episode: 11181/30000 (37.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.4474s / 75067.3994 s
agent0:                 episode reward: -0.1436,                 loss: nan
agent1:                 episode reward: 0.1436,                 loss: 0.1402
Episode: 11201/30000 (37.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.8562s / 75201.2556 s
agent0:                 episode reward: -0.4644,                 loss: nan
agent1:                 episode reward: 0.4644,                 loss: 0.1405
Episode: 11221/30000 (37.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.4455s / 75339.7011 s
agent0:                 episode reward: -0.4848,                 loss: nan
agent1:                 episode reward: 0.4848,                 loss: 0.1401
Episode: 11241/30000 (37.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.8470s / 75472.5481 s
agent0:                 episode reward: -0.3168,                 loss: nan
agent1:                 episode reward: 0.3168,                 loss: 0.1425
Episode: 11261/30000 (37.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1172s / 75607.6653 s
agent0:                 episode reward: 0.1542,                 loss: nan
agent1:                 episode reward: -0.1542,                 loss: 0.1398
Episode: 11281/30000 (37.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4250s / 75743.0903 s
agent0:                 episode reward: -0.3801,                 loss: nan
agent1:                 episode reward: 0.3801,                 loss: 0.1399
Episode: 11301/30000 (37.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1058s / 75878.1961 s
agent0:                 episode reward: -0.3937,                 loss: nan
agent1:                 episode reward: 0.3937,                 loss: 0.1406
Episode: 11321/30000 (37.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.2197s / 76015.4158 s
agent0:                 episode reward: -0.7726,                 loss: nan
agent1:                 episode reward: 0.7726,                 loss: 0.1412
Episode: 11341/30000 (37.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 131.7977s / 76147.2134 s
agent0:                 episode reward: -0.6175,                 loss: nan
agent1:                 episode reward: 0.6175,                 loss: 0.1416
Episode: 11361/30000 (37.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.6798s / 76283.8933 s
agent0:                 episode reward: -0.4397,                 loss: nan
agent1:                 episode reward: 0.4397,                 loss: 0.1412
Episode: 11381/30000 (37.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8727s / 76418.7660 s
agent0:                 episode reward: -0.3623,                 loss: nan
agent1:                 episode reward: 0.3623,                 loss: 0.1401
Episode: 11401/30000 (38.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.9904s / 76551.7564 s
agent0:                 episode reward: -0.1870,                 loss: nan
agent1:                 episode reward: 0.1870,                 loss: 0.1400
Episode: 11421/30000 (38.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.3288s / 76686.0852 s
agent0:                 episode reward: -0.0360,                 loss: nan
agent1:                 episode reward: 0.0360,                 loss: 0.1411
Episode: 11441/30000 (38.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4624s / 76821.5476 s
agent0:                 episode reward: 0.0200,                 loss: nan
agent1:                 episode reward: -0.0200,                 loss: 0.1411
Episode: 11461/30000 (38.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.8046s / 76957.3523 s
agent0:                 episode reward: -0.7029,                 loss: nan
agent1:                 episode reward: 0.7029,                 loss: 0.1393
Episode: 11481/30000 (38.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.0036s / 77092.3558 s
agent0:                 episode reward: -0.0883,                 loss: nan
agent1:                 episode reward: 0.0883,                 loss: 0.1409
Episode: 11501/30000 (38.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.7350s / 77229.0908 s
agent0:                 episode reward: -0.1121,                 loss: nan
agent1:                 episode reward: 0.1121,                 loss: 0.1413
Episode: 11521/30000 (38.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.1885s / 77362.2793 s
agent0:                 episode reward: -0.3146,                 loss: nan
agent1:                 episode reward: 0.3146,                 loss: 0.1414
Episode: 11541/30000 (38.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0733s / 77498.3526 s
agent0:                 episode reward: -0.5967,                 loss: nan
agent1:                 episode reward: 0.5967,                 loss: 0.1402
Episode: 11561/30000 (38.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1487s / 77632.5013 s
agent0:                 episode reward: -0.3544,                 loss: nan
agent1:                 episode reward: 0.3544,                 loss: 0.1405
Episode: 11581/30000 (38.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.9381s / 77766.4394 s
agent0:                 episode reward: -0.4117,                 loss: nan
agent1:                 episode reward: 0.4117,                 loss: 0.1401
Episode: 11601/30000 (38.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8587s / 77901.2981 s
agent0:                 episode reward: -0.7375,                 loss: nan
agent1:                 episode reward: 0.7375,                 loss: 0.1398
Episode: 11621/30000 (38.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4919s / 78036.7900 s
agent0:                 episode reward: -0.2078,                 loss: nan
agent1:                 episode reward: 0.2078,                 loss: 0.1397
Episode: 11641/30000 (38.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.1005s / 78169.8904 s
agent0:                 episode reward: -0.5171,                 loss: nan
agent1:                 episode reward: 0.5171,                 loss: 0.1406
Episode: 11661/30000 (38.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.6351s / 78303.5256 s
agent0:                 episode reward: -0.5943,                 loss: nan
agent1:                 episode reward: 0.5943,                 loss: 0.1393
Episode: 11681/30000 (38.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.9794s / 78436.5050 s
agent0:                 episode reward: -0.1691,                 loss: nan
agent1:                 episode reward: 0.1691,                 loss: 0.1392
Episode: 11701/30000 (39.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.4134s / 78573.9184 s
agent0:                 episode reward: -0.4683,                 loss: nan
agent1:                 episode reward: 0.4683,                 loss: 0.1406
Episode: 11721/30000 (39.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.5317s / 78709.4501 s
agent0:                 episode reward: -0.6450,                 loss: nan
agent1:                 episode reward: 0.6450,                 loss: 0.1394
Episode: 11741/30000 (39.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0851s / 78845.5353 s
agent0:                 episode reward: -0.3985,                 loss: nan
agent1:                 episode reward: 0.3985,                 loss: 0.1395
Episode: 11761/30000 (39.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7954s / 78981.3306 s
agent0:                 episode reward: -0.6160,                 loss: nan
agent1:                 episode reward: 0.6160,                 loss: 0.1402
Episode: 11781/30000 (39.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 131.9877s / 79113.3184 s
agent0:                 episode reward: -0.5410,                 loss: nan
agent1:                 episode reward: 0.5410,                 loss: 0.1396
Episode: 11801/30000 (39.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8413s / 79248.1597 s
agent0:                 episode reward: -0.6259,                 loss: nan
agent1:                 episode reward: 0.6259,                 loss: 0.1392
Episode: 11821/30000 (39.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0260s / 79382.1856 s
agent0:                 episode reward: -0.5099,                 loss: nan
agent1:                 episode reward: 0.5099,                 loss: 0.1397
Episode: 11841/30000 (39.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.3969s / 79518.5826 s
agent0:                 episode reward: -0.2028,                 loss: nan
agent1:                 episode reward: 0.2028,                 loss: 0.1403
Episode: 11861/30000 (39.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.2384s / 79651.8210 s
agent0:                 episode reward: -0.6854,                 loss: nan
agent1:                 episode reward: 0.6854,                 loss: 0.1413
Episode: 11881/30000 (39.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.5702s / 79787.3911 s
agent0:                 episode reward: -0.6595,                 loss: nan
agent1:                 episode reward: 0.6595,                 loss: 0.1382
Episode: 11901/30000 (39.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.5627s / 79924.9538 s
agent0:                 episode reward: -0.6270,                 loss: nan
agent1:                 episode reward: 0.6270,                 loss: 0.1422
Episode: 11921/30000 (39.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 130.6371s / 80055.5909 s
agent0:                 episode reward: -1.0162,                 loss: nan
agent1:                 episode reward: 1.0162,                 loss: 0.1414
Episode: 11941/30000 (39.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 131.3935s / 80186.9844 s
agent0:                 episode reward: -0.8492,                 loss: nan
agent1:                 episode reward: 0.8492,                 loss: 0.1411
Episode: 11961/30000 (39.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6314s / 80322.6158 s
agent0:                 episode reward: -0.3239,                 loss: nan
agent1:                 episode reward: 0.3239,                 loss: 0.1414
Episode: 11981/30000 (39.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.3286s / 80459.9444 s
agent0:                 episode reward: -0.5658,                 loss: nan
agent1:                 episode reward: 0.5658,                 loss: 0.1435
Episode: 12001/30000 (40.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.5244s / 80596.4688 s
agent0:                 episode reward: -0.3742,                 loss: nan
agent1:                 episode reward: 0.3742,                 loss: 0.1424
Episode: 12021/30000 (40.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.2442s / 80734.7130 s
agent0:                 episode reward: -0.2207,                 loss: nan
agent1:                 episode reward: 0.2207,                 loss: 0.1407
Episode: 12041/30000 (40.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.8199s / 80867.5330 s
agent0:                 episode reward: -0.7839,                 loss: nan
agent1:                 episode reward: 0.7839,                 loss: 0.1411
Episode: 12061/30000 (40.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.0854s / 80999.6183 s
agent0:                 episode reward: -0.4434,                 loss: nan
agent1:                 episode reward: 0.4434,                 loss: 0.1409
Episode: 12081/30000 (40.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.7337s / 81133.3521 s
agent0:                 episode reward: -0.6012,                 loss: nan
agent1:                 episode reward: 0.6012,                 loss: 0.1416
Episode: 12101/30000 (40.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.9390s / 81267.2911 s
agent0:                 episode reward: -0.4685,                 loss: nan
agent1:                 episode reward: 0.4685,                 loss: 0.1422
Episode: 12121/30000 (40.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.3168s / 81400.6078 s
agent0:                 episode reward: -0.3386,                 loss: nan
agent1:                 episode reward: 0.3386,                 loss: 0.1427
Episode: 12141/30000 (40.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.7172s / 81537.3250 s
agent0:                 episode reward: -0.0613,                 loss: nan
agent1:                 episode reward: 0.0613,                 loss: 0.1402
Episode: 12161/30000 (40.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.4099s / 81674.7349 s
agent0:                 episode reward: -0.4754,                 loss: nan
agent1:                 episode reward: 0.4754,                 loss: 0.1404
Episode: 12181/30000 (40.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.3462s / 81813.0812 s
agent0:                 episode reward: -0.0997,                 loss: nan
agent1:                 episode reward: 0.0997,                 loss: 0.1416
Episode: 12201/30000 (40.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 131.6414s / 81944.7225 s
agent0:                 episode reward: -0.2779,                 loss: nan
agent1:                 episode reward: 0.2779,                 loss: 0.1421
Episode: 12221/30000 (40.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.4402s / 82078.1627 s
agent0:                 episode reward: -0.4371,                 loss: nan
agent1:                 episode reward: 0.4371,                 loss: 0.1410
Episode: 12241/30000 (40.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.8583s / 82214.0210 s
agent0:                 episode reward: -0.6038,                 loss: nan
agent1:                 episode reward: 0.6038,                 loss: 0.1425
Episode: 12261/30000 (40.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.0454s / 82349.0664 s
agent0:                 episode reward: -0.1487,                 loss: nan
agent1:                 episode reward: 0.1487,                 loss: 0.1413
Episode: 12281/30000 (40.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6925s / 82484.7589 s
agent0:                 episode reward: -0.3323,                 loss: nan
agent1:                 episode reward: 0.3323,                 loss: 0.1414
Episode: 12301/30000 (41.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.9182s / 82621.6771 s
agent0:                 episode reward: -0.5074,                 loss: nan
agent1:                 episode reward: 0.5074,                 loss: 0.1405
Episode: 12321/30000 (41.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.7080s / 82754.3851 s
agent0:                 episode reward: -0.2167,                 loss: nan
agent1:                 episode reward: 0.2167,                 loss: 0.1428
Episode: 12341/30000 (41.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.7914s / 82887.1765 s
agent0:                 episode reward: -0.3637,                 loss: nan
agent1:                 episode reward: 0.3637,                 loss: 0.1407
Episode: 12361/30000 (41.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6370s / 83021.8135 s
agent0:                 episode reward: -0.1608,                 loss: nan
agent1:                 episode reward: 0.1608,                 loss: 0.1432
Episode: 12381/30000 (41.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.9675s / 83159.7809 s
agent0:                 episode reward: -0.4213,                 loss: nan
agent1:                 episode reward: 0.4213,                 loss: 0.1410
Episode: 12401/30000 (41.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.4781s / 83292.2591 s
agent0:                 episode reward: -0.2859,                 loss: nan
agent1:                 episode reward: 0.2859,                 loss: 0.1417
Episode: 12421/30000 (41.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 131.3458s / 83423.6049 s
agent0:                 episode reward: -0.0864,                 loss: nan
agent1:                 episode reward: 0.0864,                 loss: 0.1423
Episode: 12441/30000 (41.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.1944s / 83560.7993 s
agent0:                 episode reward: -0.8144,                 loss: nan
agent1:                 episode reward: 0.8144,                 loss: 0.1425
Episode: 12461/30000 (41.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.5396s / 83694.3389 s
agent0:                 episode reward: -0.1709,                 loss: nan
agent1:                 episode reward: 0.1709,                 loss: 0.1415
Episode: 12481/30000 (41.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.8994s / 83830.2383 s
agent0:                 episode reward: -0.2138,                 loss: nan
agent1:                 episode reward: 0.2138,                 loss: 0.1407
Episode: 12501/30000 (41.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.5078s / 83962.7461 s
agent0:                 episode reward: -0.2732,                 loss: nan
agent1:                 episode reward: 0.2732,                 loss: 0.1430
Episode: 12521/30000 (41.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.9624s / 84098.7085 s
agent0:                 episode reward: -0.7084,                 loss: nan
agent1:                 episode reward: 0.7084,                 loss: 0.1412
Episode: 12541/30000 (41.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.8596s / 84232.5681 s
agent0:                 episode reward: -0.8721,                 loss: nan
agent1:                 episode reward: 0.8721,                 loss: 0.1417
Episode: 12561/30000 (41.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.7012s / 84370.2693 s
agent0:                 episode reward: -0.3466,                 loss: nan
agent1:                 episode reward: 0.3466,                 loss: 0.1421
Episode: 12581/30000 (41.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.7609s / 84503.0302 s
agent0:                 episode reward: -0.0644,                 loss: nan
agent1:                 episode reward: 0.0644,                 loss: 0.1437
Episode: 12601/30000 (42.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4392s / 84638.4695 s
agent0:                 episode reward: -1.1617,                 loss: nan
agent1:                 episode reward: 1.1617,                 loss: 0.1422
Episode: 12621/30000 (42.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0866s / 84772.5561 s
agent0:                 episode reward: -0.1917,                 loss: nan
agent1:                 episode reward: 0.1917,                 loss: 0.1417
Episode: 12641/30000 (42.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.7826s / 84906.3387 s
agent0:                 episode reward: -0.4320,                 loss: nan
agent1:                 episode reward: 0.4320,                 loss: 0.1437
Episode: 12661/30000 (42.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2360s / 85041.5746 s
agent0:                 episode reward: -0.7258,                 loss: nan
agent1:                 episode reward: 0.7258,                 loss: 0.1417
Episode: 12681/30000 (42.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.9179s / 85177.4925 s
agent0:                 episode reward: -0.5796,                 loss: nan
agent1:                 episode reward: 0.5796,                 loss: 0.1429
Episode: 12701/30000 (42.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.0318s / 85314.5243 s
agent0:                 episode reward: -0.5364,                 loss: nan
agent1:                 episode reward: 0.5364,                 loss: 0.1416
Episode: 12721/30000 (42.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.1898s / 85452.7142 s
agent0:                 episode reward: -0.4679,                 loss: nan
agent1:                 episode reward: 0.4679,                 loss: 0.1437
Episode: 12741/30000 (42.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.5289s / 85589.2430 s
agent0:                 episode reward: -0.6929,                 loss: nan
agent1:                 episode reward: 0.6929,                 loss: 0.1415
Episode: 12761/30000 (42.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9016s / 85724.1446 s
agent0:                 episode reward: -0.7839,                 loss: nan
agent1:                 episode reward: 0.7839,                 loss: 0.1428
Episode: 12781/30000 (42.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.3049s / 85863.4495 s
agent0:                 episode reward: -0.6540,                 loss: nan
agent1:                 episode reward: 0.6540,                 loss: 0.1417
Episode: 12801/30000 (42.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.1480s / 85996.5976 s
agent0:                 episode reward: -0.2067,                 loss: nan
agent1:                 episode reward: 0.2067,                 loss: 0.1436
Episode: 12821/30000 (42.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.6870s / 86130.2845 s
agent0:                 episode reward: -0.6530,                 loss: nan
agent1:                 episode reward: 0.6530,                 loss: 0.1418
Episode: 12841/30000 (42.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.2462s / 86264.5308 s
agent0:                 episode reward: -0.4600,                 loss: nan
agent1:                 episode reward: 0.4600,                 loss: 0.1420
Episode: 12861/30000 (42.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8353s / 86399.3660 s
agent0:                 episode reward: -0.7878,                 loss: nan
agent1:                 episode reward: 0.7878,                 loss: 0.1417
Episode: 12881/30000 (42.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.7616s / 86537.1276 s
agent0:                 episode reward: -0.9263,                 loss: nan
agent1:                 episode reward: 0.9263,                 loss: 0.1416
Episode: 12901/30000 (43.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.7302s / 86670.8578 s
agent0:                 episode reward: -0.8539,                 loss: nan
agent1:                 episode reward: 0.8539,                 loss: 0.1406
Episode: 12921/30000 (43.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.9341s / 86806.7919 s
agent0:                 episode reward: -0.2440,                 loss: nan
agent1:                 episode reward: 0.2440,                 loss: 0.1390
Episode: 12941/30000 (43.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.1523s / 86943.9442 s
agent0:                 episode reward: -0.5026,                 loss: nan
agent1:                 episode reward: 0.5026,                 loss: 0.1397
Episode: 12961/30000 (43.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.1729s / 87080.1171 s
agent0:                 episode reward: -0.9022,                 loss: nan
agent1:                 episode reward: 0.9022,                 loss: 0.1395
Episode: 12981/30000 (43.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.5163s / 87213.6334 s
agent0:                 episode reward: -0.7434,                 loss: nan
agent1:                 episode reward: 0.7434,                 loss: 0.1399
Episode: 13001/30000 (43.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.6158s / 87346.2493 s
agent0:                 episode reward: -0.3508,                 loss: nan
agent1:                 episode reward: 0.3508,                 loss: 0.1401
Episode: 13021/30000 (43.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.0595s / 87483.3088 s
agent0:                 episode reward: 0.0251,                 loss: nan
agent1:                 episode reward: -0.0251,                 loss: 0.1384
Episode: 13041/30000 (43.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0071s / 87619.3159 s
agent0:                 episode reward: -0.4310,                 loss: nan
agent1:                 episode reward: 0.4310,                 loss: 0.1390
Episode: 13061/30000 (43.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6357s / 87754.9516 s
agent0:                 episode reward: -0.6598,                 loss: nan
agent1:                 episode reward: 0.6598,                 loss: 0.1396
Episode: 13081/30000 (43.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1382s / 87889.0898 s
agent0:                 episode reward: -0.1133,                 loss: nan
agent1:                 episode reward: 0.1133,                 loss: 0.1382
Episode: 13101/30000 (43.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 139.4813s / 88028.5711 s
agent0:                 episode reward: -0.3023,                 loss: nan
agent1:                 episode reward: 0.3023,                 loss: 0.1404
Episode: 13121/30000 (43.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.8172s / 88161.3883 s
agent0:                 episode reward: -0.2410,                 loss: nan
agent1:                 episode reward: 0.2410,                 loss: 0.1384
Episode: 13141/30000 (43.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.9637s / 88299.3520 s
agent0:                 episode reward: -0.6228,                 loss: nan
agent1:                 episode reward: 0.6228,                 loss: 0.1385
Episode: 13161/30000 (43.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9673s / 88434.3194 s
agent0:                 episode reward: -0.6978,                 loss: nan
agent1:                 episode reward: 0.6978,                 loss: 0.1393
Episode: 13181/30000 (43.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8123s / 88569.1316 s
agent0:                 episode reward: -0.5252,                 loss: nan
agent1:                 episode reward: 0.5252,                 loss: 0.1385
Episode: 13201/30000 (44.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1557s / 88704.2873 s
agent0:                 episode reward: -0.5708,                 loss: nan
agent1:                 episode reward: 0.5708,                 loss: 0.1395
Episode: 13221/30000 (44.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.4940s / 88838.7814 s
agent0:                 episode reward: -0.4176,                 loss: nan
agent1:                 episode reward: 0.4176,                 loss: 0.1393
Episode: 13241/30000 (44.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5010s / 88973.2824 s
agent0:                 episode reward: -0.2412,                 loss: nan
agent1:                 episode reward: 0.2412,                 loss: 0.1396
Episode: 13261/30000 (44.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.3971s / 89106.6795 s
agent0:                 episode reward: -0.1348,                 loss: nan
agent1:                 episode reward: 0.1348,                 loss: 0.1397
Episode: 13281/30000 (44.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.2275s / 89239.9071 s
agent0:                 episode reward: -0.7885,                 loss: nan
agent1:                 episode reward: 0.7885,                 loss: 0.1390
Episode: 13301/30000 (44.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2716s / 89376.1787 s
agent0:                 episode reward: -0.0983,                 loss: nan
agent1:                 episode reward: 0.0983,                 loss: 0.1393
Episode: 13321/30000 (44.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.7127s / 89512.8914 s
agent0:                 episode reward: -0.3327,                 loss: nan
agent1:                 episode reward: 0.3327,                 loss: 0.1398
Episode: 13341/30000 (44.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.1579s / 89651.0493 s
agent0:                 episode reward: -0.6182,                 loss: nan
agent1:                 episode reward: 0.6182,                 loss: 0.1392
Episode: 13361/30000 (44.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.0906s / 89783.1399 s
agent0:                 episode reward: -0.4195,                 loss: nan
agent1:                 episode reward: 0.4195,                 loss: 0.1398
Episode: 13381/30000 (44.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6680s / 89918.8079 s
agent0:                 episode reward: -0.8294,                 loss: nan
agent1:                 episode reward: 0.8294,                 loss: 0.1393
Episode: 13401/30000 (44.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.1543s / 90054.9622 s
agent0:                 episode reward: -0.2808,                 loss: nan
agent1:                 episode reward: 0.2808,                 loss: 0.1394
Episode: 13421/30000 (44.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.5577s / 90192.5199 s
agent0:                 episode reward: -0.5742,                 loss: nan
agent1:                 episode reward: 0.5742,                 loss: 0.1395
Episode: 13441/30000 (44.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.2406s / 90326.7605 s
agent0:                 episode reward: -0.2857,                 loss: nan
agent1:                 episode reward: 0.2857,                 loss: 0.1390
Episode: 13461/30000 (44.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.0692s / 90463.8298 s
agent0:                 episode reward: -0.2753,                 loss: nan
agent1:                 episode reward: 0.2753,                 loss: 0.1390
Episode: 13481/30000 (44.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.3264s / 90600.1561 s
agent0:                 episode reward: -0.8669,                 loss: nan
agent1:                 episode reward: 0.8669,                 loss: 0.1380
Episode: 13501/30000 (45.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.2512s / 90737.4074 s