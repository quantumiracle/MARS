/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/pettingzoo/utils/conversions.py:87: UserWarning: The `observation_spaces` dictionary is deprecated. Use the `observation_space` function instead.
  "The `observation_spaces` dictionary is deprecated. Use the `observation_space` function instead."
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/pettingzoo/utils/conversions.py:101: UserWarning: The `action_spaces` dictionary is deprecated. Use the `action_space` function instead.
  "The `action_spaces` dictionary is deprecated. Use the `action_space` function instead."
pettingzoo_boxing_v2
default:  {'env_name': 'boxing_v2', 'env_type': 'pettingzoo', 'num_envs': 5, 'ram': True, 'seed': 'random', 'record_video': False, 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'save_id': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'wandb_activate': False, 'wandb_entity': '', 'wandb_project': '', 'wandb_group': '', 'wandb_name': '', 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'fictitious_selfplay', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'selfplay_score_delta': 80, 'trainable_agent_idx': 0, 'opponent_idx': 1}}
{'env_name': 'boxing_v2', 'env_type': 'pettingzoo', 'num_envs': 5, 'ram': True, 'seed': 'random', 'record_video': False, 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'save_id': 202209252250, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'wandb_activate': False, 'wandb_entity': '', 'wandb_project': '', 'wandb_group': '', 'wandb_name': '', 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'fictitious_selfplay', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'selfplay_score_delta': 80, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'load_id': 202209201541, 'to_exploit': 'second_2'}
boxing_v2 pettingzoo
record video: interval 100, length 300
Load boxing_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
random seed: 129
<mars.env.wrappers.mars_wrappers.Dict2TupleWrapper object at 0x7efd03f23da0>
discrete_policy 18 Discrete(18)
Traceback (most recent call last):
  File "general_exploit.py", line 48, in <module>
    launch()
  File "general_exploit.py", line 30, in launch
    trained_model = eval(args.algorithm)(env, args)
  File "/data/zihan/research/MARS/mars/rl/agents/dqn.py", line 19, in __init__
    self._init_model(env, args)
  File "/data/zihan/research/MARS/mars/rl/agents/dqn.py", line 38, in _init_model
    self.model = self._select_type(env, args).to(self.device)
  File "/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/pettingzoo/utils/conversions.py:87: UserWarning: The `observation_spaces` dictionary is deprecated. Use the `observation_space` function instead.
  "The `observation_spaces` dictionary is deprecated. Use the `observation_space` function instead."
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/pettingzoo/utils/conversions.py:101: UserWarning: The `action_spaces` dictionary is deprecated. Use the `action_space` function instead.
  "The `action_spaces` dictionary is deprecated. Use the `action_space` function instead."
pettingzoo_boxing_v2
default:  {'env_name': 'boxing_v2', 'env_type': 'pettingzoo', 'num_envs': 5, 'ram': True, 'seed': 'random', 'record_video': False, 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'save_id': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'wandb_activate': False, 'wandb_entity': '', 'wandb_project': '', 'wandb_group': '', 'wandb_name': '', 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'fictitious_selfplay', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'selfplay_score_delta': 80, 'trainable_agent_idx': 0, 'opponent_idx': 1}}
{'env_name': 'boxing_v2', 'env_type': 'pettingzoo', 'num_envs': 5, 'ram': True, 'seed': 'random', 'record_video': False, 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'save_id': 202209270006, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'wandb_activate': False, 'wandb_entity': '', 'wandb_project': '', 'wandb_group': '', 'wandb_name': '', 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'fictitious_selfplay', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'selfplay_score_delta': 80, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'load_id': 202209201541, 'to_exploit': 'second_2'}
boxing_v2 pettingzoo
record video: interval 100, length 300
Load boxing_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
random seed: 74
<mars.env.wrappers.mars_wrappers.Dict2TupleWrapper object at 0x7f9ecd01dd68>
discrete_policy 18 Discrete(18)
Traceback (most recent call last):
  File "general_exploit.py", line 48, in <module>
    launch()
  File "general_exploit.py", line 30, in launch
    trained_model = eval(args.algorithm)(env, args)
  File "/data/zihan/research/MARS/mars/rl/agents/dqn.py", line 19, in __init__
    self._init_model(env, args)
  File "/data/zihan/research/MARS/mars/rl/agents/dqn.py", line 38, in _init_model
    self.model = self._select_type(env, args).to(self.device)
  File "/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
pettingzoo_boxing_v2
default:  {'env_name': 'boxing_v2', 'env_type': 'pettingzoo', 'num_envs': 5, 'ram': True, 'seed': 'random', 'record_video': False, 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'save_id': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'wandb_activate': False, 'wandb_entity': '', 'wandb_project': '', 'wandb_group': '', 'wandb_name': '', 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'fictitious_selfplay', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'selfplay_score_delta': 80, 'trainable_agent_idx': 0, 'opponent_idx': 1}}
{'env_name': 'boxing_v2', 'env_type': 'pettingzoo', 'num_envs': 5, 'ram': True, 'seed': 'random', 'record_video': False, 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'save_id': 202209270240, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'wandb_activate': False, 'wandb_entity': '', 'wandb_project': '', 'wandb_group': '', 'wandb_name': '', 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'fictitious_selfplay', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'selfplay_score_delta': 80, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'load_id': 202209201541, 'to_exploit': 'second_2'}
boxing_v2 pettingzoo
record video: interval 100, length 300
Load boxing_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
random seed: 873
<mars.env.wrappers.mars_wrappers.Dict2TupleWrapper object at 0x7efdb7db0d68>
discrete_policy 18 Discrete(18)
discrete_policy 18 Discrete(18)
discrete_policy 18 Discrete(18)
Agents No. [0] (index starting from 0) are not learnable.
Load meta strategy:  [[0.036 0.036 0.036 ... 0.036 0.036 0.036]
 [0.036 0.036 0.036 ... 0.036 0.036 0.036]]
Load checkpoints (policy family):  [['322' '2135' '2192' ... '7012' '7564' '7675']
 ['607' '2156' '2354' ... '7269' '7592' '7704']]
Arguments:  {'env_name': 'boxing_v2', 'env_type': 'pettingzoo', 'num_envs': 1, 'ram': True, 'seed': 'random', 'record_video': False, 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'save_id': 202209270240, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': './data/model/202209201541/pettingzoo_boxing_v2_fictitious_selfplay/', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'wandb_activate': False, 'wandb_entity': '', 'wandb_project': '', 'wandb_group': '', 'wandb_name': '', 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'fictitious_selfplay', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'selfplay_score_delta': 80, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'load_id': 202209201541, 'to_exploit': 'second_2', 'against_baseline': False, 'idx_exploited_model': 0}
Save models to : /data/zihan/research/MARS/data/model/202209201541_exploit_first/pettingzoo_boxing_v2_fictitious_selfplay. 
 Save logs to: /data/zihan/research/MARS/data/log/202209201541_exploit_first/pettingzoo_boxing_v2_fictitious_selfplay.
Episode: 1/10000 (0.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 5.78s / 5.78 s
first_0:                 episode reward: -1.0000,                 loss: nan
second_0:                 episode reward: 1.0000,                 loss: 0.9448
Episode: 21/10000 (0.2100%),                 avg. length: 269.95,                last time consumption/overall running time: 119.90s / 125.69 s
first_0:                 episode reward: 68.6000,                 loss: nan
second_0:                 episode reward: -68.6000,                 loss: 0.2868
Episode: 41/10000 (0.4100%),                 avg. length: 274.2,                last time consumption/overall running time: 125.18s / 250.86 s
first_0:                 episode reward: 70.5500,                 loss: nan
second_0:                 episode reward: -70.5500,                 loss: 0.1041
Episode: 61/10000 (0.6100%),                 avg. length: 283.55,                last time consumption/overall running time: 130.00s / 380.86 s
first_0:                 episode reward: 50.1000,                 loss: nan
second_0:                 episode reward: -50.1000,                 loss: 0.0939
Episode: 81/10000 (0.8100%),                 avg. length: 286.55,                last time consumption/overall running time: 132.53s / 513.39 s
first_0:                 episode reward: 48.4500,                 loss: nan
second_0:                 episode reward: -48.4500,                 loss: 0.0873
Episode: 101/10000 (1.0100%),                 avg. length: 279.3,                last time consumption/overall running time: 130.07s / 643.46 s
first_0:                 episode reward: 50.6000,                 loss: nan
second_0:                 episode reward: -50.6000,                 loss: 0.0862
Episode: 121/10000 (1.2100%),                 avg. length: 281.85,                last time consumption/overall running time: 132.25s / 775.71 s
first_0:                 episode reward: 52.6000,                 loss: nan
second_0:                 episode reward: -52.6000,                 loss: 0.0876
Episode: 141/10000 (1.4100%),                 avg. length: 285.0,                last time consumption/overall running time: 134.81s / 910.51 s
first_0:                 episode reward: 35.8000,                 loss: nan
second_0:                 episode reward: -35.8000,                 loss: 0.0840
Episode: 161/10000 (1.6100%),                 avg. length: 285.75,                last time consumption/overall running time: 135.42s / 1045.94 s
first_0:                 episode reward: 51.8500,                 loss: nan
second_0:                 episode reward: -51.8500,                 loss: 0.0798
Episode: 181/10000 (1.8100%),                 avg. length: 286.9,                last time consumption/overall running time: 136.63s / 1182.56 s
first_0:                 episode reward: 55.0000,                 loss: nan
second_0:                 episode reward: -55.0000,                 loss: 0.0833
Episode: 201/10000 (2.0100%),                 avg. length: 292.0,                last time consumption/overall running time: 139.26s / 1321.82 s
first_0:                 episode reward: 23.3500,                 loss: nan
second_0:                 episode reward: -23.3500,                 loss: 0.0857
Episode: 221/10000 (2.2100%),                 avg. length: 295.3,                last time consumption/overall running time: 140.67s / 1462.49 s
first_0:                 episode reward: 22.9000,                 loss: nan
second_0:                 episode reward: -22.9000,                 loss: 0.0834
Episode: 241/10000 (2.4100%),                 avg. length: 294.1,                last time consumption/overall running time: 140.76s / 1603.25 s
first_0:                 episode reward: 29.9000,                 loss: nan
second_0:                 episode reward: -29.9000,                 loss: 0.0821
Episode: 261/10000 (2.6100%),                 avg. length: 282.15,                last time consumption/overall running time: 136.00s / 1739.25 s
first_0:                 episode reward: 38.5000,                 loss: nan
second_0:                 episode reward: -38.5000,                 loss: 0.0819
Episode: 281/10000 (2.8100%),                 avg. length: 289.15,                last time consumption/overall running time: 139.39s / 1878.64 s
first_0:                 episode reward: 32.6000,                 loss: nan
second_0:                 episode reward: -32.6000,                 loss: 0.0835
Episode: 301/10000 (3.0100%),                 avg. length: 295.9,                last time consumption/overall running time: 142.28s / 2020.92 s
first_0:                 episode reward: 28.7000,                 loss: nan
second_0:                 episode reward: -28.7000,                 loss: 0.0836
Episode: 321/10000 (3.2100%),                 avg. length: 289.3,                last time consumption/overall running time: 140.68s / 2161.60 s
first_0:                 episode reward: 33.6500,                 loss: nan
second_0:                 episode reward: -33.6500,                 loss: 0.0824
Episode: 341/10000 (3.4100%),                 avg. length: 290.9,                last time consumption/overall running time: 142.48s / 2304.08 s
first_0:                 episode reward: 38.3000,                 loss: nan
second_0:                 episode reward: -38.3000,                 loss: 0.0821
Episode: 361/10000 (3.6100%),                 avg. length: 294.75,                last time consumption/overall running time: 144.50s / 2448.58 s
first_0:                 episode reward: 25.8500,                 loss: nan
second_0:                 episode reward: -25.8500,                 loss: 0.0805
Episode: 381/10000 (3.8100%),                 avg. length: 285.45,                last time consumption/overall running time: 139.77s / 2588.35 s
first_0:                 episode reward: 39.5000,                 loss: nan
second_0:                 episode reward: -39.5000,                 loss: 0.0832
Episode: 401/10000 (4.0100%),                 avg. length: 296.2,                last time consumption/overall running time: 145.65s / 2734.00 s
first_0:                 episode reward: 20.5500,                 loss: nan
second_0:                 episode reward: -20.5500,                 loss: 0.0828
Episode: 421/10000 (4.2100%),                 avg. length: 291.6,                last time consumption/overall running time: 143.15s / 2877.15 s
first_0:                 episode reward: 36.4000,                 loss: nan
second_0:                 episode reward: -36.4000,                 loss: 0.0866
Episode: 441/10000 (4.4100%),                 avg. length: 290.95,                last time consumption/overall running time: 143.45s / 3020.60 s
first_0:                 episode reward: 41.4000,                 loss: nan
second_0:                 episode reward: -41.4000,                 loss: 0.0874
Episode: 461/10000 (4.6100%),                 avg. length: 291.15,                last time consumption/overall running time: 142.79s / 3163.40 s
first_0:                 episode reward: 34.0500,                 loss: nan
second_0:                 episode reward: -34.0500,                 loss: 0.0842
Episode: 481/10000 (4.8100%),                 avg. length: 281.3,                last time consumption/overall running time: 139.36s / 3302.76 s
first_0:                 episode reward: 39.1500,                 loss: nan
second_0:                 episode reward: -39.1500,                 loss: 0.0847
Episode: 501/10000 (5.0100%),                 avg. length: 291.95,                last time consumption/overall running time: 143.48s / 3446.24 s
first_0:                 episode reward: 28.5000,                 loss: nan
second_0:                 episode reward: -28.5000,                 loss: 0.0860
Episode: 521/10000 (5.2100%),                 avg. length: 291.45,                last time consumption/overall running time: 144.51s / 3590.74 s
first_0:                 episode reward: 27.5500,                 loss: nan
second_0:                 episode reward: -27.5500,                 loss: 0.0863
Episode: 541/10000 (5.4100%),                 avg. length: 296.0,                last time consumption/overall running time: 147.07s / 3737.82 s
first_0:                 episode reward: 11.9000,                 loss: nan
second_0:                 episode reward: -11.9000,                 loss: 0.0861
Episode: 561/10000 (5.6100%),                 avg. length: 295.2,                last time consumption/overall running time: 145.75s / 3883.56 s
first_0:                 episode reward: 22.0000,                 loss: nan
second_0:                 episode reward: -22.0000,                 loss: 0.0879
Episode: 581/10000 (5.8100%),                 avg. length: 295.6,                last time consumption/overall running time: 146.69s / 4030.26 s
first_0:                 episode reward: 14.6500,                 loss: nan
second_0:                 episode reward: -14.6500,                 loss: 0.0877
Episode: 601/10000 (6.0100%),                 avg. length: 297.6,                last time consumption/overall running time: 147.87s / 4178.13 s
first_0:                 episode reward: 15.4000,                 loss: nan
second_0:                 episode reward: -15.4000,                 loss: 0.0841
Episode: 621/10000 (6.2100%),                 avg. length: 292.85,                last time consumption/overall running time: 144.90s / 4323.03 s
first_0:                 episode reward: 27.2000,                 loss: nan
second_0:                 episode reward: -27.2000,                 loss: 0.0876
Episode: 641/10000 (6.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 148.23s / 4471.26 s
first_0:                 episode reward: 9.4500,                 loss: nan
second_0:                 episode reward: -9.4500,                 loss: 0.0855
Episode: 661/10000 (6.6100%),                 avg. length: 295.05,                last time consumption/overall running time: 147.23s / 4618.49 s
first_0:                 episode reward: 17.5500,                 loss: nan
second_0:                 episode reward: -17.5500,                 loss: 0.0853
Episode: 681/10000 (6.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 148.73s / 4767.22 s
first_0:                 episode reward: 15.7000,                 loss: nan
second_0:                 episode reward: -15.7000,                 loss: 0.0827
Episode: 701/10000 (7.0100%),                 avg. length: 296.05,                last time consumption/overall running time: 147.73s / 4914.95 s
first_0:                 episode reward: 21.9500,                 loss: nan
second_0:                 episode reward: -21.9500,                 loss: 0.0862
Episode: 721/10000 (7.2100%),                 avg. length: 296.2,                last time consumption/overall running time: 148.54s / 5063.49 s
first_0:                 episode reward: 27.8000,                 loss: nan
second_0:                 episode reward: -27.8000,                 loss: 0.0842
Episode: 741/10000 (7.4100%),                 avg. length: 287.9,                last time consumption/overall running time: 143.87s / 5207.36 s
first_0:                 episode reward: 33.2000,                 loss: nan
second_0:                 episode reward: -33.2000,                 loss: 0.0844
Episode: 761/10000 (7.6100%),                 avg. length: 295.25,                last time consumption/overall running time: 148.58s / 5355.93 s
first_0:                 episode reward: 31.2500,                 loss: nan
second_0:                 episode reward: -31.2500,                 loss: 0.0833
Episode: 781/10000 (7.8100%),                 avg. length: 290.6,                last time consumption/overall running time: 145.52s / 5501.45 s
first_0:                 episode reward: 23.4500,                 loss: nan
second_0:                 episode reward: -23.4500,                 loss: 0.0836
Episode: 801/10000 (8.0100%),                 avg. length: 290.75,                last time consumption/overall running time: 146.93s / 5648.38 s
first_0:                 episode reward: 24.6500,                 loss: nan
second_0:                 episode reward: -24.6500,                 loss: 0.0819
Episode: 821/10000 (8.2100%),                 avg. length: 293.9,                last time consumption/overall running time: 146.97s / 5795.35 s
first_0:                 episode reward: 24.8500,                 loss: nan
second_0:                 episode reward: -24.8500,                 loss: 0.0783
Episode: 841/10000 (8.4100%),                 avg. length: 293.65,                last time consumption/overall running time: 147.62s / 5942.97 s
first_0:                 episode reward: 19.2000,                 loss: nan
second_0:                 episode reward: -19.2000,                 loss: 0.0788
Episode: 861/10000 (8.6100%),                 avg. length: 292.25,                last time consumption/overall running time: 147.46s / 6090.43 s
first_0:                 episode reward: 17.4500,                 loss: nan
second_0:                 episode reward: -17.4500,                 loss: 0.0795
Episode: 881/10000 (8.8100%),                 avg. length: 294.5,                last time consumption/overall running time: 147.52s / 6237.95 s
first_0:                 episode reward: 21.4000,                 loss: nan
second_0:                 episode reward: -21.4000,                 loss: 0.0767
Episode: 901/10000 (9.0100%),                 avg. length: 291.25,                last time consumption/overall running time: 148.08s / 6386.04 s
first_0:                 episode reward: 19.2000,                 loss: nan
second_0:                 episode reward: -19.2000,                 loss: 0.0769
Episode: 921/10000 (9.2100%),                 avg. length: 291.8,                last time consumption/overall running time: 149.85s / 6535.89 s
first_0:                 episode reward: 21.9000,                 loss: nan
second_0:                 episode reward: -21.9000,                 loss: 0.0764
Episode: 941/10000 (9.4100%),                 avg. length: 293.2,                last time consumption/overall running time: 150.19s / 6686.07 s
first_0:                 episode reward: 18.7000,                 loss: nan
second_0:                 episode reward: -18.7000,                 loss: 0.0718
Episode: 961/10000 (9.6100%),                 avg. length: 298.95,                last time consumption/overall running time: 151.26s / 6837.33 s
first_0:                 episode reward: 6.0000,                 loss: nan
second_0:                 episode reward: -6.0000,                 loss: 0.0723
Episode: 981/10000 (9.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 152.53s / 6989.86 s
first_0:                 episode reward: 10.7000,                 loss: nan
second_0:                 episode reward: -10.7000,                 loss: 0.0728
Episode: 1001/10000 (10.0100%),                 avg. length: 291.7,                last time consumption/overall running time: 149.14s / 7139.00 s
first_0:                 episode reward: 11.1500,                 loss: nan
second_0:                 episode reward: -11.1500,                 loss: 0.0729
Episode: 1021/10000 (10.2100%),                 avg. length: 297.85,                last time consumption/overall running time: 151.58s / 7290.58 s
first_0:                 episode reward: 11.4500,                 loss: nan
second_0:                 episode reward: -11.4500,                 loss: 0.0726
Episode: 1041/10000 (10.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 151.48s / 7442.06 s
first_0:                 episode reward: 12.1000,                 loss: nan
second_0:                 episode reward: -12.1000,                 loss: 0.0759
Episode: 1061/10000 (10.6100%),                 avg. length: 287.05,                last time consumption/overall running time: 146.41s / 7588.47 s
first_0:                 episode reward: 19.8500,                 loss: nan
second_0:                 episode reward: -19.8500,                 loss: 0.0752
Episode: 1081/10000 (10.8100%),                 avg. length: 296.95,                last time consumption/overall running time: 153.17s / 7741.64 s
first_0:                 episode reward: 14.3500,                 loss: nan
second_0:                 episode reward: -14.3500,                 loss: 0.0718
Episode: 1101/10000 (11.0100%),                 avg. length: 295.1,                last time consumption/overall running time: 150.45s / 7892.08 s
first_0:                 episode reward: 20.3000,                 loss: nan
second_0:                 episode reward: -20.3000,                 loss: 0.0766
Episode: 1121/10000 (11.2100%),                 avg. length: 290.0,                last time consumption/overall running time: 147.98s / 8040.07 s
first_0:                 episode reward: 19.0000,                 loss: nan
second_0:                 episode reward: -19.0000,                 loss: 0.0761
Episode: 1141/10000 (11.4100%),                 avg. length: 294.9,                last time consumption/overall running time: 149.58s / 8189.64 s
first_0:                 episode reward: 24.5500,                 loss: nan
second_0:                 episode reward: -24.5500,                 loss: 0.0776
Episode: 1161/10000 (11.6100%),                 avg. length: 296.0,                last time consumption/overall running time: 151.93s / 8341.57 s
first_0:                 episode reward: 11.0000,                 loss: nan
second_0:                 episode reward: -11.0000,                 loss: 0.0785
Episode: 1181/10000 (11.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 152.84s / 8494.40 s
first_0:                 episode reward: 14.9500,                 loss: nan
second_0:                 episode reward: -14.9500,                 loss: 0.0837
Episode: 1201/10000 (12.0100%),                 avg. length: 293.85,                last time consumption/overall running time: 150.05s / 8644.45 s
first_0:                 episode reward: 26.2500,                 loss: nan
second_0:                 episode reward: -26.2500,                 loss: 0.0810
Episode: 1221/10000 (12.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 152.98s / 8797.43 s
first_0:                 episode reward: 9.7500,                 loss: nan
second_0:                 episode reward: -9.7500,                 loss: 0.0783
Episode: 1241/10000 (12.4100%),                 avg. length: 296.15,                last time consumption/overall running time: 151.42s / 8948.85 s
first_0:                 episode reward: 13.4000,                 loss: nan
second_0:                 episode reward: -13.4000,                 loss: 0.0791
Episode: 1261/10000 (12.6100%),                 avg. length: 295.85,                last time consumption/overall running time: 152.15s / 9101.00 s
first_0:                 episode reward: 10.2500,                 loss: nan
second_0:                 episode reward: -10.2500,                 loss: 0.0824
Episode: 1281/10000 (12.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 153.98s / 9254.98 s
first_0:                 episode reward: 2.9500,                 loss: nan
second_0:                 episode reward: -2.9500,                 loss: 0.0839
Episode: 1301/10000 (13.0100%),                 avg. length: 290.95,                last time consumption/overall running time: 149.25s / 9404.23 s
first_0:                 episode reward: 10.0500,                 loss: nan
second_0:                 episode reward: -10.0500,                 loss: 0.0830
Episode: 1321/10000 (13.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 152.34s / 9556.57 s
first_0:                 episode reward: -2.2500,                 loss: nan
second_0:                 episode reward: 2.2500,                 loss: 0.0868
Episode: 1341/10000 (13.4100%),                 avg. length: 296.1,                last time consumption/overall running time: 151.97s / 9708.55 s
first_0:                 episode reward: 10.5000,                 loss: nan
second_0:                 episode reward: -10.5000,                 loss: 0.0857
Episode: 1361/10000 (13.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 152.13s / 9860.68 s
first_0:                 episode reward: 7.5500,                 loss: nan
second_0:                 episode reward: -7.5500,                 loss: 0.0848
Episode: 1381/10000 (13.8100%),                 avg. length: 294.85,                last time consumption/overall running time: 151.19s / 10011.87 s
first_0:                 episode reward: 12.3500,                 loss: nan
second_0:                 episode reward: -12.3500,                 loss: 0.0867
Episode: 1401/10000 (14.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 152.72s / 10164.59 s
first_0:                 episode reward: -3.0500,                 loss: nan
second_0:                 episode reward: 3.0500,                 loss: 0.0864
Episode: 1421/10000 (14.2100%),                 avg. length: 294.8,                last time consumption/overall running time: 150.21s / 10314.80 s
first_0:                 episode reward: 5.2500,                 loss: nan
second_0:                 episode reward: -5.2500,                 loss: 0.0883
Episode: 1441/10000 (14.4100%),                 avg. length: 294.55,                last time consumption/overall running time: 151.01s / 10465.81 s
first_0:                 episode reward: 10.0500,                 loss: nan
second_0:                 episode reward: -10.0500,                 loss: 0.0933
Episode: 1461/10000 (14.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 152.78s / 10618.59 s
first_0:                 episode reward: -5.7000,                 loss: nan
second_0:                 episode reward: 5.7000,                 loss: 0.0963
Episode: 1481/10000 (14.8100%),                 avg. length: 297.95,                last time consumption/overall running time: 152.64s / 10771.23 s
first_0:                 episode reward: 6.2000,                 loss: nan
second_0:                 episode reward: -6.2000,                 loss: 0.0978
Episode: 1501/10000 (15.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 152.80s / 10924.02 s
first_0:                 episode reward: 0.4500,                 loss: nan
second_0:                 episode reward: -0.4500,                 loss: 0.1036
Episode: 1521/10000 (15.2100%),                 avg. length: 291.2,                last time consumption/overall running time: 149.24s / 11073.27 s
first_0:                 episode reward: 6.1000,                 loss: nan
second_0:                 episode reward: -6.1000,                 loss: 0.1029
Episode: 1541/10000 (15.4100%),                 avg. length: 297.05,                last time consumption/overall running time: 151.23s / 11224.50 s
first_0:                 episode reward: -6.4500,                 loss: nan
second_0:                 episode reward: 6.4500,                 loss: 0.1059
Episode: 1561/10000 (15.6100%),                 avg. length: 298.95,                last time consumption/overall running time: 153.02s / 11377.52 s
first_0:                 episode reward: 6.1500,                 loss: nan
second_0:                 episode reward: -6.1500,                 loss: 0.1086
Episode: 1581/10000 (15.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 153.23s / 11530.75 s
first_0:                 episode reward: -15.6000,                 loss: nan
second_0:                 episode reward: 15.6000,                 loss: 0.1096
Episode: 1601/10000 (16.0100%),                 avg. length: 295.15,                last time consumption/overall running time: 152.19s / 11682.94 s
first_0:                 episode reward: -11.1500,                 loss: nan
second_0:                 episode reward: 11.1500,                 loss: 0.1101
Episode: 1621/10000 (16.2100%),                 avg. length: 294.75,                last time consumption/overall running time: 150.53s / 11833.47 s
first_0:                 episode reward: -19.6500,                 loss: nan
second_0:                 episode reward: 19.6500,                 loss: 0.1103
Episode: 1641/10000 (16.4100%),                 avg. length: 290.95,                last time consumption/overall running time: 148.24s / 11981.70 s
first_0:                 episode reward: -10.6500,                 loss: nan
second_0:                 episode reward: 10.6500,                 loss: 0.1104
Episode: 1661/10000 (16.6100%),                 avg. length: 295.95,                last time consumption/overall running time: 151.93s / 12133.63 s
first_0:                 episode reward: -27.2500,                 loss: nan
second_0:                 episode reward: 27.2500,                 loss: 0.1062
Episode: 1681/10000 (16.8100%),                 avg. length: 294.2,                last time consumption/overall running time: 151.03s / 12284.66 s
first_0:                 episode reward: -16.4000,                 loss: nan
second_0:                 episode reward: 16.4000,                 loss: 0.1096
Episode: 1701/10000 (17.0100%),                 avg. length: 297.95,                last time consumption/overall running time: 152.93s / 12437.59 s
first_0:                 episode reward: -42.1500,                 loss: nan
second_0:                 episode reward: 42.1500,                 loss: 0.1097
Episode: 1721/10000 (17.2100%),                 avg. length: 297.0,                last time consumption/overall running time: 152.08s / 12589.66 s
first_0:                 episode reward: -48.8500,                 loss: nan
second_0:                 episode reward: 48.8500,                 loss: 0.1125
Episode: 1741/10000 (17.4100%),                 avg. length: 296.6,                last time consumption/overall running time: 151.26s / 12740.93 s
first_0:                 episode reward: -51.5000,                 loss: nan
second_0:                 episode reward: 51.5000,                 loss: 0.1069
Episode: 1761/10000 (17.6100%),                 avg. length: 290.5,                last time consumption/overall running time: 148.30s / 12889.22 s
first_0:                 episode reward: -23.9500,                 loss: nan
second_0:                 episode reward: 23.9500,                 loss: 0.1038
Episode: 1781/10000 (17.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 152.65s / 13041.87 s
first_0:                 episode reward: -40.1000,                 loss: nan
second_0:                 episode reward: 40.1000,                 loss: 0.1042
Episode: 1801/10000 (18.0100%),                 avg. length: 287.8,                last time consumption/overall running time: 147.10s / 13188.98 s
first_0:                 episode reward: -50.9000,                 loss: nan
second_0:                 episode reward: 50.9000,                 loss: 0.1003
Episode: 1821/10000 (18.2100%),                 avg. length: 276.0,                last time consumption/overall running time: 141.19s / 13330.17 s
first_0:                 episode reward: -59.3500,                 loss: nan
second_0:                 episode reward: 59.3500,                 loss: 0.0975
Episode: 1841/10000 (18.4100%),                 avg. length: 277.4,                last time consumption/overall running time: 141.73s / 13471.90 s
first_0:                 episode reward: -78.7500,                 loss: nan
second_0:                 episode reward: 78.7500,                 loss: 0.0921
Episode: 1861/10000 (18.6100%),                 avg. length: 268.35,                last time consumption/overall running time: 136.92s / 13608.82 s
first_0:                 episode reward: -57.6000,                 loss: nan
second_0:                 episode reward: 57.6000,                 loss: 0.0880
Episode: 1881/10000 (18.8100%),                 avg. length: 267.9,                last time consumption/overall running time: 138.05s / 13746.87 s
first_0:                 episode reward: -83.7000,                 loss: nan
second_0:                 episode reward: 83.7000,                 loss: 0.0848
Episode: 1901/10000 (19.0100%),                 avg. length: 259.6,                last time consumption/overall running time: 132.10s / 13878.98 s
first_0:                 episode reward: -84.6000,                 loss: nan
second_0:                 episode reward: 84.6000,                 loss: 0.0808
Episode: 1921/10000 (19.2100%),                 avg. length: 270.0,                last time consumption/overall running time: 138.76s / 14017.74 s
first_0:                 episode reward: -64.2500,                 loss: nan
second_0:                 episode reward: 64.2500,                 loss: 0.0767
Episode: 1941/10000 (19.4100%),                 avg. length: 258.45,                last time consumption/overall running time: 132.28s / 14150.02 s
first_0:                 episode reward: -81.3500,                 loss: nan
second_0:                 episode reward: 81.3500,                 loss: 0.0730
Episode: 1961/10000 (19.6100%),                 avg. length: 261.5,                last time consumption/overall running time: 133.57s / 14283.59 s
first_0:                 episode reward: -59.8000,                 loss: nan
second_0:                 episode reward: 59.8000,                 loss: 0.0691
Episode: 1981/10000 (19.8100%),                 avg. length: 269.7,                last time consumption/overall running time: 137.84s / 14421.43 s
first_0:                 episode reward: -62.5500,                 loss: nan
second_0:                 episode reward: 62.5500,                 loss: 0.0645
Episode: 2001/10000 (20.0100%),                 avg. length: 248.05,                last time consumption/overall running time: 128.54s / 14549.96 s
first_0:                 episode reward: -88.0000,                 loss: nan
second_0:                 episode reward: 88.0000,                 loss: 0.0616
Episode: 2021/10000 (20.2100%),                 avg. length: 257.35,                last time consumption/overall running time: 131.84s / 14681.81 s
first_0:                 episode reward: -79.9500,                 loss: nan
second_0:                 episode reward: 79.9500,                 loss: 0.0586
Episode: 2041/10000 (20.4100%),                 avg. length: 253.3,                last time consumption/overall running time: 130.93s / 14812.73 s
first_0:                 episode reward: -85.0500,                 loss: nan
second_0:                 episode reward: 85.0500,                 loss: 0.0553
Episode: 2061/10000 (20.6100%),                 avg. length: 263.8,                last time consumption/overall running time: 135.83s / 14948.56 s
first_0:                 episode reward: -69.1500,                 loss: nan
second_0:                 episode reward: 69.1500,                 loss: 0.0522
Episode: 2081/10000 (20.8100%),                 avg. length: 268.25,                last time consumption/overall running time: 137.10s / 15085.66 s
first_0:                 episode reward: -72.2500,                 loss: nan
second_0:                 episode reward: 72.2500,                 loss: 0.0488
Episode: 2101/10000 (21.0100%),                 avg. length: 255.6,                last time consumption/overall running time: 131.63s / 15217.30 s
first_0:                 episode reward: -90.9500,                 loss: nan
second_0:                 episode reward: 90.9500,                 loss: 0.0477
Episode: 2121/10000 (21.2100%),                 avg. length: 264.05,                last time consumption/overall running time: 136.05s / 15353.34 s
first_0:                 episode reward: -79.8000,                 loss: nan
second_0:                 episode reward: 79.8000,                 loss: 0.0466
Episode: 2141/10000 (21.4100%),                 avg. length: 269.55,                last time consumption/overall running time: 137.74s / 15491.08 s
first_0:                 episode reward: -49.0500,                 loss: nan
second_0:                 episode reward: 49.0500,                 loss: 0.0452
Episode: 2161/10000 (21.6100%),                 avg. length: 246.5,                last time consumption/overall running time: 127.38s / 15618.46 s
first_0:                 episode reward: -88.6500,                 loss: nan
second_0:                 episode reward: 88.6500,                 loss: 0.0427
Episode: 2181/10000 (21.8100%),                 avg. length: 261.1,                last time consumption/overall running time: 133.58s / 15752.04 s
first_0:                 episode reward: -55.1500,                 loss: nan
second_0:                 episode reward: 55.1500,                 loss: 0.0399
Episode: 2201/10000 (22.0100%),                 avg. length: 248.55,                last time consumption/overall running time: 127.09s / 15879.13 s
first_0:                 episode reward: -77.7000,                 loss: nan
second_0:                 episode reward: 77.7000,                 loss: 0.0391
Episode: 2221/10000 (22.2100%),                 avg. length: 254.0,                last time consumption/overall running time: 130.89s / 16010.02 s
first_0:                 episode reward: -71.6000,                 loss: nan
second_0:                 episode reward: 71.6000,                 loss: 0.0376
Episode: 2241/10000 (22.4100%),                 avg. length: 255.5,                last time consumption/overall running time: 130.95s / 16140.97 s
first_0:                 episode reward: -67.9500,                 loss: nan
second_0:                 episode reward: 67.9500,                 loss: 0.0366
Episode: 2261/10000 (22.6100%),                 avg. length: 250.45,                last time consumption/overall running time: 128.28s / 16269.25 s
first_0:                 episode reward: -80.0500,                 loss: nan
second_0:                 episode reward: 80.0500,                 loss: 0.0365
Episode: 2281/10000 (22.8100%),                 avg. length: 250.9,                last time consumption/overall running time: 128.61s / 16397.87 s
first_0:                 episode reward: -86.1000,                 loss: nan
second_0:                 episode reward: 86.1000,                 loss: 0.0349
Episode: 2301/10000 (23.0100%),                 avg. length: 257.0,                last time consumption/overall running time: 133.06s / 16530.93 s
first_0:                 episode reward: -75.0500,                 loss: nan
second_0:                 episode reward: 75.0500,                 loss: 0.0346
Episode: 2321/10000 (23.2100%),                 avg. length: 261.25,                last time consumption/overall running time: 134.97s / 16665.90 s
first_0:                 episode reward: -76.0500,                 loss: nan
second_0:                 episode reward: 76.0500,                 loss: 0.0348
Episode: 2341/10000 (23.4100%),                 avg. length: 252.05,                last time consumption/overall running time: 128.72s / 16794.62 s
first_0:                 episode reward: -88.6500,                 loss: nan
second_0:                 episode reward: 88.6500,                 loss: 0.0347
Episode: 2361/10000 (23.6100%),                 avg. length: 265.3,                last time consumption/overall running time: 136.12s / 16930.74 s
first_0:                 episode reward: -73.4500,                 loss: nan
second_0:                 episode reward: 73.4500,                 loss: 0.0348
Episode: 2381/10000 (23.8100%),                 avg. length: 236.0,                last time consumption/overall running time: 121.02s / 17051.76 s
first_0:                 episode reward: -76.8000,                 loss: nan
second_0:                 episode reward: 76.8000,                 loss: 0.0339
Episode: 2401/10000 (24.0100%),                 avg. length: 242.0,                last time consumption/overall running time: 123.41s / 17175.17 s
first_0:                 episode reward: -81.3000,                 loss: nan
second_0:                 episode reward: 81.3000,                 loss: 0.0341
Episode: 2421/10000 (24.2100%),                 avg. length: 242.35,                last time consumption/overall running time: 124.15s / 17299.32 s
first_0:                 episode reward: -83.4000,                 loss: nan
second_0:                 episode reward: 83.4000,                 loss: 0.0330
Episode: 2441/10000 (24.4100%),                 avg. length: 246.7,                last time consumption/overall running time: 126.31s / 17425.64 s
first_0:                 episode reward: -69.0500,                 loss: nan
second_0:                 episode reward: 69.0500,                 loss: 0.0324
Episode: 2461/10000 (24.6100%),                 avg. length: 241.35,                last time consumption/overall running time: 124.33s / 17549.97 s
first_0:                 episode reward: -90.0500,                 loss: nan
second_0:                 episode reward: 90.0500,                 loss: 0.0333
Episode: 2481/10000 (24.8100%),                 avg. length: 246.5,                last time consumption/overall running time: 125.51s / 17675.48 s
first_0:                 episode reward: -94.5500,                 loss: nan
second_0:                 episode reward: 94.5500,                 loss: 0.0326
Episode: 2501/10000 (25.0100%),                 avg. length: 241.2,                last time consumption/overall running time: 123.88s / 17799.36 s
first_0:                 episode reward: -88.9500,                 loss: nan
second_0:                 episode reward: 88.9500,                 loss: 0.0316
Episode: 2521/10000 (25.2100%),                 avg. length: 249.95,                last time consumption/overall running time: 128.79s / 17928.15 s
first_0:                 episode reward: -71.7500,                 loss: nan
second_0:                 episode reward: 71.7500,                 loss: 0.0307
Episode: 2541/10000 (25.4100%),                 avg. length: 256.9,                last time consumption/overall running time: 132.70s / 18060.85 s
first_0:                 episode reward: -82.0500,                 loss: nan
second_0:                 episode reward: 82.0500,                 loss: 0.0317
Episode: 2561/10000 (25.6100%),                 avg. length: 241.1,                last time consumption/overall running time: 123.55s / 18184.41 s
first_0:                 episode reward: -73.3000,                 loss: nan
second_0:                 episode reward: 73.3000,                 loss: 0.0311
Episode: 2581/10000 (25.8100%),                 avg. length: 247.65,                last time consumption/overall running time: 126.70s / 18311.10 s
first_0:                 episode reward: -94.6000,                 loss: nan
second_0:                 episode reward: 94.6000,                 loss: 0.0320
Episode: 2601/10000 (26.0100%),                 avg. length: 248.3,                last time consumption/overall running time: 129.22s / 18440.32 s
first_0:                 episode reward: -55.0000,                 loss: nan
second_0:                 episode reward: 55.0000,                 loss: 0.0321
Episode: 2621/10000 (26.2100%),                 avg. length: 242.05,                last time consumption/overall running time: 124.99s / 18565.32 s
first_0:                 episode reward: -71.1500,                 loss: nan
second_0:                 episode reward: 71.1500,                 loss: 0.0304
Episode: 2641/10000 (26.4100%),                 avg. length: 244.55,                last time consumption/overall running time: 125.20s / 18690.51 s
first_0:                 episode reward: -63.9500,                 loss: nan
second_0:                 episode reward: 63.9500,                 loss: 0.0311
Episode: 2661/10000 (26.6100%),                 avg. length: 252.1,                last time consumption/overall running time: 129.57s / 18820.08 s
first_0:                 episode reward: -75.7500,                 loss: nan
second_0:                 episode reward: 75.7500,                 loss: 0.0311
Episode: 2681/10000 (26.8100%),                 avg. length: 236.9,                last time consumption/overall running time: 121.07s / 18941.16 s
first_0:                 episode reward: -88.0500,                 loss: nan
second_0:                 episode reward: 88.0500,                 loss: 0.0306
Episode: 2701/10000 (27.0100%),                 avg. length: 233.1,                last time consumption/overall running time: 120.61s / 19061.76 s
first_0:                 episode reward: -92.5500,                 loss: nan
second_0:                 episode reward: 92.5500,                 loss: 0.0307
Episode: 2721/10000 (27.2100%),                 avg. length: 238.55,                last time consumption/overall running time: 123.38s / 19185.15 s
first_0:                 episode reward: -87.6500,                 loss: nan
second_0:                 episode reward: 87.6500,                 loss: 0.0314
Episode: 2741/10000 (27.4100%),                 avg. length: 240.8,                last time consumption/overall running time: 123.12s / 19308.26 s
first_0:                 episode reward: -92.5500,                 loss: nan
second_0:                 episode reward: 92.5500,                 loss: 0.0313
Episode: 2761/10000 (27.6100%),                 avg. length: 227.25,                last time consumption/overall running time: 116.61s / 19424.87 s
first_0:                 episode reward: -89.9000,                 loss: nan
second_0:                 episode reward: 89.9000,                 loss: 0.0296
Episode: 2781/10000 (27.8100%),                 avg. length: 230.85,                last time consumption/overall running time: 117.91s / 19542.78 s
first_0:                 episode reward: -93.1500,                 loss: nan
second_0:                 episode reward: 93.1500,                 loss: 0.0290
Episode: 2801/10000 (28.0100%),                 avg. length: 237.45,                last time consumption/overall running time: 122.49s / 19665.27 s
first_0:                 episode reward: -57.4500,                 loss: nan
second_0:                 episode reward: 57.4500,                 loss: 0.0294
Episode: 2821/10000 (28.2100%),                 avg. length: 246.1,                last time consumption/overall running time: 125.01s / 19790.27 s
first_0:                 episode reward: -74.9500,                 loss: nan
second_0:                 episode reward: 74.9500,                 loss: 0.0290
Episode: 2841/10000 (28.4100%),                 avg. length: 232.2,                last time consumption/overall running time: 119.40s / 19909.67 s
first_0:                 episode reward: -91.8000,                 loss: nan
second_0:                 episode reward: 91.8000,                 loss: 0.0290
Episode: 2861/10000 (28.6100%),                 avg. length: 235.0,                last time consumption/overall running time: 119.98s / 20029.65 s
first_0:                 episode reward: -88.4500,                 loss: nan
second_0:                 episode reward: 88.4500,                 loss: 0.0285
Episode: 2881/10000 (28.8100%),                 avg. length: 227.45,                last time consumption/overall running time: 116.68s / 20146.33 s
first_0:                 episode reward: -93.6000,                 loss: nan
second_0:                 episode reward: 93.6000,                 loss: 0.0286
Episode: 2901/10000 (29.0100%),                 avg. length: 234.4,                last time consumption/overall running time: 119.39s / 20265.71 s
first_0:                 episode reward: -91.5500,                 loss: nan
second_0:                 episode reward: 91.5500,                 loss: 0.0285
Episode: 2921/10000 (29.2100%),                 avg. length: 240.6,                last time consumption/overall running time: 123.80s / 20389.52 s
first_0:                 episode reward: -80.3500,                 loss: nan
second_0:                 episode reward: 80.3500,                 loss: 0.0294
Episode: 2941/10000 (29.4100%),                 avg. length: 228.7,                last time consumption/overall running time: 117.32s / 20506.84 s
first_0:                 episode reward: -96.8500,                 loss: nan
second_0:                 episode reward: 96.8500,                 loss: 0.0292
Episode: 2961/10000 (29.6100%),                 avg. length: 237.45,                last time consumption/overall running time: 121.34s / 20628.18 s
first_0:                 episode reward: -94.1000,                 loss: nan
second_0:                 episode reward: 94.1000,                 loss: 0.0288
Episode: 2981/10000 (29.8100%),                 avg. length: 243.75,                last time consumption/overall running time: 125.12s / 20753.30 s
first_0:                 episode reward: -76.2000,                 loss: nan
second_0:                 episode reward: 76.2000,                 loss: 0.0286
Episode: 3001/10000 (30.0100%),                 avg. length: 237.1,                last time consumption/overall running time: 123.33s / 20876.63 s
first_0:                 episode reward: -89.8000,                 loss: nan
second_0:                 episode reward: 89.8000,                 loss: 0.0286
Episode: 3021/10000 (30.2100%),                 avg. length: 228.8,                last time consumption/overall running time: 117.75s / 20994.38 s
first_0:                 episode reward: -91.0000,                 loss: nan
second_0:                 episode reward: 91.0000,                 loss: 0.0275
Episode: 3041/10000 (30.4100%),                 avg. length: 237.4,                last time consumption/overall running time: 122.31s / 21116.69 s
first_0:                 episode reward: -91.4500,                 loss: nan
second_0:                 episode reward: 91.4500,                 loss: 0.0285
Episode: 3061/10000 (30.6100%),                 avg. length: 239.45,                last time consumption/overall running time: 123.16s / 21239.85 s
first_0:                 episode reward: -93.4500,                 loss: nan
second_0:                 episode reward: 93.4500,                 loss: 0.0285
Episode: 3081/10000 (30.8100%),                 avg. length: 227.45,                last time consumption/overall running time: 116.01s / 21355.86 s
first_0:                 episode reward: -98.1000,                 loss: nan
second_0:                 episode reward: 98.1000,                 loss: 0.0284
Episode: 3101/10000 (31.0100%),                 avg. length: 243.75,                last time consumption/overall running time: 124.66s / 21480.52 s
first_0:                 episode reward: -86.4000,                 loss: nan
second_0:                 episode reward: 86.4000,                 loss: 0.0286
Episode: 3121/10000 (31.2100%),                 avg. length: 230.35,                last time consumption/overall running time: 118.54s / 21599.06 s
first_0:                 episode reward: -83.6500,                 loss: nan
second_0:                 episode reward: 83.6500,                 loss: 0.0278
Episode: 3141/10000 (31.4100%),                 avg. length: 234.7,                last time consumption/overall running time: 120.20s / 21719.26 s
first_0:                 episode reward: -79.7500,                 loss: nan
second_0:                 episode reward: 79.7500,                 loss: 0.0283
Episode: 3161/10000 (31.6100%),                 avg. length: 234.75,                last time consumption/overall running time: 120.05s / 21839.31 s
first_0:                 episode reward: -94.4500,                 loss: nan
second_0:                 episode reward: 94.4500,                 loss: 0.0283
Episode: 3181/10000 (31.8100%),                 avg. length: 245.2,                last time consumption/overall running time: 124.82s / 21964.13 s
first_0:                 episode reward: -88.6500,                 loss: nan
second_0:                 episode reward: 88.6500,                 loss: 0.0281
Episode: 3201/10000 (32.0100%),                 avg. length: 243.95,                last time consumption/overall running time: 126.17s / 22090.31 s
first_0:                 episode reward: -75.1500,                 loss: nan
second_0:                 episode reward: 75.1500,                 loss: 0.0273
Episode: 3221/10000 (32.2100%),                 avg. length: 227.45,                last time consumption/overall running time: 116.48s / 22206.78 s
first_0:                 episode reward: -99.2000,                 loss: nan
second_0:                 episode reward: 99.2000,                 loss: 0.0281
Episode: 3241/10000 (32.4100%),                 avg. length: 228.15,                last time consumption/overall running time: 115.45s / 22322.24 s
first_0:                 episode reward: -94.4000,                 loss: nan
second_0:                 episode reward: 94.4000,                 loss: 0.0281
Episode: 3261/10000 (32.6100%),                 avg. length: 228.7,                last time consumption/overall running time: 116.43s / 22438.67 s
first_0:                 episode reward: -73.8000,                 loss: nan
second_0:                 episode reward: 73.8000,                 loss: 0.0266
Episode: 3281/10000 (32.8100%),                 avg. length: 252.95,                last time consumption/overall running time: 128.17s / 22566.84 s
first_0:                 episode reward: -80.0000,                 loss: nan
second_0:                 episode reward: 80.0000,                 loss: 0.0278
Episode: 3301/10000 (33.0100%),                 avg. length: 231.25,                last time consumption/overall running time: 117.23s / 22684.07 s
first_0:                 episode reward: -84.4500,                 loss: nan
second_0:                 episode reward: 84.4500,                 loss: 0.0268
Episode: 3321/10000 (33.2100%),                 avg. length: 239.5,                last time consumption/overall running time: 121.08s / 22805.15 s
first_0:                 episode reward: -84.5000,                 loss: nan
second_0:                 episode reward: 84.5000,                 loss: 0.0260
Episode: 3341/10000 (33.4100%),                 avg. length: 233.0,                last time consumption/overall running time: 118.07s / 22923.22 s
first_0:                 episode reward: -74.3500,                 loss: nan
second_0:                 episode reward: 74.3500,                 loss: 0.0262
Episode: 3361/10000 (33.6100%),                 avg. length: 224.5,                last time consumption/overall running time: 114.66s / 23037.88 s
first_0:                 episode reward: -99.5500,                 loss: nan
second_0:                 episode reward: 99.5500,                 loss: 0.0262
Episode: 3381/10000 (33.8100%),                 avg. length: 228.75,                last time consumption/overall running time: 117.13s / 23155.01 s
first_0:                 episode reward: -84.6000,                 loss: nan
second_0:                 episode reward: 84.6000,                 loss: 0.0260
Episode: 3401/10000 (34.0100%),                 avg. length: 235.15,                last time consumption/overall running time: 119.32s / 23274.32 s
first_0:                 episode reward: -64.5000,                 loss: nan
second_0:                 episode reward: 64.5000,                 loss: 0.0261
Episode: 3421/10000 (34.2100%),                 avg. length: 244.35,                last time consumption/overall running time: 123.82s / 23398.14 s
first_0:                 episode reward: -87.8000,                 loss: nan
second_0:                 episode reward: 87.8000,                 loss: 0.0259
Episode: 3441/10000 (34.4100%),                 avg. length: 241.05,                last time consumption/overall running time: 121.55s / 23519.69 s
first_0:                 episode reward: -91.6000,                 loss: nan
second_0:                 episode reward: 91.6000,                 loss: 0.0270
Episode: 3461/10000 (34.6100%),                 avg. length: 231.75,                last time consumption/overall running time: 118.05s / 23637.74 s
first_0:                 episode reward: -91.4000,                 loss: nan
second_0:                 episode reward: 91.4000,                 loss: 0.0274
Episode: 3481/10000 (34.8100%),                 avg. length: 235.1,                last time consumption/overall running time: 118.61s / 23756.35 s
first_0:                 episode reward: -97.2500,                 loss: nan
second_0:                 episode reward: 97.2500,                 loss: 0.0279
Episode: 3501/10000 (35.0100%),                 avg. length: 230.1,                last time consumption/overall running time: 115.22s / 23871.57 s
first_0:                 episode reward: -99.3500,                 loss: nan
second_0:                 episode reward: 99.3500,                 loss: 0.0277
Episode: 3521/10000 (35.2100%),                 avg. length: 235.75,                last time consumption/overall running time: 119.39s / 23990.96 s
first_0:                 episode reward: -86.8000,                 loss: nan
second_0:                 episode reward: 86.8000,                 loss: 0.0280
Episode: 3541/10000 (35.4100%),                 avg. length: 222.4,                last time consumption/overall running time: 114.06s / 24105.01 s
first_0:                 episode reward: -100.0000,                 loss: nan
second_0:                 episode reward: 100.0000,                 loss: 0.0272
Episode: 3561/10000 (35.6100%),                 avg. length: 244.05,                last time consumption/overall running time: 123.69s / 24228.70 s
first_0:                 episode reward: -85.5000,                 loss: nan
second_0:                 episode reward: 85.5000,                 loss: 0.0272
Episode: 3581/10000 (35.8100%),                 avg. length: 230.75,                last time consumption/overall running time: 116.63s / 24345.33 s
first_0:                 episode reward: -91.8000,                 loss: nan
second_0:                 episode reward: 91.8000,                 loss: 0.0271
Episode: 3601/10000 (36.0100%),                 avg. length: 229.3,                last time consumption/overall running time: 115.41s / 24460.75 s
first_0:                 episode reward: -88.2500,                 loss: nan
second_0:                 episode reward: 88.2500,                 loss: 0.0273
Episode: 3621/10000 (36.2100%),                 avg. length: 232.1,                last time consumption/overall running time: 117.39s / 24578.14 s
first_0:                 episode reward: -93.2000,                 loss: nan
second_0:                 episode reward: 93.2000,                 loss: 0.0278
Episode: 3641/10000 (36.4100%),                 avg. length: 220.75,                last time consumption/overall running time: 112.07s / 24690.21 s
first_0:                 episode reward: -99.4500,                 loss: nan
second_0:                 episode reward: 99.4500,                 loss: 0.0277
Episode: 3661/10000 (36.6100%),                 avg. length: 233.5,                last time consumption/overall running time: 118.52s / 24808.73 s
first_0:                 episode reward: -95.6500,                 loss: nan
second_0:                 episode reward: 95.6500,                 loss: 0.0271
Episode: 3681/10000 (36.8100%),                 avg. length: 239.4,                last time consumption/overall running time: 121.30s / 24930.02 s
first_0:                 episode reward: -93.5500,                 loss: nan
second_0:                 episode reward: 93.5500,                 loss: 0.0275
Episode: 3701/10000 (37.0100%),                 avg. length: 224.8,                last time consumption/overall running time: 114.55s / 25044.57 s
first_0:                 episode reward: -94.6500,                 loss: nan
second_0:                 episode reward: 94.6500,                 loss: 0.0277
Episode: 3721/10000 (37.2100%),                 avg. length: 228.55,                last time consumption/overall running time: 117.12s / 25161.68 s
first_0:                 episode reward: -94.6500,                 loss: nan
second_0:                 episode reward: 94.6500,                 loss: 0.0273
Episode: 3741/10000 (37.4100%),                 avg. length: 224.2,                last time consumption/overall running time: 115.24s / 25276.93 s
first_0:                 episode reward: -99.1000,                 loss: nan
second_0:                 episode reward: 99.1000,                 loss: 0.0279
Episode: 3761/10000 (37.6100%),                 avg. length: 221.05,                last time consumption/overall running time: 111.42s / 25388.35 s
first_0:                 episode reward: -99.9000,                 loss: nan
second_0:                 episode reward: 99.9000,                 loss: 0.0285
Episode: 3781/10000 (37.8100%),                 avg. length: 225.65,                last time consumption/overall running time: 114.04s / 25502.39 s
first_0:                 episode reward: -94.5500,                 loss: nan
second_0:                 episode reward: 94.5500,                 loss: 0.0284
Episode: 3801/10000 (38.0100%),                 avg. length: 229.8,                last time consumption/overall running time: 116.71s / 25619.10 s
first_0:                 episode reward: -98.1000,                 loss: nan
second_0:                 episode reward: 98.1000,                 loss: 0.0285
Episode: 3821/10000 (38.2100%),                 avg. length: 226.6,                last time consumption/overall running time: 114.77s / 25733.87 s
first_0:                 episode reward: -97.5000,                 loss: nan
second_0:                 episode reward: 97.5000,                 loss: 0.0295
Episode: 3841/10000 (38.4100%),                 avg. length: 238.05,                last time consumption/overall running time: 120.54s / 25854.41 s
first_0:                 episode reward: -88.7000,                 loss: nan
second_0:                 episode reward: 88.7000,                 loss: 0.0298
Episode: 3861/10000 (38.6100%),                 avg. length: 223.2,                last time consumption/overall running time: 113.08s / 25967.49 s
first_0:                 episode reward: -99.2500,                 loss: nan
second_0:                 episode reward: 99.2500,                 loss: 0.0298
Episode: 3881/10000 (38.8100%),                 avg. length: 225.5,                last time consumption/overall running time: 114.15s / 26081.63 s
first_0:                 episode reward: -89.9000,                 loss: nan
second_0:                 episode reward: 89.9000,                 loss: 0.0303
Episode: 3901/10000 (39.0100%),                 avg. length: 223.5,                last time consumption/overall running time: 113.04s / 26194.67 s
first_0:                 episode reward: -99.5500,                 loss: nan
second_0:                 episode reward: 99.5500,                 loss: 0.0288
Episode: 3921/10000 (39.2100%),                 avg. length: 229.55,                last time consumption/overall running time: 117.26s / 26311.94 s
first_0:                 episode reward: -94.4500,                 loss: nan
second_0:                 episode reward: 94.4500,                 loss: 0.0299
Episode: 3941/10000 (39.4100%),                 avg. length: 224.7,                last time consumption/overall running time: 113.56s / 26425.50 s
first_0:                 episode reward: -98.1500,                 loss: nan
second_0:                 episode reward: 98.1500,                 loss: 0.0302
Episode: 3961/10000 (39.6100%),                 avg. length: 235.15,                last time consumption/overall running time: 119.87s / 26545.37 s
first_0:                 episode reward: -91.4500,                 loss: nan
second_0:                 episode reward: 91.4500,                 loss: 0.0292
Episode: 3981/10000 (39.8100%),                 avg. length: 231.45,                last time consumption/overall running time: 117.37s / 26662.74 s
first_0:                 episode reward: -88.4500,                 loss: nan
second_0:                 episode reward: 88.4500,                 loss: 0.0301
Episode: 4001/10000 (40.0100%),                 avg. length: 224.1,                last time consumption/overall running time: 113.49s / 26776.23 s
first_0:                 episode reward: -89.2000,                 loss: nan
second_0:                 episode reward: 89.2000,                 loss: 0.0305
Episode: 4021/10000 (40.2100%),                 avg. length: 225.2,                last time consumption/overall running time: 113.99s / 26890.22 s
first_0:                 episode reward: -92.2000,                 loss: nan
second_0:                 episode reward: 92.2000,                 loss: 0.0301
Episode: 4041/10000 (40.4100%),                 avg. length: 221.75,                last time consumption/overall running time: 111.84s / 27002.05 s
first_0:                 episode reward: -99.4000,                 loss: nan
second_0:                 episode reward: 99.4000,                 loss: 0.0304
Episode: 4061/10000 (40.6100%),                 avg. length: 228.7,                last time consumption/overall running time: 115.58s / 27117.63 s
first_0:                 episode reward: -99.3500,                 loss: nan
second_0:                 episode reward: 99.3500,                 loss: 0.0314
Episode: 4081/10000 (40.8100%),                 avg. length: 219.4,                last time consumption/overall running time: 111.40s / 27229.03 s
first_0:                 episode reward: -99.8500,                 loss: nan
second_0:                 episode reward: 99.8500,                 loss: 0.0311
Episode: 4101/10000 (41.0100%),                 avg. length: 231.65,                last time consumption/overall running time: 117.31s / 27346.34 s
first_0:                 episode reward: -98.8000,                 loss: nan
second_0:                 episode reward: 98.8000,                 loss: 0.0310
Episode: 4121/10000 (41.2100%),                 avg. length: 224.7,                last time consumption/overall running time: 113.39s / 27459.73 s
first_0:                 episode reward: -90.1500,                 loss: nan
second_0:                 episode reward: 90.1500,                 loss: 0.0309
Episode: 4141/10000 (41.4100%),                 avg. length: 233.35,                last time consumption/overall running time: 117.84s / 27577.57 s
first_0:                 episode reward: -90.6000,                 loss: nan
second_0:                 episode reward: 90.6000,                 loss: 0.0319
Episode: 4161/10000 (41.6100%),                 avg. length: 220.3,                last time consumption/overall running time: 111.81s / 27689.38 s
first_0:                 episode reward: -99.6000,                 loss: nan
second_0:                 episode reward: 99.6000,                 loss: 0.0326
Episode: 4181/10000 (41.8100%),                 avg. length: 236.4,                last time consumption/overall running time: 120.29s / 27809.67 s
first_0:                 episode reward: -78.5500,                 loss: nan
second_0:                 episode reward: 78.5500,                 loss: 0.0322
Episode: 4201/10000 (42.0100%),                 avg. length: 219.65,                last time consumption/overall running time: 111.73s / 27921.39 s
first_0:                 episode reward: -99.7000,                 loss: nan
second_0:                 episode reward: 99.7000,                 loss: 0.0319
Episode: 4221/10000 (42.2100%),                 avg. length: 216.05,                last time consumption/overall running time: 110.15s / 28031.54 s
first_0:                 episode reward: -99.8000,                 loss: nan
second_0:                 episode reward: 99.8000,                 loss: 0.0341
Episode: 4241/10000 (42.4100%),                 avg. length: 222.45,                last time consumption/overall running time: 113.04s / 28144.59 s
first_0:                 episode reward: -90.6000,                 loss: nan
second_0:                 episode reward: 90.6000,                 loss: 0.0329
Episode: 4261/10000 (42.6100%),                 avg. length: 218.15,                last time consumption/overall running time: 110.61s / 28255.20 s
first_0:                 episode reward: -94.2500,                 loss: nan
second_0:                 episode reward: 94.2500,                 loss: 0.0335
Episode: 4281/10000 (42.8100%),                 avg. length: 218.95,                last time consumption/overall running time: 110.79s / 28365.99 s
first_0:                 episode reward: -89.7500,                 loss: nan
second_0:                 episode reward: 89.7500,                 loss: 0.0324
Episode: 4301/10000 (43.0100%),                 avg. length: 221.9,                last time consumption/overall running time: 111.91s / 28477.90 s
first_0:                 episode reward: -98.8500,                 loss: nan
second_0:                 episode reward: 98.8500,                 loss: 0.0330
Episode: 4321/10000 (43.2100%),                 avg. length: 224.75,                last time consumption/overall running time: 113.59s / 28591.48 s
first_0:                 episode reward: -99.2500,                 loss: nan
second_0:                 episode reward: 99.2500,                 loss: 0.0326
Episode: 4341/10000 (43.4100%),                 avg. length: 218.7,                last time consumption/overall running time: 111.83s / 28703.32 s
first_0:                 episode reward: -89.6500,                 loss: nan
second_0:                 episode reward: 89.6500,                 loss: 0.0342
Episode: 4361/10000 (43.6100%),                 avg. length: 230.2,                last time consumption/overall running time: 116.36s / 28819.68 s
first_0:                 episode reward: -96.7000,                 loss: nan
second_0:                 episode reward: 96.7000,                 loss: 0.0338
Episode: 4381/10000 (43.8100%),                 avg. length: 219.2,                last time consumption/overall running time: 111.99s / 28931.67 s
first_0:                 episode reward: -98.3000,                 loss: nan
second_0:                 episode reward: 98.3000,                 loss: 0.0327
Episode: 4401/10000 (44.0100%),                 avg. length: 224.95,                last time consumption/overall running time: 114.11s / 29045.79 s
first_0:                 episode reward: -99.6500,                 loss: nan
second_0:                 episode reward: 99.6500,                 loss: 0.0338
Episode: 4421/10000 (44.2100%),                 avg. length: 218.95,                last time consumption/overall running time: 111.82s / 29157.60 s
first_0:                 episode reward: -99.9000,                 loss: nan
second_0:                 episode reward: 99.9000,                 loss: 0.0324
Episode: 4441/10000 (44.4100%),                 avg. length: 236.3,                last time consumption/overall running time: 120.24s / 29277.84 s
first_0:                 episode reward: -96.3500,                 loss: nan
second_0:                 episode reward: 96.3500,                 loss: 0.0340
Episode: 4461/10000 (44.6100%),                 avg. length: 219.5,                last time consumption/overall running time: 110.18s / 29388.02 s
first_0:                 episode reward: -99.6500,                 loss: nan
second_0:                 episode reward: 99.6500,                 loss: 0.0344
Episode: 4481/10000 (44.8100%),                 avg. length: 228.3,                last time consumption/overall running time: 115.96s / 29503.98 s
first_0:                 episode reward: -94.1500,                 loss: nan
second_0:                 episode reward: 94.1500,                 loss: 0.0345
Episode: 4501/10000 (45.0100%),                 avg. length: 218.9,                last time consumption/overall running time: 111.54s / 29615.52 s
first_0:                 episode reward: -99.4000,                 loss: nan
second_0:                 episode reward: 99.4000,                 loss: 0.0345
Episode: 4521/10000 (45.2100%),                 avg. length: 227.2,                last time consumption/overall running time: 115.02s / 29730.54 s
first_0:                 episode reward: -98.8000,                 loss: nan
second_0:                 episode reward: 98.8000,                 loss: 0.0347
Episode: 4541/10000 (45.4100%),                 avg. length: 229.2,                last time consumption/overall running time: 114.70s / 29845.24 s
first_0:                 episode reward: -90.9500,                 loss: nan
second_0:                 episode reward: 90.9500,                 loss: 0.0328
Episode: 4561/10000 (45.6100%),                 avg. length: 226.45,                last time consumption/overall running time: 113.89s / 29959.13 s
first_0:                 episode reward: -89.8500,                 loss: nan
second_0:                 episode reward: 89.8500,                 loss: 0.0342
Episode: 4581/10000 (45.8100%),                 avg. length: 218.8,                last time consumption/overall running time: 110.29s / 30069.42 s
first_0:                 episode reward: -99.0500,                 loss: nan
second_0:                 episode reward: 99.0500,                 loss: 0.0343
Episode: 4601/10000 (46.0100%),                 avg. length: 220.85,                last time consumption/overall running time: 112.84s / 30182.26 s
first_0:                 episode reward: -98.9500,                 loss: nan
second_0:                 episode reward: 98.9500,                 loss: 0.0345
Episode: 4621/10000 (46.2100%),                 avg. length: 219.25,                last time consumption/overall running time: 111.32s / 30293.58 s
first_0:                 episode reward: -94.8500,                 loss: nan
second_0:                 episode reward: 94.8500,                 loss: 0.0338
Episode: 4641/10000 (46.4100%),                 avg. length: 216.25,                last time consumption/overall running time: 109.85s / 30403.43 s
first_0:                 episode reward: -90.2000,                 loss: nan
second_0:                 episode reward: 90.2000,                 loss: 0.0342
Episode: 4661/10000 (46.6100%),                 avg. length: 217.35,                last time consumption/overall running time: 111.25s / 30514.68 s
first_0:                 episode reward: -99.8500,                 loss: nan
second_0:                 episode reward: 99.8500,                 loss: 0.0336
Episode: 4681/10000 (46.8100%),                 avg. length: 225.2,                last time consumption/overall running time: 114.33s / 30629.02 s
first_0:                 episode reward: -99.2500,                 loss: nan
second_0:                 episode reward: 99.2500,                 loss: 0.0340
Episode: 4701/10000 (47.0100%),                 avg. length: 231.15,                last time consumption/overall running time: 117.00s / 30746.02 s
first_0:                 episode reward: -90.8000,                 loss: nan
second_0:                 episode reward: 90.8000,                 loss: 0.0334
Episode: 4721/10000 (47.2100%),                 avg. length: 217.45,                last time consumption/overall running time: 109.56s / 30855.58 s
first_0:                 episode reward: -89.7500,                 loss: nan
second_0:                 episode reward: 89.7500,                 loss: 0.0340
Episode: 4741/10000 (47.4100%),                 avg. length: 228.7,                last time consumption/overall running time: 115.75s / 30971.32 s
first_0:                 episode reward: -94.7000,                 loss: nan
second_0:                 episode reward: 94.7000,                 loss: 0.0334
Episode: 4761/10000 (47.6100%),                 avg. length: 225.6,                last time consumption/overall running time: 114.48s / 31085.81 s
first_0:                 episode reward: -94.8000,                 loss: nan
second_0:                 episode reward: 94.8000,                 loss: 0.0326
Episode: 4781/10000 (47.8100%),                 avg. length: 226.45,                last time consumption/overall running time: 114.23s / 31200.04 s
first_0:                 episode reward: -87.6000,                 loss: nan
second_0:                 episode reward: 87.6000,                 loss: 0.0336
Episode: 4801/10000 (48.0100%),                 avg. length: 220.85,                last time consumption/overall running time: 112.71s / 31312.75 s
first_0:                 episode reward: -99.6000,                 loss: nan
second_0:                 episode reward: 99.6000,                 loss: 0.0333
Episode: 4821/10000 (48.2100%),                 avg. length: 219.5,                last time consumption/overall running time: 111.18s / 31423.93 s
first_0:                 episode reward: -99.9500,                 loss: nan
second_0:                 episode reward: 99.9500,                 loss: 0.0323
Episode: 4841/10000 (48.4100%),                 avg. length: 218.7,                last time consumption/overall running time: 111.54s / 31535.47 s
first_0:                 episode reward: -99.4500,                 loss: nan
second_0:                 episode reward: 99.4500,                 loss: 0.0326
Episode: 4861/10000 (48.6100%),                 avg. length: 222.25,                last time consumption/overall running time: 113.48s / 31648.95 s
first_0:                 episode reward: -99.3000,                 loss: nan
second_0:                 episode reward: 99.3000,                 loss: 0.0326
Episode: 4881/10000 (48.8100%),                 avg. length: 224.8,                last time consumption/overall running time: 114.26s / 31763.21 s
first_0:                 episode reward: -91.5000,                 loss: nan
second_0:                 episode reward: 91.5000,                 loss: 0.0321
Episode: 4901/10000 (49.0100%),                 avg. length: 218.15,                last time consumption/overall running time: 110.21s / 31873.42 s
first_0:                 episode reward: -89.9500,                 loss: nan
second_0:                 episode reward: 89.9500,                 loss: 0.0321
Episode: 4921/10000 (49.2100%),                 avg. length: 217.0,                last time consumption/overall running time: 109.50s / 31982.92 s
first_0:                 episode reward: -99.6500,                 loss: nan
second_0:                 episode reward: 99.6500,                 loss: 0.0310
Episode: 4941/10000 (49.4100%),                 avg. length: 216.1,                last time consumption/overall running time: 109.69s / 32092.61 s
first_0:                 episode reward: -99.9000,                 loss: nan
second_0:                 episode reward: 99.9000,                 loss: 0.0321
Episode: 4961/10000 (49.6100%),                 avg. length: 220.25,                last time consumption/overall running time: 112.06s / 32204.67 s
first_0:                 episode reward: -89.6000,                 loss: nan
second_0:                 episode reward: 89.6000,                 loss: 0.0315
Episode: 4981/10000 (49.8100%),                 avg. length: 226.3,                last time consumption/overall running time: 115.55s / 32320.21 s
first_0:                 episode reward: -98.4500,                 loss: nan
second_0:                 episode reward: 98.4500,                 loss: 0.0314
Episode: 5001/10000 (50.0100%),                 avg. length: 219.05,                last time consumption/overall running time: 111.83s / 32432.04 s
first_0:                 episode reward: -99.7000,                 loss: nan
second_0:                 episode reward: 99.7000,                 loss: 0.0307
Episode: 5021/10000 (50.2100%),                 avg. length: 215.25,                last time consumption/overall running time: 110.43s / 32542.48 s
first_0:                 episode reward: -99.7000,                 loss: nan
second_0:                 episode reward: 99.7000,                 loss: 0.0316
Episode: 5041/10000 (50.4100%),                 avg. length: 217.1,                last time consumption/overall running time: 110.64s / 32653.11 s
first_0:                 episode reward: -89.8500,                 loss: nan
second_0:                 episode reward: 89.8500,                 loss: 0.0313
Episode: 5061/10000 (50.6100%),                 avg. length: 220.55,                last time consumption/overall running time: 112.99s / 32766.10 s
first_0:                 episode reward: -97.8500,                 loss: nan
second_0:                 episode reward: 97.8500,                 loss: 0.0323
Episode: 5081/10000 (50.8100%),                 avg. length: 219.95,                last time consumption/overall running time: 112.29s / 32878.39 s
first_0:                 episode reward: -98.2000,                 loss: nan
second_0:                 episode reward: 98.2000,                 loss: 0.0333
Episode: 5101/10000 (51.0100%),                 avg. length: 217.7,                last time consumption/overall running time: 109.94s / 32988.33 s
first_0:                 episode reward: -99.4500,                 loss: nan
second_0:                 episode reward: 99.4500,                 loss: 0.0336
Episode: 5121/10000 (51.2100%),                 avg. length: 214.45,                last time consumption/overall running time: 109.22s / 33097.55 s
first_0:                 episode reward: -100.0000,                 loss: nan
second_0:                 episode reward: 100.0000,                 loss: 0.0324
Episode: 5141/10000 (51.4100%),                 avg. length: 219.55,                last time consumption/overall running time: 111.42s / 33208.97 s
first_0:                 episode reward: -99.3500,                 loss: nan
second_0:                 episode reward: 99.3500,                 loss: 0.0316
Episode: 5161/10000 (51.6100%),                 avg. length: 216.1,                last time consumption/overall running time: 109.70s / 33318.67 s
first_0:                 episode reward: -99.8000,                 loss: nan
second_0:                 episode reward: 99.8000,                 loss: 0.0330
Episode: 5181/10000 (51.8100%),                 avg. length: 229.05,                last time consumption/overall running time: 115.45s / 33434.13 s
first_0:                 episode reward: -90.7000,                 loss: nan
second_0:                 episode reward: 90.7000,                 loss: 0.0331
Episode: 5201/10000 (52.0100%),                 avg. length: 221.65,                last time consumption/overall running time: 111.55s / 33545.67 s
first_0:                 episode reward: -99.4000,                 loss: nan
second_0:                 episode reward: 99.4000,                 loss: 0.0324
Episode: 5221/10000 (52.2100%),                 avg. length: 216.05,                last time consumption/overall running time: 109.17s / 33654.84 s
first_0:                 episode reward: -89.3000,                 loss: nan
second_0:                 episode reward: 89.3000,                 loss: 0.0346
Episode: 5241/10000 (52.4100%),                 avg. length: 219.9,                last time consumption/overall running time: 111.32s / 33766.16 s
first_0:                 episode reward: -99.5500,                 loss: nan
second_0:                 episode reward: 99.5500,                 loss: 0.0330
Episode: 5261/10000 (52.6100%),                 avg. length: 221.2,                last time consumption/overall running time: 112.69s / 33878.85 s
first_0:                 episode reward: -98.4500,                 loss: nan
second_0:                 episode reward: 98.4500,                 loss: 0.0330
Episode: 5281/10000 (52.8100%),                 avg. length: 220.7,                last time consumption/overall running time: 112.34s / 33991.20 s
first_0:                 episode reward: -94.9000,                 loss: nan
second_0:                 episode reward: 94.9000,                 loss: 0.0320
Episode: 5301/10000 (53.0100%),                 avg. length: 231.75,                last time consumption/overall running time: 117.51s / 34108.71 s
first_0:                 episode reward: -96.3000,                 loss: nan
second_0:                 episode reward: 96.3000,                 loss: 0.0326
Episode: 5321/10000 (53.2100%),                 avg. length: 221.0,                last time consumption/overall running time: 112.42s / 34221.13 s
first_0:                 episode reward: -79.7500,                 loss: nan
second_0:                 episode reward: 79.7500,                 loss: 0.0332
Episode: 5341/10000 (53.4100%),                 avg. length: 226.2,                last time consumption/overall running time: 114.99s / 34336.12 s
first_0:                 episode reward: -92.0500,                 loss: nan
second_0:                 episode reward: 92.0500,                 loss: 0.0331
Episode: 5361/10000 (53.6100%),                 avg. length: 212.55,                last time consumption/overall running time: 107.45s / 34443.57 s
first_0:                 episode reward: -100.0000,                 loss: nan
second_0:                 episode reward: 100.0000,                 loss: 0.0349
Episode: 5381/10000 (53.8100%),                 avg. length: 222.8,                last time consumption/overall running time: 113.31s / 34556.88 s
first_0:                 episode reward: -96.3500,                 loss: nan
second_0:                 episode reward: 96.3500,                 loss: 0.0339
Episode: 5401/10000 (54.0100%),                 avg. length: 235.05,                last time consumption/overall running time: 119.32s / 34676.20 s
first_0:                 episode reward: -90.3000,                 loss: nan
second_0:                 episode reward: 90.3000,                 loss: 0.0341
Episode: 5421/10000 (54.2100%),                 avg. length: 230.2,                last time consumption/overall running time: 115.94s / 34792.14 s
first_0:                 episode reward: -88.8500,                 loss: nan
second_0:                 episode reward: 88.8500,                 loss: 0.0342
Episode: 5441/10000 (54.4100%),                 avg. length: 222.3,                last time consumption/overall running time: 112.54s / 34904.68 s
first_0:                 episode reward: -98.7000,                 loss: nan
second_0:                 episode reward: 98.7000,                 loss: 0.0360
Episode: 5461/10000 (54.6100%),                 avg. length: 215.85,                last time consumption/overall running time: 109.31s / 35013.99 s
first_0:                 episode reward: -99.8500,                 loss: nan
second_0:                 episode reward: 99.8500,                 loss: 0.0359
Episode: 5481/10000 (54.8100%),                 avg. length: 221.95,                last time consumption/overall running time: 112.77s / 35126.76 s
first_0:                 episode reward: -99.3000,                 loss: nan
second_0:                 episode reward: 99.3000,                 loss: 0.0349
Episode: 5501/10000 (55.0100%),                 avg. length: 221.1,                last time consumption/overall running time: 112.12s / 35238.88 s
first_0:                 episode reward: -99.5000,                 loss: nan
second_0:                 episode reward: 99.5000,                 loss: 0.0344
Episode: 5521/10000 (55.2100%),                 avg. length: 215.55,                last time consumption/overall running time: 109.49s / 35348.37 s
first_0:                 episode reward: -99.7500,                 loss: nan
second_0:                 episode reward: 99.7500,                 loss: 0.0347
Episode: 5541/10000 (55.4100%),                 avg. length: 226.0,                last time consumption/overall running time: 114.19s / 35462.56 s
first_0:                 episode reward: -91.8500,                 loss: nan
second_0:                 episode reward: 91.8500,                 loss: 0.0347
Episode: 5561/10000 (55.6100%),                 avg. length: 214.9,                last time consumption/overall running time: 109.73s / 35572.29 s
first_0:                 episode reward: -99.8000,                 loss: nan
second_0:                 episode reward: 99.8000,                 loss: 0.0337
Episode: 5581/10000 (55.8100%),                 avg. length: 217.65,                last time consumption/overall running time: 110.52s / 35682.81 s
first_0:                 episode reward: -98.7000,                 loss: nan
second_0:                 episode reward: 98.7000,                 loss: 0.0327
Episode: 5601/10000 (56.0100%),                 avg. length: 218.8,                last time consumption/overall running time: 111.23s / 35794.04 s
first_0:                 episode reward: -99.3500,                 loss: nan
second_0:                 episode reward: 99.3500,                 loss: 0.0335
Episode: 5621/10000 (56.2100%),                 avg. length: 219.6,                last time consumption/overall running time: 113.11s / 35907.15 s
first_0:                 episode reward: -99.0000,                 loss: nan
second_0:                 episode reward: 99.0000,                 loss: 0.0342
Episode: 5641/10000 (56.4100%),                 avg. length: 220.9,                last time consumption/overall running time: 114.78s / 36021.93 s
first_0:                 episode reward: -87.5000,                 loss: nan
second_0:                 episode reward: 87.5000,                 loss: 0.0364
Episode: 5661/10000 (56.6100%),                 avg. length: 222.85,                last time consumption/overall running time: 113.15s / 36135.08 s
first_0:                 episode reward: -92.1000,                 loss: nan
second_0:                 episode reward: 92.1000,                 loss: 0.0353
Episode: 5681/10000 (56.8100%),                 avg. length: 213.45,                last time consumption/overall running time: 109.51s / 36244.59 s
first_0:                 episode reward: -100.0000,                 loss: nan
second_0:                 episode reward: 100.0000,                 loss: 0.0360
Episode: 5701/10000 (57.0100%),                 avg. length: 214.9,                last time consumption/overall running time: 110.12s / 36354.71 s
first_0:                 episode reward: -99.7500,                 loss: nan
second_0:                 episode reward: 99.7500,                 loss: 0.0359
Episode: 5721/10000 (57.2100%),                 avg. length: 219.8,                last time consumption/overall running time: 113.08s / 36467.78 s
first_0:                 episode reward: -99.4500,                 loss: nan
second_0:                 episode reward: 99.4500,                 loss: 0.0351
Episode: 5741/10000 (57.4100%),                 avg. length: 217.2,                last time consumption/overall running time: 110.88s / 36578.66 s
first_0:                 episode reward: -99.5500,                 loss: nan
second_0:                 episode reward: 99.5500,                 loss: 0.0355
Episode: 5761/10000 (57.6100%),                 avg. length: 223.4,                last time consumption/overall running time: 113.15s / 36691.81 s
first_0:                 episode reward: -99.3500,                 loss: nan
second_0:                 episode reward: 99.3500,                 loss: 0.0359
Episode: 5781/10000 (57.8100%),                 avg. length: 217.5,                last time consumption/overall running time: 110.70s / 36802.51 s
first_0:                 episode reward: -99.4500,                 loss: nan
second_0:                 episode reward: 99.4500,                 loss: 0.0364
Episode: 5801/10000 (58.0100%),                 avg. length: 218.3,                last time consumption/overall running time: 110.87s / 36913.38 s
first_0:                 episode reward: -90.1000,                 loss: nan
second_0:                 episode reward: 90.1000,                 loss: 0.0352
Episode: 5821/10000 (58.2100%),                 avg. length: 220.45,                last time consumption/overall running time: 111.72s / 37025.10 s
first_0:                 episode reward: -99.1500,                 loss: nan
second_0:                 episode reward: 99.1500,                 loss: 0.0343
Episode: 5841/10000 (58.4100%),                 avg. length: 221.3,                last time consumption/overall running time: 113.32s / 37138.42 s
first_0:                 episode reward: -98.1000,                 loss: nan
second_0:                 episode reward: 98.1000,                 loss: 0.0351
Episode: 5861/10000 (58.6100%),                 avg. length: 219.35,                last time consumption/overall running time: 111.22s / 37249.65 s
first_0:                 episode reward: -79.7500,                 loss: nan
second_0:                 episode reward: 79.7500,                 loss: 0.0365
Episode: 5881/10000 (58.8100%),                 avg. length: 215.25,                last time consumption/overall running time: 109.30s / 37358.95 s
first_0:                 episode reward: -99.9000,                 loss: nan
second_0:                 episode reward: 99.9000,                 loss: 0.0376
Episode: 5901/10000 (59.0100%),                 avg. length: 214.6,                last time consumption/overall running time: 108.61s / 37467.55 s
first_0:                 episode reward: -99.9500,                 loss: nan
second_0:                 episode reward: 99.9500,                 loss: 0.0374
Episode: 5921/10000 (59.2100%),                 avg. length: 221.1,                last time consumption/overall running time: 112.96s / 37580.52 s
first_0:                 episode reward: -99.5000,                 loss: nan
second_0:                 episode reward: 99.5000,                 loss: 0.0362
Episode: 5941/10000 (59.4100%),                 avg. length: 225.95,                last time consumption/overall running time: 114.77s / 37695.28 s
first_0:                 episode reward: -90.1500,                 loss: nan
second_0:                 episode reward: 90.1500,                 loss: 0.0370
Episode: 5961/10000 (59.6100%),                 avg. length: 216.65,                last time consumption/overall running time: 110.06s / 37805.34 s
first_0:                 episode reward: -99.8000,                 loss: nan
second_0:                 episode reward: 99.8000,                 loss: 0.0368
Episode: 5981/10000 (59.8100%),                 avg. length: 216.5,                last time consumption/overall running time: 110.60s / 37915.94 s
first_0:                 episode reward: -99.6000,                 loss: nan
second_0:                 episode reward: 99.6000,                 loss: 0.0359
Episode: 6001/10000 (60.0100%),                 avg. length: 224.0,                last time consumption/overall running time: 114.31s / 38030.25 s
first_0:                 episode reward: -89.3500,                 loss: nan
second_0:                 episode reward: 89.3500,                 loss: 0.0379
Episode: 6021/10000 (60.2100%),                 avg. length: 229.4,                last time consumption/overall running time: 117.15s / 38147.39 s
first_0:                 episode reward: -88.8000,                 loss: nan
second_0:                 episode reward: 88.8000,                 loss: 0.0374
Episode: 6041/10000 (60.4100%),                 avg. length: 221.75,                last time consumption/overall running time: 112.90s / 38260.30 s
first_0:                 episode reward: -83.6500,                 loss: nan
second_0:                 episode reward: 83.6500,                 loss: 0.0351
Episode: 6061/10000 (60.6100%),                 avg. length: 223.3,                last time consumption/overall running time: 112.87s / 38373.17 s
first_0:                 episode reward: -99.1500,                 loss: nan
second_0:                 episode reward: 99.1500,                 loss: 0.0366
Episode: 6081/10000 (60.8100%),                 avg. length: 227.4,                last time consumption/overall running time: 115.90s / 38489.08 s
first_0:                 episode reward: -98.9000,                 loss: nan
second_0:                 episode reward: 98.9000,                 loss: 0.0342
Episode: 6101/10000 (61.0100%),                 avg. length: 222.4,                last time consumption/overall running time: 112.99s / 38602.07 s
first_0:                 episode reward: -97.8500,                 loss: nan
second_0:                 episode reward: 97.8500,                 loss: 0.0348
Episode: 6121/10000 (61.2100%),                 avg. length: 217.15,                last time consumption/overall running time: 109.39s / 38711.46 s
first_0:                 episode reward: -99.7000,                 loss: nan
second_0:                 episode reward: 99.7000,                 loss: 0.0363
Episode: 6141/10000 (61.4100%),                 avg. length: 213.85,                last time consumption/overall running time: 108.40s / 38819.86 s
first_0:                 episode reward: -99.8500,                 loss: nan
second_0:                 episode reward: 99.8500,                 loss: 0.0346
Episode: 6161/10000 (61.6100%),                 avg. length: 226.85,                last time consumption/overall running time: 114.99s / 38934.85 s
first_0:                 episode reward: -99.0500,                 loss: nan
second_0:                 episode reward: 99.0500,                 loss: 0.0347
Episode: 6181/10000 (61.8100%),                 avg. length: 217.55,                last time consumption/overall running time: 109.75s / 39044.60 s
first_0:                 episode reward: -99.6500,                 loss: nan
second_0:                 episode reward: 99.6500,                 loss: 0.0348
Episode: 6201/10000 (62.0100%),                 avg. length: 220.2,                last time consumption/overall running time: 111.23s / 39155.83 s
first_0:                 episode reward: -99.0500,                 loss: nan
second_0:                 episode reward: 99.0500,                 loss: 0.0359
Episode: 6221/10000 (62.2100%),                 avg. length: 217.6,                last time consumption/overall running time: 110.81s / 39266.64 s
first_0:                 episode reward: -95.0000,                 loss: nan
second_0:                 episode reward: 95.0000,                 loss: 0.0340
Episode: 6241/10000 (62.4100%),                 avg. length: 215.85,                last time consumption/overall running time: 109.12s / 39375.76 s
first_0:                 episode reward: -99.5500,                 loss: nan
second_0:                 episode reward: 99.5500,                 loss: 0.0339
Episode: 6261/10000 (62.6100%),                 avg. length: 221.2,                last time consumption/overall running time: 111.84s / 39487.60 s
first_0:                 episode reward: -93.2000,                 loss: nan
second_0:                 episode reward: 93.2000,                 loss: 0.0338
Episode: 6281/10000 (62.8100%),                 avg. length: 222.6,                last time consumption/overall running time: 114.16s / 39601.76 s
first_0:                 episode reward: -99.3000,                 loss: nan
second_0:                 episode reward: 99.3000,                 loss: 0.0346
Episode: 6301/10000 (63.0100%),                 avg. length: 220.85,                last time consumption/overall running time: 112.97s / 39714.73 s
first_0:                 episode reward: -89.5000,                 loss: nan
second_0:                 episode reward: 89.5000,                 loss: 0.0338
Episode: 6321/10000 (63.2100%),                 avg. length: 212.5,                last time consumption/overall running time: 109.12s / 39823.85 s
first_0:                 episode reward: -99.6500,                 loss: nan
second_0:                 episode reward: 99.6500,                 loss: 0.0362
Episode: 6341/10000 (63.4100%),                 avg. length: 218.2,                last time consumption/overall running time: 110.78s / 39934.63 s
first_0:                 episode reward: -99.6500,                 loss: nan
second_0:                 episode reward: 99.6500,                 loss: 0.0352
Episode: 6361/10000 (63.6100%),                 avg. length: 228.35,                last time consumption/overall running time: 116.48s / 40051.11 s
first_0:                 episode reward: -96.8500,                 loss: nan
second_0:                 episode reward: 96.8500,                 loss: 0.0344
Episode: 6381/10000 (63.8100%),                 avg. length: 216.45,                last time consumption/overall running time: 109.20s / 40160.31 s
first_0:                 episode reward: -99.5500,                 loss: nan
second_0:                 episode reward: 99.5500,                 loss: 0.0352
Episode: 6401/10000 (64.0100%),                 avg. length: 214.7,                last time consumption/overall running time: 108.71s / 40269.02 s
first_0:                 episode reward: -99.5500,                 loss: nan
second_0:                 episode reward: 99.5500,                 loss: 0.0350
Episode: 6421/10000 (64.2100%),                 avg. length: 219.3,                last time consumption/overall running time: 110.90s / 40379.92 s
first_0:                 episode reward: -99.1500,                 loss: nan
second_0:                 episode reward: 99.1500,                 loss: 0.0348
Episode: 6441/10000 (64.4100%),                 avg. length: 223.45,                last time consumption/overall running time: 113.21s / 40493.13 s
first_0:                 episode reward: -98.6500,                 loss: nan
second_0:                 episode reward: 98.6500,                 loss: 0.0345
Episode: 6461/10000 (64.6100%),                 avg. length: 216.15,                last time consumption/overall running time: 108.35s / 40601.48 s
first_0:                 episode reward: -99.7000,                 loss: nan
second_0:                 episode reward: 99.7000,                 loss: 0.0349
Episode: 6481/10000 (64.8100%),                 avg. length: 215.95,                last time consumption/overall running time: 108.40s / 40709.87 s
first_0:                 episode reward: -99.7500,                 loss: nan
second_0:                 episode reward: 99.7500,                 loss: 0.0355
Episode: 6501/10000 (65.0100%),                 avg. length: 218.2,                last time consumption/overall running time: 110.43s / 40820.30 s
first_0:                 episode reward: -99.3000,                 loss: nan
second_0:                 episode reward: 99.3000,                 loss: 0.0357
Episode: 6521/10000 (65.2100%),                 avg. length: 218.0,                last time consumption/overall running time: 110.12s / 40930.42 s
first_0:                 episode reward: -99.5000,                 loss: nan
second_0:                 episode reward: 99.5000,                 loss: 0.0363
Episode: 6541/10000 (65.4100%),                 avg. length: 216.1,                last time consumption/overall running time: 109.52s / 41039.94 s
first_0:                 episode reward: -99.6000,                 loss: nan
second_0:                 episode reward: 99.6000,                 loss: 0.0356
Episode: 6561/10000 (65.6100%),                 avg. length: 213.55,                last time consumption/overall running time: 107.86s / 41147.80 s
first_0:                 episode reward: -99.9000,                 loss: nan
second_0:                 episode reward: 99.9000,                 loss: 0.0355
Episode: 6581/10000 (65.8100%),                 avg. length: 212.1,                last time consumption/overall running time: 107.84s / 41255.64 s
first_0:                 episode reward: -100.0000,                 loss: nan
second_0:                 episode reward: 100.0000,                 loss: 0.0342
Episode: 6601/10000 (66.0100%),                 avg. length: 228.5,                last time consumption/overall running time: 115.74s / 41371.37 s
first_0:                 episode reward: -96.8500,                 loss: nan
second_0:                 episode reward: 96.8500,                 loss: 0.0350
Episode: 6621/10000 (66.2100%),                 avg. length: 216.6,                last time consumption/overall running time: 109.58s / 41480.96 s
first_0:                 episode reward: -99.9000,                 loss: nan
second_0:                 episode reward: 99.9000,                 loss: 0.0365
Episode: 6641/10000 (66.4100%),                 avg. length: 217.4,                last time consumption/overall running time: 110.68s / 41591.63 s
first_0:                 episode reward: -99.6500,                 loss: nan
second_0:                 episode reward: 99.6500,                 loss: 0.0361
Episode: 6661/10000 (66.6100%),                 avg. length: 217.4,                last time consumption/overall running time: 111.43s / 41703.06 s
first_0:                 episode reward: -95.9500,                 loss: nan
second_0:                 episode reward: 95.9500,                 loss: 0.0362
Episode: 6681/10000 (66.8100%),                 avg. length: 210.9,                last time consumption/overall running time: 107.69s / 41810.75 s
first_0:                 episode reward: -100.0000,                 loss: nan
second_0:                 episode reward: 100.0000,                 loss: 0.0363
Episode: 6701/10000 (67.0100%),                 avg. length: 213.3,                last time consumption/overall running time: 108.34s / 41919.09 s
first_0:                 episode reward: -99.9000,                 loss: nan
second_0:                 episode reward: 99.9000,                 loss: 0.0363
Episode: 6721/10000 (67.2100%),                 avg. length: 230.95,                last time consumption/overall running time: 117.02s / 42036.11 s
first_0:                 episode reward: -90.6500,                 loss: nan
second_0:                 episode reward: 90.6500,                 loss: 0.0381
Episode: 6741/10000 (67.4100%),                 avg. length: 212.9,                last time consumption/overall running time: 108.33s / 42144.44 s
first_0:                 episode reward: -99.9000,                 loss: nan
second_0:                 episode reward: 99.9000,                 loss: 0.0376
Episode: 6761/10000 (67.6100%),                 avg. length: 221.85,                last time consumption/overall running time: 112.47s / 42256.91 s
first_0:                 episode reward: -90.6000,                 loss: nan
second_0:                 episode reward: 90.6000,                 loss: 0.0367
Episode: 6781/10000 (67.8100%),                 avg. length: 218.4,                last time consumption/overall running time: 110.45s / 42367.36 s
first_0:                 episode reward: -89.9000,                 loss: nan
second_0:                 episode reward: 89.9000,                 loss: 0.0373
Episode: 6801/10000 (68.0100%),                 avg. length: 213.8,                last time consumption/overall running time: 109.06s / 42476.43 s
first_0:                 episode reward: -89.9000,                 loss: nan
second_0:                 episode reward: 89.9000,                 loss: 0.0377
Episode: 6821/10000 (68.2100%),                 avg. length: 222.95,                last time consumption/overall running time: 112.93s / 42589.35 s
first_0:                 episode reward: -97.8000,                 loss: nan
second_0:                 episode reward: 97.8000,                 loss: 0.0376
Episode: 6841/10000 (68.4100%),                 avg. length: 213.6,                last time consumption/overall running time: 109.46s / 42698.81 s
first_0:                 episode reward: -90.3500,                 loss: nan
second_0:                 episode reward: 90.3500,                 loss: 0.0374
Episode: 6861/10000 (68.6100%),                 avg. length: 217.75,                last time consumption/overall running time: 110.05s / 42808.86 s
first_0:                 episode reward: -90.5000,                 loss: nan
second_0:                 episode reward: 90.5000,                 loss: 0.0372
Episode: 6881/10000 (68.8100%),                 avg. length: 216.3,                last time consumption/overall running time: 111.36s / 42920.23 s
first_0:                 episode reward: -99.7000,                 loss: nan
second_0:                 episode reward: 99.7000,                 loss: 0.0369
Episode: 6901/10000 (69.0100%),                 avg. length: 212.65,                last time consumption/overall running time: 108.06s / 43028.28 s
first_0:                 episode reward: -100.0000,                 loss: nan
second_0:                 episode reward: 100.0000,                 loss: 0.0373
Episode: 6921/10000 (69.2100%),                 avg. length: 216.5,                last time consumption/overall running time: 109.07s / 43137.35 s
first_0:                 episode reward: -99.7500,                 loss: nan
second_0:                 episode reward: 99.7500,                 loss: 0.0373
Episode: 6941/10000 (69.4100%),                 avg. length: 213.0,                last time consumption/overall running time: 107.49s / 43244.84 s
first_0:                 episode reward: -99.9500,                 loss: nan
second_0:                 episode reward: 99.9500,                 loss: 0.0361
Episode: 6961/10000 (69.6100%),                 avg. length: 223.6,                last time consumption/overall running time: 112.82s / 43357.66 s
first_0:                 episode reward: -96.9000,                 loss: nan
second_0:                 episode reward: 96.9000,                 loss: 0.0359
Episode: 6981/10000 (69.8100%),                 avg. length: 225.65,                last time consumption/overall running time: 114.72s / 43472.38 s
first_0:                 episode reward: -94.0500,                 loss: nan
second_0:                 episode reward: 94.0500,                 loss: 0.0370
Episode: 7001/10000 (70.0100%),                 avg. length: 218.9,                last time consumption/overall running time: 110.73s / 43583.12 s
first_0:                 episode reward: -99.5000,                 loss: nan
second_0:                 episode reward: 99.5000,                 loss: 0.0370
Episode: 7021/10000 (70.2100%),                 avg. length: 232.8,                last time consumption/overall running time: 118.57s / 43701.68 s
first_0:                 episode reward: -86.5000,                 loss: nan
second_0:                 episode reward: 86.5000,                 loss: 0.0358
Episode: 7041/10000 (70.4100%),                 avg. length: 220.35,                last time consumption/overall running time: 111.29s / 43812.98 s
first_0:                 episode reward: -96.3500,                 loss: nan
second_0:                 episode reward: 96.3500,                 loss: 0.0372
Episode: 7061/10000 (70.6100%),                 avg. length: 215.7,                last time consumption/overall running time: 109.74s / 43922.72 s
first_0:                 episode reward: -99.9500,                 loss: nan
second_0:                 episode reward: 99.9500,                 loss: 0.0359
Episode: 7081/10000 (70.8100%),                 avg. length: 220.3,                last time consumption/overall running time: 110.96s / 44033.68 s
first_0:                 episode reward: -99.7000,                 loss: nan
second_0:                 episode reward: 99.7000,                 loss: 0.0359
Episode: 7101/10000 (71.0100%),                 avg. length: 216.85,                last time consumption/overall running time: 112.00s / 44145.68 s
first_0:                 episode reward: -98.6500,                 loss: nan
second_0:                 episode reward: 98.6500,                 loss: 0.0361
Episode: 7121/10000 (71.2100%),                 avg. length: 223.3,                last time consumption/overall running time: 115.57s / 44261.26 s
first_0:                 episode reward: -95.5000,                 loss: nan
second_0:                 episode reward: 95.5000,                 loss: 0.0367
Episode: 7141/10000 (71.4100%),                 avg. length: 216.6,                last time consumption/overall running time: 110.64s / 44371.90 s
first_0:                 episode reward: -99.6000,                 loss: nan
second_0:                 episode reward: 99.6000,                 loss: 0.0357
Episode: 7161/10000 (71.6100%),                 avg. length: 215.8,                last time consumption/overall running time: 110.46s / 44482.36 s
first_0:                 episode reward: -99.7000,                 loss: nan
second_0:                 episode reward: 99.7000,                 loss: 0.0354
Episode: 7181/10000 (71.8100%),                 avg. length: 217.3,                last time consumption/overall running time: 112.05s / 44594.41 s
first_0:                 episode reward: -99.8000,                 loss: nan
second_0:                 episode reward: 99.8000,                 loss: 0.0377
Episode: 7201/10000 (72.0100%),                 avg. length: 221.5,                last time consumption/overall running time: 115.08s / 44709.50 s
first_0:                 episode reward: -97.1500,                 loss: nan
second_0:                 episode reward: 97.1500,                 loss: 0.0362
Episode: 7221/10000 (72.2100%),                 avg. length: 219.1,                last time consumption/overall running time: 113.06s / 44822.56 s
first_0:                 episode reward: -90.2500,                 loss: nan
second_0:                 episode reward: 90.2500,                 loss: 0.0354
Episode: 7241/10000 (72.4100%),                 avg. length: 220.1,                last time consumption/overall running time: 111.80s / 44934.36 s
first_0:                 episode reward: -89.3500,                 loss: nan
second_0:                 episode reward: 89.3500,                 loss: 0.0374
Episode: 7261/10000 (72.6100%),                 avg. length: 212.6,                last time consumption/overall running time: 108.12s / 45042.48 s
first_0:                 episode reward: -100.0000,                 loss: nan
second_0:                 episode reward: 100.0000,                 loss: 0.0350
Episode: 7281/10000 (72.8100%),                 avg. length: 212.25,                last time consumption/overall running time: 107.73s / 45150.21 s
first_0:                 episode reward: -100.0000,                 loss: nan
second_0:                 episode reward: 100.0000,                 loss: 0.0351
Episode: 7301/10000 (73.0100%),                 avg. length: 214.15,                last time consumption/overall running time: 108.65s / 45258.86 s
first_0:                 episode reward: -100.0000,                 loss: nan
second_0:                 episode reward: 100.0000,                 loss: 0.0351
Episode: 7321/10000 (73.2100%),                 avg. length: 213.9,                last time consumption/overall running time: 109.21s / 45368.07 s
first_0:                 episode reward: -99.8500,                 loss: nan
second_0:                 episode reward: 99.8500,                 loss: 0.0353
Episode: 7341/10000 (73.4100%),                 avg. length: 214.85,                last time consumption/overall running time: 108.98s / 45477.05 s
first_0:                 episode reward: -99.7000,                 loss: nan
second_0:                 episode reward: 99.7000,                 loss: 0.0351
Episode: 7361/10000 (73.6100%),                 avg. length: 213.95,                last time consumption/overall running time: 108.22s / 45585.26 s
first_0:                 episode reward: -99.8000,                 loss: nan
second_0:                 episode reward: 99.8000,                 loss: 0.0367
Episode: 7381/10000 (73.8100%),                 avg. length: 215.25,                last time consumption/overall running time: 109.37s / 45694.64 s
first_0:                 episode reward: -100.0000,                 loss: nan
second_0:                 episode reward: 100.0000,                 loss: 0.0361
Episode: 7401/10000 (74.0100%),                 avg. length: 222.9,                last time consumption/overall running time: 113.32s / 45807.95 s
first_0:                 episode reward: -87.9500,                 loss: nan
second_0:                 episode reward: 87.9500,                 loss: 0.0350
Episode: 7421/10000 (74.2100%),                 avg. length: 216.6,                last time consumption/overall running time: 109.81s / 45917.77 s
first_0:                 episode reward: -99.6500,                 loss: nan
second_0:                 episode reward: 99.6500,                 loss: 0.0351
Episode: 7441/10000 (74.4100%),                 avg. length: 228.05,                last time consumption/overall running time: 115.76s / 46033.52 s
first_0:                 episode reward: -81.7000,                 loss: nan
second_0:                 episode reward: 81.7000,                 loss: 0.0358
Episode: 7461/10000 (74.6100%),                 avg. length: 215.4,                last time consumption/overall running time: 109.31s / 46142.83 s
first_0:                 episode reward: -89.9500,                 loss: nan
second_0:                 episode reward: 89.9500,                 loss: 0.0358
Episode: 7481/10000 (74.8100%),                 avg. length: 209.85,                last time consumption/overall running time: 106.12s / 46248.95 s
first_0:                 episode reward: -100.0000,                 loss: nan
second_0:                 episode reward: 100.0000,                 loss: 0.0347
Episode: 7501/10000 (75.0100%),                 avg. length: 216.3,                last time consumption/overall running time: 109.71s / 46358.66 s
first_0:                 episode reward: -99.8000,                 loss: nan
second_0:                 episode reward: 99.8000,                 loss: 0.0352
Episode: 7521/10000 (75.2100%),                 avg. length: 217.35,                last time consumption/overall running time: 110.76s / 46469.42 s
first_0:                 episode reward: -99.5500,                 loss: nan
second_0:                 episode reward: 99.5500,                 loss: 0.0362
Episode: 7541/10000 (75.4100%),                 avg. length: 212.4,                last time consumption/overall running time: 107.66s / 46577.08 s
first_0:                 episode reward: -99.8500,                 loss: nan
second_0:                 episode reward: 99.8500,                 loss: 0.0356
Episode: 7561/10000 (75.6100%),                 avg. length: 222.0,                last time consumption/overall running time: 112.45s / 46689.53 s
first_0:                 episode reward: -89.4500,                 loss: nan
second_0:                 episode reward: 89.4500,                 loss: 0.0351
Episode: 7581/10000 (75.8100%),                 avg. length: 219.25,                last time consumption/overall running time: 110.93s / 46800.46 s
first_0:                 episode reward: -99.4500,                 loss: nan
second_0:                 episode reward: 99.4500,                 loss: 0.0353
Episode: 7601/10000 (76.0100%),                 avg. length: 213.65,                last time consumption/overall running time: 109.06s / 46909.53 s
first_0:                 episode reward: -99.9000,                 loss: nan
second_0:                 episode reward: 99.9000,                 loss: 0.0352
Episode: 7621/10000 (76.2100%),                 avg. length: 217.55,                last time consumption/overall running time: 111.64s / 47021.16 s
first_0:                 episode reward: -99.5500,                 loss: nan
second_0:                 episode reward: 99.5500,                 loss: 0.0361
Episode: 7641/10000 (76.4100%),                 avg. length: 222.95,                last time consumption/overall running time: 113.63s / 47134.80 s
first_0:                 episode reward: -98.7500,                 loss: nan
second_0:                 episode reward: 98.7500,                 loss: 0.0338
Episode: 7661/10000 (76.6100%),                 avg. length: 222.65,                last time consumption/overall running time: 114.72s / 47249.52 s
first_0:                 episode reward: -99.0000,                 loss: nan
second_0:                 episode reward: 99.0000,                 loss: 0.0359
Episode: 7681/10000 (76.8100%),                 avg. length: 226.5,                last time consumption/overall running time: 114.93s / 47364.45 s
first_0:                 episode reward: -93.0000,                 loss: nan
second_0:                 episode reward: 93.0000,                 loss: 0.0348
Episode: 7701/10000 (77.0100%),                 avg. length: 225.7,                last time consumption/overall running time: 115.34s / 47479.79 s
first_0:                 episode reward: -98.9500,                 loss: nan
second_0:                 episode reward: 98.9500,                 loss: 0.0359
Episode: 7721/10000 (77.2100%),                 avg. length: 226.9,                last time consumption/overall running time: 115.61s / 47595.40 s
first_0:                 episode reward: -98.9500,                 loss: nan
second_0:                 episode reward: 98.9500,                 loss: 0.0361
Episode: 7741/10000 (77.4100%),                 avg. length: 217.5,                last time consumption/overall running time: 110.35s / 47705.75 s
first_0:                 episode reward: -99.4000,                 loss: nan
second_0:                 episode reward: 99.4000,                 loss: 0.0359
Episode: 7761/10000 (77.6100%),                 avg. length: 218.55,                last time consumption/overall running time: 110.54s / 47816.28 s
first_0:                 episode reward: -90.5000,                 loss: nan
second_0:                 episode reward: 90.5000,                 loss: 0.0351
Episode: 7781/10000 (77.8100%),                 avg. length: 212.0,                last time consumption/overall running time: 108.13s / 47924.42 s
first_0:                 episode reward: -100.0000,                 loss: nan
second_0:                 episode reward: 100.0000,                 loss: 0.0348
Episode: 7801/10000 (78.0100%),                 avg. length: 220.75,                last time consumption/overall running time: 112.08s / 48036.50 s
first_0:                 episode reward: -94.4000,                 loss: nan
second_0:                 episode reward: 94.4000,                 loss: 0.0353
Episode: 7821/10000 (78.2100%),                 avg. length: 227.9,                last time consumption/overall running time: 115.02s / 48151.52 s
first_0:                 episode reward: -98.8000,                 loss: nan
second_0:                 episode reward: 98.8000,                 loss: 0.0354
Episode: 7841/10000 (78.4100%),                 avg. length: 215.8,                last time consumption/overall running time: 110.72s / 48262.24 s
first_0:                 episode reward: -99.8000,                 loss: nan
second_0:                 episode reward: 99.8000,                 loss: 0.0356
Episode: 7861/10000 (78.6100%),                 avg. length: 227.25,                last time consumption/overall running time: 115.88s / 48378.12 s
first_0:                 episode reward: -92.6500,                 loss: nan
second_0:                 episode reward: 92.6500,                 loss: 0.0371
Episode: 7881/10000 (78.8100%),                 avg. length: 222.75,                last time consumption/overall running time: 113.15s / 48491.27 s
first_0:                 episode reward: -94.9000,                 loss: nan
second_0:                 episode reward: 94.9000,                 loss: 0.0360
Episode: 7901/10000 (79.0100%),                 avg. length: 219.8,                last time consumption/overall running time: 111.29s / 48602.56 s
first_0:                 episode reward: -99.4500,                 loss: nan
second_0:                 episode reward: 99.4500,                 loss: 0.0353
Episode: 7921/10000 (79.2100%),                 avg. length: 219.1,                last time consumption/overall running time: 111.00s / 48713.56 s
first_0:                 episode reward: -99.3500,                 loss: nan
second_0:                 episode reward: 99.3500,                 loss: 0.0355
Episode: 7941/10000 (79.4100%),                 avg. length: 214.15,                last time consumption/overall running time: 108.13s / 48821.69 s
first_0:                 episode reward: -99.9000,                 loss: nan
second_0:                 episode reward: 99.9000,                 loss: 0.0350
Episode: 7961/10000 (79.6100%),                 avg. length: 215.05,                last time consumption/overall running time: 109.31s / 48931.00 s
first_0:                 episode reward: -99.6500,                 loss: nan
second_0:                 episode reward: 99.6500,                 loss: 0.0357
Episode: 7981/10000 (79.8100%),                 avg. length: 210.75,                last time consumption/overall running time: 107.02s / 49038.02 s
first_0:                 episode reward: -100.0000,                 loss: nan
second_0:                 episode reward: 100.0000,                 loss: 0.0340
Episode: 8001/10000 (80.0100%),                 avg. length: 222.35,                last time consumption/overall running time: 112.59s / 49150.62 s
first_0:                 episode reward: -93.9500,                 loss: nan
second_0:                 episode reward: 93.9500,                 loss: 0.0336
Episode: 8021/10000 (80.2100%),                 avg. length: 216.75,                last time consumption/overall running time: 111.70s / 49262.31 s
first_0:                 episode reward: -99.0500,                 loss: nan
second_0:                 episode reward: 99.0500,                 loss: 0.0332
Episode: 8041/10000 (80.4100%),                 avg. length: 226.0,                last time consumption/overall running time: 115.12s / 49377.43 s
first_0:                 episode reward: -98.8000,                 loss: nan
second_0:                 episode reward: 98.8000,                 loss: 0.0345
Episode: 8061/10000 (80.6100%),                 avg. length: 211.4,                last time consumption/overall running time: 107.79s / 49485.22 s
first_0:                 episode reward: -99.8000,                 loss: nan
second_0:                 episode reward: 99.8000,                 loss: 0.0340
Episode: 8081/10000 (80.8100%),                 avg. length: 217.1,                last time consumption/overall running time: 109.69s / 49594.91 s
first_0:                 episode reward: -99.8500,                 loss: nan
second_0:                 episode reward: 99.8500,                 loss: 0.0334
Episode: 8101/10000 (81.0100%),                 avg. length: 214.0,                last time consumption/overall running time: 108.74s / 49703.65 s
first_0:                 episode reward: -99.7000,                 loss: nan
second_0:                 episode reward: 99.7000,                 loss: 0.0325
Episode: 8121/10000 (81.2100%),                 avg. length: 213.45,                last time consumption/overall running time: 108.89s / 49812.54 s
first_0:                 episode reward: -97.9000,                 loss: nan
second_0:                 episode reward: 97.9000,                 loss: 0.0316
Episode: 8141/10000 (81.4100%),                 avg. length: 210.55,                last time consumption/overall running time: 107.38s / 49919.92 s
first_0:                 episode reward: -100.0000,                 loss: nan
second_0:                 episode reward: 100.0000,                 loss: 0.0325
Episode: 8161/10000 (81.6100%),                 avg. length: 210.15,                last time consumption/overall running time: 108.28s / 50028.20 s
first_0:                 episode reward: -100.0000,                 loss: nan
second_0:                 episode reward: 100.0000,                 loss: 0.0321
Episode: 8181/10000 (81.8100%),                 avg. length: 213.9,                last time consumption/overall running time: 108.05s / 50136.25 s
first_0:                 episode reward: -99.9000,                 loss: nan
second_0:                 episode reward: 99.9000,                 loss: 0.0335
Episode: 8201/10000 (82.0100%),                 avg. length: 213.6,                last time consumption/overall running time: 108.10s / 50244.35 s
first_0:                 episode reward: -99.8500,                 loss: nan
second_0:                 episode reward: 99.8500,                 loss: 0.0325
Episode: 8221/10000 (82.2100%),                 avg. length: 217.95,                last time consumption/overall running time: 110.60s / 50354.95 s
first_0:                 episode reward: -89.3000,                 loss: nan
second_0:                 episode reward: 89.3000,                 loss: 0.0326
Episode: 8241/10000 (82.4100%),                 avg. length: 216.15,                last time consumption/overall running time: 109.96s / 50464.91 s
first_0:                 episode reward: -98.4500,                 loss: nan
second_0:                 episode reward: 98.4500,                 loss: 0.0343
Episode: 8261/10000 (82.6100%),                 avg. length: 221.6,                last time consumption/overall running time: 112.90s / 50577.81 s
first_0:                 episode reward: -98.0000,                 loss: nan
second_0:                 episode reward: 98.0000,                 loss: 0.0348
Episode: 8281/10000 (82.8100%),                 avg. length: 217.95,                last time consumption/overall running time: 111.12s / 50688.93 s
first_0:                 episode reward: -99.3500,                 loss: nan
second_0:                 episode reward: 99.3500,                 loss: 0.0342
Episode: 8301/10000 (83.0100%),                 avg. length: 215.45,                last time consumption/overall running time: 109.78s / 50798.71 s
first_0:                 episode reward: -99.7500,                 loss: nan
second_0:                 episode reward: 99.7500,                 loss: 0.0349
Episode: 8321/10000 (83.2100%),                 avg. length: 214.3,                last time consumption/overall running time: 108.75s / 50907.46 s
first_0:                 episode reward: -89.6500,                 loss: nan
second_0:                 episode reward: 89.6500,                 loss: 0.0344
Episode: 8341/10000 (83.4100%),                 avg. length: 216.15,                last time consumption/overall running time: 109.60s / 51017.06 s
first_0:                 episode reward: -89.6500,                 loss: nan
second_0:                 episode reward: 89.6500,                 loss: 0.0356
Episode: 8361/10000 (83.6100%),                 avg. length: 218.5,                last time consumption/overall running time: 111.50s / 51128.56 s
first_0:                 episode reward: -93.2000,                 loss: nan
second_0:                 episode reward: 93.2000,                 loss: 0.0349
Episode: 8381/10000 (83.8100%),                 avg. length: 214.5,                last time consumption/overall running time: 109.13s / 51237.69 s
first_0:                 episode reward: -80.4000,                 loss: nan
second_0:                 episode reward: 80.4000,                 loss: 0.0355
Episode: 8401/10000 (84.0100%),                 avg. length: 213.65,                last time consumption/overall running time: 108.49s / 51346.19 s
first_0:                 episode reward: -90.4000,                 loss: nan
second_0:                 episode reward: 90.4000,                 loss: 0.0349
Episode: 8421/10000 (84.2100%),                 avg. length: 214.15,                last time consumption/overall running time: 107.97s / 51454.16 s
first_0:                 episode reward: -99.8000,                 loss: nan
second_0:                 episode reward: 99.8000,                 loss: 0.0362
Episode: 8441/10000 (84.4100%),                 avg. length: 220.25,                last time consumption/overall running time: 112.11s / 51566.27 s
first_0:                 episode reward: -97.1500,                 loss: nan
second_0:                 episode reward: 97.1500,                 loss: 0.0354
Episode: 8461/10000 (84.6100%),                 avg. length: 214.0,                last time consumption/overall running time: 109.04s / 51675.31 s
first_0:                 episode reward: -99.9000,                 loss: nan
second_0:                 episode reward: 99.9000,                 loss: 0.0350
Episode: 8481/10000 (84.8100%),                 avg. length: 215.8,                last time consumption/overall running time: 110.03s / 51785.34 s
first_0:                 episode reward: -99.7500,                 loss: nan
second_0:                 episode reward: 99.7500,                 loss: 0.0361
Episode: 8501/10000 (85.0100%),                 avg. length: 213.85,                last time consumption/overall running time: 109.33s / 51894.67 s
first_0:                 episode reward: -99.7500,                 loss: nan
second_0:                 episode reward: 99.7500,                 loss: 0.0358
Episode: 8521/10000 (85.2100%),                 avg. length: 224.55,                last time consumption/overall running time: 114.50s / 52009.17 s
first_0:                 episode reward: -73.1500,                 loss: nan
second_0:                 episode reward: 73.1500,                 loss: 0.0351
Episode: 8541/10000 (85.4100%),                 avg. length: 215.5,                last time consumption/overall running time: 110.65s / 52119.82 s
first_0:                 episode reward: -99.6000,                 loss: nan
second_0:                 episode reward: 99.6000,                 loss: 0.0343
Episode: 8561/10000 (85.6100%),                 avg. length: 223.25,                last time consumption/overall running time: 113.41s / 52233.24 s
first_0:                 episode reward: -98.9500,                 loss: nan
second_0:                 episode reward: 98.9500,                 loss: 0.0350
Episode: 8581/10000 (85.8100%),                 avg. length: 224.8,                last time consumption/overall running time: 113.98s / 52347.22 s
first_0:                 episode reward: -99.2000,                 loss: nan
second_0:                 episode reward: 99.2000,                 loss: 0.0360
Episode: 8601/10000 (86.0100%),                 avg. length: 216.15,                last time consumption/overall running time: 109.77s / 52456.99 s
first_0:                 episode reward: -96.3500,                 loss: nan
second_0:                 episode reward: 96.3500,                 loss: 0.0371
Episode: 8621/10000 (86.2100%),                 avg. length: 214.5,                last time consumption/overall running time: 108.55s / 52565.55 s
first_0:                 episode reward: -99.9000,                 loss: nan
second_0:                 episode reward: 99.9000,                 loss: 0.0354
Episode: 8641/10000 (86.4100%),                 avg. length: 223.5,                last time consumption/overall running time: 113.98s / 52679.53 s
first_0:                 episode reward: -83.2000,                 loss: nan
second_0:                 episode reward: 83.2000,                 loss: 0.0355
Episode: 8661/10000 (86.6100%),                 avg. length: 217.85,                last time consumption/overall running time: 109.28s / 52788.81 s
first_0:                 episode reward: -99.6000,                 loss: nan
second_0:                 episode reward: 99.6000,                 loss: 0.0331
Episode: 8681/10000 (86.8100%),                 avg. length: 213.75,                last time consumption/overall running time: 108.80s / 52897.61 s
first_0:                 episode reward: -99.9000,                 loss: nan
second_0:                 episode reward: 99.9000,                 loss: 0.0336
Episode: 8701/10000 (87.0100%),                 avg. length: 212.6,                last time consumption/overall running time: 107.39s / 53005.00 s
first_0:                 episode reward: -99.8000,                 loss: nan
second_0:                 episode reward: 99.8000,                 loss: 0.0339
Episode: 8721/10000 (87.2100%),                 avg. length: 226.8,                last time consumption/overall running time: 115.40s / 53120.40 s
first_0:                 episode reward: -85.3500,                 loss: nan
second_0:                 episode reward: 85.3500,                 loss: 0.0332
Episode: 8741/10000 (87.4100%),                 avg. length: 232.5,                last time consumption/overall running time: 117.22s / 53237.61 s
first_0:                 episode reward: -88.0000,                 loss: nan
second_0:                 episode reward: 88.0000,                 loss: 0.0326
Episode: 8761/10000 (87.6100%),                 avg. length: 216.35,                last time consumption/overall running time: 109.12s / 53346.74 s
first_0:                 episode reward: -98.2000,                 loss: nan
second_0:                 episode reward: 98.2000,                 loss: 0.0333
Episode: 8781/10000 (87.8100%),                 avg. length: 213.4,                last time consumption/overall running time: 108.65s / 53455.38 s
first_0:                 episode reward: -99.7500,                 loss: nan
second_0:                 episode reward: 99.7500,                 loss: 0.0330
Episode: 8801/10000 (88.0100%),                 avg. length: 211.7,                last time consumption/overall running time: 106.54s / 53561.92 s
first_0:                 episode reward: -99.7500,                 loss: nan
second_0:                 episode reward: 99.7500,                 loss: 0.0341
Episode: 8821/10000 (88.2100%),                 avg. length: 216.65,                last time consumption/overall running time: 109.80s / 53671.72 s
first_0:                 episode reward: -99.9000,                 loss: nan
second_0:                 episode reward: 99.9000,                 loss: 0.0332
Episode: 8841/10000 (88.4100%),                 avg. length: 212.3,                last time consumption/overall running time: 107.26s / 53778.98 s
first_0:                 episode reward: -99.9000,                 loss: nan
second_0:                 episode reward: 99.9000,                 loss: 0.0341
Episode: 8861/10000 (88.6100%),                 avg. length: 220.65,                last time consumption/overall running time: 112.61s / 53891.59 s
first_0:                 episode reward: -92.8500,                 loss: nan
second_0:                 episode reward: 92.8500,                 loss: 0.0345
Episode: 8881/10000 (88.8100%),                 avg. length: 217.05,                last time consumption/overall running time: 110.49s / 54002.08 s
first_0:                 episode reward: -99.6000,                 loss: nan
second_0:                 episode reward: 99.6000,                 loss: 0.0342
Episode: 8901/10000 (89.0100%),                 avg. length: 226.8,                last time consumption/overall running time: 115.59s / 54117.67 s
first_0:                 episode reward: -97.2000,                 loss: nan
second_0:                 episode reward: 97.2000,                 loss: 0.0351
Episode: 8921/10000 (89.2100%),                 avg. length: 213.65,                last time consumption/overall running time: 108.56s / 54226.23 s
first_0:                 episode reward: -99.7000,                 loss: nan
second_0:                 episode reward: 99.7000,                 loss: 0.0344
Episode: 8941/10000 (89.4100%),                 avg. length: 220.45,                last time consumption/overall running time: 112.06s / 54338.29 s
first_0:                 episode reward: -91.2000,                 loss: nan
second_0:                 episode reward: 91.2000,                 loss: 0.0342
Episode: 8961/10000 (89.6100%),                 avg. length: 208.85,                last time consumption/overall running time: 106.63s / 54444.92 s
first_0:                 episode reward: -100.0000,                 loss: nan
second_0:                 episode reward: 100.0000,                 loss: 0.0341
Episode: 8981/10000 (89.8100%),                 avg. length: 217.75,                last time consumption/overall running time: 110.14s / 54555.05 s
first_0:                 episode reward: -99.7000,                 loss: nan
second_0:                 episode reward: 99.7000,                 loss: 0.0347
Episode: 9001/10000 (90.0100%),                 avg. length: 210.8,                last time consumption/overall running time: 107.02s / 54662.07 s
first_0:                 episode reward: -99.8000,                 loss: nan
second_0:                 episode reward: 99.8000,                 loss: 0.0343
Episode: 9021/10000 (90.2100%),                 avg. length: 228.65,                last time consumption/overall running time: 116.35s / 54778.43 s
first_0:                 episode reward: -94.4000,                 loss: nan
second_0:                 episode reward: 94.4000,                 loss: 0.0341
Episode: 9041/10000 (90.4100%),                 avg. length: 219.8,                last time consumption/overall running time: 112.02s / 54890.44 s
first_0:                 episode reward: -99.3500,                 loss: nan
second_0:                 episode reward: 99.3500,                 loss: 0.0349
Episode: 9061/10000 (90.6100%),                 avg. length: 212.8,                last time consumption/overall running time: 107.99s / 54998.43 s
first_0:                 episode reward: -99.9500,                 loss: nan
second_0:                 episode reward: 99.9500,                 loss: 0.0345
Episode: 9081/10000 (90.8100%),                 avg. length: 212.2,                last time consumption/overall running time: 107.72s / 55106.16 s
first_0:                 episode reward: -91.3000,                 loss: nan
second_0:                 episode reward: 91.3000,                 loss: 0.0346
Episode: 9101/10000 (91.0100%),                 avg. length: 214.65,                last time consumption/overall running time: 109.08s / 55215.24 s
first_0:                 episode reward: -99.7000,                 loss: nan
second_0:                 episode reward: 99.7000,                 loss: 0.0351
Episode: 9121/10000 (91.2100%),                 avg. length: 223.0,                last time consumption/overall running time: 113.66s / 55328.90 s
first_0:                 episode reward: -99.2000,                 loss: nan
second_0:                 episode reward: 99.2000,                 loss: 0.0363
Episode: 9141/10000 (91.4100%),                 avg. length: 214.6,                last time consumption/overall running time: 108.74s / 55437.64 s
first_0:                 episode reward: -99.7500,                 loss: nan
second_0:                 episode reward: 99.7500,                 loss: 0.0348
Episode: 9161/10000 (91.6100%),                 avg. length: 215.15,                last time consumption/overall running time: 110.23s / 55547.87 s
first_0:                 episode reward: -99.5500,                 loss: nan
second_0:                 episode reward: 99.5500,                 loss: 0.0341
Episode: 9181/10000 (91.8100%),                 avg. length: 217.15,                last time consumption/overall running time: 110.78s / 55658.65 s
first_0:                 episode reward: -91.0000,                 loss: nan
second_0:                 episode reward: 91.0000,                 loss: 0.0362
Episode: 9201/10000 (92.0100%),                 avg. length: 214.75,                last time consumption/overall running time: 109.91s / 55768.56 s
first_0:                 episode reward: -99.8500,                 loss: nan
second_0:                 episode reward: 99.8500,                 loss: 0.0381
Episode: 9221/10000 (92.2100%),                 avg. length: 211.95,                last time consumption/overall running time: 108.43s / 55877.00 s
first_0:                 episode reward: -100.0000,                 loss: nan
second_0:                 episode reward: 100.0000,                 loss: 0.0372
Episode: 9241/10000 (92.4100%),                 avg. length: 215.6,                last time consumption/overall running time: 110.23s / 55987.23 s
first_0:                 episode reward: -90.0000,                 loss: nan
second_0:                 episode reward: 90.0000,                 loss: 0.0378
Episode: 9261/10000 (92.6100%),                 avg. length: 213.05,                last time consumption/overall running time: 109.34s / 56096.57 s
first_0:                 episode reward: -99.8000,                 loss: nan
second_0:                 episode reward: 99.8000,                 loss: 0.0360
Episode: 9281/10000 (92.8100%),                 avg. length: 218.5,                last time consumption/overall running time: 111.81s / 56208.37 s
first_0:                 episode reward: -97.4500,                 loss: nan
second_0:                 episode reward: 97.4500,                 loss: 0.0360
Episode: 9301/10000 (93.0100%),                 avg. length: 212.9,                last time consumption/overall running time: 102.68s / 56311.06 s
first_0:                 episode reward: -100.0000,                 loss: nan
second_0:                 episode reward: 100.0000,                 loss: 0.0365
Episode: 9321/10000 (93.2100%),                 avg. length: 212.2,                last time consumption/overall running time: 102.42s / 56413.48 s
first_0:                 episode reward: -90.0500,                 loss: nan
second_0:                 episode reward: 90.0500,                 loss: 0.0357
Episode: 9341/10000 (93.4100%),                 avg. length: 209.7,                last time consumption/overall running time: 101.08s / 56514.56 s
first_0:                 episode reward: -100.0000,                 loss: nan
second_0:                 episode reward: 100.0000,                 loss: 0.0363
Episode: 9361/10000 (93.6100%),                 avg. length: 218.1,                last time consumption/overall running time: 105.15s / 56619.71 s
first_0:                 episode reward: -96.5500,                 loss: nan
second_0:                 episode reward: 96.5500,                 loss: 0.0359
Episode: 9381/10000 (93.8100%),                 avg. length: 221.8,                last time consumption/overall running time: 106.95s / 56726.66 s
first_0:                 episode reward: -86.1500,                 loss: nan
second_0:                 episode reward: 86.1500,                 loss: 0.0358
Episode: 9401/10000 (94.0100%),                 avg. length: 212.25,                last time consumption/overall running time: 102.68s / 56829.34 s
first_0:                 episode reward: -100.0000,                 loss: nan
second_0:                 episode reward: 100.0000,                 loss: 0.0359
Episode: 9421/10000 (94.2100%),                 avg. length: 219.7,                last time consumption/overall running time: 106.42s / 56935.76 s
first_0:                 episode reward: -91.1000,                 loss: nan
second_0:                 episode reward: 91.1000,                 loss: 0.0363
Episode: 9441/10000 (94.4100%),                 avg. length: 217.8,                last time consumption/overall running time: 105.41s / 57041.18 s
first_0:                 episode reward: -99.2000,                 loss: nan
second_0:                 episode reward: 99.2000,                 loss: 0.0345
Episode: 9461/10000 (94.6100%),                 avg. length: 219.9,                last time consumption/overall running time: 106.08s / 57147.25 s
first_0:                 episode reward: -98.7000,                 loss: nan
second_0:                 episode reward: 98.7000,                 loss: 0.0348
Episode: 9481/10000 (94.8100%),                 avg. length: 216.35,                last time consumption/overall running time: 104.79s / 57252.05 s
first_0:                 episode reward: -97.3000,                 loss: nan
second_0:                 episode reward: 97.3000,                 loss: 0.0332
Episode: 9501/10000 (95.0100%),                 avg. length: 212.8,                last time consumption/overall running time: 103.02s / 57355.07 s
first_0:                 episode reward: -99.7500,                 loss: nan
second_0:                 episode reward: 99.7500,                 loss: 0.0346
Episode: 9521/10000 (95.2100%),                 avg. length: 213.35,                last time consumption/overall running time: 103.05s / 57458.12 s
first_0:                 episode reward: -99.9000,                 loss: nan
second_0:                 episode reward: 99.9000,                 loss: 0.0355
Episode: 9541/10000 (95.4100%),                 avg. length: 211.35,                last time consumption/overall running time: 102.41s / 57560.52 s
first_0:                 episode reward: -99.9000,                 loss: nan
second_0:                 episode reward: 99.9000,                 loss: 0.0343
Episode: 9561/10000 (95.6100%),                 avg. length: 222.4,                last time consumption/overall running time: 107.49s / 57668.01 s
first_0:                 episode reward: -91.2000,                 loss: nan
second_0:                 episode reward: 91.2000,                 loss: 0.0357
Episode: 9581/10000 (95.8100%),                 avg. length: 227.7,                last time consumption/overall running time: 110.57s / 57778.58 s
first_0:                 episode reward: -90.7500,                 loss: nan
second_0:                 episode reward: 90.7500,                 loss: 0.0362
Episode: 9601/10000 (96.0100%),                 avg. length: 221.95,                last time consumption/overall running time: 107.94s / 57886.52 s
first_0:                 episode reward: -84.1000,                 loss: nan
second_0:                 episode reward: 84.1000,                 loss: 0.0345
Episode: 9621/10000 (96.2100%),                 avg. length: 223.45,                last time consumption/overall running time: 108.32s / 57994.84 s
first_0:                 episode reward: -94.2000,                 loss: nan
second_0:                 episode reward: 94.2000,                 loss: 0.0353
Episode: 9641/10000 (96.4100%),                 avg. length: 215.9,                last time consumption/overall running time: 104.32s / 58099.17 s
first_0:                 episode reward: -99.3000,                 loss: nan
second_0:                 episode reward: 99.3000,                 loss: 0.0338
Episode: 9661/10000 (96.6100%),                 avg. length: 227.85,                last time consumption/overall running time: 110.01s / 58209.18 s
first_0:                 episode reward: -95.3500,                 loss: nan
second_0:                 episode reward: 95.3500,                 loss: 0.0357
Episode: 9681/10000 (96.8100%),                 avg. length: 218.75,                last time consumption/overall running time: 106.39s / 58315.57 s
first_0:                 episode reward: -98.0000,                 loss: nan
second_0:                 episode reward: 98.0000,                 loss: 0.0337
Episode: 9701/10000 (97.0100%),                 avg. length: 211.75,                last time consumption/overall running time: 102.13s / 58417.70 s
first_0:                 episode reward: -89.9000,                 loss: nan
second_0:                 episode reward: 89.9000,                 loss: 0.0338
Episode: 9721/10000 (97.2100%),                 avg. length: 220.9,                last time consumption/overall running time: 106.72s / 58524.42 s
first_0:                 episode reward: -99.3500,                 loss: nan
second_0:                 episode reward: 99.3500,                 loss: 0.0332
Episode: 9741/10000 (97.4100%),                 avg. length: 218.3,                last time consumption/overall running time: 105.15s / 58629.57 s
first_0:                 episode reward: -99.6000,                 loss: nan
second_0:                 episode reward: 99.6000,                 loss: 0.0328
Episode: 9761/10000 (97.6100%),                 avg. length: 213.6,                last time consumption/overall running time: 102.88s / 58732.45 s
first_0:                 episode reward: -99.5000,                 loss: nan
second_0:                 episode reward: 99.5000,                 loss: 0.0329
Episode: 9781/10000 (97.8100%),                 avg. length: 212.6,                last time consumption/overall running time: 102.73s / 58835.18 s
first_0:                 episode reward: -99.6000,                 loss: nan
second_0:                 episode reward: 99.6000,                 loss: 0.0328
Episode: 9801/10000 (98.0100%),                 avg. length: 212.3,                last time consumption/overall running time: 102.49s / 58937.67 s
first_0:                 episode reward: -99.8500,                 loss: nan
second_0:                 episode reward: 99.8500,                 loss: 0.0326
Episode: 9821/10000 (98.2100%),                 avg. length: 227.7,                last time consumption/overall running time: 109.76s / 59047.43 s
first_0:                 episode reward: -86.5500,                 loss: nan
second_0:                 episode reward: 86.5500,                 loss: 0.0312
Episode: 9841/10000 (98.4100%),                 avg. length: 219.15,                last time consumption/overall running time: 105.81s / 59153.24 s
first_0:                 episode reward: -90.0500,                 loss: nan
second_0:                 episode reward: 90.0500,                 loss: 0.0316
Episode: 9861/10000 (98.6100%),                 avg. length: 228.8,                last time consumption/overall running time: 110.64s / 59263.88 s
first_0:                 episode reward: -94.9000,                 loss: nan
second_0:                 episode reward: 94.9000,                 loss: 0.0328
Episode: 9881/10000 (98.8100%),                 avg. length: 220.3,                last time consumption/overall running time: 106.34s / 59370.22 s
first_0:                 episode reward: -99.1000,                 loss: nan
second_0:                 episode reward: 99.1000,                 loss: 0.0327
Episode: 9901/10000 (99.0100%),                 avg. length: 216.75,                last time consumption/overall running time: 104.79s / 59475.01 s
first_0:                 episode reward: -89.1500,                 loss: nan
second_0:                 episode reward: 89.1500,                 loss: 0.0341
Episode: 9921/10000 (99.2100%),                 avg. length: 216.0,                last time consumption/overall running time: 101.21s / 59576.22 s
first_0:                 episode reward: -98.9000,                 loss: nan
second_0:                 episode reward: 98.9000,                 loss: 0.0336
Episode: 9941/10000 (99.4100%),                 avg. length: 216.1,                last time consumption/overall running time: 92.81s / 59669.03 s
first_0:                 episode reward: -99.6500,                 loss: nan/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/pettingzoo/utils/conversions.py:87: UserWarning: The `observation_spaces` dictionary is deprecated. Use the `observation_space` function instead.
  "The `observation_spaces` dictionary is deprecated. Use the `observation_space` function instead."
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/pettingzoo/utils/conversions.py:101: UserWarning: The `action_spaces` dictionary is deprecated. Use the `action_space` function instead.
  "The `action_spaces` dictionary is deprecated. Use the `action_space` function instead."
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

second_0:                 episode reward: 99.6500,                 loss: 0.0344
Episode: 9961/10000 (99.6100%),                 avg. length: 214.8,                last time consumption/overall running time: 91.59s / 59760.62 s
first_0:                 episode reward: -99.5500,                 loss: nan
second_0:                 episode reward: 99.5500,                 loss: 0.0340
Episode: 9981/10000 (99.8100%),                 avg. length: 221.0,                last time consumption/overall running time: 94.53s / 59855.15 s
first_0:                 episode reward: -99.4500,                 loss: nan
second_0:                 episode reward: 99.4500,                 loss: 0.0341
