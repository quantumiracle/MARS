env_args:
  env_name: RoboSumo-Ant-vs-Ant-v0
  env_type: robosumo
  num_envs: 1
  ram: true
  seed: random
agent_args:
  algorithm: NashPPO
  algorithm_spec:
    episodic_update: true
    gamma: 0.99
    lambda: 0.95
    eps_clip: 0.2
    K_epoch: 4
    GAE: true
    max_grad_norm: 0.5
    entropy_coeff: 0.01
    vf_coeff: 0.5
    policy_loss_coeff: 0.08
train_args:
  batch_size: 128
  max_episodes: 10000
  max_steps_per_episode: 300
  train_start_frame: 0
  optimizer: adam
  learning_rate: 1e-4
  device: gpu
  update_itr: 1
  log_avg_window: 20
  log_interval: 20
  multiprocess: false
  net_architecture:
    feature:
      hidden_dim_list:
      - 2
      - 2
      hidden_activation: ReLU
      output_activation: false
    policy:
      hidden_dim_list:
      - 2
      - 2
      hidden_activation: ReLU
      output_activation: Tanh  # for continuous env, action range -1, 1
    value:
      hidden_dim_list:
      - 2
      - 2
      hidden_activation: ReLU
      output_activation: false
  marl_method: nash_ppo
  marl_spec:
    global_state: true
