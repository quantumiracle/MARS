/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/pettingzoo/utils/conversions.py:87: UserWarning: The `observation_spaces` dictionary is deprecated. Use the `observation_space` function instead.
  "The `observation_spaces` dictionary is deprecated. Use the `observation_space` function instead."
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/pettingzoo/utils/conversions.py:101: UserWarning: The `action_spaces` dictionary is deprecated. Use the `action_space` function instead.
  "The `action_spaces` dictionary is deprecated. Use the `action_space` function instead."
pettingzoo_boxing_v2
default:  {'env_name': 'boxing_v2', 'env_type': 'pettingzoo', 'num_envs': 5, 'ram': True, 'seed': 'random', 'record_video': False, 'algorithm': 'NashDQNExploiter', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 1000000, 'exploiter_update_itr': 3}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'save_id': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'wandb_activate': False, 'wandb_entity': '', 'wandb_project': '', 'wandb_group': '', 'wandb_name': '', 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn_exploiter', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}}
{'env_name': 'boxing_v2', 'env_type': 'pettingzoo', 'num_envs': 5, 'ram': True, 'seed': 'random', 'record_video': False, 'algorithm': 'NashDQNExploiter', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 1000000, 'exploiter_update_itr': 3}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'save_id': 202209252250, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'wandb_activate': False, 'wandb_entity': '', 'wandb_project': '', 'wandb_group': '', 'wandb_name': '', 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn_exploiter', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}, 'load_id': 202209201541, 'to_exploit': 'second_2'}
boxing_v2 pettingzoo
record video: interval 100, length 300
Load boxing_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
random seed: 157
<mars.env.wrappers.mars_wrappers.Dict2TupleWrapper object at 0x7f1af5edfd68>
discrete_policy 18 Discrete(18)
Traceback (most recent call last):
  File "general_exploit.py", line 48, in <module>
    launch()
  File "general_exploit.py", line 30, in launch
    trained_model = eval(args.algorithm)(env, args)
  File "/data/zihan/research/MARS/mars/rl/agents/nash_dqn_exploiter.py", line 20, in __init__
    super().__init__(env, args)
  File "/data/zihan/research/MARS/mars/rl/agents/dqn.py", line 19, in __init__
    self._init_model(env, args)
  File "/data/zihan/research/MARS/mars/rl/agents/nash_dqn_exploiter.py", line 38, in _init_model
    self.normal_nashQ = NashDQNBase(env, args.net_architecture, args.num_envs, two_side_obs = args.marl_spec['global_state']).to(self.device)
  File "/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/pettingzoo/utils/conversions.py:87: UserWarning: The `observation_spaces` dictionary is deprecated. Use the `observation_space` function instead.
  "The `observation_spaces` dictionary is deprecated. Use the `observation_space` function instead."
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/pettingzoo/utils/conversions.py:101: UserWarning: The `action_spaces` dictionary is deprecated. Use the `action_space` function instead.
  "The `action_spaces` dictionary is deprecated. Use the `action_space` function instead."
pettingzoo_boxing_v2
default:  {'env_name': 'boxing_v2', 'env_type': 'pettingzoo', 'num_envs': 5, 'ram': True, 'seed': 'random', 'record_video': False, 'algorithm': 'NashDQNExploiter', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 1000000, 'exploiter_update_itr': 3}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'save_id': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'wandb_activate': False, 'wandb_entity': '', 'wandb_project': '', 'wandb_group': '', 'wandb_name': '', 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn_exploiter', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}}
{'env_name': 'boxing_v2', 'env_type': 'pettingzoo', 'num_envs': 5, 'ram': True, 'seed': 'random', 'record_video': False, 'algorithm': 'NashDQNExploiter', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 1000000, 'exploiter_update_itr': 3}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'save_id': 202209270006, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'wandb_activate': False, 'wandb_entity': '', 'wandb_project': '', 'wandb_group': '', 'wandb_name': '', 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn_exploiter', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}, 'load_id': 202209201541, 'to_exploit': 'second_2'}
boxing_v2 pettingzoo
record video: interval 100, length 300
Load boxing_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
random seed: 724
<mars.env.wrappers.mars_wrappers.Dict2TupleWrapper object at 0x7fe21bdd3d30>
discrete_policy 18 Discrete(18)
Traceback (most recent call last):
  File "general_exploit.py", line 48, in <module>
    launch()
  File "general_exploit.py", line 30, in launch
    trained_model = eval(args.algorithm)(env, args)
  File "/data/zihan/research/MARS/mars/rl/agents/nash_dqn_exploiter.py", line 20, in __init__
    super().__init__(env, args)
  File "/data/zihan/research/MARS/mars/rl/agents/dqn.py", line 19, in __init__
    self._init_model(env, args)
  File "/data/zihan/research/MARS/mars/rl/agents/nash_dqn_exploiter.py", line 38, in _init_model
    self.normal_nashQ = NashDQNBase(env, args.net_architecture, args.num_envs, two_side_obs = args.marl_spec['global_state']).to(self.device)
  File "/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
pettingzoo_boxing_v2
default:  {'env_name': 'boxing_v2', 'env_type': 'pettingzoo', 'num_envs': 5, 'ram': True, 'seed': 'random', 'record_video': False, 'algorithm': 'NashDQNExploiter', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 1000000, 'exploiter_update_itr': 3}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'save_id': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'wandb_activate': False, 'wandb_entity': '', 'wandb_project': '', 'wandb_group': '', 'wandb_name': '', 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn_exploiter', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}}
{'env_name': 'boxing_v2', 'env_type': 'pettingzoo', 'num_envs': 5, 'ram': True, 'seed': 'random', 'record_video': False, 'algorithm': 'NashDQNExploiter', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 1000000, 'exploiter_update_itr': 3}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'save_id': 202209270240, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'wandb_activate': False, 'wandb_entity': '', 'wandb_project': '', 'wandb_group': '', 'wandb_name': '', 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn_exploiter', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}, 'load_id': 202209201541, 'to_exploit': 'second_2'}
boxing_v2 pettingzoo
record video: interval 100, length 300
Load boxing_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
random seed: 119
<mars.env.wrappers.mars_wrappers.Dict2TupleWrapper object at 0x7ffaf6adbd68>
discrete_policy 18 Discrete(18)
discrete_policy 18 Discrete(18)
discrete_policy 18 Discrete(18)
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  ./data/model/202209201541/pettingzoo_boxing_v2_nash_dqn_exploiter/8000_0
Arguments:  {'env_name': 'boxing_v2', 'env_type': 'pettingzoo', 'num_envs': 1, 'ram': True, 'seed': 'random', 'record_video': False, 'algorithm': 'NashDQNExploiter', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 100000, 'exploiter_update_itr': 3}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'save_id': 202209270240, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': './data/model/202209201541/pettingzoo_boxing_v2_nash_dqn_exploiter/8000_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'wandb_activate': False, 'wandb_entity': '', 'wandb_project': '', 'wandb_group': '', 'wandb_name': '', 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn_exploiter', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}, 'load_id': 202209201541, 'to_exploit': 'second_2', 'against_baseline': False, 'idx_exploited_model': 0}
Save models to : /data/zihan/research/MARS/data/model/202209201541_exploit_first/pettingzoo_boxing_v2_nash_dqn_exploiter. 
 Save logs to: /data/zihan/research/MARS/data/log/202209201541_exploit_first/pettingzoo_boxing_v2_nash_dqn_exploiter.
Episode: 1/10000 (0.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 9.71s / 9.71 s
first_0:                 episode reward: 88.0000,                 loss: nan
second_0:                 episode reward: -88.0000,                 loss: 0.9601
Episode: 21/10000 (0.2100%),                 avg. length: 289.9,                last time consumption/overall running time: 142.49s / 152.20 s
first_0:                 episode reward: 87.6000,                 loss: nan
second_0:                 episode reward: -87.6000,                 loss: 0.1620
Episode: 41/10000 (0.4100%),                 avg. length: 287.9,                last time consumption/overall running time: 145.91s / 298.12 s
first_0:                 episode reward: 92.8000,                 loss: nan
second_0:                 episode reward: -92.8000,                 loss: 0.0970
Episode: 61/10000 (0.6100%),                 avg. length: 286.55,                last time consumption/overall running time: 146.54s / 444.66 s
first_0:                 episode reward: 94.8500,                 loss: nan
second_0:                 episode reward: -94.8500,                 loss: 0.0932
Episode: 81/10000 (0.8100%),                 avg. length: 287.2,                last time consumption/overall running time: 146.41s / 591.06 s
first_0:                 episode reward: 93.6500,                 loss: nan
second_0:                 episode reward: -93.6500,                 loss: 0.0813
Episode: 101/10000 (1.0100%),                 avg. length: 291.0,                last time consumption/overall running time: 150.65s / 741.72 s
first_0:                 episode reward: 87.0000,                 loss: nan
second_0:                 episode reward: -87.0000,                 loss: 0.0766
Episode: 121/10000 (1.2100%),                 avg. length: 287.8,                last time consumption/overall running time: 149.66s / 891.37 s
first_0:                 episode reward: 85.4000,                 loss: nan
second_0:                 episode reward: -85.4000,                 loss: 0.0706
Episode: 141/10000 (1.4100%),                 avg. length: 292.25,                last time consumption/overall running time: 152.79s / 1044.17 s
first_0:                 episode reward: 82.1000,                 loss: nan
second_0:                 episode reward: -82.1000,                 loss: 0.0685
Episode: 161/10000 (1.6100%),                 avg. length: 295.95,                last time consumption/overall running time: 155.14s / 1199.31 s
first_0:                 episode reward: 62.6500,                 loss: nan
second_0:                 episode reward: -62.6500,                 loss: 0.0624
Episode: 181/10000 (1.8100%),                 avg. length: 295.2,                last time consumption/overall running time: 153.52s / 1352.83 s
first_0:                 episode reward: 61.4500,                 loss: nan
second_0:                 episode reward: -61.4500,                 loss: 0.0593
Episode: 201/10000 (2.0100%),                 avg. length: 295.1,                last time consumption/overall running time: 154.97s / 1507.80 s
first_0:                 episode reward: 58.6500,                 loss: nan
second_0:                 episode reward: -58.6500,                 loss: 0.0571
Episode: 221/10000 (2.2100%),                 avg. length: 294.5,                last time consumption/overall running time: 155.39s / 1663.19 s
first_0:                 episode reward: 57.1500,                 loss: nan
second_0:                 episode reward: -57.1500,                 loss: 0.0531
Episode: 241/10000 (2.4100%),                 avg. length: 292.6,                last time consumption/overall running time: 153.12s / 1816.31 s
first_0:                 episode reward: 58.5500,                 loss: nan
second_0:                 episode reward: -58.5500,                 loss: 0.0525
Episode: 261/10000 (2.6100%),                 avg. length: 296.95,                last time consumption/overall running time: 158.17s / 1974.48 s
first_0:                 episode reward: 52.7500,                 loss: nan
second_0:                 episode reward: -52.7500,                 loss: 0.0506
Episode: 281/10000 (2.8100%),                 avg. length: 294.4,                last time consumption/overall running time: 155.62s / 2130.10 s
first_0:                 episode reward: 49.4500,                 loss: nan
second_0:                 episode reward: -49.4500,                 loss: 0.0503
Episode: 301/10000 (3.0100%),                 avg. length: 295.95,                last time consumption/overall running time: 158.84s / 2288.94 s
first_0:                 episode reward: 34.9000,                 loss: nan
second_0:                 episode reward: -34.9000,                 loss: 0.0479
Episode: 321/10000 (3.2100%),                 avg. length: 295.1,                last time consumption/overall running time: 157.21s / 2446.15 s
first_0:                 episode reward: 47.0000,                 loss: nan
second_0:                 episode reward: -47.0000,                 loss: 0.0475
Episode: 341/10000 (3.4100%),                 avg. length: 298.1,                last time consumption/overall running time: 159.11s / 2605.27 s
first_0:                 episode reward: 25.6500,                 loss: nan
second_0:                 episode reward: -25.6500,                 loss: 0.0493
Episode: 361/10000 (3.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 160.55s / 2765.81 s
first_0:                 episode reward: 32.9000,                 loss: nan
second_0:                 episode reward: -32.9000,                 loss: 0.0471
Episode: 381/10000 (3.8100%),                 avg. length: 296.0,                last time consumption/overall running time: 159.80s / 2925.61 s
first_0:                 episode reward: 27.8500,                 loss: nan
second_0:                 episode reward: -27.8500,                 loss: 0.0443
Episode: 401/10000 (4.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 161.24s / 3086.85 s
first_0:                 episode reward: 14.7000,                 loss: nan
second_0:                 episode reward: -14.7000,                 loss: 0.0452
Episode: 421/10000 (4.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 160.50s / 3247.36 s
first_0:                 episode reward: 13.0500,                 loss: nan
second_0:                 episode reward: -13.0500,                 loss: 0.0429
Episode: 441/10000 (4.4100%),                 avg. length: 298.25,                last time consumption/overall running time: 160.00s / 3407.36 s
first_0:                 episode reward: 12.0500,                 loss: nan
second_0:                 episode reward: -12.0500,                 loss: 0.0460
Episode: 461/10000 (4.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 162.34s / 3569.71 s
first_0:                 episode reward: 9.5000,                 loss: nan
second_0:                 episode reward: -9.5000,                 loss: 0.0449
Episode: 481/10000 (4.8100%),                 avg. length: 297.9,                last time consumption/overall running time: 160.03s / 3729.74 s
first_0:                 episode reward: 21.5500,                 loss: nan
second_0:                 episode reward: -21.5500,                 loss: 0.0446
Episode: 501/10000 (5.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 163.02s / 3892.76 s
first_0:                 episode reward: 6.8000,                 loss: nan
second_0:                 episode reward: -6.8000,                 loss: 0.0430
Episode: 521/10000 (5.2100%),                 avg. length: 296.65,                last time consumption/overall running time: 159.81s / 4052.57 s
first_0:                 episode reward: 8.7000,                 loss: nan
second_0:                 episode reward: -8.7000,                 loss: 0.0441
Episode: 541/10000 (5.4100%),                 avg. length: 297.1,                last time consumption/overall running time: 160.94s / 4213.51 s
first_0:                 episode reward: 11.9000,                 loss: nan
second_0:                 episode reward: -11.9000,                 loss: 0.0430
Episode: 561/10000 (5.6100%),                 avg. length: 297.1,                last time consumption/overall running time: 162.83s / 4376.34 s
first_0:                 episode reward: 16.7000,                 loss: nan
second_0:                 episode reward: -16.7000,                 loss: 0.0468
Episode: 581/10000 (5.8100%),                 avg. length: 296.75,                last time consumption/overall running time: 161.67s / 4538.02 s
first_0:                 episode reward: 12.8500,                 loss: nan
second_0:                 episode reward: -12.8500,                 loss: 0.0454
Episode: 601/10000 (6.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 162.34s / 4700.36 s
first_0:                 episode reward: 2.7000,                 loss: nan
second_0:                 episode reward: -2.7000,                 loss: 0.0449
Episode: 621/10000 (6.2100%),                 avg. length: 296.65,                last time consumption/overall running time: 161.37s / 4861.73 s
first_0:                 episode reward: 11.3000,                 loss: nan
second_0:                 episode reward: -11.3000,                 loss: 0.0495
Episode: 641/10000 (6.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 162.89s / 5024.62 s
first_0:                 episode reward: 7.1500,                 loss: nan
second_0:                 episode reward: -7.1500,                 loss: 0.0493
Episode: 661/10000 (6.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.48s / 5189.10 s
first_0:                 episode reward: 8.3000,                 loss: nan
second_0:                 episode reward: -8.3000,                 loss: 0.0546
Episode: 681/10000 (6.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 163.41s / 5352.51 s
first_0:                 episode reward: 8.2000,                 loss: nan
second_0:                 episode reward: -8.2000,                 loss: 0.0549
Episode: 701/10000 (7.0100%),                 avg. length: 297.65,                last time consumption/overall running time: 162.34s / 5514.85 s
first_0:                 episode reward: 8.6500,                 loss: nan
second_0:                 episode reward: -8.6500,                 loss: 0.0578
Episode: 721/10000 (7.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 162.96s / 5677.80 s
first_0:                 episode reward: 8.1500,                 loss: nan
second_0:                 episode reward: -8.1500,                 loss: 0.0651
Episode: 741/10000 (7.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.48s / 5842.28 s
first_0:                 episode reward: 8.2000,                 loss: nan
second_0:                 episode reward: -8.2000,                 loss: 0.0624
Episode: 761/10000 (7.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 163.77s / 6006.05 s
first_0:                 episode reward: 2.1000,                 loss: nan
second_0:                 episode reward: -2.1000,                 loss: 0.0629
Episode: 781/10000 (7.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 163.91s / 6169.96 s
first_0:                 episode reward: 1.8000,                 loss: nan
second_0:                 episode reward: -1.8000,                 loss: 0.0609
Episode: 801/10000 (8.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 163.98s / 6333.94 s
first_0:                 episode reward: 7.7000,                 loss: nan
second_0:                 episode reward: -7.7000,                 loss: 0.0638
Episode: 821/10000 (8.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 163.16s / 6497.10 s
first_0:                 episode reward: 9.1000,                 loss: nan
second_0:                 episode reward: -9.1000,                 loss: 0.0713
Episode: 841/10000 (8.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 163.99s / 6661.09 s
first_0:                 episode reward: 3.1000,                 loss: nan
second_0:                 episode reward: -3.1000,                 loss: 0.0658
Episode: 861/10000 (8.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 163.00s / 6824.08 s
first_0:                 episode reward: 1.6000,                 loss: nan
second_0:                 episode reward: -1.6000,                 loss: 0.0715
Episode: 881/10000 (8.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 163.79s / 6987.87 s
first_0:                 episode reward: 0.5500,                 loss: nan
second_0:                 episode reward: -0.5500,                 loss: 0.0787
Episode: 901/10000 (9.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 162.70s / 7150.57 s
first_0:                 episode reward: 4.6000,                 loss: nan
second_0:                 episode reward: -4.6000,                 loss: 0.0822
Episode: 921/10000 (9.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 162.29s / 7312.86 s
first_0:                 episode reward: 3.4500,                 loss: nan
second_0:                 episode reward: -3.4500,                 loss: 0.0914
Episode: 941/10000 (9.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.48s / 7478.34 s
first_0:                 episode reward: 1.4500,                 loss: nan
second_0:                 episode reward: -1.4500,                 loss: 0.0928
Episode: 961/10000 (9.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.48s / 7642.82 s
first_0:                 episode reward: 3.1000,                 loss: nan
second_0:                 episode reward: -3.1000,                 loss: 0.1002
Episode: 981/10000 (9.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.82s / 7807.64 s
first_0:                 episode reward: 1.0500,                 loss: nan
second_0:                 episode reward: -1.0500,                 loss: 0.1043
Episode: 1001/10000 (10.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.16s / 7972.80 s
first_0:                 episode reward: 3.4000,                 loss: nan
second_0:                 episode reward: -3.4000,                 loss: 0.1009
Episode: 1021/10000 (10.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 163.58s / 8136.37 s
first_0:                 episode reward: 2.0000,                 loss: nan
second_0:                 episode reward: -2.0000,                 loss: 0.1004
Episode: 1041/10000 (10.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 163.38s / 8299.75 s
first_0:                 episode reward: 0.7000,                 loss: nan
second_0:                 episode reward: -0.7000,                 loss: 0.1096
Episode: 1061/10000 (10.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.28s / 8464.03 s
first_0:                 episode reward: 6.3500,                 loss: nan
second_0:                 episode reward: -6.3500,                 loss: 0.1186
Episode: 1081/10000 (10.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.78s / 8629.82 s
first_0:                 episode reward: 11.2500,                 loss: nan
second_0:                 episode reward: -11.2500,                 loss: 0.1131
Episode: 1101/10000 (11.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 163.82s / 8793.64 s
first_0:                 episode reward: 2.7500,                 loss: nan
second_0:                 episode reward: -2.7500,                 loss: 0.0905
Episode: 1121/10000 (11.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.88s / 8958.51 s
first_0:                 episode reward: 1.6500,                 loss: nan
second_0:                 episode reward: -1.6500,                 loss: 0.0722
Episode: 1141/10000 (11.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.13s / 9122.64 s
first_0:                 episode reward: 3.5000,                 loss: nan
second_0:                 episode reward: -3.5000,                 loss: 0.0672
Episode: 1161/10000 (11.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 163.98s / 9286.62 s
first_0:                 episode reward: 2.4000,                 loss: nan
second_0:                 episode reward: -2.4000,                 loss: 0.0600
Episode: 1181/10000 (11.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.92s / 9451.54 s
first_0:                 episode reward: 0.8000,                 loss: nan
second_0:                 episode reward: -0.8000,                 loss: 0.0555
Episode: 1201/10000 (12.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.33s / 9615.88 s
first_0:                 episode reward: 0.7000,                 loss: nan
second_0:                 episode reward: -0.7000,                 loss: 0.0613
Episode: 1221/10000 (12.2100%),                 avg. length: 296.75,                last time consumption/overall running time: 164.63s / 9780.51 s
first_0:                 episode reward: 6.1000,                 loss: nan
second_0:                 episode reward: -6.1000,                 loss: 0.0620
Episode: 1241/10000 (12.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.28s / 9945.79 s
first_0:                 episode reward: 0.9000,                 loss: nan
second_0:                 episode reward: -0.9000,                 loss: 0.0705
Episode: 1261/10000 (12.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.55s / 10111.34 s
first_0:                 episode reward: 0.7500,                 loss: nan
second_0:                 episode reward: -0.7500,                 loss: 0.0644
Episode: 1281/10000 (12.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.06s / 10276.40 s
first_0:                 episode reward: 1.1500,                 loss: nan
second_0:                 episode reward: -1.1500,                 loss: 0.0610
Episode: 1301/10000 (13.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.22s / 10440.62 s
first_0:                 episode reward: 1.7500,                 loss: nan
second_0:                 episode reward: -1.7500,                 loss: 0.0612
Episode: 1321/10000 (13.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.63s / 10605.24 s
first_0:                 episode reward: 1.2500,                 loss: nan
second_0:                 episode reward: -1.2500,                 loss: 0.0644
Episode: 1341/10000 (13.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.04s / 10769.28 s
first_0:                 episode reward: 5.3500,                 loss: nan
second_0:                 episode reward: -5.3500,                 loss: 0.0711
Episode: 1361/10000 (13.6100%),                 avg. length: 298.15,                last time consumption/overall running time: 164.84s / 10934.12 s
first_0:                 episode reward: 5.9000,                 loss: nan
second_0:                 episode reward: -5.9000,                 loss: 0.0780
Episode: 1381/10000 (13.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.28s / 11098.40 s
first_0:                 episode reward: 1.7000,                 loss: nan
second_0:                 episode reward: -1.7000,                 loss: 0.0901
Episode: 1401/10000 (14.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.53s / 11263.93 s
first_0:                 episode reward: 2.1500,                 loss: nan
second_0:                 episode reward: -2.1500,                 loss: 0.0926
Episode: 1421/10000 (14.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.48s / 11428.41 s
first_0:                 episode reward: 0.7000,                 loss: nan
second_0:                 episode reward: -0.7000,                 loss: 0.0986
Episode: 1441/10000 (14.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.63s / 11593.04 s
first_0:                 episode reward: 2.3000,                 loss: nan
second_0:                 episode reward: -2.3000,                 loss: 0.0822
Episode: 1461/10000 (14.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.36s / 11758.39 s
first_0:                 episode reward: 0.3000,                 loss: nan
second_0:                 episode reward: -0.3000,                 loss: 0.0819
Episode: 1481/10000 (14.8100%),                 avg. length: 296.8,                last time consumption/overall running time: 164.70s / 11923.09 s
first_0:                 episode reward: 5.1500,                 loss: nan
second_0:                 episode reward: -5.1500,                 loss: 0.0874
Episode: 1501/10000 (15.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.46s / 12088.55 s
first_0:                 episode reward: 1.5000,                 loss: nan
second_0:                 episode reward: -1.5000,                 loss: 0.0820
Episode: 1521/10000 (15.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.90s / 12254.45 s
first_0:                 episode reward: 3.8500,                 loss: nan
second_0:                 episode reward: -3.8500,                 loss: 0.0782
Episode: 1541/10000 (15.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.42s / 12418.87 s
first_0:                 episode reward: 0.4000,                 loss: nan
second_0:                 episode reward: -0.4000,                 loss: 0.0733
Episode: 1561/10000 (15.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.56s / 12583.43 s
first_0:                 episode reward: 0.0000,                 loss: nan
second_0:                 episode reward: 0.0000,                 loss: 0.0645
Episode: 1581/10000 (15.8100%),                 avg. length: 297.3,                last time consumption/overall running time: 163.24s / 12746.67 s
first_0:                 episode reward: 5.1500,                 loss: nan
second_0:                 episode reward: -5.1500,                 loss: 0.0524
Episode: 1601/10000 (16.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.33s / 12911.00 s
first_0:                 episode reward: 3.0500,                 loss: nan
second_0:                 episode reward: -3.0500,                 loss: 0.0511
Episode: 1621/10000 (16.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.33s / 13075.33 s
first_0:                 episode reward: 0.3500,                 loss: nan
second_0:                 episode reward: -0.3500,                 loss: 0.0468
Episode: 1641/10000 (16.4100%),                 avg. length: 295.2,                last time consumption/overall running time: 161.89s / 13237.22 s
first_0:                 episode reward: 13.5000,                 loss: nan
second_0:                 episode reward: -13.5000,                 loss: 0.0440
Episode: 1661/10000 (16.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.80s / 13403.02 s
first_0:                 episode reward: 4.5000,                 loss: nan
second_0:                 episode reward: -4.5000,                 loss: 0.0446
Episode: 1681/10000 (16.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.55s / 13567.57 s
first_0:                 episode reward: 2.7500,                 loss: nan
second_0:                 episode reward: -2.7500,                 loss: 0.0433
Episode: 1701/10000 (17.0100%),                 avg. length: 298.45,                last time consumption/overall running time: 165.36s / 13732.92 s
first_0:                 episode reward: 8.7500,                 loss: nan
second_0:                 episode reward: -8.7500,                 loss: 0.0443
Episode: 1721/10000 (17.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.34s / 13897.27 s
first_0:                 episode reward: 4.9500,                 loss: nan
second_0:                 episode reward: -4.9500,                 loss: 0.0428
Episode: 1741/10000 (17.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.30s / 14062.57 s
first_0:                 episode reward: 4.3500,                 loss: nan
second_0:                 episode reward: -4.3500,                 loss: 0.0444
Episode: 1761/10000 (17.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.49s / 14228.05 s
first_0:                 episode reward: 4.8500,                 loss: nan
second_0:                 episode reward: -4.8500,                 loss: 0.0449
Episode: 1781/10000 (17.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 166.77s / 14394.83 s
first_0:                 episode reward: 3.5000,                 loss: nan
second_0:                 episode reward: -3.5000,                 loss: 0.0438
Episode: 1801/10000 (18.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.66s / 14560.49 s
first_0:                 episode reward: 3.4000,                 loss: nan
second_0:                 episode reward: -3.4000,                 loss: 0.0416
Episode: 1821/10000 (18.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.50s / 14725.99 s
first_0:                 episode reward: 7.4000,                 loss: nan
second_0:                 episode reward: -7.4000,                 loss: 0.0430
Episode: 1841/10000 (18.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 166.31s / 14892.30 s
first_0:                 episode reward: 6.9500,                 loss: nan
second_0:                 episode reward: -6.9500,                 loss: 0.0427
Episode: 1861/10000 (18.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.80s / 15057.10 s
first_0:                 episode reward: 7.9000,                 loss: nan
second_0:                 episode reward: -7.9000,                 loss: 0.0453
Episode: 1881/10000 (18.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.32s / 15222.42 s
first_0:                 episode reward: 2.6500,                 loss: nan
second_0:                 episode reward: -2.6500,                 loss: 0.0465
Episode: 1901/10000 (19.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.91s / 15388.33 s
first_0:                 episode reward: 1.0500,                 loss: nan
second_0:                 episode reward: -1.0500,                 loss: 0.0461
Episode: 1921/10000 (19.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.43s / 15552.76 s
first_0:                 episode reward: 1.1000,                 loss: nan
second_0:                 episode reward: -1.1000,                 loss: 0.0465
Episode: 1941/10000 (19.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 163.40s / 15716.16 s
first_0:                 episode reward: 0.6500,                 loss: nan
second_0:                 episode reward: -0.6500,                 loss: 0.0480
Episode: 1961/10000 (19.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.46s / 15880.63 s
first_0:                 episode reward: 4.6000,                 loss: nan
second_0:                 episode reward: -4.6000,                 loss: 0.0475
Episode: 1981/10000 (19.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.01s / 16044.64 s
first_0:                 episode reward: 0.8500,                 loss: nan
second_0:                 episode reward: -0.8500,                 loss: 0.0443
Episode: 2001/10000 (20.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.48s / 16209.12 s
first_0:                 episode reward: 1.4000,                 loss: nan
second_0:                 episode reward: -1.4000,                 loss: 0.0449
Episode: 2021/10000 (20.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.27s / 16374.39 s
first_0:                 episode reward: 0.2500,                 loss: nan
second_0:                 episode reward: -0.2500,                 loss: 0.0413
Episode: 2041/10000 (20.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.02s / 16539.41 s
first_0:                 episode reward: 0.8500,                 loss: nan
second_0:                 episode reward: -0.8500,                 loss: 0.0385
Episode: 2061/10000 (20.6100%),                 avg. length: 296.7,                last time consumption/overall running time: 162.91s / 16702.32 s
first_0:                 episode reward: 7.4500,                 loss: nan
second_0:                 episode reward: -7.4500,                 loss: 0.0380
Episode: 2081/10000 (20.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 166.30s / 16868.61 s
first_0:                 episode reward: 0.4000,                 loss: nan
second_0:                 episode reward: -0.4000,                 loss: 0.0407
Episode: 2101/10000 (21.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.65s / 17034.26 s
first_0:                 episode reward: 3.0000,                 loss: nan
second_0:                 episode reward: -3.0000,                 loss: 0.0407
Episode: 2121/10000 (21.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.04s / 17199.30 s
first_0:                 episode reward: 0.3000,                 loss: nan
second_0:                 episode reward: -0.3000,                 loss: 0.0384
Episode: 2141/10000 (21.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.92s / 17365.22 s
first_0:                 episode reward: 1.0500,                 loss: nan
second_0:                 episode reward: -1.0500,                 loss: 0.0415
Episode: 2161/10000 (21.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.58s / 17529.80 s
first_0:                 episode reward: 0.4500,                 loss: nan
second_0:                 episode reward: -0.4500,                 loss: 0.0418
Episode: 2181/10000 (21.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.77s / 17694.58 s
first_0:                 episode reward: 1.3500,                 loss: nan
second_0:                 episode reward: -1.3500,                 loss: 0.0376
Episode: 2201/10000 (22.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 166.37s / 17860.95 s
first_0:                 episode reward: 3.0500,                 loss: nan
second_0:                 episode reward: -3.0500,                 loss: 0.0351
Episode: 2221/10000 (22.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 163.99s / 18024.94 s
first_0:                 episode reward: 5.3000,                 loss: nan
second_0:                 episode reward: -5.3000,                 loss: 0.0334
Episode: 2241/10000 (22.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.23s / 18189.17 s
first_0:                 episode reward: 26.8500,                 loss: nan
second_0:                 episode reward: -26.8500,                 loss: 0.0344
Episode: 2261/10000 (22.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.05s / 18353.22 s
first_0:                 episode reward: 6.0500,                 loss: nan
second_0:                 episode reward: -6.0500,                 loss: 0.0367
Episode: 2281/10000 (22.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.25s / 18517.47 s
first_0:                 episode reward: 5.2500,                 loss: nan
second_0:                 episode reward: -5.2500,                 loss: 0.0391
Episode: 2301/10000 (23.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.20s / 18681.66 s
first_0:                 episode reward: 1.4000,                 loss: nan
second_0:                 episode reward: -1.4000,                 loss: 0.0391
Episode: 2321/10000 (23.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.18s / 18845.84 s
first_0:                 episode reward: 0.1000,                 loss: nan
second_0:                 episode reward: -0.1000,                 loss: 0.0415
Episode: 2341/10000 (23.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 163.39s / 19009.23 s
first_0:                 episode reward: 0.5500,                 loss: nan
second_0:                 episode reward: -0.5500,                 loss: 0.0401
Episode: 2361/10000 (23.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.39s / 19174.63 s
first_0:                 episode reward: 4.6500,                 loss: nan
second_0:                 episode reward: -4.6500,                 loss: 0.0400
Episode: 2381/10000 (23.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.19s / 19339.82 s
first_0:                 episode reward: 6.4500,                 loss: nan
second_0:                 episode reward: -6.4500,                 loss: 0.0399
Episode: 2401/10000 (24.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.96s / 19505.78 s
first_0:                 episode reward: 6.5000,                 loss: nan
second_0:                 episode reward: -6.5000,                 loss: 0.0392
Episode: 2421/10000 (24.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.11s / 19669.88 s
first_0:                 episode reward: 2.0000,                 loss: nan
second_0:                 episode reward: -2.0000,                 loss: 0.0408
Episode: 2441/10000 (24.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 163.12s / 19833.00 s
first_0:                 episode reward: 3.8000,                 loss: nan
second_0:                 episode reward: -3.8000,                 loss: 0.0426
Episode: 2461/10000 (24.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.64s / 19997.64 s
first_0:                 episode reward: 0.6000,                 loss: nan
second_0:                 episode reward: -0.6000,                 loss: 0.0418
Episode: 2481/10000 (24.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.59s / 20163.23 s
first_0:                 episode reward: 0.5000,                 loss: nan
second_0:                 episode reward: -0.5000,                 loss: 0.0418
Episode: 2501/10000 (25.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.82s / 20328.05 s
first_0:                 episode reward: 7.1500,                 loss: nan
second_0:                 episode reward: -7.1500,                 loss: 0.0429
Episode: 2521/10000 (25.2100%),                 avg. length: 296.7,                last time consumption/overall running time: 163.28s / 20491.33 s
first_0:                 episode reward: 5.2000,                 loss: nan
second_0:                 episode reward: -5.2000,                 loss: 0.0422
Episode: 2541/10000 (25.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.71s / 20656.04 s
first_0:                 episode reward: 4.3000,                 loss: nan
second_0:                 episode reward: -4.3000,                 loss: 0.0448
Episode: 2561/10000 (25.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 163.64s / 20819.68 s
first_0:                 episode reward: 6.5000,                 loss: nan
second_0:                 episode reward: -6.5000,                 loss: 0.0441
Episode: 2581/10000 (25.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 163.85s / 20983.53 s
first_0:                 episode reward: 6.1500,                 loss: nan
second_0:                 episode reward: -6.1500,                 loss: 0.0446
Episode: 2601/10000 (26.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.16s / 21147.69 s
first_0:                 episode reward: 5.1500,                 loss: nan
second_0:                 episode reward: -5.1500,                 loss: 0.0433
Episode: 2621/10000 (26.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.35s / 21312.04 s
first_0:                 episode reward: 2.4000,                 loss: nan
second_0:                 episode reward: -2.4000,                 loss: 0.0435
Episode: 2641/10000 (26.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.40s / 21476.44 s
first_0:                 episode reward: 1.3000,                 loss: nan
second_0:                 episode reward: -1.3000,                 loss: 0.0432
Episode: 2661/10000 (26.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.33s / 21640.78 s
first_0:                 episode reward: 3.7500,                 loss: nan
second_0:                 episode reward: -3.7500,                 loss: 0.0412
Episode: 2681/10000 (26.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.97s / 21806.74 s
first_0:                 episode reward: 0.9000,                 loss: nan
second_0:                 episode reward: -0.9000,                 loss: 0.0437
Episode: 2701/10000 (27.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.15s / 21971.89 s
first_0:                 episode reward: 6.8500,                 loss: nan
second_0:                 episode reward: -6.8500,                 loss: 0.0415
Episode: 2721/10000 (27.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.13s / 22137.02 s
first_0:                 episode reward: 2.8500,                 loss: nan
second_0:                 episode reward: -2.8500,                 loss: 0.0429
Episode: 2741/10000 (27.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.62s / 22301.64 s
first_0:                 episode reward: 3.3000,                 loss: nan
second_0:                 episode reward: -3.3000,                 loss: 0.0456
Episode: 2761/10000 (27.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.98s / 22466.61 s
first_0:                 episode reward: 0.3000,                 loss: nan
second_0:                 episode reward: -0.3000,                 loss: 0.0450
Episode: 2781/10000 (27.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 163.98s / 22630.60 s
first_0:                 episode reward: 1.1000,                 loss: nan
second_0:                 episode reward: -1.1000,                 loss: 0.0457
Episode: 2801/10000 (28.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 163.14s / 22793.73 s
first_0:                 episode reward: 2.7000,                 loss: nan
second_0:                 episode reward: -2.7000,                 loss: 0.0435
Episode: 2821/10000 (28.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.16s / 22957.89 s
first_0:                 episode reward: 0.8500,                 loss: nan
second_0:                 episode reward: -0.8500,                 loss: 0.0459
Episode: 2841/10000 (28.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.09s / 23122.98 s
first_0:                 episode reward: 0.5500,                 loss: nan
second_0:                 episode reward: -0.5500,                 loss: 0.0453
Episode: 2861/10000 (28.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.87s / 23287.85 s
first_0:                 episode reward: 2.3500,                 loss: nan
second_0:                 episode reward: -2.3500,                 loss: 0.0447
Episode: 2881/10000 (28.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.91s / 23452.76 s
first_0:                 episode reward: 0.6000,                 loss: nan
second_0:                 episode reward: -0.6000,                 loss: 0.0421
Episode: 2901/10000 (29.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.17s / 23617.93 s
first_0:                 episode reward: 1.0500,                 loss: nan
second_0:                 episode reward: -1.0500,                 loss: 0.0437
Episode: 2921/10000 (29.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.17s / 23782.10 s
first_0:                 episode reward: 1.0000,                 loss: nan
second_0:                 episode reward: -1.0000,                 loss: 0.0480
Episode: 2941/10000 (29.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.43s / 23947.53 s
first_0:                 episode reward: -0.0500,                 loss: nan
second_0:                 episode reward: 0.0500,                 loss: 0.0445
Episode: 2961/10000 (29.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 166.24s / 24113.78 s
first_0:                 episode reward: 0.6000,                 loss: nan
second_0:                 episode reward: -0.6000,                 loss: 0.0441
Episode: 2981/10000 (29.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 163.11s / 24276.89 s
first_0:                 episode reward: 0.5500,                 loss: nan
second_0:                 episode reward: -0.5500,                 loss: 0.0458
Episode: 3001/10000 (30.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.96s / 24441.85 s
first_0:                 episode reward: 1.1500,                 loss: nan
second_0:                 episode reward: -1.1500,                 loss: 0.0497
Episode: 3021/10000 (30.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.64s / 24606.49 s
first_0:                 episode reward: 2.6500,                 loss: nan
second_0:                 episode reward: -2.6500,                 loss: 0.0507
Episode: 3041/10000 (30.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 163.93s / 24770.42 s
first_0:                 episode reward: -3.5000,                 loss: nan
second_0:                 episode reward: 3.5000,                 loss: 0.0524
Episode: 3061/10000 (30.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.65s / 24935.07 s
first_0:                 episode reward: 1.7500,                 loss: nan
second_0:                 episode reward: -1.7500,                 loss: 0.0565
Episode: 3081/10000 (30.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.09s / 25100.16 s
first_0:                 episode reward: -1.9500,                 loss: nan
second_0:                 episode reward: 1.9500,                 loss: 0.0564
Episode: 3101/10000 (31.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 163.76s / 25263.92 s
first_0:                 episode reward: -0.8000,                 loss: nan
second_0:                 episode reward: 0.8000,                 loss: 0.0586
Episode: 3121/10000 (31.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.54s / 25428.47 s
first_0:                 episode reward: 0.2000,                 loss: nan
second_0:                 episode reward: -0.2000,                 loss: 0.0644
Episode: 3141/10000 (31.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.12s / 25593.59 s
first_0:                 episode reward: -4.1000,                 loss: nan
second_0:                 episode reward: 4.1000,                 loss: 0.0711
Episode: 3161/10000 (31.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.36s / 25757.95 s
first_0:                 episode reward: -13.2000,                 loss: nan
second_0:                 episode reward: 13.2000,                 loss: 0.0770
Episode: 3181/10000 (31.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.38s / 25922.33 s
first_0:                 episode reward: -8.0500,                 loss: nan
second_0:                 episode reward: 8.0500,                 loss: 0.0777
Episode: 3201/10000 (32.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.79s / 26087.11 s
first_0:                 episode reward: -6.6500,                 loss: nan
second_0:                 episode reward: 6.6500,                 loss: 0.0772
Episode: 3221/10000 (32.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.07s / 26251.19 s
first_0:                 episode reward: -15.7500,                 loss: nan
second_0:                 episode reward: 15.7500,                 loss: 0.0767
Episode: 3241/10000 (32.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.84s / 26416.03 s
first_0:                 episode reward: -9.4500,                 loss: nan
second_0:                 episode reward: 9.4500,                 loss: 0.0792
Episode: 3261/10000 (32.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 165.34s / 26581.37 s
first_0:                 episode reward: -22.3000,                 loss: nan
second_0:                 episode reward: 22.3000,                 loss: 0.0796
Episode: 3281/10000 (32.8100%),                 avg. length: 297.15,                last time consumption/overall running time: 164.08s / 26745.45 s
first_0:                 episode reward: -5.6000,                 loss: nan
second_0:                 episode reward: 5.6000,                 loss: 0.0793
Episode: 3301/10000 (33.0100%),                 avg. length: 298.4,                last time consumption/overall running time: 164.32s / 26909.77 s
first_0:                 episode reward: -3.8500,                 loss: nan
second_0:                 episode reward: 3.8500,                 loss: 0.0719
Episode: 3321/10000 (33.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 164.48s / 27074.24 s
first_0:                 episode reward: -51.0500,                 loss: nan
second_0:                 episode reward: 51.0500,                 loss: 0.0708
Episode: 3341/10000 (33.4100%),                 avg. length: 295.2,                last time consumption/overall running time: 164.29s / 27238.53 s
first_0:                 episode reward: -41.5000,                 loss: nan
second_0:                 episode reward: 41.5000,                 loss: 0.0610
Episode: 3361/10000 (33.6100%),                 avg. length: 293.4,                last time consumption/overall running time: 162.39s / 27400.93 s
first_0:                 episode reward: -46.6000,                 loss: nan
second_0:                 episode reward: 46.6000,                 loss: 0.0539
Episode: 3381/10000 (33.8100%),                 avg. length: 294.5,                last time consumption/overall running time: 161.52s / 27562.45 s
first_0:                 episode reward: -39.4500,                 loss: nan
second_0:                 episode reward: 39.4500,                 loss: 0.0505
Episode: 3401/10000 (34.0100%),                 avg. length: 293.05,                last time consumption/overall running time: 160.67s / 27723.12 s
first_0:                 episode reward: -36.6000,                 loss: nan
second_0:                 episode reward: 36.6000,                 loss: 0.0484
Episode: 3421/10000 (34.2100%),                 avg. length: 296.9,                last time consumption/overall running time: 164.53s / 27887.66 s
first_0:                 episode reward: -43.3500,                 loss: nan
second_0:                 episode reward: 43.3500,                 loss: 0.0444
Episode: 3441/10000 (34.4100%),                 avg. length: 291.25,                last time consumption/overall running time: 161.55s / 28049.20 s
first_0:                 episode reward: -38.8500,                 loss: nan
second_0:                 episode reward: 38.8500,                 loss: 0.0413
Episode: 3461/10000 (34.6100%),                 avg. length: 293.15,                last time consumption/overall running time: 161.50s / 28210.70 s
first_0:                 episode reward: -21.0500,                 loss: nan
second_0:                 episode reward: 21.0500,                 loss: 0.0409
Episode: 3481/10000 (34.8100%),                 avg. length: 295.1,                last time consumption/overall running time: 164.25s / 28374.96 s
first_0:                 episode reward: -50.5000,                 loss: nan
second_0:                 episode reward: 50.5000,                 loss: 0.0376
Episode: 3501/10000 (35.0100%),                 avg. length: 292.4,                last time consumption/overall running time: 163.66s / 28538.61 s
first_0:                 episode reward: -45.6000,                 loss: nan
second_0:                 episode reward: 45.6000,                 loss: 0.0352
Episode: 3521/10000 (35.2100%),                 avg. length: 291.45,                last time consumption/overall running time: 159.91s / 28698.52 s
first_0:                 episode reward: -23.0000,                 loss: nan
second_0:                 episode reward: 23.0000,                 loss: 0.0347
Episode: 3541/10000 (35.4100%),                 avg. length: 296.3,                last time consumption/overall running time: 162.48s / 28861.00 s
first_0:                 episode reward: -46.3500,                 loss: nan
second_0:                 episode reward: 46.3500,                 loss: 0.0353
Episode: 3561/10000 (35.6100%),                 avg. length: 295.6,                last time consumption/overall running time: 162.31s / 29023.32 s
first_0:                 episode reward: -11.9000,                 loss: nan
second_0:                 episode reward: 11.9000,                 loss: 0.0363
Episode: 3581/10000 (35.8100%),                 avg. length: 290.4,                last time consumption/overall running time: 159.56s / 29182.88 s
first_0:                 episode reward: -36.6000,                 loss: nan
second_0:                 episode reward: 36.6000,                 loss: 0.0336
Episode: 3601/10000 (36.0100%),                 avg. length: 287.3,                last time consumption/overall running time: 159.70s / 29342.57 s
first_0:                 episode reward: -52.9500,                 loss: nan
second_0:                 episode reward: 52.9500,                 loss: 0.0343
Episode: 3621/10000 (36.2100%),                 avg. length: 293.15,                last time consumption/overall running time: 161.82s / 29504.40 s
first_0:                 episode reward: -39.8000,                 loss: nan
second_0:                 episode reward: 39.8000,                 loss: 0.0328
Episode: 3641/10000 (36.4100%),                 avg. length: 293.95,                last time consumption/overall running time: 161.93s / 29666.32 s
first_0:                 episode reward: -50.3000,                 loss: nan
second_0:                 episode reward: 50.3000,                 loss: 0.0343
Episode: 3661/10000 (36.6100%),                 avg. length: 286.85,                last time consumption/overall running time: 158.52s / 29824.84 s
first_0:                 episode reward: -49.2000,                 loss: nan
second_0:                 episode reward: 49.2000,                 loss: 0.0318
Episode: 3681/10000 (36.8100%),                 avg. length: 283.85,                last time consumption/overall running time: 155.81s / 29980.65 s
first_0:                 episode reward: -59.6000,                 loss: nan
second_0:                 episode reward: 59.6000,                 loss: 0.0336
Episode: 3701/10000 (37.0100%),                 avg. length: 293.9,                last time consumption/overall running time: 162.98s / 30143.63 s
first_0:                 episode reward: -57.1000,                 loss: nan
second_0:                 episode reward: 57.1000,                 loss: 0.0333
Episode: 3721/10000 (37.2100%),                 avg. length: 285.65,                last time consumption/overall running time: 157.51s / 30301.14 s
first_0:                 episode reward: -63.1000,                 loss: nan
second_0:                 episode reward: 63.1000,                 loss: 0.0334
Episode: 3741/10000 (37.4100%),                 avg. length: 282.6,                last time consumption/overall running time: 155.66s / 30456.80 s
first_0:                 episode reward: -61.9500,                 loss: nan
second_0:                 episode reward: 61.9500,                 loss: 0.0319
Episode: 3761/10000 (37.6100%),                 avg. length: 293.15,                last time consumption/overall running time: 162.62s / 30619.42 s
first_0:                 episode reward: -50.2500,                 loss: nan
second_0:                 episode reward: 50.2500,                 loss: 0.0331
Episode: 3781/10000 (37.8100%),                 avg. length: 290.3,                last time consumption/overall running time: 159.78s / 30779.21 s
first_0:                 episode reward: -39.5500,                 loss: nan
second_0:                 episode reward: 39.5500,                 loss: 0.0336
Episode: 3801/10000 (38.0100%),                 avg. length: 296.25,                last time consumption/overall running time: 165.21s / 30944.42 s
first_0:                 episode reward: -38.2000,                 loss: nan
second_0:                 episode reward: 38.2000,                 loss: 0.0346
Episode: 3821/10000 (38.2100%),                 avg. length: 290.5,                last time consumption/overall running time: 158.44s / 31102.86 s
first_0:                 episode reward: -40.5500,                 loss: nan
second_0:                 episode reward: 40.5500,                 loss: 0.0333
Episode: 3841/10000 (38.4100%),                 avg. length: 285.1,                last time consumption/overall running time: 157.92s / 31260.78 s
first_0:                 episode reward: -69.6500,                 loss: nan
second_0:                 episode reward: 69.6500,                 loss: 0.0317
Episode: 3861/10000 (38.6100%),                 avg. length: 290.3,                last time consumption/overall running time: 158.44s / 31419.22 s
first_0:                 episode reward: -32.0000,                 loss: nan
second_0:                 episode reward: 32.0000,                 loss: 0.0314
Episode: 3881/10000 (38.8100%),                 avg. length: 292.6,                last time consumption/overall running time: 159.04s / 31578.26 s
first_0:                 episode reward: -36.7500,                 loss: nan
second_0:                 episode reward: 36.7500,                 loss: 0.0320
Episode: 3901/10000 (39.0100%),                 avg. length: 269.9,                last time consumption/overall running time: 149.18s / 31727.43 s
first_0:                 episode reward: -69.1000,                 loss: nan
second_0:                 episode reward: 69.1000,                 loss: 0.0320
Episode: 3921/10000 (39.2100%),                 avg. length: 284.5,                last time consumption/overall running time: 157.21s / 31884.65 s
first_0:                 episode reward: -64.3000,                 loss: nan
second_0:                 episode reward: 64.3000,                 loss: 0.0313
Episode: 3941/10000 (39.4100%),                 avg. length: 272.55,                last time consumption/overall running time: 150.03s / 32034.68 s
first_0:                 episode reward: -60.7500,                 loss: nan
second_0:                 episode reward: 60.7500,                 loss: 0.0296
Episode: 3961/10000 (39.6100%),                 avg. length: 285.9,                last time consumption/overall running time: 157.21s / 32191.89 s
first_0:                 episode reward: -67.2500,                 loss: nan
second_0:                 episode reward: 67.2500,                 loss: 0.0305
Episode: 3981/10000 (39.8100%),                 avg. length: 282.15,                last time consumption/overall running time: 155.32s / 32347.21 s
first_0:                 episode reward: -43.6500,                 loss: nan
second_0:                 episode reward: 43.6500,                 loss: 0.0308
Episode: 4001/10000 (40.0100%),                 avg. length: 291.3,                last time consumption/overall running time: 161.26s / 32508.47 s
first_0:                 episode reward: -48.7000,                 loss: nan
second_0:                 episode reward: 48.7000,                 loss: 0.0304
Episode: 4021/10000 (40.2100%),                 avg. length: 290.4,                last time consumption/overall running time: 161.69s / 32670.16 s
first_0:                 episode reward: -57.2500,                 loss: nan
second_0:                 episode reward: 57.2500,                 loss: 0.0313
Episode: 4041/10000 (40.4100%),                 avg. length: 286.95,                last time consumption/overall running time: 157.25s / 32827.40 s
first_0:                 episode reward: -64.0500,                 loss: nan
second_0:                 episode reward: 64.0500,                 loss: 0.0297
Episode: 4061/10000 (40.6100%),                 avg. length: 277.2,                last time consumption/overall running time: 153.98s / 32981.39 s
first_0:                 episode reward: -54.4500,                 loss: nan
second_0:                 episode reward: 54.4500,                 loss: 0.0288
Episode: 4081/10000 (40.8100%),                 avg. length: 274.1,                last time consumption/overall running time: 150.98s / 33132.37 s
first_0:                 episode reward: -66.6500,                 loss: nan
second_0:                 episode reward: 66.6500,                 loss: 0.0288
Episode: 4101/10000 (41.0100%),                 avg. length: 284.45,                last time consumption/overall running time: 156.99s / 33289.36 s
first_0:                 episode reward: -45.0000,                 loss: nan
second_0:                 episode reward: 45.0000,                 loss: 0.0297
Episode: 4121/10000 (41.2100%),                 avg. length: 280.55,                last time consumption/overall running time: 153.81s / 33443.17 s
first_0:                 episode reward: -52.2500,                 loss: nan
second_0:                 episode reward: 52.2500,                 loss: 0.0314
Episode: 4141/10000 (41.4100%),                 avg. length: 265.9,                last time consumption/overall running time: 146.92s / 33590.09 s
first_0:                 episode reward: -85.8500,                 loss: nan
second_0:                 episode reward: 85.8500,                 loss: 0.0302
Episode: 4161/10000 (41.6100%),                 avg. length: 277.75,                last time consumption/overall running time: 152.90s / 33742.98 s
first_0:                 episode reward: -59.9500,                 loss: nan
second_0:                 episode reward: 59.9500,                 loss: 0.0278
Episode: 4181/10000 (41.8100%),                 avg. length: 278.35,                last time consumption/overall running time: 154.75s / 33897.74 s
first_0:                 episode reward: -58.7000,                 loss: nan
second_0:                 episode reward: 58.7000,                 loss: 0.0277
Episode: 4201/10000 (42.0100%),                 avg. length: 276.0,                last time consumption/overall running time: 151.40s / 34049.14 s
first_0:                 episode reward: -62.3500,                 loss: nan
second_0:                 episode reward: 62.3500,                 loss: 0.0318
Episode: 4221/10000 (42.2100%),                 avg. length: 281.15,                last time consumption/overall running time: 156.66s / 34205.79 s
first_0:                 episode reward: -72.8000,                 loss: nan
second_0:                 episode reward: 72.8000,                 loss: 0.0292
Episode: 4241/10000 (42.4100%),                 avg. length: 271.5,                last time consumption/overall running time: 149.77s / 34355.57 s
first_0:                 episode reward: -70.9000,                 loss: nan
second_0:                 episode reward: 70.9000,                 loss: 0.0288
Episode: 4261/10000 (42.6100%),                 avg. length: 282.95,                last time consumption/overall running time: 156.55s / 34512.12 s
first_0:                 episode reward: -44.5500,                 loss: nan
second_0:                 episode reward: 44.5500,                 loss: 0.0292
Episode: 4281/10000 (42.8100%),                 avg. length: 277.45,                last time consumption/overall running time: 154.13s / 34666.25 s
first_0:                 episode reward: -55.1000,                 loss: nan
second_0:                 episode reward: 55.1000,                 loss: 0.0303
Episode: 4301/10000 (43.0100%),                 avg. length: 284.15,                last time consumption/overall running time: 156.91s / 34823.16 s
first_0:                 episode reward: -45.0500,                 loss: nan
second_0:                 episode reward: 45.0500,                 loss: 0.0291
Episode: 4321/10000 (43.2100%),                 avg. length: 282.6,                last time consumption/overall running time: 156.22s / 34979.38 s
first_0:                 episode reward: -54.0500,                 loss: nan
second_0:                 episode reward: 54.0500,                 loss: 0.0273
Episode: 4341/10000 (43.4100%),                 avg. length: 284.95,                last time consumption/overall running time: 157.19s / 35136.58 s
first_0:                 episode reward: -52.4500,                 loss: nan
second_0:                 episode reward: 52.4500,                 loss: 0.0281
Episode: 4361/10000 (43.6100%),                 avg. length: 279.65,                last time consumption/overall running time: 154.28s / 35290.86 s
first_0:                 episode reward: -51.1500,                 loss: nan
second_0:                 episode reward: 51.1500,                 loss: 0.0291
Episode: 4381/10000 (43.8100%),                 avg. length: 285.1,                last time consumption/overall running time: 157.17s / 35448.03 s
first_0:                 episode reward: -55.3500,                 loss: nan
second_0:                 episode reward: 55.3500,                 loss: 0.0284
Episode: 4401/10000 (44.0100%),                 avg. length: 287.85,                last time consumption/overall running time: 158.18s / 35606.21 s
first_0:                 episode reward: -50.4000,                 loss: nan
second_0:                 episode reward: 50.4000,                 loss: 0.0290
Episode: 4421/10000 (44.2100%),                 avg. length: 277.1,                last time consumption/overall running time: 152.02s / 35758.23 s
first_0:                 episode reward: -60.5500,                 loss: nan
second_0:                 episode reward: 60.5500,                 loss: 0.0276
Episode: 4441/10000 (44.4100%),                 avg. length: 277.4,                last time consumption/overall running time: 153.51s / 35911.74 s
first_0:                 episode reward: -59.6500,                 loss: nan
second_0:                 episode reward: 59.6500,                 loss: 0.0267
Episode: 4461/10000 (44.6100%),                 avg. length: 277.5,                last time consumption/overall running time: 152.78s / 36064.53 s
first_0:                 episode reward: -66.0500,                 loss: nan
second_0:                 episode reward: 66.0500,                 loss: 0.0277
Episode: 4481/10000 (44.8100%),                 avg. length: 277.8,                last time consumption/overall running time: 154.48s / 36219.01 s
first_0:                 episode reward: -52.8000,                 loss: nan
second_0:                 episode reward: 52.8000,                 loss: 0.0259
Episode: 4501/10000 (45.0100%),                 avg. length: 271.65,                last time consumption/overall running time: 150.88s / 36369.89 s
first_0:                 episode reward: -71.9000,                 loss: nan
second_0:                 episode reward: 71.9000,                 loss: 0.0274
Episode: 4521/10000 (45.2100%),                 avg. length: 287.55,                last time consumption/overall running time: 157.53s / 36527.43 s
first_0:                 episode reward: -55.2000,                 loss: nan
second_0:                 episode reward: 55.2000,                 loss: 0.0271
Episode: 4541/10000 (45.4100%),                 avg. length: 290.5,                last time consumption/overall running time: 160.92s / 36688.34 s
first_0:                 episode reward: -60.9000,                 loss: nan
second_0:                 episode reward: 60.9000,                 loss: 0.0278
Episode: 4561/10000 (45.6100%),                 avg. length: 276.0,                last time consumption/overall running time: 151.68s / 36840.03 s
first_0:                 episode reward: -72.5000,                 loss: nan
second_0:                 episode reward: 72.5000,                 loss: 0.0273
Episode: 4581/10000 (45.8100%),                 avg. length: 294.1,                last time consumption/overall running time: 161.00s / 37001.02 s
first_0:                 episode reward: -28.5000,                 loss: nan
second_0:                 episode reward: 28.5000,                 loss: 0.0272
Episode: 4601/10000 (46.0100%),                 avg. length: 280.2,                last time consumption/overall running time: 153.49s / 37154.51 s
first_0:                 episode reward: -53.8000,                 loss: nan
second_0:                 episode reward: 53.8000,                 loss: 0.0276
Episode: 4621/10000 (46.2100%),                 avg. length: 285.5,                last time consumption/overall running time: 157.38s / 37311.89 s
first_0:                 episode reward: -52.9000,                 loss: nan
second_0:                 episode reward: 52.9000,                 loss: 0.0263
Episode: 4641/10000 (46.4100%),                 avg. length: 292.9,                last time consumption/overall running time: 161.05s / 37472.94 s
first_0:                 episode reward: -71.4500,                 loss: nan
second_0:                 episode reward: 71.4500,                 loss: 0.0265
Episode: 4661/10000 (46.6100%),                 avg. length: 279.55,                last time consumption/overall running time: 154.31s / 37627.25 s
first_0:                 episode reward: -43.5500,                 loss: nan
second_0:                 episode reward: 43.5500,                 loss: 0.0257
Episode: 4681/10000 (46.8100%),                 avg. length: 291.55,                last time consumption/overall running time: 162.14s / 37789.39 s
first_0:                 episode reward: -32.7000,                 loss: nan
second_0:                 episode reward: 32.7000,                 loss: 0.0266
Episode: 4701/10000 (47.0100%),                 avg. length: 286.9,                last time consumption/overall running time: 159.20s / 37948.58 s
first_0:                 episode reward: -53.2000,                 loss: nan
second_0:                 episode reward: 53.2000,                 loss: 0.0267
Episode: 4721/10000 (47.2100%),                 avg. length: 277.6,                last time consumption/overall running time: 155.04s / 38103.63 s
first_0:                 episode reward: -73.7500,                 loss: nan
second_0:                 episode reward: 73.7500,                 loss: 0.0265
Episode: 4741/10000 (47.4100%),                 avg. length: 290.55,                last time consumption/overall running time: 160.27s / 38263.90 s
first_0:                 episode reward: -36.9500,                 loss: nan
second_0:                 episode reward: 36.9500,                 loss: 0.0270
Episode: 4761/10000 (47.6100%),                 avg. length: 274.05,                last time consumption/overall running time: 151.10s / 38414.99 s
first_0:                 episode reward: -73.6500,                 loss: nan
second_0:                 episode reward: 73.6500,                 loss: 0.0270
Episode: 4781/10000 (47.8100%),                 avg. length: 283.25,                last time consumption/overall running time: 156.70s / 38571.70 s
first_0:                 episode reward: -66.2500,                 loss: nan
second_0:                 episode reward: 66.2500,                 loss: 0.0284
Episode: 4801/10000 (48.0100%),                 avg. length: 276.2,                last time consumption/overall running time: 152.97s / 38724.67 s
first_0:                 episode reward: -76.9000,                 loss: nan
second_0:                 episode reward: 76.9000,                 loss: 0.0262
Episode: 4821/10000 (48.2100%),                 avg. length: 282.05,                last time consumption/overall running time: 157.74s / 38882.41 s
first_0:                 episode reward: -67.3500,                 loss: nan
second_0:                 episode reward: 67.3500,                 loss: 0.0279
Episode: 4841/10000 (48.4100%),                 avg. length: 277.3,                last time consumption/overall running time: 153.18s / 39035.59 s
first_0:                 episode reward: -77.9500,                 loss: nan
second_0:                 episode reward: 77.9500,                 loss: 0.0277
Episode: 4861/10000 (48.6100%),                 avg. length: 289.45,                last time consumption/overall running time: 159.02s / 39194.61 s
first_0:                 episode reward: -36.6000,                 loss: nan
second_0:                 episode reward: 36.6000,                 loss: 0.0280
Episode: 4881/10000 (48.8100%),                 avg. length: 279.55,                last time consumption/overall running time: 154.20s / 39348.80 s
first_0:                 episode reward: -65.3500,                 loss: nan
second_0:                 episode reward: 65.3500,                 loss: 0.0279
Episode: 4901/10000 (49.0100%),                 avg. length: 281.0,                last time consumption/overall running time: 153.22s / 39502.02 s
first_0:                 episode reward: -52.5500,                 loss: nan
second_0:                 episode reward: 52.5500,                 loss: 0.0305
Episode: 4921/10000 (49.2100%),                 avg. length: 278.15,                last time consumption/overall running time: 153.65s / 39655.67 s
first_0:                 episode reward: -72.2500,                 loss: nan
second_0:                 episode reward: 72.2500,                 loss: 0.0300
Episode: 4941/10000 (49.4100%),                 avg. length: 279.05,                last time consumption/overall running time: 154.36s / 39810.03 s
first_0:                 episode reward: -49.9000,                 loss: nan
second_0:                 episode reward: 49.9000,                 loss: 0.0284
Episode: 4961/10000 (49.6100%),                 avg. length: 278.05,                last time consumption/overall running time: 154.53s / 39964.56 s
first_0:                 episode reward: -67.2000,                 loss: nan
second_0:                 episode reward: 67.2000,                 loss: 0.0281
Episode: 4981/10000 (49.8100%),                 avg. length: 279.95,                last time consumption/overall running time: 154.80s / 40119.36 s
first_0:                 episode reward: -61.1500,                 loss: nan
second_0:                 episode reward: 61.1500,                 loss: 0.0278
Episode: 5001/10000 (50.0100%),                 avg. length: 288.1,                last time consumption/overall running time: 159.29s / 40278.65 s
first_0:                 episode reward: -56.8000,                 loss: nan
second_0:                 episode reward: 56.8000,                 loss: 0.0290
Episode: 5021/10000 (50.2100%),                 avg. length: 275.65,                last time consumption/overall running time: 152.03s / 40430.68 s
first_0:                 episode reward: -65.2000,                 loss: nan
second_0:                 episode reward: 65.2000,                 loss: 0.0305
Episode: 5041/10000 (50.4100%),                 avg. length: 269.65,                last time consumption/overall running time: 151.00s / 40581.68 s
first_0:                 episode reward: -64.5500,                 loss: nan
second_0:                 episode reward: 64.5500,                 loss: 0.0288
Episode: 5061/10000 (50.6100%),                 avg. length: 289.5,                last time consumption/overall running time: 159.81s / 40741.49 s
first_0:                 episode reward: -55.2500,                 loss: nan
second_0:                 episode reward: 55.2500,                 loss: 0.0279
Episode: 5081/10000 (50.8100%),                 avg. length: 289.55,                last time consumption/overall running time: 161.11s / 40902.60 s
first_0:                 episode reward: -37.9500,                 loss: nan
second_0:                 episode reward: 37.9500,                 loss: 0.0286
Episode: 5101/10000 (51.0100%),                 avg. length: 271.75,                last time consumption/overall running time: 150.28s / 41052.88 s
first_0:                 episode reward: -73.3500,                 loss: nan
second_0:                 episode reward: 73.3500,                 loss: 0.0304
Episode: 5121/10000 (51.2100%),                 avg. length: 275.15,                last time consumption/overall running time: 151.93s / 41204.81 s
first_0:                 episode reward: -62.5500,                 loss: nan
second_0:                 episode reward: 62.5500,                 loss: 0.0286
Episode: 5141/10000 (51.4100%),                 avg. length: 282.15,                last time consumption/overall running time: 154.41s / 41359.22 s
first_0:                 episode reward: -57.1000,                 loss: nan
second_0:                 episode reward: 57.1000,                 loss: 0.0305
Episode: 5161/10000 (51.6100%),                 avg. length: 268.0,                last time consumption/overall running time: 148.42s / 41507.64 s
first_0:                 episode reward: -70.8000,                 loss: nan
second_0:                 episode reward: 70.8000,                 loss: 0.0293
Episode: 5181/10000 (51.8100%),                 avg. length: 276.4,                last time consumption/overall running time: 154.32s / 41661.97 s
first_0:                 episode reward: -78.9500,                 loss: nan
second_0:                 episode reward: 78.9500,                 loss: 0.0282
Episode: 5201/10000 (52.0100%),                 avg. length: 277.15,                last time consumption/overall running time: 152.11s / 41814.08 s
first_0:                 episode reward: -62.1000,                 loss: nan
second_0:                 episode reward: 62.1000,                 loss: 0.0288
Episode: 5221/10000 (52.2100%),                 avg. length: 281.3,                last time consumption/overall running time: 155.75s / 41969.82 s
first_0:                 episode reward: -67.9000,                 loss: nan
second_0:                 episode reward: 67.9000,                 loss: 0.0288
Episode: 5241/10000 (52.4100%),                 avg. length: 275.15,                last time consumption/overall running time: 150.18s / 42120.01 s
first_0:                 episode reward: -79.9500,                 loss: nan
second_0:                 episode reward: 79.9500,                 loss: 0.0290
Episode: 5261/10000 (52.6100%),                 avg. length: 277.5,                last time consumption/overall running time: 152.09s / 42272.10 s
first_0:                 episode reward: -60.1500,                 loss: nan
second_0:                 episode reward: 60.1500,                 loss: 0.0275
Episode: 5281/10000 (52.8100%),                 avg. length: 281.35,                last time consumption/overall running time: 154.37s / 42426.47 s
first_0:                 episode reward: -60.3000,                 loss: nan
second_0:                 episode reward: 60.3000,                 loss: 0.0294
Episode: 5301/10000 (53.0100%),                 avg. length: 267.05,                last time consumption/overall running time: 147.15s / 42573.62 s
first_0:                 episode reward: -82.9500,                 loss: nan
second_0:                 episode reward: 82.9500,                 loss: 0.0281
Episode: 5321/10000 (53.2100%),                 avg. length: 272.75,                last time consumption/overall running time: 151.27s / 42724.89 s
first_0:                 episode reward: -68.9500,                 loss: nan
second_0:                 episode reward: 68.9500,                 loss: 0.0281
Episode: 5341/10000 (53.4100%),                 avg. length: 278.45,                last time consumption/overall running time: 154.42s / 42879.31 s
first_0:                 episode reward: -49.5500,                 loss: nan
second_0:                 episode reward: 49.5500,                 loss: 0.0283
Episode: 5361/10000 (53.6100%),                 avg. length: 280.25,                last time consumption/overall running time: 153.81s / 43033.12 s
first_0:                 episode reward: -70.7000,                 loss: nan
second_0:                 episode reward: 70.7000,                 loss: 0.0286
Episode: 5381/10000 (53.8100%),                 avg. length: 286.15,                last time consumption/overall running time: 159.71s / 43192.83 s
first_0:                 episode reward: -72.5000,                 loss: nan
second_0:                 episode reward: 72.5000,                 loss: 0.0275
Episode: 5401/10000 (54.0100%),                 avg. length: 283.95,                last time consumption/overall running time: 157.33s / 43350.16 s
first_0:                 episode reward: -57.2500,                 loss: nan
second_0:                 episode reward: 57.2500,                 loss: 0.0292
Episode: 5421/10000 (54.2100%),                 avg. length: 288.2,                last time consumption/overall running time: 158.70s / 43508.86 s
first_0:                 episode reward: -51.8500,                 loss: nan
second_0:                 episode reward: 51.8500,                 loss: 0.0285
Episode: 5441/10000 (54.4100%),                 avg. length: 285.8,                last time consumption/overall running time: 156.67s / 43665.53 s
first_0:                 episode reward: -62.9500,                 loss: nan
second_0:                 episode reward: 62.9500,                 loss: 0.0286
Episode: 5461/10000 (54.6100%),                 avg. length: 281.9,                last time consumption/overall running time: 153.92s / 43819.45 s
first_0:                 episode reward: -61.8000,                 loss: nan
second_0:                 episode reward: 61.8000,                 loss: 0.0306
Episode: 5481/10000 (54.8100%),                 avg. length: 285.1,                last time consumption/overall running time: 155.31s / 43974.76 s
first_0:                 episode reward: -72.4500,                 loss: nan
second_0:                 episode reward: 72.4500,                 loss: 0.0297
Episode: 5501/10000 (55.0100%),                 avg. length: 289.4,                last time consumption/overall running time: 159.79s / 44134.55 s
first_0:                 episode reward: -66.9000,                 loss: nan
second_0:                 episode reward: 66.9000,                 loss: 0.0286
Episode: 5521/10000 (55.2100%),                 avg. length: 269.05,                last time consumption/overall running time: 150.57s / 44285.12 s
first_0:                 episode reward: -78.3500,                 loss: nan
second_0:                 episode reward: 78.3500,                 loss: 0.0294
Episode: 5541/10000 (55.4100%),                 avg. length: 277.95,                last time consumption/overall running time: 155.40s / 44440.52 s
first_0:                 episode reward: -62.0000,                 loss: nan
second_0:                 episode reward: 62.0000,                 loss: 0.0307
Episode: 5561/10000 (55.6100%),                 avg. length: 277.55,                last time consumption/overall running time: 152.99s / 44593.51 s
first_0:                 episode reward: -70.4000,                 loss: nan
second_0:                 episode reward: 70.4000,                 loss: 0.0307
Episode: 5581/10000 (55.8100%),                 avg. length: 283.2,                last time consumption/overall running time: 154.77s / 44748.28 s
first_0:                 episode reward: -55.8000,                 loss: nan
second_0:                 episode reward: 55.8000,                 loss: 0.0298
Episode: 5601/10000 (56.0100%),                 avg. length: 270.35,                last time consumption/overall running time: 151.21s / 44899.49 s
first_0:                 episode reward: -77.7500,                 loss: nan
second_0:                 episode reward: 77.7500,                 loss: 0.0285
Episode: 5621/10000 (56.2100%),                 avg. length: 276.95,                last time consumption/overall running time: 154.54s / 45054.03 s
first_0:                 episode reward: -77.9500,                 loss: nan
second_0:                 episode reward: 77.9500,                 loss: 0.0284
Episode: 5641/10000 (56.4100%),                 avg. length: 284.5,                last time consumption/overall running time: 157.15s / 45211.18 s
first_0:                 episode reward: -76.1500,                 loss: nan
second_0:                 episode reward: 76.1500,                 loss: 0.0292
Episode: 5661/10000 (56.6100%),                 avg. length: 283.65,                last time consumption/overall running time: 154.79s / 45365.97 s
first_0:                 episode reward: -62.2500,                 loss: nan
second_0:                 episode reward: 62.2500,                 loss: 0.0293
Episode: 5681/10000 (56.8100%),                 avg. length: 273.9,                last time consumption/overall running time: 150.84s / 45516.81 s
first_0:                 episode reward: -71.3000,                 loss: nan
second_0:                 episode reward: 71.3000,                 loss: 0.0292
Episode: 5701/10000 (57.0100%),                 avg. length: 284.2,                last time consumption/overall running time: 156.96s / 45673.77 s
first_0:                 episode reward: -62.4000,                 loss: nan
second_0:                 episode reward: 62.4000,                 loss: 0.0294
Episode: 5721/10000 (57.2100%),                 avg. length: 280.85,                last time consumption/overall running time: 154.84s / 45828.61 s
first_0:                 episode reward: -63.8000,                 loss: nan
second_0:                 episode reward: 63.8000,                 loss: 0.0293
Episode: 5741/10000 (57.4100%),                 avg. length: 269.1,                last time consumption/overall running time: 150.22s / 45978.83 s
first_0:                 episode reward: -67.9000,                 loss: nan
second_0:                 episode reward: 67.9000,                 loss: 0.0293
Episode: 5761/10000 (57.6100%),                 avg. length: 271.2,                last time consumption/overall running time: 149.91s / 46128.74 s
first_0:                 episode reward: -75.0500,                 loss: nan
second_0:                 episode reward: 75.0500,                 loss: 0.0289
Episode: 5781/10000 (57.8100%),                 avg. length: 286.15,                last time consumption/overall running time: 157.79s / 46286.53 s
first_0:                 episode reward: -61.2000,                 loss: nan
second_0:                 episode reward: 61.2000,                 loss: 0.0289
Episode: 5801/10000 (58.0100%),                 avg. length: 271.4,                last time consumption/overall running time: 149.56s / 46436.09 s
first_0:                 episode reward: -76.8000,                 loss: nan
second_0:                 episode reward: 76.8000,                 loss: 0.0284
Episode: 5821/10000 (58.2100%),                 avg. length: 289.25,                last time consumption/overall running time: 159.54s / 46595.63 s
first_0:                 episode reward: -43.2000,                 loss: nan
second_0:                 episode reward: 43.2000,                 loss: 0.0280
Episode: 5841/10000 (58.4100%),                 avg. length: 282.7,                last time consumption/overall running time: 155.77s / 46751.40 s
first_0:                 episode reward: -68.2000,                 loss: nan
second_0:                 episode reward: 68.2000,                 loss: 0.0292
Episode: 5861/10000 (58.6100%),                 avg. length: 270.9,                last time consumption/overall running time: 150.00s / 46901.40 s
first_0:                 episode reward: -74.4000,                 loss: nan
second_0:                 episode reward: 74.4000,                 loss: 0.0277
Episode: 5881/10000 (58.8100%),                 avg. length: 277.75,                last time consumption/overall running time: 152.37s / 47053.77 s
first_0:                 episode reward: -70.8500,                 loss: nan
second_0:                 episode reward: 70.8500,                 loss: 0.0287
Episode: 5901/10000 (59.0100%),                 avg. length: 283.05,                last time consumption/overall running time: 155.72s / 47209.50 s
first_0:                 episode reward: -72.6500,                 loss: nan
second_0:                 episode reward: 72.6500,                 loss: 0.0277
Episode: 5921/10000 (59.2100%),                 avg. length: 267.45,                last time consumption/overall running time: 145.86s / 47355.36 s
first_0:                 episode reward: -74.1000,                 loss: nan
second_0:                 episode reward: 74.1000,                 loss: 0.0279
Episode: 5941/10000 (59.4100%),                 avg. length: 274.6,                last time consumption/overall running time: 151.20s / 47506.55 s
first_0:                 episode reward: -36.5500,                 loss: nan
second_0:                 episode reward: 36.5500,                 loss: 0.0267
Episode: 5961/10000 (59.6100%),                 avg. length: 273.85,                last time consumption/overall running time: 152.05s / 47658.61 s
first_0:                 episode reward: -83.0500,                 loss: nan
second_0:                 episode reward: 83.0500,                 loss: 0.0270
Episode: 5981/10000 (59.8100%),                 avg. length: 259.2,                last time consumption/overall running time: 142.60s / 47801.21 s
first_0:                 episode reward: -76.8000,                 loss: nan
second_0:                 episode reward: 76.8000,                 loss: 0.0285
Episode: 6001/10000 (60.0100%),                 avg. length: 274.6,                last time consumption/overall running time: 151.89s / 47953.09 s
first_0:                 episode reward: -85.0000,                 loss: nan
second_0:                 episode reward: 85.0000,                 loss: 0.0268
Episode: 6021/10000 (60.2100%),                 avg. length: 283.3,                last time consumption/overall running time: 156.63s / 48109.72 s
first_0:                 episode reward: -73.1000,                 loss: nan
second_0:                 episode reward: 73.1000,                 loss: 0.0260
Episode: 6041/10000 (60.4100%),                 avg. length: 281.2,                last time consumption/overall running time: 155.34s / 48265.06 s
first_0:                 episode reward: -64.4500,                 loss: nan
second_0:                 episode reward: 64.4500,                 loss: 0.0269
Episode: 6061/10000 (60.6100%),                 avg. length: 278.8,                last time consumption/overall running time: 152.77s / 48417.83 s
first_0:                 episode reward: -70.3000,                 loss: nan
second_0:                 episode reward: 70.3000,                 loss: 0.0255
Episode: 6081/10000 (60.8100%),                 avg. length: 279.35,                last time consumption/overall running time: 154.12s / 48571.95 s
first_0:                 episode reward: -72.8500,                 loss: nan
second_0:                 episode reward: 72.8500,                 loss: 0.0272
Episode: 6101/10000 (61.0100%),                 avg. length: 277.85,                last time consumption/overall running time: 152.94s / 48724.89 s
first_0:                 episode reward: -56.5500,                 loss: nan
second_0:                 episode reward: 56.5500,                 loss: 0.0270
Episode: 6121/10000 (61.2100%),                 avg. length: 268.25,                last time consumption/overall running time: 148.78s / 48873.67 s
first_0:                 episode reward: -82.7000,                 loss: nan
second_0:                 episode reward: 82.7000,                 loss: 0.0267
Episode: 6141/10000 (61.4100%),                 avg. length: 281.05,                last time consumption/overall running time: 156.12s / 49029.79 s
first_0:                 episode reward: -49.6000,                 loss: nan
second_0:                 episode reward: 49.6000,                 loss: 0.0273
Episode: 6161/10000 (61.6100%),                 avg. length: 278.05,                last time consumption/overall running time: 151.38s / 49181.18 s
first_0:                 episode reward: -70.8000,                 loss: nan
second_0:                 episode reward: 70.8000,                 loss: 0.0272
Episode: 6181/10000 (61.8100%),                 avg. length: 275.8,                last time consumption/overall running time: 153.04s / 49334.22 s
first_0:                 episode reward: -56.9500,                 loss: nan
second_0:                 episode reward: 56.9500,                 loss: 0.0264
Episode: 6201/10000 (62.0100%),                 avg. length: 281.95,                last time consumption/overall running time: 155.11s / 49489.33 s
first_0:                 episode reward: -63.8000,                 loss: nan
second_0:                 episode reward: 63.8000,                 loss: 0.0268
Episode: 6221/10000 (62.2100%),                 avg. length: 283.45,                last time consumption/overall running time: 157.17s / 49646.50 s
first_0:                 episode reward: -80.1000,                 loss: nan
second_0:                 episode reward: 80.1000,                 loss: 0.0272
Episode: 6241/10000 (62.4100%),                 avg. length: 284.6,                last time consumption/overall running time: 156.45s / 49802.95 s
first_0:                 episode reward: -56.0500,                 loss: nan
second_0:                 episode reward: 56.0500,                 loss: 0.0276
Episode: 6261/10000 (62.6100%),                 avg. length: 272.3,                last time consumption/overall running time: 150.25s / 49953.20 s
first_0:                 episode reward: -83.7500,                 loss: nan
second_0:                 episode reward: 83.7500,                 loss: 0.0267
Episode: 6281/10000 (62.8100%),                 avg. length: 284.4,                last time consumption/overall running time: 156.45s / 50109.66 s
first_0:                 episode reward: -73.1000,                 loss: nan
second_0:                 episode reward: 73.1000,                 loss: 0.0270
Episode: 6301/10000 (63.0100%),                 avg. length: 282.15,                last time consumption/overall running time: 156.17s / 50265.83 s
first_0:                 episode reward: -60.8000,                 loss: nan
second_0:                 episode reward: 60.8000,                 loss: 0.0280
Episode: 6321/10000 (63.2100%),                 avg. length: 283.95,                last time consumption/overall running time: 156.99s / 50422.81 s
first_0:                 episode reward: -70.0000,                 loss: nan
second_0:                 episode reward: 70.0000,                 loss: 0.0296
Episode: 6341/10000 (63.4100%),                 avg. length: 287.1,                last time consumption/overall running time: 157.65s / 50580.47 s
first_0:                 episode reward: -59.3500,                 loss: nan
second_0:                 episode reward: 59.3500,                 loss: 0.0270
Episode: 6361/10000 (63.6100%),                 avg. length: 277.55,                last time consumption/overall running time: 154.01s / 50734.47 s
first_0:                 episode reward: -72.5000,                 loss: nan
second_0:                 episode reward: 72.5000,                 loss: 0.0272
Episode: 6381/10000 (63.8100%),                 avg. length: 284.05,                last time consumption/overall running time: 156.23s / 50890.70 s
first_0:                 episode reward: -59.4500,                 loss: nan
second_0:                 episode reward: 59.4500,                 loss: 0.0271
Episode: 6401/10000 (64.0100%),                 avg. length: 279.65,                last time consumption/overall running time: 155.13s / 51045.83 s
first_0:                 episode reward: -71.8000,                 loss: nan
second_0:                 episode reward: 71.8000,                 loss: 0.0284
Episode: 6421/10000 (64.2100%),                 avg. length: 274.35,                last time consumption/overall running time: 150.95s / 51196.78 s
first_0:                 episode reward: -78.7000,                 loss: nan
second_0:                 episode reward: 78.7000,                 loss: 0.0273
Episode: 6441/10000 (64.4100%),                 avg. length: 283.35,                last time consumption/overall running time: 155.64s / 51352.42 s
first_0:                 episode reward: -67.2500,                 loss: nan
second_0:                 episode reward: 67.2500,                 loss: 0.0271
Episode: 6461/10000 (64.6100%),                 avg. length: 284.1,                last time consumption/overall running time: 157.87s / 51510.29 s
first_0:                 episode reward: -53.2000,                 loss: nan
second_0:                 episode reward: 53.2000,                 loss: 0.0302
Episode: 6481/10000 (64.8100%),                 avg. length: 276.9,                last time consumption/overall running time: 152.64s / 51662.93 s
first_0:                 episode reward: -68.0000,                 loss: nan
second_0:                 episode reward: 68.0000,                 loss: 0.0279
Episode: 6501/10000 (65.0100%),                 avg. length: 274.05,                last time consumption/overall running time: 151.49s / 51814.43 s
first_0:                 episode reward: -69.4500,                 loss: nan
second_0:                 episode reward: 69.4500,                 loss: 0.0269
Episode: 6521/10000 (65.2100%),                 avg. length: 273.15,                last time consumption/overall running time: 151.03s / 51965.46 s
first_0:                 episode reward: -77.6500,                 loss: nan
second_0:                 episode reward: 77.6500,                 loss: 0.0273
Episode: 6541/10000 (65.4100%),                 avg. length: 272.4,                last time consumption/overall running time: 151.06s / 52116.52 s
first_0:                 episode reward: -79.7500,                 loss: nan
second_0:                 episode reward: 79.7500,                 loss: 0.0283
Episode: 6561/10000 (65.6100%),                 avg. length: 273.75,                last time consumption/overall running time: 150.29s / 52266.80 s
first_0:                 episode reward: -65.7500,                 loss: nan
second_0:                 episode reward: 65.7500,                 loss: 0.0275
Episode: 6581/10000 (65.8100%),                 avg. length: 278.3,                last time consumption/overall running time: 154.00s / 52420.80 s
first_0:                 episode reward: -70.2500,                 loss: nan
second_0:                 episode reward: 70.2500,                 loss: 0.0281
Episode: 6601/10000 (66.0100%),                 avg. length: 276.35,                last time consumption/overall running time: 152.03s / 52572.83 s
first_0:                 episode reward: -59.9500,                 loss: nan
second_0:                 episode reward: 59.9500,                 loss: 0.0283
Episode: 6621/10000 (66.2100%),                 avg. length: 276.95,                last time consumption/overall running time: 153.02s / 52725.85 s
first_0:                 episode reward: -50.6500,                 loss: nan
second_0:                 episode reward: 50.6500,                 loss: 0.0284
Episode: 6641/10000 (66.4100%),                 avg. length: 267.25,                last time consumption/overall running time: 146.51s / 52872.36 s
first_0:                 episode reward: -58.4500,                 loss: nan
second_0:                 episode reward: 58.4500,                 loss: 0.0271
Episode: 6661/10000 (66.6100%),                 avg. length: 281.75,                last time consumption/overall running time: 156.92s / 53029.28 s
first_0:                 episode reward: -74.1000,                 loss: nan
second_0:                 episode reward: 74.1000,                 loss: 0.0256
Episode: 6681/10000 (66.8100%),                 avg. length: 271.3,                last time consumption/overall running time: 150.09s / 53179.36 s
first_0:                 episode reward: -66.1000,                 loss: nan
second_0:                 episode reward: 66.1000,                 loss: 0.0265
Episode: 6701/10000 (67.0100%),                 avg. length: 280.2,                last time consumption/overall running time: 154.20s / 53333.56 s
first_0:                 episode reward: -84.7500,                 loss: nan
second_0:                 episode reward: 84.7500,                 loss: 0.0265
Episode: 6721/10000 (67.2100%),                 avg. length: 275.7,                last time consumption/overall running time: 151.52s / 53485.09 s
first_0:                 episode reward: -70.1500,                 loss: nan
second_0:                 episode reward: 70.1500,                 loss: 0.0262
Episode: 6741/10000 (67.4100%),                 avg. length: 274.05,                last time consumption/overall running time: 150.34s / 53635.43 s
first_0:                 episode reward: -66.1500,                 loss: nan
second_0:                 episode reward: 66.1500,                 loss: 0.0260
Episode: 6761/10000 (67.6100%),                 avg. length: 286.2,                last time consumption/overall running time: 157.03s / 53792.46 s
first_0:                 episode reward: -53.0500,                 loss: nan
second_0:                 episode reward: 53.0500,                 loss: 0.0265
Episode: 6781/10000 (67.8100%),                 avg. length: 275.75,                last time consumption/overall running time: 151.75s / 53944.21 s
first_0:                 episode reward: -76.8500,                 loss: nan
second_0:                 episode reward: 76.8500,                 loss: 0.0259
Episode: 6801/10000 (68.0100%),                 avg. length: 280.4,                last time consumption/overall running time: 154.03s / 54098.24 s
first_0:                 episode reward: -66.9500,                 loss: nan
second_0:                 episode reward: 66.9500,                 loss: 0.0256
Episode: 6821/10000 (68.2100%),                 avg. length: 273.2,                last time consumption/overall running time: 149.81s / 54248.05 s
first_0:                 episode reward: -69.7500,                 loss: nan
second_0:                 episode reward: 69.7500,                 loss: 0.0261
Episode: 6841/10000 (68.4100%),                 avg. length: 277.9,                last time consumption/overall running time: 152.79s / 54400.83 s
first_0:                 episode reward: -58.4000,                 loss: nan
second_0:                 episode reward: 58.4000,                 loss: 0.0256
Episode: 6861/10000 (68.6100%),                 avg. length: 281.95,                last time consumption/overall running time: 154.42s / 54555.26 s
first_0:                 episode reward: -46.3000,                 loss: nan
second_0:                 episode reward: 46.3000,                 loss: 0.0257
Episode: 6881/10000 (68.8100%),                 avg. length: 281.7,                last time consumption/overall running time: 153.63s / 54708.88 s
first_0:                 episode reward: -51.5000,                 loss: nan
second_0:                 episode reward: 51.5000,                 loss: 0.0265
Episode: 6901/10000 (69.0100%),                 avg. length: 268.85,                last time consumption/overall running time: 146.48s / 54855.36 s
first_0:                 episode reward: -70.6500,                 loss: nan
second_0:                 episode reward: 70.6500,                 loss: 0.0249
Episode: 6921/10000 (69.2100%),                 avg. length: 282.35,                last time consumption/overall running time: 155.78s / 55011.14 s
first_0:                 episode reward: -67.5000,                 loss: nan
second_0:                 episode reward: 67.5000,                 loss: 0.0260
Episode: 6941/10000 (69.4100%),                 avg. length: 276.85,                last time consumption/overall running time: 152.14s / 55163.28 s
first_0:                 episode reward: -57.1500,                 loss: nan
second_0:                 episode reward: 57.1500,                 loss: 0.0259
Episode: 6961/10000 (69.6100%),                 avg. length: 276.1,                last time consumption/overall running time: 152.64s / 55315.92 s
first_0:                 episode reward: -54.3500,                 loss: nan
second_0:                 episode reward: 54.3500,                 loss: 0.0250
Episode: 6981/10000 (69.8100%),                 avg. length: 271.65,                last time consumption/overall running time: 149.58s / 55465.50 s
first_0:                 episode reward: -80.0000,                 loss: nan
second_0:                 episode reward: 80.0000,                 loss: 0.0258
Episode: 7001/10000 (70.0100%),                 avg. length: 269.45,                last time consumption/overall running time: 148.80s / 55614.30 s
first_0:                 episode reward: -63.7000,                 loss: nan
second_0:                 episode reward: 63.7000,                 loss: 0.0259
Episode: 7021/10000 (70.2100%),                 avg. length: 263.85,                last time consumption/overall running time: 144.94s / 55759.24 s
first_0:                 episode reward: -68.2500,                 loss: nan
second_0:                 episode reward: 68.2500,                 loss: 0.0262
Episode: 7041/10000 (70.4100%),                 avg. length: 265.25,                last time consumption/overall running time: 146.08s / 55905.31 s
first_0:                 episode reward: -85.2500,                 loss: nan
second_0:                 episode reward: 85.2500,                 loss: 0.0256
Episode: 7061/10000 (70.6100%),                 avg. length: 263.8,                last time consumption/overall running time: 146.00s / 56051.32 s
first_0:                 episode reward: -67.8000,                 loss: nan
second_0:                 episode reward: 67.8000,                 loss: 0.0246
Episode: 7081/10000 (70.8100%),                 avg. length: 280.3,                last time consumption/overall running time: 154.33s / 56205.64 s
first_0:                 episode reward: -51.3000,                 loss: nan
second_0:                 episode reward: 51.3000,                 loss: 0.0263
Episode: 7101/10000 (71.0100%),                 avg. length: 272.8,                last time consumption/overall running time: 142.62s / 56348.26 s
first_0:                 episode reward: -71.0000,                 loss: nan
second_0:                 episode reward: 71.0000,                 loss: 0.0253
Episode: 7121/10000 (71.2100%),                 avg. length: 279.85,                last time consumption/overall running time: 146.25s / 56494.51 s
first_0:                 episode reward: -63.6500,                 loss: nan
second_0:                 episode reward: 63.6500,                 loss: 0.0253
Episode: 7141/10000 (71.4100%),                 avg. length: 276.65,                last time consumption/overall running time: 144.29s / 56638.80 s
first_0:                 episode reward: -83.3500,                 loss: nan
second_0:                 episode reward: 83.3500,                 loss: 0.0252
Episode: 7161/10000 (71.6100%),                 avg. length: 272.0,                last time consumption/overall running time: 142.65s / 56781.45 s
first_0:                 episode reward: -75.7000,                 loss: nan
second_0:                 episode reward: 75.7000,                 loss: 0.0255
Episode: 7181/10000 (71.8100%),                 avg. length: 267.25,                last time consumption/overall running time: 139.55s / 56921.00 s
first_0:                 episode reward: -87.3500,                 loss: nan
second_0:                 episode reward: 87.3500,                 loss: 0.0265
Episode: 7201/10000 (72.0100%),                 avg. length: 273.65,                last time consumption/overall running time: 142.82s / 57063.82 s
first_0:                 episode reward: -75.5000,                 loss: nan
second_0:                 episode reward: 75.5000,                 loss: 0.0265
Episode: 7221/10000 (72.2100%),                 avg. length: 279.55,                last time consumption/overall running time: 146.06s / 57209.88 s
first_0:                 episode reward: -76.1000,                 loss: nan
second_0:                 episode reward: 76.1000,                 loss: 0.0260
Episode: 7241/10000 (72.4100%),                 avg. length: 271.6,                last time consumption/overall running time: 141.57s / 57351.45 s
first_0:                 episode reward: -91.4000,                 loss: nan
second_0:                 episode reward: 91.4000,                 loss: 0.0257
Episode: 7261/10000 (72.6100%),                 avg. length: 279.35,                last time consumption/overall running time: 145.71s / 57497.16 s
first_0:                 episode reward: -73.5500,                 loss: nan
second_0:                 episode reward: 73.5500,                 loss: 0.0257
Episode: 7281/10000 (72.8100%),                 avg. length: 279.75,                last time consumption/overall running time: 145.95s / 57643.12 s
first_0:                 episode reward: -77.4000,                 loss: nan
second_0:                 episode reward: 77.4000,                 loss: 0.0261
Episode: 7301/10000 (73.0100%),                 avg. length: 286.25,                last time consumption/overall running time: 149.33s / 57792.45 s
first_0:                 episode reward: -52.7500,                 loss: nan
second_0:                 episode reward: 52.7500,                 loss: 0.0257
Episode: 7321/10000 (73.2100%),                 avg. length: 285.45,                last time consumption/overall running time: 148.70s / 57941.15 s
first_0:                 episode reward: -70.1500,                 loss: nan
second_0:                 episode reward: 70.1500,                 loss: 0.0269
Episode: 7341/10000 (73.4100%),                 avg. length: 276.8,                last time consumption/overall running time: 144.04s / 58085.18 s
first_0:                 episode reward: -66.0500,                 loss: nan
second_0:                 episode reward: 66.0500,                 loss: 0.0271
Episode: 7361/10000 (73.6100%),                 avg. length: 290.05,                last time consumption/overall running time: 151.25s / 58236.44 s
first_0:                 episode reward: -61.8000,                 loss: nan
second_0:                 episode reward: 61.8000,                 loss: 0.0282
Episode: 7381/10000 (73.8100%),                 avg. length: 277.5,                last time consumption/overall running time: 144.66s / 58381.10 s
first_0:                 episode reward: -88.2000,                 loss: nan
second_0:                 episode reward: 88.2000,                 loss: 0.0266
Episode: 7401/10000 (74.0100%),                 avg. length: 276.7,                last time consumption/overall running time: 144.84s / 58525.93 s
first_0:                 episode reward: -68.8500,                 loss: nan
second_0:                 episode reward: 68.8500,                 loss: 0.0274
Episode: 7421/10000 (74.2100%),                 avg. length: 280.2,                last time consumption/overall running time: 146.78s / 58672.71 s
first_0:                 episode reward: -75.4000,                 loss: nan
second_0:                 episode reward: 75.4000,                 loss: 0.0270
Episode: 7441/10000 (74.4100%),                 avg. length: 285.05,                last time consumption/overall running time: 148.69s / 58821.40 s
first_0:                 episode reward: -71.1000,                 loss: nan
second_0:                 episode reward: 71.1000,                 loss: 0.0270
Episode: 7461/10000 (74.6100%),                 avg. length: 272.95,                last time consumption/overall running time: 142.17s / 58963.58 s
first_0:                 episode reward: -66.5000,                 loss: nan
second_0:                 episode reward: 66.5000,                 loss: 0.0289
Episode: 7481/10000 (74.8100%),                 avg. length: 282.35,                last time consumption/overall running time: 147.55s / 59111.13 s
first_0:                 episode reward: -62.5500,                 loss: nan
second_0:                 episode reward: 62.5500,                 loss: 0.0275
Episode: 7501/10000 (75.0100%),                 avg. length: 289.5,                last time consumption/overall running time: 151.40s / 59262.53 s
first_0:                 episode reward: -47.6000,                 loss: nan
second_0:                 episode reward: 47.6000,                 loss: 0.0281
Episode: 7521/10000 (75.2100%),                 avg. length: 270.45,                last time consumption/overall running time: 141.68s / 59404.21 s
first_0:                 episode reward: -67.6500,                 loss: nan
second_0:                 episode reward: 67.6500,                 loss: 0.0285
Episode: 7541/10000 (75.4100%),                 avg. length: 284.15,                last time consumption/overall running time: 146.71s / 59550.92 s
first_0:                 episode reward: -59.4000,                 loss: nan
second_0:                 episode reward: 59.4000,                 loss: 0.0288
Episode: 7561/10000 (75.6100%),                 avg. length: 286.65,                last time consumption/overall running time: 135.00s / 59685.92 s
first_0:                 episode reward: -67.6000,                 loss: nan
second_0:                 episode reward: 67.6000,                 loss: 0.0284
Episode: 7581/10000 (75.8100%),                 avg. length: 278.35,                last time consumption/overall running time: 129.66s / 59815.58 s
first_0:                 episode reward: -81.3000,                 loss: nan
second_0:                 episode reward: 81.3000,                 loss: 0.0282
Episode: 7601/10000 (76.0100%),                 avg. length: 286.75,                last time consumption/overall running time: 132.04s / 59947.62 s
first_0:                 episode reward: -52.3500,                 loss: nan
second_0:                 episode reward: 52.3500,                 loss: 0.0284
Episode: 7621/10000 (76.2100%),                 avg. length: 274.7,                last time consumption/overall running time: 120.08s / 60067.70 s
first_0:                 episode reward: -65.1000,                 loss: nan
second_0:                 episode reward: 65.1000,                 loss: 0.0272
Episode: 7641/10000 (76.4100%),                 avg. length: 272.8,                last time consumption/overall running time: 118.34s / 60186.04 s
first_0:                 episode reward: -68.4000,                 loss: nan
second_0:                 episode reward: 68.4000,                 loss: 0.0273
Episode: 7661/10000 (76.6100%),                 avg. length: 281.75,                last time consumption/overall running time: 123.08s / 60309.12 s
first_0:                 episode reward: -78.4500,                 loss: nan
second_0:                 episode reward: 78.4500,                 loss: 0.0275
Episode: 7681/10000 (76.8100%),                 avg. length: 274.55,                last time consumption/overall running time: 119.24s / 60428.36 s
first_0:                 episode reward: -78.7000,                 loss: nan
second_0:                 episode reward: 78.7000,                 loss: 0.0274
Episode: 7701/10000 (77.0100%),                 avg. length: 285.7,                last time consumption/overall running time: 124.34s / 60552.70 s
first_0:                 episode reward: -66.9000,                 loss: nan
second_0:                 episode reward: 66.9000,                 loss: 0.0280
Episode: 7721/10000 (77.2100%),                 avg. length: 271.6,                last time consumption/overall running time: 118.11s / 60670.81 s
first_0:                 episode reward: -75.7000,                 loss: nan
second_0:                 episode reward: 75.7000,                 loss: 0.0273
Episode: 7741/10000 (77.4100%),                 avg. length: 284.95,                last time consumption/overall running time: 124.05s / 60794.86 s
first_0:                 episode reward: -63.6500,                 loss: nan
second_0:                 episode reward: 63.6500,                 loss: 0.0274
Episode: 7761/10000 (77.6100%),                 avg. length: 272.8,                last time consumption/overall running time: 118.89s / 60913.75 s
first_0:                 episode reward: -83.1500,                 loss: nan
second_0:                 episode reward: 83.1500,                 loss: 0.0281
Episode: 7781/10000 (77.8100%),                 avg. length: 275.55,                last time consumption/overall running time: 120.18s / 61033.93 s
first_0:                 episode reward: -67.2500,                 loss: nan
second_0:                 episode reward: 67.2500,                 loss: 0.0287
Episode: 7801/10000 (78.0100%),                 avg. length: 260.05,                last time consumption/overall running time: 113.36s / 61147.29 s
first_0:                 episode reward: -81.9500,                 loss: nan
second_0:                 episode reward: 81.9500,                 loss: 0.0272
Episode: 7821/10000 (78.2100%),                 avg. length: 267.6,                last time consumption/overall running time: 115.83s / 61263.12 s
first_0:                 episode reward: -58.4000,                 loss: nan
second_0:                 episode reward: 58.4000,                 loss: 0.0277
Episode: 7841/10000 (78.4100%),                 avg. length: 289.9,                last time consumption/overall running time: 126.36s / 61389.48 s
first_0:                 episode reward: -48.7500,                 loss: nan
second_0:                 episode reward: 48.7500,                 loss: 0.0283
Episode: 7861/10000 (78.6100%),                 avg. length: 285.15,                last time consumption/overall running time: 123.38s / 61512.86 s
first_0:                 episode reward: -69.0500,                 loss: nan
second_0:                 episode reward: 69.0500,                 loss: 0.0270
Episode: 7881/10000 (78.8100%),                 avg. length: 279.25,                last time consumption/overall running time: 121.27s / 61634.13 s
first_0:                 episode reward: -85.5500,                 loss: nan
second_0:                 episode reward: 85.5500,                 loss: 0.0268
Episode: 7901/10000 (79.0100%),                 avg. length: 275.15,                last time consumption/overall running time: 115.72s / 61749.85 s
first_0:                 episode reward: -73.8000,                 loss: nan
second_0:                 episode reward: 73.8000,                 loss: 0.0268
Episode: 7921/10000 (79.2100%),                 avg. length: 282.2,                last time consumption/overall running time: 114.77s / 61864.61 s
first_0:                 episode reward: -62.5500,                 loss: nan
second_0:                 episode reward: 62.5500,                 loss: 0.0267
Episode: 7941/10000 (79.4100%),                 avg. length: 286.3,                last time consumption/overall running time: 116.09s / 61980.70 s
first_0:                 episode reward: -67.6000,                 loss: nan
second_0:                 episode reward: 67.6000,                 loss: 0.0258
Episode: 7961/10000 (79.6100%),                 avg. length: 276.15,                last time consumption/overall running time: 111.36s / 62092.06 s
first_0:                 episode reward: -74.7500,                 loss: nan
second_0:                 episode reward: 74.7500,                 loss: 0.0272
Episode: 7981/10000 (79.8100%),                 avg. length: 283.2,                last time consumption/overall running time: 114.52s / 62206.58 s
first_0:                 episode reward: -73.6000,                 loss: nan
second_0:                 episode reward: 73.6000,                 loss: 0.0273
Episode: 8001/10000 (80.0100%),                 avg. length: 283.4,                last time consumption/overall running time: 114.90s / 62321.48 s
first_0:                 episode reward: -68.9500,                 loss: nan
second_0:                 episode reward: 68.9500,                 loss: 0.0275
Episode: 8021/10000 (80.2100%),                 avg. length: 279.1,                last time consumption/overall running time: 112.74s / 62434.23 s
first_0:                 episode reward: -73.8000,                 loss: nan
second_0:                 episode reward: 73.8000,                 loss: 0.0263
Episode: 8041/10000 (80.4100%),                 avg. length: 273.85,                last time consumption/overall running time: 110.66s / 62544.89 s
first_0:                 episode reward: -65.5500,                 loss: nan
second_0:                 episode reward: 65.5500,                 loss: 0.0267
Episode: 8061/10000 (80.6100%),                 avg. length: 276.0,                last time consumption/overall running time: 111.53s / 62656.42 s
first_0:                 episode reward: -62.0500,                 loss: nan
second_0:                 episode reward: 62.0500,                 loss: 0.0262
Episode: 8081/10000 (80.8100%),                 avg. length: 273.15,                last time consumption/overall running time: 109.25s / 62765.67 s
first_0:                 episode reward: -72.6500,                 loss: nan
second_0:                 episode reward: 72.6500,                 loss: 0.0269
Episode: 8101/10000 (81.0100%),                 avg. length: 279.5,                last time consumption/overall running time: 98.07s / 62863.74 s
first_0:                 episode reward: -68.9000,                 loss: nan
second_0:                 episode reward: 68.9000,                 loss: 0.0274
Episode: 8121/10000 (81.2100%),                 avg. length: 274.75,                last time consumption/overall running time: 95.28s / 62959.02 s
first_0:                 episode reward: -75.2000,                 loss: nan
second_0:                 episode reward: 75.2000,                 loss: 0.0275
Episode: 8141/10000 (81.4100%),                 avg. length: 269.0,                last time consumption/overall running time: 92.81s / 63051.83 s
first_0:                 episode reward: -52.8500,                 loss: nan
second_0:                 episode reward: 52.8500,                 loss: 0.0267
Episode: 8161/10000 (81.6100%),                 avg. length: 277.2,                last time consumption/overall running time: 95.87s / 63147.70 s
first_0:                 episode reward: -70.3000,                 loss: nan
second_0:                 episode reward: 70.3000,                 loss: 0.0275
Episode: 8181/10000 (81.8100%),                 avg. length: 288.2,                last time consumption/overall running time: 99.92s / 63247.62 s
first_0:                 episode reward: -60.7500,                 loss: nan
second_0:                 episode reward: 60.7500,                 loss: 0.0284
Episode: 8201/10000 (82.0100%),                 avg. length: 270.45,                last time consumption/overall running time: 94.77s / 63342.38 s
first_0:                 episode reward: -65.2000,                 loss: nan
second_0:                 episode reward: 65.2000,                 loss: 0.0274
Episode: 8221/10000 (82.2100%),                 avg. length: 258.75,                last time consumption/overall running time: 89.92s / 63432.30 s
first_0:                 episode reward: -83.7500,                 loss: nan
second_0:                 episode reward: 83.7500,                 loss: 0.0265
Episode: 8241/10000 (82.4100%),                 avg. length: 284.1,                last time consumption/overall running time: 98.67s / 63530.97 s
first_0:                 episode reward: -60.5000,                 loss: nan
second_0:                 episode reward: 60.5000,                 loss: 0.0277
Episode: 8261/10000 (82.6100%),                 avg. length: 269.85,                last time consumption/overall running time: 94.01s / 63624.98 s
first_0:                 episode reward: -77.5500,                 loss: nan
second_0:                 episode reward: 77.5500,                 loss: 0.0278
Episode: 8281/10000 (82.8100%),                 avg. length: 269.45,                last time consumption/overall running time: 93.13s / 63718.11 s
first_0:                 episode reward: -76.6500,                 loss: nan
second_0:                 episode reward: 76.6500,                 loss: 0.0264
Episode: 8301/10000 (83.0100%),                 avg. length: 280.9,                last time consumption/overall running time: 98.44s / 63816.55 s
first_0:                 episode reward: -45.5500,                 loss: nan
second_0:                 episode reward: 45.5500,                 loss: 0.0268
Episode: 8321/10000 (83.2100%),                 avg. length: 273.15,                last time consumption/overall running time: 94.83s / 63911.38 s
first_0:                 episode reward: -75.0000,                 loss: nan
second_0:                 episode reward: 75.0000,                 loss: 0.0279
Episode: 8341/10000 (83.4100%),                 avg. length: 265.9,                last time consumption/overall running time: 92.49s / 64003.87 s
first_0:                 episode reward: -72.0500,                 loss: nan
second_0:                 episode reward: 72.0500,                 loss: 0.0283
Episode: 8361/10000 (83.6100%),                 avg. length: 285.3,                last time consumption/overall running time: 98.74s / 64102.61 s
first_0:                 episode reward: -63.3500,                 loss: nan
second_0:                 episode reward: 63.3500,                 loss: 0.0268
Episode: 8381/10000 (83.8100%),                 avg. length: 263.7,                last time consumption/overall running time: 91.24s / 64193.85 s
first_0:                 episode reward: -86.8000,                 loss: nan
second_0:                 episode reward: 86.8000,                 loss: 0.0263
Episode: 8401/10000 (84.0100%),                 avg. length: 271.9,                last time consumption/overall running time: 94.19s / 64288.04 s
first_0:                 episode reward: -62.1500,                 loss: nan
second_0:                 episode reward: 62.1500,                 loss: 0.0265
Episode: 8421/10000 (84.2100%),                 avg. length: 282.2,                last time consumption/overall running time: 97.54s / 64385.58 s
first_0:                 episode reward: -60.9000,                 loss: nan
second_0:                 episode reward: 60.9000,                 loss: 0.0272
Episode: 8441/10000 (84.4100%),                 avg. length: 256.5,                last time consumption/overall running time: 89.08s / 64474.66 s
first_0:                 episode reward: -90.0000,                 loss: nan
second_0:                 episode reward: 90.0000,                 loss: 0.0267
Episode: 8461/10000 (84.6100%),                 avg. length: 273.75,                last time consumption/overall running time: 94.84s / 64569.51 s
first_0:                 episode reward: -71.0000,                 loss: nan
second_0:                 episode reward: 71.0000,                 loss: 0.0266
Episode: 8481/10000 (84.8100%),                 avg. length: 275.2,                last time consumption/overall running time: 95.26s / 64664.77 s
first_0:                 episode reward: -90.6000,                 loss: nan
second_0:                 episode reward: 90.6000,                 loss: 0.0270
Episode: 8501/10000 (85.0100%),                 avg. length: 283.7,                last time consumption/overall running time: 98.70s / 64763.47 s
first_0:                 episode reward: -70.5000,                 loss: nan
second_0:                 episode reward: 70.5000,                 loss: 0.0257
Episode: 8521/10000 (85.2100%),                 avg. length: 273.1,                last time consumption/overall running time: 94.02s / 64857.49 s
first_0:                 episode reward: -67.9000,                 loss: nan
second_0:                 episode reward: 67.9000,                 loss: 0.0273
Episode: 8541/10000 (85.4100%),                 avg. length: 285.35,                last time consumption/overall running time: 90.49s / 64947.97 s
first_0:                 episode reward: -59.6000,                 loss: nan
second_0:                 episode reward: 59.6000,                 loss: 0.0272
Episode: 8561/10000 (85.6100%),                 avg. length: 284.7,                last time consumption/overall running time: 89.87s / 65037.85 s
first_0:                 episode reward: -71.0000,                 loss: nan
second_0:                 episode reward: 71.0000,                 loss: 0.0277
Episode: 8581/10000 (85.8100%),                 avg. length: 288.4,                last time consumption/overall running time: 90.74s / 65128.58 s
first_0:                 episode reward: -38.3000,                 loss: nan
second_0:                 episode reward: 38.3000,                 loss: 0.0276
Episode: 8601/10000 (86.0100%),                 avg. length: 282.65,                last time consumption/overall running time: 89.31s / 65217.89 s
first_0:                 episode reward: -78.1000,                 loss: nan
second_0:                 episode reward: 78.1000,                 loss: 0.0275
Episode: 8621/10000 (86.2100%),                 avg. length: 273.85,                last time consumption/overall running time: 85.83s / 65303.72 s
first_0:                 episode reward: -73.0500,                 loss: nan
second_0:                 episode reward: 73.0500,                 loss: 0.0290
Episode: 8641/10000 (86.4100%),                 avg. length: 283.45,                last time consumption/overall running time: 89.36s / 65393.08 s
first_0:                 episode reward: -45.9000,                 loss: nan
second_0:                 episode reward: 45.9000,                 loss: 0.0284
Episode: 8661/10000 (86.6100%),                 avg. length: 282.05,                last time consumption/overall running time: 88.61s / 65481.69 s
first_0:                 episode reward: -80.0000,                 loss: nan
second_0:                 episode reward: 80.0000,                 loss: 0.0293
Episode: 8681/10000 (86.8100%),                 avg. length: 275.6,                last time consumption/overall running time: 87.10s / 65568.78 s
first_0:                 episode reward: -60.8500,                 loss: nan
second_0:                 episode reward: 60.8500,                 loss: 0.0275
Episode: 8701/10000 (87.0100%),                 avg. length: 273.1,                last time consumption/overall running time: 86.14s / 65654.92 s
first_0:                 episode reward: -76.3000,                 loss: nan
second_0:                 episode reward: 76.3000,                 loss: 0.0276
Episode: 8721/10000 (87.2100%),                 avg. length: 288.5,                last time consumption/overall running time: 90.72s / 65745.64 s
first_0:                 episode reward: -67.6000,                 loss: nan
second_0:                 episode reward: 67.6000,                 loss: 0.0277
Episode: 8741/10000 (87.4100%),                 avg. length: 281.45,                last time consumption/overall running time: 88.59s / 65834.23 s
first_0:                 episode reward: -69.2000,                 loss: nan
second_0:                 episode reward: 69.2000,                 loss: 0.0283
Episode: 8761/10000 (87.6100%),                 avg. length: 267.25,                last time consumption/overall running time: 84.09s / 65918.32 s
first_0:                 episode reward: -75.6000,                 loss: nan
second_0:                 episode reward: 75.6000,                 loss: 0.0273
Episode: 8781/10000 (87.8100%),                 avg. length: 269.35,                last time consumption/overall running time: 84.79s / 66003.12 s
first_0:                 episode reward: -68.4000,                 loss: nan
second_0:                 episode reward: 68.4000,                 loss: 0.0275
Episode: 8801/10000 (88.0100%),                 avg. length: 270.05,                last time consumption/overall running time: 85.24s / 66088.36 s
first_0:                 episode reward: -75.4000,                 loss: nan
second_0:                 episode reward: 75.4000,                 loss: 0.0279
Episode: 8821/10000 (88.2100%),                 avg. length: 274.7,                last time consumption/overall running time: 86.06s / 66174.41 s
first_0:                 episode reward: -79.0000,                 loss: nan
second_0:                 episode reward: 79.0000,                 loss: 0.0274
Episode: 8841/10000 (88.4100%),                 avg. length: 273.9,                last time consumption/overall running time: 86.04s / 66260.45 s
first_0:                 episode reward: -81.5000,                 loss: nan
second_0:                 episode reward: 81.5000,                 loss: 0.0264
Episode: 8861/10000 (88.6100%),                 avg. length: 286.2,                last time consumption/overall running time: 89.83s / 66350.28 s
first_0:                 episode reward: -50.7000,                 loss: nan
second_0:                 episode reward: 50.7000,                 loss: 0.0269
Episode: 8881/10000 (88.8100%),                 avg. length: 277.15,                last time consumption/overall running time: 87.52s / 66437.81 s
first_0:                 episode reward: -71.0000,                 loss: nan
second_0:                 episode reward: 71.0000,                 loss: 0.0268
Episode: 8901/10000 (89.0100%),                 avg. length: 282.55,                last time consumption/overall running time: 89.45s / 66527.26 s
first_0:                 episode reward: -72.9500,                 loss: nan
second_0:                 episode reward: 72.9500,                 loss: 0.0273
Episode: 8921/10000 (89.2100%),                 avg. length: 281.5,                last time consumption/overall running time: 88.25s / 66615.51 s
first_0:                 episode reward: -65.5500,                 loss: nan
second_0:                 episode reward: 65.5500,                 loss: 0.0276
Episode: 8941/10000 (89.4100%),                 avg. length: 277.95,                last time consumption/overall running time: 88.00s / 66703.51 s
first_0:                 episode reward: -76.7000,                 loss: nan
second_0:                 episode reward: 76.7000,                 loss: 0.0252
Episode: 8961/10000 (89.6100%),                 avg. length: 277.85,                last time consumption/overall running time: 87.75s / 66791.26 s
first_0:                 episode reward: -66.3000,                 loss: nan
second_0:                 episode reward: 66.3000,                 loss: 0.0274
Episode: 8981/10000 (89.8100%),                 avg. length: 276.75,                last time consumption/overall running time: 82.09s / 66873.35 s
first_0:                 episode reward: -68.6000,                 loss: nan
second_0:                 episode reward: 68.6000,                 loss: 0.0259
Episode: 9001/10000 (90.0100%),                 avg. length: 279.35,                last time consumption/overall running time: 80.76s / 66954.12 s
first_0:                 episode reward: -70.9000,                 loss: nan
second_0:                 episode reward: 70.9000,                 loss: 0.0276
Episode: 9021/10000 (90.2100%),                 avg. length: 279.95,                last time consumption/overall running time: 81.87s / 67035.98 s
first_0:                 episode reward: -62.1000,                 loss: nan
second_0:                 episode reward: 62.1000,                 loss: 0.0258
Episode: 9041/10000 (90.4100%),                 avg. length: 269.4,                last time consumption/overall running time: 77.93s / 67113.91 s
first_0:                 episode reward: -77.4000,                 loss: nan
second_0:                 episode reward: 77.4000,                 loss: 0.0261
Episode: 9061/10000 (90.6100%),                 avg. length: 269.9,                last time consumption/overall running time: 74.50s / 67188.42 s
first_0:                 episode reward: -79.7000,                 loss: nan
second_0:                 episode reward: 79.7000,                 loss: 0.0261
Episode: 9081/10000 (90.8100%),                 avg. length: 281.6,                last time consumption/overall running time: 70.42s / 67258.84 s
first_0:                 episode reward: -55.2000,                 loss: nan
second_0:                 episode reward: 55.2000,                 loss: 0.0245
Episode: 9101/10000 (91.0100%),                 avg. length: 274.4,                last time consumption/overall running time: 66.31s / 67325.15 s
first_0:                 episode reward: -71.4500,                 loss: nan
second_0:                 episode reward: 71.4500,                 loss: 0.0260
Episode: 9121/10000 (91.2100%),                 avg. length: 284.75,                last time consumption/overall running time: 67.50s / 67392.65 s
first_0:                 episode reward: -80.2500,                 loss: nan
second_0:                 episode reward: 80.2500,                 loss: 0.0250
Episode: 9141/10000 (91.4100%),                 avg. length: 276.25,                last time consumption/overall running time: 69.38s / 67462.04 s
first_0:                 episode reward: -64.3500,                 loss: nan
second_0:                 episode reward: 64.3500,                 loss: 0.0262
Episode: 9161/10000 (91.6100%),                 avg. length: 267.45,                last time consumption/overall running time: 65.58s / 67527.62 s
first_0:                 episode reward: -84.7500,                 loss: nan
second_0:                 episode reward: 84.7500,                 loss: 0.0267
Episode: 9181/10000 (91.8100%),                 avg. length: 283.2,                last time consumption/overall running time: 68.92s / 67596.54 s
first_0:                 episode reward: -66.7500,                 loss: nan
second_0:                 episode reward: 66.7500,                 loss: 0.0254
Episode: 9201/10000 (92.0100%),                 avg. length: 272.65,                last time consumption/overall running time: 65.08s / 67661.62 s
first_0:                 episode reward: -61.5000,                 loss: nan
second_0:                 episode reward: 61.5000,                 loss: 0.0260
Episode: 9221/10000 (92.2100%),                 avg. length: 262.5,                last time consumption/overall running time: 62.67s / 67724.29 s
first_0:                 episode reward: -75.5500,                 loss: nan
second_0:                 episode reward: 75.5500,                 loss: 0.0266
Episode: 9241/10000 (92.4100%),                 avg. length: 293.9,                last time consumption/overall running time: 69.89s / 67794.18 s
first_0:                 episode reward: -59.0500,                 loss: nan
second_0:                 episode reward: 59.0500,                 loss: 0.0278
Episode: 9261/10000 (92.6100%),                 avg. length: 280.9,                last time consumption/overall running time: 67.56s / 67861.74 s
first_0:                 episode reward: -53.9000,                 loss: nan
second_0:                 episode reward: 53.9000,                 loss: 0.0269
Episode: 9281/10000 (92.8100%),                 avg. length: 273.4,                last time consumption/overall running time: 64.65s / 67926.40 s
first_0:                 episode reward: -58.1500,                 loss: nan
second_0:                 episode reward: 58.1500,                 loss: 0.0268
Episode: 9301/10000 (93.0100%),                 avg. length: 267.6,                last time consumption/overall running time: 63.84s / 67990.24 s
first_0:                 episode reward: -84.1500,                 loss: nan
second_0:                 episode reward: 84.1500,                 loss: 0.0265
Episode: 9321/10000 (93.2100%),                 avg. length: 269.6,                last time consumption/overall running time: 63.91s / 68054.15 s
first_0:                 episode reward: -73.2500,                 loss: nan
second_0:                 episode reward: 73.2500,                 loss: 0.0264
Episode: 9341/10000 (93.4100%),                 avg. length: 280.9,                last time consumption/overall running time: 66.68s / 68120.83 s
first_0:                 episode reward: -73.2500,                 loss: nan
second_0:                 episode reward: 73.2500,                 loss: 0.0267
Episode: 9361/10000 (93.6100%),                 avg. length: 279.05,                last time consumption/overall running time: 66.39s / 68187.23 s
first_0:                 episode reward: -75.9000,                 loss: nan
second_0:                 episode reward: 75.9000,                 loss: 0.0264
Episode: 9381/10000 (93.8100%),                 avg. length: 270.55,                last time consumption/overall running time: 64.70s / 68251.93 s
first_0:                 episode reward: -74.3000,                 loss: nan
second_0:                 episode reward: 74.3000,                 loss: 0.0266
Episode: 9401/10000 (94.0100%),                 avg. length: 258.05,                last time consumption/overall running time: 61.67s / 68313.60 s
first_0:                 episode reward: -89.5000,                 loss: nan
second_0:                 episode reward: 89.5000,                 loss: 0.0268
Episode: 9421/10000 (94.2100%),                 avg. length: 274.2,                last time consumption/overall running time: 65.92s / 68379.53 s
first_0:                 episode reward: -67.1500,                 loss: nan
second_0:                 episode reward: 67.1500,                 loss: 0.0275
Episode: 9441/10000 (94.4100%),                 avg. length: 272.2,                last time consumption/overall running time: 64.94s / 68444.46 s
first_0:                 episode reward: -59.5500,                 loss: nan
second_0:                 episode reward: 59.5500,                 loss: 0.0264
Episode: 9461/10000 (94.6100%),                 avg. length: 267.55,                last time consumption/overall running time: 64.38s / 68508.84 s
first_0:                 episode reward: -77.4000,                 loss: nan
second_0:                 episode reward: 77.4000,                 loss: 0.0268
Episode: 9481/10000 (94.8100%),                 avg. length: 275.65,                last time consumption/overall running time: 65.40s / 68574.24 s
first_0:                 episode reward: -70.8000,                 loss: nan
second_0:                 episode reward: 70.8000,                 loss: 0.0270
Episode: 9501/10000 (95.0100%),                 avg. length: 259.6,                last time consumption/overall running time: 55.77s / 68630.01 s
first_0:                 episode reward: -87.7000,                 loss: nan
second_0:                 episode reward: 87.7000,                 loss: 0.0269
Episode: 9521/10000 (95.2100%),                 avg. length: 270.5,                last time consumption/overall running time: 57.42s / 68687.43 s
first_0:                 episode reward: -72.1000,                 loss: nan
second_0:                 episode reward: 72.1000,                 loss: 0.0263
Episode: 9541/10000 (95.4100%),                 avg. length: 267.0,                last time consumption/overall running time: 56.46s / 68743.89 s
first_0:                 episode reward: -74.7000,                 loss: nan
second_0:                 episode reward: 74.7000,                 loss: 0.0263
Episode: 9561/10000 (95.6100%),                 avg. length: 281.65,                last time consumption/overall running time: 58.64s / 68802.53 s
first_0:                 episode reward: -70.0500,                 loss: nan
second_0:                 episode reward: 70.0500,                 loss: 0.0269
Episode: 9581/10000 (95.8100%),                 avg. length: 260.65,                last time consumption/overall running time: 54.90s / 68857.43 s
first_0:                 episode reward: -86.7000,                 loss: nan
second_0:                 episode reward: 86.7000,                 loss: 0.0270
Episode: 9601/10000 (96.0100%),                 avg. length: 274.55,                last time consumption/overall running time: 57.50s / 68914.93 s
first_0:                 episode reward: -73.2500,                 loss: nan
second_0:                 episode reward: 73.2500,                 loss: 0.0277
Episode: 9621/10000 (96.2100%),                 avg. length: 280.95,                last time consumption/overall running time: 60.12s / 68975.04 s
first_0:                 episode reward: -64.9500,                 loss: nan
second_0:                 episode reward: 64.9500,                 loss: 0.0277
Episode: 9641/10000 (96.4100%),                 avg. length: 266.25,                last time consumption/overall running time: 57.01s / 69032.05 s
first_0:                 episode reward: -81.7000,                 loss: nan
second_0:                 episode reward: 81.7000,                 loss: 0.0267
Episode: 9661/10000 (96.6100%),                 avg. length: 273.55,                last time consumption/overall running time: 57.41s / 69089.46 s
first_0:                 episode reward: -63.9000,                 loss: nan
second_0:                 episode reward: 63.9000,                 loss: 0.0264
Episode: 9681/10000 (96.8100%),                 avg. length: 280.35,                last time consumption/overall running time: 58.79s / 69148.25 s
first_0:                 episode reward: -70.1500,                 loss: nan
second_0:                 episode reward: 70.1500,                 loss: 0.0267
Episode: 9701/10000 (97.0100%),                 avg. length: 264.15,                last time consumption/overall running time: 55.44s / 69203.70 s
first_0:                 episode reward: -59.6500,                 loss: nan
second_0:                 episode reward: 59.6500,                 loss: 0.0260
Episode: 9721/10000 (97.2100%),                 avg. length: 279.1,                last time consumption/overall running time: 59.40s / 69263.10 s
first_0:                 episode reward: -69.3000,                 loss: nan
second_0:                 episode reward: 69.3000,                 loss: 0.0259
Episode: 9741/10000 (97.4100%),                 avg. length: 276.1,                last time consumption/overall running time: 60.89s / 69323.99 s
first_0:                 episode reward: -80.3500,                 loss: nan
second_0:                 episode reward: 80.3500,                 loss: 0.0272
Episode: 9761/10000 (97.6100%),                 avg. length: 280.85,                last time consumption/overall running time: 59.25s / 69383.24 s
first_0:                 episode reward: -52.4500,                 loss: nan
second_0:                 episode reward: 52.4500,                 loss: 0.0259
Episode: 9781/10000 (97.8100%),                 avg. length: 274.85,                last time consumption/overall running time: 57.80s / 69441.04 s
first_0:                 episode reward: -69.0500,                 loss: nan
second_0:                 episode reward: 69.0500,                 loss: 0.0268
Episode: 9801/10000 (98.0100%),                 avg. length: 270.25,                last time consumption/overall running time: 56.77s / 69497.81 s
first_0:                 episode reward: -77.2500,                 loss: nan
second_0:                 episode reward: 77.2500,                 loss: 0.0272
Episode: 9821/10000 (98.2100%),                 avg. length: 277.65,                last time consumption/overall running time: 58.69s / 69556.50 s
first_0:                 episode reward: -77.0500,                 loss: nan
second_0:                 episode reward: 77.0500,                 loss: 0.0263
Episode: 9841/10000 (98.4100%),                 avg. length: 271.7,                last time consumption/overall running time: 57.39s / 69613.89 s
first_0:                 episode reward: -84.3500,                 loss: nan
second_0:                 episode reward: 84.3500,                 loss: 0.0266
Episode: 9861/10000 (98.6100%),                 avg. length: 268.05,                last time consumption/overall running time: 56.79s / 69670.68 s
first_0:                 episode reward: -70.4500,                 loss: nan
second_0:                 episode reward: 70.4500,                 loss: 0.0277
Episode: 9881/10000 (98.8100%),                 avg. length: 255.65,                last time consumption/overall running time: 54.22s / 69724.91 s
first_0:                 episode reward: -91.2500,                 loss: nan
second_0:                 episode reward: 91.2500,                 loss: 0.0267
Episode: 9901/10000 (99.0100%),                 avg. length: 268.3,                last time consumption/overall running time: 56.72s / 69781.63 s
first_0:                 episode reward: -83.6500,                 loss: nan
second_0:                 episode reward: 83.6500,                 loss: 0.0267
Episode: 9921/10000 (99.2100%),                 avg. length: 276.75,                last time consumption/overall running time: 58.05s / 69839.68 s
first_0:                 episode reward: -67.1500,                 loss: nan
second_0:                 episode reward: 67.1500,                 loss: 0.0277
Episode: 9941/10000 (99.4100%),                 avg. length: 261.8,                last time consumption/overall running time: 54.89s / 69894.56 s
first_0:                 episode reward: -85.2000,                 loss: nan
second_0:                 episode reward: 85.2000,                 loss: 0.0258
Episode: 9961/10000 (99.6100%),                 avg. length: 263.75,                last time consumption/overall running time: 55.52s / 69950.08 s
first_0:                 episode reward: -83.4500,                 loss: nan
second_0:                 episode reward: 83.4500,                 loss: 0.0266
Episode: 9981/10000 (99.8100%),                 avg. length: 268.8,                last time consumption/overall running time: 56.53s / 70006.61 s
first_0:                 episode reward: -81.8000,                 loss: nan/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/pettingzoo/utils/conversions.py:87: UserWarning: The `observation_spaces` dictionary is deprecated. Use the `observation_space` function instead.
  "The `observation_spaces` dictionary is deprecated. Use the `observation_space` function instead."
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/pettingzoo/utils/conversions.py:101: UserWarning: The `action_spaces` dictionary is deprecated. Use the `action_space` function instead.
  "The `action_spaces` dictionary is deprecated. Use the `action_space` function instead."
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

second_0:                 episode reward: 81.8000,                 loss: 0.0268
