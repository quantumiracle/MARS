pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
SlimeVolley-v0 slimevolley
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
random seed: [91, 69]
<SubprocVectorEnv instance>
No agent are not learnable.
Arguments:  {'env_name': 'SlimeVolley-v0', 'env_type': 'slimevolley', 'num_envs': 2, 'ram': True, 'seed': 'random', 'against_baseline': False, 'algorithm': 'NashPPO', 'algorithm_spec': {'episodic_update': True, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000, 'lambda': 0.95, 'eps_clip': 0.2, 'K_epoch': 4, 'GAE': True}, 'num_process': 1, 'batch_size': 32, 'max_episodes': 50000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False, 'policy': {'hidden_dim_list': [64, 64, 64], 'hidden_activation': 'Tanh', 'output_activation': 'Softmax'}, 'value': {'hidden_dim_list': [64, 64, 64], 'hidden_activation': 'Tanh', 'output_activation': False}}, 'marl_method': 'nash_ppo', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True}}
Save models to : /home/zihan/research/MARS/data/model/20220204_1545/slimevolley_SlimeVolley-v0_nash_ppo. 
 Save logs to: /home/zihan/research/MARS/data/log/20220204_1545/slimevolley_SlimeVolley-v0_nash_ppo.
Episode: 1/50000 (0.0020%),                 avg. length: 458.0,                last time consumption/overall running time: 2.1008s / 2.1008 s
env0_first_0:                 episode reward: -1.0000,                 loss: -0.0043
env0_second_0:                 episode reward: 1.0000,                 loss: 0.0591
env1_first_0:                 episode reward: 4.0000,                 loss: nan
env1_second_0:                 episode reward: -4.0000,                 loss: nan
Episode: 21/50000 (0.0420%),                 avg. length: 575.8,                last time consumption/overall running time: 35.1962s / 37.2971 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0830
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0963
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 41/50000 (0.0820%),                 avg. length: 570.4,                last time consumption/overall running time: 35.1232s / 72.4203 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.1947
env0_second_0:                 episode reward: 0.5000,                 loss: 0.1783
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 61/50000 (0.1220%),                 avg. length: 548.9,                last time consumption/overall running time: 33.6276s / 106.0479 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2443
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2487
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 81/50000 (0.1620%),                 avg. length: 600.5,                last time consumption/overall running time: 36.4684s / 142.5162 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.2359
env0_second_0:                 episode reward: 0.7000,                 loss: 0.2448
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 101/50000 (0.2020%),                 avg. length: 586.9,                last time consumption/overall running time: 36.2298s / 178.7460 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.2161
env0_second_0:                 episode reward: -1.0500,                 loss: 0.2231
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 121/50000 (0.2420%),                 avg. length: 583.85,                last time consumption/overall running time: 35.4146s / 214.1606 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2212
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2212
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 141/50000 (0.2820%),                 avg. length: 567.95,                last time consumption/overall running time: 34.9104s / 249.0710 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2240
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2241
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 161/50000 (0.3220%),                 avg. length: 590.35,                last time consumption/overall running time: 35.6130s / 284.6840 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2379
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2338
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 181/50000 (0.3620%),                 avg. length: 562.05,                last time consumption/overall running time: 33.4087s / 318.0927 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2504
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2540
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 201/50000 (0.4020%),                 avg. length: 584.4,                last time consumption/overall running time: 35.1558s / 353.2485 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2508
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2492
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 221/50000 (0.4420%),                 avg. length: 577.4,                last time consumption/overall running time: 34.1593s / 387.4079 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2359
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2374
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 241/50000 (0.4820%),                 avg. length: 522.05,                last time consumption/overall running time: 31.9287s / 419.3366 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.2661
env0_second_0:                 episode reward: 0.8000,                 loss: 0.2730
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 261/50000 (0.5220%),                 avg. length: 556.25,                last time consumption/overall running time: 33.3156s / 452.6522 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2770
env0_second_0:                 episode reward: -0.5500,                 loss: 0.2952
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 281/50000 (0.5620%),                 avg. length: 580.05,                last time consumption/overall running time: 34.3714s / 487.0236 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.2502
env0_second_0:                 episode reward: -0.4500,                 loss: 0.2546
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 301/50000 (0.6020%),                 avg. length: 555.9,                last time consumption/overall running time: 33.1657s / 520.1893 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2678
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2818
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 321/50000 (0.6420%),                 avg. length: 576.4,                last time consumption/overall running time: 34.5295s / 554.7188 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2412
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2652
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 341/50000 (0.6820%),                 avg. length: 571.2,                last time consumption/overall running time: 34.5720s / 589.2908 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2595
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2500
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 361/50000 (0.7220%),                 avg. length: 563.85,                last time consumption/overall running time: 33.6870s / 622.9778 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2328
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2233
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 381/50000 (0.7620%),                 avg. length: 555.0,                last time consumption/overall running time: 33.1767s / 656.1545 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.2481
env0_second_0:                 episode reward: -0.7500,                 loss: 0.2467
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 401/50000 (0.8020%),                 avg. length: 553.95,                last time consumption/overall running time: 34.1976s / 690.3521 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.2549
env0_second_0:                 episode reward: 0.7000,                 loss: 0.2549
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 421/50000 (0.8420%),                 avg. length: 620.8,                last time consumption/overall running time: 36.8685s / 727.2207 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.2339
env0_second_0:                 episode reward: -0.9000,                 loss: 0.2282
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 441/50000 (0.8820%),                 avg. length: 593.85,                last time consumption/overall running time: 35.2997s / 762.5204 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2546
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2549
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 461/50000 (0.9220%),                 avg. length: 587.65,                last time consumption/overall running time: 35.9210s / 798.4414 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2598
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2642
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 481/50000 (0.9620%),                 avg. length: 519.5,                last time consumption/overall running time: 31.8135s / 830.2550 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2759
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2695
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 501/50000 (1.0020%),                 avg. length: 573.15,                last time consumption/overall running time: 34.3562s / 864.6111 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2591
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2530
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 521/50000 (1.0420%),                 avg. length: 574.35,                last time consumption/overall running time: 34.8381s / 899.4492 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2356
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2397
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 541/50000 (1.0820%),                 avg. length: 569.0,                last time consumption/overall running time: 34.6025s / 934.0518 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2611
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2478
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 561/50000 (1.1220%),                 avg. length: 589.05,                last time consumption/overall running time: 35.4606s / 969.5123 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2395
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2364
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 581/50000 (1.1620%),                 avg. length: 574.7,                last time consumption/overall running time: 34.6392s / 1004.1515 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.2424
env0_second_0:                 episode reward: -0.4500,                 loss: 0.2449
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 601/50000 (1.2020%),                 avg. length: 553.95,                last time consumption/overall running time: 33.3248s / 1037.4763 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2339
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2442
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 621/50000 (1.2420%),                 avg. length: 595.85,                last time consumption/overall running time: 35.4537s / 1072.9300 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.2767
env0_second_0:                 episode reward: -0.7000,                 loss: 0.2717
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 641/50000 (1.2820%),                 avg. length: 577.55,                last time consumption/overall running time: 34.5685s / 1107.4986 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2639
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2644
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 661/50000 (1.3220%),                 avg. length: 568.0,                last time consumption/overall running time: 34.2301s / 1141.7286 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2520
env0_second_0:                 episode reward: -0.5500,                 loss: 0.2597
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 681/50000 (1.3620%),                 avg. length: 553.45,                last time consumption/overall running time: 33.5069s / 1175.2355 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2719
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2700
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 701/50000 (1.4020%),                 avg. length: 552.2,                last time consumption/overall running time: 33.4264s / 1208.6619 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.2951
env0_second_0:                 episode reward: 0.9500,                 loss: 0.2981
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 721/50000 (1.4420%),                 avg. length: 559.9,                last time consumption/overall running time: 35.1646s / 1243.8265 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2825
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2902
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 741/50000 (1.4820%),                 avg. length: 557.55,                last time consumption/overall running time: 35.6299s / 1279.4564 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2840
env0_second_0:                 episode reward: -0.5500,                 loss: 0.2806
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 761/50000 (1.5220%),                 avg. length: 554.2,                last time consumption/overall running time: 34.8174s / 1314.2739 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2833
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2950
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 781/50000 (1.5620%),                 avg. length: 545.2,                last time consumption/overall running time: 33.7971s / 1348.0710 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2713
env0_second_0:                 episode reward: -0.5500,                 loss: 0.2755
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 801/50000 (1.6020%),                 avg. length: 593.05,                last time consumption/overall running time: 36.5296s / 1384.6005 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2867
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2960
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 821/50000 (1.6420%),                 avg. length: 600.5,                last time consumption/overall running time: 35.6608s / 1420.2614 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2723
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2652
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 841/50000 (1.6820%),                 avg. length: 566.05,                last time consumption/overall running time: 33.8452s / 1454.1065 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2647
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2604
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 861/50000 (1.7220%),                 avg. length: 556.2,                last time consumption/overall running time: 33.8998s / 1488.0063 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2525
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2579
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 881/50000 (1.7620%),                 avg. length: 630.3,                last time consumption/overall running time: 36.9926s / 1524.9989 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2615
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2497
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 901/50000 (1.8020%),                 avg. length: 555.95,                last time consumption/overall running time: 33.3050s / 1558.3040 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2502
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2500
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 921/50000 (1.8420%),                 avg. length: 606.65,                last time consumption/overall running time: 38.0907s / 1596.3946 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2358
env0_second_0:                 episode reward: 0.6500,                 loss: 0.2383
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 941/50000 (1.8820%),                 avg. length: 615.6,                last time consumption/overall running time: 40.9417s / 1637.3363 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2504
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2478
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 961/50000 (1.9220%),                 avg. length: 577.55,                last time consumption/overall running time: 34.8876s / 1672.2239 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2068
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2072
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 981/50000 (1.9620%),                 avg. length: 568.65,                last time consumption/overall running time: 34.0720s / 1706.2959 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2339
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2313
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 1001/50000 (2.0020%),                 avg. length: 564.1,                last time consumption/overall running time: 33.8366s / 1740.1324 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2573
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2523
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 1021/50000 (2.0420%),                 avg. length: 582.05,                last time consumption/overall running time: 44.0554s / 1784.1878 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2322
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2276
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 1041/50000 (2.0820%),                 avg. length: 557.2,                last time consumption/overall running time: 34.5890s / 1818.7768 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2410
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2480
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 1061/50000 (2.1220%),                 avg. length: 598.25,                last time consumption/overall running time: 36.5732s / 1855.3501 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2709
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2706
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 1081/50000 (2.1620%),                 avg. length: 563.3,                last time consumption/overall running time: 35.0719s / 1890.4220 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2481
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2382
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 1101/50000 (2.2020%),                 avg. length: 571.35,                last time consumption/overall running time: 36.1682s / 1926.5902 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.2624
env0_second_0:                 episode reward: -0.7000,                 loss: 0.2615
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 1121/50000 (2.2420%),                 avg. length: 556.8,                last time consumption/overall running time: 35.5968s / 1962.1869 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2506
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2540
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 1141/50000 (2.2820%),                 avg. length: 576.2,                last time consumption/overall running time: 34.5926s / 1996.7796 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2681
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2767
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 1161/50000 (2.3220%),                 avg. length: 607.0,                last time consumption/overall running time: 35.6859s / 2032.4655 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2703
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2785
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 1181/50000 (2.3620%),                 avg. length: 567.1,                last time consumption/overall running time: 34.2731s / 2066.7386 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2878
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2950
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 1201/50000 (2.4020%),                 avg. length: 583.0,                last time consumption/overall running time: 35.8994s / 2102.6380 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.3046
env0_second_0:                 episode reward: 0.4500,                 loss: 0.3081
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 1221/50000 (2.4420%),                 avg. length: 555.2,                last time consumption/overall running time: 33.8192s / 2136.4572 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2866
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2923
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 1241/50000 (2.4820%),                 avg. length: 584.25,                last time consumption/overall running time: 34.6641s / 2171.1213 s
env0_first_0:                 episode reward: 1.2000,                 loss: 0.2910
env0_second_0:                 episode reward: -1.2000,                 loss: 0.2995
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 1261/50000 (2.5220%),                 avg. length: 546.65,                last time consumption/overall running time: 34.5741s / 2205.6954 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2890
env0_second_0:                 episode reward: -0.3000,                 loss: 0.3057
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 1281/50000 (2.5620%),                 avg. length: 545.6,                last time consumption/overall running time: 34.1716s / 2239.8670 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2776
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2832
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 1301/50000 (2.6020%),                 avg. length: 559.0,                last time consumption/overall running time: 36.6455s / 2276.5125 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.3187
env0_second_0:                 episode reward: -0.1500,                 loss: 0.3273
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 1321/50000 (2.6420%),                 avg. length: 567.5,                last time consumption/overall running time: 34.2118s / 2310.7243 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.3345
env0_second_0:                 episode reward: -0.1500,                 loss: 0.3431
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 1341/50000 (2.6820%),                 avg. length: 563.85,                last time consumption/overall running time: 34.0380s / 2344.7624 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.3027
env0_second_0:                 episode reward: 0.6000,                 loss: 0.3050
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 1361/50000 (2.7220%),                 avg. length: 549.6,                last time consumption/overall running time: 34.7836s / 2379.5459 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.3252
env0_second_0:                 episode reward: -0.4500,                 loss: 0.3376
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 1381/50000 (2.7620%),                 avg. length: 570.8,                last time consumption/overall running time: 36.8771s / 2416.4230 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.3262
env0_second_0:                 episode reward: 0.5000,                 loss: 0.3264
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 1401/50000 (2.8020%),                 avg. length: 562.15,                last time consumption/overall running time: 33.8298s / 2450.2528 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.3190
env0_second_0:                 episode reward: 1.1000,                 loss: 0.3322
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 1421/50000 (2.8420%),                 avg. length: 567.2,                last time consumption/overall running time: 34.0667s / 2484.3196 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.3136
env0_second_0:                 episode reward: 0.2000,                 loss: 0.3304
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 1441/50000 (2.8820%),                 avg. length: 580.6,                last time consumption/overall running time: 35.5665s / 2519.8860 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.3462
env0_second_0:                 episode reward: 0.1500,                 loss: 0.3632
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 1461/50000 (2.9220%),                 avg. length: 593.35,                last time consumption/overall running time: 36.6760s / 2556.5621 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.3457
env0_second_0:                 episode reward: 0.7000,                 loss: 0.3534
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 1481/50000 (2.9620%),                 avg. length: 542.6,                last time consumption/overall running time: 32.9659s / 2589.5279 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.3060
env0_second_0:                 episode reward: 0.0500,                 loss: 0.3220
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 1501/50000 (3.0020%),                 avg. length: 595.45,                last time consumption/overall running time: 35.9806s / 2625.5086 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.3437
env0_second_0:                 episode reward: 0.4000,                 loss: 0.3507
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 1521/50000 (3.0420%),                 avg. length: 559.05,                last time consumption/overall running time: 33.5067s / 2659.0153 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.3036
env0_second_0:                 episode reward: -0.5500,                 loss: 0.3109
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 1541/50000 (3.0820%),                 avg. length: 594.35,                last time consumption/overall running time: 35.6939s / 2694.7092 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.3194
env0_second_0:                 episode reward: -0.2000,                 loss: 0.3254
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 1561/50000 (3.1220%),                 avg. length: 556.2,                last time consumption/overall running time: 33.5276s / 2728.2368 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.3088
env0_second_0:                 episode reward: 0.0500,                 loss: 0.3196
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 1581/50000 (3.1620%),                 avg. length: 559.4,                last time consumption/overall running time: 33.4175s / 2761.6543 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.3118
env0_second_0:                 episode reward: 0.1500,                 loss: 0.3163
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 1601/50000 (3.2020%),                 avg. length: 596.65,                last time consumption/overall running time: 35.5684s / 2797.2227 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.3135
env0_second_0:                 episode reward: 0.3500,                 loss: 0.3176
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 1621/50000 (3.2420%),                 avg. length: 581.9,                last time consumption/overall running time: 34.4555s / 2831.6782 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.3184
env0_second_0:                 episode reward: -0.6000,                 loss: 0.3257
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 1641/50000 (3.2820%),                 avg. length: 528.6,                last time consumption/overall running time: 34.6524s / 2866.3306 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.3409
env0_second_0:                 episode reward: 0.0000,                 loss: 0.3546
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 1661/50000 (3.3220%),                 avg. length: 560.8,                last time consumption/overall running time: 39.5213s / 2905.8519 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.3330
env0_second_0:                 episode reward: 0.4000,                 loss: 0.3440
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 1681/50000 (3.3620%),                 avg. length: 554.25,                last time consumption/overall running time: 33.4948s / 2939.3467 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.3282
env0_second_0:                 episode reward: 0.6500,                 loss: 0.3295
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 1701/50000 (3.4020%),                 avg. length: 557.25,                last time consumption/overall running time: 33.1437s / 2972.4904 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.3016
env0_second_0:                 episode reward: -0.3500,                 loss: 0.3075
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 1721/50000 (3.4420%),                 avg. length: 568.25,                last time consumption/overall running time: 34.2798s / 3006.7702 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.3025
env0_second_0:                 episode reward: 0.6000,                 loss: 0.3120
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1741/50000 (3.4820%),                 avg. length: 567.9,                last time consumption/overall running time: 34.0477s / 3040.8179 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.3453
env0_second_0:                 episode reward: 0.4500,                 loss: 0.3512
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 1761/50000 (3.5220%),                 avg. length: 538.5,                last time consumption/overall running time: 32.4345s / 3073.2524 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.3090
env0_second_0:                 episode reward: -0.2000,                 loss: 0.3090
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1781/50000 (3.5620%),                 avg. length: 563.0,                last time consumption/overall running time: 33.5764s / 3106.8287 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.3326
env0_second_0:                 episode reward: -0.2500,                 loss: 0.3360
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 1801/50000 (3.6020%),                 avg. length: 537.65,                last time consumption/overall running time: 32.2386s / 3139.0673 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.3244
env0_second_0:                 episode reward: -0.6000,                 loss: 0.3361
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 1821/50000 (3.6420%),                 avg. length: 529.0,                last time consumption/overall running time: 31.8287s / 3170.8960 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.3191
env0_second_0:                 episode reward: -0.6000,                 loss: 0.3294
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 1841/50000 (3.6820%),                 avg. length: 549.35,                last time consumption/overall running time: 33.3065s / 3204.2025 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.3546
env0_second_0:                 episode reward: 0.2000,                 loss: 0.3629
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 1861/50000 (3.7220%),                 avg. length: 565.9,                last time consumption/overall running time: 33.8130s / 3238.0155 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.3535
env0_second_0:                 episode reward: -0.8000,                 loss: 0.3669
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1881/50000 (3.7620%),                 avg. length: 611.0,                last time consumption/overall running time: 36.0565s / 3274.0720 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.3347
env0_second_0:                 episode reward: 0.8000,                 loss: 0.3413
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 1901/50000 (3.8020%),                 avg. length: 546.45,                last time consumption/overall running time: 33.4754s / 3307.5474 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.3373
env0_second_0:                 episode reward: -0.1000,                 loss: 0.3490
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 1921/50000 (3.8420%),                 avg. length: 571.9,                last time consumption/overall running time: 34.2063s / 3341.7538 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.3420
env0_second_0:                 episode reward: 0.1500,                 loss: 0.3401
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 1941/50000 (3.8820%),                 avg. length: 598.9,                last time consumption/overall running time: 35.7027s / 3377.4565 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.3382
env0_second_0:                 episode reward: -0.3500,                 loss: 0.3532
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1961/50000 (3.9220%),                 avg. length: 549.2,                last time consumption/overall running time: 32.8151s / 3410.2716 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.3501
env0_second_0:                 episode reward: -0.6000,                 loss: 0.3607
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1981/50000 (3.9620%),                 avg. length: 565.25,                last time consumption/overall running time: 33.5803s / 3443.8519 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.3209
env0_second_0:                 episode reward: 0.4500,                 loss: 0.3319
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 2001/50000 (4.0020%),                 avg. length: 591.65,                last time consumption/overall running time: 35.1872s / 3479.0391 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.3524
env0_second_0:                 episode reward: -0.8000,                 loss: 0.3543
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 2021/50000 (4.0420%),                 avg. length: 577.85,                last time consumption/overall running time: 34.9592s / 3513.9983 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.3537
env0_second_0:                 episode reward: 0.1000,                 loss: 0.3535
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 2041/50000 (4.0820%),                 avg. length: 564.35,                last time consumption/overall running time: 35.6748s / 3549.6731 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.3673
env0_second_0:                 episode reward: 0.1500,                 loss: 0.3679
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 2061/50000 (4.1220%),                 avg. length: 548.7,                last time consumption/overall running time: 34.1466s / 3583.8197 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.3473
env0_second_0:                 episode reward: 0.9000,                 loss: 0.3552
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 2081/50000 (4.1620%),                 avg. length: 546.65,                last time consumption/overall running time: 33.9263s / 3617.7460 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.3541
env0_second_0:                 episode reward: 1.2000,                 loss: 0.3601
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 2101/50000 (4.2020%),                 avg. length: 574.9,                last time consumption/overall running time: 34.1707s / 3651.9167 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.3424
env0_second_0:                 episode reward: -0.1000,                 loss: 0.3503
env1_first_0:                 episode reward: -1.5000,                 loss: nan
env1_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 2121/50000 (4.2420%),                 avg. length: 544.25,                last time consumption/overall running time: 32.9374s / 3684.8541 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.3188
env0_second_0:                 episode reward: -0.1000,                 loss: 0.3352
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 2141/50000 (4.2820%),                 avg. length: 561.45,                last time consumption/overall running time: 33.3689s / 3718.2230 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.3350
env0_second_0:                 episode reward: 0.6000,                 loss: 0.3482
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 2161/50000 (4.3220%),                 avg. length: 586.85,                last time consumption/overall running time: 34.7160s / 3752.9390 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.3213
env0_second_0:                 episode reward: 0.2500,                 loss: 0.3342
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 2181/50000 (4.3620%),                 avg. length: 558.1,                last time consumption/overall running time: 33.7546s / 3786.6936 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.3298
env0_second_0:                 episode reward: 0.1500,                 loss: 0.3396
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 2201/50000 (4.4020%),                 avg. length: 563.35,                last time consumption/overall running time: 33.6040s / 3820.2976 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.3160
env0_second_0:                 episode reward: -0.5000,                 loss: 0.3334
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 2221/50000 (4.4420%),                 avg. length: 618.45,                last time consumption/overall running time: 36.2427s / 3856.5403 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.3100
env0_second_0:                 episode reward: 0.3500,                 loss: 0.3275
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 2241/50000 (4.4820%),                 avg. length: 545.6,                last time consumption/overall running time: 36.7460s / 3893.2864 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.3109
env0_second_0:                 episode reward: 0.4500,                 loss: 0.3203
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 2261/50000 (4.5220%),                 avg. length: 583.85,                last time consumption/overall running time: 34.7520s / 3928.0384 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.3018
env0_second_0:                 episode reward: -0.2500,                 loss: 0.3138
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 2281/50000 (4.5620%),                 avg. length: 563.4,                last time consumption/overall running time: 34.1883s / 3962.2267 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.3310
env0_second_0:                 episode reward: 0.5500,                 loss: 0.3397
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 2301/50000 (4.6020%),                 avg. length: 633.35,                last time consumption/overall running time: 37.5387s / 3999.7654 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.3115
env0_second_0:                 episode reward: 0.4500,                 loss: 0.3228
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 2321/50000 (4.6420%),                 avg. length: 526.95,                last time consumption/overall running time: 39.4365s / 4039.2019 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.3232
env0_second_0:                 episode reward: 0.2000,                 loss: 0.3325
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 2341/50000 (4.6820%),                 avg. length: 593.5,                last time consumption/overall running time: 35.2056s / 4074.4075 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.3244
env0_second_0:                 episode reward: 0.6500,                 loss: 0.3301
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 2361/50000 (4.7220%),                 avg. length: 573.2,                last time consumption/overall running time: 34.0338s / 4108.4413 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.3330
env0_second_0:                 episode reward: -0.7000,                 loss: 0.3343
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 2381/50000 (4.7620%),                 avg. length: 563.85,                last time consumption/overall running time: 33.6737s / 4142.1150 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.3363
env0_second_0:                 episode reward: -0.5000,                 loss: 0.3448
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 2401/50000 (4.8020%),                 avg. length: 584.8,                last time consumption/overall running time: 34.7782s / 4176.8932 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.3449
env0_second_0:                 episode reward: 0.5000,                 loss: 0.3500
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 2421/50000 (4.8420%),                 avg. length: 585.1,                last time consumption/overall running time: 34.8952s / 4211.7884 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.3192
env0_second_0:                 episode reward: 0.2000,                 loss: 0.3263
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 2441/50000 (4.8820%),                 avg. length: 543.2,                last time consumption/overall running time: 33.4364s / 4245.2248 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.3253
env0_second_0:                 episode reward: 0.3000,                 loss: 0.3336
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 2461/50000 (4.9220%),                 avg. length: 578.75,                last time consumption/overall running time: 35.3074s / 4280.5322 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.3363
env0_second_0:                 episode reward: -0.2000,                 loss: 0.3419
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 2481/50000 (4.9620%),                 avg. length: 598.4,                last time consumption/overall running time: 35.8505s / 4316.3827 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.3336
env0_second_0:                 episode reward: -0.0500,                 loss: 0.3284
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 2501/50000 (5.0020%),                 avg. length: 533.75,                last time consumption/overall running time: 36.2296s / 4352.6123 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.3306
env0_second_0:                 episode reward: 0.8000,                 loss: 0.3384
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 2521/50000 (5.0420%),                 avg. length: 575.7,                last time consumption/overall running time: 34.3336s / 4386.9459 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.3502
env0_second_0:                 episode reward: 0.6500,                 loss: 0.3542
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 2541/50000 (5.0820%),                 avg. length: 566.25,                last time consumption/overall running time: 33.7219s / 4420.6678 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.3257
env0_second_0:                 episode reward: -0.1500,                 loss: 0.3392
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 2561/50000 (5.1220%),                 avg. length: 588.1,                last time consumption/overall running time: 34.7964s / 4455.4642 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.3124
env0_second_0:                 episode reward: 0.1000,                 loss: 0.3200
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 2581/50000 (5.1620%),                 avg. length: 539.0,                last time consumption/overall running time: 36.1160s / 4491.5803 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2998
env0_second_0:                 episode reward: -0.3500,                 loss: 0.3161
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 2601/50000 (5.2020%),                 avg. length: 557.4,                last time consumption/overall running time: 33.3668s / 4524.9471 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.3125
env0_second_0:                 episode reward: 0.0500,                 loss: 0.3204
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 2621/50000 (5.2420%),                 avg. length: 571.75,                last time consumption/overall running time: 34.7189s / 4559.6660 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.2920
env0_second_0:                 episode reward: -1.0000,                 loss: 0.3167
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 2641/50000 (5.2820%),                 avg. length: 570.25,                last time consumption/overall running time: 34.6500s / 4594.3160 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.3060
env0_second_0:                 episode reward: 0.5000,                 loss: 0.3105
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 2661/50000 (5.3220%),                 avg. length: 533.65,                last time consumption/overall running time: 33.0472s / 4627.3632 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2973
env0_second_0:                 episode reward: -0.1000,                 loss: 0.3055
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 2681/50000 (5.3620%),                 avg. length: 559.9,                last time consumption/overall running time: 33.7756s / 4661.1388 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2700
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2696
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 2701/50000 (5.4020%),                 avg. length: 605.15,                last time consumption/overall running time: 36.2589s / 4697.3977 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2799
env0_second_0:                 episode reward: 0.5000,                 loss: 0.2963
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 2721/50000 (5.4420%),                 avg. length: 572.5,                last time consumption/overall running time: 34.7840s / 4732.1817 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2657
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2859
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 2741/50000 (5.4820%),                 avg. length: 583.0,                last time consumption/overall running time: 35.5570s / 4767.7386 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.3021
env0_second_0:                 episode reward: 0.1500,                 loss: 0.3216
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 2761/50000 (5.5220%),                 avg. length: 534.05,                last time consumption/overall running time: 33.1966s / 4800.9353 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2820
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2906
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 2781/50000 (5.5620%),                 avg. length: 557.2,                last time consumption/overall running time: 33.7527s / 4834.6879 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.3074
env0_second_0:                 episode reward: 0.1500,                 loss: 0.3239
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 2801/50000 (5.6020%),                 avg. length: 570.15,                last time consumption/overall running time: 34.8514s / 4869.5393 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2911
env0_second_0:                 episode reward: -0.1500,                 loss: 0.3019
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 2821/50000 (5.6420%),                 avg. length: 518.25,                last time consumption/overall running time: 32.2988s / 4901.8381 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2950
env0_second_0:                 episode reward: 0.2500,                 loss: 0.3110
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 2841/50000 (5.6820%),                 avg. length: 548.4,                last time consumption/overall running time: 32.9720s / 4934.8102 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2825
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2967
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 2861/50000 (5.7220%),                 avg. length: 570.0,                last time consumption/overall running time: 33.9030s / 4968.7132 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.2843
env0_second_0:                 episode reward: 0.9500,                 loss: 0.2959
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 2881/50000 (5.7620%),                 avg. length: 564.7,                last time consumption/overall running time: 33.6112s / 5002.3244 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2793
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2848
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 2901/50000 (5.8020%),                 avg. length: 581.4,                last time consumption/overall running time: 34.3526s / 5036.6770 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2628
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2729
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 2921/50000 (5.8420%),                 avg. length: 563.6,                last time consumption/overall running time: 33.5677s / 5070.2447 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2884
env0_second_0:                 episode reward: -0.5500,                 loss: 0.3057
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 2941/50000 (5.8820%),                 avg. length: 515.05,                last time consumption/overall running time: 30.9830s / 5101.2277 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2851
env0_second_0:                 episode reward: -0.5500,                 loss: 0.2897
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 2961/50000 (5.9220%),                 avg. length: 574.25,                last time consumption/overall running time: 34.1509s / 5135.3786 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2810
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2957
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 2981/50000 (5.9620%),                 avg. length: 565.9,                last time consumption/overall running time: 33.7006s / 5169.0792 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2797
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2950
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 3001/50000 (6.0020%),                 avg. length: 539.65,                last time consumption/overall running time: 32.3820s / 5201.4611 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.3063
env0_second_0:                 episode reward: 0.8000,                 loss: 0.3112
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 3021/50000 (6.0420%),                 avg. length: 533.0,                last time consumption/overall running time: 32.0110s / 5233.4721 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2981
env0_second_0:                 episode reward: -0.6000,                 loss: 0.3107
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 3041/50000 (6.0820%),                 avg. length: 524.15,                last time consumption/overall running time: 31.4634s / 5264.9355 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.3047
env0_second_0:                 episode reward: -0.1500,                 loss: 0.3162
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 3061/50000 (6.1220%),                 avg. length: 580.4,                last time consumption/overall running time: 34.3273s / 5299.2628 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.2986
env0_second_0:                 episode reward: -0.4500,                 loss: 0.3032
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 3081/50000 (6.1620%),                 avg. length: 557.65,                last time consumption/overall running time: 33.3900s / 5332.6528 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.3137
env0_second_0:                 episode reward: 1.2000,                 loss: 0.3232
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 3101/50000 (6.2020%),                 avg. length: 595.8,                last time consumption/overall running time: 36.7315s / 5369.3843 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.3032
env0_second_0:                 episode reward: 1.0500,                 loss: 0.3219
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 3121/50000 (6.2420%),                 avg. length: 551.35,                last time consumption/overall running time: 33.1680s / 5402.5523 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.2689
env0_second_0:                 episode reward: -0.9500,                 loss: 0.3033
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 3141/50000 (6.2820%),                 avg. length: 574.85,                last time consumption/overall running time: 34.4058s / 5436.9581 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2796
env0_second_0:                 episode reward: 0.6500,                 loss: 0.3008
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 3161/50000 (6.3220%),                 avg. length: 578.0,                last time consumption/overall running time: 34.5969s / 5471.5550 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2312
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2637
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 3181/50000 (6.3620%),                 avg. length: 572.15,                last time consumption/overall running time: 34.5617s / 5506.1167 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2562
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2739
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 3201/50000 (6.4020%),                 avg. length: 577.0,                last time consumption/overall running time: 35.5252s / 5541.6418 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2484
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2582
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 3221/50000 (6.4420%),                 avg. length: 569.45,                last time consumption/overall running time: 35.4842s / 5577.1260 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.2438
env0_second_0:                 episode reward: -0.7500,                 loss: 0.2681
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 3241/50000 (6.4820%),                 avg. length: 580.65,                last time consumption/overall running time: 35.5338s / 5612.6598 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.2476
env0_second_0:                 episode reward: -1.0000,                 loss: 0.2772
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 3261/50000 (6.5220%),                 avg. length: 575.85,                last time consumption/overall running time: 34.8162s / 5647.4760 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2934
env0_second_0:                 episode reward: -0.3000,                 loss: 0.3137
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 3281/50000 (6.5620%),                 avg. length: 588.4,                last time consumption/overall running time: 35.3093s / 5682.7852 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.3273
env0_second_0:                 episode reward: -0.0500,                 loss: 0.3481
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 3301/50000 (6.6020%),                 avg. length: 604.8,                last time consumption/overall running time: 36.2575s / 5719.0428 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2837
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2985
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 3321/50000 (6.6420%),                 avg. length: 562.4,                last time consumption/overall running time: 33.9860s / 5753.0288 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2824
env0_second_0:                 episode reward: 0.5000,                 loss: 0.2972
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 3341/50000 (6.6820%),                 avg. length: 528.25,                last time consumption/overall running time: 32.2922s / 5785.3210 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2964
env0_second_0:                 episode reward: 0.6500,                 loss: 0.3121
env1_first_0:                 episode reward: 1.6000,                 loss: nan
env1_second_0:                 episode reward: -1.6000,                 loss: nan
Episode: 3361/50000 (6.7220%),                 avg. length: 559.9,                last time consumption/overall running time: 34.0031s / 5819.3241 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.2835
env0_second_0:                 episode reward: -0.8500,                 loss: 0.3072
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 3381/50000 (6.7620%),                 avg. length: 556.3,                last time consumption/overall running time: 33.6292s / 5852.9533 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.2816
env0_second_0:                 episode reward: -1.0000,                 loss: 0.2982
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 3401/50000 (6.8020%),                 avg. length: 574.15,                last time consumption/overall running time: 35.0442s / 5887.9975 s
env0_first_0:                 episode reward: 1.1000,                 loss: 0.2877
env0_second_0:                 episode reward: -1.1000,                 loss: 0.2948
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 3421/50000 (6.8420%),                 avg. length: 582.25,                last time consumption/overall running time: 35.1089s / 5923.1064 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2818
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2930
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 3441/50000 (6.8820%),                 avg. length: 553.8,                last time consumption/overall running time: 34.0548s / 5957.1612 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2803
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2911
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 3461/50000 (6.9220%),                 avg. length: 553.3,                last time consumption/overall running time: 33.4722s / 5990.6334 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.3242
env0_second_0:                 episode reward: -0.7000,                 loss: 0.3363
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 3481/50000 (6.9620%),                 avg. length: 581.3,                last time consumption/overall running time: 34.9124s / 6025.5459 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.3051
env0_second_0:                 episode reward: -0.1000,                 loss: 0.3179
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 3501/50000 (7.0020%),                 avg. length: 532.7,                last time consumption/overall running time: 32.3546s / 6057.9005 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2538
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2705
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 3521/50000 (7.0420%),                 avg. length: 583.3,                last time consumption/overall running time: 36.0738s / 6093.9743 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.2927
env0_second_0:                 episode reward: -0.7000,                 loss: 0.3166
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 3541/50000 (7.0820%),                 avg. length: 575.3,                last time consumption/overall running time: 34.7963s / 6128.7707 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2909
env0_second_0:                 episode reward: -0.0500,                 loss: 0.3078
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 3561/50000 (7.1220%),                 avg. length: 549.4,                last time consumption/overall running time: 34.3861s / 6163.1568 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2924
env0_second_0:                 episode reward: 0.2000,                 loss: 0.3023
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 3581/50000 (7.1620%),                 avg. length: 595.35,                last time consumption/overall running time: 35.2711s / 6198.4279 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.3024
env0_second_0:                 episode reward: 0.2000,                 loss: 0.3046
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 3601/50000 (7.2020%),                 avg. length: 555.05,                last time consumption/overall running time: 34.7899s / 6233.2178 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.3062
env0_second_0:                 episode reward: 0.3500,                 loss: 0.3284
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 3621/50000 (7.2420%),                 avg. length: 552.9,                last time consumption/overall running time: 34.6532s / 6267.8710 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.3262
env0_second_0:                 episode reward: 0.1000,                 loss: 0.3258
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 3641/50000 (7.2820%),                 avg. length: 576.8,                last time consumption/overall running time: 34.9868s / 6302.8578 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.3044
env0_second_0:                 episode reward: 0.5000,                 loss: 0.3111
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 3661/50000 (7.3220%),                 avg. length: 592.85,                last time consumption/overall running time: 35.2882s / 6338.1460 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.3055
env0_second_0:                 episode reward: -1.0000,                 loss: 0.3063
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 3681/50000 (7.3620%),                 avg. length: 538.0,                last time consumption/overall running time: 32.6012s / 6370.7472 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.3088
env0_second_0:                 episode reward: -0.6500,                 loss: 0.3160
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 3701/50000 (7.4020%),                 avg. length: 555.0,                last time consumption/overall running time: 33.9711s / 6404.7183 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.3155
env0_second_0:                 episode reward: -0.5500,                 loss: 0.3266
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 3721/50000 (7.4420%),                 avg. length: 540.15,                last time consumption/overall running time: 32.8906s / 6437.6089 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.2890
env0_second_0:                 episode reward: 0.6000,                 loss: 0.2974
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 3741/50000 (7.4820%),                 avg. length: 561.45,                last time consumption/overall running time: 34.0593s / 6471.6682 s
env0_first_0:                 episode reward: 1.3000,                 loss: 0.3059
env0_second_0:                 episode reward: -1.3000,                 loss: 0.3229
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 3761/50000 (7.5220%),                 avg. length: 576.3,                last time consumption/overall running time: 34.6319s / 6506.3001 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2984
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2981
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 3781/50000 (7.5620%),                 avg. length: 539.45,                last time consumption/overall running time: 32.4319s / 6538.7320 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2891
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2938
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 3801/50000 (7.6020%),                 avg. length: 567.7,                last time consumption/overall running time: 33.8854s / 6572.6174 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2957
env0_second_0:                 episode reward: -0.4000,                 loss: 0.3186
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 3821/50000 (7.6420%),                 avg. length: 564.75,                last time consumption/overall running time: 33.4693s / 6606.0868 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.3120
env0_second_0:                 episode reward: 0.5500,                 loss: 0.3282
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 3841/50000 (7.6820%),                 avg. length: 561.85,                last time consumption/overall running time: 33.8944s / 6639.9812 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.3025
env0_second_0:                 episode reward: 0.0500,                 loss: 0.3175
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 3861/50000 (7.7220%),                 avg. length: 530.8,                last time consumption/overall running time: 32.9676s / 6672.9488 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.3174
env0_second_0:                 episode reward: -0.1000,                 loss: 0.3224
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 3881/50000 (7.7620%),                 avg. length: 575.95,                last time consumption/overall running time: 34.6717s / 6707.6205 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.3540
env0_second_0:                 episode reward: -0.7500,                 loss: 0.3691
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 3901/50000 (7.8020%),                 avg. length: 588.8,                last time consumption/overall running time: 35.1909s / 6742.8114 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.3043
env0_second_0:                 episode reward: 0.0500,                 loss: 0.3191
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 3921/50000 (7.8420%),                 avg. length: 558.75,                last time consumption/overall running time: 33.6999s / 6776.5113 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.3256
env0_second_0:                 episode reward: 0.7500,                 loss: 0.3322
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 3941/50000 (7.8820%),                 avg. length: 575.0,                last time consumption/overall running time: 34.5385s / 6811.0498 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2915
env0_second_0:                 episode reward: 0.5000,                 loss: 0.3057
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 3961/50000 (7.9220%),                 avg. length: 569.95,                last time consumption/overall running time: 34.8893s / 6845.9391 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.3045
env0_second_0:                 episode reward: 0.5000,                 loss: 0.3111
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 3981/50000 (7.9620%),                 avg. length: 573.4,                last time consumption/overall running time: 34.1915s / 6880.1306 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.3114
env0_second_0:                 episode reward: 0.4500,                 loss: 0.3232
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 4001/50000 (8.0020%),                 avg. length: 551.75,                last time consumption/overall running time: 34.6442s / 6914.7747 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.3106
env0_second_0:                 episode reward: 0.1000,                 loss: 0.3152
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 4021/50000 (8.0420%),                 avg. length: 548.2,                last time consumption/overall running time: 32.7439s / 6947.5186 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.3119
env0_second_0:                 episode reward: 0.1500,                 loss: 0.3170
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 4041/50000 (8.0820%),                 avg. length: 559.1,                last time consumption/overall running time: 33.8044s / 6981.3230 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.3419
env0_second_0:                 episode reward: -0.2000,                 loss: 0.3493
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 4061/50000 (8.1220%),                 avg. length: 580.8,                last time consumption/overall running time: 34.3708s / 7015.6939 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.3401
env0_second_0:                 episode reward: 0.2000,                 loss: 0.3420
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4081/50000 (8.1620%),                 avg. length: 575.45,                last time consumption/overall running time: 34.1232s / 7049.8171 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.3143
env0_second_0:                 episode reward: 0.6500,                 loss: 0.3214
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 4101/50000 (8.2020%),                 avg. length: 562.55,                last time consumption/overall running time: 33.6859s / 7083.5030 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.3064
env0_second_0:                 episode reward: 0.9000,                 loss: 0.3232
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 4121/50000 (8.2420%),                 avg. length: 565.4,                last time consumption/overall running time: 33.9673s / 7117.4703 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.3003
env0_second_0:                 episode reward: 0.1500,                 loss: 0.3037
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 4141/50000 (8.2820%),                 avg. length: 604.75,                last time consumption/overall running time: 35.7071s / 7153.1774 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.2790
env0_second_0:                 episode reward: 0.6000,                 loss: 0.2934
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 4161/50000 (8.3220%),                 avg. length: 569.75,                last time consumption/overall running time: 33.8979s / 7187.0753 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.3257
env0_second_0:                 episode reward: 0.0500,                 loss: 0.3350
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 4181/50000 (8.3620%),                 avg. length: 579.65,                last time consumption/overall running time: 34.3034s / 7221.3787 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2975
env0_second_0:                 episode reward: -0.5000,                 loss: 0.3112
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 4201/50000 (8.4020%),                 avg. length: 561.05,                last time consumption/overall running time: 33.2235s / 7254.6022 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2944
env0_second_0:                 episode reward: 0.4000,                 loss: 0.3087
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 4221/50000 (8.4420%),                 avg. length: 553.25,                last time consumption/overall running time: 32.9464s / 7287.5486 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.3059
env0_second_0:                 episode reward: 0.1500,                 loss: 0.3068
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 4241/50000 (8.4820%),                 avg. length: 560.9,                last time consumption/overall running time: 33.5773s / 7321.1259 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2979
env0_second_0:                 episode reward: -0.5000,                 loss: 0.3001
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 4261/50000 (8.5220%),                 avg. length: 579.05,                last time consumption/overall running time: 34.7149s / 7355.8408 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.3062
env0_second_0:                 episode reward: 0.4500,                 loss: 0.3077
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 4281/50000 (8.5620%),                 avg. length: 561.55,                last time consumption/overall running time: 34.3584s / 7390.1992 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.3039
env0_second_0:                 episode reward: 0.4500,                 loss: 0.3050
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 4301/50000 (8.6020%),                 avg. length: 569.3,                last time consumption/overall running time: 34.8766s / 7425.0758 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.2991
env0_second_0:                 episode reward: 1.0500,                 loss: 0.3065
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 4321/50000 (8.6420%),                 avg. length: 538.4,                last time consumption/overall running time: 32.5816s / 7457.6574 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.2971
env0_second_0:                 episode reward: -0.7000,                 loss: 0.3103
env1_first_0:                 episode reward: 1.9500,                 loss: nan
env1_second_0:                 episode reward: -1.9500,                 loss: nan
Episode: 4341/50000 (8.6820%),                 avg. length: 561.15,                last time consumption/overall running time: 33.3527s / 7491.0100 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.3210
env0_second_0:                 episode reward: 1.1500,                 loss: 0.3294
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 4361/50000 (8.7220%),                 avg. length: 556.5,                last time consumption/overall running time: 33.3675s / 7524.3775 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2947
env0_second_0:                 episode reward: 0.0000,                 loss: 0.3103
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 4381/50000 (8.7620%),                 avg. length: 586.3,                last time consumption/overall running time: 34.9950s / 7559.3725 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.3261
env0_second_0:                 episode reward: 0.7500,                 loss: 0.3310
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 4401/50000 (8.8020%),                 avg. length: 579.85,                last time consumption/overall running time: 35.7259s / 7595.0984 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.3236
env0_second_0:                 episode reward: -0.6000,                 loss: 0.3266
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 4421/50000 (8.8420%),                 avg. length: 590.9,                last time consumption/overall running time: 36.5916s / 7631.6900 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2823
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2912
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 4441/50000 (8.8820%),                 avg. length: 545.1,                last time consumption/overall running time: 33.2555s / 7664.9455 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.2979
env0_second_0:                 episode reward: 0.8500,                 loss: 0.3132
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 4461/50000 (8.9220%),                 avg. length: 559.05,                last time consumption/overall running time: 33.4337s / 7698.3792 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.3064
env0_second_0:                 episode reward: -1.2500,                 loss: 0.3076
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 4481/50000 (8.9620%),                 avg. length: 538.15,                last time consumption/overall running time: 32.6128s / 7730.9921 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.3152
env0_second_0:                 episode reward: -0.4000,                 loss: 0.3434
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 4501/50000 (9.0020%),                 avg. length: 553.9,                last time consumption/overall running time: 37.8955s / 7768.8876 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.3117
env0_second_0:                 episode reward: 1.3000,                 loss: 0.3220
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 4521/50000 (9.0420%),                 avg. length: 530.9,                last time consumption/overall running time: 33.3968s / 7802.2844 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.3085
env0_second_0:                 episode reward: 0.3000,                 loss: 0.3110
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 4541/50000 (9.0820%),                 avg. length: 592.9,                last time consumption/overall running time: 35.1788s / 7837.4632 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.3381
env0_second_0:                 episode reward: 0.2000,                 loss: 0.3347
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 4561/50000 (9.1220%),                 avg. length: 553.3,                last time consumption/overall running time: 33.0953s / 7870.5584 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.3200
env0_second_0:                 episode reward: 0.1000,                 loss: 0.3308
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 4581/50000 (9.1620%),                 avg. length: 575.7,                last time consumption/overall running time: 38.0217s / 7908.5801 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.3524
env0_second_0:                 episode reward: 0.7500,                 loss: 0.3495
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 4601/50000 (9.2020%),                 avg. length: 548.65,                last time consumption/overall running time: 35.5200s / 7944.1002 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.3322
env0_second_0:                 episode reward: 0.1000,                 loss: 0.3253
env1_first_0:                 episode reward: -1.5000,                 loss: nan
env1_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 4621/50000 (9.2420%),                 avg. length: 545.0,                last time consumption/overall running time: 33.5707s / 7977.6709 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.3349
env0_second_0:                 episode reward: -0.0500,                 loss: 0.3494
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 4641/50000 (9.2820%),                 avg. length: 534.55,                last time consumption/overall running time: 32.5082s / 8010.1791 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.3229
env0_second_0:                 episode reward: 0.5000,                 loss: 0.3422
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 4661/50000 (9.3220%),                 avg. length: 587.6,                last time consumption/overall running time: 36.0769s / 8046.2560 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.3501
env0_second_0:                 episode reward: 0.2500,                 loss: 0.3571
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 4681/50000 (9.3620%),                 avg. length: 553.15,                last time consumption/overall running time: 44.8191s / 8091.0751 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.3190
env0_second_0:                 episode reward: -0.2000,                 loss: 0.3251
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 4701/50000 (9.4020%),                 avg. length: 574.0,                last time consumption/overall running time: 37.8247s / 8128.8999 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.3160
env0_second_0:                 episode reward: -0.2500,                 loss: 0.3178
env1_first_0:                 episode reward: 1.5000,                 loss: nan
env1_second_0:                 episode reward: -1.5000,                 loss: nan
Episode: 4721/50000 (9.4420%),                 avg. length: 567.9,                last time consumption/overall running time: 34.5410s / 8163.4408 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2952
env0_second_0:                 episode reward: -0.3000,                 loss: 0.3141
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 4741/50000 (9.4820%),                 avg. length: 544.55,                last time consumption/overall running time: 33.7242s / 8197.1651 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.3127
env0_second_0:                 episode reward: 0.8000,                 loss: 0.3165
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 4761/50000 (9.5220%),                 avg. length: 599.8,                last time consumption/overall running time: 40.3749s / 8237.5400 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.3155
env0_second_0:                 episode reward: 0.3000,                 loss: 0.3350
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 4781/50000 (9.5620%),                 avg. length: 593.65,                last time consumption/overall running time: 43.4544s / 8280.9944 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.3210
env0_second_0:                 episode reward: 0.5000,                 loss: 0.3303
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 4801/50000 (9.6020%),                 avg. length: 573.05,                last time consumption/overall running time: 34.7838s / 8315.7782 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.3020
env0_second_0:                 episode reward: 0.1000,                 loss: 0.3294
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 4821/50000 (9.6420%),                 avg. length: 568.3,                last time consumption/overall running time: 35.0651s / 8350.8432 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.3218
env0_second_0:                 episode reward: 0.4000,                 loss: 0.3435
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 4841/50000 (9.6820%),                 avg. length: 566.15,                last time consumption/overall running time: 40.5901s / 8391.4334 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.3341
env0_second_0:                 episode reward: 0.7500,                 loss: 0.3452
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 4861/50000 (9.7220%),                 avg. length: 581.35,                last time consumption/overall running time: 41.8219s / 8433.2552 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.3149
env0_second_0:                 episode reward: 0.1500,                 loss: 0.3180
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 4881/50000 (9.7620%),                 avg. length: 589.7,                last time consumption/overall running time: 35.6442s / 8468.8994 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.3386
env0_second_0:                 episode reward: -0.5500,                 loss: 0.3494
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 4901/50000 (9.8020%),                 avg. length: 578.4,                last time consumption/overall running time: 37.6053s / 8506.5047 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.3228
env0_second_0:                 episode reward: -0.4000,                 loss: 0.3323
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 4921/50000 (9.8420%),                 avg. length: 584.5,                last time consumption/overall running time: 39.5058s / 8546.0105 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.3256
env0_second_0:                 episode reward: 0.6500,                 loss: 0.3263
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 4941/50000 (9.8820%),                 avg. length: 575.0,                last time consumption/overall running time: 34.4994s / 8580.5099 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.3212
env0_second_0:                 episode reward: -0.2500,                 loss: 0.3287
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4961/50000 (9.9220%),                 avg. length: 538.3,                last time consumption/overall running time: 32.4935s / 8613.0035 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.3104
env0_second_0:                 episode reward: -0.3000,                 loss: 0.3201
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 4981/50000 (9.9620%),                 avg. length: 567.05,                last time consumption/overall running time: 35.5312s / 8648.5347 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.3264
env0_second_0:                 episode reward: 0.1000,                 loss: 0.3284
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 5001/50000 (10.0020%),                 avg. length: 548.05,                last time consumption/overall running time: 34.0536s / 8682.5882 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.3240
env0_second_0:                 episode reward: -0.7500,                 loss: 0.3415
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 5021/50000 (10.0420%),                 avg. length: 576.8,                last time consumption/overall running time: 42.7146s / 8725.3028 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.3089
env0_second_0:                 episode reward: 0.2500,                 loss: 0.3143
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 5041/50000 (10.0820%),                 avg. length: 524.5,                last time consumption/overall running time: 32.0794s / 8757.3822 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2903
env0_second_0:                 episode reward: -0.1000,                 loss: 0.3010
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 5061/50000 (10.1220%),                 avg. length: 522.45,                last time consumption/overall running time: 31.9877s / 8789.3699 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.2731
env0_second_0:                 episode reward: 1.1000,                 loss: 0.2877
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 5081/50000 (10.1620%),                 avg. length: 565.8,                last time consumption/overall running time: 34.2414s / 8823.6114 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.2949
env0_second_0:                 episode reward: -0.7500,                 loss: 0.3176
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 5101/50000 (10.2020%),                 avg. length: 569.55,                last time consumption/overall running time: 52.5101s / 8876.1215 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.3175
env0_second_0:                 episode reward: -0.2000,                 loss: 0.3340
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 5121/50000 (10.2420%),                 avg. length: 558.95,                last time consumption/overall running time: 34.2967s / 8910.4182 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.3390
env0_second_0:                 episode reward: -0.1000,                 loss: 0.3507
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 5141/50000 (10.2820%),                 avg. length: 564.25,                last time consumption/overall running time: 33.9268s / 8944.3450 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.3770
env0_second_0:                 episode reward: 0.1500,                 loss: 0.3918
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 5161/50000 (10.3220%),                 avg. length: 553.1,                last time consumption/overall running time: 33.8498s / 8978.1948 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.3429
env0_second_0:                 episode reward: -0.4500,                 loss: 0.3572
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 5181/50000 (10.3620%),                 avg. length: 557.55,                last time consumption/overall running time: 36.5455s / 9014.7403 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.3406
env0_second_0:                 episode reward: 0.5000,                 loss: 0.3577
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 5201/50000 (10.4020%),                 avg. length: 567.35,                last time consumption/overall running time: 35.1155s / 9049.8558 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.3440
env0_second_0:                 episode reward: -0.7500,                 loss: 0.3581
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 5221/50000 (10.4420%),                 avg. length: 606.45,                last time consumption/overall running time: 36.3096s / 9086.1654 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.3372
env0_second_0:                 episode reward: 0.0500,                 loss: 0.3440
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 5241/50000 (10.4820%),                 avg. length: 554.8,                last time consumption/overall running time: 35.4660s / 9121.6314 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.3583
env0_second_0:                 episode reward: 0.6500,                 loss: 0.3697
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 5261/50000 (10.5220%),                 avg. length: 594.9,                last time consumption/overall running time: 45.0323s / 9166.6637 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.3320
env0_second_0:                 episode reward: -0.6000,                 loss: 0.3446
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 5281/50000 (10.5620%),                 avg. length: 574.55,                last time consumption/overall running time: 35.7817s / 9202.4454 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.3343
env0_second_0:                 episode reward: -0.7500,                 loss: 0.3428
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 5301/50000 (10.6020%),                 avg. length: 533.45,                last time consumption/overall running time: 32.2813s / 9234.7266 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.3242
env0_second_0:                 episode reward: 0.1000,                 loss: 0.3389
env1_first_0:                 episode reward: 1.6500,                 loss: nan
env1_second_0:                 episode reward: -1.6500,                 loss: nan
Episode: 5321/50000 (10.6420%),                 avg. length: 566.0,                last time consumption/overall running time: 34.8152s / 9269.5418 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.3250
env0_second_0:                 episode reward: 0.2000,                 loss: 0.3439
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 5341/50000 (10.6820%),                 avg. length: 565.7,                last time consumption/overall running time: 39.3493s / 9308.8911 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.3215
env0_second_0:                 episode reward: -0.6500,                 loss: 0.3299
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 5361/50000 (10.7220%),                 avg. length: 562.5,                last time consumption/overall running time: 39.6544s / 9348.5455 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.3383
env0_second_0:                 episode reward: -0.5000,                 loss: 0.3542
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 5381/50000 (10.7620%),                 avg. length: 531.15,                last time consumption/overall running time: 32.1242s / 9380.6697 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.3285
env0_second_0:                 episode reward: -0.3500,                 loss: 0.3479
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 5401/50000 (10.8020%),                 avg. length: 574.35,                last time consumption/overall running time: 34.9577s / 9415.6274 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.3274
env0_second_0:                 episode reward: -0.5000,                 loss: 0.3533
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 5421/50000 (10.8420%),                 avg. length: 547.55,                last time consumption/overall running time: 33.2528s / 9448.8801 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2997
env0_second_0:                 episode reward: -0.2000,                 loss: 0.3286
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 5441/50000 (10.8820%),                 avg. length: 559.8,                last time consumption/overall running time: 48.9324s / 9497.8126 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.3273
env0_second_0:                 episode reward: -0.4000,                 loss: 0.3611
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 5461/50000 (10.9220%),                 avg. length: 528.1,                last time consumption/overall running time: 32.0480s / 9529.8605 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.3228
env0_second_0:                 episode reward: 0.0000,                 loss: 0.3639
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 5481/50000 (10.9620%),                 avg. length: 552.05,                last time consumption/overall running time: 34.1175s / 9563.9780 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.3150
env0_second_0:                 episode reward: 0.1000,                 loss: 0.3494
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 5501/50000 (11.0020%),                 avg. length: 585.0,                last time consumption/overall running time: 41.5432s / 9605.5212 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.3070
env0_second_0:                 episode reward: 0.0500,                 loss: 0.3479
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 5521/50000 (11.0420%),                 avg. length: 522.35,                last time consumption/overall running time: 36.3407s / 9641.8619 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.3259
env0_second_0:                 episode reward: -0.2000,                 loss: 0.3522
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 5541/50000 (11.0820%),                 avg. length: 561.5,                last time consumption/overall running time: 34.4846s / 9676.3466 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.3362
env0_second_0:                 episode reward: 0.4000,                 loss: 0.3821
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 5561/50000 (11.1220%),                 avg. length: 609.75,                last time consumption/overall running time: 37.3989s / 9713.7454 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.3200
env0_second_0:                 episode reward: 0.0000,                 loss: 0.4556
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 5581/50000 (11.1620%),                 avg. length: 557.8,                last time consumption/overall running time: 35.6981s / 9749.4435 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.3372
env0_second_0:                 episode reward: 0.4500,                 loss: 0.4028
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5601/50000 (11.2020%),                 avg. length: 560.95,                last time consumption/overall running time: 37.2465s / 9786.6901 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.3235
env0_second_0:                 episode reward: -0.2500,                 loss: 0.3666
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 5621/50000 (11.2420%),                 avg. length: 563.85,                last time consumption/overall running time: 34.9908s / 9821.6808 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.3525
env0_second_0:                 episode reward: 1.1000,                 loss: 0.3871
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 5641/50000 (11.2820%),                 avg. length: 562.0,                last time consumption/overall running time: 34.8683s / 9856.5491 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.3400
env0_second_0:                 episode reward: -0.3500,                 loss: 0.3652
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 5661/50000 (11.3220%),                 avg. length: 565.25,                last time consumption/overall running time: 35.1711s / 9891.7202 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.3282
env0_second_0:                 episode reward: -0.4500,                 loss: 0.3674
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 5681/50000 (11.3620%),                 avg. length: 562.1,                last time consumption/overall running time: 37.5859s / 9929.3061 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.3461
env0_second_0:                 episode reward: -0.1000,                 loss: 0.3861
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 5701/50000 (11.4020%),                 avg. length: 615.75,                last time consumption/overall running time: 39.2945s / 9968.6005 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.3319
env0_second_0:                 episode reward: -0.7000,                 loss: 0.3951
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 5721/50000 (11.4420%),                 avg. length: 542.9,                last time consumption/overall running time: 33.2246s / 10001.8251 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2943
env0_second_0:                 episode reward: 0.3500,                 loss: 0.3419
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 5741/50000 (11.4820%),                 avg. length: 552.25,                last time consumption/overall running time: 33.8339s / 10035.6590 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.3200
env0_second_0:                 episode reward: 0.0000,                 loss: 0.3576
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 5761/50000 (11.5220%),                 avg. length: 614.1,                last time consumption/overall running time: 38.7187s / 10074.3777 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.3387
env0_second_0:                 episode reward: 0.8500,                 loss: 0.3797
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 5781/50000 (11.5620%),                 avg. length: 578.75,                last time consumption/overall running time: 35.5334s / 10109.9111 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.3383
env0_second_0:                 episode reward: 0.0500,                 loss: 0.3839
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 5801/50000 (11.6020%),                 avg. length: 594.0,                last time consumption/overall running time: 35.5871s / 10145.4982 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.3404
env0_second_0:                 episode reward: -0.4000,                 loss: 0.3701
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 5821/50000 (11.6420%),                 avg. length: 589.85,                last time consumption/overall running time: 34.9008s / 10180.3990 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.3241
env0_second_0:                 episode reward: 0.7000,                 loss: 0.3373
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 5841/50000 (11.6820%),                 avg. length: 547.0,                last time consumption/overall running time: 33.1518s / 10213.5508 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.3223
env0_second_0:                 episode reward: -0.3000,                 loss: 0.3354
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 5861/50000 (11.7220%),                 avg. length: 544.55,                last time consumption/overall running time: 34.0417s / 10247.5925 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.3148
env0_second_0:                 episode reward: -0.7500,                 loss: 0.3265
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 5881/50000 (11.7620%),                 avg. length: 590.6,                last time consumption/overall running time: 36.7951s / 10284.3876 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.3162
env0_second_0:                 episode reward: 0.2500,                 loss: 0.3268
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 5901/50000 (11.8020%),                 avg. length: 594.9,                last time consumption/overall running time: 35.4924s / 10319.8800 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.3359
env0_second_0:                 episode reward: -0.2500,                 loss: 0.3373
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 5921/50000 (11.8420%),                 avg. length: 565.3,                last time consumption/overall running time: 34.2629s / 10354.1430 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.2822
env0_second_0:                 episode reward: 0.7500,                 loss: 0.3022
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 5941/50000 (11.8820%),                 avg. length: 551.15,                last time consumption/overall running time: 37.8459s / 10391.9889 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.3398
env0_second_0:                 episode reward: 0.7000,                 loss: 0.3544
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 5961/50000 (11.9220%),                 avg. length: 596.85,                last time consumption/overall running time: 35.6605s / 10427.6494 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.3646
env0_second_0:                 episode reward: 0.5000,                 loss: 0.3803
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 5981/50000 (11.9620%),                 avg. length: 526.9,                last time consumption/overall running time: 48.2245s / 10475.8739 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.3201
env0_second_0:                 episode reward: 0.6000,                 loss: 0.3372
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 6001/50000 (12.0020%),                 avg. length: 546.9,                last time consumption/overall running time: 33.2471s / 10509.1210 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.3534
env0_second_0:                 episode reward: 0.0000,                 loss: 0.3667
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 6021/50000 (12.0420%),                 avg. length: 527.1,                last time consumption/overall running time: 32.6675s / 10541.7885 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.3276
env0_second_0:                 episode reward: -0.4000,                 loss: 0.3446
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 6041/50000 (12.0820%),                 avg. length: 595.05,                last time consumption/overall running time: 50.0976s / 10591.8861 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.3540
env0_second_0:                 episode reward: -0.0500,                 loss: 0.3725
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 6061/50000 (12.1220%),                 avg. length: 580.4,                last time consumption/overall running time: 34.5885s / 10626.4746 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.3322
env0_second_0:                 episode reward: -0.3000,                 loss: 0.3430
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 6081/50000 (12.1620%),                 avg. length: 535.15,                last time consumption/overall running time: 32.5693s / 10659.0439 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.3117
env0_second_0:                 episode reward: -0.0500,                 loss: 0.3235
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 6101/50000 (12.2020%),                 avg. length: 562.05,                last time consumption/overall running time: 39.6583s / 10698.7021 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.3312
env0_second_0:                 episode reward: -0.7000,                 loss: 0.3431
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 6121/50000 (12.2420%),                 avg. length: 563.3,                last time consumption/overall running time: 35.3624s / 10734.0645 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.3402
env0_second_0:                 episode reward: -1.2500,                 loss: 0.3473
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 6141/50000 (12.2820%),                 avg. length: 542.3,                last time consumption/overall running time: 32.8589s / 10766.9234 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.3241
env0_second_0:                 episode reward: 0.1500,                 loss: 0.3405
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 6161/50000 (12.3220%),                 avg. length: 560.15,                last time consumption/overall running time: 33.5031s / 10800.4265 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.3306
env0_second_0:                 episode reward: 0.5000,                 loss: 0.3462
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 6181/50000 (12.3620%),                 avg. length: 537.85,                last time consumption/overall running time: 32.5522s / 10832.9787 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.3357
env0_second_0:                 episode reward: 0.2000,                 loss: 0.3483
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 6201/50000 (12.4020%),                 avg. length: 545.15,                last time consumption/overall running time: 37.9064s / 10870.8852 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.3020
env0_second_0:                 episode reward: -0.4000,                 loss: 0.3274
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 6221/50000 (12.4420%),                 avg. length: 592.35,                last time consumption/overall running time: 39.9142s / 10910.7993 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2885
env0_second_0:                 episode reward: -0.2500,                 loss: 0.3094
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 6241/50000 (12.4820%),                 avg. length: 570.6,                last time consumption/overall running time: 35.0003s / 10945.7996 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.3203
env0_second_0:                 episode reward: 0.1500,                 loss: 0.3223
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 6261/50000 (12.5220%),                 avg. length: 538.45,                last time consumption/overall running time: 33.1594s / 10978.9590 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.3185
env0_second_0:                 episode reward: -0.7500,                 loss: 0.3268
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 6281/50000 (12.5620%),                 avg. length: 538.55,                last time consumption/overall running time: 37.3959s / 11016.3550 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.3043
env0_second_0:                 episode reward: 0.8500,                 loss: 0.3241
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 6301/50000 (12.6020%),                 avg. length: 552.35,                last time consumption/overall running time: 36.3195s / 11052.6745 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.3148
env0_second_0:                 episode reward: -0.8500,                 loss: 0.3303
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 6321/50000 (12.6420%),                 avg. length: 587.15,                last time consumption/overall running time: 37.7188s / 11090.3932 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.3124
env0_second_0:                 episode reward: -0.1500,                 loss: 0.3318
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 6341/50000 (12.6820%),                 avg. length: 595.0,                last time consumption/overall running time: 35.5399s / 11125.9331 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.3049
env0_second_0:                 episode reward: -0.1500,                 loss: 0.3216
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 6361/50000 (12.7220%),                 avg. length: 577.55,                last time consumption/overall running time: 38.2205s / 11164.1536 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.3204
env0_second_0:                 episode reward: 0.6500,                 loss: 0.3381
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 6381/50000 (12.7620%),                 avg. length: 600.1,                last time consumption/overall running time: 42.6547s / 11206.8083 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.3370
env0_second_0:                 episode reward: -0.7000,                 loss: 0.3516
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 6401/50000 (12.8020%),                 avg. length: 554.9,                last time consumption/overall running time: 33.4517s / 11240.2600 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.3154
env0_second_0:                 episode reward: -0.0500,                 loss: 0.3359
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 6421/50000 (12.8420%),                 avg. length: 559.85,                last time consumption/overall running time: 33.7368s / 11273.9968 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.3165
env0_second_0:                 episode reward: 0.5000,                 loss: 0.3382
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 6441/50000 (12.8820%),                 avg. length: 589.9,                last time consumption/overall running time: 35.7592s / 11309.7560 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.3227
env0_second_0:                 episode reward: -0.4000,                 loss: 0.3473
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 6461/50000 (12.9220%),                 avg. length: 580.65,                last time consumption/overall running time: 34.9840s / 11344.7400 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.3009
env0_second_0:                 episode reward: 0.2000,                 loss: 0.3224
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 6481/50000 (12.9620%),                 avg. length: 583.6,                last time consumption/overall running time: 35.8494s / 11380.5893 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.3203
env0_second_0:                 episode reward: -0.1000,                 loss: 0.3351
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 6501/50000 (13.0020%),                 avg. length: 592.55,                last time consumption/overall running time: 35.6700s / 11416.2593 s
env0_first_0:                 episode reward: -1.4500,                 loss: 0.3186
env0_second_0:                 episode reward: 1.4500,                 loss: 0.3169
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 6521/50000 (13.0420%),                 avg. length: 556.5,                last time consumption/overall running time: 34.3709s / 11450.6302 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.3307
env0_second_0:                 episode reward: 0.6500,                 loss: 0.3406
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 6541/50000 (13.0820%),                 avg. length: 582.95,                last time consumption/overall running time: 35.4297s / 11486.0599 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.3185
env0_second_0:                 episode reward: 0.1500,                 loss: 0.3331
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 6561/50000 (13.1220%),                 avg. length: 562.6,                last time consumption/overall running time: 34.9772s / 11521.0370 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.3296
env0_second_0:                 episode reward: 0.9500,                 loss: 0.3434
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 6581/50000 (13.1620%),                 avg. length: 581.3,                last time consumption/overall running time: 34.9059s / 11555.9429 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.3252
env0_second_0:                 episode reward: -0.6000,                 loss: 0.3412
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 6601/50000 (13.2020%),                 avg. length: 543.65,                last time consumption/overall running time: 33.2683s / 11589.2112 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.3113
env0_second_0:                 episode reward: -0.9500,                 loss: 0.3265
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 6621/50000 (13.2420%),                 avg. length: 579.35,                last time consumption/overall running time: 36.3467s / 11625.5579 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.3013
env0_second_0:                 episode reward: -0.7000,                 loss: 0.3138
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 6641/50000 (13.2820%),                 avg. length: 557.9,                last time consumption/overall running time: 34.9956s / 11660.5535 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.3266
env0_second_0:                 episode reward: 0.8500,                 loss: 0.3423
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 6661/50000 (13.3220%),                 avg. length: 562.5,                last time consumption/overall running time: 34.0354s / 11694.5889 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.3216
env0_second_0:                 episode reward: -0.5000,                 loss: 0.3287
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 6681/50000 (13.3620%),                 avg. length: 550.55,                last time consumption/overall running time: 33.1292s / 11727.7181 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.3363
env0_second_0:                 episode reward: 0.4500,                 loss: 0.3523
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 6701/50000 (13.4020%),                 avg. length: 564.35,                last time consumption/overall running time: 34.8523s / 11762.5703 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.3224
env0_second_0:                 episode reward: -0.7500,                 loss: 0.3423
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 6721/50000 (13.4420%),                 avg. length: 532.7,                last time consumption/overall running time: 36.7430s / 11799.3134 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.3338
env0_second_0:                 episode reward: -0.1500,                 loss: 0.3445
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 6741/50000 (13.4820%),                 avg. length: 566.05,                last time consumption/overall running time: 36.3038s / 11835.6172 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.3317
env0_second_0:                 episode reward: -0.2000,                 loss: 0.3426
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 6761/50000 (13.5220%),                 avg. length: 591.0,                last time consumption/overall running time: 35.5770s / 11871.1941 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.3332
env0_second_0:                 episode reward: 0.4500,                 loss: 0.3572
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 6781/50000 (13.5620%),                 avg. length: 561.2,                last time consumption/overall running time: 34.1765s / 11905.3707 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.3051
env0_second_0:                 episode reward: -0.1000,                 loss: 0.3157
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 6801/50000 (13.6020%),                 avg. length: 562.2,                last time consumption/overall running time: 35.3175s / 11940.6882 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2996
env0_second_0:                 episode reward: 0.3000,                 loss: 0.3174
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 6821/50000 (13.6420%),                 avg. length: 553.35,                last time consumption/overall running time: 35.0347s / 11975.7229 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.3308
env0_second_0:                 episode reward: 0.0500,                 loss: 0.3341
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 6841/50000 (13.6820%),                 avg. length: 574.0,                last time consumption/overall running time: 34.8356s / 12010.5585 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2857
env0_second_0:                 episode reward: -0.5500,                 loss: 0.3037
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 6861/50000 (13.7220%),                 avg. length: 544.2,                last time consumption/overall running time: 33.1130s / 12043.6715 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2947
env0_second_0:                 episode reward: -0.6500,                 loss: 0.3132
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 6881/50000 (13.7620%),                 avg. length: 575.35,                last time consumption/overall running time: 34.8188s / 12078.4903 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.3201
env0_second_0:                 episode reward: 0.0500,                 loss: 0.3341
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 6901/50000 (13.8020%),                 avg. length: 561.3,                last time consumption/overall running time: 35.7672s / 12114.2575 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.3096
env0_second_0:                 episode reward: 0.2500,                 loss: 0.3231
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 6921/50000 (13.8420%),                 avg. length: 563.8,                last time consumption/overall running time: 34.8028s / 12149.0603 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.3292
env0_second_0:                 episode reward: -0.2500,                 loss: 0.3318
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 6941/50000 (13.8820%),                 avg. length: 578.0,                last time consumption/overall running time: 34.5055s / 12183.5659 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.3449
env0_second_0:                 episode reward: -0.5500,                 loss: 0.3465
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 6961/50000 (13.9220%),                 avg. length: 530.3,                last time consumption/overall running time: 32.4211s / 12215.9869 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.3207
env0_second_0:                 episode reward: 1.3500,                 loss: 0.3256
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 6981/50000 (13.9620%),                 avg. length: 593.6,                last time consumption/overall running time: 36.1693s / 12252.1562 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.3328
env0_second_0:                 episode reward: -0.6500,                 loss: 0.3445
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 7001/50000 (14.0020%),                 avg. length: 529.8,                last time consumption/overall running time: 32.8285s / 12284.9847 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.3449
env0_second_0:                 episode reward: -0.3500,                 loss: 0.3588
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 7021/50000 (14.0420%),                 avg. length: 574.9,                last time consumption/overall running time: 34.8358s / 12319.8205 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.3402
env0_second_0:                 episode reward: 0.4500,                 loss: 0.3729
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 7041/50000 (14.0820%),                 avg. length: 574.7,                last time consumption/overall running time: 34.5342s / 12354.3547 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.3129
env0_second_0:                 episode reward: 1.2500,                 loss: 0.3349
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 7061/50000 (14.1220%),                 avg. length: 594.0,                last time consumption/overall running time: 39.0341s / 12393.3888 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.3267
env0_second_0:                 episode reward: -0.4000,                 loss: 0.3353
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 7081/50000 (14.1620%),                 avg. length: 567.35,                last time consumption/overall running time: 38.3065s / 12431.6953 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.3288
env0_second_0:                 episode reward: -0.3000,                 loss: 0.3569
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 7101/50000 (14.2020%),                 avg. length: 555.75,                last time consumption/overall running time: 33.4135s / 12465.1088 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.3219
env0_second_0:                 episode reward: -0.3500,                 loss: 0.3541
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 7121/50000 (14.2420%),                 avg. length: 543.05,                last time consumption/overall running time: 32.8723s / 12497.9811 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.3131
env0_second_0:                 episode reward: 0.3500,                 loss: 0.3504
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 7141/50000 (14.2820%),                 avg. length: 606.8,                last time consumption/overall running time: 38.0406s / 12536.0216 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.3079
env0_second_0:                 episode reward: -0.3500,                 loss: 0.3150
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 7161/50000 (14.3220%),                 avg. length: 557.75,                last time consumption/overall running time: 36.9992s / 12573.0208 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2994
env0_second_0:                 episode reward: 0.4000,                 loss: 0.3121
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 7181/50000 (14.3620%),                 avg. length: 580.15,                last time consumption/overall running time: 36.3105s / 12609.3313 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.3101
env0_second_0:                 episode reward: -0.8500,                 loss: 0.3268
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 7201/50000 (14.4020%),                 avg. length: 566.6,                last time consumption/overall running time: 33.9947s / 12643.3260 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.3113
env0_second_0:                 episode reward: -0.3000,                 loss: 0.3336
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 7221/50000 (14.4420%),                 avg. length: 548.35,                last time consumption/overall running time: 34.0559s / 12677.3819 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.3206
env0_second_0:                 episode reward: -0.3000,                 loss: 0.3430
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 7241/50000 (14.4820%),                 avg. length: 589.05,                last time consumption/overall running time: 40.4025s / 12717.7844 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.3184
env0_second_0:                 episode reward: 0.3000,                 loss: 0.3299
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 7261/50000 (14.5220%),                 avg. length: 540.95,                last time consumption/overall running time: 34.2394s / 12752.0238 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2831
env0_second_0:                 episode reward: -0.3500,                 loss: 0.3051
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 7281/50000 (14.5620%),                 avg. length: 572.8,                last time consumption/overall running time: 34.1412s / 12786.1651 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.3368
env0_second_0:                 episode reward: 0.5000,                 loss: 0.3484
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 7301/50000 (14.6020%),                 avg. length: 586.45,                last time consumption/overall running time: 34.9667s / 12821.1318 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.3141
env0_second_0:                 episode reward: 0.5000,                 loss: 0.3245
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 7321/50000 (14.6420%),                 avg. length: 573.9,                last time consumption/overall running time: 37.2940s / 12858.4258 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.3217
env0_second_0:                 episode reward: -0.1000,                 loss: 0.3282
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 7341/50000 (14.6820%),                 avg. length: 531.95,                last time consumption/overall running time: 35.9547s / 12894.3805 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.3357
env0_second_0:                 episode reward: -0.5000,                 loss: 0.3570
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 7361/50000 (14.7220%),                 avg. length: 549.5,                last time consumption/overall running time: 33.0551s / 12927.4355 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.3293
env0_second_0:                 episode reward: -0.1000,                 loss: 0.3406
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 7381/50000 (14.7620%),                 avg. length: 552.7,                last time consumption/overall running time: 33.1587s / 12960.5942 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.3100
env0_second_0:                 episode reward: -0.6500,                 loss: 0.3374
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 7401/50000 (14.8020%),                 avg. length: 576.0,                last time consumption/overall running time: 35.7819s / 12996.3761 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.3279
env0_second_0:                 episode reward: -0.2000,                 loss: 0.3426
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 7421/50000 (14.8420%),                 avg. length: 547.1,                last time consumption/overall running time: 36.0153s / 13032.3914 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.3068
env0_second_0:                 episode reward: 0.3000,                 loss: 0.3213
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 7441/50000 (14.8820%),                 avg. length: 558.95,                last time consumption/overall running time: 33.9035s / 13066.2950 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.3074
env0_second_0:                 episode reward: -0.8000,                 loss: 0.3150
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 7461/50000 (14.9220%),                 avg. length: 521.65,                last time consumption/overall running time: 31.6318s / 13097.9268 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.3075
env0_second_0:                 episode reward: 0.4500,                 loss: 0.3359
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 7481/50000 (14.9620%),                 avg. length: 559.2,                last time consumption/overall running time: 33.7978s / 13131.7246 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2987
env0_second_0:                 episode reward: 0.1000,                 loss: 0.3402
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 7501/50000 (15.0020%),                 avg. length: 570.15,                last time consumption/overall running time: 34.5026s / 13166.2272 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.3094
env0_second_0:                 episode reward: -0.4500,                 loss: 0.3491
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 7521/50000 (15.0420%),                 avg. length: 562.55,                last time consumption/overall running time: 33.9091s / 13200.1363 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.3249
env0_second_0:                 episode reward: -0.2500,                 loss: 0.3503
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 7541/50000 (15.0820%),                 avg. length: 556.85,                last time consumption/overall running time: 33.2310s / 13233.3674 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.3407
env0_second_0:                 episode reward: -0.5000,                 loss: 0.4616
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 7561/50000 (15.1220%),                 avg. length: 555.05,                last time consumption/overall running time: 33.1187s / 13266.4861 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.3225
env0_second_0:                 episode reward: -0.0500,                 loss: 0.4319
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 7581/50000 (15.1620%),                 avg. length: 575.3,                last time consumption/overall running time: 34.4810s / 13300.9671 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.3414
env0_second_0:                 episode reward: 0.2000,                 loss: 0.4237
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 7601/50000 (15.2020%),                 avg. length: 544.85,                last time consumption/overall running time: 33.7560s / 13334.7231 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.3254
env0_second_0:                 episode reward: -0.2500,                 loss: 0.4008
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 7621/50000 (15.2420%),                 avg. length: 531.05,                last time consumption/overall running time: 32.4260s / 13367.1490 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.3309
env0_second_0:                 episode reward: 0.2500,                 loss: 0.4335
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 7641/50000 (15.2820%),                 avg. length: 575.35,                last time consumption/overall running time: 34.6705s / 13401.8195 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.3322
env0_second_0:                 episode reward: 0.5000,                 loss: 0.4362
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 7661/50000 (15.3220%),                 avg. length: 557.45,                last time consumption/overall running time: 33.9487s / 13435.7682 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2821
env0_second_0:                 episode reward: 0.2500,                 loss: 0.3539
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 7681/50000 (15.3620%),                 avg. length: 552.65,                last time consumption/overall running time: 34.0019s / 13469.7701 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.3079
env0_second_0:                 episode reward: 0.2000,                 loss: 0.3706
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 7701/50000 (15.4020%),                 avg. length: 574.4,                last time consumption/overall running time: 34.5690s / 13504.3391 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.3278
env0_second_0:                 episode reward: 0.5500,                 loss: 0.3828
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 7721/50000 (15.4420%),                 avg. length: 559.75,                last time consumption/overall running time: 33.4154s / 13537.7545 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.3388
env0_second_0:                 episode reward: 1.1500,                 loss: 0.4090
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 7741/50000 (15.4820%),                 avg. length: 571.1,                last time consumption/overall running time: 34.2565s / 13572.0110 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.3300
env0_second_0:                 episode reward: -0.6000,                 loss: 0.3658
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 7761/50000 (15.5220%),                 avg. length: 589.85,                last time consumption/overall running time: 35.0696s / 13607.0806 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.3267
env0_second_0:                 episode reward: -0.0500,                 loss: 0.3494
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 7781/50000 (15.5620%),                 avg. length: 564.9,                last time consumption/overall running time: 34.2305s / 13641.3111 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.3449
env0_second_0:                 episode reward: 0.9000,                 loss: 0.3774
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 7801/50000 (15.6020%),                 avg. length: 536.2,                last time consumption/overall running time: 32.4955s / 13673.8066 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.3379
env0_second_0:                 episode reward: 0.1000,                 loss: 0.3692
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 7821/50000 (15.6420%),                 avg. length: 574.8,                last time consumption/overall running time: 34.3957s / 13708.2023 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.3032
env0_second_0:                 episode reward: -0.9500,                 loss: 0.3651
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 7841/50000 (15.6820%),                 avg. length: 574.25,                last time consumption/overall running time: 34.7418s / 13742.9441 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.3240
env0_second_0:                 episode reward: 0.2500,                 loss: 0.3597
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 7861/50000 (15.7220%),                 avg. length: 564.6,                last time consumption/overall running time: 34.2404s / 13777.1845 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.3251
env0_second_0:                 episode reward: -0.3000,                 loss: 0.3719
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 7881/50000 (15.7620%),                 avg. length: 566.2,                last time consumption/overall running time: 34.6424s / 13811.8269 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.3072
env0_second_0:                 episode reward: 0.3500,                 loss: 0.5646
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 7901/50000 (15.8020%),                 avg. length: 593.85,                last time consumption/overall running time: 35.4753s / 13847.3022 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.3282
env0_second_0:                 episode reward: -0.4500,                 loss: 0.4273
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 7921/50000 (15.8420%),                 avg. length: 547.45,                last time consumption/overall running time: 35.1885s / 13882.4908 s
env0_first_0:                 episode reward: 1.5500,                 loss: 0.3228
env0_second_0:                 episode reward: -1.5500,                 loss: 0.4912
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 7941/50000 (15.8820%),                 avg. length: 562.4,                last time consumption/overall running time: 34.5023s / 13916.9931 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.3407
env0_second_0:                 episode reward: -0.4000,                 loss: 0.4404
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 7961/50000 (15.9220%),                 avg. length: 577.5,                last time consumption/overall running time: 35.1903s / 13952.1833 s
env0_first_0:                 episode reward: 1.1000,                 loss: 0.3334
env0_second_0:                 episode reward: -1.1000,                 loss: 0.4468
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 7981/50000 (15.9620%),                 avg. length: 570.2,                last time consumption/overall running time: 34.5979s / 13986.7812 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.3256
env0_second_0:                 episode reward: -0.1500,                 loss: 0.4900
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 8001/50000 (16.0020%),                 avg. length: 577.5,                last time consumption/overall running time: 35.3150s / 14022.0962 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.3467
env0_second_0:                 episode reward: 0.2000,                 loss: 0.4145
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 8021/50000 (16.0420%),                 avg. length: 522.8,                last time consumption/overall running time: 31.7472s / 14053.8434 s
env0_first_0:                 episode reward: -1.7000,                 loss: 0.3383
env0_second_0:                 episode reward: 1.7000,                 loss: 0.4464
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 8041/50000 (16.0820%),                 avg. length: 587.65,                last time consumption/overall running time: 35.0512s / 14088.8946 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.3407
env0_second_0:                 episode reward: -0.7500,                 loss: 0.5023
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 8061/50000 (16.1220%),                 avg. length: 586.45,                last time consumption/overall running time: 35.0065s / 14123.9011 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.3403
env0_second_0:                 episode reward: 0.8000,                 loss: 0.4911
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 8081/50000 (16.1620%),                 avg. length: 616.25,                last time consumption/overall running time: 36.3212s / 14160.2223 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.3168
env0_second_0:                 episode reward: -0.4000,                 loss: 0.4451
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 8101/50000 (16.2020%),                 avg. length: 594.0,                last time consumption/overall running time: 35.3328s / 14195.5551 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.3150
env0_second_0:                 episode reward: 0.5500,                 loss: 0.4146
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 8121/50000 (16.2420%),                 avg. length: 566.05,                last time consumption/overall running time: 34.1135s / 14229.6686 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.3174
env0_second_0:                 episode reward: 0.4500,                 loss: 0.4391
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 8141/50000 (16.2820%),                 avg. length: 548.8,                last time consumption/overall running time: 33.5694s / 14263.2380 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.3011
env0_second_0:                 episode reward: 1.0000,                 loss: 0.3703
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 8161/50000 (16.3220%),                 avg. length: 579.05,                last time consumption/overall running time: 35.5714s / 14298.8094 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.3085
env0_second_0:                 episode reward: -0.2500,                 loss: 0.4003
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 8181/50000 (16.3620%),                 avg. length: 602.55,                last time consumption/overall running time: 36.7808s / 14335.5902 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.3173
env0_second_0:                 episode reward: -0.3500,                 loss: 0.4007
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 8201/50000 (16.4020%),                 avg. length: 586.0,                last time consumption/overall running time: 35.2113s / 14370.8015 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2878
env0_second_0:                 episode reward: 0.2000,                 loss: 0.3672
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 8221/50000 (16.4420%),                 avg. length: 549.4,                last time consumption/overall running time: 33.1552s / 14403.9566 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2963
env0_second_0:                 episode reward: 0.0500,                 loss: 0.3837
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 8241/50000 (16.4820%),                 avg. length: 589.5,                last time consumption/overall running time: 35.2554s / 14439.2121 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.3167
env0_second_0:                 episode reward: -0.7500,                 loss: 0.4450
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 8261/50000 (16.5220%),                 avg. length: 574.5,                last time consumption/overall running time: 34.1359s / 14473.3479 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.3222
env0_second_0:                 episode reward: -0.1000,                 loss: 0.4556
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 8281/50000 (16.5620%),                 avg. length: 549.65,                last time consumption/overall running time: 33.1473s / 14506.4952 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.3219
env0_second_0:                 episode reward: 0.1500,                 loss: 0.4292
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 8301/50000 (16.6020%),                 avg. length: 587.95,                last time consumption/overall running time: 35.2829s / 14541.7780 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.3232
env0_second_0:                 episode reward: -0.4500,                 loss: 0.4710
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 8321/50000 (16.6420%),                 avg. length: 601.75,                last time consumption/overall running time: 36.9889s / 14578.7670 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.3204
env0_second_0:                 episode reward: -0.1500,                 loss: 0.4231
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 8341/50000 (16.6820%),                 avg. length: 603.25,                last time consumption/overall running time: 37.4995s / 14616.2665 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.3192
env0_second_0:                 episode reward: 0.7500,                 loss: 0.4523
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 8361/50000 (16.7220%),                 avg. length: 526.0,                last time consumption/overall running time: 32.0797s / 14648.3462 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.3174
env0_second_0:                 episode reward: 0.0000,                 loss: 0.4229
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 8381/50000 (16.7620%),                 avg. length: 588.3,                last time consumption/overall running time: 35.4969s / 14683.8431 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.3241
env0_second_0:                 episode reward: 0.7000,                 loss: 0.5353
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 8401/50000 (16.8020%),                 avg. length: 567.25,                last time consumption/overall running time: 33.8645s / 14717.7076 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.3062
env0_second_0:                 episode reward: -0.3500,                 loss: 0.5223
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 8421/50000 (16.8420%),                 avg. length: 577.25,                last time consumption/overall running time: 34.5723s / 14752.2800 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.3143
env0_second_0:                 episode reward: 0.2000,                 loss: 0.4584
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 8441/50000 (16.8820%),                 avg. length: 541.55,                last time consumption/overall running time: 32.6487s / 14784.9287 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.3185
env0_second_0:                 episode reward: 0.2000,                 loss: 0.4723
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 8461/50000 (16.9220%),                 avg. length: 568.3,                last time consumption/overall running time: 33.8121s / 14818.7408 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.3211
env0_second_0:                 episode reward: 0.0000,                 loss: 0.4360
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 8481/50000 (16.9620%),                 avg. length: 530.95,                last time consumption/overall running time: 32.1083s / 14850.8491 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.3290
env0_second_0:                 episode reward: -0.7500,                 loss: 0.6314
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 8501/50000 (17.0020%),                 avg. length: 552.0,                last time consumption/overall running time: 34.2056s / 14885.0547 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.3484
env0_second_0:                 episode reward: -0.0500,                 loss: 0.4732
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 8521/50000 (17.0420%),                 avg. length: 568.7,                last time consumption/overall running time: 34.1278s / 14919.1825 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.3496
env0_second_0:                 episode reward: 0.2000,                 loss: 0.4936
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 8541/50000 (17.0820%),                 avg. length: 544.7,                last time consumption/overall running time: 32.6414s / 14951.8239 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.3285
env0_second_0:                 episode reward: -0.0500,                 loss: 0.5037
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 8561/50000 (17.1220%),                 avg. length: 544.1,                last time consumption/overall running time: 32.7324s / 14984.5562 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.3095
env0_second_0:                 episode reward: -0.3000,                 loss: 0.4701
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 8581/50000 (17.1620%),                 avg. length: 538.9,                last time consumption/overall running time: 33.0751s / 15017.6313 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.3152
env0_second_0:                 episode reward: 0.9000,                 loss: 0.4417
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 8601/50000 (17.2020%),                 avg. length: 577.95,                last time consumption/overall running time: 34.7477s / 15052.3790 s
env0_first_0:                 episode reward: -1.5500,                 loss: 0.3403
env0_second_0:                 episode reward: 1.5500,                 loss: 0.4786
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 8621/50000 (17.2420%),                 avg. length: 561.6,                last time consumption/overall running time: 33.5791s / 15085.9581 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.3212
env0_second_0:                 episode reward: -0.7000,                 loss: 0.5764
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 8641/50000 (17.2820%),                 avg. length: 554.5,                last time consumption/overall running time: 33.2026s / 15119.1607 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.3102
env0_second_0:                 episode reward: -0.2500,                 loss: 0.4545
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 8661/50000 (17.3220%),                 avg. length: 572.2,                last time consumption/overall running time: 34.6895s / 15153.8503 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.3043
env0_second_0:                 episode reward: 0.4500,                 loss: 0.5165
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 8681/50000 (17.3620%),                 avg. length: 536.0,                last time consumption/overall running time: 32.4558s / 15186.3060 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.3025
env0_second_0:                 episode reward: 0.2500,                 loss: 0.4832
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 8701/50000 (17.4020%),                 avg. length: 578.75,                last time consumption/overall running time: 34.3019s / 15220.6079 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.2973
env0_second_0:                 episode reward: 1.0000,                 loss: 0.4841
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 8721/50000 (17.4420%),                 avg. length: 558.6,                last time consumption/overall running time: 33.3075s / 15253.9154 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2978
env0_second_0:                 episode reward: 0.2500,                 loss: 0.4981
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 8741/50000 (17.4820%),                 avg. length: 559.75,                last time consumption/overall running time: 33.3374s / 15287.2529 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.3049
env0_second_0:                 episode reward: -0.8000,                 loss: 0.5035
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 8761/50000 (17.5220%),                 avg. length: 582.6,                last time consumption/overall running time: 35.2405s / 15322.4934 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2751
env0_second_0:                 episode reward: 0.1500,                 loss: 0.4097
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 8781/50000 (17.5620%),                 avg. length: 584.05,                last time consumption/overall running time: 34.8054s / 15357.2988 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.2997
env0_second_0:                 episode reward: 0.8000,                 loss: 0.7113
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 8801/50000 (17.6020%),                 avg. length: 532.45,                last time consumption/overall running time: 32.0126s / 15389.3114 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.2836
env0_second_0:                 episode reward: 1.1500,                 loss: 0.4018
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 8821/50000 (17.6420%),                 avg. length: 600.95,                last time consumption/overall running time: 35.6534s / 15424.9648 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.3141
env0_second_0:                 episode reward: 0.7500,                 loss: 0.4072
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 8841/50000 (17.6820%),                 avg. length: 588.6,                last time consumption/overall running time: 35.1719s / 15460.1367 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.3226
env0_second_0:                 episode reward: 0.1500,                 loss: 0.3930
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 8861/50000 (17.7220%),                 avg. length: 580.7,                last time consumption/overall running time: 35.4881s / 15495.6248 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.3231
env0_second_0:                 episode reward: 0.4000,                 loss: 0.4383
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 8881/50000 (17.7620%),                 avg. length: 587.85,                last time consumption/overall running time: 35.1170s / 15530.7418 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.3178
env0_second_0:                 episode reward: 0.7000,                 loss: 0.4577
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 8901/50000 (17.8020%),                 avg. length: 558.8,                last time consumption/overall running time: 33.3444s / 15564.0863 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.2983
env0_second_0:                 episode reward: -0.4500,                 loss: 0.3736
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 8921/50000 (17.8420%),                 avg. length: 568.95,                last time consumption/overall running time: 33.9903s / 15598.0765 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.2736
env0_second_0:                 episode reward: 0.8500,                 loss: 0.3784
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 8941/50000 (17.8820%),                 avg. length: 590.6,                last time consumption/overall running time: 35.5710s / 15633.6476 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.3003
env0_second_0:                 episode reward: 0.2500,                 loss: 0.4981
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 8961/50000 (17.9220%),                 avg. length: 529.9,                last time consumption/overall running time: 31.9826s / 15665.6301 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.3049
env0_second_0:                 episode reward: -0.2500,                 loss: 0.4688
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 8981/50000 (17.9620%),                 avg. length: 558.45,                last time consumption/overall running time: 33.3990s / 15699.0292 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.3323
env0_second_0:                 episode reward: -0.4500,                 loss: 0.4301
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 9001/50000 (18.0020%),                 avg. length: 545.55,                last time consumption/overall running time: 32.6781s / 15731.7073 s
env0_first_0:                 episode reward: 1.4500,                 loss: 0.3003
env0_second_0:                 episode reward: -1.4500,                 loss: 0.4736
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 9021/50000 (18.0420%),                 avg. length: 571.05,                last time consumption/overall running time: 34.4871s / 15766.1944 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.3256
env0_second_0:                 episode reward: 0.9500,                 loss: 0.5530
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 9041/50000 (18.0820%),                 avg. length: 554.6,                last time consumption/overall running time: 33.4966s / 15799.6910 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.3379
env0_second_0:                 episode reward: 0.8000,                 loss: 0.4060
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 9061/50000 (18.1220%),                 avg. length: 539.7,                last time consumption/overall running time: 32.5458s / 15832.2368 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.3054
env0_second_0:                 episode reward: 0.8000,                 loss: 0.4383
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 9081/50000 (18.1620%),                 avg. length: 578.55,                last time consumption/overall running time: 34.3486s / 15866.5854 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.3129
env0_second_0:                 episode reward: 0.1000,                 loss: 0.3974
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 9101/50000 (18.2020%),                 avg. length: 539.0,                last time consumption/overall running time: 32.5635s / 15899.1489 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.3186
env0_second_0:                 episode reward: 0.6500,                 loss: 0.3985
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 9121/50000 (18.2420%),                 avg. length: 568.9,                last time consumption/overall running time: 36.7195s / 15935.8683 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.3157
env0_second_0:                 episode reward: -0.2500,                 loss: 0.4144
env1_first_0:                 episode reward: -1.9000,                 loss: nan
env1_second_0:                 episode reward: 1.9000,                 loss: nan
Episode: 9141/50000 (18.2820%),                 avg. length: 604.4,                last time consumption/overall running time: 35.9731s / 15971.8414 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2860
env0_second_0:                 episode reward: -0.6000,                 loss: 0.4129
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 9161/50000 (18.3220%),                 avg. length: 575.1,                last time consumption/overall running time: 34.2890s / 16006.1304 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.3142
env0_second_0:                 episode reward: 0.2000,                 loss: 0.4035
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 9181/50000 (18.3620%),                 avg. length: 556.9,                last time consumption/overall running time: 33.3767s / 16039.5071 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.3000
env0_second_0:                 episode reward: -0.1000,                 loss: 0.4057
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 9201/50000 (18.4020%),                 avg. length: 558.95,                last time consumption/overall running time: 33.8709s / 16073.3780 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.3084
env0_second_0:                 episode reward: -0.0500,                 loss: 0.5325
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 9221/50000 (18.4420%),                 avg. length: 556.9,                last time consumption/overall running time: 34.4626s / 16107.8406 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.3387
env0_second_0:                 episode reward: 0.5000,                 loss: 0.4679
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 9241/50000 (18.4820%),                 avg. length: 532.4,                last time consumption/overall running time: 32.6418s / 16140.4824 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.2853
env0_second_0:                 episode reward: 1.1500,                 loss: 0.3598
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 9261/50000 (18.5220%),                 avg. length: 567.15,                last time consumption/overall running time: 33.9101s / 16174.3925 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.3102
env0_second_0:                 episode reward: 0.8500,                 loss: 0.4879
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 9281/50000 (18.5620%),                 avg. length: 537.45,                last time consumption/overall running time: 32.4853s / 16206.8778 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2984
env0_second_0:                 episode reward: 0.1500,                 loss: 0.4492
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 9301/50000 (18.6020%),                 avg. length: 582.55,                last time consumption/overall running time: 35.9626s / 16242.8404 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.3446
env0_second_0:                 episode reward: -0.2500,                 loss: 0.5335
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 9321/50000 (18.6420%),                 avg. length: 553.2,                last time consumption/overall running time: 34.2246s / 16277.0650 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.3254
env0_second_0:                 episode reward: -1.2500,                 loss: 0.4014
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 9341/50000 (18.6820%),                 avg. length: 588.2,                last time consumption/overall running time: 35.0015s / 16312.0665 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.3186
env0_second_0:                 episode reward: -0.3000,                 loss: 0.5635
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 9361/50000 (18.7220%),                 avg. length: 559.3,                last time consumption/overall running time: 33.8678s / 16345.9343 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.3221
env0_second_0:                 episode reward: 0.4000,                 loss: 0.4519
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 9381/50000 (18.7620%),                 avg. length: 538.75,                last time consumption/overall running time: 32.5173s / 16378.4516 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.3042
env0_second_0:                 episode reward: 1.0000,                 loss: 0.4816
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 9401/50000 (18.8020%),                 avg. length: 537.0,                last time consumption/overall running time: 32.6214s / 16411.0730 s
env0_first_0:                 episode reward: 1.3000,                 loss: 0.3064
env0_second_0:                 episode reward: -1.3000,                 loss: 0.4840
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 9421/50000 (18.8420%),                 avg. length: 562.55,                last time consumption/overall running time: 33.8858s / 16444.9589 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.2993
env0_second_0:                 episode reward: 0.7000,                 loss: 0.5459
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 9441/50000 (18.8820%),                 avg. length: 555.75,                last time consumption/overall running time: 33.2173s / 16478.1762 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.3373
env0_second_0:                 episode reward: 1.0000,                 loss: 0.5080
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 9461/50000 (18.9220%),                 avg. length: 571.65,                last time consumption/overall running time: 34.0873s / 16512.2635 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.3097
env0_second_0:                 episode reward: -0.2500,                 loss: 0.4641
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 9481/50000 (18.9620%),                 avg. length: 558.45,                last time consumption/overall running time: 33.4719s / 16545.7354 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.3076
env0_second_0:                 episode reward: -1.0000,                 loss: 0.4613
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 9501/50000 (19.0020%),                 avg. length: 559.65,                last time consumption/overall running time: 33.5846s / 16579.3200 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.3144
env0_second_0:                 episode reward: 0.7500,                 loss: 0.4438
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 9521/50000 (19.0420%),                 avg. length: 573.05,                last time consumption/overall running time: 34.2883s / 16613.6083 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.3214
env0_second_0:                 episode reward: -0.9000,                 loss: 0.4165
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 9541/50000 (19.0820%),                 avg. length: 570.05,                last time consumption/overall running time: 33.9602s / 16647.5685 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.3137
env0_second_0:                 episode reward: -0.2500,                 loss: 1.9574
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 9561/50000 (19.1220%),                 avg. length: 562.7,                last time consumption/overall running time: 33.6770s / 16681.2455 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.3304
env0_second_0:                 episode reward: -0.2000,                 loss: 0.6157
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 9581/50000 (19.1620%),                 avg. length: 578.75,                last time consumption/overall running time: 35.3008s / 16716.5462 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.3099
env0_second_0:                 episode reward: 0.0000,                 loss: 0.5845
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 9601/50000 (19.2020%),                 avg. length: 581.35,                last time consumption/overall running time: 35.0870s / 16751.6333 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.3228
env0_second_0:                 episode reward: -0.1500,                 loss: 0.6368
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 9621/50000 (19.2420%),                 avg. length: 599.55,                last time consumption/overall running time: 36.1336s / 16787.7669 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.3152
env0_second_0:                 episode reward: 0.1000,                 loss: 0.5181
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 9641/50000 (19.2820%),                 avg. length: 550.95,                last time consumption/overall running time: 33.8985s / 16821.6654 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.3038
env0_second_0:                 episode reward: 0.2500,                 loss: 0.4917
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 9661/50000 (19.3220%),                 avg. length: 503.55,                last time consumption/overall running time: 30.8544s / 16852.5198 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2822
env0_second_0:                 episode reward: 0.1000,                 loss: 0.4201
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 9681/50000 (19.3620%),                 avg. length: 581.05,                last time consumption/overall running time: 36.1943s / 16888.7141 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.3385
env0_second_0:                 episode reward: 0.1000,                 loss: 0.4605
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 9701/50000 (19.4020%),                 avg. length: 585.7,                last time consumption/overall running time: 34.7893s / 16923.5034 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2970
env0_second_0:                 episode reward: -0.1500,                 loss: 0.4406
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 9721/50000 (19.4420%),                 avg. length: 578.9,                last time consumption/overall running time: 34.4495s / 16957.9529 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.3023
env0_second_0:                 episode reward: 0.6000,                 loss: 0.4742
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 9741/50000 (19.4820%),                 avg. length: 566.0,                last time consumption/overall running time: 33.8155s / 16991.7684 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.2807
env0_second_0:                 episode reward: -0.9500,                 loss: 0.4200
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 9761/50000 (19.5220%),                 avg. length: 571.7,                last time consumption/overall running time: 34.5937s / 17026.3621 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.3079
env0_second_0:                 episode reward: 0.6500,                 loss: 0.4521
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 9781/50000 (19.5620%),                 avg. length: 557.35,                last time consumption/overall running time: 33.7566s / 17060.1188 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.3019
env0_second_0:                 episode reward: -0.1500,                 loss: 0.5838
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 9801/50000 (19.6020%),                 avg. length: 557.85,                last time consumption/overall running time: 34.2852s / 17094.4040 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.2906
env0_second_0:                 episode reward: -0.9000,                 loss: 0.4205
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 9821/50000 (19.6420%),                 avg. length: 552.6,                last time consumption/overall running time: 34.0330s / 17128.4370 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.3190
env0_second_0:                 episode reward: 0.7500,                 loss: 0.4656
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 9841/50000 (19.6820%),                 avg. length: 580.2,                last time consumption/overall running time: 34.7549s / 17163.1919 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.3136
env0_second_0:                 episode reward: 0.3500,                 loss: 0.4249
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 9861/50000 (19.7220%),                 avg. length: 608.75,                last time consumption/overall running time: 36.3279s / 17199.5198 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.3198
env0_second_0:                 episode reward: -0.5000,                 loss: 0.4757
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 9881/50000 (19.7620%),                 avg. length: 582.4,                last time consumption/overall running time: 34.7123s / 17234.2322 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.3009
env0_second_0:                 episode reward: -0.5500,                 loss: 0.4681
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 9901/50000 (19.8020%),                 avg. length: 536.4,                last time consumption/overall running time: 32.8675s / 17267.0997 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2918
env0_second_0:                 episode reward: 0.2000,                 loss: 0.5084
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 9921/50000 (19.8420%),                 avg. length: 575.2,                last time consumption/overall running time: 35.0430s / 17302.1426 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.3127
env0_second_0:                 episode reward: -0.3000,                 loss: 0.4454
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 9941/50000 (19.8820%),                 avg. length: 563.55,                last time consumption/overall running time: 35.3546s / 17337.4972 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.3042
env0_second_0:                 episode reward: 0.2000,                 loss: 0.4190
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 9961/50000 (19.9220%),                 avg. length: 575.8,                last time consumption/overall running time: 36.0688s / 17373.5660 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.3096
env0_second_0:                 episode reward: -1.0500,                 loss: 0.4444
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 9981/50000 (19.9620%),                 avg. length: 580.95,                last time consumption/overall running time: 35.5366s / 17409.1026 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.3263
env0_second_0:                 episode reward: 0.3500,                 loss: 0.4067
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 10001/50000 (20.0020%),                 avg. length: 587.45,                last time consumption/overall running time: 36.1042s / 17445.2068 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.3166
env0_second_0:                 episode reward: 0.4500,                 loss: 0.4371
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 10021/50000 (20.0420%),                 avg. length: 594.15,                last time consumption/overall running time: 36.6204s / 17481.8272 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.3176
env0_second_0:                 episode reward: -0.7000,                 loss: 0.4572
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 10041/50000 (20.0820%),                 avg. length: 581.8,                last time consumption/overall running time: 35.0126s / 17516.8398 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.3288
env0_second_0:                 episode reward: -1.0000,                 loss: 0.4434
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 10061/50000 (20.1220%),                 avg. length: 576.9,                last time consumption/overall running time: 34.7571s / 17551.5969 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.3454
env0_second_0:                 episode reward: 0.3000,                 loss: 0.4841
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 10081/50000 (20.1620%),                 avg. length: 555.55,                last time consumption/overall running time: 33.9058s / 17585.5027 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.3582
env0_second_0:                 episode reward: -0.3000,                 loss: 0.4878
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 10101/50000 (20.2020%),                 avg. length: 556.0,                last time consumption/overall running time: 33.7493s / 17619.2520 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.3504
env0_second_0:                 episode reward: -0.2000,                 loss: 0.4524
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 10121/50000 (20.2420%),                 avg. length: 573.6,                last time consumption/overall running time: 34.4923s / 17653.7444 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.3223
env0_second_0:                 episode reward: 0.1500,                 loss: 0.4252
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 10141/50000 (20.2820%),                 avg. length: 581.8,                last time consumption/overall running time: 35.2047s / 17688.9490 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.3243
env0_second_0:                 episode reward: -0.2000,                 loss: 0.4292
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 10161/50000 (20.3220%),                 avg. length: 545.75,                last time consumption/overall running time: 33.1484s / 17722.0974 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.3177
env0_second_0:                 episode reward: -0.4000,                 loss: 0.4563
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 10181/50000 (20.3620%),                 avg. length: 592.5,                last time consumption/overall running time: 35.8735s / 17757.9709 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.3310
env0_second_0:                 episode reward: -0.5000,                 loss: 0.4111
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 10201/50000 (20.4020%),                 avg. length: 582.35,                last time consumption/overall running time: 34.9479s / 17792.9188 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.3003
env0_second_0:                 episode reward: -0.7500,                 loss: 0.4123
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 10221/50000 (20.4420%),                 avg. length: 577.6,                last time consumption/overall running time: 35.0706s / 17827.9894 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.3218
env0_second_0:                 episode reward: -0.0500,                 loss: 0.6520
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 10241/50000 (20.4820%),                 avg. length: 520.7,                last time consumption/overall running time: 32.3836s / 17860.3729 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.3043
env0_second_0:                 episode reward: 1.3000,                 loss: 0.6099
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 10261/50000 (20.5220%),                 avg. length: 543.95,                last time consumption/overall running time: 33.1284s / 17893.5014 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.3449
env0_second_0:                 episode reward: 0.0000,                 loss: 0.5499
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 10281/50000 (20.5620%),                 avg. length: 587.35,                last time consumption/overall running time: 35.1836s / 17928.6850 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.3084
env0_second_0:                 episode reward: -0.2500,                 loss: 0.5430
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 10301/50000 (20.6020%),                 avg. length: 578.7,                last time consumption/overall running time: 37.5417s / 17966.2267 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.3081
env0_second_0:                 episode reward: 0.3000,                 loss: 0.4853
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 10321/50000 (20.6420%),                 avg. length: 564.75,                last time consumption/overall running time: 35.9951s / 18002.2217 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.3045
env0_second_0:                 episode reward: -0.3500,                 loss: 0.4606
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 10341/50000 (20.6820%),                 avg. length: 557.2,                last time consumption/overall running time: 33.9349s / 18036.1567 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.3231
env0_second_0:                 episode reward: -0.4500,                 loss: 0.4997
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 10361/50000 (20.7220%),                 avg. length: 591.85,                last time consumption/overall running time: 36.2781s / 18072.4348 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.3285
env0_second_0:                 episode reward: -0.3000,                 loss: 0.4586
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 10381/50000 (20.7620%),                 avg. length: 553.15,                last time consumption/overall running time: 34.5251s / 18106.9599 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2930
env0_second_0:                 episode reward: 0.1500,                 loss: 0.4614
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 10401/50000 (20.8020%),                 avg. length: 574.7,                last time consumption/overall running time: 35.8831s / 18142.8430 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.3250
env0_second_0:                 episode reward: -0.0500,                 loss: 0.5581
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 10421/50000 (20.8420%),                 avg. length: 597.75,                last time consumption/overall running time: 35.5298s / 18178.3729 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.3339
env0_second_0:                 episode reward: -0.9500,                 loss: 0.5490
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 10441/50000 (20.8820%),                 avg. length: 555.15,                last time consumption/overall running time: 33.8385s / 18212.2113 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.3478
env0_second_0:                 episode reward: -0.3000,                 loss: 0.5752
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 10461/50000 (20.9220%),                 avg. length: 524.2,                last time consumption/overall running time: 34.6538s / 18246.8651 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.3332
env0_second_0:                 episode reward: 1.4000,                 loss: 0.5321
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 10481/50000 (20.9620%),                 avg. length: 535.25,                last time consumption/overall running time: 35.8025s / 18282.6676 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.3695
env0_second_0:                 episode reward: 0.2500,                 loss: 0.5505
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 10501/50000 (21.0020%),                 avg. length: 554.85,                last time consumption/overall running time: 33.4100s / 18316.0776 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.3399
env0_second_0:                 episode reward: -0.8000,                 loss: 0.5386
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 10521/50000 (21.0420%),                 avg. length: 568.75,                last time consumption/overall running time: 34.5442s / 18350.6218 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.3203
env0_second_0:                 episode reward: 0.9000,                 loss: 0.4612
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 10541/50000 (21.0820%),                 avg. length: 543.1,                last time consumption/overall running time: 34.7962s / 18385.4180 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.3256
env0_second_0:                 episode reward: 1.3500,                 loss: 0.5227
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 10561/50000 (21.1220%),                 avg. length: 566.15,                last time consumption/overall running time: 38.8786s / 18424.2967 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.3443
env0_second_0:                 episode reward: 0.2500,                 loss: 9.2197
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 10581/50000 (21.1620%),                 avg. length: 566.8,                last time consumption/overall running time: 34.4903s / 18458.7869 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.3399
env0_second_0:                 episode reward: -0.4000,                 loss: 0.9642
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 10601/50000 (21.2020%),                 avg. length: 572.1,                last time consumption/overall running time: 34.3065s / 18493.0934 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.3408
env0_second_0:                 episode reward: 0.5500,                 loss: 0.9425
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 10621/50000 (21.2420%),                 avg. length: 608.25,                last time consumption/overall running time: 37.0502s / 18530.1436 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.3315
env0_second_0:                 episode reward: -0.3500,                 loss: 1.1813
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 10641/50000 (21.2820%),                 avg. length: 553.1,                last time consumption/overall running time: 33.4068s / 18563.5504 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.3177
env0_second_0:                 episode reward: 0.1500,                 loss: 0.8872
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 10661/50000 (21.3220%),                 avg. length: 534.8,                last time consumption/overall running time: 32.5818s / 18596.1322 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.3270
env0_second_0:                 episode reward: 0.9000,                 loss: 0.7682
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 10681/50000 (21.3620%),                 avg. length: 563.8,                last time consumption/overall running time: 33.8073s / 18629.9394 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.3392
env0_second_0:                 episode reward: -0.2000,                 loss: 0.7848
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 10701/50000 (21.4020%),                 avg. length: 602.95,                last time consumption/overall running time: 36.0291s / 18665.9685 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.3420
env0_second_0:                 episode reward: -0.2000,                 loss: 0.7334
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 10721/50000 (21.4420%),                 avg. length: 564.85,                last time consumption/overall running time: 34.2509s / 18700.2194 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.3155
env0_second_0:                 episode reward: -0.2500,                 loss: 0.6049
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 10741/50000 (21.4820%),                 avg. length: 537.35,                last time consumption/overall running time: 33.7877s / 18734.0071 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.3354
env0_second_0:                 episode reward: 0.2000,                 loss: 0.6587
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 10761/50000 (21.5220%),                 avg. length: 568.7,                last time consumption/overall running time: 35.4616s / 18769.4687 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.3358
env0_second_0:                 episode reward: -0.2500,                 loss: 0.6149
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 10781/50000 (21.5620%),                 avg. length: 595.95,                last time consumption/overall running time: 35.4872s / 18804.9559 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.3315
env0_second_0:                 episode reward: 0.4500,                 loss: 0.7107
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 10801/50000 (21.6020%),                 avg. length: 574.55,                last time consumption/overall running time: 39.9221s / 18844.8780 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.3171
env0_second_0:                 episode reward: -0.4000,                 loss: 1.1718
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 10821/50000 (21.6420%),                 avg. length: 549.25,                last time consumption/overall running time: 33.6258s / 18878.5038 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.3119
env0_second_0:                 episode reward: -0.5000,                 loss: 0.5288
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 10841/50000 (21.6820%),                 avg. length: 570.1,                last time consumption/overall running time: 34.4525s / 18912.9563 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2917
env0_second_0:                 episode reward: -0.2500,                 loss: 0.5451
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 10861/50000 (21.7220%),                 avg. length: 521.5,                last time consumption/overall running time: 32.2100s / 18945.1663 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.3184
env0_second_0:                 episode reward: -0.6000,                 loss: 0.4844
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 10881/50000 (21.7620%),                 avg. length: 586.5,                last time consumption/overall running time: 36.3430s / 18981.5093 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.3301
env0_second_0:                 episode reward: 0.5500,                 loss: 0.5251
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 10901/50000 (21.8020%),                 avg. length: 537.35,                last time consumption/overall running time: 35.7952s / 19017.3045 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.3046
env0_second_0:                 episode reward: -0.2000,                 loss: 0.5982
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 10921/50000 (21.8420%),                 avg. length: 538.5,                last time consumption/overall running time: 33.8086s / 19051.1131 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.3340
env0_second_0:                 episode reward: 0.0500,                 loss: 0.5506
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 10941/50000 (21.8820%),                 avg. length: 586.05,                last time consumption/overall running time: 34.7324s / 19085.8455 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.3359
env0_second_0:                 episode reward: -1.0000,                 loss: 0.4803
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 10961/50000 (21.9220%),                 avg. length: 551.95,                last time consumption/overall running time: 33.0960s / 19118.9414 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.3398
env0_second_0:                 episode reward: 0.0000,                 loss: 0.4208
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 10981/50000 (21.9620%),                 avg. length: 578.35,                last time consumption/overall running time: 34.2446s / 19153.1861 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.3592
env0_second_0:                 episode reward: 0.1500,                 loss: 0.4895
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 11001/50000 (22.0020%),                 avg. length: 563.75,                last time consumption/overall running time: 33.8936s / 19187.0796 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.3345
env0_second_0:                 episode reward: 0.7500,                 loss: 0.4042
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 11021/50000 (22.0420%),                 avg. length: 594.4,                last time consumption/overall running time: 35.1931s / 19222.2728 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.3596
env0_second_0:                 episode reward: 0.0500,                 loss: 0.4439
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 11041/50000 (22.0820%),                 avg. length: 596.8,                last time consumption/overall running time: 36.8959s / 19259.1686 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.3352
env0_second_0:                 episode reward: 0.3000,                 loss: 0.3916
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 11061/50000 (22.1220%),                 avg. length: 554.4,                last time consumption/overall running time: 34.7180s / 19293.8866 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.3279
env0_second_0:                 episode reward: -0.5000,                 loss: 0.4600
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 11081/50000 (22.1620%),                 avg. length: 573.45,                last time consumption/overall running time: 39.6453s / 19333.5320 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.3301
env0_second_0:                 episode reward: 0.7500,                 loss: 0.4406
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 11101/50000 (22.2020%),                 avg. length: 561.25,                last time consumption/overall running time: 36.4680s / 19370.0000 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.3216
env0_second_0:                 episode reward: -0.6000,                 loss: 1.1243
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 11121/50000 (22.2420%),                 avg. length: 604.85,                last time consumption/overall running time: 36.1248s / 19406.1248 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.3279
env0_second_0:                 episode reward: 1.1500,                 loss: 0.4351
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 11141/50000 (22.2820%),                 avg. length: 588.5,                last time consumption/overall running time: 36.9107s / 19443.0355 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2923
env0_second_0:                 episode reward: 0.0000,                 loss: 0.3818
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 11161/50000 (22.3220%),                 avg. length: 541.8,                last time consumption/overall running time: 32.7908s / 19475.8263 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.3084
env0_second_0:                 episode reward: -0.1500,                 loss: 0.4206
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 11181/50000 (22.3620%),                 avg. length: 532.1,                last time consumption/overall running time: 36.3949s / 19512.2211 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.3536
env0_second_0:                 episode reward: 0.2500,                 loss: 0.4444
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 11201/50000 (22.4020%),                 avg. length: 573.2,                last time consumption/overall running time: 34.1238s / 19546.3450 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.3278
env0_second_0:                 episode reward: -0.4500,                 loss: 0.4382
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 11221/50000 (22.4420%),                 avg. length: 533.15,                last time consumption/overall running time: 32.2424s / 19578.5874 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.3582
env0_second_0:                 episode reward: -0.2000,                 loss: 1.4617
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 11241/50000 (22.4820%),                 avg. length: 557.5,                last time consumption/overall running time: 33.3194s / 19611.9068 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.3066
env0_second_0:                 episode reward: 0.5500,                 loss: 0.5386
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 11261/50000 (22.5220%),                 avg. length: 578.65,                last time consumption/overall running time: 35.1326s / 19647.0394 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.3211
env0_second_0:                 episode reward: -0.0500,                 loss: 0.6495
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 11281/50000 (22.5620%),                 avg. length: 574.85,                last time consumption/overall running time: 34.6714s / 19681.7109 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.3111
env0_second_0:                 episode reward: -0.9500,                 loss: 0.5283
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 11301/50000 (22.6020%),                 avg. length: 551.85,                last time consumption/overall running time: 33.0795s / 19714.7904 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.3133
env0_second_0:                 episode reward: -0.7000,                 loss: 0.5878
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 11321/50000 (22.6420%),                 avg. length: 540.95,                last time consumption/overall running time: 32.5115s / 19747.3019 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.3150
env0_second_0:                 episode reward: -1.0000,                 loss: 0.5506
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 11341/50000 (22.6820%),                 avg. length: 567.1,                last time consumption/overall running time: 34.0233s / 19781.3252 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.3018
env0_second_0:                 episode reward: -0.2500,                 loss: 0.8284
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 11361/50000 (22.7220%),                 avg. length: 537.8,                last time consumption/overall running time: 33.5978s / 19814.9230 s
env0_first_0:                 episode reward: 1.4500,                 loss: 0.2967
env0_second_0:                 episode reward: -1.4500,                 loss: 0.4922
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 11381/50000 (22.7620%),                 avg. length: 562.4,                last time consumption/overall running time: 34.6028s / 19849.5258 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.3063
env0_second_0:                 episode reward: 0.3500,                 loss: 0.4455
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 11401/50000 (22.8020%),                 avg. length: 578.35,                last time consumption/overall running time: 34.5978s / 19884.1236 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.3361
env0_second_0:                 episode reward: 1.1000,                 loss: 0.4932
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 11421/50000 (22.8420%),                 avg. length: 600.5,                last time consumption/overall running time: 36.0290s / 19920.1526 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.3245
env0_second_0:                 episode reward: 0.1000,                 loss: 0.5220
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 11441/50000 (22.8820%),                 avg. length: 600.65,                last time consumption/overall running time: 35.6440s / 19955.7965 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.3245
env0_second_0:                 episode reward: -0.3500,                 loss: 0.4761
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 11461/50000 (22.9220%),                 avg. length: 557.1,                last time consumption/overall running time: 33.4465s / 19989.2431 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2918
env0_second_0:                 episode reward: -0.0500,                 loss: 0.5764
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 11481/50000 (22.9620%),                 avg. length: 555.85,                last time consumption/overall running time: 33.6706s / 20022.9137 s
env0_first_0:                 episode reward: 1.4000,                 loss: 0.3041
env0_second_0:                 episode reward: -1.4000,                 loss: 0.4070
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 11501/50000 (23.0020%),                 avg. length: 563.5,                last time consumption/overall running time: 34.1256s / 20057.0393 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.3024
env0_second_0:                 episode reward: 0.1500,                 loss: 0.4190
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 11521/50000 (23.0420%),                 avg. length: 533.95,                last time consumption/overall running time: 33.2386s / 20090.2778 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.3259
env0_second_0:                 episode reward: 0.3000,                 loss: 0.5080
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 11541/50000 (23.0820%),                 avg. length: 550.2,                last time consumption/overall running time: 34.1498s / 20124.4277 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.3564
env0_second_0:                 episode reward: 0.0500,                 loss: 0.4677
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 11561/50000 (23.1220%),                 avg. length: 544.1,                last time consumption/overall running time: 33.0147s / 20157.4423 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.3218
env0_second_0:                 episode reward: 0.0500,                 loss: 0.5872
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 11581/50000 (23.1620%),                 avg. length: 566.3,                last time consumption/overall running time: 33.9227s / 20191.3651 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.3138
env0_second_0:                 episode reward: -0.1500,                 loss: 0.7824
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 11601/50000 (23.2020%),                 avg. length: 558.95,                last time consumption/overall running time: 33.7652s / 20225.1303 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.3255
env0_second_0:                 episode reward: 0.0500,                 loss: 0.5005
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 11621/50000 (23.2420%),                 avg. length: 548.45,                last time consumption/overall running time: 33.0357s / 20258.1660 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.3286
env0_second_0:                 episode reward: 0.5000,                 loss: 0.4872
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 11641/50000 (23.2820%),                 avg. length: 559.15,                last time consumption/overall running time: 41.9298s / 20300.0958 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2940
env0_second_0:                 episode reward: 0.4500,                 loss: 0.4952
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 11661/50000 (23.3220%),                 avg. length: 584.85,                last time consumption/overall running time: 35.1066s / 20335.2024 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.3096
env0_second_0:                 episode reward: 0.1000,                 loss: 0.4796
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 11681/50000 (23.3620%),                 avg. length: 582.45,                last time consumption/overall running time: 34.8485s / 20370.0509 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.2979
env0_second_0:                 episode reward: 0.9500,                 loss: 0.4121
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 11701/50000 (23.4020%),                 avg. length: 578.95,                last time consumption/overall running time: 38.3120s / 20408.3629 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.3221
env0_second_0:                 episode reward: 0.7000,                 loss: 0.4377
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 11721/50000 (23.4420%),                 avg. length: 551.3,                last time consumption/overall running time: 34.4595s / 20442.8224 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.2961
env0_second_0:                 episode reward: -0.7500,                 loss: 0.4447
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 11741/50000 (23.4820%),                 avg. length: 544.55,                last time consumption/overall running time: 33.0281s / 20475.8505 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2936
env0_second_0:                 episode reward: -0.3000,                 loss: 0.4598
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 11761/50000 (23.5220%),                 avg. length: 570.85,                last time consumption/overall running time: 34.3846s / 20510.2352 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.3078
env0_second_0:                 episode reward: -0.3000,                 loss: 0.5592
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 11781/50000 (23.5620%),                 avg. length: 609.95,                last time consumption/overall running time: 36.4358s / 20546.6710 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.3009
env0_second_0:                 episode reward: 0.0000,                 loss: 1.3062
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 11801/50000 (23.6020%),                 avg. length: 596.55,                last time consumption/overall running time: 35.7653s / 20582.4362 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.3058
env0_second_0:                 episode reward: -0.3000,                 loss: 0.6440
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 11821/50000 (23.6420%),                 avg. length: 505.35,                last time consumption/overall running time: 30.9619s / 20613.3982 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.2815
env0_second_0:                 episode reward: -0.7000,                 loss: 0.6783
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 11841/50000 (23.6820%),                 avg. length: 583.7,                last time consumption/overall running time: 35.0416s / 20648.4397 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2860
env0_second_0:                 episode reward: -0.1500,                 loss: 0.4940
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 11861/50000 (23.7220%),                 avg. length: 552.75,                last time consumption/overall running time: 33.5602s / 20681.9999 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.3125
env0_second_0:                 episode reward: -0.2500,                 loss: 0.4889
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 11881/50000 (23.7620%),                 avg. length: 560.95,                last time consumption/overall running time: 34.3819s / 20716.3818 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2878
env0_second_0:                 episode reward: 0.6500,                 loss: 0.4895
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 11901/50000 (23.8020%),                 avg. length: 541.9,                last time consumption/overall running time: 33.0020s / 20749.3838 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.3259
env0_second_0:                 episode reward: 0.7500,                 loss: 0.5615
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 11921/50000 (23.8420%),                 avg. length: 563.35,                last time consumption/overall running time: 33.6948s / 20783.0786 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.3483
env0_second_0:                 episode reward: 0.8000,                 loss: 0.4769
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 11941/50000 (23.8820%),                 avg. length: 555.25,                last time consumption/overall running time: 33.4929s / 20816.5715 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.3368
env0_second_0:                 episode reward: -0.0500,                 loss: 0.4632
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 11961/50000 (23.9220%),                 avg. length: 575.95,                last time consumption/overall running time: 36.0578s / 20852.6293 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.3212
env0_second_0:                 episode reward: -0.5500,                 loss: 0.4496
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 11981/50000 (23.9620%),                 avg. length: 558.5,                last time consumption/overall running time: 36.6319s / 20889.2613 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.2999
env0_second_0:                 episode reward: -0.9000,                 loss: 0.4453
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 12001/50000 (24.0020%),                 avg. length: 585.15,                last time consumption/overall running time: 37.8148s / 20927.0761 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.3115
env0_second_0:                 episode reward: -0.0500,                 loss: 0.4322
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 12021/50000 (24.0420%),                 avg. length: 552.25,                last time consumption/overall running time: 33.2412s / 20960.3173 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2778
env0_second_0:                 episode reward: 0.1500,                 loss: 0.4786
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 12041/50000 (24.0820%),                 avg. length: 583.0,                last time consumption/overall running time: 36.1284s / 20996.4457 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.3182
env0_second_0:                 episode reward: 0.5000,                 loss: 0.4411
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 12061/50000 (24.1220%),                 avg. length: 556.9,                last time consumption/overall running time: 34.2201s / 21030.6658 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.2953
env0_second_0:                 episode reward: 1.0000,                 loss: 0.4006
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 12081/50000 (24.1620%),                 avg. length: 531.3,                last time consumption/overall running time: 33.6802s / 21064.3460 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.3092
env0_second_0:                 episode reward: -0.5500,                 loss: 0.4477
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 12101/50000 (24.2020%),                 avg. length: 556.2,                last time consumption/overall running time: 33.7076s / 21098.0536 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.3182
env0_second_0:                 episode reward: 0.4000,                 loss: 0.4415
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 12121/50000 (24.2420%),                 avg. length: 562.25,                last time consumption/overall running time: 34.0621s / 21132.1157 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.3220
env0_second_0:                 episode reward: 0.3000,                 loss: 0.5118
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 12141/50000 (24.2820%),                 avg. length: 587.5,                last time consumption/overall running time: 40.9485s / 21173.0642 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.3200
env0_second_0:                 episode reward: 0.3000,                 loss: 0.4656
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 12161/50000 (24.3220%),                 avg. length: 588.25,                last time consumption/overall running time: 37.0955s / 21210.1596 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.3010
env0_second_0:                 episode reward: 0.3000,                 loss: 0.4175
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 12181/50000 (24.3620%),                 avg. length: 578.75,                last time consumption/overall running time: 34.6892s / 21244.8488 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.3152
env0_second_0:                 episode reward: -0.1000,                 loss: 0.4473
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 12201/50000 (24.4020%),                 avg. length: 579.55,                last time consumption/overall running time: 36.3859s / 21281.2347 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2575
env0_second_0:                 episode reward: -0.3000,                 loss: 0.5032
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 12221/50000 (24.4420%),                 avg. length: 590.25,                last time consumption/overall running time: 35.6382s / 21316.8729 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2783
env0_second_0:                 episode reward: 0.2500,                 loss: 0.4681
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 12241/50000 (24.4820%),                 avg. length: 576.65,                last time consumption/overall running time: 34.5839s / 21351.4568 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.2816
env0_second_0:                 episode reward: 0.8000,                 loss: 1.1399
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 12261/50000 (24.5220%),                 avg. length: 546.15,                last time consumption/overall running time: 35.7308s / 21387.1876 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.3047
env0_second_0:                 episode reward: 0.2500,                 loss: 0.5961
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 12281/50000 (24.5620%),                 avg. length: 560.15,                last time consumption/overall running time: 33.5329s / 21420.7206 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.3126
env0_second_0:                 episode reward: -0.9000,                 loss: 0.5171
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 12301/50000 (24.6020%),                 avg. length: 533.5,                last time consumption/overall running time: 32.7056s / 21453.4262 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.3142
env0_second_0:                 episode reward: -0.8000,                 loss: 0.5629
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 12321/50000 (24.6420%),                 avg. length: 586.8,                last time consumption/overall running time: 37.0853s / 21490.5115 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.3404
env0_second_0:                 episode reward: 0.1500,                 loss: 0.5219
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 12341/50000 (24.6820%),                 avg. length: 598.4,                last time consumption/overall running time: 36.3338s / 21526.8453 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.3197
env0_second_0:                 episode reward: 1.1000,                 loss: 0.4911
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 12361/50000 (24.7220%),                 avg. length: 579.05,                last time consumption/overall running time: 34.7681s / 21561.6133 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.3199
env0_second_0:                 episode reward: -0.8000,                 loss: 0.4801
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 12381/50000 (24.7620%),                 avg. length: 572.75,                last time consumption/overall running time: 34.3697s / 21595.9830 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.3076
env0_second_0:                 episode reward: -0.3500,                 loss: 0.4269
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 12401/50000 (24.8020%),                 avg. length: 597.4,                last time consumption/overall running time: 38.9473s / 21634.9303 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.3023
env0_second_0:                 episode reward: 0.0500,                 loss: 0.4024
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 12421/50000 (24.8420%),                 avg. length: 597.55,                last time consumption/overall running time: 36.0763s / 21671.0066 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.3266
env0_second_0:                 episode reward: -0.1000,                 loss: 0.4546
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 12441/50000 (24.8820%),                 avg. length: 534.45,                last time consumption/overall running time: 32.6946s / 21703.7012 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2933
env0_second_0:                 episode reward: 0.3500,                 loss: 0.3721
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 12461/50000 (24.9220%),                 avg. length: 577.0,                last time consumption/overall running time: 34.3400s / 21738.0413 s
env0_first_0:                 episode reward: 1.6000,                 loss: 0.3218
env0_second_0:                 episode reward: -1.6000,                 loss: 0.4079
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 12481/50000 (24.9620%),                 avg. length: 566.75,                last time consumption/overall running time: 34.0463s / 21772.0876 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.3182
env0_second_0:                 episode reward: -1.1500,                 loss: 0.4112
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 12501/50000 (25.0020%),                 avg. length: 569.45,                last time consumption/overall running time: 34.1070s / 21806.1945 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.3085
env0_second_0:                 episode reward: -0.3000,                 loss: 0.4108
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 12521/50000 (25.0420%),                 avg. length: 591.25,                last time consumption/overall running time: 35.9026s / 21842.0971 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.3119
env0_second_0:                 episode reward: 0.3500,                 loss: 0.3870
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 12541/50000 (25.0820%),                 avg. length: 564.1,                last time consumption/overall running time: 35.8666s / 21877.9637 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.3110
env0_second_0:                 episode reward: 0.2500,                 loss: 0.6562
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 12561/50000 (25.1220%),                 avg. length: 579.9,                last time consumption/overall running time: 35.9668s / 21913.9305 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.3283
env0_second_0:                 episode reward: -0.7000,                 loss: 0.4745
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 12581/50000 (25.1620%),                 avg. length: 566.9,                last time consumption/overall running time: 35.7327s / 21949.6632 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.3126
env0_second_0:                 episode reward: 0.0000,                 loss: 0.4232
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 12601/50000 (25.2020%),                 avg. length: 559.15,                last time consumption/overall running time: 35.0044s / 21984.6676 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.3083
env0_second_0:                 episode reward: 0.5500,                 loss: 0.3848
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 12621/50000 (25.2420%),                 avg. length: 577.35,                last time consumption/overall running time: 34.7138s / 22019.3813 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.3149
env0_second_0:                 episode reward: 0.4500,                 loss: 0.4462
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 12641/50000 (25.2820%),                 avg. length: 537.95,                last time consumption/overall running time: 32.7485s / 22052.1298 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.3043
env0_second_0:                 episode reward: 0.2000,                 loss: 0.4014
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 12661/50000 (25.3220%),                 avg. length: 559.65,                last time consumption/overall running time: 33.9045s / 22086.0343 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2893
env0_second_0:                 episode reward: 0.6500,                 loss: 0.4260
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 12681/50000 (25.3620%),                 avg. length: 519.25,                last time consumption/overall running time: 31.5900s / 22117.6243 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2919
env0_second_0:                 episode reward: -0.2000,                 loss: 0.4092
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 12701/50000 (25.4020%),                 avg. length: 554.2,                last time consumption/overall running time: 35.0290s / 22152.6533 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.2967
env0_second_0:                 episode reward: 0.9500,                 loss: 0.3787
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 12721/50000 (25.4420%),                 avg. length: 557.15,                last time consumption/overall running time: 33.7954s / 22186.4486 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2935
env0_second_0:                 episode reward: 0.1000,                 loss: 0.3522
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 12741/50000 (25.4820%),                 avg. length: 572.65,                last time consumption/overall running time: 34.5930s / 22221.0416 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2848
env0_second_0:                 episode reward: -0.5500,                 loss: 0.3608
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 12761/50000 (25.5220%),                 avg. length: 588.0,                last time consumption/overall running time: 37.1747s / 22258.2163 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2844
env0_second_0:                 episode reward: 0.2500,                 loss: 0.3769
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 12781/50000 (25.5620%),                 avg. length: 541.45,                last time consumption/overall running time: 32.9745s / 22291.1908 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2940
env0_second_0:                 episode reward: -0.2000,                 loss: 0.3806
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 12801/50000 (25.6020%),                 avg. length: 588.9,                last time consumption/overall running time: 35.4773s / 22326.6681 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.3132
env0_second_0:                 episode reward: 0.1000,                 loss: 0.4126
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 12821/50000 (25.6420%),                 avg. length: 598.35,                last time consumption/overall running time: 36.5334s / 22363.2016 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.3058
env0_second_0:                 episode reward: 0.4500,                 loss: 0.4212
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 12841/50000 (25.6820%),                 avg. length: 551.35,                last time consumption/overall running time: 35.2738s / 22398.4753 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2859
env0_second_0:                 episode reward: 0.2500,                 loss: 0.4165
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 12861/50000 (25.7220%),                 avg. length: 588.3,                last time consumption/overall running time: 39.0888s / 22437.5641 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.3124
env0_second_0:                 episode reward: 0.9000,                 loss: 0.4274
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 12881/50000 (25.7620%),                 avg. length: 558.9,                last time consumption/overall running time: 33.7974s / 22471.3615 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.3048
env0_second_0:                 episode reward: -0.5000,                 loss: 0.3772
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 12901/50000 (25.8020%),                 avg. length: 559.85,                last time consumption/overall running time: 33.7368s / 22505.0984 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2923
env0_second_0:                 episode reward: 0.2000,                 loss: 0.3803
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 12921/50000 (25.8420%),                 avg. length: 567.6,                last time consumption/overall running time: 34.0824s / 22539.1808 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2830
env0_second_0:                 episode reward: 0.3000,                 loss: 0.3972
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 12941/50000 (25.8820%),                 avg. length: 537.65,                last time consumption/overall running time: 36.5002s / 22575.6809 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.3176
env0_second_0:                 episode reward: 0.8000,                 loss: 0.4118
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 12961/50000 (25.9220%),                 avg. length: 554.3,                last time consumption/overall running time: 34.2253s / 22609.9062 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.3002
env0_second_0:                 episode reward: -0.1000,                 loss: 0.4111
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 12981/50000 (25.9620%),                 avg. length: 572.55,                last time consumption/overall running time: 34.8209s / 22644.7271 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.3079
env0_second_0:                 episode reward: -0.4000,                 loss: 0.4160
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 13001/50000 (26.0020%),                 avg. length: 564.05,                last time consumption/overall running time: 34.9509s / 22679.6780 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.3148
env0_second_0:                 episode reward: 0.2500,                 loss: 0.4074
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 13021/50000 (26.0420%),                 avg. length: 554.9,                last time consumption/overall running time: 35.0535s / 22714.7315 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2914
env0_second_0:                 episode reward: 0.1500,                 loss: 0.3520
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 13041/50000 (26.0820%),                 avg. length: 545.25,                last time consumption/overall running time: 35.0173s / 22749.7487 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2960
env0_second_0:                 episode reward: -0.3000,                 loss: 0.3803
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 13061/50000 (26.1220%),                 avg. length: 583.0,                last time consumption/overall running time: 34.6410s / 22784.3898 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.3246
env0_second_0:                 episode reward: -1.0500,                 loss: 0.5026
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 13081/50000 (26.1620%),                 avg. length: 556.1,                last time consumption/overall running time: 33.3171s / 22817.7068 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.3171
env0_second_0:                 episode reward: -0.1000,                 loss: 0.4845
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 13101/50000 (26.2020%),                 avg. length: 591.75,                last time consumption/overall running time: 35.3402s / 22853.0470 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.3360
env0_second_0:                 episode reward: -0.3500,                 loss: 0.4369
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 13121/50000 (26.2420%),                 avg. length: 553.5,                last time consumption/overall running time: 33.2758s / 22886.3228 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.3136
env0_second_0:                 episode reward: -0.4000,                 loss: 0.3811
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 13141/50000 (26.2820%),                 avg. length: 586.8,                last time consumption/overall running time: 34.9078s / 22921.2306 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2987
env0_second_0:                 episode reward: -0.0500,                 loss: 0.3726
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 13161/50000 (26.3220%),                 avg. length: 572.15,                last time consumption/overall running time: 34.0501s / 22955.2807 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.3059
env0_second_0:                 episode reward: 0.8000,                 loss: 0.3875
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 13181/50000 (26.3620%),                 avg. length: 572.85,                last time consumption/overall running time: 34.2143s / 22989.4949 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.2971
env0_second_0:                 episode reward: 0.7000,                 loss: 0.3584
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 13201/50000 (26.4020%),                 avg. length: 556.25,                last time consumption/overall running time: 34.1887s / 23023.6837 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2948
env0_second_0:                 episode reward: -0.2000,                 loss: 0.3649
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 13221/50000 (26.4420%),                 avg. length: 594.9,                last time consumption/overall running time: 39.5172s / 23063.2009 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.3045
env0_second_0:                 episode reward: 0.5000,                 loss: 0.3648
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 13241/50000 (26.4820%),                 avg. length: 559.35,                last time consumption/overall running time: 33.7641s / 23096.9650 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2836
env0_second_0:                 episode reward: -0.5500,                 loss: 0.3559
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 13261/50000 (26.5220%),                 avg. length: 530.85,                last time consumption/overall running time: 32.6330s / 23129.5981 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2823
env0_second_0:                 episode reward: 0.5000,                 loss: 0.3530
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 13281/50000 (26.5620%),                 avg. length: 570.0,                last time consumption/overall running time: 37.1318s / 23166.7298 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.3302
env0_second_0:                 episode reward: 1.1000,                 loss: 0.3993
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 13301/50000 (26.6020%),                 avg. length: 572.15,                last time consumption/overall running time: 35.2389s / 23201.9687 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.3077
env0_second_0:                 episode reward: -0.7000,                 loss: 0.3915
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 13321/50000 (26.6420%),                 avg. length: 550.5,                last time consumption/overall running time: 33.1127s / 23235.0814 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2791
env0_second_0:                 episode reward: -0.1500,                 loss: 0.3611
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 13341/50000 (26.6820%),                 avg. length: 573.15,                last time consumption/overall running time: 35.3848s / 23270.4662 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2810
env0_second_0:                 episode reward: -0.6500,                 loss: 0.3570
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 13361/50000 (26.7220%),                 avg. length: 592.05,                last time consumption/overall running time: 37.6395s / 23308.1057 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2835
env0_second_0:                 episode reward: 0.0000,                 loss: 0.3539
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 13381/50000 (26.7620%),                 avg. length: 510.9,                last time consumption/overall running time: 38.1078s / 23346.2134 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2942
env0_second_0:                 episode reward: 0.3000,                 loss: 0.3730
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 13401/50000 (26.8020%),                 avg. length: 603.65,                last time consumption/overall running time: 39.0475s / 23385.2610 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2726
env0_second_0:                 episode reward: -0.2000,                 loss: 0.3542
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 13421/50000 (26.8420%),                 avg. length: 571.9,                last time consumption/overall running time: 34.4682s / 23419.7292 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2666
env0_second_0:                 episode reward: -0.0500,                 loss: 0.3496
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 13441/50000 (26.8820%),                 avg. length: 563.0,                last time consumption/overall running time: 34.3833s / 23454.1125 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2659
env0_second_0:                 episode reward: -0.5500,                 loss: 0.3473
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 13461/50000 (26.9220%),                 avg. length: 572.5,                last time consumption/overall running time: 34.6724s / 23488.7850 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2813
env0_second_0:                 episode reward: 0.5500,                 loss: 0.3327
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 13481/50000 (26.9620%),                 avg. length: 584.8,                last time consumption/overall running time: 37.1605s / 23525.9454 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2928
env0_second_0:                 episode reward: 0.4500,                 loss: 0.3302
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 13501/50000 (27.0020%),                 avg. length: 588.75,                last time consumption/overall running time: 35.3335s / 23561.2790 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.3125
env0_second_0:                 episode reward: -0.1000,                 loss: 0.3475
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 13521/50000 (27.0420%),                 avg. length: 578.95,                last time consumption/overall running time: 35.3371s / 23596.6160 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2902
env0_second_0:                 episode reward: -0.4000,                 loss: 0.3701
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 13541/50000 (27.0820%),                 avg. length: 576.25,                last time consumption/overall running time: 35.0768s / 23631.6929 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.2901
env0_second_0:                 episode reward: 1.0000,                 loss: 0.3444
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 13561/50000 (27.1220%),                 avg. length: 556.55,                last time consumption/overall running time: 40.0767s / 23671.7696 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.2824
env0_second_0:                 episode reward: 0.7000,                 loss: 0.3180
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 13581/50000 (27.1620%),                 avg. length: 590.25,                last time consumption/overall running time: 35.6180s / 23707.3877 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2866
env0_second_0:                 episode reward: -0.0500,                 loss: 0.3336
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 13601/50000 (27.2020%),                 avg. length: 567.6,                last time consumption/overall running time: 34.9673s / 23742.3550 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2936
env0_second_0:                 episode reward: 0.4500,                 loss: 0.3415
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 13621/50000 (27.2420%),                 avg. length: 594.0,                last time consumption/overall running time: 40.0030s / 23782.3580 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.3140
env0_second_0:                 episode reward: 0.6500,                 loss: 0.3645
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 13641/50000 (27.2820%),                 avg. length: 554.85,                last time consumption/overall running time: 34.3977s / 23816.7557 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2983
env0_second_0:                 episode reward: 0.0500,                 loss: 0.3381
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 13661/50000 (27.3220%),                 avg. length: 566.55,                last time consumption/overall running time: 34.3992s / 23851.1549 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.3109
env0_second_0:                 episode reward: 0.7000,                 loss: 0.3361
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 13681/50000 (27.3620%),                 avg. length: 559.4,                last time consumption/overall running time: 33.7042s / 23884.8591 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2716
env0_second_0:                 episode reward: 0.0000,                 loss: 0.3164
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 13701/50000 (27.4020%),                 avg. length: 588.1,                last time consumption/overall running time: 36.1824s / 23921.0415 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.3099
env0_second_0:                 episode reward: 0.1000,                 loss: 0.3733
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 13721/50000 (27.4420%),                 avg. length: 569.4,                last time consumption/overall running time: 34.1590s / 23955.2005 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2891
env0_second_0:                 episode reward: -0.3500,                 loss: 0.3628
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 13741/50000 (27.4820%),                 avg. length: 570.75,                last time consumption/overall running time: 34.6139s / 23989.8145 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2996
env0_second_0:                 episode reward: 0.3500,                 loss: 0.3767
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 13761/50000 (27.5220%),                 avg. length: 552.2,                last time consumption/overall running time: 34.1206s / 24023.9351 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2920
env0_second_0:                 episode reward: 0.0500,                 loss: 0.3848
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 13781/50000 (27.5620%),                 avg. length: 562.9,                last time consumption/overall running time: 34.4319s / 24058.3670 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.3233
env0_second_0:                 episode reward: -0.2500,                 loss: 0.4046
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 13801/50000 (27.6020%),                 avg. length: 555.55,                last time consumption/overall running time: 33.4179s / 24091.7850 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.3009
env0_second_0:                 episode reward: 1.2500,                 loss: 0.3533
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 13821/50000 (27.6420%),                 avg. length: 558.75,                last time consumption/overall running time: 33.5432s / 24125.3282 s
env0_first_0:                 episode reward: 1.1000,                 loss: 0.3027
env0_second_0:                 episode reward: -1.1000,                 loss: 0.4030
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 13841/50000 (27.6820%),                 avg. length: 558.8,                last time consumption/overall running time: 33.6111s / 24158.9393 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2952
env0_second_0:                 episode reward: 0.1500,                 loss: 0.3646
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 13861/50000 (27.7220%),                 avg. length: 571.1,                last time consumption/overall running time: 34.2767s / 24193.2161 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2813
env0_second_0:                 episode reward: -0.2500,                 loss: 0.3334
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 13881/50000 (27.7620%),                 avg. length: 564.55,                last time consumption/overall running time: 34.3287s / 24227.5448 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.3080
env0_second_0:                 episode reward: 0.3000,                 loss: 0.3610
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 13901/50000 (27.8020%),                 avg. length: 543.3,                last time consumption/overall running time: 38.0816s / 24265.6263 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.3065
env0_second_0:                 episode reward: 0.5000,                 loss: 0.3676
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 13921/50000 (27.8420%),                 avg. length: 540.25,                last time consumption/overall running time: 32.6228s / 24298.2491 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.3132
env0_second_0:                 episode reward: -0.5000,                 loss: 0.3841
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 13941/50000 (27.8820%),                 avg. length: 572.95,                last time consumption/overall running time: 34.3556s / 24332.6047 s
env0_first_0:                 episode reward: 1.5000,                 loss: 0.3194
env0_second_0:                 episode reward: -1.5000,                 loss: 0.3744
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 13961/50000 (27.9220%),                 avg. length: 551.9,                last time consumption/overall running time: 33.2439s / 24365.8486 s
env0_first_0:                 episode reward: 1.2000,                 loss: 0.3222
env0_second_0:                 episode reward: -1.2000,                 loss: 0.4059
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 13981/50000 (27.9620%),                 avg. length: 607.5,                last time consumption/overall running time: 36.1072s / 24401.9558 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.3070
env0_second_0:                 episode reward: 0.4500,                 loss: 0.3919
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 14001/50000 (28.0020%),                 avg. length: 560.85,                last time consumption/overall running time: 33.8662s / 24435.8220 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.3024
env0_second_0:                 episode reward: 0.0500,                 loss: 0.3589
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 14021/50000 (28.0420%),                 avg. length: 563.9,                last time consumption/overall running time: 33.8703s / 24469.6924 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.3071
env0_second_0:                 episode reward: 0.8500,                 loss: 0.3959
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 14041/50000 (28.0820%),                 avg. length: 585.85,                last time consumption/overall running time: 35.2562s / 24504.9486 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.3016
env0_second_0:                 episode reward: 0.0500,                 loss: 0.4121
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 14061/50000 (28.1220%),                 avg. length: 580.05,                last time consumption/overall running time: 36.1198s / 24541.0684 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.2901
env0_second_0:                 episode reward: 0.7500,                 loss: 0.3720
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 14081/50000 (28.1620%),                 avg. length: 578.0,                last time consumption/overall running time: 35.0138s / 24576.0822 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.3120
env0_second_0:                 episode reward: -0.3500,                 loss: 0.8314
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 14101/50000 (28.2020%),                 avg. length: 549.25,                last time consumption/overall running time: 32.8711s / 24608.9532 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.3066
env0_second_0:                 episode reward: -0.1500,                 loss: 0.4168
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 14121/50000 (28.2420%),                 avg. length: 567.2,                last time consumption/overall running time: 34.1118s / 24643.0651 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.3041
env0_second_0:                 episode reward: 0.8500,                 loss: 0.4409
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 14141/50000 (28.2820%),                 avg. length: 562.7,                last time consumption/overall running time: 34.0219s / 24677.0870 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.3125
env0_second_0:                 episode reward: 0.6500,                 loss: 0.4309
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 14161/50000 (28.3220%),                 avg. length: 567.0,                last time consumption/overall running time: 34.0230s / 24711.1100 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.3003
env0_second_0:                 episode reward: 0.4500,                 loss: 0.4552
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 14181/50000 (28.3620%),                 avg. length: 547.65,                last time consumption/overall running time: 33.1042s / 24744.2142 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.3382
env0_second_0:                 episode reward: -0.0500,                 loss: 0.4659
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 14201/50000 (28.4020%),                 avg. length: 605.05,                last time consumption/overall running time: 35.8540s / 24780.0682 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.3420
env0_second_0:                 episode reward: 0.6500,                 loss: 0.4448
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 14221/50000 (28.4420%),                 avg. length: 611.15,                last time consumption/overall running time: 37.1845s / 24817.2527 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.3197
env0_second_0:                 episode reward: 0.4500,                 loss: 0.4206
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 14241/50000 (28.4820%),                 avg. length: 581.15,                last time consumption/overall running time: 34.9627s / 24852.2154 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2955
env0_second_0:                 episode reward: 0.0500,                 loss: 0.3702
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 14261/50000 (28.5220%),                 avg. length: 536.4,                last time consumption/overall running time: 32.6083s / 24884.8237 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.3060
env0_second_0:                 episode reward: 0.3500,                 loss: 0.7129
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 14281/50000 (28.5620%),                 avg. length: 568.6,                last time consumption/overall running time: 34.4285s / 24919.2522 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2924
env0_second_0:                 episode reward: -0.4000,                 loss: 0.4459
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 14301/50000 (28.6020%),                 avg. length: 548.5,                last time consumption/overall running time: 33.7517s / 24953.0039 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.3030
env0_second_0:                 episode reward: -0.0500,                 loss: 0.4303
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 14321/50000 (28.6420%),                 avg. length: 592.6,                last time consumption/overall running time: 35.5529s / 24988.5568 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.3075
env0_second_0:                 episode reward: 0.1000,                 loss: 0.4427
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 14341/50000 (28.6820%),                 avg. length: 552.85,                last time consumption/overall running time: 33.3465s / 25021.9033 s
env0_first_0:                 episode reward: 1.2000,                 loss: 0.3094
env0_second_0:                 episode reward: -1.2000,                 loss: 0.4472
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 14361/50000 (28.7220%),                 avg. length: 586.4,                last time consumption/overall running time: 35.0555s / 25056.9588 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.3094
env0_second_0:                 episode reward: -0.3000,                 loss: 0.4187
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 14381/50000 (28.7620%),                 avg. length: 559.2,                last time consumption/overall running time: 34.0951s / 25091.0539 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.3204
env0_second_0:                 episode reward: 1.3500,                 loss: 0.4286
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 14401/50000 (28.8020%),                 avg. length: 578.1,                last time consumption/overall running time: 36.3049s / 25127.3588 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.3394
env0_second_0:                 episode reward: 0.0000,                 loss: 0.4201
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 14421/50000 (28.8420%),                 avg. length: 543.1,                last time consumption/overall running time: 33.8138s / 25161.1725 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.3086
env0_second_0:                 episode reward: -0.0500,                 loss: 0.3819
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 14441/50000 (28.8820%),                 avg. length: 561.3,                last time consumption/overall running time: 33.8574s / 25195.0300 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2854
env0_second_0:                 episode reward: 0.2000,                 loss: 0.3803
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 14461/50000 (28.9220%),                 avg. length: 565.6,                last time consumption/overall running time: 34.0818s / 25229.1117 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.3241
env0_second_0:                 episode reward: -0.4500,                 loss: 0.4038
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 14481/50000 (28.9620%),                 avg. length: 555.95,                last time consumption/overall running time: 33.5888s / 25262.7005 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2985
env0_second_0:                 episode reward: -0.5000,                 loss: 0.3625
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 14501/50000 (29.0020%),                 avg. length: 597.45,                last time consumption/overall running time: 36.6645s / 25299.3651 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.3096
env0_second_0:                 episode reward: 0.5000,                 loss: 0.3819
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 14521/50000 (29.0420%),                 avg. length: 568.3,                last time consumption/overall running time: 37.6867s / 25337.0518 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.3050
env0_second_0:                 episode reward: 0.1500,                 loss: 0.3925
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 14541/50000 (29.0820%),                 avg. length: 549.5,                last time consumption/overall running time: 33.3308s / 25370.3826 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.2970
env0_second_0:                 episode reward: 0.9500,                 loss: 0.3919
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 14561/50000 (29.1220%),                 avg. length: 567.55,                last time consumption/overall running time: 34.2859s / 25404.6685 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.3023
env0_second_0:                 episode reward: -0.0500,                 loss: 0.4211
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 14581/50000 (29.1620%),                 avg. length: 551.75,                last time consumption/overall running time: 35.1581s / 25439.8266 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.3062
env0_second_0:                 episode reward: -0.4500,                 loss: 0.4092
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 14601/50000 (29.2020%),                 avg. length: 599.5,                last time consumption/overall running time: 42.2399s / 25482.0665 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2930
env0_second_0:                 episode reward: -0.6500,                 loss: 0.3864
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 14621/50000 (29.2420%),                 avg. length: 577.3,                last time consumption/overall running time: 34.7521s / 25516.8185 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.3059
env0_second_0:                 episode reward: -0.2500,                 loss: 0.4054
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 14641/50000 (29.2820%),                 avg. length: 535.8,                last time consumption/overall running time: 32.5729s / 25549.3915 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.3072
env0_second_0:                 episode reward: -0.0500,                 loss: 0.4384
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 14661/50000 (29.3220%),                 avg. length: 586.75,                last time consumption/overall running time: 35.0441s / 25584.4356 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2877
env0_second_0:                 episode reward: 0.1500,                 loss: 0.4012
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 14681/50000 (29.3620%),                 avg. length: 584.35,                last time consumption/overall running time: 34.8701s / 25619.3056 s
env0_first_0:                 episode reward: -1.5500,                 loss: 0.2905
env0_second_0:                 episode reward: 1.5500,                 loss: 0.3777
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 14701/50000 (29.4020%),                 avg. length: 566.35,                last time consumption/overall running time: 34.1980s / 25653.5036 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.3012
env0_second_0:                 episode reward: 0.5500,                 loss: 0.4095
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 14721/50000 (29.4420%),                 avg. length: 595.85,                last time consumption/overall running time: 35.5627s / 25689.0663 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.3025
env0_second_0:                 episode reward: -0.1500,                 loss: 0.3862
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 14741/50000 (29.4820%),                 avg. length: 572.35,                last time consumption/overall running time: 34.3499s / 25723.4162 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.3068
env0_second_0:                 episode reward: 0.1000,                 loss: 0.3867
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 14761/50000 (29.5220%),                 avg. length: 552.1,                last time consumption/overall running time: 33.3928s / 25756.8090 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.2974
env0_second_0:                 episode reward: -0.4500,                 loss: 0.4076
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 14781/50000 (29.5620%),                 avg. length: 602.25,                last time consumption/overall running time: 35.7217s / 25792.5307 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2899
env0_second_0:                 episode reward: 0.5500,                 loss: 0.4197
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 14801/50000 (29.6020%),                 avg. length: 563.95,                last time consumption/overall running time: 33.8950s / 25826.4257 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2742
env0_second_0:                 episode reward: 0.0500,                 loss: 2.3140
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 14821/50000 (29.6420%),                 avg. length: 548.3,                last time consumption/overall running time: 33.4499s / 25859.8755 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.2958
env0_second_0:                 episode reward: -0.8000,                 loss: 0.6337
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 14841/50000 (29.6820%),                 avg. length: 547.15,                last time consumption/overall running time: 33.0374s / 25892.9129 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2713
env0_second_0:                 episode reward: 0.3000,                 loss: 0.4464
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 14861/50000 (29.7220%),                 avg. length: 564.7,                last time consumption/overall running time: 35.5848s / 25928.4977 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2877
env0_second_0:                 episode reward: -0.4000,                 loss: 0.4223
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 14881/50000 (29.7620%),                 avg. length: 572.6,                last time consumption/overall running time: 35.4831s / 25963.9808 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.3321
env0_second_0:                 episode reward: -0.2000,                 loss: 0.5391
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 14901/50000 (29.8020%),                 avg. length: 553.0,                last time consumption/overall running time: 33.4163s / 25997.3971 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2995
env0_second_0:                 episode reward: 0.6500,                 loss: 0.5086
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 14921/50000 (29.8420%),                 avg. length: 555.6,                last time consumption/overall running time: 33.9354s / 26031.3326 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2968
env0_second_0:                 episode reward: -0.1000,                 loss: 0.4504
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 14941/50000 (29.8820%),                 avg. length: 604.7,                last time consumption/overall running time: 36.1354s / 26067.4680 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.3086
env0_second_0:                 episode reward: -0.3000,                 loss: 0.4221
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 14961/50000 (29.9220%),                 avg. length: 564.55,                last time consumption/overall running time: 34.4584s / 26101.9264 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.3194
env0_second_0:                 episode reward: 0.0000,                 loss: 0.4053
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 14981/50000 (29.9620%),                 avg. length: 572.15,                last time consumption/overall running time: 34.2498s / 26136.1762 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.3386
env0_second_0:                 episode reward: -0.2000,                 loss: 0.4233
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 15001/50000 (30.0020%),                 avg. length: 533.5,                last time consumption/overall running time: 32.2102s / 26168.3864 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2874
env0_second_0:                 episode reward: 0.2000,                 loss: 0.3756
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 15021/50000 (30.0420%),                 avg. length: 566.25,                last time consumption/overall running time: 34.4096s / 26202.7960 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.3254
env0_second_0:                 episode reward: -0.1000,                 loss: 0.4176
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 15041/50000 (30.0820%),                 avg. length: 567.45,                last time consumption/overall running time: 34.3344s / 26237.1303 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.3368
env0_second_0:                 episode reward: -0.9000,                 loss: 0.4167
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 15061/50000 (30.1220%),                 avg. length: 541.55,                last time consumption/overall running time: 32.8539s / 26269.9842 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.3183
env0_second_0:                 episode reward: -0.0500,                 loss: 0.3965
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 15081/50000 (30.1620%),                 avg. length: 560.85,                last time consumption/overall running time: 33.6322s / 26303.6165 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.3412
env0_second_0:                 episode reward: -0.1500,                 loss: 0.4246
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 15101/50000 (30.2020%),                 avg. length: 561.85,                last time consumption/overall running time: 33.9078s / 26337.5242 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2985
env0_second_0:                 episode reward: -0.0500,                 loss: 0.3754
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 15121/50000 (30.2420%),                 avg. length: 584.3,                last time consumption/overall running time: 35.1518s / 26372.6761 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.3302
env0_second_0:                 episode reward: 0.0000,                 loss: 0.4184
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 15141/50000 (30.2820%),                 avg. length: 567.25,                last time consumption/overall running time: 37.4572s / 26410.1333 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.3178
env0_second_0:                 episode reward: 1.2000,                 loss: 0.3953
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 15161/50000 (30.3220%),                 avg. length: 581.75,                last time consumption/overall running time: 35.3592s / 26445.4925 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.3103
env0_second_0:                 episode reward: -0.6000,                 loss: 0.3949
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 15181/50000 (30.3620%),                 avg. length: 556.05,                last time consumption/overall running time: 33.4452s / 26478.9377 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.3190
env0_second_0:                 episode reward: -0.5000,                 loss: 0.6343
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 15201/50000 (30.4020%),                 avg. length: 569.65,                last time consumption/overall running time: 36.9445s / 26515.8822 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.3412
env0_second_0:                 episode reward: 0.5000,                 loss: 0.4573
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 15221/50000 (30.4420%),                 avg. length: 561.9,                last time consumption/overall running time: 35.4479s / 26551.3301 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.3312
env0_second_0:                 episode reward: -0.8000,                 loss: 0.4606
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 15241/50000 (30.4820%),                 avg. length: 579.75,                last time consumption/overall running time: 39.2485s / 26590.5785 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.3122
env0_second_0:                 episode reward: 1.0500,                 loss: 0.4564
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 15261/50000 (30.5220%),                 avg. length: 542.85,                last time consumption/overall running time: 32.7365s / 26623.3151 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.3219
env0_second_0:                 episode reward: 1.0000,                 loss: 0.4045
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 15281/50000 (30.5620%),                 avg. length: 581.75,                last time consumption/overall running time: 34.5782s / 26657.8933 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.3410
env0_second_0:                 episode reward: 0.4500,                 loss: 0.4473
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 15301/50000 (30.6020%),                 avg. length: 583.85,                last time consumption/overall running time: 35.4828s / 26693.3761 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.3076
env0_second_0:                 episode reward: 0.2500,                 loss: 0.4019
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 15321/50000 (30.6420%),                 avg. length: 545.15,                last time consumption/overall running time: 32.8517s / 26726.2278 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.2838
env0_second_0:                 episode reward: 1.2500,                 loss: 0.3996
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 15341/50000 (30.6820%),                 avg. length: 564.85,                last time consumption/overall running time: 33.7112s / 26759.9389 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2921
env0_second_0:                 episode reward: 0.2000,                 loss: 0.3643
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 15361/50000 (30.7220%),                 avg. length: 585.25,                last time consumption/overall running time: 34.6620s / 26794.6009 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2968
env0_second_0:                 episode reward: -0.1000,                 loss: 0.3596
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 15381/50000 (30.7620%),                 avg. length: 603.3,                last time consumption/overall running time: 35.9177s / 26830.5187 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2905
env0_second_0:                 episode reward: -0.3500,                 loss: 0.3661
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 15401/50000 (30.8020%),                 avg. length: 569.45,                last time consumption/overall running time: 35.4721s / 26865.9907 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.2744
env0_second_0:                 episode reward: -0.4500,                 loss: 0.3187
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 15421/50000 (30.8420%),                 avg. length: 562.8,                last time consumption/overall running time: 33.5630s / 26899.5537 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2907
env0_second_0:                 episode reward: 0.1000,                 loss: 0.3623
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 15441/50000 (30.8820%),                 avg. length: 563.25,                last time consumption/overall running time: 33.8435s / 26933.3971 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2872
env0_second_0:                 episode reward: -0.1500,                 loss: 0.3623
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 15461/50000 (30.9220%),                 avg. length: 539.5,                last time consumption/overall running time: 32.6657s / 26966.0629 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.3039
env0_second_0:                 episode reward: -0.6000,                 loss: 0.3815
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 15481/50000 (30.9620%),                 avg. length: 569.15,                last time consumption/overall running time: 34.0024s / 27000.0653 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.3321
env0_second_0:                 episode reward: 0.7000,                 loss: 0.4113
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 15501/50000 (31.0020%),                 avg. length: 561.3,                last time consumption/overall running time: 33.4737s / 27033.5389 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.3211
env0_second_0:                 episode reward: 0.1500,                 loss: 0.3898
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 15521/50000 (31.0420%),                 avg. length: 562.6,                last time consumption/overall running time: 33.5765s / 27067.1154 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.3000
env0_second_0:                 episode reward: 0.0500,                 loss: 0.3698
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 15541/50000 (31.0820%),                 avg. length: 581.05,                last time consumption/overall running time: 34.9435s / 27102.0589 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.2995
env0_second_0:                 episode reward: -0.7500,                 loss: 0.4257
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 15561/50000 (31.1220%),                 avg. length: 562.3,                last time consumption/overall running time: 35.6660s / 27137.7250 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.3038
env0_second_0:                 episode reward: 0.5500,                 loss: 0.4056
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 15581/50000 (31.1620%),                 avg. length: 586.85,                last time consumption/overall running time: 35.6327s / 27173.3577 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2893
env0_second_0:                 episode reward: 0.5500,                 loss: 0.3796
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 15601/50000 (31.2020%),                 avg. length: 581.3,                last time consumption/overall running time: 34.8653s / 27208.2230 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.3031
env0_second_0:                 episode reward: -0.5500,                 loss: 0.3721
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 15621/50000 (31.2420%),                 avg. length: 561.6,                last time consumption/overall running time: 33.9851s / 27242.2081 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.2813
env0_second_0:                 episode reward: 0.6000,                 loss: 0.3417
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 15641/50000 (31.2820%),                 avg. length: 535.55,                last time consumption/overall running time: 33.1179s / 27275.3260 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.2916
env0_second_0:                 episode reward: 1.2000,                 loss: 0.3774
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 15661/50000 (31.3220%),                 avg. length: 564.95,                last time consumption/overall running time: 35.2787s / 27310.6047 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.3092
env0_second_0:                 episode reward: 0.0000,                 loss: 0.3572
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 15681/50000 (31.3620%),                 avg. length: 572.4,                last time consumption/overall running time: 34.8826s / 27345.4873 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.3186
env0_second_0:                 episode reward: 0.0500,                 loss: 0.3789
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 15701/50000 (31.4020%),                 avg. length: 596.7,                last time consumption/overall running time: 35.5240s / 27381.0113 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.3121
env0_second_0:                 episode reward: -0.1000,                 loss: 0.4217
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 15721/50000 (31.4420%),                 avg. length: 585.1,                last time consumption/overall running time: 35.0550s / 27416.0663 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2862
env0_second_0:                 episode reward: 0.5500,                 loss: 0.4146
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 15741/50000 (31.4820%),                 avg. length: 544.6,                last time consumption/overall running time: 32.8641s / 27448.9304 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2849
env0_second_0:                 episode reward: -0.3000,                 loss: 0.3436
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 15761/50000 (31.5220%),                 avg. length: 588.6,                last time consumption/overall running time: 35.2434s / 27484.1739 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.3171
env0_second_0:                 episode reward: -0.8000,                 loss: 0.3607
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 15781/50000 (31.5620%),                 avg. length: 615.35,                last time consumption/overall running time: 36.4108s / 27520.5847 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.2978
env0_second_0:                 episode reward: 0.9500,                 loss: 1.3453
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 15801/50000 (31.6020%),                 avg. length: 545.3,                last time consumption/overall running time: 32.8579s / 27553.4426 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2990
env0_second_0:                 episode reward: -0.5500,                 loss: 0.4308
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 15821/50000 (31.6420%),                 avg. length: 547.65,                last time consumption/overall running time: 33.1309s / 27586.5736 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.3199
env0_second_0:                 episode reward: -0.3000,                 loss: 0.4395
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 15841/50000 (31.6820%),                 avg. length: 548.5,                last time consumption/overall running time: 39.5193s / 27626.0929 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.3354
env0_second_0:                 episode reward: 0.1000,                 loss: 0.4518
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 15861/50000 (31.7220%),                 avg. length: 529.15,                last time consumption/overall running time: 37.7413s / 27663.8342 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.3292
env0_second_0:                 episode reward: 0.1000,                 loss: 0.3911
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 15881/50000 (31.7620%),                 avg. length: 572.4,                last time consumption/overall running time: 34.2389s / 27698.0731 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2968
env0_second_0:                 episode reward: 0.0500,                 loss: 0.4074
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 15901/50000 (31.8020%),                 avg. length: 578.05,                last time consumption/overall running time: 34.6070s / 27732.6801 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2828
env0_second_0:                 episode reward: 0.3500,                 loss: 0.4019
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 15921/50000 (31.8420%),                 avg. length: 558.9,                last time consumption/overall running time: 34.9622s / 27767.6423 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2852
env0_second_0:                 episode reward: 0.3000,                 loss: 0.4198
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 15941/50000 (31.8820%),                 avg. length: 556.15,                last time consumption/overall running time: 34.2060s / 27801.8483 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.3038
env0_second_0:                 episode reward: 0.9500,                 loss: 0.4100
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 15961/50000 (31.9220%),                 avg. length: 596.05,                last time consumption/overall running time: 41.7022s / 27843.5505 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2786
env0_second_0:                 episode reward: -0.2500,                 loss: 0.3875
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 15981/50000 (31.9620%),                 avg. length: 533.35,                last time consumption/overall running time: 32.2552s / 27875.8058 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.3004
env0_second_0:                 episode reward: -1.1500,                 loss: 0.3862
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 16001/50000 (32.0020%),                 avg. length: 571.95,                last time consumption/overall running time: 35.1033s / 27910.9091 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.3185
env0_second_0:                 episode reward: 0.1500,                 loss: 0.4205
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 16021/50000 (32.0420%),                 avg. length: 573.25,                last time consumption/overall running time: 41.6825s / 27952.5916 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.3403
env0_second_0:                 episode reward: 0.4000,                 loss: 0.4201
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 16041/50000 (32.0820%),                 avg. length: 592.8,                last time consumption/overall running time: 35.2839s / 27987.8756 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.3372
env0_second_0:                 episode reward: 0.1000,                 loss: 0.3925
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 16061/50000 (32.1220%),                 avg. length: 560.75,                last time consumption/overall running time: 33.5470s / 28021.4225 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.3264
env0_second_0:                 episode reward: 0.0000,                 loss: 0.4101
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 16081/50000 (32.1620%),                 avg. length: 604.3,                last time consumption/overall running time: 35.9773s / 28057.3999 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.3318
env0_second_0:                 episode reward: -0.2500,                 loss: 0.3959
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 16101/50000 (32.2020%),                 avg. length: 567.4,                last time consumption/overall running time: 39.4806s / 28096.8804 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.3305
env0_second_0:                 episode reward: -0.2000,                 loss: 0.3851
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 16121/50000 (32.2420%),                 avg. length: 559.3,                last time consumption/overall running time: 35.3226s / 28132.2030 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.2875
env0_second_0:                 episode reward: -0.9000,                 loss: 0.3550
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 16141/50000 (32.2820%),                 avg. length: 569.15,                last time consumption/overall running time: 34.6365s / 28166.8395 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.3176
env0_second_0:                 episode reward: -0.0500,                 loss: 0.3810
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 16161/50000 (32.3220%),                 avg. length: 565.55,                last time consumption/overall running time: 33.7911s / 28200.6306 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.3306
env0_second_0:                 episode reward: 0.6000,                 loss: 0.3905
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 16181/50000 (32.3620%),                 avg. length: 544.6,                last time consumption/overall running time: 38.1563s / 28238.7869 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.3122
env0_second_0:                 episode reward: 0.3500,                 loss: 0.3991
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 16201/50000 (32.4020%),                 avg. length: 552.6,                last time consumption/overall running time: 33.8491s / 28272.6360 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.2960
env0_second_0:                 episode reward: 1.0500,                 loss: 0.3369
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 16221/50000 (32.4420%),                 avg. length: 547.0,                last time consumption/overall running time: 33.1011s / 28305.7372 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.3399
env0_second_0:                 episode reward: 0.1500,                 loss: 0.4054
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 16241/50000 (32.4820%),                 avg. length: 552.1,                last time consumption/overall running time: 33.0088s / 28338.7459 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.3083
env0_second_0:                 episode reward: -0.3000,                 loss: 0.3691
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 16261/50000 (32.5220%),                 avg. length: 574.1,                last time consumption/overall running time: 34.9039s / 28373.6499 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.3136
env0_second_0:                 episode reward: -0.2000,                 loss: 0.3795
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 16281/50000 (32.5620%),                 avg. length: 544.2,                last time consumption/overall running time: 33.8994s / 28407.5492 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2865
env0_second_0:                 episode reward: -0.3000,                 loss: 0.3594
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 16301/50000 (32.6020%),                 avg. length: 543.3,                last time consumption/overall running time: 32.7544s / 28440.3036 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.3173
env0_second_0:                 episode reward: -0.7000,                 loss: 0.4039
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 16321/50000 (32.6420%),                 avg. length: 584.2,                last time consumption/overall running time: 34.6998s / 28475.0034 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.3127
env0_second_0:                 episode reward: -0.8000,                 loss: 0.3596
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 16341/50000 (32.6820%),                 avg. length: 584.5,                last time consumption/overall running time: 34.8356s / 28509.8390 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.3084
env0_second_0:                 episode reward: 0.2000,                 loss: 0.4103
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 16361/50000 (32.7220%),                 avg. length: 581.45,                last time consumption/overall running time: 38.3498s / 28548.1888 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2990
env0_second_0:                 episode reward: 0.0000,                 loss: 0.3637
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 16381/50000 (32.7620%),                 avg. length: 603.45,                last time consumption/overall running time: 40.6605s / 28588.8493 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.3214
env0_second_0:                 episode reward: -1.0500,                 loss: 0.3920
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 16401/50000 (32.8020%),                 avg. length: 590.3,                last time consumption/overall running time: 35.2133s / 28624.0626 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.3399
env0_second_0:                 episode reward: 0.5000,                 loss: 0.4597
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 16421/50000 (32.8420%),                 avg. length: 546.05,                last time consumption/overall running time: 33.4216s / 28657.4842 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.3129
env0_second_0:                 episode reward: 0.8500,                 loss: 0.4196
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 16441/50000 (32.8820%),                 avg. length: 554.3,                last time consumption/overall running time: 36.0148s / 28693.4990 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.3054
env0_second_0:                 episode reward: 0.3500,                 loss: 0.3823
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 16461/50000 (32.9220%),                 avg. length: 582.0,                last time consumption/overall running time: 38.5736s / 28732.0727 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.3545
env0_second_0:                 episode reward: 0.0500,                 loss: 0.4016
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 16481/50000 (32.9620%),                 avg. length: 546.8,                last time consumption/overall running time: 34.3853s / 28766.4580 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.3089
env0_second_0:                 episode reward: -0.0500,                 loss: 0.3496
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 16501/50000 (33.0020%),                 avg. length: 568.35,                last time consumption/overall running time: 33.8588s / 28800.3168 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.3015
env0_second_0:                 episode reward: 0.9000,                 loss: 0.3523
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 16521/50000 (33.0420%),                 avg. length: 574.7,                last time consumption/overall running time: 34.2489s / 28834.5657 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.3297
env0_second_0:                 episode reward: -0.1500,                 loss: 0.4031
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 16541/50000 (33.0820%),                 avg. length: 583.45,                last time consumption/overall running time: 35.0784s / 28869.6441 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.3080
env0_second_0:                 episode reward: 0.6000,                 loss: 0.4208
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 16561/50000 (33.1220%),                 avg. length: 574.9,                last time consumption/overall running time: 34.4919s / 28904.1360 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.3138
env0_second_0:                 episode reward: 0.4500,                 loss: 0.4052
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 16581/50000 (33.1620%),                 avg. length: 560.4,                last time consumption/overall running time: 33.7027s / 28937.8386 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2978
env0_second_0:                 episode reward: -0.2000,                 loss: 0.3649
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 16601/50000 (33.2020%),                 avg. length: 571.15,                last time consumption/overall running time: 33.9898s / 28971.8284 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2981
env0_second_0:                 episode reward: 0.5500,                 loss: 0.3770
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 16621/50000 (33.2420%),                 avg. length: 579.3,                last time consumption/overall running time: 38.1761s / 29010.0045 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.3056
env0_second_0:                 episode reward: -0.1500,                 loss: 0.3705
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 16641/50000 (33.2820%),                 avg. length: 544.55,                last time consumption/overall running time: 36.0236s / 29046.0281 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.3246
env0_second_0:                 episode reward: -0.7000,                 loss: 0.3818
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 16661/50000 (33.3220%),                 avg. length: 526.95,                last time consumption/overall running time: 34.3428s / 29080.3709 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.3099
env0_second_0:                 episode reward: -0.0500,                 loss: 0.4041
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 16681/50000 (33.3620%),                 avg. length: 557.15,                last time consumption/overall running time: 33.3352s / 29113.7061 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.3314
env0_second_0:                 episode reward: -0.0500,                 loss: 0.3998
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 16701/50000 (33.4020%),                 avg. length: 526.45,                last time consumption/overall running time: 32.3637s / 29146.0698 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.3115
env0_second_0:                 episode reward: -0.8000,                 loss: 0.3886
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 16721/50000 (33.4420%),                 avg. length: 605.05,                last time consumption/overall running time: 37.4460s / 29183.5158 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2957
env0_second_0:                 episode reward: -0.0500,                 loss: 0.3745
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 16741/50000 (33.4820%),                 avg. length: 556.55,                last time consumption/overall running time: 34.6020s / 29218.1178 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.2922
env0_second_0:                 episode reward: 0.7000,                 loss: 0.3452
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 16761/50000 (33.5220%),                 avg. length: 556.45,                last time consumption/overall running time: 33.6562s / 29251.7740 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.2930
env0_second_0:                 episode reward: -0.4500,                 loss: 0.3519
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 16781/50000 (33.5620%),                 avg. length: 553.75,                last time consumption/overall running time: 33.5259s / 29285.2999 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.3145
env0_second_0:                 episode reward: 0.2500,                 loss: 0.3662
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 16801/50000 (33.6020%),                 avg. length: 603.2,                last time consumption/overall running time: 35.8065s / 29321.1064 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.3272
env0_second_0:                 episode reward: 0.3500,                 loss: 0.3848
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 16821/50000 (33.6420%),                 avg. length: 590.4,                last time consumption/overall running time: 35.2513s / 29356.3577 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.3132
env0_second_0:                 episode reward: -0.2500,                 loss: 0.3540
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 16841/50000 (33.6820%),                 avg. length: 587.05,                last time consumption/overall running time: 35.0846s / 29391.4423 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2868
env0_second_0:                 episode reward: 0.3500,                 loss: 0.3492
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 16861/50000 (33.7220%),                 avg. length: 551.55,                last time consumption/overall running time: 33.2300s / 29424.6723 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.3067
env0_second_0:                 episode reward: -0.3000,                 loss: 0.3646
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 16881/50000 (33.7620%),                 avg. length: 544.75,                last time consumption/overall running time: 32.8082s / 29457.4805 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.3081
env0_second_0:                 episode reward: 0.9000,                 loss: 0.4265
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 16901/50000 (33.8020%),                 avg. length: 553.3,                last time consumption/overall running time: 33.4449s / 29490.9254 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.3313
env0_second_0:                 episode reward: 1.1500,                 loss: 0.4138
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 16921/50000 (33.8420%),                 avg. length: 580.3,                last time consumption/overall running time: 35.4416s / 29526.3670 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.3160
env0_second_0:                 episode reward: 0.0500,                 loss: 0.3715
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 16941/50000 (33.8820%),                 avg. length: 560.8,                last time consumption/overall running time: 33.6905s / 29560.0575 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.3305
env0_second_0:                 episode reward: 0.4000,                 loss: 0.4570
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 16961/50000 (33.9220%),                 avg. length: 551.7,                last time consumption/overall running time: 33.1927s / 29593.2502 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.3306
env0_second_0:                 episode reward: -0.8500,                 loss: 0.4278
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 16981/50000 (33.9620%),                 avg. length: 565.3,                last time consumption/overall running time: 35.0966s / 29628.3468 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.3053
env0_second_0:                 episode reward: -0.4500,                 loss: 0.3696
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 17001/50000 (34.0020%),                 avg. length: 563.8,                last time consumption/overall running time: 33.8647s / 29662.2114 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.3284
env0_second_0:                 episode reward: 0.0000,                 loss: 0.3914
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 17021/50000 (34.0420%),                 avg. length: 544.9,                last time consumption/overall running time: 33.6586s / 29695.8701 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.3212
env0_second_0:                 episode reward: 0.1000,                 loss: 0.3492
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 17041/50000 (34.0820%),                 avg. length: 565.5,                last time consumption/overall running time: 33.8403s / 29729.7104 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.3486
env0_second_0:                 episode reward: -0.4500,                 loss: 0.3944
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 17061/50000 (34.1220%),                 avg. length: 565.75,                last time consumption/overall running time: 33.9972s / 29763.7076 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.3228
env0_second_0:                 episode reward: 0.9000,                 loss: 0.3708
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 17081/50000 (34.1620%),                 avg. length: 580.2,                last time consumption/overall running time: 36.1538s / 29799.8614 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.3527
env0_second_0:                 episode reward: -0.5500,                 loss: 0.4204
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 17101/50000 (34.2020%),                 avg. length: 558.5,                last time consumption/overall running time: 34.0270s / 29833.8884 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.3057
env0_second_0:                 episode reward: 0.1000,                 loss: 0.3584
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 17121/50000 (34.2420%),                 avg. length: 504.9,                last time consumption/overall running time: 30.7188s / 29864.6071 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.3059
env0_second_0:                 episode reward: 0.3000,                 loss: 0.3819
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 17141/50000 (34.2820%),                 avg. length: 603.45,                last time consumption/overall running time: 35.8095s / 29900.4167 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.3420
env0_second_0:                 episode reward: -0.7000,                 loss: 0.4169
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 17161/50000 (34.3220%),                 avg. length: 489.9,                last time consumption/overall running time: 30.5281s / 29930.9447 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2914
env0_second_0:                 episode reward: 0.3500,                 loss: 0.3389
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 17181/50000 (34.3620%),                 avg. length: 533.9,                last time consumption/overall running time: 33.1854s / 29964.1301 s
env0_first_0:                 episode reward: 1.3500,                 loss: 0.3150
env0_second_0:                 episode reward: -1.3500,                 loss: 0.3867
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 17201/50000 (34.4020%),                 avg. length: 542.75,                last time consumption/overall running time: 32.8995s / 29997.0296 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2955
env0_second_0:                 episode reward: -0.3500,                 loss: 0.3573
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 17221/50000 (34.4420%),                 avg. length: 548.5,                last time consumption/overall running time: 32.8556s / 30029.8853 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.3274
env0_second_0:                 episode reward: 0.9500,                 loss: 0.3908
env1_first_0:                 episode reward: 1.5000,                 loss: nan
env1_second_0:                 episode reward: -1.5000,                 loss: nan
Episode: 17241/50000 (34.4820%),                 avg. length: 540.65,                last time consumption/overall running time: 32.4131s / 30062.2984 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.3001
env0_second_0:                 episode reward: 0.7000,                 loss: 0.3710
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 17261/50000 (34.5220%),                 avg. length: 536.55,                last time consumption/overall running time: 33.1919s / 30095.4903 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.3048
env0_second_0:                 episode reward: -0.5500,                 loss: 0.3998
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 17281/50000 (34.5620%),                 avg. length: 582.5,                last time consumption/overall running time: 34.9737s / 30130.4640 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.3241
env0_second_0:                 episode reward: -0.1500,                 loss: 0.3851
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 17301/50000 (34.6020%),                 avg. length: 553.3,                last time consumption/overall running time: 33.3139s / 30163.7779 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2975
env0_second_0:                 episode reward: -0.3000,                 loss: 0.3603
env1_first_0:                 episode reward: 1.5000,                 loss: nan
env1_second_0:                 episode reward: -1.5000,                 loss: nan
Episode: 17321/50000 (34.6420%),                 avg. length: 591.15,                last time consumption/overall running time: 35.2865s / 30199.0644 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2963
env0_second_0:                 episode reward: -0.5500,                 loss: 0.3541
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 17341/50000 (34.6820%),                 avg. length: 565.35,                last time consumption/overall running time: 34.3469s / 30233.4112 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2998
env0_second_0:                 episode reward: 0.0000,                 loss: 0.3636
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 17361/50000 (34.7220%),                 avg. length: 574.6,                last time consumption/overall running time: 34.7066s / 30268.1179 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.3142
env0_second_0:                 episode reward: 1.0000,                 loss: 0.3772
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 17381/50000 (34.7620%),                 avg. length: 619.05,                last time consumption/overall running time: 36.6634s / 30304.7812 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.3249
env0_second_0:                 episode reward: -0.5000,                 loss: 0.4162
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 17401/50000 (34.8020%),                 avg. length: 569.35,                last time consumption/overall running time: 33.9495s / 30338.7307 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2934
env0_second_0:                 episode reward: -0.1500,                 loss: 0.3566
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 17421/50000 (34.8420%),                 avg. length: 564.0,                last time consumption/overall running time: 33.9444s / 30372.6751 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.3050
env0_second_0:                 episode reward: -0.1000,                 loss: 0.3566
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 17441/50000 (34.8820%),                 avg. length: 557.45,                last time consumption/overall running time: 34.3167s / 30406.9919 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.3055
env0_second_0:                 episode reward: 0.5500,                 loss: 0.3678
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 17461/50000 (34.9220%),                 avg. length: 586.7,                last time consumption/overall running time: 34.9667s / 30441.9586 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.3159
env0_second_0:                 episode reward: 0.6500,                 loss: 0.4079
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 17481/50000 (34.9620%),                 avg. length: 605.9,                last time consumption/overall running time: 35.9082s / 30477.8668 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.3238
env0_second_0:                 episode reward: 0.6500,                 loss: 0.3584
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 17501/50000 (35.0020%),                 avg. length: 566.45,                last time consumption/overall running time: 34.0536s / 30511.9204 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2973
env0_second_0:                 episode reward: -0.6500,                 loss: 0.3546
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 17521/50000 (35.0420%),                 avg. length: 541.7,                last time consumption/overall running time: 33.3192s / 30545.2396 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.3219
env0_second_0:                 episode reward: 0.2000,                 loss: 0.3856
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 17541/50000 (35.0820%),                 avg. length: 553.35,                last time consumption/overall running time: 33.8259s / 30579.0655 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.3085
env0_second_0:                 episode reward: 0.5000,                 loss: 0.3769
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 17561/50000 (35.1220%),                 avg. length: 593.1,                last time consumption/overall running time: 35.1353s / 30614.2007 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.3263
env0_second_0:                 episode reward: 0.8000,                 loss: 0.3698
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 17581/50000 (35.1620%),                 avg. length: 579.25,                last time consumption/overall running time: 34.5397s / 30648.7404 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.3275
env0_second_0:                 episode reward: -0.3500,                 loss: 0.3826
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 17601/50000 (35.2020%),                 avg. length: 578.5,                last time consumption/overall running time: 34.7922s / 30683.5326 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.3061
env0_second_0:                 episode reward: 0.7000,                 loss: 0.3425
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 17621/50000 (35.2420%),                 avg. length: 558.7,                last time consumption/overall running time: 34.8584s / 30718.3911 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.3100
env0_second_0:                 episode reward: 0.7500,                 loss: 0.4028
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 17641/50000 (35.2820%),                 avg. length: 570.5,                last time consumption/overall running time: 36.4468s / 30754.8378 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.3221
env0_second_0:                 episode reward: 0.1500,                 loss: 0.4591
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 17661/50000 (35.3220%),                 avg. length: 540.35,                last time consumption/overall running time: 32.5406s / 30787.3784 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.3132
env0_second_0:                 episode reward: -0.2500,                 loss: 0.4427
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 17681/50000 (35.3620%),                 avg. length: 563.5,                last time consumption/overall running time: 33.8006s / 30821.1790 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.3007
env0_second_0:                 episode reward: 1.0000,                 loss: 0.3808
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 17701/50000 (35.4020%),                 avg. length: 591.75,                last time consumption/overall running time: 39.7745s / 30860.9535 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.3167
env0_second_0:                 episode reward: 1.0000,                 loss: 0.4009
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 17721/50000 (35.4420%),                 avg. length: 559.3,                last time consumption/overall running time: 35.3780s / 30896.3315 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2980
env0_second_0:                 episode reward: -0.2000,                 loss: 0.3582
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 17741/50000 (35.4820%),                 avg. length: 613.95,                last time consumption/overall running time: 37.9490s / 30934.2805 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.3086
env0_second_0:                 episode reward: 0.4500,                 loss: 0.3645
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 17761/50000 (35.5220%),                 avg. length: 577.4,                last time consumption/overall running time: 36.5163s / 30970.7969 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.3075
env0_second_0:                 episode reward: -0.2000,                 loss: 0.3579
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 17781/50000 (35.5620%),                 avg. length: 581.25,                last time consumption/overall running time: 35.2709s / 31006.0677 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.3121
env0_second_0:                 episode reward: -0.5500,                 loss: 0.3447
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 17801/50000 (35.6020%),                 avg. length: 558.6,                last time consumption/overall running time: 34.5926s / 31040.6603 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.3365
env0_second_0:                 episode reward: -0.1500,                 loss: 0.3690
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 17821/50000 (35.6420%),                 avg. length: 594.8,                last time consumption/overall running time: 36.3771s / 31077.0375 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.3127
env0_second_0:                 episode reward: -0.2000,                 loss: 0.3517
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 17841/50000 (35.6820%),                 avg. length: 526.25,                last time consumption/overall running time: 32.9343s / 31109.9718 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.3086
env0_second_0:                 episode reward: -0.7000,                 loss: 0.3496
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 17861/50000 (35.7220%),                 avg. length: 569.0,                last time consumption/overall running time: 35.8775s / 31145.8493 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.3399
env0_second_0:                 episode reward: 0.5000,                 loss: 0.4027
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 17881/50000 (35.7620%),                 avg. length: 573.95,                last time consumption/overall running time: 37.0876s / 31182.9369 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.3116
env0_second_0:                 episode reward: -0.4000,                 loss: 0.3618
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 17901/50000 (35.8020%),                 avg. length: 568.6,                last time consumption/overall running time: 35.2631s / 31218.2000 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.3123
env0_second_0:                 episode reward: -0.6000,                 loss: 0.3858
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 17921/50000 (35.8420%),                 avg. length: 581.25,                last time consumption/overall running time: 35.6875s / 31253.8875 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.2900
env0_second_0:                 episode reward: -0.4500,                 loss: 0.3395
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 17941/50000 (35.8820%),                 avg. length: 553.6,                last time consumption/overall running time: 34.3815s / 31288.2690 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.3003
env0_second_0:                 episode reward: -0.4000,                 loss: 0.3433
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 17961/50000 (35.9220%),                 avg. length: 553.5,                last time consumption/overall running time: 34.4948s / 31322.7637 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2955
env0_second_0:                 episode reward: -0.1000,                 loss: 0.3490
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 17981/50000 (35.9620%),                 avg. length: 535.2,                last time consumption/overall running time: 32.8651s / 31355.6288 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.3053
env0_second_0:                 episode reward: 1.3000,                 loss: 0.3691
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 18001/50000 (36.0020%),                 avg. length: 562.4,                last time consumption/overall running time: 34.2333s / 31389.8622 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2951
env0_second_0:                 episode reward: 0.3000,                 loss: 0.3450
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 18021/50000 (36.0420%),                 avg. length: 579.0,                last time consumption/overall running time: 35.2056s / 31425.0678 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.3284
env0_second_0:                 episode reward: -0.5500,                 loss: 0.3870
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 18041/50000 (36.0820%),                 avg. length: 567.45,                last time consumption/overall running time: 34.8043s / 31459.8721 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.3013
env0_second_0:                 episode reward: -0.5500,                 loss: 0.3445
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 18061/50000 (36.1220%),                 avg. length: 542.65,                last time consumption/overall running time: 33.2368s / 31493.1089 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.3093
env0_second_0:                 episode reward: 0.2000,                 loss: 0.3567
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 18081/50000 (36.1620%),                 avg. length: 547.2,                last time consumption/overall running time: 33.3384s / 31526.4473 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.2959
env0_second_0:                 episode reward: 0.8500,                 loss: 0.3427
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 18101/50000 (36.2020%),                 avg. length: 543.6,                last time consumption/overall running time: 33.1368s / 31559.5842 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.3221
env0_second_0:                 episode reward: 0.0500,                 loss: 0.3795
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 18121/50000 (36.2420%),                 avg. length: 543.65,                last time consumption/overall running time: 33.0556s / 31592.6398 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.3209
env0_second_0:                 episode reward: -0.2500,                 loss: 0.3734
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 18141/50000 (36.2820%),                 avg. length: 546.4,                last time consumption/overall running time: 33.5055s / 31626.1452 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.3167
env0_second_0:                 episode reward: 0.1000,                 loss: 0.3807
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 18161/50000 (36.3220%),                 avg. length: 540.6,                last time consumption/overall running time: 33.0221s / 31659.1673 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.3352
env0_second_0:                 episode reward: 0.2000,                 loss: 0.3754
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 18181/50000 (36.3620%),                 avg. length: 559.95,                last time consumption/overall running time: 33.9763s / 31693.1436 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.3000
env0_second_0:                 episode reward: 0.2500,                 loss: 0.3526
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 18201/50000 (36.4020%),                 avg. length: 597.75,                last time consumption/overall running time: 35.6730s / 31728.8166 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2888
env0_second_0:                 episode reward: -0.1000,                 loss: 0.3285
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 18221/50000 (36.4420%),                 avg. length: 587.5,                last time consumption/overall running time: 35.8127s / 31764.6294 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.3024
env0_second_0:                 episode reward: -0.3000,                 loss: 0.3733
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 18241/50000 (36.4820%),                 avg. length: 580.5,                last time consumption/overall running time: 36.5445s / 31801.1739 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2955
env0_second_0:                 episode reward: -0.1500,                 loss: 0.3465
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 18261/50000 (36.5220%),                 avg. length: 548.05,                last time consumption/overall running time: 33.5949s / 31834.7687 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.3225
env0_second_0:                 episode reward: -0.5000,                 loss: 0.3805
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 18281/50000 (36.5620%),                 avg. length: 521.75,                last time consumption/overall running time: 32.0335s / 31866.8022 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.3125
env0_second_0:                 episode reward: -0.0500,                 loss: 0.3725
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 18301/50000 (36.6020%),                 avg. length: 578.4,                last time consumption/overall running time: 36.4638s / 31903.2660 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.3281
env0_second_0:                 episode reward: -0.5500,                 loss: 0.3782
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 18321/50000 (36.6420%),                 avg. length: 578.7,                last time consumption/overall running time: 34.7834s / 31938.0494 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.2991
env0_second_0:                 episode reward: -0.7500,                 loss: 0.3595
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 18341/50000 (36.6820%),                 avg. length: 559.85,                last time consumption/overall running time: 35.3941s / 31973.4435 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.3120
env0_second_0:                 episode reward: 0.5000,                 loss: 0.3727
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 18361/50000 (36.7220%),                 avg. length: 569.05,                last time consumption/overall running time: 34.4386s / 32007.8821 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.3082
env0_second_0:                 episode reward: 0.5500,                 loss: 0.3673
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 18381/50000 (36.7620%),                 avg. length: 575.8,                last time consumption/overall running time: 36.6762s / 32044.5584 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.3246
env0_second_0:                 episode reward: -0.1500,                 loss: 0.4039
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 18401/50000 (36.8020%),                 avg. length: 596.45,                last time consumption/overall running time: 38.0551s / 32082.6135 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.3205
env0_second_0:                 episode reward: 0.1500,                 loss: 0.3767
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 18421/50000 (36.8420%),                 avg. length: 524.85,                last time consumption/overall running time: 35.0621s / 32117.6756 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.3130
env0_second_0:                 episode reward: 0.0000,                 loss: 0.3652
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 18441/50000 (36.8820%),                 avg. length: 583.4,                last time consumption/overall running time: 35.2016s / 32152.8773 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.3479
env0_second_0:                 episode reward: 0.0500,                 loss: 0.3942
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 18461/50000 (36.9220%),                 avg. length: 550.75,                last time consumption/overall running time: 35.6571s / 32188.5344 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.3612
env0_second_0:                 episode reward: 0.8500,                 loss: 0.4291
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 18481/50000 (36.9620%),                 avg. length: 595.35,                last time consumption/overall running time: 36.3591s / 32224.8935 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.3399
env0_second_0:                 episode reward: -0.2000,                 loss: 0.3929
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 18501/50000 (37.0020%),                 avg. length: 545.1,                last time consumption/overall running time: 34.7405s / 32259.6340 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.3214
env0_second_0:                 episode reward: -0.9500,                 loss: 0.3903
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 18521/50000 (37.0420%),                 avg. length: 505.35,                last time consumption/overall running time: 30.8928s / 32290.5268 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.3048
env0_second_0:                 episode reward: 0.4000,                 loss: 0.3495
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 18541/50000 (37.0820%),                 avg. length: 588.9,                last time consumption/overall running time: 35.0129s / 32325.5397 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.3583
env0_second_0:                 episode reward: -0.8000,                 loss: 0.4271
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 18561/50000 (37.1220%),                 avg. length: 546.35,                last time consumption/overall running time: 33.3081s / 32358.8478 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.3270
env0_second_0:                 episode reward: 0.2000,                 loss: 0.3728
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 18581/50000 (37.1620%),                 avg. length: 567.45,                last time consumption/overall running time: 35.0000s / 32393.8478 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.3261
env0_second_0:                 episode reward: -0.1000,                 loss: 0.3895
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 18601/50000 (37.2020%),                 avg. length: 597.25,                last time consumption/overall running time: 37.1459s / 32430.9937 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.3279
env0_second_0:                 episode reward: -0.0500,                 loss: 0.3939
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 18621/50000 (37.2420%),                 avg. length: 575.8,                last time consumption/overall running time: 34.3721s / 32465.3659 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.3068
env0_second_0:                 episode reward: -0.4500,                 loss: 0.3872
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 18641/50000 (37.2820%),                 avg. length: 551.05,                last time consumption/overall running time: 33.2722s / 32498.6380 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.3497
env0_second_0:                 episode reward: -0.7500,                 loss: 0.4299
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 18661/50000 (37.3220%),                 avg. length: 519.05,                last time consumption/overall running time: 32.0966s / 32530.7346 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.3176
env0_second_0:                 episode reward: 0.0000,                 loss: 0.3500
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 18681/50000 (37.3620%),                 avg. length: 562.0,                last time consumption/overall running time: 33.9534s / 32564.6881 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.3315
env0_second_0:                 episode reward: -0.4000,                 loss: 0.3811
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 18701/50000 (37.4020%),                 avg. length: 571.4,                last time consumption/overall running time: 35.5807s / 32600.2688 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.3875
env0_second_0:                 episode reward: 0.3500,                 loss: 0.4882
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 18721/50000 (37.4420%),                 avg. length: 558.15,                last time consumption/overall running time: 34.7783s / 32635.0471 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.3762
env0_second_0:                 episode reward: 0.5000,                 loss: 0.4484
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 18741/50000 (37.4820%),                 avg. length: 583.6,                last time consumption/overall running time: 35.5518s / 32670.5989 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.3748
env0_second_0:                 episode reward: 0.6000,                 loss: 0.4203
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 18761/50000 (37.5220%),                 avg. length: 526.9,                last time consumption/overall running time: 32.2438s / 32702.8427 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.4022
env0_second_0:                 episode reward: -0.6500,                 loss: 0.4602
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 18781/50000 (37.5620%),                 avg. length: 566.05,                last time consumption/overall running time: 34.2476s / 32737.0903 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.3829
env0_second_0:                 episode reward: -0.0500,                 loss: 0.4331
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 18801/50000 (37.6020%),                 avg. length: 543.55,                last time consumption/overall running time: 32.7498s / 32769.8402 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.3702
env0_second_0:                 episode reward: 0.6000,                 loss: 0.4348
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 18821/50000 (37.6420%),                 avg. length: 569.8,                last time consumption/overall running time: 33.9532s / 32803.7934 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.3408
env0_second_0:                 episode reward: -0.2000,                 loss: 0.3945
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 18841/50000 (37.6820%),                 avg. length: 575.8,                last time consumption/overall running time: 35.5836s / 32839.3770 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.3555
env0_second_0:                 episode reward: -0.2500,                 loss: 0.4101
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 18861/50000 (37.7220%),                 avg. length: 582.6,                last time consumption/overall running time: 38.4704s / 32877.8475 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.3368
env0_second_0:                 episode reward: -0.2000,                 loss: 0.3798
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 18881/50000 (37.7620%),                 avg. length: 557.65,                last time consumption/overall running time: 35.5274s / 32913.3749 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.3291
env0_second_0:                 episode reward: -0.1500,                 loss: 0.3876
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 18901/50000 (37.8020%),                 avg. length: 549.5,                last time consumption/overall running time: 33.9750s / 32947.3499 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.3166
env0_second_0:                 episode reward: -0.9500,                 loss: 0.3880
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 18921/50000 (37.8420%),                 avg. length: 565.6,                last time consumption/overall running time: 33.9730s / 32981.3228 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.3249
env0_second_0:                 episode reward: 0.5000,                 loss: 0.3742
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 18941/50000 (37.8820%),                 avg. length: 596.75,                last time consumption/overall running time: 35.5151s / 33016.8380 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.3511
env0_second_0:                 episode reward: 0.4500,                 loss: 0.3908
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 18961/50000 (37.9220%),                 avg. length: 578.6,                last time consumption/overall running time: 34.8778s / 33051.7157 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.3296
env0_second_0:                 episode reward: -0.3500,                 loss: 0.3936
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 18981/50000 (37.9620%),                 avg. length: 584.45,                last time consumption/overall running time: 34.8185s / 33086.5342 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.3477
env0_second_0:                 episode reward: 0.2500,                 loss: 0.3851
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 19001/50000 (38.0020%),                 avg. length: 605.3,                last time consumption/overall running time: 36.0219s / 33122.5561 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.3614
env0_second_0:                 episode reward: -0.1500,                 loss: 0.4134
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 19021/50000 (38.0420%),                 avg. length: 588.2,                last time consumption/overall running time: 35.1308s / 33157.6869 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.3425
env0_second_0:                 episode reward: -0.1000,                 loss: 0.4564
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 19041/50000 (38.0820%),                 avg. length: 587.5,                last time consumption/overall running time: 35.1071s / 33192.7940 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.3786
env0_second_0:                 episode reward: -0.6000,                 loss: 0.4714
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 19061/50000 (38.1220%),                 avg. length: 580.35,                last time consumption/overall running time: 34.5965s / 33227.3906 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.3545
env0_second_0:                 episode reward: 0.4000,                 loss: 0.5186
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 19081/50000 (38.1620%),                 avg. length: 520.25,                last time consumption/overall running time: 31.6772s / 33259.0678 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.3543
env0_second_0:                 episode reward: 0.3000,                 loss: 0.4544
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 19101/50000 (38.2020%),                 avg. length: 573.2,                last time consumption/overall running time: 34.3972s / 33293.4650 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.3122
env0_second_0:                 episode reward: 0.2000,                 loss: 0.4674
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 19121/50000 (38.2420%),                 avg. length: 578.45,                last time consumption/overall running time: 35.2660s / 33328.7310 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.3241
env0_second_0:                 episode reward: -0.2500,                 loss: 0.4470
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 19141/50000 (38.2820%),                 avg. length: 563.95,                last time consumption/overall running time: 34.0475s / 33362.7785 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.3231
env0_second_0:                 episode reward: -0.8000,                 loss: 0.4186
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 19161/50000 (38.3220%),                 avg. length: 539.05,                last time consumption/overall running time: 32.6610s / 33395.4394 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.3261
env0_second_0:                 episode reward: -0.6000,                 loss: 0.4164
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 19181/50000 (38.3620%),                 avg. length: 589.15,                last time consumption/overall running time: 35.0407s / 33430.4802 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.3275
env0_second_0:                 episode reward: 1.3000,                 loss: 0.4073
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 19201/50000 (38.4020%),                 avg. length: 574.05,                last time consumption/overall running time: 35.4310s / 33465.9112 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.3295
env0_second_0:                 episode reward: -0.4000,                 loss: 0.3901
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 19221/50000 (38.4420%),                 avg. length: 591.4,                last time consumption/overall running time: 35.3622s / 33501.2734 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.3349
env0_second_0:                 episode reward: 1.1500,                 loss: 0.3960
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 19241/50000 (38.4820%),                 avg. length: 588.15,                last time consumption/overall running time: 35.2626s / 33536.5360 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.3279
env0_second_0:                 episode reward: 0.5500,                 loss: 0.3725
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 19261/50000 (38.5220%),                 avg. length: 571.85,                last time consumption/overall running time: 34.2558s / 33570.7917 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2824
env0_second_0:                 episode reward: -0.1500,                 loss: 0.3712
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 19281/50000 (38.5620%),                 avg. length: 591.85,                last time consumption/overall running time: 35.1772s / 33605.9690 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.3411
env0_second_0:                 episode reward: 0.1500,                 loss: 0.3936
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 19301/50000 (38.6020%),                 avg. length: 545.2,                last time consumption/overall running time: 33.0202s / 33638.9891 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.3087
env0_second_0:                 episode reward: 0.0500,                 loss: 0.3900
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 19321/50000 (38.6420%),                 avg. length: 590.6,                last time consumption/overall running time: 35.2677s / 33674.2568 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.3481
env0_second_0:                 episode reward: 0.2500,                 loss: 0.4015
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 19341/50000 (38.6820%),                 avg. length: 551.3,                last time consumption/overall running time: 33.2017s / 33707.4585 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.3292
env0_second_0:                 episode reward: 0.2500,                 loss: 0.3764
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 19361/50000 (38.7220%),                 avg. length: 593.5,                last time consumption/overall running time: 35.4227s / 33742.8812 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.3205
env0_second_0:                 episode reward: 0.5500,                 loss: 0.3768
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 19381/50000 (38.7620%),                 avg. length: 554.75,                last time consumption/overall running time: 34.2765s / 33777.1577 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.3124
env0_second_0:                 episode reward: 0.4500,                 loss: 0.3755
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 19401/50000 (38.8020%),                 avg. length: 589.5,                last time consumption/overall running time: 35.8979s / 33813.0556 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.3390
env0_second_0:                 episode reward: 0.4000,                 loss: 0.4141
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 19421/50000 (38.8420%),                 avg. length: 563.9,                last time consumption/overall running time: 33.6950s / 33846.7506 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.3060
env0_second_0:                 episode reward: -0.5000,                 loss: 0.5559
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 19441/50000 (38.8820%),                 avg. length: 570.85,                last time consumption/overall running time: 34.1541s / 33880.9046 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.3059
env0_second_0:                 episode reward: -0.5000,                 loss: 0.3986
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 19461/50000 (38.9220%),                 avg. length: 588.9,                last time consumption/overall running time: 35.0631s / 33915.9678 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.3188
env0_second_0:                 episode reward: -0.2000,                 loss: 0.3846
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 19481/50000 (38.9620%),                 avg. length: 643.65,                last time consumption/overall running time: 38.3523s / 33954.3201 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.3336
env0_second_0:                 episode reward: 0.4500,                 loss: 0.3954
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 19501/50000 (39.0020%),                 avg. length: 604.2,                last time consumption/overall running time: 35.8069s / 33990.1270 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2869
env0_second_0:                 episode reward: -0.0500,                 loss: 0.3372
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 19521/50000 (39.0420%),                 avg. length: 572.35,                last time consumption/overall running time: 34.2897s / 34024.4167 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.3454
env0_second_0:                 episode reward: -0.5000,                 loss: 0.4387
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 19541/50000 (39.0820%),                 avg. length: 588.95,                last time consumption/overall running time: 35.2677s / 34059.6844 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.3241
env0_second_0:                 episode reward: -0.7000,                 loss: 0.3981
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 19561/50000 (39.1220%),                 avg. length: 589.75,                last time consumption/overall running time: 36.0150s / 34095.6994 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.3274
env0_second_0:                 episode reward: 0.4500,                 loss: 0.4210
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 19581/50000 (39.1620%),                 avg. length: 558.55,                last time consumption/overall running time: 33.5561s / 34129.2554 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.3064
env0_second_0:                 episode reward: -0.5500,                 loss: 0.3863
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 19601/50000 (39.2020%),                 avg. length: 566.7,                last time consumption/overall running time: 33.8799s / 34163.1353 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.3235
env0_second_0:                 episode reward: 0.8000,                 loss: 0.3778
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 19621/50000 (39.2420%),                 avg. length: 543.05,                last time consumption/overall running time: 32.6557s / 34195.7911 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.3412
env0_second_0:                 episode reward: 0.3000,                 loss: 0.4016
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 19641/50000 (39.2820%),                 avg. length: 528.55,                last time consumption/overall running time: 32.3379s / 34228.1290 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.3115
env0_second_0:                 episode reward: -0.1500,                 loss: 0.4016
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 19661/50000 (39.3220%),                 avg. length: 533.8,                last time consumption/overall running time: 32.6060s / 34260.7350 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.3275
env0_second_0:                 episode reward: -1.1500,                 loss: 0.4076
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 19681/50000 (39.3620%),                 avg. length: 561.05,                last time consumption/overall running time: 36.0084s / 34296.7434 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.3134
env0_second_0:                 episode reward: -0.1500,                 loss: 0.3784
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 19701/50000 (39.4020%),                 avg. length: 541.85,                last time consumption/overall running time: 32.6416s / 34329.3851 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.3139
env0_second_0:                 episode reward: -0.1500,                 loss: 0.3813
env1_first_0:                 episode reward: -1.8500,                 loss: nan
env1_second_0:                 episode reward: 1.8500,                 loss: nan
Episode: 19721/50000 (39.4420%),                 avg. length: 606.1,                last time consumption/overall running time: 35.9252s / 34365.3103 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.3411
env0_second_0:                 episode reward: -0.1000,                 loss: 0.3955
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 19741/50000 (39.4820%),                 avg. length: 542.9,                last time consumption/overall running time: 33.0247s / 34398.3350 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.3183
env0_second_0:                 episode reward: -1.0500,                 loss: 0.4220
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 19761/50000 (39.5220%),                 avg. length: 595.85,                last time consumption/overall running time: 35.4777s / 34433.8127 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.3272
env0_second_0:                 episode reward: -0.3000,                 loss: 0.4096
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 19781/50000 (39.5620%),                 avg. length: 575.85,                last time consumption/overall running time: 34.3969s / 34468.2096 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.3116
env0_second_0:                 episode reward: -0.1000,                 loss: 0.3875
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 19801/50000 (39.6020%),                 avg. length: 533.1,                last time consumption/overall running time: 32.2151s / 34500.4247 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.3105
env0_second_0:                 episode reward: -0.1500,                 loss: 0.3945
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 19821/50000 (39.6420%),                 avg. length: 557.8,                last time consumption/overall running time: 33.5391s / 34533.9638 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2994
env0_second_0:                 episode reward: 0.2000,                 loss: 0.3947
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 19841/50000 (39.6820%),                 avg. length: 578.15,                last time consumption/overall running time: 34.5939s / 34568.5578 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.2933
env0_second_0:                 episode reward: -1.0000,                 loss: 0.4030
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 19861/50000 (39.7220%),                 avg. length: 551.5,                last time consumption/overall running time: 34.2282s / 34602.7860 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.3130
env0_second_0:                 episode reward: -0.2500,                 loss: 0.4115
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 19881/50000 (39.7620%),                 avg. length: 598.45,                last time consumption/overall running time: 35.9619s / 34638.7479 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.3074
env0_second_0:                 episode reward: -0.4000,                 loss: 0.5190
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 19901/50000 (39.8020%),                 avg. length: 586.8,                last time consumption/overall running time: 35.7514s / 34674.4994 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.3225
env0_second_0:                 episode reward: 0.1000,                 loss: 0.4361
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 19921/50000 (39.8420%),                 avg. length: 566.05,                last time consumption/overall running time: 34.5013s / 34709.0007 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.3145
env0_second_0:                 episode reward: 1.0000,                 loss: 0.4227
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 19941/50000 (39.8820%),                 avg. length: 596.25,                last time consumption/overall running time: 36.8828s / 34745.8835 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.3105
env0_second_0:                 episode reward: -0.6000,                 loss: 0.6782
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 19961/50000 (39.9220%),                 avg. length: 584.45,                last time consumption/overall running time: 35.5210s / 34781.4045 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.3110
env0_second_0:                 episode reward: 0.3500,                 loss: 0.4584
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 19981/50000 (39.9620%),                 avg. length: 589.2,                last time consumption/overall running time: 35.2547s / 34816.6591 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2888
env0_second_0:                 episode reward: 0.1500,                 loss: 0.4792
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 20001/50000 (40.0020%),                 avg. length: 541.7,                last time consumption/overall running time: 32.8787s / 34849.5379 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.3003
env0_second_0:                 episode reward: 0.5500,                 loss: 0.4804
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 20021/50000 (40.0420%),                 avg. length: 596.2,                last time consumption/overall running time: 35.7192s / 34885.2570 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.3085
env0_second_0:                 episode reward: 0.0000,                 loss: 0.4681
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 20041/50000 (40.0820%),                 avg. length: 558.35,                last time consumption/overall running time: 34.0157s / 34919.2727 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2873
env0_second_0:                 episode reward: -0.5000,                 loss: 0.4258
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 20061/50000 (40.1220%),                 avg. length: 578.95,                last time consumption/overall running time: 34.6409s / 34953.9136 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.2953
env0_second_0:                 episode reward: -0.7500,                 loss: 0.5759
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 20081/50000 (40.1620%),                 avg. length: 559.4,                last time consumption/overall running time: 34.0689s / 34987.9825 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2961
env0_second_0:                 episode reward: 0.4000,                 loss: 0.5019
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 20101/50000 (40.2020%),                 avg. length: 606.7,                last time consumption/overall running time: 36.6081s / 35024.5906 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.3022
env0_second_0:                 episode reward: 0.1000,                 loss: 0.4932
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 20121/50000 (40.2420%),                 avg. length: 602.25,                last time consumption/overall running time: 37.3841s / 35061.9747 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2794
env0_second_0:                 episode reward: -0.3000,                 loss: 0.4575
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 20141/50000 (40.2820%),                 avg. length: 541.35,                last time consumption/overall running time: 33.0465s / 35095.0212 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2865
env0_second_0:                 episode reward: -0.1000,                 loss: 0.4756
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 20161/50000 (40.3220%),                 avg. length: 519.7,                last time consumption/overall running time: 31.9340s / 35126.9552 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2990
env0_second_0:                 episode reward: 0.5500,                 loss: 0.5066
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 20181/50000 (40.3620%),                 avg. length: 565.6,                last time consumption/overall running time: 34.3534s / 35161.3087 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.3144
env0_second_0:                 episode reward: 1.1000,                 loss: 0.5266
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 20201/50000 (40.4020%),                 avg. length: 585.8,                last time consumption/overall running time: 37.3395s / 35198.6481 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.3277
env0_second_0:                 episode reward: 0.0500,                 loss: 0.5556
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 20221/50000 (40.4420%),                 avg. length: 603.15,                last time consumption/overall running time: 36.0923s / 35234.7404 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.3383
env0_second_0:                 episode reward: 0.8000,                 loss: 0.5213
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 20241/50000 (40.4820%),                 avg. length: 512.85,                last time consumption/overall running time: 31.4603s / 35266.2007 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.3354
env0_second_0:                 episode reward: 0.2500,                 loss: 0.4568
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 20261/50000 (40.5220%),                 avg. length: 585.05,                last time consumption/overall running time: 35.2686s / 35301.4692 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.3142
env0_second_0:                 episode reward: -0.5500,                 loss: 0.4858
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 20281/50000 (40.5620%),                 avg. length: 579.35,                last time consumption/overall running time: 37.6533s / 35339.1225 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.3068
env0_second_0:                 episode reward: -0.5000,                 loss: 0.4405
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 20301/50000 (40.6020%),                 avg. length: 549.2,                last time consumption/overall running time: 34.2870s / 35373.4096 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.3119
env0_second_0:                 episode reward: -0.1000,                 loss: 0.5422
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 20321/50000 (40.6420%),                 avg. length: 592.35,                last time consumption/overall running time: 35.4947s / 35408.9043 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.3070
env0_second_0:                 episode reward: -0.7000,                 loss: 0.4490
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 20341/50000 (40.6820%),                 avg. length: 573.8,                last time consumption/overall running time: 34.6078s / 35443.5121 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.3225
env0_second_0:                 episode reward: 0.5000,                 loss: 0.4056
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
Episode: 20361/50000 (40.7220%),                 avg. length: 582.55,                last time consumption/overall running time: 35.5625s / 35479.0746 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.3282
env0_second_0:                 episode reward: 0.4500,                 loss: 0.4566
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 20381/50000 (40.7620%),                 avg. length: 553.15,                last time consumption/overall running time: 33.7954s / 35512.8701 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.3031
env0_second_0:                 episode reward: -0.1000,                 loss: 0.4800
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 20401/50000 (40.8020%),                 avg. length: 576.2,                last time consumption/overall running time: 34.8131s / 35547.6832 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.3263
env0_second_0:                 episode reward: 0.5000,                 loss: 0.4374
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 20421/50000 (40.8420%),                 avg. length: 551.75,                last time consumption/overall running time: 33.2804s / 35580.9635 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.3118
env0_second_0:                 episode reward: -0.3500,                 loss: 0.5027
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 20441/50000 (40.8820%),                 avg. length: 549.65,                last time consumption/overall running time: 33.1310s / 35614.0945 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.2973
env0_second_0:                 episode reward: 0.8500,                 loss: 0.4848
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 20461/50000 (40.9220%),                 avg. length: 580.25,                last time consumption/overall running time: 34.6277s / 35648.7223 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.3481
env0_second_0:                 episode reward: -0.2500,                 loss: 0.5081
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 20481/50000 (40.9620%),                 avg. length: 600.05,                last time consumption/overall running time: 36.1682s / 35684.8905 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.3258
env0_second_0:                 episode reward: -0.3000,                 loss: 0.4318
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 20501/50000 (41.0020%),                 avg. length: 530.75,                last time consumption/overall running time: 32.0478s / 35716.9383 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.3102
env0_second_0:                 episode reward: 0.3000,                 loss: 0.4362
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 20521/50000 (41.0420%),                 avg. length: 573.5,                last time consumption/overall running time: 34.2787s / 35751.2170 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.3380
env0_second_0:                 episode reward: 0.1000,                 loss: 0.5040
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 20541/50000 (41.0820%),                 avg. length: 538.1,                last time consumption/overall running time: 32.5677s / 35783.7847 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.3163
env0_second_0:                 episode reward: -0.2000,                 loss: 0.4721
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 20561/50000 (41.1220%),                 avg. length: 513.15,                last time consumption/overall running time: 32.3048s / 35816.0895 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.3134
env0_second_0:                 episode reward: -0.1500,                 loss: 0.4623
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 20581/50000 (41.1620%),                 avg. length: 611.05,                last time consumption/overall running time: 36.3489s / 35852.4385 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.3241
env0_second_0:                 episode reward: -0.4500,                 loss: 0.4494
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 20601/50000 (41.2020%),                 avg. length: 577.6,                last time consumption/overall running time: 34.7510s / 35887.1895 s
env0_first_0:                 episode reward: 1.6500,                 loss: 0.3005
env0_second_0:                 episode reward: -1.6500,                 loss: 0.4099
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 20621/50000 (41.2420%),                 avg. length: 600.85,                last time consumption/overall running time: 35.7171s / 35922.9066 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.3166
env0_second_0:                 episode reward: 0.7500,                 loss: 0.4375
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 20641/50000 (41.2820%),                 avg. length: 601.4,                last time consumption/overall running time: 37.1879s / 35960.0945 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2962
env0_second_0:                 episode reward: -0.5000,                 loss: 0.4351
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 20661/50000 (41.3220%),                 avg. length: 600.35,                last time consumption/overall running time: 36.9060s / 35997.0006 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2810
env0_second_0:                 episode reward: -0.6500,                 loss: 0.3903
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 20681/50000 (41.3620%),                 avg. length: 558.75,                last time consumption/overall running time: 34.7778s / 36031.7784 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.3167
env0_second_0:                 episode reward: -0.0500,                 loss: 0.4060
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 20701/50000 (41.4020%),                 avg. length: 570.7,                last time consumption/overall running time: 34.7496s / 36066.5281 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.3371
env0_second_0:                 episode reward: -0.5000,                 loss: 0.4400
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 20721/50000 (41.4420%),                 avg. length: 596.45,                last time consumption/overall running time: 35.5955s / 36102.1236 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.3309
env0_second_0:                 episode reward: -0.1000,                 loss: 0.4423
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 20741/50000 (41.4820%),                 avg. length: 571.1,                last time consumption/overall running time: 35.2358s / 36137.3593 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.3269
env0_second_0:                 episode reward: 0.8500,                 loss: 1.0004
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 20761/50000 (41.5220%),                 avg. length: 600.1,                last time consumption/overall running time: 36.0587s / 36173.4180 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.2986
env0_second_0:                 episode reward: -0.4500,                 loss: 0.5236
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 20781/50000 (41.5620%),                 avg. length: 564.55,                last time consumption/overall running time: 34.2932s / 36207.7112 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.3078
env0_second_0:                 episode reward: 0.6000,                 loss: 0.5280
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 20801/50000 (41.6020%),                 avg. length: 572.0,                last time consumption/overall running time: 34.6846s / 36242.3958 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2957
env0_second_0:                 episode reward: -0.0500,                 loss: 0.7115
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 20821/50000 (41.6420%),                 avg. length: 573.85,                last time consumption/overall running time: 34.8365s / 36277.2323 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2950
env0_second_0:                 episode reward: 0.0500,                 loss: 0.4428
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 20841/50000 (41.6820%),                 avg. length: 604.2,                last time consumption/overall running time: 36.2801s / 36313.5124 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2778
env0_second_0:                 episode reward: 0.1000,                 loss: 0.4405
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 20861/50000 (41.7220%),                 avg. length: 612.45,                last time consumption/overall running time: 36.6903s / 36350.2027 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2948
env0_second_0:                 episode reward: 0.5000,                 loss: 0.4521
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 20881/50000 (41.7620%),                 avg. length: 615.4,                last time consumption/overall running time: 37.2294s / 36387.4321 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2547
env0_second_0:                 episode reward: -0.4000,                 loss: 0.4484
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 20901/50000 (41.8020%),                 avg. length: 552.05,                last time consumption/overall running time: 33.6991s / 36421.1312 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2833
env0_second_0:                 episode reward: -0.0500,                 loss: 0.4334
env1_first_0:                 episode reward: 1.6500,                 loss: nan
env1_second_0:                 episode reward: -1.6500,                 loss: nan
Episode: 20921/50000 (41.8420%),                 avg. length: 569.75,                last time consumption/overall running time: 34.8387s / 36455.9699 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.3141
env0_second_0:                 episode reward: -0.3000,                 loss: 0.4620
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 20941/50000 (41.8820%),                 avg. length: 521.7,                last time consumption/overall running time: 32.1689s / 36488.1388 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2728
env0_second_0:                 episode reward: 0.3500,                 loss: 0.3659
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 20961/50000 (41.9220%),                 avg. length: 577.85,                last time consumption/overall running time: 35.0384s / 36523.1772 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2862
env0_second_0:                 episode reward: -0.6000,                 loss: 0.3994
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 20981/50000 (41.9620%),                 avg. length: 548.3,                last time consumption/overall running time: 33.5089s / 36556.6861 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2887
env0_second_0:                 episode reward: -0.0500,                 loss: 0.3851
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 21001/50000 (42.0020%),                 avg. length: 614.85,                last time consumption/overall running time: 36.8327s / 36593.5188 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2818
env0_second_0:                 episode reward: 0.2000,                 loss: 0.3918
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 21021/50000 (42.0420%),                 avg. length: 571.45,                last time consumption/overall running time: 35.1702s / 36628.6889 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2891
env0_second_0:                 episode reward: -0.5000,                 loss: 0.4377
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 21041/50000 (42.0820%),                 avg. length: 551.95,                last time consumption/overall running time: 33.7101s / 36662.3991 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.2876
env0_second_0:                 episode reward: -1.1500,                 loss: 0.4056
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 21061/50000 (42.1220%),                 avg. length: 561.35,                last time consumption/overall running time: 33.9322s / 36696.3313 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2851
env0_second_0:                 episode reward: 0.6500,                 loss: 0.6766
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 21081/50000 (42.1620%),                 avg. length: 601.6,                last time consumption/overall running time: 36.3491s / 36732.6804 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.3190
env0_second_0:                 episode reward: -0.6500,                 loss: 0.4867
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 21101/50000 (42.2020%),                 avg. length: 612.45,                last time consumption/overall running time: 36.5048s / 36769.1851 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2900
env0_second_0:                 episode reward: -0.2000,                 loss: 0.4649
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 21121/50000 (42.2420%),                 avg. length: 564.3,                last time consumption/overall running time: 34.9531s / 36804.1382 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2829
env0_second_0:                 episode reward: -0.3500,                 loss: 0.4310
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 21141/50000 (42.2820%),                 avg. length: 561.5,                last time consumption/overall running time: 33.8834s / 36838.0217 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2799
env0_second_0:                 episode reward: -0.6500,                 loss: 0.4715
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 21161/50000 (42.3220%),                 avg. length: 572.95,                last time consumption/overall running time: 34.9311s / 36872.9527 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2857
env0_second_0:                 episode reward: -0.4000,                 loss: 0.3824
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 21181/50000 (42.3620%),                 avg. length: 563.6,                last time consumption/overall running time: 34.7068s / 36907.6595 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.2849
env0_second_0:                 episode reward: -0.7500,                 loss: 0.4653
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 21201/50000 (42.4020%),                 avg. length: 520.0,                last time consumption/overall running time: 31.7885s / 36939.4480 s
env0_first_0:                 episode reward: -1.5000,                 loss: 0.2866
env0_second_0:                 episode reward: 1.5000,                 loss: 0.3934
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 21221/50000 (42.4420%),                 avg. length: 581.25,                last time consumption/overall running time: 34.8180s / 36974.2660 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.3385
env0_second_0:                 episode reward: 0.6500,                 loss: 0.4184
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 21241/50000 (42.4820%),                 avg. length: 573.2,                last time consumption/overall running time: 34.8714s / 37009.1374 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.3296
env0_second_0:                 episode reward: 0.1500,                 loss: 0.4300
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 21261/50000 (42.5220%),                 avg. length: 549.55,                last time consumption/overall running time: 33.2770s / 37042.4144 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2750
env0_second_0:                 episode reward: 0.0000,                 loss: 0.3533
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 21281/50000 (42.5620%),                 avg. length: 557.7,                last time consumption/overall running time: 33.6651s / 37076.0795 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.3199
env0_second_0:                 episode reward: -0.8000,                 loss: 0.3922
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 21301/50000 (42.6020%),                 avg. length: 555.35,                last time consumption/overall running time: 33.5266s / 37109.6061 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.3076
env0_second_0:                 episode reward: 1.2500,                 loss: 0.3694
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 21321/50000 (42.6420%),                 avg. length: 586.6,                last time consumption/overall running time: 35.2007s / 37144.8068 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.3057
env0_second_0:                 episode reward: 0.0500,                 loss: 0.3890
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 21341/50000 (42.6820%),                 avg. length: 548.75,                last time consumption/overall running time: 33.4179s / 37178.2247 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.2946
env0_second_0:                 episode reward: -0.9000,                 loss: 0.4057
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 21361/50000 (42.7220%),                 avg. length: 558.3,                last time consumption/overall running time: 33.6976s / 37211.9223 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2981
env0_second_0:                 episode reward: 0.1000,                 loss: 0.3693
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 21381/50000 (42.7620%),                 avg. length: 596.15,                last time consumption/overall running time: 35.6530s / 37247.5752 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.3161
env0_second_0:                 episode reward: 0.5000,                 loss: 0.4255
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 21401/50000 (42.8020%),                 avg. length: 558.75,                last time consumption/overall running time: 34.1761s / 37281.7513 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.3029
env0_second_0:                 episode reward: 0.1500,                 loss: 0.3968
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 21421/50000 (42.8420%),                 avg. length: 582.0,                last time consumption/overall running time: 35.7919s / 37317.5432 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2886
env0_second_0:                 episode reward: -0.1500,                 loss: 0.3720
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 21441/50000 (42.8820%),                 avg. length: 567.6,                last time consumption/overall running time: 34.3450s / 37351.8882 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.3280
env0_second_0:                 episode reward: -0.4000,                 loss: 0.3718
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 21461/50000 (42.9220%),                 avg. length: 584.2,                last time consumption/overall running time: 36.2716s / 37388.1599 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.3248
env0_second_0:                 episode reward: -0.0500,                 loss: 0.3783
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 21481/50000 (42.9620%),                 avg. length: 587.75,                last time consumption/overall running time: 35.6411s / 37423.8010 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.3287
env0_second_0:                 episode reward: 1.2000,                 loss: 0.3988
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 21501/50000 (43.0020%),                 avg. length: 581.8,                last time consumption/overall running time: 35.9504s / 37459.7513 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.3356
env0_second_0:                 episode reward: 0.8000,                 loss: 0.4255
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 21521/50000 (43.0420%),                 avg. length: 562.45,                last time consumption/overall running time: 33.8277s / 37493.5791 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.3288
env0_second_0:                 episode reward: -0.6000,                 loss: 0.4256
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 21541/50000 (43.0820%),                 avg. length: 602.25,                last time consumption/overall running time: 35.7601s / 37529.3392 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.3458
env0_second_0:                 episode reward: 0.1000,                 loss: 0.4733
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 21561/50000 (43.1220%),                 avg. length: 583.65,                last time consumption/overall running time: 36.6043s / 37565.9435 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.3253
env0_second_0:                 episode reward: 0.5000,                 loss: 0.3944
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 21581/50000 (43.1620%),                 avg. length: 555.8,                last time consumption/overall running time: 33.9162s / 37599.8597 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.3265
env0_second_0:                 episode reward: -0.4500,                 loss: 0.4113
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 21601/50000 (43.2020%),                 avg. length: 603.5,                last time consumption/overall running time: 35.7707s / 37635.6304 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.3270
env0_second_0:                 episode reward: 0.9000,                 loss: 0.4281
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 21621/50000 (43.2420%),                 avg. length: 549.45,                last time consumption/overall running time: 33.2078s / 37668.8382 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.3167
env0_second_0:                 episode reward: -0.1500,                 loss: 0.4490
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 21641/50000 (43.2820%),                 avg. length: 552.9,                last time consumption/overall running time: 33.2215s / 37702.0597 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.3104
env0_second_0:                 episode reward: 0.0500,                 loss: 0.4059
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 21661/50000 (43.3220%),                 avg. length: 566.15,                last time consumption/overall running time: 34.0610s / 37736.1207 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.3455
env0_second_0:                 episode reward: -0.8000,                 loss: 0.4570
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 21681/50000 (43.3620%),                 avg. length: 574.45,                last time consumption/overall running time: 34.7701s / 37770.8908 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.3230
env0_second_0:                 episode reward: 0.5500,                 loss: 0.4660
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 21701/50000 (43.4020%),                 avg. length: 569.5,                last time consumption/overall running time: 35.0654s / 37805.9562 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.3025
env0_second_0:                 episode reward: 0.2500,                 loss: 0.4437
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 21721/50000 (43.4420%),                 avg. length: 590.75,                last time consumption/overall running time: 35.3130s / 37841.2692 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.3289
env0_second_0:                 episode reward: 0.0500,                 loss: 0.9752
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 21741/50000 (43.4820%),                 avg. length: 577.6,                last time consumption/overall running time: 36.3119s / 37877.5810 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.3128
env0_second_0:                 episode reward: 0.6500,                 loss: 0.4494
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 21761/50000 (43.5220%),                 avg. length: 571.15,                last time consumption/overall running time: 37.0126s / 37914.5937 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.3126
env0_second_0:                 episode reward: -0.1000,                 loss: 0.4502
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 21781/50000 (43.5620%),                 avg. length: 527.85,                last time consumption/overall running time: 32.1473s / 37946.7410 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.3026
env0_second_0:                 episode reward: 0.6000,                 loss: 0.4133
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 21801/50000 (43.6020%),                 avg. length: 562.35,                last time consumption/overall running time: 33.9579s / 37980.6989 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.2891
env0_second_0:                 episode reward: 0.7500,                 loss: 0.4071
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 21821/50000 (43.6420%),                 avg. length: 579.15,                last time consumption/overall running time: 34.7888s / 38015.4877 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.3125
env0_second_0:                 episode reward: -0.8000,                 loss: 0.4709
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 21841/50000 (43.6820%),                 avg. length: 572.0,                last time consumption/overall running time: 34.4097s / 38049.8973 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.3234
env0_second_0:                 episode reward: -0.1500,                 loss: 0.4428
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 21861/50000 (43.7220%),                 avg. length: 590.45,                last time consumption/overall running time: 35.5984s / 38085.4957 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.3211
env0_second_0:                 episode reward: 0.0000,                 loss: 0.5024
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 21881/50000 (43.7620%),                 avg. length: 542.5,                last time consumption/overall running time: 33.7369s / 38119.2325 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.3342
env0_second_0:                 episode reward: 1.2000,                 loss: 0.4556
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 21901/50000 (43.8020%),                 avg. length: 565.25,                last time consumption/overall running time: 34.6573s / 38153.8899 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.3199
env0_second_0:                 episode reward: 0.3000,                 loss: 0.5989
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 21921/50000 (43.8420%),                 avg. length: 613.95,                last time consumption/overall running time: 36.9474s / 38190.8372 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.3143
env0_second_0:                 episode reward: 0.1500,                 loss: 0.5107
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 21941/50000 (43.8820%),                 avg. length: 534.8,                last time consumption/overall running time: 32.8665s / 38223.7037 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.3065
env0_second_0:                 episode reward: 1.2500,                 loss: 0.5032
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 21961/50000 (43.9220%),                 avg. length: 601.7,                last time consumption/overall running time: 35.9833s / 38259.6870 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.3286
env0_second_0:                 episode reward: -0.4000,                 loss: 0.4391
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 21981/50000 (43.9620%),                 avg. length: 570.95,                last time consumption/overall running time: 34.6850s / 38294.3720 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.3237
env0_second_0:                 episode reward: -0.3500,                 loss: 0.4540
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 22001/50000 (44.0020%),                 avg. length: 567.2,                last time consumption/overall running time: 34.5078s / 38328.8798 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.3310
env0_second_0:                 episode reward: 0.0000,                 loss: 0.4248
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 22021/50000 (44.0420%),                 avg. length: 529.25,                last time consumption/overall running time: 32.7794s / 38361.6591 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.3210
env0_second_0:                 episode reward: 0.4000,                 loss: 0.4474
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 22041/50000 (44.0820%),                 avg. length: 543.85,                last time consumption/overall running time: 33.2712s / 38394.9303 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.3350
env0_second_0:                 episode reward: 0.8000,                 loss: 0.4657
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 22061/50000 (44.1220%),                 avg. length: 579.9,                last time consumption/overall running time: 35.0857s / 38430.0160 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.3333
env0_second_0:                 episode reward: 1.2000,                 loss: 0.4530
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 22081/50000 (44.1620%),                 avg. length: 595.45,                last time consumption/overall running time: 35.9019s / 38465.9179 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.3297
env0_second_0:                 episode reward: 0.0000,                 loss: 0.4471
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 22101/50000 (44.2020%),                 avg. length: 567.85,                last time consumption/overall running time: 34.6897s / 38500.6076 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.3211
env0_second_0:                 episode reward: 0.8000,                 loss: 2.0686
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 22121/50000 (44.2420%),                 avg. length: 615.65,                last time consumption/overall running time: 37.0659s / 38537.6735 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.3256
env0_second_0:                 episode reward: 0.4000,                 loss: 0.6679
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 22141/50000 (44.2820%),                 avg. length: 573.25,                last time consumption/overall running time: 34.7750s / 38572.4485 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.3054
env0_second_0:                 episode reward: 0.5000,                 loss: 0.6360
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 22161/50000 (44.3220%),                 avg. length: 585.1,                last time consumption/overall running time: 35.3893s / 38607.8378 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.3028
env0_second_0:                 episode reward: 0.3000,                 loss: 0.5505
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 22181/50000 (44.3620%),                 avg. length: 590.8,                last time consumption/overall running time: 35.8533s / 38643.6911 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2898
env0_second_0:                 episode reward: 0.0000,                 loss: 0.4882
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 22201/50000 (44.4020%),                 avg. length: 578.05,                last time consumption/overall running time: 34.9746s / 38678.6657 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.2935
env0_second_0:                 episode reward: 0.8500,                 loss: 0.5239
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 22221/50000 (44.4420%),                 avg. length: 548.5,                last time consumption/overall running time: 34.1458s / 38712.8115 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.2759
env0_second_0:                 episode reward: 1.0500,                 loss: 0.4835
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 22241/50000 (44.4820%),                 avg. length: 527.65,                last time consumption/overall running time: 32.8759s / 38745.6874 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2984
env0_second_0:                 episode reward: 0.3000,                 loss: 0.4467
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 22261/50000 (44.5220%),                 avg. length: 594.95,                last time consumption/overall running time: 35.6273s / 38781.3146 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.3186
env0_second_0:                 episode reward: 0.5000,                 loss: 0.4332
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 22281/50000 (44.5620%),                 avg. length: 579.15,                last time consumption/overall running time: 34.9871s / 38816.3017 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.3099
env0_second_0:                 episode reward: 0.7000,                 loss: 0.4142
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 22301/50000 (44.6020%),                 avg. length: 533.7,                last time consumption/overall running time: 32.5745s / 38848.8762 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.2942
env0_second_0:                 episode reward: 1.1500,                 loss: 0.3816
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 22321/50000 (44.6420%),                 avg. length: 598.7,                last time consumption/overall running time: 35.9290s / 38884.8052 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.3227
env0_second_0:                 episode reward: 0.1500,                 loss: 0.4564
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 22341/50000 (44.6820%),                 avg. length: 586.65,                last time consumption/overall running time: 34.9739s / 38919.7791 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.3283
env0_second_0:                 episode reward: -0.1500,                 loss: 0.4633
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 22361/50000 (44.7220%),                 avg. length: 583.1,                last time consumption/overall running time: 34.8639s / 38954.6429 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.3019
env0_second_0:                 episode reward: 0.8500,                 loss: 0.4282
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 22381/50000 (44.7620%),                 avg. length: 556.05,                last time consumption/overall running time: 33.6151s / 38988.2580 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.3230
env0_second_0:                 episode reward: 0.4500,                 loss: 0.4118
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 22401/50000 (44.8020%),                 avg. length: 580.2,                last time consumption/overall running time: 34.8546s / 39023.1126 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.3174
env0_second_0:                 episode reward: 0.3500,                 loss: 0.4026
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 22421/50000 (44.8420%),                 avg. length: 606.9,                last time consumption/overall running time: 36.3746s / 39059.4872 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.3298
env0_second_0:                 episode reward: -0.5000,                 loss: 0.4260
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 22441/50000 (44.8820%),                 avg. length: 562.85,                last time consumption/overall running time: 34.0388s / 39093.5260 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.3242
env0_second_0:                 episode reward: 0.0000,                 loss: 0.4201
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 22461/50000 (44.9220%),                 avg. length: 529.4,                last time consumption/overall running time: 32.5677s / 39126.0937 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.3319
env0_second_0:                 episode reward: -0.3500,                 loss: 0.4202
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 22481/50000 (44.9620%),                 avg. length: 572.45,                last time consumption/overall running time: 34.4751s / 39160.5688 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.3580
env0_second_0:                 episode reward: 0.3000,                 loss: 0.4441
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 22501/50000 (45.0020%),                 avg. length: 572.6,                last time consumption/overall running time: 34.3846s / 39194.9534 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.3052
env0_second_0:                 episode reward: -0.5500,                 loss: 0.4146
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 22521/50000 (45.0420%),                 avg. length: 580.4,                last time consumption/overall running time: 34.8772s / 39229.8306 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.3124
env0_second_0:                 episode reward: -0.0500,                 loss: 0.4073
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 22541/50000 (45.0820%),                 avg. length: 588.7,                last time consumption/overall running time: 35.3408s / 39265.1714 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.3072
env0_second_0:                 episode reward: 0.1000,                 loss: 0.4210
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 22561/50000 (45.1220%),                 avg. length: 573.55,                last time consumption/overall running time: 34.7233s / 39299.8947 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.2905
env0_second_0:                 episode reward: -0.7000,                 loss: 0.4171
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 22581/50000 (45.1620%),                 avg. length: 584.7,                last time consumption/overall running time: 35.0452s / 39334.9399 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2809
env0_second_0:                 episode reward: -0.2500,                 loss: 0.4642
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 22601/50000 (45.2020%),                 avg. length: 605.15,                last time consumption/overall running time: 35.9599s / 39370.8997 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.2678
env0_second_0:                 episode reward: 0.8000,                 loss: 0.4180
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 22621/50000 (45.2420%),                 avg. length: 566.5,                last time consumption/overall running time: 34.1945s / 39405.0942 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.2865
env0_second_0:                 episode reward: 1.2500,                 loss: 0.4126
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 22641/50000 (45.2820%),                 avg. length: 581.7,                last time consumption/overall running time: 34.9538s / 39440.0480 s
env0_first_0:                 episode reward: 1.9500,                 loss: 0.2626
env0_second_0:                 episode reward: -1.9500,                 loss: 0.4409
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 22661/50000 (45.3220%),                 avg. length: 539.4,                last time consumption/overall running time: 32.7287s / 39472.7767 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2766
env0_second_0:                 episode reward: -0.5500,                 loss: 0.4894
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 22681/50000 (45.3620%),                 avg. length: 508.8,                last time consumption/overall running time: 31.2098s / 39503.9865 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.3189
env0_second_0:                 episode reward: 0.0500,                 loss: 0.5100
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 22701/50000 (45.4020%),                 avg. length: 534.0,                last time consumption/overall running time: 32.7240s / 39536.7105 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.3457
env0_second_0:                 episode reward: 1.3000,                 loss: 0.7042
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 22721/50000 (45.4420%),                 avg. length: 589.25,                last time consumption/overall running time: 37.2137s / 39573.9241 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.3194
env0_second_0:                 episode reward: -0.5500,                 loss: 0.5138
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 22741/50000 (45.4820%),                 avg. length: 554.95,                last time consumption/overall running time: 38.3116s / 39612.2358 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.3158
env0_second_0:                 episode reward: 0.6000,                 loss: 0.4703
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 22761/50000 (45.5220%),                 avg. length: 559.85,                last time consumption/overall running time: 34.1888s / 39646.4246 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2889
env0_second_0:                 episode reward: 0.3000,                 loss: 0.4635
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 22781/50000 (45.5620%),                 avg. length: 559.55,                last time consumption/overall running time: 33.6241s / 39680.0487 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.3095
env0_second_0:                 episode reward: 0.6500,                 loss: 0.4679
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 22801/50000 (45.6020%),                 avg. length: 568.7,                last time consumption/overall running time: 34.2595s / 39714.3082 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.3105
env0_second_0:                 episode reward: -0.0500,                 loss: 0.5265
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 22821/50000 (45.6420%),                 avg. length: 597.9,                last time consumption/overall running time: 36.0395s / 39750.3478 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.3104
env0_second_0:                 episode reward: 0.0500,                 loss: 0.4251
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 22841/50000 (45.6820%),                 avg. length: 587.6,                last time consumption/overall running time: 35.1711s / 39785.5188 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.3130
env0_second_0:                 episode reward: -0.0500,                 loss: 0.4839
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 22861/50000 (45.7220%),                 avg. length: 536.4,                last time consumption/overall running time: 32.5144s / 39818.0333 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.3225
env0_second_0:                 episode reward: -0.2500,                 loss: 0.4417
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 22881/50000 (45.7620%),                 avg. length: 554.65,                last time consumption/overall running time: 33.4900s / 39851.5233 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.3001
env0_second_0:                 episode reward: 0.5500,                 loss: 0.4100
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 22901/50000 (45.8020%),                 avg. length: 567.2,                last time consumption/overall running time: 34.3600s / 39885.8833 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.3204
env0_second_0:                 episode reward: -0.3500,                 loss: 0.4925
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 22921/50000 (45.8420%),                 avg. length: 551.65,                last time consumption/overall running time: 33.3398s / 39919.2232 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.3060
env0_second_0:                 episode reward: 0.0500,                 loss: 1.8695
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 22941/50000 (45.8820%),                 avg. length: 552.75,                last time consumption/overall running time: 33.4667s / 39952.6898 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.3076
env0_second_0:                 episode reward: -0.3000,                 loss: 0.5811
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 22961/50000 (45.9220%),                 avg. length: 581.2,                last time consumption/overall running time: 34.8733s / 39987.5631 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.3188
env0_second_0:                 episode reward: -0.1500,                 loss: 0.4980
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 22981/50000 (45.9620%),                 avg. length: 566.3,                last time consumption/overall running time: 34.6379s / 40022.2010 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.3091
env0_second_0:                 episode reward: 0.6000,                 loss: 0.4601
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 23001/50000 (46.0020%),                 avg. length: 610.65,                last time consumption/overall running time: 36.4643s / 40058.6653 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.3018
env0_second_0:                 episode reward: 0.2500,                 loss: 0.4579
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 23021/50000 (46.0420%),                 avg. length: 551.35,                last time consumption/overall running time: 33.5313s / 40092.1967 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.3085
env0_second_0:                 episode reward: 0.1000,                 loss: 0.4478
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 23041/50000 (46.0820%),                 avg. length: 614.5,                last time consumption/overall running time: 37.0253s / 40129.2220 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.3059
env0_second_0:                 episode reward: 0.5000,                 loss: 0.4552
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 23061/50000 (46.1220%),                 avg. length: 572.75,                last time consumption/overall running time: 34.9475s / 40164.1695 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.3006
env0_second_0:                 episode reward: 0.0500,                 loss: 0.4565
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 23081/50000 (46.1620%),                 avg. length: 543.2,                last time consumption/overall running time: 33.5592s / 40197.7287 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.3122
env0_second_0:                 episode reward: -0.7000,                 loss: 0.4648
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 23101/50000 (46.2020%),                 avg. length: 590.35,                last time consumption/overall running time: 36.1884s / 40233.9172 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.3264
env0_second_0:                 episode reward: 0.1500,                 loss: 0.4453
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 23121/50000 (46.2420%),                 avg. length: 543.7,                last time consumption/overall running time: 33.1677s / 40267.0848 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.3386
env0_second_0:                 episode reward: 0.5500,                 loss: 0.4620
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 23141/50000 (46.2820%),                 avg. length: 575.0,                last time consumption/overall running time: 34.8877s / 40301.9725 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.3239
env0_second_0:                 episode reward: 0.1500,                 loss: 0.5191
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 23161/50000 (46.3220%),                 avg. length: 549.9,                last time consumption/overall running time: 33.5656s / 40335.5381 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.3177
env0_second_0:                 episode reward: 0.8000,                 loss: 0.9504
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 23181/50000 (46.3620%),                 avg. length: 588.25,                last time consumption/overall running time: 35.2787s / 40370.8168 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2931
env0_second_0:                 episode reward: 0.2500,                 loss: 0.4299
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 23201/50000 (46.4020%),                 avg. length: 558.75,                last time consumption/overall running time: 35.0570s / 40405.8738 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.3023
env0_second_0:                 episode reward: -0.6000,                 loss: 0.5397
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 23221/50000 (46.4420%),                 avg. length: 574.2,                last time consumption/overall running time: 34.8655s / 40440.7394 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.3285
env0_second_0:                 episode reward: -0.6500,                 loss: 0.4438
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 23241/50000 (46.4820%),                 avg. length: 562.5,                last time consumption/overall running time: 34.0829s / 40474.8222 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.3205
env0_second_0:                 episode reward: 0.1000,                 loss: 0.4467
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 23261/50000 (46.5220%),                 avg. length: 614.55,                last time consumption/overall running time: 37.0976s / 40511.9199 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.3241
env0_second_0:                 episode reward: 0.8000,                 loss: 0.5104
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 23281/50000 (46.5620%),                 avg. length: 601.15,                last time consumption/overall running time: 35.8291s / 40547.7490 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.3003
env0_second_0:                 episode reward: 0.2000,                 loss: 0.3962
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 23301/50000 (46.6020%),                 avg. length: 553.6,                last time consumption/overall running time: 33.3855s / 40581.1345 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.3252
env0_second_0:                 episode reward: -0.1000,                 loss: 0.4366
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 23321/50000 (46.6420%),                 avg. length: 556.75,                last time consumption/overall running time: 33.5148s / 40614.6493 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.3000
env0_second_0:                 episode reward: -0.4000,                 loss: 0.4435
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 23341/50000 (46.6820%),                 avg. length: 594.35,                last time consumption/overall running time: 35.3640s / 40650.0133 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.3178
env0_second_0:                 episode reward: -0.7500,                 loss: 0.5314
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 23361/50000 (46.7220%),                 avg. length: 563.9,                last time consumption/overall running time: 33.8654s / 40683.8787 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.3056
env0_second_0:                 episode reward: 0.2500,                 loss: 0.4551
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 23381/50000 (46.7620%),                 avg. length: 599.85,                last time consumption/overall running time: 35.6514s / 40719.5301 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.3414
env0_second_0:                 episode reward: -0.5000,                 loss: 1.2931
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 23401/50000 (46.8020%),                 avg. length: 561.45,                last time consumption/overall running time: 33.8589s / 40753.3891 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.3096
env0_second_0:                 episode reward: -0.7000,                 loss: 0.5097
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 23421/50000 (46.8420%),                 avg. length: 547.0,                last time consumption/overall running time: 32.9763s / 40786.3654 s
env0_first_0:                 episode reward: 1.3500,                 loss: 0.3056
env0_second_0:                 episode reward: -1.3500,                 loss: 0.4918
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 23441/50000 (46.8820%),                 avg. length: 580.65,                last time consumption/overall running time: 35.0349s / 40821.4003 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.3310
env0_second_0:                 episode reward: 0.1500,                 loss: 0.5040
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 23461/50000 (46.9220%),                 avg. length: 550.0,                last time consumption/overall running time: 33.1350s / 40854.5352 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.3320
env0_second_0:                 episode reward: 0.4000,                 loss: 0.4572
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 23481/50000 (46.9620%),                 avg. length: 568.6,                last time consumption/overall running time: 34.3348s / 40888.8700 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.3157
env0_second_0:                 episode reward: 0.0000,                 loss: 0.6378
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 23501/50000 (47.0020%),                 avg. length: 540.3,                last time consumption/overall running time: 32.9303s / 40921.8003 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2949
env0_second_0:                 episode reward: 0.2500,                 loss: 0.6219
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 23521/50000 (47.0420%),                 avg. length: 632.9,                last time consumption/overall running time: 37.5992s / 40959.3995 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.3102
env0_second_0:                 episode reward: -1.1500,                 loss: 0.4787
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 23541/50000 (47.0820%),                 avg. length: 633.3,                last time consumption/overall running time: 37.5090s / 40996.9086 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.3033
env0_second_0:                 episode reward: 0.2000,                 loss: 0.4498
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 23561/50000 (47.1220%),                 avg. length: 560.85,                last time consumption/overall running time: 33.8975s / 41030.8060 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.2984
env0_second_0:                 episode reward: 0.9500,                 loss: 0.4000
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 23581/50000 (47.1620%),                 avg. length: 566.3,                last time consumption/overall running time: 34.0636s / 41064.8696 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.3545
env0_second_0:                 episode reward: 0.7500,                 loss: 0.4609
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 23601/50000 (47.2020%),                 avg. length: 527.25,                last time consumption/overall running time: 32.3877s / 41097.2573 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2964
env0_second_0:                 episode reward: 0.5000,                 loss: 0.4179
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 23621/50000 (47.2420%),                 avg. length: 618.8,                last time consumption/overall running time: 37.0461s / 41134.3034 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.3372
env0_second_0:                 episode reward: 0.2500,                 loss: 0.5507
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 23641/50000 (47.2820%),                 avg. length: 587.3,                last time consumption/overall running time: 36.6811s / 41170.9845 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.3072
env0_second_0:                 episode reward: -0.1000,                 loss: 0.4506
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 23661/50000 (47.3220%),                 avg. length: 535.05,                last time consumption/overall running time: 34.7499s / 41205.7344 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.3088
env0_second_0:                 episode reward: 1.0000,                 loss: 0.4269
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 23681/50000 (47.3620%),                 avg. length: 543.85,                last time consumption/overall running time: 33.3081s / 41239.0426 s
env0_first_0:                 episode reward: 1.6000,                 loss: 0.3279
env0_second_0:                 episode reward: -1.6000,                 loss: 0.6843
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 23701/50000 (47.4020%),                 avg. length: 546.55,                last time consumption/overall running time: 33.1729s / 41272.2155 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.3302
env0_second_0:                 episode reward: 0.5000,                 loss: 0.4915
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 23721/50000 (47.4420%),                 avg. length: 564.7,                last time consumption/overall running time: 33.8294s / 41306.0448 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.3426
env0_second_0:                 episode reward: 0.2500,                 loss: 0.4720
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 23741/50000 (47.4820%),                 avg. length: 599.05,                last time consumption/overall running time: 35.8019s / 41341.8468 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.3582
env0_second_0:                 episode reward: 1.3000,                 loss: 0.4559
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 23761/50000 (47.5220%),                 avg. length: 579.35,                last time consumption/overall running time: 34.9145s / 41376.7613 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.3550
env0_second_0:                 episode reward: 0.9000,                 loss: 0.5283
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 23781/50000 (47.5620%),                 avg. length: 565.5,                last time consumption/overall running time: 33.8090s / 41410.5703 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.3723
env0_second_0:                 episode reward: 0.1000,                 loss: 0.4838
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 23801/50000 (47.6020%),                 avg. length: 570.55,                last time consumption/overall running time: 34.0661s / 41444.6364 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.3361
env0_second_0:                 episode reward: 0.9000,                 loss: 0.4476
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 23821/50000 (47.6420%),                 avg. length: 574.8,                last time consumption/overall running time: 38.1623s / 41482.7987 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.3275
env0_second_0:                 episode reward: 0.0000,                 loss: 0.4925
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 23841/50000 (47.6820%),                 avg. length: 538.1,                last time consumption/overall running time: 35.1358s / 41517.9345 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.3123
env0_second_0:                 episode reward: -0.6500,                 loss: 0.4885
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 23861/50000 (47.7220%),                 avg. length: 568.55,                last time consumption/overall running time: 34.0580s / 41551.9925 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.3254
env0_second_0:                 episode reward: -0.8500,                 loss: 0.6854
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 23881/50000 (47.7620%),                 avg. length: 566.7,                last time consumption/overall running time: 33.8640s / 41585.8565 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.3111
env0_second_0:                 episode reward: 0.7500,                 loss: 0.4817
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 23901/50000 (47.8020%),                 avg. length: 575.05,                last time consumption/overall running time: 34.2911s / 41620.1476 s
env0_first_0:                 episode reward: 1.6000,                 loss: 0.2968
env0_second_0:                 episode reward: -1.6000,                 loss: 0.4575
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 23921/50000 (47.8420%),                 avg. length: 605.75,                last time consumption/overall running time: 35.7100s / 41655.8576 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2996
env0_second_0:                 episode reward: 0.3000,                 loss: 0.5130
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 23941/50000 (47.8820%),                 avg. length: 583.7,                last time consumption/overall running time: 35.6840s / 41691.5415 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.3148
env0_second_0:                 episode reward: 0.0500,                 loss: 0.6437
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 23961/50000 (47.9220%),                 avg. length: 565.85,                last time consumption/overall running time: 34.0294s / 41725.5709 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.2928
env0_second_0:                 episode reward: 0.9000,                 loss: 0.5121
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 23981/50000 (47.9620%),                 avg. length: 574.45,                last time consumption/overall running time: 34.0982s / 41759.6691 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.3360
env0_second_0:                 episode reward: 0.4500,                 loss: 0.4700
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 24001/50000 (48.0020%),                 avg. length: 564.95,                last time consumption/overall running time: 33.6274s / 41793.2965 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2983
env0_second_0:                 episode reward: 0.2000,                 loss: 0.4163
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 24021/50000 (48.0420%),                 avg. length: 567.55,                last time consumption/overall running time: 33.8730s / 41827.1695 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.3094
env0_second_0:                 episode reward: 0.6500,                 loss: 0.4200
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 24041/50000 (48.0820%),                 avg. length: 560.75,                last time consumption/overall running time: 33.9659s / 41861.1353 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.3139
env0_second_0:                 episode reward: -0.4000,                 loss: 0.4077
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 24061/50000 (48.1220%),                 avg. length: 572.35,                last time consumption/overall running time: 34.2679s / 41895.4032 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.3067
env0_second_0:                 episode reward: 0.7500,                 loss: 0.4474
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 24081/50000 (48.1620%),                 avg. length: 567.1,                last time consumption/overall running time: 33.9363s / 41929.3396 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.3116
env0_second_0:                 episode reward: 0.3500,                 loss: 0.4867
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 24101/50000 (48.2020%),                 avg. length: 545.8,                last time consumption/overall running time: 32.9995s / 41962.3391 s
env0_first_0:                 episode reward: -2.0500,                 loss: 0.3140
env0_second_0:                 episode reward: 2.0500,                 loss: 0.4761
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 24121/50000 (48.2420%),                 avg. length: 637.55,                last time consumption/overall running time: 37.5755s / 41999.9145 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.2941
env0_second_0:                 episode reward: 0.7000,                 loss: 0.5057
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 24141/50000 (48.2820%),                 avg. length: 616.3,                last time consumption/overall running time: 36.4880s / 42036.4025 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.2955
env0_second_0:                 episode reward: -0.8500,                 loss: 0.5029
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 24161/50000 (48.3220%),                 avg. length: 553.7,                last time consumption/overall running time: 33.0586s / 42069.4611 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.3160
env0_second_0:                 episode reward: -0.0500,                 loss: 0.4663
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 24181/50000 (48.3620%),                 avg. length: 595.05,                last time consumption/overall running time: 35.5237s / 42104.9848 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2854
env0_second_0:                 episode reward: 0.0500,                 loss: 0.5133
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 24201/50000 (48.4020%),                 avg. length: 580.35,                last time consumption/overall running time: 35.4824s / 42140.4672 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.3058
env0_second_0:                 episode reward: 0.2500,                 loss: 0.4574
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 24221/50000 (48.4420%),                 avg. length: 557.7,                last time consumption/overall running time: 34.3967s / 42174.8640 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.3048
env0_second_0:                 episode reward: -0.4500,                 loss: 0.4633
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 24241/50000 (48.4820%),                 avg. length: 527.7,                last time consumption/overall running time: 31.9011s / 42206.7651 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.2971
env0_second_0:                 episode reward: -0.8000,                 loss: 0.4602
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 24261/50000 (48.5220%),                 avg. length: 573.85,                last time consumption/overall running time: 34.3534s / 42241.1184 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.3129
env0_second_0:                 episode reward: -0.1000,                 loss: 0.4522
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 24281/50000 (48.5620%),                 avg. length: 596.9,                last time consumption/overall running time: 35.5286s / 42276.6470 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.3091
env0_second_0:                 episode reward: -0.7000,                 loss: 0.4544
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 24301/50000 (48.6020%),                 avg. length: 586.9,                last time consumption/overall running time: 35.1625s / 42311.8095 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.3009
env0_second_0:                 episode reward: 0.0500,                 loss: 0.4670
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 24321/50000 (48.6420%),                 avg. length: 572.95,                last time consumption/overall running time: 34.5729s / 42346.3824 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.3018
env0_second_0:                 episode reward: 0.3500,                 loss: 0.4543
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 24341/50000 (48.6820%),                 avg. length: 598.65,                last time consumption/overall running time: 35.4138s / 42381.7962 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.3223
env0_second_0:                 episode reward: 0.8500,                 loss: 0.4744
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 24361/50000 (48.7220%),                 avg. length: 603.0,                last time consumption/overall running time: 35.6018s / 42417.3980 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.3307
env0_second_0:                 episode reward: 0.9000,                 loss: 0.4540
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 24381/50000 (48.7620%),                 avg. length: 563.65,                last time consumption/overall running time: 33.7303s / 42451.1283 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.3234
env0_second_0:                 episode reward: 0.5000,                 loss: 0.6800
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 24401/50000 (48.8020%),                 avg. length: 592.35,                last time consumption/overall running time: 35.5031s / 42486.6314 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.3395
env0_second_0:                 episode reward: -0.5000,                 loss: 1.1437
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 24421/50000 (48.8420%),                 avg. length: 576.8,                last time consumption/overall running time: 34.4507s / 42521.0822 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.3131
env0_second_0:                 episode reward: -0.5000,                 loss: 0.5526
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 24441/50000 (48.8820%),                 avg. length: 582.8,                last time consumption/overall running time: 34.7348s / 42555.8169 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2960
env0_second_0:                 episode reward: 0.0000,                 loss: 0.4697
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 24461/50000 (48.9220%),                 avg. length: 607.15,                last time consumption/overall running time: 36.3252s / 42592.1422 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.3103
env0_second_0:                 episode reward: -0.2000,                 loss: 0.4385
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 24481/50000 (48.9620%),                 avg. length: 569.8,                last time consumption/overall running time: 34.2868s / 42626.4290 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.3042
env0_second_0:                 episode reward: 0.6000,                 loss: 0.5260
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 24501/50000 (49.0020%),                 avg. length: 573.4,                last time consumption/overall running time: 34.3517s / 42660.7806 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.3092
env0_second_0:                 episode reward: 0.5000,                 loss: 0.5430
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 24521/50000 (49.0420%),                 avg. length: 575.6,                last time consumption/overall running time: 34.5806s / 42695.3612 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.3130
env0_second_0:                 episode reward: 0.6000,                 loss: 0.5498
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 24541/50000 (49.0820%),                 avg. length: 550.6,                last time consumption/overall running time: 32.9737s / 42728.3349 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2723
env0_second_0:                 episode reward: -0.2000,                 loss: 0.4456
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 24561/50000 (49.1220%),                 avg. length: 548.75,                last time consumption/overall running time: 33.0821s / 42761.4170 s
env0_first_0:                 episode reward: 1.4500,                 loss: 0.2920
env0_second_0:                 episode reward: -1.4500,                 loss: 0.4550
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 24581/50000 (49.1620%),                 avg. length: 589.8,                last time consumption/overall running time: 36.0407s / 42797.4577 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.3022
env0_second_0:                 episode reward: -0.7000,                 loss: 0.4488
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 24601/50000 (49.2020%),                 avg. length: 559.05,                last time consumption/overall running time: 33.5570s / 42831.0147 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.3168
env0_second_0:                 episode reward: 1.1000,                 loss: 0.4827
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 24621/50000 (49.2420%),                 avg. length: 526.95,                last time consumption/overall running time: 32.1943s / 42863.2091 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.3245
env0_second_0:                 episode reward: -0.4000,                 loss: 0.4529
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 24641/50000 (49.2820%),                 avg. length: 539.15,                last time consumption/overall running time: 33.4196s / 42896.6287 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.3189
env0_second_0:                 episode reward: 0.1000,                 loss: 0.5457
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 24661/50000 (49.3220%),                 avg. length: 569.85,                last time consumption/overall running time: 34.8394s / 42931.4680 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.3298
env0_second_0:                 episode reward: -0.1000,                 loss: 0.4763
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 24681/50000 (49.3620%),                 avg. length: 585.65,                last time consumption/overall running time: 35.0040s / 42966.4721 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.3358
env0_second_0:                 episode reward: 0.3000,                 loss: 2.7794
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 24701/50000 (49.4020%),                 avg. length: 523.3,                last time consumption/overall running time: 31.9370s / 42998.4091 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2884
env0_second_0:                 episode reward: 0.6500,                 loss: 0.4643
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 24721/50000 (49.4420%),                 avg. length: 594.35,                last time consumption/overall running time: 35.2977s / 43033.7068 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.3444
env0_second_0:                 episode reward: 0.6500,                 loss: 0.5578
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 24741/50000 (49.4820%),                 avg. length: 549.4,                last time consumption/overall running time: 34.3709s / 43068.0776 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.3304
env0_second_0:                 episode reward: -0.4000,                 loss: 0.5173
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 24761/50000 (49.5220%),                 avg. length: 550.45,                last time consumption/overall running time: 33.6178s / 43101.6954 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.3217
env0_second_0:                 episode reward: -0.4500,                 loss: 0.5077
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 24781/50000 (49.5620%),                 avg. length: 585.4,                last time consumption/overall running time: 35.4586s / 43137.1540 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.3091
env0_second_0:                 episode reward: -0.5500,                 loss: 0.4434
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 24801/50000 (49.6020%),                 avg. length: 575.7,                last time consumption/overall running time: 34.5041s / 43171.6581 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.3404
env0_second_0:                 episode reward: 0.7000,                 loss: 0.6174
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 24821/50000 (49.6420%),                 avg. length: 563.4,                last time consumption/overall running time: 34.1233s / 43205.7813 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.3073
env0_second_0:                 episode reward: -0.8500,                 loss: 0.5157
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 24841/50000 (49.6820%),                 avg. length: 543.3,                last time consumption/overall running time: 34.8726s / 43240.6539 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.3330
env0_second_0:                 episode reward: 0.7000,                 loss: 0.5267
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 24861/50000 (49.7220%),                 avg. length: 587.4,                last time consumption/overall running time: 36.1821s / 43276.8361 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.3161
env0_second_0:                 episode reward: -0.4500,                 loss: 0.5476
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 24881/50000 (49.7620%),                 avg. length: 554.5,                last time consumption/overall running time: 33.5202s / 43310.3563 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2914
env0_second_0:                 episode reward: -0.0500,                 loss: 0.4778
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 24901/50000 (49.8020%),                 avg. length: 574.9,                last time consumption/overall running time: 34.5605s / 43344.9168 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2727
env0_second_0:                 episode reward: 0.3000,                 loss: 0.4690
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 24921/50000 (49.8420%),                 avg. length: 609.9,                last time consumption/overall running time: 36.2142s / 43381.1310 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2939
env0_second_0:                 episode reward: 0.6500,                 loss: 0.4794
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 24941/50000 (49.8820%),                 avg. length: 556.85,                last time consumption/overall running time: 33.5687s / 43414.6996 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.3004
env0_second_0:                 episode reward: -0.9500,                 loss: 0.5528
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 24961/50000 (49.9220%),                 avg. length: 566.75,                last time consumption/overall running time: 35.1363s / 43449.8360 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.2790
env0_second_0:                 episode reward: 1.0000,                 loss: 0.4883
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 24981/50000 (49.9620%),                 avg. length: 595.1,                last time consumption/overall running time: 35.5970s / 43485.4330 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.3119
env0_second_0:                 episode reward: -0.8500,                 loss: 0.4729
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 25001/50000 (50.0020%),                 avg. length: 564.45,                last time consumption/overall running time: 33.9858s / 43519.4187 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.3046
env0_second_0:                 episode reward: 0.7500,                 loss: 0.4007
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 25021/50000 (50.0420%),                 avg. length: 544.4,                last time consumption/overall running time: 33.4483s / 43552.8671 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.3105
env0_second_0:                 episode reward: 0.8000,                 loss: 0.4194
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 25041/50000 (50.0820%),                 avg. length: 565.75,                last time consumption/overall running time: 34.1390s / 43587.0061 s
env0_first_0:                 episode reward: -1.7000,                 loss: 0.3043
env0_second_0:                 episode reward: 1.7000,                 loss: 0.3989
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 25061/50000 (50.1220%),                 avg. length: 572.05,                last time consumption/overall running time: 34.4446s / 43621.4506 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2657
env0_second_0:                 episode reward: 0.1500,                 loss: 0.4346
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 25081/50000 (50.1620%),                 avg. length: 567.8,                last time consumption/overall running time: 34.1436s / 43655.5942 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2857
env0_second_0:                 episode reward: 0.6500,                 loss: 0.4697
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 25101/50000 (50.2020%),                 avg. length: 563.7,                last time consumption/overall running time: 33.8463s / 43689.4406 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.2815
env0_second_0:                 episode reward: 0.7500,                 loss: 0.4846
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 25121/50000 (50.2420%),                 avg. length: 577.55,                last time consumption/overall running time: 34.4827s / 43723.9233 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.3321
env0_second_0:                 episode reward: -0.2500,                 loss: 0.4942
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 25141/50000 (50.2820%),                 avg. length: 557.6,                last time consumption/overall running time: 33.9900s / 43757.9133 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2946
env0_second_0:                 episode reward: -0.0500,                 loss: 0.4354
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 25161/50000 (50.3220%),                 avg. length: 603.85,                last time consumption/overall running time: 36.5599s / 43794.4732 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2992
env0_second_0:                 episode reward: 0.3000,                 loss: 0.4696
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 25181/50000 (50.3620%),                 avg. length: 603.65,                last time consumption/overall running time: 36.7204s / 43831.1935 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.2867
env0_second_0:                 episode reward: -0.8000,                 loss: 0.5431
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 25201/50000 (50.4020%),                 avg. length: 609.35,                last time consumption/overall running time: 38.7906s / 43869.9841 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2864
env0_second_0:                 episode reward: -0.3500,                 loss: 0.4273
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 25221/50000 (50.4420%),                 avg. length: 574.25,                last time consumption/overall running time: 34.6695s / 43904.6536 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.2802
env0_second_0:                 episode reward: 0.8000,                 loss: 0.4204
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 25241/50000 (50.4820%),                 avg. length: 547.7,                last time consumption/overall running time: 32.7842s / 43937.4378 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2734
env0_second_0:                 episode reward: -0.5500,                 loss: 0.4266
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 25261/50000 (50.5220%),                 avg. length: 575.35,                last time consumption/overall running time: 34.4394s / 43971.8772 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.3059
env0_second_0:                 episode reward: 1.2000,                 loss: 0.4557
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 25281/50000 (50.5620%),                 avg. length: 592.6,                last time consumption/overall running time: 35.2772s / 44007.1545 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.3084
env0_second_0:                 episode reward: 0.5000,                 loss: 0.4373
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 25301/50000 (50.6020%),                 avg. length: 583.7,                last time consumption/overall running time: 36.6020s / 44043.7564 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.2766
env0_second_0:                 episode reward: 0.7500,                 loss: 0.4787
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 25321/50000 (50.6420%),                 avg. length: 611.7,                last time consumption/overall running time: 36.8743s / 44080.6307 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2888
env0_second_0:                 episode reward: -0.6500,                 loss: 0.4334
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 25341/50000 (50.6820%),                 avg. length: 557.2,                last time consumption/overall running time: 33.7091s / 44114.3398 s
env0_first_0:                 episode reward: -1.5000,                 loss: 0.3126
env0_second_0:                 episode reward: 1.5000,                 loss: 0.4396
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 25361/50000 (50.7220%),                 avg. length: 591.2,                last time consumption/overall running time: 35.3649s / 44149.7047 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.3093
env0_second_0:                 episode reward: 0.3500,                 loss: 0.4425
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 25381/50000 (50.7620%),                 avg. length: 580.1,                last time consumption/overall running time: 34.8566s / 44184.5613 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2968
env0_second_0:                 episode reward: 0.2000,                 loss: 0.6814
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 25401/50000 (50.8020%),                 avg. length: 605.4,                last time consumption/overall running time: 36.0463s / 44220.6076 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2969
env0_second_0:                 episode reward: 0.1000,                 loss: 0.4794
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 25421/50000 (50.8420%),                 avg. length: 561.25,                last time consumption/overall running time: 33.7806s / 44254.3882 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2968
env0_second_0:                 episode reward: -0.3500,                 loss: 0.5013
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 25441/50000 (50.8820%),                 avg. length: 573.9,                last time consumption/overall running time: 34.5403s / 44288.9284 s
env0_first_0:                 episode reward: -1.5500,                 loss: 0.3238
env0_second_0:                 episode reward: 1.5500,                 loss: 0.5104
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 25461/50000 (50.9220%),                 avg. length: 517.3,                last time consumption/overall running time: 32.0296s / 44320.9580 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.3066
env0_second_0:                 episode reward: 1.3500,                 loss: 0.4668
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 25481/50000 (50.9620%),                 avg. length: 600.2,                last time consumption/overall running time: 36.1028s / 44357.0608 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.3478
env0_second_0:                 episode reward: -0.7000,                 loss: 0.5374
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 25501/50000 (51.0020%),                 avg. length: 604.4,                last time consumption/overall running time: 36.9252s / 44393.9860 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.3093
env0_second_0:                 episode reward: -0.6000,                 loss: 0.5042
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 25521/50000 (51.0420%),                 avg. length: 568.75,                last time consumption/overall running time: 34.7006s / 44428.6865 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2954
env0_second_0:                 episode reward: 0.4000,                 loss: 0.4599
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 25541/50000 (51.0820%),                 avg. length: 551.95,                last time consumption/overall running time: 33.4025s / 44462.0890 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2856
env0_second_0:                 episode reward: 0.2000,                 loss: 0.5427
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 25561/50000 (51.1220%),                 avg. length: 565.25,                last time consumption/overall running time: 35.1667s / 44497.2558 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2732
env0_second_0:                 episode reward: 0.1500,                 loss: 0.5107
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 25581/50000 (51.1620%),                 avg. length: 539.3,                last time consumption/overall running time: 34.1025s / 44531.3582 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2951
env0_second_0:                 episode reward: -0.2500,                 loss: 0.7089
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 25601/50000 (51.2020%),                 avg. length: 584.2,                last time consumption/overall running time: 35.0682s / 44566.4265 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.3082
env0_second_0:                 episode reward: 1.1000,                 loss: 0.4368
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 25621/50000 (51.2420%),                 avg. length: 592.4,                last time consumption/overall running time: 35.3662s / 44601.7926 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2813
env0_second_0:                 episode reward: 0.1500,                 loss: 0.5243
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 25641/50000 (51.2820%),                 avg. length: 585.6,                last time consumption/overall running time: 35.4681s / 44637.2608 s
env0_first_0:                 episode reward: -1.6000,                 loss: 0.2839
env0_second_0:                 episode reward: 1.6000,                 loss: 0.5112
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 25661/50000 (51.3220%),                 avg. length: 562.6,                last time consumption/overall running time: 36.1344s / 44673.3952 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2616
env0_second_0:                 episode reward: 0.0000,                 loss: 0.5696
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 25681/50000 (51.3620%),                 avg. length: 578.35,                last time consumption/overall running time: 34.7913s / 44708.1864 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.3170
env0_second_0:                 episode reward: 0.0000,                 loss: 0.4690
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 25701/50000 (51.4020%),                 avg. length: 543.15,                last time consumption/overall running time: 32.9683s / 44741.1548 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2910
env0_second_0:                 episode reward: -0.4000,                 loss: 0.4890
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 25721/50000 (51.4420%),                 avg. length: 558.55,                last time consumption/overall running time: 33.7147s / 44774.8695 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.3196
env0_second_0:                 episode reward: -0.2500,                 loss: 0.5098
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 25741/50000 (51.4820%),                 avg. length: 576.6,                last time consumption/overall running time: 35.0655s / 44809.9350 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.3029
env0_second_0:                 episode reward: 0.1500,                 loss: 0.4562
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 25761/50000 (51.5220%),                 avg. length: 539.45,                last time consumption/overall running time: 33.1406s / 44843.0756 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2962
env0_second_0:                 episode reward: 0.0000,                 loss: 0.4464
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 25781/50000 (51.5620%),                 avg. length: 543.65,                last time consumption/overall running time: 33.2879s / 44876.3635 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.3051
env0_second_0:                 episode reward: 0.7500,                 loss: 0.7128
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 25801/50000 (51.6020%),                 avg. length: 555.25,                last time consumption/overall running time: 33.9889s / 44910.3524 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.3151
env0_second_0:                 episode reward: 1.0500,                 loss: 0.5645
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 25821/50000 (51.6420%),                 avg. length: 588.0,                last time consumption/overall running time: 35.5119s / 44945.8643 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.3085
env0_second_0:                 episode reward: 1.0500,                 loss: 0.4845
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 25841/50000 (51.6820%),                 avg. length: 580.65,                last time consumption/overall running time: 35.0942s / 44980.9585 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.3069
env0_second_0:                 episode reward: 0.2500,                 loss: 0.5276
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 25861/50000 (51.7220%),                 avg. length: 522.95,                last time consumption/overall running time: 31.8832s / 45012.8417 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.3133
env0_second_0:                 episode reward: 1.0500,                 loss: 0.5405
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 25881/50000 (51.7620%),                 avg. length: 542.0,                last time consumption/overall running time: 32.6707s / 45045.5124 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.3012
env0_second_0:                 episode reward: 1.0000,                 loss: 0.6528
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 25901/50000 (51.8020%),                 avg. length: 559.9,                last time consumption/overall running time: 34.0717s / 45079.5841 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.3287
env0_second_0:                 episode reward: -0.1500,                 loss: 1.1318
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 25921/50000 (51.8420%),                 avg. length: 536.2,                last time consumption/overall running time: 33.1115s / 45112.6956 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.3438
env0_second_0:                 episode reward: 0.1000,                 loss: 0.6019
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 25941/50000 (51.8820%),                 avg. length: 595.85,                last time consumption/overall running time: 35.5779s / 45148.2735 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.3360
env0_second_0:                 episode reward: -0.5500,                 loss: 0.5247
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 25961/50000 (51.9220%),                 avg. length: 556.3,                last time consumption/overall running time: 33.5343s / 45181.8079 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.3408
env0_second_0:                 episode reward: -0.7500,                 loss: 0.4828
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 25981/50000 (51.9620%),                 avg. length: 630.45,                last time consumption/overall running time: 37.7002s / 45219.5081 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.3196
env0_second_0:                 episode reward: -0.1000,                 loss: 0.5033
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 26001/50000 (52.0020%),                 avg. length: 552.9,                last time consumption/overall running time: 33.4391s / 45252.9472 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.3471
env0_second_0:                 episode reward: 0.7000,                 loss: 0.5319
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 26021/50000 (52.0420%),                 avg. length: 538.7,                last time consumption/overall running time: 32.7591s / 45285.7063 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.3459
env0_second_0:                 episode reward: 0.4500,                 loss: 0.4912
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 26041/50000 (52.0820%),                 avg. length: 598.2,                last time consumption/overall running time: 35.5598s / 45321.2662 s
env0_first_0:                 episode reward: 1.3500,                 loss: 0.3065
env0_second_0:                 episode reward: -1.3500,                 loss: 0.5223
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 26061/50000 (52.1220%),                 avg. length: 591.95,                last time consumption/overall running time: 35.4076s / 45356.6738 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2976
env0_second_0:                 episode reward: -0.5000,                 loss: 0.4973
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 26081/50000 (52.1620%),                 avg. length: 565.35,                last time consumption/overall running time: 34.0429s / 45390.7167 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.3245
env0_second_0:                 episode reward: -0.3000,                 loss: 0.4985
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 26101/50000 (52.2020%),                 avg. length: 602.4,                last time consumption/overall running time: 36.0019s / 45426.7186 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2986
env0_second_0:                 episode reward: -0.1000,                 loss: 0.4696
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 26121/50000 (52.2420%),                 avg. length: 535.45,                last time consumption/overall running time: 32.5153s / 45459.2339 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.3073
env0_second_0:                 episode reward: 1.4000,                 loss: 0.4577
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 26141/50000 (52.2820%),                 avg. length: 567.65,                last time consumption/overall running time: 34.1558s / 45493.3896 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.3033
env0_second_0:                 episode reward: 0.7000,                 loss: 0.4729
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 26161/50000 (52.3220%),                 avg. length: 566.15,                last time consumption/overall running time: 34.3017s / 45527.6913 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.3215
env0_second_0:                 episode reward: 0.5000,                 loss: 0.4676
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 26181/50000 (52.3620%),                 avg. length: 586.05,                last time consumption/overall running time: 35.4963s / 45563.1876 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2967
env0_second_0:                 episode reward: -0.4000,                 loss: 0.4820
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 26201/50000 (52.4020%),                 avg. length: 593.2,                last time consumption/overall running time: 35.4070s / 45598.5946 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.3167
env0_second_0:                 episode reward: 0.4000,                 loss: 0.6320
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 26221/50000 (52.4420%),                 avg. length: 612.6,                last time consumption/overall running time: 36.4834s / 45635.0780 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.3283
env0_second_0:                 episode reward: 0.0000,                 loss: 0.4769
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 26241/50000 (52.4820%),                 avg. length: 595.15,                last time consumption/overall running time: 35.8504s / 45670.9283 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.3082
env0_second_0:                 episode reward: -0.4000,                 loss: 0.4765
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 26261/50000 (52.5220%),                 avg. length: 572.8,                last time consumption/overall running time: 35.0859s / 45706.0143 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2962
env0_second_0:                 episode reward: 0.3500,                 loss: 0.4647
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 26281/50000 (52.5620%),                 avg. length: 551.6,                last time consumption/overall running time: 35.0891s / 45741.1034 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.2971
env0_second_0:                 episode reward: 0.8500,                 loss: 0.4879
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 26301/50000 (52.6020%),                 avg. length: 604.4,                last time consumption/overall running time: 35.9640s / 45777.0675 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2992
env0_second_0:                 episode reward: 0.3500,                 loss: 0.4644
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 26321/50000 (52.6420%),                 avg. length: 578.15,                last time consumption/overall running time: 34.6439s / 45811.7113 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2960
env0_second_0:                 episode reward: 0.4500,                 loss: 0.4558
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 26341/50000 (52.6820%),                 avg. length: 557.55,                last time consumption/overall running time: 33.8167s / 45845.5281 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2781
env0_second_0:                 episode reward: -0.3500,                 loss: 0.6535
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 26361/50000 (52.7220%),                 avg. length: 603.85,                last time consumption/overall running time: 36.4704s / 45881.9985 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2914
env0_second_0:                 episode reward: 0.3500,                 loss: 0.5184
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 26381/50000 (52.7620%),                 avg. length: 586.9,                last time consumption/overall running time: 35.1063s / 45917.1048 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2959
env0_second_0:                 episode reward: 0.0000,                 loss: 0.5426
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 26401/50000 (52.8020%),                 avg. length: 597.95,                last time consumption/overall running time: 35.8595s / 45952.9643 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2823
env0_second_0:                 episode reward: -0.1000,                 loss: 0.5292
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 26421/50000 (52.8420%),                 avg. length: 631.65,                last time consumption/overall running time: 37.3139s / 45990.2782 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.3034
env0_second_0:                 episode reward: 1.1000,                 loss: 0.5906
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 26441/50000 (52.8820%),                 avg. length: 572.4,                last time consumption/overall running time: 35.0155s / 46025.2937 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2987
env0_second_0:                 episode reward: 0.1000,                 loss: 1.4789
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 26461/50000 (52.9220%),                 avg. length: 565.8,                last time consumption/overall running time: 34.0232s / 46059.3170 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.3008
env0_second_0:                 episode reward: -0.2500,                 loss: 0.4640
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 26481/50000 (52.9620%),                 avg. length: 608.95,                last time consumption/overall running time: 36.2147s / 46095.5316 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.3231
env0_second_0:                 episode reward: 0.0500,                 loss: 0.4816
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 26501/50000 (53.0020%),                 avg. length: 586.1,                last time consumption/overall running time: 35.6599s / 46131.1915 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.3127
env0_second_0:                 episode reward: 1.3000,                 loss: 0.4776
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 26521/50000 (53.0420%),                 avg. length: 552.85,                last time consumption/overall running time: 33.8510s / 46165.0425 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.3232
env0_second_0:                 episode reward: 1.1000,                 loss: 0.5417
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 26541/50000 (53.0820%),                 avg. length: 550.45,                last time consumption/overall running time: 33.4147s / 46198.4572 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.3089
env0_second_0:                 episode reward: -0.3500,                 loss: 0.4864
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 26561/50000 (53.1220%),                 avg. length: 576.05,                last time consumption/overall running time: 34.4994s / 46232.9566 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.3464
env0_second_0:                 episode reward: 0.2500,                 loss: 0.5510
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 26581/50000 (53.1620%),                 avg. length: 615.1,                last time consumption/overall running time: 36.5628s / 46269.5193 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.3267
env0_second_0:                 episode reward: -0.4500,                 loss: 0.5512
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 26601/50000 (53.2020%),                 avg. length: 585.85,                last time consumption/overall running time: 34.9563s / 46304.4756 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.3293
env0_second_0:                 episode reward: 0.2000,                 loss: 0.6902
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 26621/50000 (53.2420%),                 avg. length: 581.2,                last time consumption/overall running time: 34.9016s / 46339.3772 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.3371
env0_second_0:                 episode reward: 0.4500,                 loss: 0.5330
env1_first_0:                 episode reward: -2.1000,                 loss: nan
env1_second_0:                 episode reward: 2.1000,                 loss: nan
Episode: 26641/50000 (53.2820%),                 avg. length: 633.2,                last time consumption/overall running time: 37.4384s / 46376.8156 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.3201
env0_second_0:                 episode reward: -0.9000,                 loss: 0.5772
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 26661/50000 (53.3220%),                 avg. length: 601.6,                last time consumption/overall running time: 35.8691s / 46412.6847 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.3394
env0_second_0:                 episode reward: 0.7000,                 loss: 0.6268
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 26681/50000 (53.3620%),                 avg. length: 549.35,                last time consumption/overall running time: 34.3682s / 46447.0529 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.3298
env0_second_0:                 episode reward: 1.2000,                 loss: 0.5253
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 26701/50000 (53.4020%),                 avg. length: 588.6,                last time consumption/overall running time: 37.5528s / 46484.6057 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.3636
env0_second_0:                 episode reward: 1.0000,                 loss: 0.5497
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 26721/50000 (53.4420%),                 avg. length: 586.1,                last time consumption/overall running time: 35.8570s / 46520.4627 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.3288
env0_second_0:                 episode reward: 1.0000,                 loss: 0.5219
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 26741/50000 (53.4820%),                 avg. length: 570.15,                last time consumption/overall running time: 34.9072s / 46555.3699 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.3422
env0_second_0:                 episode reward: 1.2000,                 loss: 0.6922
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 26761/50000 (53.5220%),                 avg. length: 600.1,                last time consumption/overall running time: 35.7721s / 46591.1421 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2937
env0_second_0:                 episode reward: -0.0500,                 loss: 0.6448
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 26781/50000 (53.5620%),                 avg. length: 571.85,                last time consumption/overall running time: 34.4679s / 46625.6100 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.3016
env0_second_0:                 episode reward: 0.7000,                 loss: 0.5147
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 26801/50000 (53.6020%),                 avg. length: 564.0,                last time consumption/overall running time: 34.0008s / 46659.6109 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.3108
env0_second_0:                 episode reward: 0.2500,                 loss: 1.3572
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 26821/50000 (53.6420%),                 avg. length: 561.1,                last time consumption/overall running time: 34.7121s / 46694.3230 s
env0_first_0:                 episode reward: -1.4500,                 loss: 0.2908
env0_second_0:                 episode reward: 1.4500,                 loss: 0.6691
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 26841/50000 (53.6820%),                 avg. length: 577.95,                last time consumption/overall running time: 34.9893s / 46729.3123 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.3370
env0_second_0:                 episode reward: -0.5000,                 loss: 0.7044
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 26861/50000 (53.7220%),                 avg. length: 568.6,                last time consumption/overall running time: 35.7050s / 46765.0173 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.3196
env0_second_0:                 episode reward: 0.8000,                 loss: 1.0028
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 26881/50000 (53.7620%),                 avg. length: 616.9,                last time consumption/overall running time: 38.0921s / 46803.1093 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.3212
env0_second_0:                 episode reward: 1.2500,                 loss: 0.7590
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 26901/50000 (53.8020%),                 avg. length: 614.5,                last time consumption/overall running time: 37.5090s / 46840.6183 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.3171
env0_second_0:                 episode reward: 0.7000,                 loss: 0.6222
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 26921/50000 (53.8420%),                 avg. length: 584.4,                last time consumption/overall running time: 35.3388s / 46875.9572 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.3149
env0_second_0:                 episode reward: 0.2000,                 loss: 0.5289
env1_first_0:                 episode reward: -1.6500,                 loss: nan
env1_second_0:                 episode reward: 1.6500,                 loss: nan
Episode: 26941/50000 (53.8820%),                 avg. length: 610.0,                last time consumption/overall running time: 37.1427s / 46913.0999 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.3259
env0_second_0:                 episode reward: 0.3000,                 loss: 0.5863
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 26961/50000 (53.9220%),                 avg. length: 616.7,                last time consumption/overall running time: 37.1145s / 46950.2144 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.3277
env0_second_0:                 episode reward: 1.1500,                 loss: 0.6793
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 26981/50000 (53.9620%),                 avg. length: 633.55,                last time consumption/overall running time: 37.5798s / 46987.7942 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.3525
env0_second_0:                 episode reward: 0.4000,                 loss: 0.6275
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 27001/50000 (54.0020%),                 avg. length: 589.05,                last time consumption/overall running time: 35.5738s / 47023.3680 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.3136
env0_second_0:                 episode reward: 0.9500,                 loss: 0.6021
env1_first_0:                 episode reward: -1.9500,                 loss: nan
env1_second_0:                 episode reward: 1.9500,                 loss: nan
Episode: 27021/50000 (54.0420%),                 avg. length: 577.9,                last time consumption/overall running time: 34.7247s / 47058.0927 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.3297
env0_second_0:                 episode reward: 0.7500,                 loss: 0.6268
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 27041/50000 (54.0820%),                 avg. length: 569.2,                last time consumption/overall running time: 35.0554s / 47093.1481 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.3381
env0_second_0:                 episode reward: 1.3000,                 loss: 0.8006
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 27061/50000 (54.1220%),                 avg. length: 616.7,                last time consumption/overall running time: 38.0737s / 47131.2218 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.3030
env0_second_0:                 episode reward: 0.3000,                 loss: 0.6228
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 27081/50000 (54.1620%),                 avg. length: 659.45,                last time consumption/overall running time: 39.6085s / 47170.8302 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.3332
env0_second_0:                 episode reward: 0.2000,                 loss: 1.7638
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 27101/50000 (54.2020%),                 avg. length: 603.6,                last time consumption/overall running time: 36.6646s / 47207.4948 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.3246
env0_second_0:                 episode reward: 1.2500,                 loss: 0.8148
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 27121/50000 (54.2420%),                 avg. length: 629.9,                last time consumption/overall running time: 37.5493s / 47245.0441 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.3675
env0_second_0:                 episode reward: 0.3500,                 loss: 0.8314
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 27141/50000 (54.2820%),                 avg. length: 553.1,                last time consumption/overall running time: 33.3889s / 47278.4330 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.3237
env0_second_0:                 episode reward: 1.1000,                 loss: 0.6580
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 27161/50000 (54.3220%),                 avg. length: 540.1,                last time consumption/overall running time: 32.9889s / 47311.4219 s
env0_first_0:                 episode reward: -1.6500,                 loss: 0.2979
env0_second_0:                 episode reward: 1.6500,                 loss: 0.5980
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 27181/50000 (54.3620%),                 avg. length: 614.4,                last time consumption/overall running time: 36.6634s / 47348.0853 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2901
env0_second_0:                 episode reward: 0.0500,                 loss: 0.8475
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 27201/50000 (54.4020%),                 avg. length: 566.0,                last time consumption/overall running time: 34.3840s / 47382.4693 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2968
env0_second_0:                 episode reward: 0.0500,                 loss: 1.0660
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 27221/50000 (54.4420%),                 avg. length: 549.7,                last time consumption/overall running time: 33.5406s / 47416.0099 s
env0_first_0:                 episode reward: -1.5500,                 loss: 0.2829
env0_second_0:                 episode reward: 1.5500,                 loss: 0.5902
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 27241/50000 (54.4820%),                 avg. length: 588.35,                last time consumption/overall running time: 35.3907s / 47451.4006 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.2915
env0_second_0:                 episode reward: 0.6000,                 loss: 0.4727
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 27261/50000 (54.5220%),                 avg. length: 596.5,                last time consumption/overall running time: 35.8187s / 47487.2193 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.2830
env0_second_0:                 episode reward: -0.8000,                 loss: 0.5220
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 27281/50000 (54.5620%),                 avg. length: 592.0,                last time consumption/overall running time: 35.4783s / 47522.6976 s
env0_first_0:                 episode reward: -1.4500,                 loss: 0.2682
env0_second_0:                 episode reward: 1.4500,                 loss: 0.4698
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 27301/50000 (54.6020%),                 avg. length: 581.5,                last time consumption/overall running time: 35.0811s / 47557.7787 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2882
env0_second_0:                 episode reward: 0.0000,                 loss: 0.5299
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 27321/50000 (54.6420%),                 avg. length: 633.55,                last time consumption/overall running time: 37.6452s / 47595.4239 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.3005
env0_second_0:                 episode reward: 0.1500,                 loss: 4.2554
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 27341/50000 (54.6820%),                 avg. length: 604.85,                last time consumption/overall running time: 36.3862s / 47631.8101 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2865
env0_second_0:                 episode reward: 0.2500,                 loss: 0.6357
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 27361/50000 (54.7220%),                 avg. length: 585.75,                last time consumption/overall running time: 35.2708s / 47667.0808 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2856
env0_second_0:                 episode reward: 0.6500,                 loss: 0.5556
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 27381/50000 (54.7620%),                 avg. length: 577.25,                last time consumption/overall running time: 34.9448s / 47702.0257 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.3056
env0_second_0:                 episode reward: 1.1500,                 loss: 0.6560
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 27401/50000 (54.8020%),                 avg. length: 636.15,                last time consumption/overall running time: 38.0873s / 47740.1129 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.3105
env0_second_0:                 episode reward: 0.7000,                 loss: 0.6790
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 27421/50000 (54.8420%),                 avg. length: 602.3,                last time consumption/overall running time: 37.5356s / 47777.6485 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.3408
env0_second_0:                 episode reward: 1.0000,                 loss: 0.6871
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 27441/50000 (54.8820%),                 avg. length: 576.6,                last time consumption/overall running time: 35.2950s / 47812.9435 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.3286
env0_second_0:                 episode reward: 0.9500,                 loss: 0.6060
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 27461/50000 (54.9220%),                 avg. length: 639.0,                last time consumption/overall running time: 42.0054s / 47854.9488 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.3172
env0_second_0:                 episode reward: 0.2000,                 loss: 0.6020
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 27481/50000 (54.9620%),                 avg. length: 570.95,                last time consumption/overall running time: 34.3374s / 47889.2862 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.3084
env0_second_0:                 episode reward: 0.6500,                 loss: 0.5616
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 27501/50000 (55.0020%),                 avg. length: 614.5,                last time consumption/overall running time: 36.7403s / 47926.0265 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.3060
env0_second_0:                 episode reward: 0.9500,                 loss: 0.5352
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 27521/50000 (55.0420%),                 avg. length: 636.15,                last time consumption/overall running time: 37.7517s / 47963.7782 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.3179
env0_second_0:                 episode reward: -0.1000,                 loss: 0.9226
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 27541/50000 (55.0820%),                 avg. length: 567.8,                last time consumption/overall running time: 40.1886s / 48003.9668 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.2607
env0_second_0:                 episode reward: 0.7500,                 loss: 0.5190
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 27561/50000 (55.1220%),                 avg. length: 649.8,                last time consumption/overall running time: 40.3878s / 48044.3546 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.3051
env0_second_0:                 episode reward: -0.2000,                 loss: 0.5016
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 27581/50000 (55.1620%),                 avg. length: 605.85,                last time consumption/overall running time: 36.1174s / 48080.4720 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.2934
env0_second_0:                 episode reward: 0.7500,                 loss: 0.4648
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 27601/50000 (55.2020%),                 avg. length: 567.0,                last time consumption/overall running time: 34.4412s / 48114.9132 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.2480
env0_second_0:                 episode reward: 1.2500,                 loss: 0.7224
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 27621/50000 (55.2420%),                 avg. length: 554.2,                last time consumption/overall running time: 33.8462s / 48148.7593 s
env0_first_0:                 episode reward: -1.5500,                 loss: 0.2633
env0_second_0:                 episode reward: 1.5500,                 loss: 0.4747
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 27641/50000 (55.2820%),                 avg. length: 570.75,                last time consumption/overall running time: 35.3582s / 48184.1176 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.2695
env0_second_0:                 episode reward: 1.2500,                 loss: 0.4262
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 27661/50000 (55.3220%),                 avg. length: 557.2,                last time consumption/overall running time: 35.6666s / 48219.7842 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.2889
env0_second_0:                 episode reward: 1.1000,                 loss: 0.4093
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 27681/50000 (55.3620%),                 avg. length: 600.75,                last time consumption/overall running time: 37.4229s / 48257.2071 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.3202
env0_second_0:                 episode reward: 0.4500,                 loss: 0.4586
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 27701/50000 (55.4020%),                 avg. length: 573.15,                last time consumption/overall running time: 34.7494s / 48291.9565 s
env0_first_0:                 episode reward: -1.4500,                 loss: 0.3232
env0_second_0:                 episode reward: 1.4500,                 loss: 0.4913
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 27721/50000 (55.4420%),                 avg. length: 599.7,                last time consumption/overall running time: 35.9322s / 48327.8887 s
env0_first_0:                 episode reward: -2.1500,                 loss: 0.3032
env0_second_0:                 episode reward: 2.1500,                 loss: 0.4727
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 27741/50000 (55.4820%),                 avg. length: 577.5,                last time consumption/overall running time: 34.8530s / 48362.7416 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.3186
env0_second_0:                 episode reward: 1.1500,                 loss: 0.4945
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 27761/50000 (55.5220%),                 avg. length: 573.25,                last time consumption/overall running time: 34.7249s / 48397.4666 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.2948
env0_second_0:                 episode reward: 1.1500,                 loss: 0.5545
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 27781/50000 (55.5620%),                 avg. length: 575.85,                last time consumption/overall running time: 34.6543s / 48432.1208 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.3078
env0_second_0:                 episode reward: 1.1500,                 loss: 0.4489
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 27801/50000 (55.6020%),                 avg. length: 635.35,                last time consumption/overall running time: 38.7486s / 48470.8694 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.2855
env0_second_0:                 episode reward: 0.9500,                 loss: 0.4270
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 27821/50000 (55.6420%),                 avg. length: 628.85,                last time consumption/overall running time: 37.0829s / 48507.9523 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2835
env0_second_0:                 episode reward: 0.4000,                 loss: 0.4356
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 27841/50000 (55.6820%),                 avg. length: 603.85,                last time consumption/overall running time: 35.5794s / 48543.5317 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.3210
env0_second_0:                 episode reward: 0.8500,                 loss: 0.4565
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 27861/50000 (55.7220%),                 avg. length: 576.65,                last time consumption/overall running time: 34.3489s / 48577.8807 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.3121
env0_second_0:                 episode reward: 1.0500,                 loss: 0.6180
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 27881/50000 (55.7620%),                 avg. length: 584.0,                last time consumption/overall running time: 34.9764s / 48612.8571 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.3080
env0_second_0:                 episode reward: 1.4000,                 loss: 0.5052
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 27901/50000 (55.8020%),                 avg. length: 572.05,                last time consumption/overall running time: 34.6450s / 48647.5020 s
env0_first_0:                 episode reward: -1.5500,                 loss: 0.2621
env0_second_0:                 episode reward: 1.5500,                 loss: 0.5117
env1_first_0:                 episode reward: -2.2500,                 loss: nan
env1_second_0:                 episode reward: 2.2500,                 loss: nan
Episode: 27921/50000 (55.8420%),                 avg. length: 628.85,                last time consumption/overall running time: 36.9593s / 48684.4613 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.3026
env0_second_0:                 episode reward: 1.3000,                 loss: 0.5150
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 27941/50000 (55.8820%),                 avg. length: 547.1,                last time consumption/overall running time: 32.9806s / 48717.4419 s
env0_first_0:                 episode reward: -1.7500,                 loss: 0.2778
env0_second_0:                 episode reward: 1.7500,                 loss: 0.6271
env1_first_0:                 episode reward: -2.1000,                 loss: nan
env1_second_0:                 episode reward: 2.1000,                 loss: nan
Episode: 27961/50000 (55.9220%),                 avg. length: 607.9,                last time consumption/overall running time: 36.8937s / 48754.3356 s
env0_first_0:                 episode reward: -1.8500,                 loss: 0.2867
env0_second_0:                 episode reward: 1.8500,                 loss: 0.7839
env1_first_0:                 episode reward: -1.9500,                 loss: nan
env1_second_0:                 episode reward: 1.9500,                 loss: nan
Episode: 27981/50000 (55.9620%),                 avg. length: 599.9,                last time consumption/overall running time: 36.3798s / 48790.7154 s
env0_first_0:                 episode reward: -2.0500,                 loss: 0.2509
env0_second_0:                 episode reward: 2.0500,                 loss: 0.5032
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
Episode: 28001/50000 (56.0020%),                 avg. length: 581.95,                last time consumption/overall running time: 35.2048s / 48825.9202 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.2847
env0_second_0:                 episode reward: 0.9500,                 loss: 0.5006
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 28021/50000 (56.0420%),                 avg. length: 578.75,                last time consumption/overall running time: 34.3353s / 48860.2555 s
env0_first_0:                 episode reward: -2.4500,                 loss: 0.3111
env0_second_0:                 episode reward: 2.4500,                 loss: 0.5343
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 28041/50000 (56.0820%),                 avg. length: 565.45,                last time consumption/overall running time: 34.7873s / 48895.0428 s
env0_first_0:                 episode reward: -1.9500,                 loss: 0.2890
env0_second_0:                 episode reward: 1.9500,                 loss: 0.5317
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 28061/50000 (56.1220%),                 avg. length: 551.55,                last time consumption/overall running time: 34.0309s / 48929.0738 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.3004
env0_second_0:                 episode reward: -0.1000,                 loss: 0.5022
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 28081/50000 (56.1620%),                 avg. length: 584.1,                last time consumption/overall running time: 35.4096s / 48964.4833 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.3189
env0_second_0:                 episode reward: 0.0000,                 loss: 0.5470
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 28101/50000 (56.2020%),                 avg. length: 571.45,                last time consumption/overall running time: 34.3449s / 48998.8282 s
env0_first_0:                 episode reward: -2.0000,                 loss: 0.2929
env0_second_0:                 episode reward: 2.0000,                 loss: 0.6534
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 28121/50000 (56.2420%),                 avg. length: 574.5,                last time consumption/overall running time: 34.5508s / 49033.3790 s
env0_first_0:                 episode reward: -1.7500,                 loss: 0.3272
env0_second_0:                 episode reward: 1.7500,                 loss: 0.5531
env1_first_0:                 episode reward: -2.3500,                 loss: nan
env1_second_0:                 episode reward: 2.3500,                 loss: nan
Episode: 28141/50000 (56.2820%),                 avg. length: 580.65,                last time consumption/overall running time: 39.2445s / 49072.6235 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.3189
env0_second_0:                 episode reward: 0.6000,                 loss: 0.5721
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 28161/50000 (56.3220%),                 avg. length: 583.35,                last time consumption/overall running time: 37.5960s / 49110.2195 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.3192
env0_second_0:                 episode reward: 0.6000,                 loss: 0.6011
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 28181/50000 (56.3620%),                 avg. length: 603.2,                last time consumption/overall running time: 36.8803s / 49147.0999 s
env0_first_0:                 episode reward: -1.8500,                 loss: 0.3158
env0_second_0:                 episode reward: 1.8500,                 loss: 0.5994
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 28201/50000 (56.4020%),                 avg. length: 585.15,                last time consumption/overall running time: 36.0336s / 49183.1335 s
env0_first_0:                 episode reward: -1.8000,                 loss: 0.3119
env0_second_0:                 episode reward: 1.8000,                 loss: 0.9448
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 28221/50000 (56.4420%),                 avg. length: 563.25,                last time consumption/overall running time: 34.5281s / 49217.6616 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.2875
env0_second_0:                 episode reward: 0.9500,                 loss: 1.2260
env1_first_0:                 episode reward: -2.3000,                 loss: nan
env1_second_0:                 episode reward: 2.3000,                 loss: nan
Episode: 28241/50000 (56.4820%),                 avg. length: 613.7,                last time consumption/overall running time: 36.7254s / 49254.3870 s
env0_first_0:                 episode reward: -1.8500,                 loss: 0.3134
env0_second_0:                 episode reward: 1.8500,                 loss: 0.5991
env1_first_0:                 episode reward: -2.0500,                 loss: nan
env1_second_0:                 episode reward: 2.0500,                 loss: nan
Episode: 28261/50000 (56.5220%),                 avg. length: 560.65,                last time consumption/overall running time: 34.5766s / 49288.9636 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.3153
env0_second_0:                 episode reward: 0.6000,                 loss: 0.7353
env1_first_0:                 episode reward: -2.0500,                 loss: nan
env1_second_0:                 episode reward: 2.0500,                 loss: nan
Episode: 28281/50000 (56.5620%),                 avg. length: 607.05,                last time consumption/overall running time: 35.9071s / 49324.8706 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.3141
env0_second_0:                 episode reward: 1.4000,                 loss: 0.9019
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 28301/50000 (56.6020%),                 avg. length: 634.55,                last time consumption/overall running time: 39.4111s / 49364.2817 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.3077
env0_second_0:                 episode reward: 0.8000,                 loss: 0.6698
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 28321/50000 (56.6420%),                 avg. length: 563.9,                last time consumption/overall running time: 35.9974s / 49400.2791 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.2973
env0_second_0:                 episode reward: 0.9500,                 loss: 0.6633
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 28341/50000 (56.6820%),                 avg. length: 658.3,                last time consumption/overall running time: 39.4353s / 49439.7144 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.3297
env0_second_0:                 episode reward: 0.2500,                 loss: 0.7448
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 28361/50000 (56.7220%),                 avg. length: 599.2,                last time consumption/overall running time: 35.9289s / 49475.6433 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.3107
env0_second_0:                 episode reward: 0.7000,                 loss: 0.6260
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 28381/50000 (56.7620%),                 avg. length: 644.85,                last time consumption/overall running time: 39.1701s / 49514.8134 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.3057
env0_second_0:                 episode reward: 0.8500,                 loss: 0.7323
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 28401/50000 (56.8020%),                 avg. length: 599.4,                last time consumption/overall running time: 37.1081s / 49551.9215 s
env0_first_0:                 episode reward: -1.5500,                 loss: 0.2912
env0_second_0:                 episode reward: 1.5500,                 loss: 0.6931
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 28421/50000 (56.8420%),                 avg. length: 614.0,                last time consumption/overall running time: 38.7439s / 49590.6654 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.2986
env0_second_0:                 episode reward: 0.9500,                 loss: 0.9479
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 28441/50000 (56.8820%),                 avg. length: 552.35,                last time consumption/overall running time: 33.7774s / 49624.4428 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.2958
env0_second_0:                 episode reward: 1.2000,                 loss: 0.9848
env1_first_0:                 episode reward: -2.1000,                 loss: nan
env1_second_0:                 episode reward: 2.1000,                 loss: nan
Episode: 28461/50000 (56.9220%),                 avg. length: 629.05,                last time consumption/overall running time: 38.0721s / 49662.5148 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.3108
env0_second_0:                 episode reward: 1.0000,                 loss: 0.9133
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 28481/50000 (56.9620%),                 avg. length: 603.55,                last time consumption/overall running time: 35.9900s / 49698.5048 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2764
env0_second_0:                 episode reward: 0.2000,                 loss: 0.8916
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 28501/50000 (57.0020%),                 avg. length: 644.35,                last time consumption/overall running time: 38.7639s / 49737.2687 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.3034
env0_second_0:                 episode reward: -0.1500,                 loss: 1.2274
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 28521/50000 (57.0420%),                 avg. length: 604.95,                last time consumption/overall running time: 35.8942s / 49773.1628 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.3180
env0_second_0:                 episode reward: 0.8500,                 loss: 0.9582
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
Episode: 28541/50000 (57.0820%),                 avg. length: 625.1,                last time consumption/overall running time: 37.1056s / 49810.2684 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.2996
env0_second_0:                 episode reward: 1.3000,                 loss: 0.9366
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 28561/50000 (57.1220%),                 avg. length: 591.45,                last time consumption/overall running time: 37.2378s / 49847.5062 s
env0_first_0:                 episode reward: -1.6500,                 loss: 0.2896
env0_second_0:                 episode reward: 1.6500,                 loss: 1.2375
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 28581/50000 (57.1620%),                 avg. length: 575.35,                last time consumption/overall running time: 38.8107s / 49886.3169 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.2746
env0_second_0:                 episode reward: 1.0000,                 loss: 1.1045
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 28601/50000 (57.2020%),                 avg. length: 680.7,                last time consumption/overall running time: 40.6881s / 49927.0050 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.3030
env0_second_0:                 episode reward: 0.6000,                 loss: 1.0250
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 28621/50000 (57.2420%),                 avg. length: 636.65,                last time consumption/overall running time: 38.3443s / 49965.3492 s
env0_first_0:                 episode reward: -1.5500,                 loss: 0.2906
env0_second_0:                 episode reward: 1.5500,                 loss: 1.0369
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 28641/50000 (57.2820%),                 avg. length: 634.45,                last time consumption/overall running time: 38.0330s / 50003.3822 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2994
env0_second_0:                 episode reward: 0.0500,                 loss: 1.1136
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 28661/50000 (57.3220%),                 avg. length: 661.15,                last time consumption/overall running time: 39.2460s / 50042.6282 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.2599
env0_second_0:                 episode reward: 0.7000,                 loss: 0.9799
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 28681/50000 (57.3620%),                 avg. length: 578.75,                last time consumption/overall running time: 34.8875s / 50077.5157 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.3006
env0_second_0:                 episode reward: 1.1000,                 loss: 0.9071
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 28701/50000 (57.4020%),                 avg. length: 633.1,                last time consumption/overall running time: 37.7270s / 50115.2427 s
env0_first_0:                 episode reward: -1.8500,                 loss: 0.2692
env0_second_0:                 episode reward: 1.8500,                 loss: 0.6302
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 28721/50000 (57.4420%),                 avg. length: 624.75,                last time consumption/overall running time: 37.9465s / 50153.1892 s
env0_first_0:                 episode reward: -1.9000,                 loss: 0.2578
env0_second_0:                 episode reward: 1.9000,                 loss: 0.5719
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 28741/50000 (57.4820%),                 avg. length: 666.55,                last time consumption/overall running time: 39.9418s / 50193.1310 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2637
env0_second_0:                 episode reward: 0.3000,                 loss: 0.5688
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
Episode: 28761/50000 (57.5220%),                 avg. length: 645.85,                last time consumption/overall running time: 38.4468s / 50231.5778 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.2724
env0_second_0:                 episode reward: 1.2000,                 loss: 0.5563
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 28781/50000 (57.5620%),                 avg. length: 684.65,                last time consumption/overall running time: 40.3937s / 50271.9715 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.2679
env0_second_0:                 episode reward: 0.6000,                 loss: 0.6587
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 28801/50000 (57.6020%),                 avg. length: 559.4,                last time consumption/overall running time: 35.1674s / 50307.1389 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.2643
env0_second_0:                 episode reward: 1.3500,                 loss: 0.9891
env1_first_0:                 episode reward: -1.6500,                 loss: nan
env1_second_0:                 episode reward: 1.6500,                 loss: nan
Episode: 28821/50000 (57.6420%),                 avg. length: 651.65,                last time consumption/overall running time: 38.2857s / 50345.4246 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.2820
env0_second_0:                 episode reward: 1.0000,                 loss: 0.7406
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 28841/50000 (57.6820%),                 avg. length: 593.6,                last time consumption/overall running time: 35.1567s / 50380.5813 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.2847
env0_second_0:                 episode reward: 1.0500,                 loss: 0.6443
env1_first_0:                 episode reward: -1.9500,                 loss: nan
env1_second_0:                 episode reward: 1.9500,                 loss: nan
Episode: 28861/50000 (57.7220%),                 avg. length: 651.15,                last time consumption/overall running time: 38.1513s / 50418.7327 s
env0_first_0:                 episode reward: -1.4500,                 loss: 0.2511
env0_second_0:                 episode reward: 1.4500,                 loss: 0.6441
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 28881/50000 (57.7620%),                 avg. length: 657.05,                last time consumption/overall running time: 38.5341s / 50457.2668 s
env0_first_0:                 episode reward: -1.4500,                 loss: 0.2256
env0_second_0:                 episode reward: 1.4500,                 loss: 0.5438
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 28901/50000 (57.8020%),                 avg. length: 589.9,                last time consumption/overall running time: 36.5311s / 50493.7979 s
env0_first_0:                 episode reward: -1.5500,                 loss: 0.2725
env0_second_0:                 episode reward: 1.5500,                 loss: 0.5861
env1_first_0:                 episode reward: -1.6500,                 loss: nan
env1_second_0:                 episode reward: 1.6500,                 loss: nan
Episode: 28921/50000 (57.8420%),                 avg. length: 615.05,                last time consumption/overall running time: 40.2408s / 50534.0387 s
env0_first_0:                 episode reward: -2.3000,                 loss: 0.2281
env0_second_0:                 episode reward: 2.3000,                 loss: 0.5172
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 28941/50000 (57.8820%),                 avg. length: 640.3,                last time consumption/overall running time: 38.0985s / 50572.1372 s
env0_first_0:                 episode reward: -2.1500,                 loss: 0.2517
env0_second_0:                 episode reward: 2.1500,                 loss: 0.5711
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 28961/50000 (57.9220%),                 avg. length: 621.15,                last time consumption/overall running time: 36.9793s / 50609.1165 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2733
env0_second_0:                 episode reward: 0.6500,                 loss: 0.6388
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 28981/50000 (57.9620%),                 avg. length: 615.3,                last time consumption/overall running time: 36.6225s / 50645.7391 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2279
env0_second_0:                 episode reward: 0.0000,                 loss: 0.5786
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 29001/50000 (58.0020%),                 avg. length: 608.3,                last time consumption/overall running time: 36.5812s / 50682.3203 s
env0_first_0:                 episode reward: -1.6500,                 loss: 0.2345
env0_second_0:                 episode reward: 1.6500,                 loss: 0.5719
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 29021/50000 (58.0420%),                 avg. length: 620.95,                last time consumption/overall running time: 37.1086s / 50719.4288 s
env0_first_0:                 episode reward: -1.6500,                 loss: 0.2463
env0_second_0:                 episode reward: 1.6500,                 loss: 0.6000
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 29041/50000 (58.0820%),                 avg. length: 636.85,                last time consumption/overall running time: 37.6687s / 50757.0976 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.2663
env0_second_0:                 episode reward: 1.1000,                 loss: 0.6500
env1_first_0:                 episode reward: -1.8500,                 loss: nan
env1_second_0:                 episode reward: 1.8500,                 loss: nan
Episode: 29061/50000 (58.1220%),                 avg. length: 611.4,                last time consumption/overall running time: 36.2289s / 50793.3264 s
env0_first_0:                 episode reward: -1.9000,                 loss: 0.2624
env0_second_0:                 episode reward: 1.9000,                 loss: 0.5624
env1_first_0:                 episode reward: -1.5000,                 loss: nan
env1_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 29081/50000 (58.1620%),                 avg. length: 584.5,                last time consumption/overall running time: 37.2406s / 50830.5670 s
env0_first_0:                 episode reward: -1.5000,                 loss: 0.2525
env0_second_0:                 episode reward: 1.5000,                 loss: 0.5244
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 29101/50000 (58.2020%),                 avg. length: 675.7,                last time consumption/overall running time: 40.1259s / 50870.6930 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.2544
env0_second_0:                 episode reward: 0.7000,                 loss: 0.5009
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 29121/50000 (58.2420%),                 avg. length: 642.85,                last time consumption/overall running time: 37.9340s / 50908.6270 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.2435
env0_second_0:                 episode reward: 0.9000,                 loss: 0.4653
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 29141/50000 (58.2820%),                 avg. length: 644.55,                last time consumption/overall running time: 38.2807s / 50946.9077 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.2589
env0_second_0:                 episode reward: 1.2000,                 loss: 0.4363
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 29161/50000 (58.3220%),                 avg. length: 609.45,                last time consumption/overall running time: 37.3567s / 50984.2644 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.2821
env0_second_0:                 episode reward: 1.2000,                 loss: 0.4751
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 29181/50000 (58.3620%),                 avg. length: 615.6,                last time consumption/overall running time: 37.3034s / 51021.5679 s
env0_first_0:                 episode reward: -1.7000,                 loss: 0.2289
env0_second_0:                 episode reward: 1.7000,                 loss: 0.4513
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 29201/50000 (58.4020%),                 avg. length: 616.25,                last time consumption/overall running time: 36.9913s / 51058.5591 s
env0_first_0:                 episode reward: -2.3500,                 loss: 0.2479
env0_second_0:                 episode reward: 2.3500,                 loss: 0.6244
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 29221/50000 (58.4420%),                 avg. length: 634.0,                last time consumption/overall running time: 39.6965s / 51098.2556 s
env0_first_0:                 episode reward: -1.9000,                 loss: 0.2587
env0_second_0:                 episode reward: 1.9000,                 loss: 0.4685
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 29241/50000 (58.4820%),                 avg. length: 670.55,                last time consumption/overall running time: 40.0336s / 51138.2892 s
env0_first_0:                 episode reward: -1.4500,                 loss: 0.2596
env0_second_0:                 episode reward: 1.4500,                 loss: 0.5055
env1_first_0:                 episode reward: -1.6500,                 loss: nan
env1_second_0:                 episode reward: 1.6500,                 loss: nan
Episode: 29261/50000 (58.5220%),                 avg. length: 670.1,                last time consumption/overall running time: 39.4587s / 51177.7479 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.2426
env0_second_0:                 episode reward: 1.3500,                 loss: 0.5113
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 29281/50000 (58.5620%),                 avg. length: 559.85,                last time consumption/overall running time: 34.3878s / 51212.1356 s
env0_first_0:                 episode reward: -2.3500,                 loss: 0.2564
env0_second_0:                 episode reward: 2.3500,                 loss: 0.5140
env1_first_0:                 episode reward: -1.5000,                 loss: nan
env1_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 29301/50000 (58.6020%),                 avg. length: 621.15,                last time consumption/overall running time: 40.3582s / 51252.4938 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.2570
env0_second_0:                 episode reward: 0.8000,                 loss: 0.5334
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
Episode: 29321/50000 (58.6420%),                 avg. length: 606.55,                last time consumption/overall running time: 36.2235s / 51288.7174 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.2698
env0_second_0:                 episode reward: 0.8000,                 loss: 0.4964
env1_first_0:                 episode reward: -1.9000,                 loss: nan
env1_second_0:                 episode reward: 1.9000,                 loss: nan
Episode: 29341/50000 (58.6820%),                 avg. length: 644.35,                last time consumption/overall running time: 38.0445s / 51326.7619 s
env0_first_0:                 episode reward: -1.6000,                 loss: 0.2671
env0_second_0:                 episode reward: 1.6000,                 loss: 0.4516
env1_first_0:                 episode reward: -1.8500,                 loss: nan
env1_second_0:                 episode reward: 1.8500,                 loss: nan
Episode: 29361/50000 (58.7220%),                 avg. length: 589.7,                last time consumption/overall running time: 36.1021s / 51362.8640 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.2758
env0_second_0:                 episode reward: 1.1000,                 loss: 0.4757
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 29381/50000 (58.7620%),                 avg. length: 675.3,                last time consumption/overall running time: 39.7371s / 51402.6011 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2560
env0_second_0:                 episode reward: 0.1500,                 loss: 0.4817
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 29401/50000 (58.8020%),                 avg. length: 639.1,                last time consumption/overall running time: 37.6942s / 51440.2953 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.2853
env0_second_0:                 episode reward: 1.2500,                 loss: 0.6514
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 29421/50000 (58.8420%),                 avg. length: 638.3,                last time consumption/overall running time: 38.0827s / 51478.3780 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.2816
env0_second_0:                 episode reward: 1.2000,                 loss: 0.4961
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 29441/50000 (58.8820%),                 avg. length: 625.25,                last time consumption/overall running time: 37.2588s / 51515.6369 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.2807
env0_second_0:                 episode reward: 0.9500,                 loss: 0.5386
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 29461/50000 (58.9220%),                 avg. length: 645.45,                last time consumption/overall running time: 40.8089s / 51556.4457 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.2500
env0_second_0:                 episode reward: 1.1500,                 loss: 0.4814
env1_first_0:                 episode reward: -1.6500,                 loss: nan
env1_second_0:                 episode reward: 1.6500,                 loss: nan
Episode: 29481/50000 (58.9620%),                 avg. length: 639.65,                last time consumption/overall running time: 39.0869s / 51595.5326 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.2720
env0_second_0:                 episode reward: 1.2500,                 loss: 0.5077
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 29501/50000 (59.0020%),                 avg. length: 647.05,                last time consumption/overall running time: 39.0267s / 51634.5593 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.2292
env0_second_0:                 episode reward: 0.8000,                 loss: 0.5136
env1_first_0:                 episode reward: -2.4500,                 loss: nan
env1_second_0:                 episode reward: 2.4500,                 loss: nan
Episode: 29521/50000 (59.0420%),                 avg. length: 615.6,                last time consumption/overall running time: 36.4879s / 51671.0472 s
env0_first_0:                 episode reward: -1.6500,                 loss: 0.2556
env0_second_0:                 episode reward: 1.6500,                 loss: 0.4875
env1_first_0:                 episode reward: -1.8000,                 loss: nan
env1_second_0:                 episode reward: 1.8000,                 loss: nan
Episode: 29541/50000 (59.0820%),                 avg. length: 647.45,                last time consumption/overall running time: 40.7493s / 51711.7965 s
env0_first_0:                 episode reward: -1.4500,                 loss: 0.2610
env0_second_0:                 episode reward: 1.4500,                 loss: 0.4982
env1_first_0:                 episode reward: -1.5000,                 loss: nan
env1_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 29561/50000 (59.1220%),                 avg. length: 611.35,                last time consumption/overall running time: 37.0111s / 51748.8076 s
env0_first_0:                 episode reward: -1.9500,                 loss: 0.2447
env0_second_0:                 episode reward: 1.9500,                 loss: 0.3657
env1_first_0:                 episode reward: -1.5000,                 loss: nan
env1_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 29581/50000 (59.1620%),                 avg. length: 643.8,                last time consumption/overall running time: 38.1414s / 51786.9490 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.2408
env0_second_0:                 episode reward: 1.3500,                 loss: 0.4273
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 29601/50000 (59.2020%),                 avg. length: 636.9,                last time consumption/overall running time: 39.3469s / 51826.2960 s
env0_first_0:                 episode reward: -1.5000,                 loss: 0.2455
env0_second_0:                 episode reward: 1.5000,                 loss: 0.3923
env1_first_0:                 episode reward: -1.8500,                 loss: nan
env1_second_0:                 episode reward: 1.8500,                 loss: nan
Episode: 29621/50000 (59.2420%),                 avg. length: 624.3,                last time consumption/overall running time: 37.7614s / 51864.0574 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.2852
env0_second_0:                 episode reward: 1.2500,                 loss: 0.5666
env1_first_0:                 episode reward: -1.5000,                 loss: nan
env1_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 29641/50000 (59.2820%),                 avg. length: 648.25,                last time consumption/overall running time: 40.3688s / 51904.4261 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.2330
env0_second_0:                 episode reward: 1.2000,                 loss: 0.6417
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 29661/50000 (59.3220%),                 avg. length: 563.2,                last time consumption/overall running time: 34.6977s / 51939.1239 s
env0_first_0:                 episode reward: -1.8000,                 loss: 0.2501
env0_second_0:                 episode reward: 1.8000,                 loss: 0.5229
env1_first_0:                 episode reward: -2.7000,                 loss: nan
env1_second_0:                 episode reward: 2.7000,                 loss: nan
Episode: 29681/50000 (59.3620%),                 avg. length: 607.65,                last time consumption/overall running time: 36.2386s / 51975.3624 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.2382
env0_second_0:                 episode reward: 1.1500,                 loss: 0.4243
env1_first_0:                 episode reward: -1.5000,                 loss: nan
env1_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 29701/50000 (59.4020%),                 avg. length: 619.35,                last time consumption/overall running time: 36.9339s / 52012.2963 s
env0_first_0:                 episode reward: -1.8000,                 loss: 0.2406
env0_second_0:                 episode reward: 1.8000,                 loss: 0.3945
env1_first_0:                 episode reward: -1.8000,                 loss: nan
env1_second_0:                 episode reward: 1.8000,                 loss: nan
Episode: 29721/50000 (59.4420%),                 avg. length: 640.3,                last time consumption/overall running time: 39.6639s / 52051.9602 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.2313
env0_second_0:                 episode reward: 1.2500,                 loss: 0.3956
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 29741/50000 (59.4820%),                 avg. length: 620.45,                last time consumption/overall running time: 37.5488s / 52089.5089 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.2294
env0_second_0:                 episode reward: 0.9500,                 loss: 0.3956
env1_first_0:                 episode reward: -1.5000,                 loss: nan
env1_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 29761/50000 (59.5220%),                 avg. length: 648.2,                last time consumption/overall running time: 38.2009s / 52127.7098 s
env0_first_0:                 episode reward: -1.6000,                 loss: 0.2292
env0_second_0:                 episode reward: 1.6000,                 loss: 0.4426
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 29781/50000 (59.5620%),                 avg. length: 612.4,                last time consumption/overall running time: 37.4730s / 52165.1828 s
env0_first_0:                 episode reward: -1.5500,                 loss: 0.2213
env0_second_0:                 episode reward: 1.5500,                 loss: 0.3920
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
Episode: 29801/50000 (59.6020%),                 avg. length: 601.55,                last time consumption/overall running time: 37.8409s / 52203.0238 s
env0_first_0:                 episode reward: -1.8500,                 loss: 0.2572
env0_second_0:                 episode reward: 1.8500,                 loss: 0.4268
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 29821/50000 (59.6420%),                 avg. length: 625.95,                last time consumption/overall running time: 37.2496s / 52240.2733 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.2422
env0_second_0:                 episode reward: 1.3500,                 loss: 0.3603
env1_first_0:                 episode reward: -2.0000,                 loss: nan
env1_second_0:                 episode reward: 2.0000,                 loss: nan
Episode: 29841/50000 (59.6820%),                 avg. length: 608.65,                last time consumption/overall running time: 36.1236s / 52276.3969 s
env0_first_0:                 episode reward: -1.4500,                 loss: 0.2229
env0_second_0:                 episode reward: 1.4500,                 loss: 0.4005
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 29861/50000 (59.7220%),                 avg. length: 640.4,                last time consumption/overall running time: 38.7979s / 52315.1949 s
env0_first_0:                 episode reward: -1.8000,                 loss: 0.2302
env0_second_0:                 episode reward: 1.8000,                 loss: 0.4263
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 29881/50000 (59.7620%),                 avg. length: 667.45,                last time consumption/overall running time: 39.6256s / 52354.8205 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.2518
env0_second_0:                 episode reward: 1.1500,                 loss: 0.4480
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 29901/50000 (59.8020%),                 avg. length: 583.65,                last time consumption/overall running time: 34.7466s / 52389.5671 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.2361
env0_second_0:                 episode reward: 1.2000,                 loss: 0.4286
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 29921/50000 (59.8420%),                 avg. length: 612.35,                last time consumption/overall running time: 36.3992s / 52425.9663 s
env0_first_0:                 episode reward: -1.4500,                 loss: 0.2560
env0_second_0:                 episode reward: 1.4500,                 loss: 0.4719
env1_first_0:                 episode reward: -2.0500,                 loss: nan
env1_second_0:                 episode reward: 2.0500,                 loss: nan
Episode: 29941/50000 (59.8820%),                 avg. length: 620.8,                last time consumption/overall running time: 37.3050s / 52463.2713 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.2802
env0_second_0:                 episode reward: 1.2500,                 loss: 1.9540
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 29961/50000 (59.9220%),                 avg. length: 578.95,                last time consumption/overall running time: 34.7667s / 52498.0380 s
env0_first_0:                 episode reward: -1.8000,                 loss: 0.2368
env0_second_0:                 episode reward: 1.8000,                 loss: 0.4856
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 29981/50000 (59.9620%),                 avg. length: 646.1,                last time consumption/overall running time: 37.9678s / 52536.0058 s
env0_first_0:                 episode reward: -2.2500,                 loss: 0.2569
env0_second_0:                 episode reward: 2.2500,                 loss: 0.4769
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 30001/50000 (60.0020%),                 avg. length: 619.45,                last time consumption/overall running time: 36.6786s / 52572.6844 s
env0_first_0:                 episode reward: -1.9500,                 loss: 0.2437
env0_second_0:                 episode reward: 1.9500,                 loss: 0.4260
env1_first_0:                 episode reward: -1.5000,                 loss: nan
env1_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 30021/50000 (60.0420%),                 avg. length: 634.45,                last time consumption/overall running time: 37.5369s / 52610.2214 s
env0_first_0:                 episode reward: -1.5500,                 loss: 0.2432
env0_second_0:                 episode reward: 1.5500,                 loss: 0.4470
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 30041/50000 (60.0820%),                 avg. length: 652.2,                last time consumption/overall running time: 39.2413s / 52649.4626 s
env0_first_0:                 episode reward: -1.4500,                 loss: 0.2505
env0_second_0:                 episode reward: 1.4500,                 loss: 0.4704
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 30061/50000 (60.1220%),                 avg. length: 620.25,                last time consumption/overall running time: 37.2712s / 52686.7338 s
env0_first_0:                 episode reward: -1.5000,                 loss: 0.2403
env0_second_0:                 episode reward: 1.5000,                 loss: 0.4236
env1_first_0:                 episode reward: -1.9000,                 loss: nan
env1_second_0:                 episode reward: 1.9000,                 loss: nan
Episode: 30081/50000 (60.1620%),                 avg. length: 623.0,                last time consumption/overall running time: 36.6448s / 52723.3787 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2343
env0_second_0:                 episode reward: 0.3500,                 loss: 0.4416
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 30101/50000 (60.2020%),                 avg. length: 608.8,                last time consumption/overall running time: 36.2454s / 52759.6241 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2422
env0_second_0:                 episode reward: 0.5500,                 loss: 0.4388
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 30121/50000 (60.2420%),                 avg. length: 566.4,                last time consumption/overall running time: 34.0193s / 52793.6435 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.2390
env0_second_0:                 episode reward: 0.9000,                 loss: 0.4566
env1_first_0:                 episode reward: -2.2500,                 loss: nan
env1_second_0:                 episode reward: 2.2500,                 loss: nan
Episode: 30141/50000 (60.2820%),                 avg. length: 610.95,                last time consumption/overall running time: 36.5293s / 52830.1728 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.2568
env0_second_0:                 episode reward: 1.1500,                 loss: 0.4461
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 30161/50000 (60.3220%),                 avg. length: 678.95,                last time consumption/overall running time: 39.6161s / 52869.7889 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2689
env0_second_0:                 episode reward: 0.6500,                 loss: 0.4147
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 30181/50000 (60.3620%),                 avg. length: 649.15,                last time consumption/overall running time: 37.9950s / 52907.7839 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.2574
env0_second_0:                 episode reward: 1.1500,                 loss: 0.3886
env1_first_0:                 episode reward: -2.2000,                 loss: nan
env1_second_0:                 episode reward: 2.2000,                 loss: nan
Episode: 30201/50000 (60.4020%),                 avg. length: 634.45,                last time consumption/overall running time: 38.1089s / 52945.8928 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.2298
env0_second_0:                 episode reward: 1.0500,                 loss: 0.4027
env1_first_0:                 episode reward: -1.5000,                 loss: nan
env1_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 30221/50000 (60.4420%),                 avg. length: 629.25,                last time consumption/overall running time: 36.9843s / 52982.8771 s
env0_first_0:                 episode reward: -2.0000,                 loss: 0.2322
env0_second_0:                 episode reward: 2.0000,                 loss: 0.4046
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 30241/50000 (60.4820%),                 avg. length: 620.7,                last time consumption/overall running time: 36.5672s / 53019.4443 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.2481
env0_second_0:                 episode reward: 1.3000,                 loss: 0.4155
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 30261/50000 (60.5220%),                 avg. length: 597.1,                last time consumption/overall running time: 36.0068s / 53055.4511 s
env0_first_0:                 episode reward: -1.8500,                 loss: 0.2412
env0_second_0:                 episode reward: 1.8500,                 loss: 0.3809
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 30281/50000 (60.5620%),                 avg. length: 585.25,                last time consumption/overall running time: 35.8604s / 53091.3115 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.2376
env0_second_0:                 episode reward: 1.3000,                 loss: 0.3811
env1_first_0:                 episode reward: -2.6000,                 loss: nan
env1_second_0:                 episode reward: 2.6000,                 loss: nan
Episode: 30301/50000 (60.6020%),                 avg. length: 583.7,                last time consumption/overall running time: 35.8814s / 53127.1929 s
env0_first_0:                 episode reward: -1.6000,                 loss: 0.2614
env0_second_0:                 episode reward: 1.6000,                 loss: 0.4256
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 30321/50000 (60.6420%),                 avg. length: 661.05,                last time consumption/overall running time: 40.0657s / 53167.2585 s
env0_first_0:                 episode reward: -1.4500,                 loss: 0.2461
env0_second_0:                 episode reward: 1.4500,                 loss: 0.4654
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 30341/50000 (60.6820%),                 avg. length: 605.45,                last time consumption/overall running time: 36.0202s / 53203.2788 s
env0_first_0:                 episode reward: -1.9500,                 loss: 0.2339
env0_second_0:                 episode reward: 1.9500,                 loss: 0.4254
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 30361/50000 (60.7220%),                 avg. length: 666.5,                last time consumption/overall running time: 39.0760s / 53242.3548 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.2461
env0_second_0:                 episode reward: 1.2500,                 loss: 0.4135
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 30381/50000 (60.7620%),                 avg. length: 655.5,                last time consumption/overall running time: 39.1025s / 53281.4573 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.2358
env0_second_0:                 episode reward: 1.0000,                 loss: 0.3998
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 30401/50000 (60.8020%),                 avg. length: 588.15,                last time consumption/overall running time: 35.4913s / 53316.9486 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.2297
env0_second_0:                 episode reward: 1.2000,                 loss: 0.4859
env1_first_0:                 episode reward: -2.9000,                 loss: nan
env1_second_0:                 episode reward: 2.9000,                 loss: nan
Episode: 30421/50000 (60.8420%),                 avg. length: 600.0,                last time consumption/overall running time: 35.8575s / 53352.8062 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.2623
env0_second_0:                 episode reward: 1.1500,                 loss: 0.4557
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 30441/50000 (60.8820%),                 avg. length: 599.4,                last time consumption/overall running time: 37.0832s / 53389.8893 s
env0_first_0:                 episode reward: -1.5000,                 loss: 0.2409
env0_second_0:                 episode reward: 1.5000,                 loss: 0.4890
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 30461/50000 (60.9220%),                 avg. length: 597.9,                last time consumption/overall running time: 37.5438s / 53427.4331 s
env0_first_0:                 episode reward: -1.5500,                 loss: 0.2583
env0_second_0:                 episode reward: 1.5500,                 loss: 0.4755
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 30481/50000 (60.9620%),                 avg. length: 614.0,                last time consumption/overall running time: 38.3843s / 53465.8174 s
env0_first_0:                 episode reward: -1.6000,                 loss: 0.2483
env0_second_0:                 episode reward: 1.6000,                 loss: 0.4378
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 30501/50000 (61.0020%),                 avg. length: 553.05,                last time consumption/overall running time: 33.4657s / 53499.2831 s
env0_first_0:                 episode reward: -2.2500,                 loss: 0.2218
env0_second_0:                 episode reward: 2.2500,                 loss: 0.3837
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 30521/50000 (61.0420%),                 avg. length: 577.7,                last time consumption/overall running time: 34.6197s / 53533.9028 s
env0_first_0:                 episode reward: -2.0500,                 loss: 0.2593
env0_second_0:                 episode reward: 2.0500,                 loss: 0.4615
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 30541/50000 (61.0820%),                 avg. length: 620.65,                last time consumption/overall running time: 36.8708s / 53570.7737 s
env0_first_0:                 episode reward: -1.6000,                 loss: 0.2329
env0_second_0:                 episode reward: 1.6000,                 loss: 0.4380
env1_first_0:                 episode reward: -1.5000,                 loss: nan
env1_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 30561/50000 (61.1220%),                 avg. length: 626.6,                last time consumption/overall running time: 37.2378s / 53608.0115 s
env0_first_0:                 episode reward: -2.1500,                 loss: 0.2424
env0_second_0:                 episode reward: 2.1500,                 loss: 0.5196
env1_first_0:                 episode reward: -2.1000,                 loss: nan
env1_second_0:                 episode reward: 2.1000,                 loss: nan
Episode: 30581/50000 (61.1620%),                 avg. length: 637.45,                last time consumption/overall running time: 37.6222s / 53645.6337 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.2435
env0_second_0:                 episode reward: 1.0500,                 loss: 0.4932
env1_first_0:                 episode reward: -2.0000,                 loss: nan
env1_second_0:                 episode reward: 2.0000,                 loss: nan
Episode: 30601/50000 (61.2020%),                 avg. length: 600.05,                last time consumption/overall running time: 36.0346s / 53681.6682 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.2112
env0_second_0:                 episode reward: 0.8500,                 loss: 0.4567
env1_first_0:                 episode reward: -2.1000,                 loss: nan
env1_second_0:                 episode reward: 2.1000,                 loss: nan
Episode: 30621/50000 (61.2420%),                 avg. length: 587.4,                last time consumption/overall running time: 35.3613s / 53717.0295 s
env0_first_0:                 episode reward: -2.5500,                 loss: 0.2372
env0_second_0:                 episode reward: 2.5500,                 loss: 0.4521
env1_first_0:                 episode reward: -2.2500,                 loss: nan
env1_second_0:                 episode reward: 2.2500,                 loss: nan
Episode: 30641/50000 (61.2820%),                 avg. length: 596.65,                last time consumption/overall running time: 35.7509s / 53752.7804 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.2191
env0_second_0:                 episode reward: 1.4000,                 loss: 0.4214
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 30661/50000 (61.3220%),                 avg. length: 624.8,                last time consumption/overall running time: 37.8918s / 53790.6722 s
env0_first_0:                 episode reward: -2.2500,                 loss: 0.2167
env0_second_0:                 episode reward: 2.2500,                 loss: 0.4092
env1_first_0:                 episode reward: -1.5000,                 loss: nan
env1_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 30681/50000 (61.3620%),                 avg. length: 578.4,                last time consumption/overall running time: 35.2313s / 53825.9035 s
env0_first_0:                 episode reward: -2.3500,                 loss: 0.2091
env0_second_0:                 episode reward: 2.3500,                 loss: 0.3913
env1_first_0:                 episode reward: -2.0000,                 loss: nan
env1_second_0:                 episode reward: 2.0000,                 loss: nan
Episode: 30701/50000 (61.4020%),                 avg. length: 618.85,                last time consumption/overall running time: 37.1436s / 53863.0471 s
env0_first_0:                 episode reward: -2.4500,                 loss: 0.2712
env0_second_0:                 episode reward: 2.4500,                 loss: 0.4941
env1_first_0:                 episode reward: -1.9000,                 loss: nan
env1_second_0:                 episode reward: 1.9000,                 loss: nan
Episode: 30721/50000 (61.4420%),                 avg. length: 557.05,                last time consumption/overall running time: 34.0119s / 53897.0590 s
env0_first_0:                 episode reward: -2.0000,                 loss: 0.2246
env0_second_0:                 episode reward: 2.0000,                 loss: 0.4536
env1_first_0:                 episode reward: -2.1000,                 loss: nan
env1_second_0:                 episode reward: 2.1000,                 loss: nan
Episode: 30741/50000 (61.4820%),                 avg. length: 582.45,                last time consumption/overall running time: 35.2190s / 53932.2780 s
env0_first_0:                 episode reward: -2.8000,                 loss: 0.2359
env0_second_0:                 episode reward: 2.8000,                 loss: 0.6420
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 30761/50000 (61.5220%),                 avg. length: 645.45,                last time consumption/overall running time: 38.4519s / 53970.7299 s
env0_first_0:                 episode reward: -1.7500,                 loss: 0.2276
env0_second_0:                 episode reward: 1.7500,                 loss: 0.4642
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 30781/50000 (61.5620%),                 avg. length: 625.55,                last time consumption/overall running time: 38.6714s / 54009.4013 s
env0_first_0:                 episode reward: -2.3000,                 loss: 0.2158
env0_second_0:                 episode reward: 2.3000,                 loss: 0.4254
env1_first_0:                 episode reward: -2.5000,                 loss: nan
env1_second_0:                 episode reward: 2.5000,                 loss: nan
Episode: 30801/50000 (61.6020%),                 avg. length: 622.35,                last time consumption/overall running time: 37.7316s / 54047.1329 s
env0_first_0:                 episode reward: -2.4500,                 loss: 0.2535
env0_second_0:                 episode reward: 2.4500,                 loss: 0.5061
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 30821/50000 (61.6420%),                 avg. length: 649.6,                last time consumption/overall running time: 39.6041s / 54086.7370 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.2514
env0_second_0:                 episode reward: 1.3000,                 loss: 0.4605
env1_first_0:                 episode reward: -2.2000,                 loss: nan
env1_second_0:                 episode reward: 2.2000,                 loss: nan
Episode: 30841/50000 (61.6820%),                 avg. length: 626.1,                last time consumption/overall running time: 37.2227s / 54123.9598 s
env0_first_0:                 episode reward: -2.1500,                 loss: 0.2456
env0_second_0:                 episode reward: 2.1500,                 loss: 0.4539
env1_first_0:                 episode reward: -2.2500,                 loss: nan
env1_second_0:                 episode reward: 2.2500,                 loss: nan
Episode: 30861/50000 (61.7220%),                 avg. length: 621.35,                last time consumption/overall running time: 37.5525s / 54161.5123 s
env0_first_0:                 episode reward: -2.1500,                 loss: 0.2584
env0_second_0:                 episode reward: 2.1500,                 loss: 0.4725
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 30881/50000 (61.7620%),                 avg. length: 664.35,                last time consumption/overall running time: 40.1535s / 54201.6657 s
env0_first_0:                 episode reward: -1.4500,                 loss: 0.2715
env0_second_0:                 episode reward: 1.4500,                 loss: 0.4259
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 30901/50000 (61.8020%),                 avg. length: 658.15,                last time consumption/overall running time: 40.2821s / 54241.9478 s
env0_first_0:                 episode reward: -2.4000,                 loss: 0.2473
env0_second_0:                 episode reward: 2.4000,                 loss: 0.4220
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 30921/50000 (61.8420%),                 avg. length: 613.05,                last time consumption/overall running time: 36.0652s / 54278.0130 s
env0_first_0:                 episode reward: -1.5500,                 loss: 0.2931
env0_second_0:                 episode reward: 1.5500,                 loss: 0.5606
env1_first_0:                 episode reward: -2.1500,                 loss: nan
env1_second_0:                 episode reward: 2.1500,                 loss: nan
Episode: 30941/50000 (61.8820%),                 avg. length: 629.1,                last time consumption/overall running time: 37.4330s / 54315.4460 s
env0_first_0:                 episode reward: -2.3000,                 loss: 0.2587
env0_second_0:                 episode reward: 2.3000,                 loss: 0.4665
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 30961/50000 (61.9220%),                 avg. length: 640.3,                last time consumption/overall running time: 37.6805s / 54353.1265 s
env0_first_0:                 episode reward: -1.5500,                 loss: 0.2494
env0_second_0:                 episode reward: 1.5500,                 loss: 0.4748
env1_first_0:                 episode reward: -2.2500,                 loss: nan
env1_second_0:                 episode reward: 2.2500,                 loss: nan
Episode: 30981/50000 (61.9620%),                 avg. length: 620.85,                last time consumption/overall running time: 36.6246s / 54389.7511 s
env0_first_0:                 episode reward: -1.8000,                 loss: 0.2195
env0_second_0:                 episode reward: 1.8000,                 loss: 0.4251
env1_first_0:                 episode reward: -2.0000,                 loss: nan
env1_second_0:                 episode reward: 2.0000,                 loss: nan
Episode: 31001/50000 (62.0020%),                 avg. length: 607.15,                last time consumption/overall running time: 35.9819s / 54425.7330 s
env0_first_0:                 episode reward: -2.2000,                 loss: 0.2190
env0_second_0:                 episode reward: 2.2000,                 loss: 0.3741
env1_first_0:                 episode reward: -2.0500,                 loss: nan
env1_second_0:                 episode reward: 2.0500,                 loss: nan
Episode: 31021/50000 (62.0420%),                 avg. length: 614.55,                last time consumption/overall running time: 36.3378s / 54462.0708 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.2033
env0_second_0:                 episode reward: 1.0500,                 loss: 0.3656
env1_first_0:                 episode reward: -2.8000,                 loss: nan
env1_second_0:                 episode reward: 2.8000,                 loss: nan
Episode: 31041/50000 (62.0820%),                 avg. length: 601.15,                last time consumption/overall running time: 36.5466s / 54498.6174 s
env0_first_0:                 episode reward: -2.1000,                 loss: 0.2073
env0_second_0:                 episode reward: 2.1000,                 loss: 0.3733
env1_first_0:                 episode reward: -2.0000,                 loss: nan
env1_second_0:                 episode reward: 2.0000,                 loss: nan
Episode: 31061/50000 (62.1220%),                 avg. length: 597.9,                last time consumption/overall running time: 35.9243s / 54534.5417 s
env0_first_0:                 episode reward: -1.6500,                 loss: 0.2256
env0_second_0:                 episode reward: 1.6500,                 loss: 0.4069
env1_first_0:                 episode reward: -2.3000,                 loss: nan
env1_second_0:                 episode reward: 2.3000,                 loss: nan
Episode: 31081/50000 (62.1620%),                 avg. length: 678.6,                last time consumption/overall running time: 39.5202s / 54574.0619 s
env0_first_0:                 episode reward: -1.5000,                 loss: 0.2147
env0_second_0:                 episode reward: 1.5000,                 loss: 0.4118
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 31101/50000 (62.2020%),                 avg. length: 578.6,                last time consumption/overall running time: 34.4135s / 54608.4754 s
env0_first_0:                 episode reward: -1.5500,                 loss: 0.2111
env0_second_0:                 episode reward: 1.5500,                 loss: 0.7412
env1_first_0:                 episode reward: -3.1500,                 loss: nan
env1_second_0:                 episode reward: 3.1500,                 loss: nan
Episode: 31121/50000 (62.2420%),                 avg. length: 664.35,                last time consumption/overall running time: 38.9920s / 54647.4674 s
env0_first_0:                 episode reward: -2.1500,                 loss: 0.2148
env0_second_0:                 episode reward: 2.1500,                 loss: 0.3881
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 31141/50000 (62.2820%),                 avg. length: 605.5,                last time consumption/overall running time: 35.8748s / 54683.3422 s
env0_first_0:                 episode reward: -2.1000,                 loss: 0.2266
env0_second_0:                 episode reward: 2.1000,                 loss: 0.6548
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 31161/50000 (62.3220%),                 avg. length: 646.75,                last time consumption/overall running time: 37.9475s / 54721.2897 s
env0_first_0:                 episode reward: -1.8500,                 loss: 0.1984
env0_second_0:                 episode reward: 1.8500,                 loss: 0.4190
env1_first_0:                 episode reward: -2.1000,                 loss: nan
env1_second_0:                 episode reward: 2.1000,                 loss: nan
Episode: 31181/50000 (62.3620%),                 avg. length: 659.25,                last time consumption/overall running time: 38.7666s / 54760.0563 s
env0_first_0:                 episode reward: -2.1500,                 loss: 0.2439
env0_second_0:                 episode reward: 2.1500,                 loss: 0.4750
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 31201/50000 (62.4020%),                 avg. length: 630.55,                last time consumption/overall running time: 37.1611s / 54797.2174 s
env0_first_0:                 episode reward: -2.0500,                 loss: 0.2167
env0_second_0:                 episode reward: 2.0500,                 loss: 0.4166
env1_first_0:                 episode reward: -2.2500,                 loss: nan
env1_second_0:                 episode reward: 2.2500,                 loss: nan
Episode: 31221/50000 (62.4420%),                 avg. length: 641.9,                last time consumption/overall running time: 39.0744s / 54836.2918 s
env0_first_0:                 episode reward: -1.7500,                 loss: 0.2286
env0_second_0:                 episode reward: 1.7500,                 loss: 0.4101
env1_first_0:                 episode reward: -2.2500,                 loss: nan
env1_second_0:                 episode reward: 2.2500,                 loss: nan
Episode: 31241/50000 (62.4820%),                 avg. length: 588.1,                last time consumption/overall running time: 35.6254s / 54871.9172 s
env0_first_0:                 episode reward: -2.6000,                 loss: 0.2373
env0_second_0:                 episode reward: 2.6000,                 loss: 0.4136
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
Episode: 31261/50000 (62.5220%),                 avg. length: 632.8,                last time consumption/overall running time: 38.7683s / 54910.6855 s
env0_first_0:                 episode reward: -2.1000,                 loss: 0.2122
env0_second_0:                 episode reward: 2.1000,                 loss: 0.3514
env1_first_0:                 episode reward: -2.2500,                 loss: nan
env1_second_0:                 episode reward: 2.2500,                 loss: nan
Episode: 31281/50000 (62.5620%),                 avg. length: 587.75,                last time consumption/overall running time: 35.7062s / 54946.3917 s
env0_first_0:                 episode reward: -2.6000,                 loss: 0.2422
env0_second_0:                 episode reward: 2.6000,                 loss: 0.4850
env1_first_0:                 episode reward: -2.2000,                 loss: nan
env1_second_0:                 episode reward: 2.2000,                 loss: nan
Episode: 31301/50000 (62.6020%),                 avg. length: 629.7,                last time consumption/overall running time: 37.3598s / 54983.7515 s
env0_first_0:                 episode reward: -1.5500,                 loss: 0.2482
env0_second_0:                 episode reward: 1.5500,                 loss: 0.3978
env1_first_0:                 episode reward: -1.8000,                 loss: nan
env1_second_0:                 episode reward: 1.8000,                 loss: nan
Episode: 31321/50000 (62.6420%),                 avg. length: 645.05,                last time consumption/overall running time: 38.2881s / 55022.0396 s
env0_first_0:                 episode reward: -2.4500,                 loss: 0.2381
env0_second_0:                 episode reward: 2.4500,                 loss: 0.3761
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 31341/50000 (62.6820%),                 avg. length: 662.6,                last time consumption/overall running time: 39.0056s / 55061.0452 s
env0_first_0:                 episode reward: -1.6000,                 loss: 0.2400
env0_second_0:                 episode reward: 1.6000,                 loss: 0.3512
env1_first_0:                 episode reward: -2.7500,                 loss: nan
env1_second_0:                 episode reward: 2.7500,                 loss: nan
Episode: 31361/50000 (62.7220%),                 avg. length: 603.0,                last time consumption/overall running time: 36.0633s / 55097.1085 s
env0_first_0:                 episode reward: -1.9000,                 loss: 0.2340
env0_second_0:                 episode reward: 1.9000,                 loss: 0.4253
env1_first_0:                 episode reward: -1.6500,                 loss: nan
env1_second_0:                 episode reward: 1.6500,                 loss: nan
Episode: 31381/50000 (62.7620%),                 avg. length: 596.5,                last time consumption/overall running time: 35.8715s / 55132.9800 s
env0_first_0:                 episode reward: -2.3000,                 loss: 0.2295
env0_second_0:                 episode reward: 2.3000,                 loss: 0.3613
env1_first_0:                 episode reward: -2.6500,                 loss: nan
env1_second_0:                 episode reward: 2.6500,                 loss: nan
Episode: 31401/50000 (62.8020%),                 avg. length: 644.45,                last time consumption/overall running time: 38.7523s / 55171.7323 s
env0_first_0:                 episode reward: -1.9500,                 loss: 0.2279
env0_second_0:                 episode reward: 1.9500,                 loss: 0.3319
env1_first_0:                 episode reward: -2.4500,                 loss: nan
env1_second_0:                 episode reward: 2.4500,                 loss: nan
Episode: 31421/50000 (62.8420%),                 avg. length: 603.05,                last time consumption/overall running time: 37.9331s / 55209.6654 s
env0_first_0:                 episode reward: -1.9500,                 loss: 0.2335
env0_second_0:                 episode reward: 1.9500,                 loss: 0.3307
env1_first_0:                 episode reward: -2.4000,                 loss: nan
env1_second_0:                 episode reward: 2.4000,                 loss: nan
Episode: 31441/50000 (62.8820%),                 avg. length: 604.9,                last time consumption/overall running time: 37.6318s / 55247.2973 s
env0_first_0:                 episode reward: -1.6500,                 loss: 0.2409
env0_second_0:                 episode reward: 1.6500,                 loss: 0.3734
env1_first_0:                 episode reward: -2.5000,                 loss: nan
env1_second_0:                 episode reward: 2.5000,                 loss: nan
Episode: 31461/50000 (62.9220%),                 avg. length: 603.05,                last time consumption/overall running time: 37.3301s / 55284.6273 s
env0_first_0:                 episode reward: -1.8000,                 loss: 0.2435
env0_second_0:                 episode reward: 1.8000,                 loss: 0.3584
env1_first_0:                 episode reward: -1.9500,                 loss: nan
env1_second_0:                 episode reward: 1.9500,                 loss: nan
Episode: 31481/50000 (62.9620%),                 avg. length: 627.7,                last time consumption/overall running time: 37.1590s / 55321.7863 s
env0_first_0:                 episode reward: -2.3000,                 loss: 0.2480
env0_second_0:                 episode reward: 2.3000,                 loss: 0.3914
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 31501/50000 (63.0020%),                 avg. length: 664.35,                last time consumption/overall running time: 38.9312s / 55360.7175 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.2317
env0_second_0:                 episode reward: 1.4000,                 loss: 0.4397
env1_first_0:                 episode reward: -2.2000,                 loss: nan
env1_second_0:                 episode reward: 2.2000,                 loss: nan
Episode: 31521/50000 (63.0420%),                 avg. length: 566.25,                last time consumption/overall running time: 34.1516s / 55394.8691 s
env0_first_0:                 episode reward: -1.8000,                 loss: 0.2105
env0_second_0:                 episode reward: 1.8000,                 loss: 0.3325
env1_first_0:                 episode reward: -2.0000,                 loss: nan
env1_second_0:                 episode reward: 2.0000,                 loss: nan
Episode: 31541/50000 (63.0820%),                 avg. length: 605.8,                last time consumption/overall running time: 38.5990s / 55433.4681 s
env0_first_0:                 episode reward: -1.7500,                 loss: 0.2443
env0_second_0:                 episode reward: 1.7500,                 loss: 0.3543
env1_first_0:                 episode reward: -2.6500,                 loss: nan
env1_second_0:                 episode reward: 2.6500,                 loss: nan
Episode: 31561/50000 (63.1220%),                 avg. length: 638.0,                last time consumption/overall running time: 37.9004s / 55471.3685 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2618
env0_second_0:                 episode reward: 0.3000,                 loss: 0.4466
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 31581/50000 (63.1620%),                 avg. length: 614.95,                last time consumption/overall running time: 36.5257s / 55507.8941 s
env0_first_0:                 episode reward: -2.4000,                 loss: 0.2247
env0_second_0:                 episode reward: 2.4000,                 loss: 0.3869
env1_first_0:                 episode reward: -2.2500,                 loss: nan
env1_second_0:                 episode reward: 2.2500,                 loss: nan
Episode: 31601/50000 (63.2020%),                 avg. length: 649.65,                last time consumption/overall running time: 38.9987s / 55546.8928 s
env0_first_0:                 episode reward: -1.6000,                 loss: 0.2042
env0_second_0:                 episode reward: 1.6000,                 loss: 0.4102
env1_first_0:                 episode reward: -2.8500,                 loss: nan
env1_second_0:                 episode reward: 2.8500,                 loss: nan
Episode: 31621/50000 (63.2420%),                 avg. length: 683.05,                last time consumption/overall running time: 41.4179s / 55588.3107 s
env0_first_0:                 episode reward: -2.0500,                 loss: 0.2130
env0_second_0:                 episode reward: 2.0500,                 loss: 0.4961
env1_first_0:                 episode reward: -2.2000,                 loss: nan
env1_second_0:                 episode reward: 2.2000,                 loss: nan
Episode: 31641/50000 (63.2820%),                 avg. length: 658.75,                last time consumption/overall running time: 40.1474s / 55628.4581 s
env0_first_0:                 episode reward: -2.2500,                 loss: 0.2370
env0_second_0:                 episode reward: 2.2500,                 loss: 0.4354
env1_first_0:                 episode reward: -1.8000,                 loss: nan
env1_second_0:                 episode reward: 1.8000,                 loss: nan
Episode: 31661/50000 (63.3220%),                 avg. length: 603.1,                last time consumption/overall running time: 36.1811s / 55664.6392 s
env0_first_0:                 episode reward: -2.9000,                 loss: 0.1967
env0_second_0:                 episode reward: 2.9000,                 loss: 0.3627
env1_first_0:                 episode reward: -2.2500,                 loss: nan
env1_second_0:                 episode reward: 2.2500,                 loss: nan
Episode: 31681/50000 (63.3620%),                 avg. length: 576.4,                last time consumption/overall running time: 35.3039s / 55699.9430 s
env0_first_0:                 episode reward: -1.6500,                 loss: 0.2190
env0_second_0:                 episode reward: 1.6500,                 loss: 0.3754
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 31701/50000 (63.4020%),                 avg. length: 660.4,                last time consumption/overall running time: 39.1573s / 55739.1003 s
env0_first_0:                 episode reward: -1.9000,                 loss: 0.2249
env0_second_0:                 episode reward: 1.9000,                 loss: 0.5122
env1_first_0:                 episode reward: -1.6500,                 loss: nan
env1_second_0:                 episode reward: 1.6500,                 loss: nan
Episode: 31721/50000 (63.4420%),                 avg. length: 604.25,                last time consumption/overall running time: 36.1248s / 55775.2252 s
env0_first_0:                 episode reward: -1.7500,                 loss: 0.2264
env0_second_0:                 episode reward: 1.7500,                 loss: 0.4501
env1_first_0:                 episode reward: -2.6000,                 loss: nan
env1_second_0:                 episode reward: 2.6000,                 loss: nan
Episode: 31741/50000 (63.4820%),                 avg. length: 674.2,                last time consumption/overall running time: 39.8278s / 55815.0530 s
env0_first_0:                 episode reward: -2.1000,                 loss: 0.2157
env0_second_0:                 episode reward: 2.1000,                 loss: 0.4466
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 31761/50000 (63.5220%),                 avg. length: 671.6,                last time consumption/overall running time: 39.4909s / 55854.5439 s
env0_first_0:                 episode reward: -1.5500,                 loss: 0.1903
env0_second_0:                 episode reward: 1.5500,                 loss: 0.3886
env1_first_0:                 episode reward: -2.1500,                 loss: nan
env1_second_0:                 episode reward: 2.1500,                 loss: nan
Episode: 31781/50000 (63.5620%),                 avg. length: 615.75,                last time consumption/overall running time: 37.9941s / 55892.5380 s
env0_first_0:                 episode reward: -2.3500,                 loss: 0.2117
env0_second_0:                 episode reward: 2.3500,                 loss: 0.3795
env1_first_0:                 episode reward: -1.9500,                 loss: nan
env1_second_0:                 episode reward: 1.9500,                 loss: nan
Episode: 31801/50000 (63.6020%),                 avg. length: 657.55,                last time consumption/overall running time: 39.6006s / 55932.1386 s
env0_first_0:                 episode reward: -1.5500,                 loss: 0.1852
env0_second_0:                 episode reward: 1.5500,                 loss: 0.3240
env1_first_0:                 episode reward: -1.6500,                 loss: nan
env1_second_0:                 episode reward: 1.6500,                 loss: nan
Episode: 31821/50000 (63.6420%),                 avg. length: 602.55,                last time consumption/overall running time: 35.8630s / 55968.0017 s
env0_first_0:                 episode reward: -1.7000,                 loss: 0.1841
env0_second_0:                 episode reward: 1.7000,                 loss: 0.3434
env1_first_0:                 episode reward: -2.1000,                 loss: nan
env1_second_0:                 episode reward: 2.1000,                 loss: nan
Episode: 31841/50000 (63.6820%),                 avg. length: 596.1,                last time consumption/overall running time: 35.8464s / 56003.8480 s
env0_first_0:                 episode reward: -2.2500,                 loss: 0.1828
env0_second_0:                 episode reward: 2.2500,                 loss: 0.3691
env1_first_0:                 episode reward: -1.6500,                 loss: nan
env1_second_0:                 episode reward: 1.6500,                 loss: nan
Episode: 31861/50000 (63.7220%),                 avg. length: 628.55,                last time consumption/overall running time: 38.1344s / 56041.9824 s
env0_first_0:                 episode reward: -2.7000,                 loss: 0.1698
env0_second_0:                 episode reward: 2.7000,                 loss: 0.3450
env1_first_0:                 episode reward: -1.9500,                 loss: nan
env1_second_0:                 episode reward: 1.9500,                 loss: nan
Episode: 31881/50000 (63.7620%),                 avg. length: 626.45,                last time consumption/overall running time: 38.5513s / 56080.5338 s
env0_first_0:                 episode reward: -3.1000,                 loss: 0.1711
env0_second_0:                 episode reward: 3.1000,                 loss: 0.2995
env1_first_0:                 episode reward: -2.6000,                 loss: nan
env1_second_0:                 episode reward: 2.6000,                 loss: nan
Episode: 31901/50000 (63.8020%),                 avg. length: 656.55,                last time consumption/overall running time: 38.8589s / 56119.3927 s
env0_first_0:                 episode reward: -1.9000,                 loss: 0.1672
env0_second_0:                 episode reward: 1.9000,                 loss: 0.3615
env1_first_0:                 episode reward: -3.1000,                 loss: nan
env1_second_0:                 episode reward: 3.1000,                 loss: nan
Episode: 31921/50000 (63.8420%),                 avg. length: 681.95,                last time consumption/overall running time: 40.0698s / 56159.4624 s
env0_first_0:                 episode reward: -2.8000,                 loss: 0.1502
env0_second_0:                 episode reward: 2.8000,                 loss: 0.6151
env1_first_0:                 episode reward: -2.3500,                 loss: nan
env1_second_0:                 episode reward: 2.3500,                 loss: nan
Episode: 31941/50000 (63.8820%),                 avg. length: 606.5,                last time consumption/overall running time: 38.7573s / 56198.2197 s
env0_first_0:                 episode reward: -3.1000,                 loss: 0.1693
env0_second_0:                 episode reward: 3.1000,                 loss: 0.3982
env1_first_0:                 episode reward: -2.0000,                 loss: nan
env1_second_0:                 episode reward: 2.0000,                 loss: nan
Episode: 31961/50000 (63.9220%),                 avg. length: 684.15,                last time consumption/overall running time: 40.1502s / 56238.3699 s
env0_first_0:                 episode reward: -2.4500,                 loss: 0.1336
env0_second_0:                 episode reward: 2.4500,                 loss: 0.3448
env1_first_0:                 episode reward: -2.6000,                 loss: nan
env1_second_0:                 episode reward: 2.6000,                 loss: nan
Episode: 31981/50000 (63.9620%),                 avg. length: 656.0,                last time consumption/overall running time: 38.6848s / 56277.0547 s
env0_first_0:                 episode reward: -2.7000,                 loss: 0.1540
env0_second_0:                 episode reward: 2.7000,                 loss: 0.3463
env1_first_0:                 episode reward: -3.0500,                 loss: nan
env1_second_0:                 episode reward: 3.0500,                 loss: nan
Episode: 32001/50000 (64.0020%),                 avg. length: 682.3,                last time consumption/overall running time: 40.6283s / 56317.6830 s
env0_first_0:                 episode reward: -3.3500,                 loss: 0.1275
env0_second_0:                 episode reward: 3.3500,                 loss: 0.5580
env1_first_0:                 episode reward: -2.9000,                 loss: nan
env1_second_0:                 episode reward: 2.9000,                 loss: nan
Episode: 32021/50000 (64.0420%),                 avg. length: 629.0,                last time consumption/overall running time: 39.2771s / 56356.9600 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.1249
env0_second_0:                 episode reward: 3.9500,                 loss: 0.3133
env1_first_0:                 episode reward: -2.5000,                 loss: nan
env1_second_0:                 episode reward: 2.5000,                 loss: nan
Episode: 32041/50000 (64.0820%),                 avg. length: 713.65,                last time consumption/overall running time: 41.6254s / 56398.5854 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.1182
env0_second_0:                 episode reward: 3.4500,                 loss: 0.2611
env1_first_0:                 episode reward: -2.7000,                 loss: nan
env1_second_0:                 episode reward: 2.7000,                 loss: nan
Episode: 32061/50000 (64.1220%),                 avg. length: 677.55,                last time consumption/overall running time: 39.9130s / 56438.4984 s
env0_first_0:                 episode reward: -2.5500,                 loss: 0.1498
env0_second_0:                 episode reward: 2.5500,                 loss: 0.2772
env1_first_0:                 episode reward: -3.0500,                 loss: nan
env1_second_0:                 episode reward: 3.0500,                 loss: nan
Episode: 32081/50000 (64.1620%),                 avg. length: 627.55,                last time consumption/overall running time: 38.0888s / 56476.5872 s
env0_first_0:                 episode reward: -3.2000,                 loss: 0.1180
env0_second_0:                 episode reward: 3.2000,                 loss: 0.2524
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 32101/50000 (64.2020%),                 avg. length: 619.3,                last time consumption/overall running time: 37.5620s / 56514.1492 s
env0_first_0:                 episode reward: -2.6000,                 loss: 0.1193
env0_second_0:                 episode reward: 2.6000,                 loss: 0.2276
env1_first_0:                 episode reward: -4.1500,                 loss: nan
env1_second_0:                 episode reward: 4.1500,                 loss: nan
Episode: 32121/50000 (64.2420%),                 avg. length: 652.55,                last time consumption/overall running time: 38.3948s / 56552.5440 s
env0_first_0:                 episode reward: -2.6500,                 loss: 0.1380
env0_second_0:                 episode reward: 2.6500,                 loss: 0.2413
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 32141/50000 (64.2820%),                 avg. length: 562.95,                last time consumption/overall running time: 34.0165s / 56586.5605 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.1170
env0_second_0:                 episode reward: 3.5000,                 loss: 0.2095
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 32161/50000 (64.3220%),                 avg. length: 596.65,                last time consumption/overall running time: 36.4568s / 56623.0173 s
env0_first_0:                 episode reward: -2.8500,                 loss: 0.1577
env0_second_0:                 episode reward: 2.8500,                 loss: 0.3338
env1_first_0:                 episode reward: -3.5000,                 loss: nan
env1_second_0:                 episode reward: 3.5000,                 loss: nan
Episode: 32181/50000 (64.3620%),                 avg. length: 597.05,                last time consumption/overall running time: 37.4960s / 56660.5133 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.1108
env0_second_0:                 episode reward: 3.7000,                 loss: 0.2964
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 32201/50000 (64.4020%),                 avg. length: 511.6,                last time consumption/overall running time: 31.7448s / 56692.2581 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.1308
env0_second_0:                 episode reward: 4.0000,                 loss: 0.3121
env1_first_0:                 episode reward: -3.3500,                 loss: nan
env1_second_0:                 episode reward: 3.3500,                 loss: nan
Episode: 32221/50000 (64.4420%),                 avg. length: 525.6,                last time consumption/overall running time: 32.1458s / 56724.4039 s
env0_first_0:                 episode reward: -3.3500,                 loss: 0.1588
env0_second_0:                 episode reward: 3.3500,                 loss: 0.3265
env1_first_0:                 episode reward: -4.1500,                 loss: nan
env1_second_0:                 episode reward: 4.1500,                 loss: nan
Episode: 32241/50000 (64.4820%),                 avg. length: 637.95,                last time consumption/overall running time: 38.3623s / 56762.7662 s
env0_first_0:                 episode reward: -3.0500,                 loss: 0.1243
env0_second_0:                 episode reward: 3.0500,                 loss: 0.3102
env1_first_0:                 episode reward: -3.0000,                 loss: nan
env1_second_0:                 episode reward: 3.0000,                 loss: nan
Episode: 32261/50000 (64.5220%),                 avg. length: 565.45,                last time consumption/overall running time: 34.5945s / 56797.3607 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.1303
env0_second_0:                 episode reward: 3.6000,                 loss: 0.2651
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 32281/50000 (64.5620%),                 avg. length: 535.25,                last time consumption/overall running time: 33.2978s / 56830.6585 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.1274
env0_second_0:                 episode reward: 3.8000,                 loss: 0.2772
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 32301/50000 (64.6020%),                 avg. length: 592.25,                last time consumption/overall running time: 35.8878s / 56866.5464 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.1415
env0_second_0:                 episode reward: 3.8500,                 loss: 0.2805
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 32321/50000 (64.6420%),                 avg. length: 630.05,                last time consumption/overall running time: 37.8189s / 56904.3653 s
env0_first_0:                 episode reward: -3.2500,                 loss: 0.1391
env0_second_0:                 episode reward: 3.2500,                 loss: 0.2855
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 32341/50000 (64.6820%),                 avg. length: 588.15,                last time consumption/overall running time: 35.7204s / 56940.0857 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.1254
env0_second_0:                 episode reward: 3.8500,                 loss: 0.2298
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 32361/50000 (64.7220%),                 avg. length: 599.65,                last time consumption/overall running time: 36.3587s / 56976.4444 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.1324
env0_second_0:                 episode reward: 3.7000,                 loss: 0.2747
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 32381/50000 (64.7620%),                 avg. length: 597.6,                last time consumption/overall running time: 35.8535s / 57012.2979 s
env0_first_0:                 episode reward: -3.0500,                 loss: 0.1376
env0_second_0:                 episode reward: 3.0500,                 loss: 0.3075
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 32401/50000 (64.8020%),                 avg. length: 599.05,                last time consumption/overall running time: 35.9772s / 57048.2751 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.0986
env0_second_0:                 episode reward: 3.4500,                 loss: 0.2300
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 32421/50000 (64.8420%),                 avg. length: 588.4,                last time consumption/overall running time: 37.3779s / 57085.6529 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.1180
env0_second_0:                 episode reward: 3.6500,                 loss: 0.2201
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 32441/50000 (64.8820%),                 avg. length: 542.8,                last time consumption/overall running time: 33.3705s / 57119.0234 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.1281
env0_second_0:                 episode reward: 3.5000,                 loss: 0.2466
env1_first_0:                 episode reward: -3.3500,                 loss: nan
env1_second_0:                 episode reward: 3.3500,                 loss: nan
Episode: 32461/50000 (64.9220%),                 avg. length: 566.1,                last time consumption/overall running time: 34.8550s / 57153.8784 s
env0_first_0:                 episode reward: -3.0000,                 loss: 0.1482
env0_second_0:                 episode reward: 3.0000,                 loss: 0.2734
env1_first_0:                 episode reward: -4.3000,                 loss: nan
env1_second_0:                 episode reward: 4.3000,                 loss: nan
Episode: 32481/50000 (64.9620%),                 avg. length: 571.7,                last time consumption/overall running time: 34.5531s / 57188.4315 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.1511
env0_second_0:                 episode reward: 4.0000,                 loss: 0.2556
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 32501/50000 (65.0020%),                 avg. length: 569.4,                last time consumption/overall running time: 34.4123s / 57222.8438 s
env0_first_0:                 episode reward: -3.3500,                 loss: 0.1346
env0_second_0:                 episode reward: 3.3500,                 loss: 0.2534
env1_first_0:                 episode reward: -4.1000,                 loss: nan
env1_second_0:                 episode reward: 4.1000,                 loss: nan
Episode: 32521/50000 (65.0420%),                 avg. length: 549.35,                last time consumption/overall running time: 33.5848s / 57256.4286 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.1361
env0_second_0:                 episode reward: 3.6500,                 loss: 0.2115
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 32541/50000 (65.0820%),                 avg. length: 551.75,                last time consumption/overall running time: 34.3035s / 57290.7321 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.1441
env0_second_0:                 episode reward: 3.6000,                 loss: 0.2385
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 32561/50000 (65.1220%),                 avg. length: 580.7,                last time consumption/overall running time: 34.9204s / 57325.6525 s
env0_first_0:                 episode reward: -3.7500,                 loss: 0.1409
env0_second_0:                 episode reward: 3.7500,                 loss: 0.2495
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 32581/50000 (65.1620%),                 avg. length: 558.85,                last time consumption/overall running time: 33.7126s / 57359.3651 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.1372
env0_second_0:                 episode reward: 3.8500,                 loss: 0.3510
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 32601/50000 (65.2020%),                 avg. length: 562.65,                last time consumption/overall running time: 34.0406s / 57393.4057 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.1711
env0_second_0:                 episode reward: 3.7000,                 loss: 0.3020
env1_first_0:                 episode reward: -3.5000,                 loss: nan
env1_second_0:                 episode reward: 3.5000,                 loss: nan
Episode: 32621/50000 (65.2420%),                 avg. length: 546.15,                last time consumption/overall running time: 33.6624s / 57427.0681 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.1208
env0_second_0:                 episode reward: 3.8500,                 loss: 0.2679
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 32641/50000 (65.2820%),                 avg. length: 601.4,                last time consumption/overall running time: 36.2112s / 57463.2793 s
env0_first_0:                 episode reward: -4.0500,                 loss: 0.1110
env0_second_0:                 episode reward: 4.0500,                 loss: 0.2447
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 32661/50000 (65.3220%),                 avg. length: 520.0,                last time consumption/overall running time: 31.5276s / 57494.8068 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.1118
env0_second_0:                 episode reward: 3.6500,                 loss: 0.1813
env1_first_0:                 episode reward: -4.2500,                 loss: nan
env1_second_0:                 episode reward: 4.2500,                 loss: nan
Episode: 32681/50000 (65.3620%),                 avg. length: 555.95,                last time consumption/overall running time: 33.3353s / 57528.1421 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.1273
env0_second_0:                 episode reward: 3.9500,                 loss: 0.1998
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 32701/50000 (65.4020%),                 avg. length: 559.85,                last time consumption/overall running time: 34.6631s / 57562.8052 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.1262
env0_second_0:                 episode reward: 3.6000,                 loss: 0.2059
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 32721/50000 (65.4420%),                 avg. length: 552.3,                last time consumption/overall running time: 36.3402s / 57599.1455 s
env0_first_0:                 episode reward: -3.7500,                 loss: 0.1782
env0_second_0:                 episode reward: 3.7500,                 loss: 0.2543
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 32741/50000 (65.4820%),                 avg. length: 559.3,                last time consumption/overall running time: 33.3898s / 57632.5353 s
env0_first_0:                 episode reward: -2.7000,                 loss: 0.1385
env0_second_0:                 episode reward: 2.7000,                 loss: 0.2411
env1_first_0:                 episode reward: -4.3000,                 loss: nan
env1_second_0:                 episode reward: 4.3000,                 loss: nan
Episode: 32761/50000 (65.5220%),                 avg. length: 554.05,                last time consumption/overall running time: 33.3402s / 57665.8755 s
env0_first_0:                 episode reward: -3.7500,                 loss: 0.1248
env0_second_0:                 episode reward: 3.7500,                 loss: 0.1907
env1_first_0:                 episode reward: -4.1000,                 loss: nan
env1_second_0:                 episode reward: 4.1000,                 loss: nan
Episode: 32781/50000 (65.5620%),                 avg. length: 562.65,                last time consumption/overall running time: 33.7050s / 57699.5805 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.1242
env0_second_0:                 episode reward: 3.9000,                 loss: 0.2161
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 32801/50000 (65.6020%),                 avg. length: 606.05,                last time consumption/overall running time: 36.0080s / 57735.5885 s
env0_first_0:                 episode reward: -3.2500,                 loss: 0.0994
env0_second_0:                 episode reward: 3.2500,                 loss: 0.1937
env1_first_0:                 episode reward: -4.2000,                 loss: nan
env1_second_0:                 episode reward: 4.2000,                 loss: nan
Episode: 32821/50000 (65.6420%),                 avg. length: 608.0,                last time consumption/overall running time: 35.9664s / 57771.5549 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.0887
env0_second_0:                 episode reward: 4.0000,                 loss: 0.1679
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 32841/50000 (65.6820%),                 avg. length: 543.4,                last time consumption/overall running time: 32.8520s / 57804.4068 s
env0_first_0:                 episode reward: -4.2500,                 loss: 0.1140
env0_second_0:                 episode reward: 4.2500,                 loss: 0.1693
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 32861/50000 (65.7220%),                 avg. length: 632.55,                last time consumption/overall running time: 37.2965s / 57841.7034 s
env0_first_0:                 episode reward: -2.7000,                 loss: 0.1191
env0_second_0:                 episode reward: 2.7000,                 loss: 0.2309
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 32881/50000 (65.7620%),                 avg. length: 609.1,                last time consumption/overall running time: 36.0032s / 57877.7066 s
env0_first_0:                 episode reward: -3.1500,                 loss: 0.1325
env0_second_0:                 episode reward: 3.1500,                 loss: 0.1920
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 32901/50000 (65.8020%),                 avg. length: 570.35,                last time consumption/overall running time: 34.2890s / 57911.9955 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.1282
env0_second_0:                 episode reward: 3.6500,                 loss: 0.2085
env1_first_0:                 episode reward: -3.5000,                 loss: nan
env1_second_0:                 episode reward: 3.5000,                 loss: nan
Episode: 32921/50000 (65.8420%),                 avg. length: 545.35,                last time consumption/overall running time: 32.6703s / 57944.6658 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.1090
env0_second_0:                 episode reward: 3.5500,                 loss: 0.2093
env1_first_0:                 episode reward: -4.1000,                 loss: nan
env1_second_0:                 episode reward: 4.1000,                 loss: nan
Episode: 32941/50000 (65.8820%),                 avg. length: 610.9,                last time consumption/overall running time: 36.1852s / 57980.8510 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.1019
env0_second_0:                 episode reward: 3.9000,                 loss: 0.2475
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 32961/50000 (65.9220%),                 avg. length: 593.45,                last time consumption/overall running time: 35.8070s / 58016.6580 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.0944
env0_second_0:                 episode reward: 3.7000,                 loss: 0.2181
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 32981/50000 (65.9620%),                 avg. length: 614.7,                last time consumption/overall running time: 41.7470s / 58058.4049 s
env0_first_0:                 episode reward: -3.1000,                 loss: 0.1075
env0_second_0:                 episode reward: 3.1000,                 loss: 0.2701
env1_first_0:                 episode reward: -4.5000,                 loss: nan
env1_second_0:                 episode reward: 4.5000,                 loss: nan
Episode: 33001/50000 (66.0020%),                 avg. length: 587.0,                last time consumption/overall running time: 34.9726s / 58093.3775 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.1379
env0_second_0:                 episode reward: 3.5500,                 loss: 0.2434
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 33021/50000 (66.0420%),                 avg. length: 551.55,                last time consumption/overall running time: 33.2493s / 58126.6268 s
env0_first_0:                 episode reward: -4.1000,                 loss: 0.1118
env0_second_0:                 episode reward: 4.1000,                 loss: 0.2239
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 33041/50000 (66.0820%),                 avg. length: 568.05,                last time consumption/overall running time: 34.0130s / 58160.6398 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.1001
env0_second_0:                 episode reward: 3.8000,                 loss: 0.1982
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 33061/50000 (66.1220%),                 avg. length: 526.95,                last time consumption/overall running time: 32.3933s / 58193.0331 s
env0_first_0:                 episode reward: -4.4000,                 loss: 0.1520
env0_second_0:                 episode reward: 4.4000,                 loss: 0.2659
env1_first_0:                 episode reward: -3.1000,                 loss: nan
env1_second_0:                 episode reward: 3.1000,                 loss: nan
Episode: 33081/50000 (66.1620%),                 avg. length: 517.85,                last time consumption/overall running time: 32.1361s / 58225.1692 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.1398
env0_second_0:                 episode reward: 3.6000,                 loss: 0.2833
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 33101/50000 (66.2020%),                 avg. length: 543.9,                last time consumption/overall running time: 32.7947s / 58257.9639 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.1370
env0_second_0:                 episode reward: 3.5000,                 loss: 0.2787
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 33121/50000 (66.2420%),                 avg. length: 538.9,                last time consumption/overall running time: 32.5634s / 58290.5273 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.1268
env0_second_0:                 episode reward: 3.8000,                 loss: 0.3113
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 33141/50000 (66.2820%),                 avg. length: 589.55,                last time consumption/overall running time: 36.1805s / 58326.7078 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.1277
env0_second_0:                 episode reward: 3.5500,                 loss: 0.2354
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 33161/50000 (66.3220%),                 avg. length: 582.75,                last time consumption/overall running time: 35.4071s / 58362.1148 s
env0_first_0:                 episode reward: -3.2500,                 loss: 0.0969
env0_second_0:                 episode reward: 3.2500,                 loss: 0.1993
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 33181/50000 (66.3620%),                 avg. length: 607.1,                last time consumption/overall running time: 38.6739s / 58400.7887 s
env0_first_0:                 episode reward: -3.2500,                 loss: 0.1397
env0_second_0:                 episode reward: 3.2500,                 loss: 0.2334
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 33201/50000 (66.4020%),                 avg. length: 526.2,                last time consumption/overall running time: 32.1404s / 58432.9291 s
env0_first_0:                 episode reward: -3.7500,                 loss: 0.1556
env0_second_0:                 episode reward: 3.7500,                 loss: 0.2546
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 33221/50000 (66.4420%),                 avg. length: 583.0,                last time consumption/overall running time: 35.2171s / 58468.1462 s
env0_first_0:                 episode reward: -3.7500,                 loss: 0.1596
env0_second_0:                 episode reward: 3.7500,                 loss: 0.2548
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 33241/50000 (66.4820%),                 avg. length: 581.4,                last time consumption/overall running time: 34.9260s / 58503.0722 s
env0_first_0:                 episode reward: -3.7500,                 loss: 0.1018
env0_second_0:                 episode reward: 3.7500,                 loss: 0.1916
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 33261/50000 (66.5220%),                 avg. length: 542.2,                last time consumption/overall running time: 32.8120s / 58535.8842 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.1058
env0_second_0:                 episode reward: 4.0000,                 loss: 0.2837
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 33281/50000 (66.5620%),                 avg. length: 557.05,                last time consumption/overall running time: 34.3504s / 58570.2346 s
env0_first_0:                 episode reward: -3.0500,                 loss: 0.1222
env0_second_0:                 episode reward: 3.0500,                 loss: 0.2283
env1_first_0:                 episode reward: -4.2500,                 loss: nan
env1_second_0:                 episode reward: 4.2500,                 loss: nan
Episode: 33301/50000 (66.6020%),                 avg. length: 600.6,                last time consumption/overall running time: 35.9106s / 58606.1451 s
env0_first_0:                 episode reward: -3.3500,                 loss: 0.1069
env0_second_0:                 episode reward: 3.3500,                 loss: 0.2291
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 33321/50000 (66.6420%),                 avg. length: 590.05,                last time consumption/overall running time: 35.4666s / 58641.6117 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.1120
env0_second_0:                 episode reward: 3.8000,                 loss: 0.2179
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 33341/50000 (66.6820%),                 avg. length: 607.7,                last time consumption/overall running time: 36.2549s / 58677.8666 s
env0_first_0:                 episode reward: -4.2000,                 loss: 0.1106
env0_second_0:                 episode reward: 4.2000,                 loss: 0.1884
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 33361/50000 (66.7220%),                 avg. length: 554.0,                last time consumption/overall running time: 33.4625s / 58711.3291 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.1007
env0_second_0:                 episode reward: 3.8500,                 loss: 0.2217
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 33381/50000 (66.7620%),                 avg. length: 550.45,                last time consumption/overall running time: 33.2938s / 58744.6229 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.1287
env0_second_0:                 episode reward: 3.7000,                 loss: 0.2297
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 33401/50000 (66.8020%),                 avg. length: 585.85,                last time consumption/overall running time: 35.2468s / 58779.8697 s
env0_first_0:                 episode reward: -4.1000,                 loss: 0.1198
env0_second_0:                 episode reward: 4.1000,                 loss: 0.2259
env1_first_0:                 episode reward: -3.2500,                 loss: nan
env1_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 33421/50000 (66.8420%),                 avg. length: 527.0,                last time consumption/overall running time: 34.7849s / 58814.6546 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.1424
env0_second_0:                 episode reward: 3.7000,                 loss: 0.2944
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 33441/50000 (66.8820%),                 avg. length: 616.2,                last time consumption/overall running time: 38.5970s / 58853.2517 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.1508
env0_second_0:                 episode reward: 3.5000,                 loss: 0.2778
env1_first_0:                 episode reward: -3.0000,                 loss: nan
env1_second_0:                 episode reward: 3.0000,                 loss: nan
Episode: 33461/50000 (66.9220%),                 avg. length: 585.7,                last time consumption/overall running time: 34.9901s / 58888.2417 s
env0_first_0:                 episode reward: -3.3500,                 loss: 0.1058
env0_second_0:                 episode reward: 3.3500,                 loss: 0.2314
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 33481/50000 (66.9620%),                 avg. length: 539.65,                last time consumption/overall running time: 32.8591s / 58921.1008 s
env0_first_0:                 episode reward: -4.0500,                 loss: 0.1685
env0_second_0:                 episode reward: 4.0500,                 loss: 0.3663
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 33501/50000 (67.0020%),                 avg. length: 556.85,                last time consumption/overall running time: 33.4884s / 58954.5892 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.1557
env0_second_0:                 episode reward: 3.8500,                 loss: 0.2620
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 33521/50000 (67.0420%),                 avg. length: 619.55,                last time consumption/overall running time: 36.5547s / 58991.1439 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.1190
env0_second_0:                 episode reward: 3.8500,                 loss: 0.2016
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 33541/50000 (67.0820%),                 avg. length: 577.7,                last time consumption/overall running time: 34.8325s / 59025.9764 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.0967
env0_second_0:                 episode reward: 3.6500,                 loss: 0.3290
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 33561/50000 (67.1220%),                 avg. length: 543.65,                last time consumption/overall running time: 32.8551s / 59058.8316 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.1232
env0_second_0:                 episode reward: 3.9000,                 loss: 0.3848
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 33581/50000 (67.1620%),                 avg. length: 572.3,                last time consumption/overall running time: 34.3968s / 59093.2284 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.1244
env0_second_0:                 episode reward: 3.5500,                 loss: 0.2844
env1_first_0:                 episode reward: -4.2000,                 loss: nan
env1_second_0:                 episode reward: 4.2000,                 loss: nan
Episode: 33601/50000 (67.2020%),                 avg. length: 548.9,                last time consumption/overall running time: 39.3866s / 59132.6150 s
env0_first_0:                 episode reward: -4.3500,                 loss: 0.1218
env0_second_0:                 episode reward: 4.3500,                 loss: 0.2740
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 33621/50000 (67.2420%),                 avg. length: 557.9,                last time consumption/overall running time: 34.8544s / 59167.4694 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.1478
env0_second_0:                 episode reward: 3.6000,                 loss: 0.2759
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 33641/50000 (67.2820%),                 avg. length: 584.7,                last time consumption/overall running time: 34.9977s / 59202.4671 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.1420
env0_second_0:                 episode reward: 3.9000,                 loss: 0.2211
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 33661/50000 (67.3220%),                 avg. length: 580.55,                last time consumption/overall running time: 34.9652s / 59237.4323 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.1421
env0_second_0:                 episode reward: 4.0000,                 loss: 0.2465
env1_first_0:                 episode reward: -3.3500,                 loss: nan
env1_second_0:                 episode reward: 3.3500,                 loss: nan
Episode: 33681/50000 (67.3620%),                 avg. length: 537.85,                last time consumption/overall running time: 33.7783s / 59271.2106 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.1229
env0_second_0:                 episode reward: 3.5500,                 loss: 0.2456
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 33701/50000 (67.4020%),                 avg. length: 622.2,                last time consumption/overall running time: 37.1591s / 59308.3697 s
env0_first_0:                 episode reward: -3.2500,                 loss: 0.0723
env0_second_0:                 episode reward: 3.2500,                 loss: 0.1907
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 33721/50000 (67.4420%),                 avg. length: 542.65,                last time consumption/overall running time: 32.7838s / 59341.1534 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.1416
env0_second_0:                 episode reward: 3.8000,                 loss: 0.2667
env1_first_0:                 episode reward: -3.2500,                 loss: nan
env1_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 33741/50000 (67.4820%),                 avg. length: 614.9,                last time consumption/overall running time: 37.0957s / 59378.2491 s
env0_first_0:                 episode reward: -2.5500,                 loss: 0.1966
env0_second_0:                 episode reward: 2.5500,                 loss: 0.4512
env1_first_0:                 episode reward: -2.7500,                 loss: nan
env1_second_0:                 episode reward: 2.7500,                 loss: nan
Episode: 33761/50000 (67.5220%),                 avg. length: 589.75,                last time consumption/overall running time: 35.7404s / 59413.9895 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.1389
env0_second_0:                 episode reward: 3.9000,                 loss: 0.3475
env1_first_0:                 episode reward: -2.8500,                 loss: nan
env1_second_0:                 episode reward: 2.8500,                 loss: nan
Episode: 33781/50000 (67.5620%),                 avg. length: 571.95,                last time consumption/overall running time: 34.8582s / 59448.8477 s
env0_first_0:                 episode reward: -3.3000,                 loss: 0.0979
env0_second_0:                 episode reward: 3.3000,                 loss: 0.3514
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 33801/50000 (67.6020%),                 avg. length: 579.6,                last time consumption/overall running time: 34.5831s / 59483.4309 s
env0_first_0:                 episode reward: -4.1000,                 loss: 0.1434
env0_second_0:                 episode reward: 4.1000,                 loss: 0.3318
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 33821/50000 (67.6420%),                 avg. length: 595.75,                last time consumption/overall running time: 35.6800s / 59519.1108 s
env0_first_0:                 episode reward: -2.9500,                 loss: 0.1437
env0_second_0:                 episode reward: 2.9500,                 loss: 0.3228
env1_first_0:                 episode reward: -4.2000,                 loss: nan
env1_second_0:                 episode reward: 4.2000,                 loss: nan
Episode: 33841/50000 (67.6820%),                 avg. length: 512.6,                last time consumption/overall running time: 36.3006s / 59555.4114 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.1401
env0_second_0:                 episode reward: 3.8500,                 loss: 0.3455
env1_first_0:                 episode reward: -4.2000,                 loss: nan
env1_second_0:                 episode reward: 4.2000,                 loss: nan
Episode: 33861/50000 (67.7220%),                 avg. length: 548.45,                last time consumption/overall running time: 34.0617s / 59589.4731 s
env0_first_0:                 episode reward: -4.1000,                 loss: 0.1072
env0_second_0:                 episode reward: 4.1000,                 loss: 0.2746
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 33881/50000 (67.7620%),                 avg. length: 561.0,                last time consumption/overall running time: 34.9240s / 59624.3971 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.1272
env0_second_0:                 episode reward: 3.8500,                 loss: 0.2444
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 33901/50000 (67.8020%),                 avg. length: 558.8,                last time consumption/overall running time: 34.1113s / 59658.5084 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.1636
env0_second_0:                 episode reward: 3.4500,                 loss: 0.2814
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 33921/50000 (67.8420%),                 avg. length: 539.85,                last time consumption/overall running time: 32.6158s / 59691.1241 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.1351
env0_second_0:                 episode reward: 3.9500,                 loss: 0.2790
env1_first_0:                 episode reward: -4.1000,                 loss: nan
env1_second_0:                 episode reward: 4.1000,                 loss: nan
Episode: 33941/50000 (67.8820%),                 avg. length: 558.1,                last time consumption/overall running time: 40.1693s / 59731.2935 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.1626
env0_second_0:                 episode reward: 3.9000,                 loss: 0.3186
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 33961/50000 (67.9220%),                 avg. length: 597.05,                last time consumption/overall running time: 35.8542s / 59767.1477 s
env0_first_0:                 episode reward: -4.1000,                 loss: 0.1368
env0_second_0:                 episode reward: 4.1000,                 loss: 0.2636
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 33981/50000 (67.9620%),                 avg. length: 579.85,                last time consumption/overall running time: 35.0025s / 59802.1502 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.1357
env0_second_0:                 episode reward: 4.0000,                 loss: 0.2915
env1_first_0:                 episode reward: -3.5000,                 loss: nan
env1_second_0:                 episode reward: 3.5000,                 loss: nan
Episode: 34001/50000 (68.0020%),                 avg. length: 588.45,                last time consumption/overall running time: 35.4274s / 59837.5776 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.1156
env0_second_0:                 episode reward: 3.9500,                 loss: 0.2564
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 34021/50000 (68.0420%),                 avg. length: 560.2,                last time consumption/overall running time: 33.9769s / 59871.5545 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.0977
env0_second_0:                 episode reward: 3.5000,                 loss: 0.1909
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 34041/50000 (68.0820%),                 avg. length: 538.0,                last time consumption/overall running time: 34.0969s / 59905.6514 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.1502
env0_second_0:                 episode reward: 3.8500,                 loss: 0.2150
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 34061/50000 (68.1220%),                 avg. length: 544.0,                last time consumption/overall running time: 33.0801s / 59938.7315 s
env0_first_0:                 episode reward: -3.2500,                 loss: 0.1455
env0_second_0:                 episode reward: 3.2500,                 loss: 0.3385
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 34081/50000 (68.1620%),                 avg. length: 566.0,                last time consumption/overall running time: 34.3342s / 59973.0657 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.1550
env0_second_0:                 episode reward: 3.6500,                 loss: 0.2744
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 34101/50000 (68.2020%),                 avg. length: 512.9,                last time consumption/overall running time: 31.9694s / 60005.0351 s
env0_first_0:                 episode reward: -3.3000,                 loss: 0.1222
env0_second_0:                 episode reward: 3.3000,                 loss: 0.2972
env1_first_0:                 episode reward: -4.2500,                 loss: nan
env1_second_0:                 episode reward: 4.2500,                 loss: nan
Episode: 34121/50000 (68.2420%),                 avg. length: 561.1,                last time consumption/overall running time: 34.3917s / 60039.4267 s
env0_first_0:                 episode reward: -2.7500,                 loss: 0.2632
env0_second_0:                 episode reward: 2.7500,                 loss: 0.7308
env1_first_0:                 episode reward: -2.1000,                 loss: nan
env1_second_0:                 episode reward: 2.1000,                 loss: nan
Episode: 34141/50000 (68.2820%),                 avg. length: 538.7,                last time consumption/overall running time: 33.7758s / 60073.2026 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.1543
env0_second_0:                 episode reward: 3.6000,                 loss: 0.3863
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 34161/50000 (68.3220%),                 avg. length: 547.85,                last time consumption/overall running time: 33.8295s / 60107.0321 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.1336
env0_second_0:                 episode reward: 4.0000,                 loss: 0.3432
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 34181/50000 (68.3620%),                 avg. length: 515.85,                last time consumption/overall running time: 31.6577s / 60138.6898 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.1308
env0_second_0:                 episode reward: 4.0000,                 loss: 0.3449
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 34201/50000 (68.4020%),                 avg. length: 545.5,                last time consumption/overall running time: 33.3379s / 60172.0276 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.1292
env0_second_0:                 episode reward: 3.9500,                 loss: 0.3578
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 34221/50000 (68.4420%),                 avg. length: 551.65,                last time consumption/overall running time: 33.7298s / 60205.7574 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.1391
env0_second_0:                 episode reward: 3.6000,                 loss: 0.2915
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 34241/50000 (68.4820%),                 avg. length: 603.8,                last time consumption/overall running time: 36.5781s / 60242.3355 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.0761
env0_second_0:                 episode reward: 4.0000,                 loss: 0.2372
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 34261/50000 (68.5220%),                 avg. length: 610.75,                last time consumption/overall running time: 36.6402s / 60278.9757 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.1075
env0_second_0:                 episode reward: 3.5500,                 loss: 0.3135
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 34281/50000 (68.5620%),                 avg. length: 545.4,                last time consumption/overall running time: 34.6627s / 60313.6384 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.0992
env0_second_0:                 episode reward: 3.8000,                 loss: 0.2298
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 34301/50000 (68.6020%),                 avg. length: 561.15,                last time consumption/overall running time: 35.4490s / 60349.0874 s
env0_first_0:                 episode reward: -3.2000,                 loss: 0.1216
env0_second_0:                 episode reward: 3.2000,                 loss: 0.2653
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 34321/50000 (68.6420%),                 avg. length: 592.8,                last time consumption/overall running time: 35.6301s / 60384.7175 s
env0_first_0:                 episode reward: -3.2500,                 loss: 0.1064
env0_second_0:                 episode reward: 3.2500,                 loss: 0.2664
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 34341/50000 (68.6820%),                 avg. length: 609.85,                last time consumption/overall running time: 37.5817s / 60422.2991 s
env0_first_0:                 episode reward: -3.3500,                 loss: 0.1011
env0_second_0:                 episode reward: 3.3500,                 loss: 0.2443
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 34361/50000 (68.7220%),                 avg. length: 612.0,                last time consumption/overall running time: 38.6309s / 60460.9301 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.0965
env0_second_0:                 episode reward: 3.6500,                 loss: 0.2678
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 34381/50000 (68.7620%),                 avg. length: 597.95,                last time consumption/overall running time: 38.3445s / 60499.2746 s
env0_first_0:                 episode reward: -4.3000,                 loss: 0.1161
env0_second_0:                 episode reward: 4.3000,                 loss: 0.2866
env1_first_0:                 episode reward: -2.9500,                 loss: nan
env1_second_0:                 episode reward: 2.9500,                 loss: nan
Episode: 34401/50000 (68.8020%),                 avg. length: 658.65,                last time consumption/overall running time: 39.7304s / 60539.0050 s
env0_first_0:                 episode reward: -3.3500,                 loss: 0.1026
env0_second_0:                 episode reward: 3.3500,                 loss: 0.2931
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 34421/50000 (68.8420%),                 avg. length: 585.55,                last time consumption/overall running time: 34.8767s / 60573.8817 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.0905
env0_second_0:                 episode reward: 3.4500,                 loss: 0.2806
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 34441/50000 (68.8820%),                 avg. length: 558.1,                last time consumption/overall running time: 33.5824s / 60607.4641 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.1543
env0_second_0:                 episode reward: 3.4500,                 loss: 0.3086
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 34461/50000 (68.9220%),                 avg. length: 541.6,                last time consumption/overall running time: 33.4485s / 60640.9126 s
env0_first_0:                 episode reward: -3.1000,                 loss: 0.1436
env0_second_0:                 episode reward: 3.1000,                 loss: 0.3214
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 34481/50000 (68.9620%),                 avg. length: 529.0,                last time consumption/overall running time: 32.3035s / 60673.2162 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.1356
env0_second_0:                 episode reward: 3.9000,                 loss: 0.2819
env1_first_0:                 episode reward: -3.0500,                 loss: nan
env1_second_0:                 episode reward: 3.0500,                 loss: nan
Episode: 34501/50000 (69.0020%),                 avg. length: 521.65,                last time consumption/overall running time: 31.7755s / 60704.9917 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.1085
env0_second_0:                 episode reward: 3.8500,                 loss: 0.2414
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 34521/50000 (69.0420%),                 avg. length: 556.85,                last time consumption/overall running time: 33.7382s / 60738.7299 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.1375
env0_second_0:                 episode reward: 3.6000,                 loss: 0.2843
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 34541/50000 (69.0820%),                 avg. length: 496.7,                last time consumption/overall running time: 30.5481s / 60769.2780 s
env0_first_0:                 episode reward: -4.1000,                 loss: 0.1468
env0_second_0:                 episode reward: 4.1000,                 loss: 0.2846
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 34561/50000 (69.1220%),                 avg. length: 547.75,                last time consumption/overall running time: 33.1031s / 60802.3811 s
env0_first_0:                 episode reward: -4.1000,                 loss: 0.1242
env0_second_0:                 episode reward: 4.1000,                 loss: 0.2939
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 34581/50000 (69.1620%),                 avg. length: 622.9,                last time consumption/overall running time: 37.9531s / 60840.3342 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.1004
env0_second_0:                 episode reward: 3.6500,                 loss: 0.2823
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 34601/50000 (69.2020%),                 avg. length: 534.1,                last time consumption/overall running time: 32.2216s / 60872.5558 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.0873
env0_second_0:                 episode reward: 4.0000,                 loss: 0.2276
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 34621/50000 (69.2420%),                 avg. length: 644.15,                last time consumption/overall running time: 37.8674s / 60910.4232 s
env0_first_0:                 episode reward: -4.1000,                 loss: 0.0658
env0_second_0:                 episode reward: 4.1000,                 loss: 0.1983
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 34641/50000 (69.2820%),                 avg. length: 554.45,                last time consumption/overall running time: 35.0150s / 60945.4382 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.1601
env0_second_0:                 episode reward: 3.4500,                 loss: 0.3973
env1_first_0:                 episode reward: -4.1500,                 loss: nan
env1_second_0:                 episode reward: 4.1500,                 loss: nan
Episode: 34661/50000 (69.3220%),                 avg. length: 543.55,                last time consumption/overall running time: 35.8906s / 60981.3288 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.1247
env0_second_0:                 episode reward: 3.5000,                 loss: 0.2715
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 34681/50000 (69.3620%),                 avg. length: 526.55,                last time consumption/overall running time: 32.2589s / 61013.5877 s
env0_first_0:                 episode reward: -4.1000,                 loss: 0.1076
env0_second_0:                 episode reward: 4.1000,                 loss: 0.2193
env1_first_0:                 episode reward: -3.3500,                 loss: nan
env1_second_0:                 episode reward: 3.3500,                 loss: nan
Episode: 34701/50000 (69.4020%),                 avg. length: 573.1,                last time consumption/overall running time: 34.5229s / 61048.1106 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.1055
env0_second_0:                 episode reward: 3.8000,                 loss: 0.2074
env1_first_0:                 episode reward: -3.5000,                 loss: nan
env1_second_0:                 episode reward: 3.5000,                 loss: nan
Episode: 34721/50000 (69.4420%),                 avg. length: 584.6,                last time consumption/overall running time: 35.3503s / 61083.4609 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.1132
env0_second_0:                 episode reward: 3.6500,                 loss: 0.2440
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 34741/50000 (69.4820%),                 avg. length: 632.4,                last time consumption/overall running time: 38.4622s / 61121.9231 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.0762
env0_second_0:                 episode reward: 3.6500,                 loss: 0.2638
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 34761/50000 (69.5220%),                 avg. length: 599.15,                last time consumption/overall running time: 35.8574s / 61157.7805 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.0638
env0_second_0:                 episode reward: 3.7000,                 loss: 0.1589
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 34781/50000 (69.5620%),                 avg. length: 547.7,                last time consumption/overall running time: 33.1987s / 61190.9792 s
env0_first_0:                 episode reward: -3.2500,                 loss: 0.0910
env0_second_0:                 episode reward: 3.2500,                 loss: 0.2010
env1_first_0:                 episode reward: -4.2500,                 loss: nan
env1_second_0:                 episode reward: 4.2500,                 loss: nan
Episode: 34801/50000 (69.6020%),                 avg. length: 561.35,                last time consumption/overall running time: 33.7906s / 61224.7698 s
env0_first_0:                 episode reward: -3.7500,                 loss: 0.1089
env0_second_0:                 episode reward: 3.7500,                 loss: 0.2824
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 34821/50000 (69.6420%),                 avg. length: 572.9,                last time consumption/overall running time: 34.4016s / 61259.1714 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.1087
env0_second_0:                 episode reward: 3.8500,                 loss: 0.2294
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 34841/50000 (69.6820%),                 avg. length: 575.45,                last time consumption/overall running time: 34.9408s / 61294.1122 s
env0_first_0:                 episode reward: -4.1000,                 loss: 0.1063
env0_second_0:                 episode reward: 4.1000,                 loss: 0.2483
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 34861/50000 (69.7220%),                 avg. length: 573.0,                last time consumption/overall running time: 34.5233s / 61328.6355 s
env0_first_0:                 episode reward: -4.0500,                 loss: 0.0994
env0_second_0:                 episode reward: 4.0500,                 loss: 0.3430
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 34881/50000 (69.7620%),                 avg. length: 572.45,                last time consumption/overall running time: 34.4542s / 61363.0897 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.1052
env0_second_0:                 episode reward: 3.5000,                 loss: 0.2860
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 34901/50000 (69.8020%),                 avg. length: 534.1,                last time consumption/overall running time: 32.7108s / 61395.8005 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.1454
env0_second_0:                 episode reward: 4.0000,                 loss: 0.3588
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 34921/50000 (69.8420%),                 avg. length: 569.0,                last time consumption/overall running time: 35.2422s / 61431.0427 s
env0_first_0:                 episode reward: -4.0500,                 loss: 0.0913
env0_second_0:                 episode reward: 4.0500,                 loss: 0.2786
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 34941/50000 (69.8820%),                 avg. length: 597.15,                last time consumption/overall running time: 36.8725s / 61467.9152 s
env0_first_0:                 episode reward: -3.2500,                 loss: 0.1270
env0_second_0:                 episode reward: 3.2500,                 loss: 0.3386
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 34961/50000 (69.9220%),                 avg. length: 581.55,                last time consumption/overall running time: 35.0132s / 61502.9285 s
env0_first_0:                 episode reward: -3.1500,                 loss: 0.1560
env0_second_0:                 episode reward: 3.1500,                 loss: 0.3535
env1_first_0:                 episode reward: -2.9500,                 loss: nan
env1_second_0:                 episode reward: 2.9500,                 loss: nan
Episode: 34981/50000 (69.9620%),                 avg. length: 567.55,                last time consumption/overall running time: 34.5064s / 61537.4348 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.1075
env0_second_0:                 episode reward: 3.6500,                 loss: 0.2584
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 35001/50000 (70.0020%),                 avg. length: 527.55,                last time consumption/overall running time: 33.1162s / 61570.5510 s
env0_first_0:                 episode reward: -4.1000,                 loss: 0.1292
env0_second_0:                 episode reward: 4.1000,                 loss: 0.3091
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 35021/50000 (70.0420%),                 avg. length: 545.1,                last time consumption/overall running time: 34.2581s / 61604.8091 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.1379
env0_second_0:                 episode reward: 3.7000,                 loss: 0.3160
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 35041/50000 (70.0820%),                 avg. length: 541.45,                last time consumption/overall running time: 33.1585s / 61637.9676 s
env0_first_0:                 episode reward: -3.2000,                 loss: 0.1472
env0_second_0:                 episode reward: 3.2000,                 loss: 0.3041
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 35061/50000 (70.1220%),                 avg. length: 544.45,                last time consumption/overall running time: 33.3433s / 61671.3109 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.1005
env0_second_0:                 episode reward: 3.7000,                 loss: 0.2689
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 35081/50000 (70.1620%),                 avg. length: 571.0,                last time consumption/overall running time: 34.5965s / 61705.9073 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.0975
env0_second_0:                 episode reward: 3.9500,                 loss: 0.2834
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 35101/50000 (70.2020%),                 avg. length: 582.2,                last time consumption/overall running time: 35.7160s / 61741.6233 s
env0_first_0:                 episode reward: -3.3500,                 loss: 0.1227
env0_second_0:                 episode reward: 3.3500,                 loss: 0.3033
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 35121/50000 (70.2420%),                 avg. length: 587.75,                last time consumption/overall running time: 35.2659s / 61776.8892 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.0797
env0_second_0:                 episode reward: 3.9500,                 loss: 0.2385
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 35141/50000 (70.2820%),                 avg. length: 592.95,                last time consumption/overall running time: 35.3118s / 61812.2011 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.1023
env0_second_0:                 episode reward: 3.4500,                 loss: 0.2195
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 35161/50000 (70.3220%),                 avg. length: 512.85,                last time consumption/overall running time: 32.0851s / 61844.2862 s
env0_first_0:                 episode reward: -3.7500,                 loss: 0.1353
env0_second_0:                 episode reward: 3.7500,                 loss: 0.2910
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 35181/50000 (70.3620%),                 avg. length: 583.55,                last time consumption/overall running time: 35.7837s / 61880.0699 s
env0_first_0:                 episode reward: -4.5500,                 loss: 0.1145
env0_second_0:                 episode reward: 4.5500,                 loss: 0.2141
env1_first_0:                 episode reward: -2.9500,                 loss: nan
env1_second_0:                 episode reward: 2.9500,                 loss: nan
Episode: 35201/50000 (70.4020%),                 avg. length: 566.65,                last time consumption/overall running time: 34.3218s / 61914.3917 s
env0_first_0:                 episode reward: -4.4500,                 loss: 0.0853
env0_second_0:                 episode reward: 4.4500,                 loss: 0.2159
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 35221/50000 (70.4420%),                 avg. length: 538.45,                last time consumption/overall running time: 32.6858s / 61947.0775 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.1046
env0_second_0:                 episode reward: 3.8000,                 loss: 0.2377
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 35241/50000 (70.4820%),                 avg. length: 588.65,                last time consumption/overall running time: 35.1990s / 61982.2765 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.1104
env0_second_0:                 episode reward: 3.5500,                 loss: 0.2292
env1_first_0:                 episode reward: -3.5000,                 loss: nan
env1_second_0:                 episode reward: 3.5000,                 loss: nan
Episode: 35261/50000 (70.5220%),                 avg. length: 566.25,                last time consumption/overall running time: 35.6713s / 62017.9478 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.1122
env0_second_0:                 episode reward: 3.5500,                 loss: 0.2301
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 35281/50000 (70.5620%),                 avg. length: 619.6,                last time consumption/overall running time: 42.7031s / 62060.6509 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.1264
env0_second_0:                 episode reward: 3.4500,                 loss: 0.3859
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 35301/50000 (70.6020%),                 avg. length: 578.55,                last time consumption/overall running time: 35.1874s / 62095.8383 s
env0_first_0:                 episode reward: -4.3000,                 loss: 0.1274
env0_second_0:                 episode reward: 4.3000,                 loss: 0.2800
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 35321/50000 (70.6420%),                 avg. length: 528.7,                last time consumption/overall running time: 32.5354s / 62128.3737 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.1251
env0_second_0:                 episode reward: 3.6000,                 loss: 0.2176
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 35341/50000 (70.6820%),                 avg. length: 588.4,                last time consumption/overall running time: 35.6384s / 62164.0121 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.1090
env0_second_0:                 episode reward: 3.8000,                 loss: 0.2279
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 35361/50000 (70.7220%),                 avg. length: 557.2,                last time consumption/overall running time: 34.6600s / 62198.6721 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.1515
env0_second_0:                 episode reward: 3.8000,                 loss: 0.3774
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 35381/50000 (70.7620%),                 avg. length: 557.05,                last time consumption/overall running time: 35.2408s / 62233.9129 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.0935
env0_second_0:                 episode reward: 3.6000,                 loss: 0.2702
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 35401/50000 (70.8020%),                 avg. length: 573.15,                last time consumption/overall running time: 34.6323s / 62268.5452 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.1113
env0_second_0:                 episode reward: 3.6500,                 loss: 0.2314
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 35421/50000 (70.8420%),                 avg. length: 548.0,                last time consumption/overall running time: 33.6009s / 62302.1461 s
env0_first_0:                 episode reward: -3.0500,                 loss: 0.1240
env0_second_0:                 episode reward: 3.0500,                 loss: 0.2514
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 35441/50000 (70.8820%),                 avg. length: 609.2,                last time consumption/overall running time: 36.5468s / 62338.6929 s
env0_first_0:                 episode reward: -3.4000,                 loss: 0.1455
env0_second_0:                 episode reward: 3.4000,                 loss: 0.2809
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 35461/50000 (70.9220%),                 avg. length: 589.4,                last time consumption/overall running time: 35.5032s / 62374.1961 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.1306
env0_second_0:                 episode reward: 3.9500,                 loss: 0.2399
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 35481/50000 (70.9620%),                 avg. length: 552.2,                last time consumption/overall running time: 33.5201s / 62407.7162 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.1542
env0_second_0:                 episode reward: 3.6000,                 loss: 0.3020
env1_first_0:                 episode reward: -3.1500,                 loss: nan
env1_second_0:                 episode reward: 3.1500,                 loss: nan
Episode: 35501/50000 (71.0020%),                 avg. length: 553.9,                last time consumption/overall running time: 33.8670s / 62441.5831 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.1318
env0_second_0:                 episode reward: 3.5000,                 loss: 0.2430
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 35521/50000 (71.0420%),                 avg. length: 583.35,                last time consumption/overall running time: 35.5625s / 62477.1457 s
env0_first_0:                 episode reward: -3.3500,                 loss: 0.0790
env0_second_0:                 episode reward: 3.3500,                 loss: 0.1970
env1_first_0:                 episode reward: -4.2000,                 loss: nan
env1_second_0:                 episode reward: 4.2000,                 loss: nan
Episode: 35541/50000 (71.0820%),                 avg. length: 572.95,                last time consumption/overall running time: 35.1449s / 62512.2905 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.0870
env0_second_0:                 episode reward: 3.6000,                 loss: 0.2001
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 35561/50000 (71.1220%),                 avg. length: 550.35,                last time consumption/overall running time: 33.7124s / 62546.0029 s
env0_first_0:                 episode reward: -3.2000,                 loss: 0.1242
env0_second_0:                 episode reward: 3.2000,                 loss: 0.2269
env1_first_0:                 episode reward: -4.1500,                 loss: nan
env1_second_0:                 episode reward: 4.1500,                 loss: nan
Episode: 35581/50000 (71.1620%),                 avg. length: 535.05,                last time consumption/overall running time: 33.1108s / 62579.1137 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.1331
env0_second_0:                 episode reward: 4.0000,                 loss: 0.3007
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 35601/50000 (71.2020%),                 avg. length: 563.25,                last time consumption/overall running time: 34.3410s / 62613.4547 s
env0_first_0:                 episode reward: -4.2500,                 loss: 0.1324
env0_second_0:                 episode reward: 4.2500,                 loss: 0.2611
env1_first_0:                 episode reward: -3.2500,                 loss: nan
env1_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 35621/50000 (71.2420%),                 avg. length: 572.85,                last time consumption/overall running time: 35.5079s / 62648.9625 s
env0_first_0:                 episode reward: -4.1000,                 loss: 0.0956
env0_second_0:                 episode reward: 4.1000,                 loss: 0.2632
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 35641/50000 (71.2820%),                 avg. length: 537.95,                last time consumption/overall running time: 33.0112s / 62681.9738 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.1183
env0_second_0:                 episode reward: 3.9500,                 loss: 0.2376
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 35661/50000 (71.3220%),                 avg. length: 565.95,                last time consumption/overall running time: 34.2488s / 62716.2225 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.1457
env0_second_0:                 episode reward: 3.7000,                 loss: 0.2940
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 35681/50000 (71.3620%),                 avg. length: 573.2,                last time consumption/overall running time: 34.7446s / 62750.9671 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.0869
env0_second_0:                 episode reward: 3.5500,                 loss: 0.2490
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 35701/50000 (71.4020%),                 avg. length: 552.15,                last time consumption/overall running time: 33.6031s / 62784.5703 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.1050
env0_second_0:                 episode reward: 3.7000,                 loss: 0.2351
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 35721/50000 (71.4420%),                 avg. length: 517.2,                last time consumption/overall running time: 32.0546s / 62816.6248 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.1225
env0_second_0:                 episode reward: 3.7000,                 loss: 0.2366
env1_first_0:                 episode reward: -3.3500,                 loss: nan
env1_second_0:                 episode reward: 3.3500,                 loss: nan
Episode: 35741/50000 (71.4820%),                 avg. length: 572.55,                last time consumption/overall running time: 34.8579s / 62851.4827 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.1078
env0_second_0:                 episode reward: 3.9000,                 loss: 0.2062
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 35761/50000 (71.5220%),                 avg. length: 628.95,                last time consumption/overall running time: 37.6741s / 62889.1568 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.0775
env0_second_0:                 episode reward: 3.8500,                 loss: 0.1884
env1_first_0:                 episode reward: -4.1500,                 loss: nan
env1_second_0:                 episode reward: 4.1500,                 loss: nan
Episode: 35781/50000 (71.5620%),                 avg. length: 566.95,                last time consumption/overall running time: 34.6890s / 62923.8458 s
env0_first_0:                 episode reward: -4.2500,                 loss: 0.0785
env0_second_0:                 episode reward: 4.2500,                 loss: 0.1743
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 35801/50000 (71.6020%),                 avg. length: 551.5,                last time consumption/overall running time: 34.1154s / 62957.9612 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.1403
env0_second_0:                 episode reward: 4.0000,                 loss: 0.2871
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 35821/50000 (71.6420%),                 avg. length: 562.5,                last time consumption/overall running time: 35.5628s / 62993.5240 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.1510
env0_second_0:                 episode reward: 3.8000,                 loss: 0.2332
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 35841/50000 (71.6820%),                 avg. length: 558.75,                last time consumption/overall running time: 35.3153s / 63028.8393 s
env0_first_0:                 episode reward: -4.1000,                 loss: 0.1263
env0_second_0:                 episode reward: 4.1000,                 loss: 0.2422
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 35861/50000 (71.7220%),                 avg. length: 551.75,                last time consumption/overall running time: 34.9660s / 63063.8053 s
env0_first_0:                 episode reward: -4.2000,                 loss: 0.1000
env0_second_0:                 episode reward: 4.2000,                 loss: 0.2076
env1_first_0:                 episode reward: -4.2500,                 loss: nan
env1_second_0:                 episode reward: 4.2500,                 loss: nan
Episode: 35881/50000 (71.7620%),                 avg. length: 550.75,                last time consumption/overall running time: 34.4010s / 63098.2063 s
env0_first_0:                 episode reward: -4.2500,                 loss: 0.1130
env0_second_0:                 episode reward: 4.2500,                 loss: 0.2285
env1_first_0:                 episode reward: -3.1000,                 loss: nan
env1_second_0:                 episode reward: 3.1000,                 loss: nan
Episode: 35901/50000 (71.8020%),                 avg. length: 570.4,                last time consumption/overall running time: 34.7461s / 63132.9524 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.1310
env0_second_0:                 episode reward: 3.8500,                 loss: 0.2453
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 35921/50000 (71.8420%),                 avg. length: 557.4,                last time consumption/overall running time: 34.2265s / 63167.1789 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.1117
env0_second_0:                 episode reward: 3.8000,                 loss: 0.2639
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 35941/50000 (71.8820%),                 avg. length: 575.6,                last time consumption/overall running time: 35.3448s / 63202.5237 s
env0_first_0:                 episode reward: -3.4000,                 loss: 0.1332
env0_second_0:                 episode reward: 3.4000,                 loss: 0.3071
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 35961/50000 (71.9220%),                 avg. length: 540.65,                last time consumption/overall running time: 32.9745s / 63235.4982 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.1565
env0_second_0:                 episode reward: 3.8500,                 loss: 0.4537
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 35981/50000 (71.9620%),                 avg. length: 544.75,                last time consumption/overall running time: 33.3181s / 63268.8163 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.1257
env0_second_0:                 episode reward: 3.9500,                 loss: 0.3654
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 36001/50000 (72.0020%),                 avg. length: 560.45,                last time consumption/overall running time: 34.1280s / 63302.9444 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.0864
env0_second_0:                 episode reward: 3.5500,                 loss: 0.3005
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 36021/50000 (72.0420%),                 avg. length: 591.0,                last time consumption/overall running time: 36.1929s / 63339.1373 s
env0_first_0:                 episode reward: -4.0500,                 loss: 0.1120
env0_second_0:                 episode reward: 4.0500,                 loss: 0.3063
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 36041/50000 (72.0820%),                 avg. length: 596.85,                last time consumption/overall running time: 36.8131s / 63375.9504 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.1071
env0_second_0:                 episode reward: 3.6000,                 loss: 0.2858
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 36061/50000 (72.1220%),                 avg. length: 549.0,                last time consumption/overall running time: 34.6157s / 63410.5661 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.0941
env0_second_0:                 episode reward: 3.6500,                 loss: 0.2709
env1_first_0:                 episode reward: -4.2500,                 loss: nan
env1_second_0:                 episode reward: 4.2500,                 loss: nan
Episode: 36081/50000 (72.1620%),                 avg. length: 569.7,                last time consumption/overall running time: 35.7025s / 63446.2686 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.0917
env0_second_0:                 episode reward: 3.8000,                 loss: 0.2614
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 36101/50000 (72.2020%),                 avg. length: 533.05,                last time consumption/overall running time: 33.4434s / 63479.7121 s
env0_first_0:                 episode reward: -4.4000,                 loss: 0.1112
env0_second_0:                 episode reward: 4.4000,                 loss: 0.2675
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 36121/50000 (72.2420%),                 avg. length: 543.25,                last time consumption/overall running time: 33.4653s / 63513.1773 s
env0_first_0:                 episode reward: -4.2500,                 loss: 0.1041
env0_second_0:                 episode reward: 4.2500,                 loss: 0.2379
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 36141/50000 (72.2820%),                 avg. length: 582.0,                last time consumption/overall running time: 36.0942s / 63549.2715 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.0855
env0_second_0:                 episode reward: 3.5500,                 loss: 0.2369
env1_first_0:                 episode reward: -4.4000,                 loss: nan
env1_second_0:                 episode reward: 4.4000,                 loss: nan
Episode: 36161/50000 (72.3220%),                 avg. length: 579.7,                last time consumption/overall running time: 35.9784s / 63585.2500 s
env0_first_0:                 episode reward: -3.3000,                 loss: 0.1150
env0_second_0:                 episode reward: 3.3000,                 loss: 0.2625
env1_first_0:                 episode reward: -4.2000,                 loss: nan
env1_second_0:                 episode reward: 4.2000,                 loss: nan
Episode: 36181/50000 (72.3620%),                 avg. length: 624.45,                last time consumption/overall running time: 37.6977s / 63622.9476 s
env0_first_0:                 episode reward: -3.7500,                 loss: 0.1262
env0_second_0:                 episode reward: 3.7500,                 loss: 0.4509
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 36201/50000 (72.4020%),                 avg. length: 546.8,                last time consumption/overall running time: 34.2274s / 63657.1750 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.1204
env0_second_0:                 episode reward: 3.9500,                 loss: 0.2445
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 36221/50000 (72.4420%),                 avg. length: 585.85,                last time consumption/overall running time: 36.2468s / 63693.4218 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.1293
env0_second_0:                 episode reward: 3.5000,                 loss: 0.3021
env1_first_0:                 episode reward: -4.2500,                 loss: nan
env1_second_0:                 episode reward: 4.2500,                 loss: nan
Episode: 36241/50000 (72.4820%),                 avg. length: 575.1,                last time consumption/overall running time: 37.1171s / 63730.5389 s
env0_first_0:                 episode reward: -4.1000,                 loss: 0.1374
env0_second_0:                 episode reward: 4.1000,                 loss: 0.2743
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 36261/50000 (72.5220%),                 avg. length: 562.25,                last time consumption/overall running time: 35.3196s / 63765.8584 s
env0_first_0:                 episode reward: -4.1500,                 loss: 0.1335
env0_second_0:                 episode reward: 4.1500,                 loss: 0.2541
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 36281/50000 (72.5620%),                 avg. length: 602.95,                last time consumption/overall running time: 37.0017s / 63802.8601 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.1335
env0_second_0:                 episode reward: 3.8000,                 loss: 0.2974
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 36301/50000 (72.6020%),                 avg. length: 561.65,                last time consumption/overall running time: 36.0160s / 63838.8761 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.1221
env0_second_0:                 episode reward: 3.9500,                 loss: 0.3260
env1_first_0:                 episode reward: -3.2500,                 loss: nan
env1_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 36321/50000 (72.6420%),                 avg. length: 542.7,                last time consumption/overall running time: 32.9001s / 63871.7763 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.1149
env0_second_0:                 episode reward: 3.9500,                 loss: 0.2901
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 36341/50000 (72.6820%),                 avg. length: 588.7,                last time consumption/overall running time: 35.7417s / 63907.5179 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.1236
env0_second_0:                 episode reward: 3.8500,                 loss: 0.2896
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 36361/50000 (72.7220%),                 avg. length: 560.45,                last time consumption/overall running time: 34.8713s / 63942.3892 s
env0_first_0:                 episode reward: -4.2000,                 loss: 0.1055
env0_second_0:                 episode reward: 4.2000,                 loss: 0.2619
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 36381/50000 (72.7620%),                 avg. length: 531.2,                last time consumption/overall running time: 33.2401s / 63975.6293 s
env0_first_0:                 episode reward: -3.4000,                 loss: 0.1485
env0_second_0:                 episode reward: 3.4000,                 loss: 0.3576
env1_first_0:                 episode reward: -4.2500,                 loss: nan
env1_second_0:                 episode reward: 4.2500,                 loss: nan
Episode: 36401/50000 (72.8020%),                 avg. length: 552.55,                last time consumption/overall running time: 33.8085s / 64009.4379 s
env0_first_0:                 episode reward: -3.4000,                 loss: 0.1180
env0_second_0:                 episode reward: 3.4000,                 loss: 0.7373
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 36421/50000 (72.8420%),                 avg. length: 536.4,                last time consumption/overall running time: 32.6836s / 64042.1215 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.1031
env0_second_0:                 episode reward: 4.0000,                 loss: 0.5244
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 36441/50000 (72.8820%),                 avg. length: 549.15,                last time consumption/overall running time: 33.1945s / 64075.3160 s
env0_first_0:                 episode reward: -3.3500,                 loss: 0.1234
env0_second_0:                 episode reward: 3.3500,                 loss: 0.4108
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 36461/50000 (72.9220%),                 avg. length: 526.7,                last time consumption/overall running time: 32.5212s / 64107.8371 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.1512
env0_second_0:                 episode reward: 3.6500,                 loss: 0.3410
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 36481/50000 (72.9620%),                 avg. length: 570.4,                last time consumption/overall running time: 34.2063s / 64142.0435 s
env0_first_0:                 episode reward: -3.4000,                 loss: 0.1142
env0_second_0:                 episode reward: 3.4000,                 loss: 0.3082
env1_first_0:                 episode reward: -4.1500,                 loss: nan
env1_second_0:                 episode reward: 4.1500,                 loss: nan
Episode: 36501/50000 (73.0020%),                 avg. length: 563.95,                last time consumption/overall running time: 34.0015s / 64176.0449 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.1034
env0_second_0:                 episode reward: 4.0000,                 loss: 0.2986
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 36521/50000 (73.0420%),                 avg. length: 579.95,                last time consumption/overall running time: 34.7876s / 64210.8325 s
env0_first_0:                 episode reward: -4.3000,                 loss: 0.1126
env0_second_0:                 episode reward: 4.3000,                 loss: 0.2460
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 36541/50000 (73.0820%),                 avg. length: 581.3,                last time consumption/overall running time: 34.8870s / 64245.7196 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.0834
env0_second_0:                 episode reward: 3.7000,                 loss: 0.2467
env1_first_0:                 episode reward: -4.2000,                 loss: nan
env1_second_0:                 episode reward: 4.2000,                 loss: nan
Episode: 36561/50000 (73.1220%),                 avg. length: 545.6,                last time consumption/overall running time: 33.2409s / 64278.9604 s
env0_first_0:                 episode reward: -4.4500,                 loss: 0.1098
env0_second_0:                 episode reward: 4.4500,                 loss: 0.2694
env1_first_0:                 episode reward: -3.1000,                 loss: nan
env1_second_0:                 episode reward: 3.1000,                 loss: nan
Episode: 36581/50000 (73.1620%),                 avg. length: 618.3,                last time consumption/overall running time: 36.6119s / 64315.5723 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.0847
env0_second_0:                 episode reward: 3.7000,                 loss: 0.2990
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 36601/50000 (73.2020%),                 avg. length: 544.65,                last time consumption/overall running time: 32.9509s / 64348.5232 s
env0_first_0:                 episode reward: -4.1000,                 loss: 0.1030
env0_second_0:                 episode reward: 4.1000,                 loss: 0.3127
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 36621/50000 (73.2420%),                 avg. length: 573.2,                last time consumption/overall running time: 35.4843s / 64384.0076 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.0911
env0_second_0:                 episode reward: 3.6000,                 loss: 0.3847
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 36641/50000 (73.2820%),                 avg. length: 564.95,                last time consumption/overall running time: 33.8567s / 64417.8642 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.0873
env0_second_0:                 episode reward: 3.8500,                 loss: 0.2192
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 36661/50000 (73.3220%),                 avg. length: 581.95,                last time consumption/overall running time: 35.0121s / 64452.8764 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.1189
env0_second_0:                 episode reward: 3.9000,                 loss: 0.3895
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 36681/50000 (73.3620%),                 avg. length: 569.2,                last time consumption/overall running time: 34.7638s / 64487.6402 s
env0_first_0:                 episode reward: -4.3000,                 loss: 0.0799
env0_second_0:                 episode reward: 4.3000,                 loss: 0.3436
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 36701/50000 (73.4020%),                 avg. length: 559.9,                last time consumption/overall running time: 34.3458s / 64521.9860 s
env0_first_0:                 episode reward: -4.1000,                 loss: 0.0828
env0_second_0:                 episode reward: 4.1000,                 loss: 0.2535
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 36721/50000 (73.4420%),                 avg. length: 545.9,                last time consumption/overall running time: 33.1064s / 64555.0924 s
env0_first_0:                 episode reward: -4.2500,                 loss: 0.0799
env0_second_0:                 episode reward: 4.2500,                 loss: 0.2166
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 36741/50000 (73.4820%),                 avg. length: 535.25,                last time consumption/overall running time: 32.6277s / 64587.7201 s
env0_first_0:                 episode reward: -3.3000,                 loss: 0.0981
env0_second_0:                 episode reward: 3.3000,                 loss: 0.2531
env1_first_0:                 episode reward: -4.2500,                 loss: nan
env1_second_0:                 episode reward: 4.2500,                 loss: nan
Episode: 36761/50000 (73.5220%),                 avg. length: 563.5,                last time consumption/overall running time: 33.9065s / 64621.6266 s
env0_first_0:                 episode reward: -3.3500,                 loss: 0.1155
env0_second_0:                 episode reward: 3.3500,                 loss: 0.3326
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 36781/50000 (73.5620%),                 avg. length: 563.35,                last time consumption/overall running time: 34.4074s / 64656.0339 s
env0_first_0:                 episode reward: -4.0500,                 loss: 0.1134
env0_second_0:                 episode reward: 4.0500,                 loss: 0.2467
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 36801/50000 (73.6020%),                 avg. length: 554.25,                last time consumption/overall running time: 33.5063s / 64689.5402 s
env0_first_0:                 episode reward: -3.7500,                 loss: 0.1200
env0_second_0:                 episode reward: 3.7500,                 loss: 0.3635
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 36821/50000 (73.6420%),                 avg. length: 614.45,                last time consumption/overall running time: 36.5153s / 64726.0554 s
env0_first_0:                 episode reward: -3.2500,                 loss: 0.1631
env0_second_0:                 episode reward: 3.2500,                 loss: 0.3530
env1_first_0:                 episode reward: -3.2500,                 loss: nan
env1_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 36841/50000 (73.6820%),                 avg. length: 566.6,                last time consumption/overall running time: 34.2679s / 64760.3234 s
env0_first_0:                 episode reward: -3.7500,                 loss: 0.1159
env0_second_0:                 episode reward: 3.7500,                 loss: 0.2350
env1_first_0:                 episode reward: -4.2500,                 loss: nan
env1_second_0:                 episode reward: 4.2500,                 loss: nan
Episode: 36861/50000 (73.7220%),                 avg. length: 536.5,                last time consumption/overall running time: 32.5697s / 64792.8931 s
env0_first_0:                 episode reward: -3.7500,                 loss: 0.0961
env0_second_0:                 episode reward: 3.7500,                 loss: 0.2658
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 36881/50000 (73.7620%),                 avg. length: 563.2,                last time consumption/overall running time: 37.8042s / 64830.6974 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.1243
env0_second_0:                 episode reward: 3.4500,                 loss: 0.2802
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 36901/50000 (73.8020%),                 avg. length: 598.4,                last time consumption/overall running time: 35.8340s / 64866.5314 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.1246
env0_second_0:                 episode reward: 3.6000,                 loss: 0.2998
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 36921/50000 (73.8420%),                 avg. length: 583.0,                last time consumption/overall running time: 35.7636s / 64902.2950 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.0795
env0_second_0:                 episode reward: 3.8500,                 loss: 0.2153
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 36941/50000 (73.8820%),                 avg. length: 543.1,                last time consumption/overall running time: 33.5841s / 64935.8791 s
env0_first_0:                 episode reward: -4.1500,                 loss: 0.1232
env0_second_0:                 episode reward: 4.1500,                 loss: 0.2484
env1_first_0:                 episode reward: -3.5000,                 loss: nan
env1_second_0:                 episode reward: 3.5000,                 loss: nan
Episode: 36961/50000 (73.9220%),                 avg. length: 558.5,                last time consumption/overall running time: 34.0812s / 64969.9603 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.1074
env0_second_0:                 episode reward: 3.7000,                 loss: 0.2660
env1_first_0:                 episode reward: -4.2000,                 loss: nan
env1_second_0:                 episode reward: 4.2000,                 loss: nan
Episode: 36981/50000 (73.9620%),                 avg. length: 571.55,                last time consumption/overall running time: 34.7260s / 65004.6863 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.1110
env0_second_0:                 episode reward: 3.9500,                 loss: 0.2789
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 37001/50000 (74.0020%),                 avg. length: 551.85,                last time consumption/overall running time: 33.3706s / 65038.0569 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.1477
env0_second_0:                 episode reward: 3.6000,                 loss: 0.2875
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 37021/50000 (74.0420%),                 avg. length: 540.2,                last time consumption/overall running time: 32.6443s / 65070.7012 s
env0_first_0:                 episode reward: -4.0500,                 loss: 0.1508
env0_second_0:                 episode reward: 4.0500,                 loss: 0.2932
env1_first_0:                 episode reward: -3.5000,                 loss: nan
env1_second_0:                 episode reward: 3.5000,                 loss: nan
Episode: 37041/50000 (74.0820%),                 avg. length: 548.95,                last time consumption/overall running time: 32.9436s / 65103.6448 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.1405
env0_second_0:                 episode reward: 3.8500,                 loss: 0.3555
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 37061/50000 (74.1220%),                 avg. length: 598.15,                last time consumption/overall running time: 36.4857s / 65140.1305 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.1111
env0_second_0:                 episode reward: 3.8000,                 loss: 0.2827
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 37081/50000 (74.1620%),                 avg. length: 583.4,                last time consumption/overall running time: 35.1868s / 65175.3174 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.1561
env0_second_0:                 episode reward: 4.0000,                 loss: 0.3326
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 37101/50000 (74.2020%),                 avg. length: 557.15,                last time consumption/overall running time: 33.4376s / 65208.7549 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.1493
env0_second_0:                 episode reward: 4.0000,                 loss: 0.3234
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 37121/50000 (74.2420%),                 avg. length: 554.5,                last time consumption/overall running time: 33.3045s / 65242.0594 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.1589
env0_second_0:                 episode reward: 3.4500,                 loss: 0.3314
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 37141/50000 (74.2820%),                 avg. length: 530.0,                last time consumption/overall running time: 32.2529s / 65274.3123 s
env0_first_0:                 episode reward: -3.7500,                 loss: 0.1505
env0_second_0:                 episode reward: 3.7500,                 loss: 0.3095
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 37161/50000 (74.3220%),                 avg. length: 592.95,                last time consumption/overall running time: 35.3183s / 65309.6306 s
env0_first_0:                 episode reward: -4.2500,                 loss: 0.1059
env0_second_0:                 episode reward: 4.2500,                 loss: 0.2983
env1_first_0:                 episode reward: -3.3500,                 loss: nan
env1_second_0:                 episode reward: 3.3500,                 loss: nan
Episode: 37181/50000 (74.3620%),                 avg. length: 536.8,                last time consumption/overall running time: 32.2722s / 65341.9028 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.2046
env0_second_0:                 episode reward: 3.5500,                 loss: 0.4260
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 37201/50000 (74.4020%),                 avg. length: 534.6,                last time consumption/overall running time: 32.3478s / 65374.2506 s
env0_first_0:                 episode reward: -3.7500,                 loss: 0.1873
env0_second_0:                 episode reward: 3.7500,                 loss: 0.4058
env1_first_0:                 episode reward: -4.1500,                 loss: nan
env1_second_0:                 episode reward: 4.1500,                 loss: nan
Episode: 37221/50000 (74.4420%),                 avg. length: 579.65,                last time consumption/overall running time: 34.5211s / 65408.7717 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.1773
env0_second_0:                 episode reward: 3.5500,                 loss: 0.4270
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 37241/50000 (74.4820%),                 avg. length: 553.85,                last time consumption/overall running time: 33.8784s / 65442.6501 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.1436
env0_second_0:                 episode reward: 3.9500,                 loss: 0.2730
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 37261/50000 (74.5220%),                 avg. length: 541.2,                last time consumption/overall running time: 34.5282s / 65477.1783 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.1380
env0_second_0:                 episode reward: 3.9500,                 loss: 0.2953
env1_first_0:                 episode reward: -3.3500,                 loss: nan
env1_second_0:                 episode reward: 3.3500,                 loss: nan
Episode: 37281/50000 (74.5620%),                 avg. length: 578.5,                last time consumption/overall running time: 35.7801s / 65512.9585 s
env0_first_0:                 episode reward: -4.2000,                 loss: 0.1387
env0_second_0:                 episode reward: 4.2000,                 loss: 0.5867
env1_first_0:                 episode reward: -3.3500,                 loss: nan
env1_second_0:                 episode reward: 3.3500,                 loss: nan
Episode: 37301/50000 (74.6020%),                 avg. length: 554.55,                last time consumption/overall running time: 33.8253s / 65546.7838 s
env0_first_0:                 episode reward: -3.1500,                 loss: 0.1387
env0_second_0:                 episode reward: 3.1500,                 loss: 0.3109
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 37321/50000 (74.6420%),                 avg. length: 518.65,                last time consumption/overall running time: 31.9541s / 65578.7379 s
env0_first_0:                 episode reward: -4.0500,                 loss: 0.1192
env0_second_0:                 episode reward: 4.0500,                 loss: 0.2465
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 37341/50000 (74.6820%),                 avg. length: 569.85,                last time consumption/overall running time: 36.3132s / 65615.0511 s
env0_first_0:                 episode reward: -3.3000,                 loss: 0.1369
env0_second_0:                 episode reward: 3.3000,                 loss: 0.2760
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 37361/50000 (74.7220%),                 avg. length: 533.55,                last time consumption/overall running time: 32.5207s / 65647.5718 s
env0_first_0:                 episode reward: -3.7500,                 loss: 0.0965
env0_second_0:                 episode reward: 3.7500,                 loss: 0.2713
env1_first_0:                 episode reward: -4.1000,                 loss: nan
env1_second_0:                 episode reward: 4.1000,                 loss: nan
Episode: 37381/50000 (74.7620%),                 avg. length: 559.85,                last time consumption/overall running time: 34.9066s / 65682.4784 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.1052
env0_second_0:                 episode reward: 3.7000,                 loss: 0.2755
env1_first_0:                 episode reward: -4.4000,                 loss: nan
env1_second_0:                 episode reward: 4.4000,                 loss: nan
Episode: 37401/50000 (74.8020%),                 avg. length: 548.1,                last time consumption/overall running time: 33.5445s / 65716.0229 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.1457
env0_second_0:                 episode reward: 3.4500,                 loss: 0.2988
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 37421/50000 (74.8420%),                 avg. length: 582.3,                last time consumption/overall running time: 37.0192s / 65753.0421 s
env0_first_0:                 episode reward: -3.2500,                 loss: 0.1143
env0_second_0:                 episode reward: 3.2500,                 loss: 0.2873
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 37441/50000 (74.8820%),                 avg. length: 599.1,                last time consumption/overall running time: 36.4716s / 65789.5137 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.1121
env0_second_0:                 episode reward: 3.9000,                 loss: 0.4633
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 37461/50000 (74.9220%),                 avg. length: 569.9,                last time consumption/overall running time: 35.5112s / 65825.0249 s
env0_first_0:                 episode reward: -4.3000,                 loss: 0.0752
env0_second_0:                 episode reward: 4.3000,                 loss: 0.3452
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 37481/50000 (74.9620%),                 avg. length: 522.55,                last time consumption/overall running time: 32.8402s / 65857.8651 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.0903
env0_second_0:                 episode reward: 3.5500,                 loss: 0.3673
env1_first_0:                 episode reward: -4.3500,                 loss: nan
env1_second_0:                 episode reward: 4.3500,                 loss: nan
Episode: 37501/50000 (75.0020%),                 avg. length: 537.55,                last time consumption/overall running time: 33.2151s / 65891.0802 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.1269
env0_second_0:                 episode reward: 3.5500,                 loss: 0.3552
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 37521/50000 (75.0420%),                 avg. length: 562.8,                last time consumption/overall running time: 34.8564s / 65925.9366 s
env0_first_0:                 episode reward: -3.3000,                 loss: 0.1455
env0_second_0:                 episode reward: 3.3000,                 loss: 0.3022
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 37541/50000 (75.0820%),                 avg. length: 558.05,                last time consumption/overall running time: 34.0146s / 65959.9512 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.1246
env0_second_0:                 episode reward: 3.9000,                 loss: 0.2860
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 37561/50000 (75.1220%),                 avg. length: 601.2,                last time consumption/overall running time: 35.9897s / 65995.9408 s
env0_first_0:                 episode reward: -4.2000,                 loss: 0.1115
env0_second_0:                 episode reward: 4.2000,                 loss: 0.2456
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 37581/50000 (75.1620%),                 avg. length: 566.6,                last time consumption/overall running time: 34.3607s / 66030.3016 s
env0_first_0:                 episode reward: -3.3000,                 loss: 0.0843
env0_second_0:                 episode reward: 3.3000,                 loss: 0.2485
env1_first_0:                 episode reward: -4.2000,                 loss: nan
env1_second_0:                 episode reward: 4.2000,                 loss: nan
Episode: 37601/50000 (75.2020%),                 avg. length: 555.65,                last time consumption/overall running time: 34.2011s / 66064.5027 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.1052
env0_second_0:                 episode reward: 3.9500,                 loss: 0.2766
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 37621/50000 (75.2420%),                 avg. length: 545.1,                last time consumption/overall running time: 33.4065s / 66097.9091 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.0982
env0_second_0:                 episode reward: 3.5500,                 loss: 0.2283
env1_first_0:                 episode reward: -4.1500,                 loss: nan
env1_second_0:                 episode reward: 4.1500,                 loss: nan
Episode: 37641/50000 (75.2820%),                 avg. length: 541.85,                last time consumption/overall running time: 33.0661s / 66130.9752 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.0632
env0_second_0:                 episode reward: 3.8000,                 loss: 0.2430
env1_first_0:                 episode reward: -4.2500,                 loss: nan
env1_second_0:                 episode reward: 4.2500,                 loss: nan
Episode: 37661/50000 (75.3220%),                 avg. length: 558.9,                last time consumption/overall running time: 34.1314s / 66165.1066 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.1282
env0_second_0:                 episode reward: 3.8000,                 loss: 0.2777
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 37681/50000 (75.3620%),                 avg. length: 566.35,                last time consumption/overall running time: 34.7664s / 66199.8730 s
env0_first_0:                 episode reward: -3.2500,                 loss: 0.1523
env0_second_0:                 episode reward: 3.2500,                 loss: 0.3568
env1_first_0:                 episode reward: -3.3500,                 loss: nan
env1_second_0:                 episode reward: 3.3500,                 loss: nan
Episode: 37701/50000 (75.4020%),                 avg. length: 509.75,                last time consumption/overall running time: 31.2087s / 66231.0817 s
env0_first_0:                 episode reward: -4.2500,                 loss: 0.1119
env0_second_0:                 episode reward: 4.2500,                 loss: 0.2683
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 37721/50000 (75.4420%),                 avg. length: 578.95,                last time consumption/overall running time: 34.7918s / 66265.8736 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.1168
env0_second_0:                 episode reward: 4.0000,                 loss: 0.3095
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 37741/50000 (75.4820%),                 avg. length: 532.95,                last time consumption/overall running time: 32.6206s / 66298.4942 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.0908
env0_second_0:                 episode reward: 3.8500,                 loss: 0.2475
env1_first_0:                 episode reward: -4.1000,                 loss: nan
env1_second_0:                 episode reward: 4.1000,                 loss: nan
Episode: 37761/50000 (75.5220%),                 avg. length: 610.5,                last time consumption/overall running time: 37.0135s / 66335.5076 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.0850
env0_second_0:                 episode reward: 3.6500,                 loss: 0.2846
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 37781/50000 (75.5620%),                 avg. length: 586.8,                last time consumption/overall running time: 36.6154s / 66372.1231 s
env0_first_0:                 episode reward: -2.9500,                 loss: 0.0869
env0_second_0:                 episode reward: 2.9500,                 loss: 0.2622
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 37801/50000 (75.6020%),                 avg. length: 566.15,                last time consumption/overall running time: 35.2081s / 66407.3312 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.0937
env0_second_0:                 episode reward: 4.0000,                 loss: 0.2846
env1_first_0:                 episode reward: -3.5000,                 loss: nan
env1_second_0:                 episode reward: 3.5000,                 loss: nan
Episode: 37821/50000 (75.6420%),                 avg. length: 566.65,                last time consumption/overall running time: 34.2779s / 66441.6091 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.1112
env0_second_0:                 episode reward: 3.6500,                 loss: 0.3070
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 37841/50000 (75.6820%),                 avg. length: 572.6,                last time consumption/overall running time: 34.7919s / 66476.4010 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.0793
env0_second_0:                 episode reward: 3.5500,                 loss: 0.3051
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 37861/50000 (75.7220%),                 avg. length: 595.0,                last time consumption/overall running time: 36.3477s / 66512.7487 s
env0_first_0:                 episode reward: -3.4000,                 loss: 0.1158
env0_second_0:                 episode reward: 3.4000,                 loss: 0.2916
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 37881/50000 (75.7620%),                 avg. length: 540.85,                last time consumption/overall running time: 32.8298s / 66545.5785 s
env0_first_0:                 episode reward: -4.1000,                 loss: 0.0835
env0_second_0:                 episode reward: 4.1000,                 loss: 0.2636
env1_first_0:                 episode reward: -3.5000,                 loss: nan
env1_second_0:                 episode reward: 3.5000,                 loss: nan
Episode: 37901/50000 (75.8020%),                 avg. length: 535.5,                last time consumption/overall running time: 32.9967s / 66578.5752 s
env0_first_0:                 episode reward: -4.2500,                 loss: 0.1110
env0_second_0:                 episode reward: 4.2500,                 loss: 0.2820
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 37921/50000 (75.8420%),                 avg. length: 571.25,                last time consumption/overall running time: 34.3584s / 66612.9337 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.1092
env0_second_0:                 episode reward: 3.4500,                 loss: 0.2425
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 37941/50000 (75.8820%),                 avg. length: 560.5,                last time consumption/overall running time: 33.7183s / 66646.6520 s
env0_first_0:                 episode reward: -3.1500,                 loss: 0.1259
env0_second_0:                 episode reward: 3.1500,                 loss: 0.2814
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 37961/50000 (75.9220%),                 avg. length: 562.5,                last time consumption/overall running time: 33.9397s / 66680.5917 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.0946
env0_second_0:                 episode reward: 3.5000,                 loss: 0.2809
env1_first_0:                 episode reward: -4.1000,                 loss: nan
env1_second_0:                 episode reward: 4.1000,                 loss: nan
Episode: 37981/50000 (75.9620%),                 avg. length: 566.0,                last time consumption/overall running time: 35.5334s / 66716.1251 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.1485
env0_second_0:                 episode reward: 3.9000,                 loss: 0.2755
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 38001/50000 (76.0020%),                 avg. length: 568.75,                last time consumption/overall running time: 34.9439s / 66751.0690 s
env0_first_0:                 episode reward: -4.1000,                 loss: 0.0963
env0_second_0:                 episode reward: 4.1000,                 loss: 0.2430
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 38021/50000 (76.0420%),                 avg. length: 576.65,                last time consumption/overall running time: 35.4057s / 66786.4747 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.1131
env0_second_0:                 episode reward: 3.8500,                 loss: 0.3766
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 38041/50000 (76.0820%),                 avg. length: 552.15,                last time consumption/overall running time: 34.8488s / 66821.3235 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.0836
env0_second_0:                 episode reward: 3.9000,                 loss: 0.2798
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 38061/50000 (76.1220%),                 avg. length: 592.5,                last time consumption/overall running time: 36.7873s / 66858.1107 s
env0_first_0:                 episode reward: -4.0500,                 loss: 0.0814
env0_second_0:                 episode reward: 4.0500,                 loss: 0.2432
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 38081/50000 (76.1620%),                 avg. length: 591.7,                last time consumption/overall running time: 37.9205s / 66896.0312 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.0865
env0_second_0:                 episode reward: 3.8500,                 loss: 0.3307
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 38101/50000 (76.2020%),                 avg. length: 583.35,                last time consumption/overall running time: 35.0402s / 66931.0714 s
env0_first_0:                 episode reward: -4.2000,                 loss: 0.0961
env0_second_0:                 episode reward: 4.2000,                 loss: 0.3007
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 38121/50000 (76.2420%),                 avg. length: 595.25,                last time consumption/overall running time: 36.1568s / 66967.2282 s
env0_first_0:                 episode reward: -3.7500,                 loss: 0.0925
env0_second_0:                 episode reward: 3.7500,                 loss: 0.2596
env1_first_0:                 episode reward: -4.2000,                 loss: nan
env1_second_0:                 episode reward: 4.2000,                 loss: nan
Episode: 38141/50000 (76.2820%),                 avg. length: 550.95,                last time consumption/overall running time: 35.5673s / 67002.7955 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.0919
env0_second_0:                 episode reward: 3.8000,                 loss: 0.2344
env1_first_0:                 episode reward: -4.1000,                 loss: nan
env1_second_0:                 episode reward: 4.1000,                 loss: nan
Episode: 38161/50000 (76.3220%),                 avg. length: 593.9,                last time consumption/overall running time: 37.5945s / 67040.3900 s
env0_first_0:                 episode reward: -3.2000,                 loss: 0.0916
env0_second_0:                 episode reward: 3.2000,                 loss: 0.2872
env1_first_0:                 episode reward: -4.1000,                 loss: nan
env1_second_0:                 episode reward: 4.1000,                 loss: nan
Episode: 38181/50000 (76.3620%),                 avg. length: 578.4,                last time consumption/overall running time: 34.8598s / 67075.2498 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.1293
env0_second_0:                 episode reward: 3.5500,                 loss: 0.3313
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 38201/50000 (76.4020%),                 avg. length: 586.6,                last time consumption/overall running time: 35.1934s / 67110.4432 s
env0_first_0:                 episode reward: -3.7500,                 loss: 0.1318
env0_second_0:                 episode reward: 3.7500,                 loss: 0.2950
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 38221/50000 (76.4420%),                 avg. length: 593.9,                last time consumption/overall running time: 35.3688s / 67145.8120 s
env0_first_0:                 episode reward: -3.2500,                 loss: 0.1209
env0_second_0:                 episode reward: 3.2500,                 loss: 0.2466
env1_first_0:                 episode reward: -4.1000,                 loss: nan
env1_second_0:                 episode reward: 4.1000,                 loss: nan
Episode: 38241/50000 (76.4820%),                 avg. length: 551.1,                last time consumption/overall running time: 33.1947s / 67179.0068 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.0943
env0_second_0:                 episode reward: 4.0000,                 loss: 0.2418
env1_first_0:                 episode reward: -4.2000,                 loss: nan
env1_second_0:                 episode reward: 4.2000,                 loss: nan
Episode: 38261/50000 (76.5220%),                 avg. length: 547.35,                last time consumption/overall running time: 33.1125s / 67212.1193 s
env0_first_0:                 episode reward: -4.0500,                 loss: 0.1272
env0_second_0:                 episode reward: 4.0500,                 loss: 0.3147
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 38281/50000 (76.5620%),                 avg. length: 544.05,                last time consumption/overall running time: 32.8940s / 67245.0133 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.1686
env0_second_0:                 episode reward: 3.8000,                 loss: 0.3805
env1_first_0:                 episode reward: -3.5000,                 loss: nan
env1_second_0:                 episode reward: 3.5000,                 loss: nan
Episode: 38301/50000 (76.6020%),                 avg. length: 557.8,                last time consumption/overall running time: 33.6769s / 67278.6901 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.1334
env0_second_0:                 episode reward: 3.8000,                 loss: 0.3432
env1_first_0:                 episode reward: -4.2000,                 loss: nan
env1_second_0:                 episode reward: 4.2000,                 loss: nan
Episode: 38321/50000 (76.6420%),                 avg. length: 557.0,                last time consumption/overall running time: 33.6704s / 67312.3606 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.1381
env0_second_0:                 episode reward: 3.7000,                 loss: 0.3190
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 38341/50000 (76.6820%),                 avg. length: 545.85,                last time consumption/overall running time: 33.8843s / 67346.2449 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.1175
env0_second_0:                 episode reward: 3.6500,                 loss: 0.3253
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 38361/50000 (76.7220%),                 avg. length: 570.45,                last time consumption/overall running time: 34.3107s / 67380.5556 s
env0_first_0:                 episode reward: -3.7500,                 loss: 0.0960
env0_second_0:                 episode reward: 3.7500,                 loss: 0.3071
env1_first_0:                 episode reward: -4.1500,                 loss: nan
env1_second_0:                 episode reward: 4.1500,                 loss: nan
Episode: 38381/50000 (76.7620%),                 avg. length: 544.2,                last time consumption/overall running time: 33.1820s / 67413.7375 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.1480
env0_second_0:                 episode reward: 3.8500,                 loss: 0.2943
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 38401/50000 (76.8020%),                 avg. length: 598.65,                last time consumption/overall running time: 36.3968s / 67450.1344 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.1249
env0_second_0:                 episode reward: 3.6500,                 loss: 0.3752
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 38421/50000 (76.8420%),                 avg. length: 588.3,                last time consumption/overall running time: 36.2349s / 67486.3693 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.1150
env0_second_0:                 episode reward: 3.8500,                 loss: 0.3735
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 38441/50000 (76.8820%),                 avg. length: 541.85,                last time consumption/overall running time: 32.8253s / 67519.1946 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.1152
env0_second_0:                 episode reward: 3.7000,                 loss: 0.2895
env1_first_0:                 episode reward: -4.1000,                 loss: nan
env1_second_0:                 episode reward: 4.1000,                 loss: nan
Episode: 38461/50000 (76.9220%),                 avg. length: 582.8,                last time consumption/overall running time: 35.1931s / 67554.3877 s
env0_first_0:                 episode reward: -4.1500,                 loss: 0.0981
env0_second_0:                 episode reward: 4.1500,                 loss: 0.2365
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 38481/50000 (76.9620%),                 avg. length: 546.25,                last time consumption/overall running time: 33.5319s / 67587.9196 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.1187
env0_second_0:                 episode reward: 4.0000,                 loss: 0.2734
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 38501/50000 (77.0020%),                 avg. length: 529.1,                last time consumption/overall running time: 31.9670s / 67619.8866 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.1471
env0_second_0:                 episode reward: 4.0000,                 loss: 0.2957
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 38521/50000 (77.0420%),                 avg. length: 535.4,                last time consumption/overall running time: 32.2584s / 67652.1450 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.1252
env0_second_0:                 episode reward: 4.0000,                 loss: 0.2694
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 38541/50000 (77.0820%),                 avg. length: 555.4,                last time consumption/overall running time: 33.7180s / 67685.8630 s
env0_first_0:                 episode reward: -3.2500,                 loss: 0.1197
env0_second_0:                 episode reward: 3.2500,                 loss: 0.6857
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 38561/50000 (77.1220%),                 avg. length: 573.85,                last time consumption/overall running time: 34.4438s / 67720.3068 s
env0_first_0:                 episode reward: -3.2000,                 loss: 0.1348
env0_second_0:                 episode reward: 3.2000,                 loss: 0.3128
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 38581/50000 (77.1620%),                 avg. length: 585.65,                last time consumption/overall running time: 34.9089s / 67755.2157 s
env0_first_0:                 episode reward: -3.7500,                 loss: 0.1006
env0_second_0:                 episode reward: 3.7500,                 loss: 0.2941
env1_first_0:                 episode reward: -4.1000,                 loss: nan
env1_second_0:                 episode reward: 4.1000,                 loss: nan
Episode: 38601/50000 (77.2020%),                 avg. length: 572.55,                last time consumption/overall running time: 35.3720s / 67790.5877 s
env0_first_0:                 episode reward: -4.1000,                 loss: 0.0857
env0_second_0:                 episode reward: 4.1000,                 loss: 0.2561
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 38621/50000 (77.2420%),                 avg. length: 583.25,                last time consumption/overall running time: 35.3742s / 67825.9619 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.0840
env0_second_0:                 episode reward: 4.0000,                 loss: 0.2531
env1_first_0:                 episode reward: -4.3000,                 loss: nan
env1_second_0:                 episode reward: 4.3000,                 loss: nan
Episode: 38641/50000 (77.2820%),                 avg. length: 544.6,                last time consumption/overall running time: 33.1402s / 67859.1020 s
env0_first_0:                 episode reward: -4.0500,                 loss: 0.1011
env0_second_0:                 episode reward: 4.0500,                 loss: 0.2475
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 38661/50000 (77.3220%),                 avg. length: 587.1,                last time consumption/overall running time: 35.5370s / 67894.6390 s
env0_first_0:                 episode reward: -3.7500,                 loss: 0.1011
env0_second_0:                 episode reward: 3.7500,                 loss: 0.2609
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 38681/50000 (77.3620%),                 avg. length: 561.75,                last time consumption/overall running time: 33.9687s / 67928.6077 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.0998
env0_second_0:                 episode reward: 3.9500,                 loss: 0.2181
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 38701/50000 (77.4020%),                 avg. length: 595.65,                last time consumption/overall running time: 35.4478s / 67964.0555 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.0680
env0_second_0:                 episode reward: 4.0000,                 loss: 0.1904
env1_first_0:                 episode reward: -4.1000,                 loss: nan
env1_second_0:                 episode reward: 4.1000,                 loss: nan
Episode: 38721/50000 (77.4420%),                 avg. length: 553.85,                last time consumption/overall running time: 33.3202s / 67997.3757 s
env0_first_0:                 episode reward: -3.1000,                 loss: 0.1023
env0_second_0:                 episode reward: 3.1000,                 loss: 0.2679
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 38741/50000 (77.4820%),                 avg. length: 566.65,                last time consumption/overall running time: 34.5574s / 68031.9331 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.1099
env0_second_0:                 episode reward: 3.5000,                 loss: 0.3050
env1_first_0:                 episode reward: -3.2500,                 loss: nan
env1_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 38761/50000 (77.5220%),                 avg. length: 576.2,                last time consumption/overall running time: 35.2530s / 68067.1862 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.1246
env0_second_0:                 episode reward: 3.6000,                 loss: 0.2232
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 38781/50000 (77.5620%),                 avg. length: 560.25,                last time consumption/overall running time: 33.8350s / 68101.0212 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.1095
env0_second_0:                 episode reward: 3.4500,                 loss: 0.2590
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 38801/50000 (77.6020%),                 avg. length: 564.8,                last time consumption/overall running time: 33.7922s / 68134.8134 s
env0_first_0:                 episode reward: -3.7500,                 loss: 0.1562
env0_second_0:                 episode reward: 3.7500,                 loss: 0.3367
env1_first_0:                 episode reward: -3.5000,                 loss: nan
env1_second_0:                 episode reward: 3.5000,                 loss: nan
Episode: 38821/50000 (77.6420%),                 avg. length: 538.85,                last time consumption/overall running time: 32.5951s / 68167.4085 s
env0_first_0:                 episode reward: -3.1000,                 loss: 0.1803
env0_second_0:                 episode reward: 3.1000,                 loss: 0.3355
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 38841/50000 (77.6820%),                 avg. length: 547.6,                last time consumption/overall running time: 33.0198s / 68200.4283 s
env0_first_0:                 episode reward: -4.4500,                 loss: 0.1527
env0_second_0:                 episode reward: 4.4500,                 loss: 0.3038
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 38861/50000 (77.7220%),                 avg. length: 566.65,                last time consumption/overall running time: 33.9301s / 68234.3585 s
env0_first_0:                 episode reward: -3.3500,                 loss: 0.1573
env0_second_0:                 episode reward: 3.3500,                 loss: 0.3520
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 38881/50000 (77.7620%),                 avg. length: 601.75,                last time consumption/overall running time: 36.2485s / 68270.6070 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.0956
env0_second_0:                 episode reward: 3.9500,                 loss: 0.2394
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 38901/50000 (77.8020%),                 avg. length: 549.15,                last time consumption/overall running time: 33.0988s / 68303.7058 s
env0_first_0:                 episode reward: -4.1500,                 loss: 0.1212
env0_second_0:                 episode reward: 4.1500,                 loss: 0.2470
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 38921/50000 (77.8420%),                 avg. length: 569.35,                last time consumption/overall running time: 34.1348s / 68337.8406 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.1235
env0_second_0:                 episode reward: 3.4500,                 loss: 0.2435
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 38941/50000 (77.8820%),                 avg. length: 557.95,                last time consumption/overall running time: 34.0406s / 68371.8812 s
env0_first_0:                 episode reward: -3.7500,                 loss: 0.1332
env0_second_0:                 episode reward: 3.7500,                 loss: 0.3232
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 38961/50000 (77.9220%),                 avg. length: 560.35,                last time consumption/overall running time: 33.8257s / 68405.7069 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.0859
env0_second_0:                 episode reward: 3.6000,                 loss: 0.3781
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 38981/50000 (77.9620%),                 avg. length: 536.85,                last time consumption/overall running time: 33.0359s / 68438.7428 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.1002
env0_second_0:                 episode reward: 3.8000,                 loss: 0.3690
env1_first_0:                 episode reward: -3.5000,                 loss: nan
env1_second_0:                 episode reward: 3.5000,                 loss: nan
Episode: 39001/50000 (78.0020%),                 avg. length: 546.0,                last time consumption/overall running time: 33.9495s / 68472.6923 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.1359
env0_second_0:                 episode reward: 4.0000,                 loss: 0.3029
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 39021/50000 (78.0420%),                 avg. length: 551.35,                last time consumption/overall running time: 33.8257s / 68506.5180 s
env0_first_0:                 episode reward: -3.7500,                 loss: 0.1150
env0_second_0:                 episode reward: 3.7500,                 loss: 0.2631
env1_first_0:                 episode reward: -4.2000,                 loss: nan
env1_second_0:                 episode reward: 4.2000,                 loss: nan
Episode: 39041/50000 (78.0820%),                 avg. length: 541.6,                last time consumption/overall running time: 32.9159s / 68539.4340 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.1097
env0_second_0:                 episode reward: 3.9000,                 loss: 0.2380
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 39061/50000 (78.1220%),                 avg. length: 556.6,                last time consumption/overall running time: 33.8791s / 68573.3131 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.1379
env0_second_0:                 episode reward: 3.6500,                 loss: 0.2765
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 39081/50000 (78.1620%),                 avg. length: 526.2,                last time consumption/overall running time: 32.2790s / 68605.5921 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.1589
env0_second_0:                 episode reward: 4.0000,                 loss: 0.3321
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 39101/50000 (78.2020%),                 avg. length: 541.35,                last time consumption/overall running time: 33.0038s / 68638.5958 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.1788
env0_second_0:                 episode reward: 3.8500,                 loss: 0.3010
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 39121/50000 (78.2420%),                 avg. length: 605.8,                last time consumption/overall running time: 36.7351s / 68675.3309 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.1356
env0_second_0:                 episode reward: 3.9000,                 loss: 0.3041
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 39141/50000 (78.2820%),                 avg. length: 526.85,                last time consumption/overall running time: 32.2828s / 68707.6137 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.1070
env0_second_0:                 episode reward: 3.6000,                 loss: 0.3340
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 39161/50000 (78.3220%),                 avg. length: 581.9,                last time consumption/overall running time: 35.0901s / 68742.7038 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.0891
env0_second_0:                 episode reward: 3.7000,                 loss: 0.2855
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 39181/50000 (78.3620%),                 avg. length: 570.2,                last time consumption/overall running time: 34.5582s / 68777.2620 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.1204
env0_second_0:                 episode reward: 3.6000,                 loss: 0.4073
env1_first_0:                 episode reward: -4.2500,                 loss: nan
env1_second_0:                 episode reward: 4.2500,                 loss: nan
Episode: 39201/50000 (78.4020%),                 avg. length: 565.6,                last time consumption/overall running time: 35.0461s / 68812.3082 s
env0_first_0:                 episode reward: -4.3000,                 loss: 0.1039
env0_second_0:                 episode reward: 4.3000,                 loss: 0.2447
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 39221/50000 (78.4420%),                 avg. length: 552.7,                last time consumption/overall running time: 34.8495s / 68847.1577 s
env0_first_0:                 episode reward: -4.0500,                 loss: 0.1274
env0_second_0:                 episode reward: 4.0500,                 loss: 0.4708
env1_first_0:                 episode reward: -3.5000,                 loss: nan
env1_second_0:                 episode reward: 3.5000,                 loss: nan
Episode: 39241/50000 (78.4820%),                 avg. length: 574.3,                last time consumption/overall running time: 35.2650s / 68882.4227 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.1038
env0_second_0:                 episode reward: 3.9000,                 loss: 0.2956
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 39261/50000 (78.5220%),                 avg. length: 560.85,                last time consumption/overall running time: 34.1313s / 68916.5539 s
env0_first_0:                 episode reward: -3.2500,                 loss: 0.0953
env0_second_0:                 episode reward: 3.2500,                 loss: 0.2335
env1_first_0:                 episode reward: -4.1500,                 loss: nan
env1_second_0:                 episode reward: 4.1500,                 loss: nan
Episode: 39281/50000 (78.5620%),                 avg. length: 549.6,                last time consumption/overall running time: 33.7925s / 68950.3465 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.1192
env0_second_0:                 episode reward: 3.8500,                 loss: 0.3062
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 39301/50000 (78.6020%),                 avg. length: 482.9,                last time consumption/overall running time: 32.0366s / 68982.3831 s
env0_first_0:                 episode reward: -4.2500,                 loss: 0.1316
env0_second_0:                 episode reward: 4.2500,                 loss: 0.2662
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 39321/50000 (78.6420%),                 avg. length: 540.35,                last time consumption/overall running time: 33.5492s / 69015.9322 s
env0_first_0:                 episode reward: -4.2000,                 loss: 0.1354
env0_second_0:                 episode reward: 4.2000,                 loss: 0.2630
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 39341/50000 (78.6820%),                 avg. length: 539.55,                last time consumption/overall running time: 33.1433s / 69049.0755 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.0890
env0_second_0:                 episode reward: 4.0000,                 loss: 0.2660
env1_first_0:                 episode reward: -4.1500,                 loss: nan
env1_second_0:                 episode reward: 4.1500,                 loss: nan
Episode: 39361/50000 (78.7220%),                 avg. length: 552.85,                last time consumption/overall running time: 33.5944s / 69082.6699 s
env0_first_0:                 episode reward: -4.2000,                 loss: 0.0969
env0_second_0:                 episode reward: 4.2000,                 loss: 0.2624
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 39381/50000 (78.7620%),                 avg. length: 503.1,                last time consumption/overall running time: 31.0418s / 69113.7117 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.0946
env0_second_0:                 episode reward: 4.0000,                 loss: 0.2738
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 39401/50000 (78.8020%),                 avg. length: 538.95,                last time consumption/overall running time: 32.5826s / 69146.2942 s
env0_first_0:                 episode reward: -4.1500,                 loss: 0.0838
env0_second_0:                 episode reward: 4.1500,                 loss: 0.2248
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 39421/50000 (78.8420%),                 avg. length: 497.0,                last time consumption/overall running time: 30.7736s / 69177.0678 s
env0_first_0:                 episode reward: -3.2500,                 loss: 0.0989
env0_second_0:                 episode reward: 3.2500,                 loss: 0.2331
env1_first_0:                 episode reward: -4.2500,                 loss: nan
env1_second_0:                 episode reward: 4.2500,                 loss: nan
Episode: 39441/50000 (78.8820%),                 avg. length: 530.85,                last time consumption/overall running time: 32.5216s / 69209.5895 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.1258
env0_second_0:                 episode reward: 4.0000,                 loss: 0.2988
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 39461/50000 (78.9220%),                 avg. length: 546.5,                last time consumption/overall running time: 32.9038s / 69242.4933 s
env0_first_0:                 episode reward: -4.2000,                 loss: 0.0835
env0_second_0:                 episode reward: 4.2000,                 loss: 0.2893
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 39481/50000 (78.9620%),                 avg. length: 613.8,                last time consumption/overall running time: 37.8456s / 69280.3389 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.1146
env0_second_0:                 episode reward: 3.4500,                 loss: 0.3208
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 39501/50000 (79.0020%),                 avg. length: 585.4,                last time consumption/overall running time: 34.8096s / 69315.1485 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.1342
env0_second_0:                 episode reward: 4.0000,                 loss: 0.2839
env1_first_0:                 episode reward: -3.0000,                 loss: nan
env1_second_0:                 episode reward: 3.0000,                 loss: nan
Episode: 39521/50000 (79.0420%),                 avg. length: 571.6,                last time consumption/overall running time: 34.2455s / 69349.3940 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.0976
env0_second_0:                 episode reward: 3.8000,                 loss: 0.2697
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 39541/50000 (79.0820%),                 avg. length: 550.35,                last time consumption/overall running time: 33.1492s / 69382.5432 s
env0_first_0:                 episode reward: -3.4000,                 loss: 0.0995
env0_second_0:                 episode reward: 3.4000,                 loss: 0.3251
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 39561/50000 (79.1220%),                 avg. length: 573.55,                last time consumption/overall running time: 34.6326s / 69417.1758 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.1136
env0_second_0:                 episode reward: 3.5000,                 loss: 0.2990
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 39581/50000 (79.1620%),                 avg. length: 605.5,                last time consumption/overall running time: 36.3512s / 69453.5270 s
env0_first_0:                 episode reward: -3.3500,                 loss: 0.1380
env0_second_0:                 episode reward: 3.3500,                 loss: 0.3204
env1_first_0:                 episode reward: -3.3500,                 loss: nan
env1_second_0:                 episode reward: 3.3500,                 loss: nan
Episode: 39601/50000 (79.2020%),                 avg. length: 546.75,                last time consumption/overall running time: 33.3467s / 69486.8737 s
env0_first_0:                 episode reward: -4.1500,                 loss: 0.1272
env0_second_0:                 episode reward: 4.1500,                 loss: 0.3075
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 39621/50000 (79.2420%),                 avg. length: 550.4,                last time consumption/overall running time: 33.2489s / 69520.1226 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.1152
env0_second_0:                 episode reward: 3.7000,                 loss: 0.2695
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 39641/50000 (79.2820%),                 avg. length: 529.75,                last time consumption/overall running time: 32.0996s / 69552.2222 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.1617
env0_second_0:                 episode reward: 3.8500,                 loss: 0.3159
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 39661/50000 (79.3220%),                 avg. length: 541.9,                last time consumption/overall running time: 33.3160s / 69585.5382 s
env0_first_0:                 episode reward: -4.2000,                 loss: 0.0618
env0_second_0:                 episode reward: 4.2000,                 loss: 0.2493
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 39681/50000 (79.3620%),                 avg. length: 575.55,                last time consumption/overall running time: 34.4832s / 69620.0214 s
env0_first_0:                 episode reward: -4.5500,                 loss: 0.0941
env0_second_0:                 episode reward: 4.5500,                 loss: 0.2248
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 39701/50000 (79.4020%),                 avg. length: 547.25,                last time consumption/overall running time: 33.0629s / 69653.0843 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.1109
env0_second_0:                 episode reward: 4.0000,                 loss: 0.2513
env1_first_0:                 episode reward: -3.3500,                 loss: nan
env1_second_0:                 episode reward: 3.3500,                 loss: nan
Episode: 39721/50000 (79.4420%),                 avg. length: 573.55,                last time consumption/overall running time: 34.4439s / 69687.5282 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.1087
env0_second_0:                 episode reward: 3.9500,                 loss: 0.3167
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 39741/50000 (79.4820%),                 avg. length: 564.5,                last time consumption/overall running time: 35.4207s / 69722.9489 s
env0_first_0:                 episode reward: -4.1000,                 loss: 0.0891
env0_second_0:                 episode reward: 4.1000,                 loss: 0.2468
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 39761/50000 (79.5220%),                 avg. length: 569.1,                last time consumption/overall running time: 36.7851s / 69759.7340 s
env0_first_0:                 episode reward: -3.0500,                 loss: 0.2020
env0_second_0:                 episode reward: 3.0500,                 loss: 0.5591
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 39781/50000 (79.5620%),                 avg. length: 555.05,                last time consumption/overall running time: 33.4372s / 69793.1712 s
env0_first_0:                 episode reward: -4.4000,                 loss: 0.0859
env0_second_0:                 episode reward: 4.4000,                 loss: 0.2530
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 39801/50000 (79.6020%),                 avg. length: 521.3,                last time consumption/overall running time: 31.5111s / 69824.6823 s
env0_first_0:                 episode reward: -4.1500,                 loss: 0.1226
env0_second_0:                 episode reward: 4.1500,                 loss: 0.3282
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 39821/50000 (79.6420%),                 avg. length: 565.05,                last time consumption/overall running time: 33.8692s / 69858.5515 s
env0_first_0:                 episode reward: -3.3000,                 loss: 0.1014
env0_second_0:                 episode reward: 3.3000,                 loss: 0.3292
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 39841/50000 (79.6820%),                 avg. length: 567.95,                last time consumption/overall running time: 34.3308s / 69892.8823 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.1448
env0_second_0:                 episode reward: 3.5500,                 loss: 0.3476
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 39861/50000 (79.7220%),                 avg. length: 565.85,                last time consumption/overall running time: 33.9074s / 69926.7897 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.1004
env0_second_0:                 episode reward: 3.9000,                 loss: 0.2372
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 39881/50000 (79.7620%),                 avg. length: 558.2,                last time consumption/overall running time: 33.5888s / 69960.3785 s
env0_first_0:                 episode reward: -3.4000,                 loss: 0.1466
env0_second_0:                 episode reward: 3.4000,                 loss: 0.3152
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 39901/50000 (79.8020%),                 avg. length: 552.9,                last time consumption/overall running time: 33.7658s / 69994.1443 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.0612
env0_second_0:                 episode reward: 3.9000,                 loss: 0.3751
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 39921/50000 (79.8420%),                 avg. length: 537.5,                last time consumption/overall running time: 32.4876s / 70026.6319 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.1206
env0_second_0:                 episode reward: 3.9500,                 loss: 0.3433
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 39941/50000 (79.8820%),                 avg. length: 553.65,                last time consumption/overall running time: 34.8363s / 70061.4682 s
env0_first_0:                 episode reward: -3.1500,                 loss: 0.0698
env0_second_0:                 episode reward: 3.1500,                 loss: 0.2209
env1_first_0:                 episode reward: -4.3500,                 loss: nan
env1_second_0:                 episode reward: 4.3500,                 loss: nan
Episode: 39961/50000 (79.9220%),                 avg. length: 532.2,                last time consumption/overall running time: 32.1270s / 70093.5953 s
env0_first_0:                 episode reward: -4.1500,                 loss: 0.0778
env0_second_0:                 episode reward: 4.1500,                 loss: 0.1761
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 39981/50000 (79.9620%),                 avg. length: 526.5,                last time consumption/overall running time: 31.8189s / 70125.4142 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.1736
env0_second_0:                 episode reward: 3.7000,                 loss: 0.3125
env1_first_0:                 episode reward: -3.0500,                 loss: nan
env1_second_0:                 episode reward: 3.0500,                 loss: nan
Episode: 40001/50000 (80.0020%),                 avg. length: 504.5,                last time consumption/overall running time: 30.7848s / 70156.1990 s
env0_first_0:                 episode reward: -3.7500,                 loss: 0.0996
env0_second_0:                 episode reward: 3.7500,                 loss: 0.2481
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 40021/50000 (80.0420%),                 avg. length: 557.0,                last time consumption/overall running time: 33.8645s / 70190.0635 s
env0_first_0:                 episode reward: -4.1500,                 loss: 0.0962
env0_second_0:                 episode reward: 4.1500,                 loss: 0.2359
env1_first_0:                 episode reward: -4.2000,                 loss: nan
env1_second_0:                 episode reward: 4.2000,                 loss: nan
Episode: 40041/50000 (80.0820%),                 avg. length: 574.3,                last time consumption/overall running time: 35.7366s / 70225.8000 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.0855
env0_second_0:                 episode reward: 3.9000,                 loss: 0.2260
env1_first_0:                 episode reward: -4.3000,                 loss: nan
env1_second_0:                 episode reward: 4.3000,                 loss: nan
Episode: 40061/50000 (80.1220%),                 avg. length: 577.4,                last time consumption/overall running time: 35.1685s / 70260.9685 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.0633
env0_second_0:                 episode reward: 3.9500,                 loss: 0.2627
env1_first_0:                 episode reward: -4.1000,                 loss: nan
env1_second_0:                 episode reward: 4.1000,                 loss: nan
Episode: 40081/50000 (80.1620%),                 avg. length: 547.95,                last time consumption/overall running time: 33.1112s / 70294.0797 s
env0_first_0:                 episode reward: -4.1500,                 loss: 0.0959
env0_second_0:                 episode reward: 4.1500,                 loss: 0.2567
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 40101/50000 (80.2020%),                 avg. length: 553.0,                last time consumption/overall running time: 33.7695s / 70327.8492 s
env0_first_0:                 episode reward: -4.2000,                 loss: 0.0683
env0_second_0:                 episode reward: 4.2000,                 loss: 0.2384
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 40121/50000 (80.2420%),                 avg. length: 531.95,                last time consumption/overall running time: 32.5997s / 70360.4488 s
env0_first_0:                 episode reward: -3.7500,                 loss: 0.1567
env0_second_0:                 episode reward: 3.7500,                 loss: 0.3074
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 40141/50000 (80.2820%),                 avg. length: 593.65,                last time consumption/overall running time: 35.6303s / 70396.0792 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.1075
env0_second_0:                 episode reward: 3.8000,                 loss: 0.3125
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 40161/50000 (80.3220%),                 avg. length: 543.0,                last time consumption/overall running time: 32.8443s / 70428.9235 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.1131
env0_second_0:                 episode reward: 3.7000,                 loss: 0.2879
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 40181/50000 (80.3620%),                 avg. length: 579.35,                last time consumption/overall running time: 35.1017s / 70464.0252 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.1216
env0_second_0:                 episode reward: 3.9500,                 loss: 0.2842
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 40201/50000 (80.4020%),                 avg. length: 512.45,                last time consumption/overall running time: 32.8317s / 70496.8569 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.1441
env0_second_0:                 episode reward: 3.5500,                 loss: 0.2794
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 40221/50000 (80.4420%),                 avg. length: 543.9,                last time consumption/overall running time: 33.8257s / 70530.6826 s
env0_first_0:                 episode reward: -3.0500,                 loss: 0.1815
env0_second_0:                 episode reward: 3.0500,                 loss: 0.3758
env1_first_0:                 episode reward: -2.8500,                 loss: nan
env1_second_0:                 episode reward: 2.8500,                 loss: nan
Episode: 40241/50000 (80.4820%),                 avg. length: 555.85,                last time consumption/overall running time: 34.6740s / 70565.3566 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.1005
env0_second_0:                 episode reward: 3.4500,                 loss: 0.2569
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 40261/50000 (80.5220%),                 avg. length: 556.35,                last time consumption/overall running time: 33.5793s / 70598.9359 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.0934
env0_second_0:                 episode reward: 3.6500,                 loss: 0.2932
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 40281/50000 (80.5620%),                 avg. length: 529.25,                last time consumption/overall running time: 32.2250s / 70631.1609 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.1205
env0_second_0:                 episode reward: 3.5000,                 loss: 0.2422
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 40301/50000 (80.6020%),                 avg. length: 567.75,                last time consumption/overall running time: 34.5163s / 70665.6772 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.0917
env0_second_0:                 episode reward: 3.5500,                 loss: 0.2029
env1_first_0:                 episode reward: -4.1500,                 loss: nan
env1_second_0:                 episode reward: 4.1500,                 loss: nan
Episode: 40321/50000 (80.6420%),                 avg. length: 577.85,                last time consumption/overall running time: 35.7767s / 70701.4539 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.0628
env0_second_0:                 episode reward: 3.8500,                 loss: 0.1907
env1_first_0:                 episode reward: -4.2000,                 loss: nan
env1_second_0:                 episode reward: 4.2000,                 loss: nan
Episode: 40341/50000 (80.6820%),                 avg. length: 605.15,                last time consumption/overall running time: 37.1182s / 70738.5720 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.0610
env0_second_0:                 episode reward: 3.6500,                 loss: 0.1661
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 40361/50000 (80.7220%),                 avg. length: 535.2,                last time consumption/overall running time: 32.3788s / 70770.9509 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.1338
env0_second_0:                 episode reward: 3.6500,                 loss: 0.2482
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 40381/50000 (80.7620%),                 avg. length: 524.6,                last time consumption/overall running time: 32.0001s / 70802.9510 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.1372
env0_second_0:                 episode reward: 4.0000,                 loss: 0.2634
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 40401/50000 (80.8020%),                 avg. length: 556.85,                last time consumption/overall running time: 33.6813s / 70836.6323 s
env0_first_0:                 episode reward: -3.3500,                 loss: 0.1162
env0_second_0:                 episode reward: 3.3500,                 loss: 0.2590
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 40421/50000 (80.8420%),                 avg. length: 556.3,                last time consumption/overall running time: 35.2406s / 70871.8729 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.0904
env0_second_0:                 episode reward: 3.9500,                 loss: 0.2518
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 40441/50000 (80.8820%),                 avg. length: 572.75,                last time consumption/overall running time: 35.8858s / 70907.7587 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.0900
env0_second_0:                 episode reward: 3.9000,                 loss: 0.2185
env1_first_0:                 episode reward: -4.3500,                 loss: nan
env1_second_0:                 episode reward: 4.3500,                 loss: nan
Episode: 40461/50000 (80.9220%),                 avg. length: 511.35,                last time consumption/overall running time: 31.4752s / 70939.2339 s
env0_first_0:                 episode reward: -4.0500,                 loss: 0.0750
env0_second_0:                 episode reward: 4.0500,                 loss: 0.2245
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 40481/50000 (80.9620%),                 avg. length: 545.7,                last time consumption/overall running time: 33.1090s / 70972.3429 s
env0_first_0:                 episode reward: -4.0500,                 loss: 0.1251
env0_second_0:                 episode reward: 4.0500,                 loss: 0.3018
env1_first_0:                 episode reward: -4.1500,                 loss: nan
env1_second_0:                 episode reward: 4.1500,                 loss: nan
Episode: 40501/50000 (81.0020%),                 avg. length: 551.4,                last time consumption/overall running time: 33.4055s / 71005.7484 s
env0_first_0:                 episode reward: -3.2500,                 loss: 0.1317
env0_second_0:                 episode reward: 3.2500,                 loss: 0.3381
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 40521/50000 (81.0420%),                 avg. length: 568.25,                last time consumption/overall running time: 34.1095s / 71039.8579 s
env0_first_0:                 episode reward: -4.3000,                 loss: 0.0975
env0_second_0:                 episode reward: 4.3000,                 loss: 0.2376
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 40541/50000 (81.0820%),                 avg. length: 536.75,                last time consumption/overall running time: 32.6274s / 71072.4853 s
env0_first_0:                 episode reward: -4.5000,                 loss: 0.1203
env0_second_0:                 episode reward: 4.5000,                 loss: 0.2977
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 40561/50000 (81.1220%),                 avg. length: 572.3,                last time consumption/overall running time: 36.0329s / 71108.5182 s
env0_first_0:                 episode reward: -4.2500,                 loss: 0.1056
env0_second_0:                 episode reward: 4.2500,                 loss: 0.2327
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 40581/50000 (81.1620%),                 avg. length: 564.7,                last time consumption/overall running time: 35.4327s / 71143.9510 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.1495
env0_second_0:                 episode reward: 3.8000,                 loss: 0.2745
env1_first_0:                 episode reward: -3.5000,                 loss: nan
env1_second_0:                 episode reward: 3.5000,                 loss: nan
Episode: 40601/50000 (81.2020%),                 avg. length: 563.65,                last time consumption/overall running time: 34.2151s / 71178.1660 s
env0_first_0:                 episode reward: -4.1500,                 loss: 0.0916
env0_second_0:                 episode reward: 4.1500,                 loss: 0.2445
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 40621/50000 (81.2420%),                 avg. length: 578.5,                last time consumption/overall running time: 35.0565s / 71213.2226 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.1299
env0_second_0:                 episode reward: 4.0000,                 loss: 0.2369
env1_first_0:                 episode reward: -3.5000,                 loss: nan
env1_second_0:                 episode reward: 3.5000,                 loss: nan
Episode: 40641/50000 (81.2820%),                 avg. length: 535.0,                last time consumption/overall running time: 32.6967s / 71245.9192 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.1299
env0_second_0:                 episode reward: 3.8500,                 loss: 0.2969
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 40661/50000 (81.3220%),                 avg. length: 580.5,                last time consumption/overall running time: 36.2752s / 71282.1944 s
env0_first_0:                 episode reward: -3.7500,                 loss: 0.1159
env0_second_0:                 episode reward: 3.7500,                 loss: 0.2673
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 40681/50000 (81.3620%),                 avg. length: 557.7,                last time consumption/overall running time: 33.8962s / 71316.0906 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.1079
env0_second_0:                 episode reward: 3.9000,                 loss: 0.3311
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 40701/50000 (81.4020%),                 avg. length: 586.25,                last time consumption/overall running time: 36.0813s / 71352.1719 s
env0_first_0:                 episode reward: -4.3500,                 loss: 0.0845
env0_second_0:                 episode reward: 4.3500,                 loss: 0.2556
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 40721/50000 (81.4420%),                 avg. length: 590.45,                last time consumption/overall running time: 36.7484s / 71388.9203 s
env0_first_0:                 episode reward: -4.1000,                 loss: 0.1064
env0_second_0:                 episode reward: 4.1000,                 loss: 0.4226
env1_first_0:                 episode reward: -3.5000,                 loss: nan
env1_second_0:                 episode reward: 3.5000,                 loss: nan
Episode: 40741/50000 (81.4820%),                 avg. length: 542.75,                last time consumption/overall running time: 34.1606s / 71423.0809 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.1563
env0_second_0:                 episode reward: 3.8500,                 loss: 0.3815
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 40761/50000 (81.5220%),                 avg. length: 607.9,                last time consumption/overall running time: 36.1663s / 71459.2471 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.0896
env0_second_0:                 episode reward: 3.8500,                 loss: 0.3420
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 40781/50000 (81.5620%),                 avg. length: 559.55,                last time consumption/overall running time: 33.5300s / 71492.7772 s
env0_first_0:                 episode reward: -4.1500,                 loss: 0.1020
env0_second_0:                 episode reward: 4.1500,                 loss: 0.2964
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 40801/50000 (81.6020%),                 avg. length: 559.55,                last time consumption/overall running time: 33.8019s / 71526.5791 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.1110
env0_second_0:                 episode reward: 3.6500,                 loss: 0.2998
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 40821/50000 (81.6420%),                 avg. length: 538.25,                last time consumption/overall running time: 34.0188s / 71560.5978 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.1056
env0_second_0:                 episode reward: 3.8000,                 loss: 0.2763
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 40841/50000 (81.6820%),                 avg. length: 590.75,                last time consumption/overall running time: 35.8011s / 71596.3990 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.0727
env0_second_0:                 episode reward: 3.5000,                 loss: 0.2374
env1_first_0:                 episode reward: -4.3000,                 loss: nan
env1_second_0:                 episode reward: 4.3000,                 loss: nan
Episode: 40861/50000 (81.7220%),                 avg. length: 549.15,                last time consumption/overall running time: 34.4740s / 71630.8730 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.0472
env0_second_0:                 episode reward: 3.8000,                 loss: 0.1846
env1_first_0:                 episode reward: -4.3000,                 loss: nan
env1_second_0:                 episode reward: 4.3000,                 loss: nan
Episode: 40881/50000 (81.7620%),                 avg. length: 572.85,                last time consumption/overall running time: 34.3190s / 71665.1919 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.0751
env0_second_0:                 episode reward: 4.0000,                 loss: 0.2540
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 40901/50000 (81.8020%),                 avg. length: 568.05,                last time consumption/overall running time: 34.1802s / 71699.3722 s
env0_first_0:                 episode reward: -4.0500,                 loss: 0.0766
env0_second_0:                 episode reward: 4.0500,                 loss: 0.2658
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 40921/50000 (81.8420%),                 avg. length: 552.0,                last time consumption/overall running time: 41.9344s / 71741.3065 s
env0_first_0:                 episode reward: -3.0500,                 loss: 0.1939
env0_second_0:                 episode reward: 3.0500,                 loss: 0.3380
env1_first_0:                 episode reward: -2.9000,                 loss: nan
env1_second_0:                 episode reward: 2.9000,                 loss: nan
Episode: 40941/50000 (81.8820%),                 avg. length: 564.7,                last time consumption/overall running time: 34.2279s / 71775.5344 s
env0_first_0:                 episode reward: -4.1000,                 loss: 0.0998
env0_second_0:                 episode reward: 4.1000,                 loss: 0.2269
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 40961/50000 (81.9220%),                 avg. length: 567.3,                last time consumption/overall running time: 34.1364s / 71809.6708 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.0623
env0_second_0:                 episode reward: 4.0000,                 loss: 0.1721
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 40981/50000 (81.9620%),                 avg. length: 588.9,                last time consumption/overall running time: 35.2313s / 71844.9021 s
env0_first_0:                 episode reward: -4.3500,                 loss: 0.0839
env0_second_0:                 episode reward: 4.3500,                 loss: 0.2311
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 41001/50000 (82.0020%),                 avg. length: 579.7,                last time consumption/overall running time: 36.4141s / 71881.3162 s
env0_first_0:                 episode reward: -3.4000,                 loss: 0.1048
env0_second_0:                 episode reward: 3.4000,                 loss: 0.2959
env1_first_0:                 episode reward: -4.2500,                 loss: nan
env1_second_0:                 episode reward: 4.2500,                 loss: nan
Episode: 41021/50000 (82.0420%),                 avg. length: 559.4,                last time consumption/overall running time: 36.0673s / 71917.3835 s
env0_first_0:                 episode reward: -4.1000,                 loss: 0.1060
env0_second_0:                 episode reward: 4.1000,                 loss: 0.2670
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 41041/50000 (82.0820%),                 avg. length: 554.35,                last time consumption/overall running time: 33.9232s / 71951.3067 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.0904
env0_second_0:                 episode reward: 3.6500,                 loss: 0.2535
env1_first_0:                 episode reward: -4.1000,                 loss: nan
env1_second_0:                 episode reward: 4.1000,                 loss: nan
Episode: 41061/50000 (82.1220%),                 avg. length: 603.1,                last time consumption/overall running time: 36.1091s / 71987.4158 s
env0_first_0:                 episode reward: -4.2500,                 loss: 0.0936
env0_second_0:                 episode reward: 4.2500,                 loss: 0.2578
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 41081/50000 (82.1620%),                 avg. length: 553.45,                last time consumption/overall running time: 33.5493s / 72020.9651 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.1323
env0_second_0:                 episode reward: 3.8500,                 loss: 0.2547
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 41101/50000 (82.2020%),                 avg. length: 542.85,                last time consumption/overall running time: 34.8472s / 72055.8123 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.1216
env0_second_0:                 episode reward: 3.5500,                 loss: 0.2948
env1_first_0:                 episode reward: -4.2000,                 loss: nan
env1_second_0:                 episode reward: 4.2000,                 loss: nan
Episode: 41121/50000 (82.2420%),                 avg. length: 556.55,                last time consumption/overall running time: 34.0274s / 72089.8397 s
env0_first_0:                 episode reward: -4.1500,                 loss: 0.1419
env0_second_0:                 episode reward: 4.1500,                 loss: 0.3434
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 41141/50000 (82.2820%),                 avg. length: 621.95,                last time consumption/overall running time: 38.1064s / 72127.9461 s
env0_first_0:                 episode reward: -3.3000,                 loss: 0.1163
env0_second_0:                 episode reward: 3.3000,                 loss: 0.4188
env1_first_0:                 episode reward: -4.1000,                 loss: nan
env1_second_0:                 episode reward: 4.1000,                 loss: nan
Episode: 41161/50000 (82.3220%),                 avg. length: 574.55,                last time consumption/overall running time: 35.0562s / 72163.0024 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.1300
env0_second_0:                 episode reward: 3.8500,                 loss: 0.3307
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 41181/50000 (82.3620%),                 avg. length: 543.6,                last time consumption/overall running time: 35.7707s / 72198.7731 s
env0_first_0:                 episode reward: -4.2000,                 loss: 0.0978
env0_second_0:                 episode reward: 4.2000,                 loss: 0.2503
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 41201/50000 (82.4020%),                 avg. length: 575.4,                last time consumption/overall running time: 36.2340s / 72235.0071 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.0776
env0_second_0:                 episode reward: 3.8500,                 loss: 0.2221
env1_first_0:                 episode reward: -4.2000,                 loss: nan
env1_second_0:                 episode reward: 4.2000,                 loss: nan
Episode: 41221/50000 (82.4420%),                 avg. length: 601.9,                last time consumption/overall running time: 35.9663s / 72270.9734 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.1005
env0_second_0:                 episode reward: 3.9000,                 loss: 0.2529
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 41241/50000 (82.4820%),                 avg. length: 551.45,                last time consumption/overall running time: 34.0904s / 72305.0638 s
env0_first_0:                 episode reward: -4.1500,                 loss: 0.1327
env0_second_0:                 episode reward: 4.1500,                 loss: 0.2737
env1_first_0:                 episode reward: -3.3500,                 loss: nan
env1_second_0:                 episode reward: 3.3500,                 loss: nan
Episode: 41261/50000 (82.5220%),                 avg. length: 615.35,                last time consumption/overall running time: 37.9207s / 72342.9844 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.1029
env0_second_0:                 episode reward: 3.6500,                 loss: 0.2900
env1_first_0:                 episode reward: -3.5000,                 loss: nan
env1_second_0:                 episode reward: 3.5000,                 loss: nan
Episode: 41281/50000 (82.5620%),                 avg. length: 583.25,                last time consumption/overall running time: 35.6872s / 72378.6717 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.1046
env0_second_0:                 episode reward: 3.9000,                 loss: 0.2635
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 41301/50000 (82.6020%),                 avg. length: 612.7,                last time consumption/overall running time: 36.9328s / 72415.6045 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.1277
env0_second_0:                 episode reward: 3.9500,                 loss: 0.3084
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 41321/50000 (82.6420%),                 avg. length: 571.0,                last time consumption/overall running time: 34.5082s / 72450.1127 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.1098
env0_second_0:                 episode reward: 3.5000,                 loss: 0.2402
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 41341/50000 (82.6820%),                 avg. length: 592.05,                last time consumption/overall running time: 35.9433s / 72486.0559 s
env0_first_0:                 episode reward: -3.3500,                 loss: 0.1880
env0_second_0:                 episode reward: 3.3500,                 loss: 0.3455
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 41361/50000 (82.7220%),                 avg. length: 546.85,                last time consumption/overall running time: 33.3150s / 72519.3709 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.0989
env0_second_0:                 episode reward: 3.7000,                 loss: 0.2747
env1_first_0:                 episode reward: -4.2000,                 loss: nan
env1_second_0:                 episode reward: 4.2000,                 loss: nan
Episode: 41381/50000 (82.7620%),                 avg. length: 567.35,                last time consumption/overall running time: 34.7086s / 72554.0795 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.1165
env0_second_0:                 episode reward: 3.9500,                 loss: 0.2437
env1_first_0:                 episode reward: -4.1000,                 loss: nan
env1_second_0:                 episode reward: 4.1000,                 loss: nan
Episode: 41401/50000 (82.8020%),                 avg. length: 558.9,                last time consumption/overall running time: 34.0554s / 72588.1349 s
env0_first_0:                 episode reward: -3.3500,                 loss: 0.1080
env0_second_0:                 episode reward: 3.3500,                 loss: 0.2352
env1_first_0:                 episode reward: -4.1000,                 loss: nan
env1_second_0:                 episode reward: 4.1000,                 loss: nan
Episode: 41421/50000 (82.8420%),                 avg. length: 616.9,                last time consumption/overall running time: 38.9898s / 72627.1247 s
env0_first_0:                 episode reward: -4.0500,                 loss: 0.1005
env0_second_0:                 episode reward: 4.0500,                 loss: 0.2766
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 41441/50000 (82.8820%),                 avg. length: 544.7,                last time consumption/overall running time: 33.6759s / 72660.8005 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.1136
env0_second_0:                 episode reward: 3.9500,                 loss: 0.3726
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 41461/50000 (82.9220%),                 avg. length: 588.0,                last time consumption/overall running time: 40.7936s / 72701.5941 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.0945
env0_second_0:                 episode reward: 3.8500,                 loss: 0.3297
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 41481/50000 (82.9620%),                 avg. length: 560.95,                last time consumption/overall running time: 34.0602s / 72735.6544 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.1338
env0_second_0:                 episode reward: 3.6500,                 loss: 0.3012
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 41501/50000 (83.0020%),                 avg. length: 554.65,                last time consumption/overall running time: 34.0523s / 72769.7067 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.1105
env0_second_0:                 episode reward: 3.5500,                 loss: 0.2430
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 41521/50000 (83.0420%),                 avg. length: 610.7,                last time consumption/overall running time: 37.9782s / 72807.6849 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.1138
env0_second_0:                 episode reward: 3.4500,                 loss: 0.2610
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 41541/50000 (83.0820%),                 avg. length: 552.8,                last time consumption/overall running time: 33.8820s / 72841.5669 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.1191
env0_second_0:                 episode reward: 3.4500,                 loss: 0.2586
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 41561/50000 (83.1220%),                 avg. length: 583.45,                last time consumption/overall running time: 34.7166s / 72876.2835 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.1222
env0_second_0:                 episode reward: 3.9000,                 loss: 0.2306
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 41581/50000 (83.1620%),                 avg. length: 548.7,                last time consumption/overall running time: 33.3241s / 72909.6076 s
env0_first_0:                 episode reward: -4.0500,                 loss: 0.1542
env0_second_0:                 episode reward: 4.0500,                 loss: 0.3040
env1_first_0:                 episode reward: -3.1500,                 loss: nan
env1_second_0:                 episode reward: 3.1500,                 loss: nan
Episode: 41601/50000 (83.2020%),                 avg. length: 602.9,                last time consumption/overall running time: 36.9490s / 72946.5565 s
env0_first_0:                 episode reward: -2.9000,                 loss: 0.1265
env0_second_0:                 episode reward: 2.9000,                 loss: 0.2517
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 41621/50000 (83.2420%),                 avg. length: 609.05,                last time consumption/overall running time: 37.9683s / 72984.5248 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.1263
env0_second_0:                 episode reward: 3.8000,                 loss: 0.2689
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 41641/50000 (83.2820%),                 avg. length: 597.65,                last time consumption/overall running time: 36.2597s / 73020.7845 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.1062
env0_second_0:                 episode reward: 3.7000,                 loss: 0.2478
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 41661/50000 (83.3220%),                 avg. length: 522.95,                last time consumption/overall running time: 33.2080s / 73053.9925 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.1235
env0_second_0:                 episode reward: 4.0000,                 loss: 0.2451
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 41681/50000 (83.3620%),                 avg. length: 586.9,                last time consumption/overall running time: 36.9431s / 73090.9357 s
env0_first_0:                 episode reward: -4.0500,                 loss: 0.1044
env0_second_0:                 episode reward: 4.0500,                 loss: 0.2398
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 41701/50000 (83.4020%),                 avg. length: 567.25,                last time consumption/overall running time: 35.9203s / 73126.8560 s
env0_first_0:                 episode reward: -3.1500,                 loss: 0.0951
env0_second_0:                 episode reward: 3.1500,                 loss: 0.2119
env1_first_0:                 episode reward: -4.1500,                 loss: nan
env1_second_0:                 episode reward: 4.1500,                 loss: nan
Episode: 41721/50000 (83.4420%),                 avg. length: 577.35,                last time consumption/overall running time: 36.4625s / 73163.3185 s
env0_first_0:                 episode reward: -3.7500,                 loss: 0.1181
env0_second_0:                 episode reward: 3.7500,                 loss: 0.2885
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 41741/50000 (83.4820%),                 avg. length: 569.15,                last time consumption/overall running time: 34.1657s / 73197.4842 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.1197
env0_second_0:                 episode reward: 3.6500,                 loss: 0.2666
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 41761/50000 (83.5220%),                 avg. length: 582.5,                last time consumption/overall running time: 34.9571s / 73232.4414 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.1294
env0_second_0:                 episode reward: 3.7000,                 loss: 0.2540
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 41781/50000 (83.5620%),                 avg. length: 554.5,                last time consumption/overall running time: 39.3196s / 73271.7609 s
env0_first_0:                 episode reward: -4.1500,                 loss: 0.0963
env0_second_0:                 episode reward: 4.1500,                 loss: 0.2085
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 41801/50000 (83.6020%),                 avg. length: 555.05,                last time consumption/overall running time: 33.5820s / 73305.3429 s
env0_first_0:                 episode reward: -4.0500,                 loss: 0.0895
env0_second_0:                 episode reward: 4.0500,                 loss: 0.2160
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 41821/50000 (83.6420%),                 avg. length: 513.55,                last time consumption/overall running time: 31.7281s / 73337.0710 s
env0_first_0:                 episode reward: -4.2500,                 loss: 0.1681
env0_second_0:                 episode reward: 4.2500,                 loss: 0.3494
env1_first_0:                 episode reward: -3.3500,                 loss: nan
env1_second_0:                 episode reward: 3.3500,                 loss: nan
Episode: 41841/50000 (83.6820%),                 avg. length: 506.65,                last time consumption/overall running time: 31.2166s / 73368.2876 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.1662
env0_second_0:                 episode reward: 3.6000,                 loss: 0.2834
env1_first_0:                 episode reward: -4.2500,                 loss: nan
env1_second_0:                 episode reward: 4.2500,                 loss: nan
Episode: 41861/50000 (83.7220%),                 avg. length: 578.55,                last time consumption/overall running time: 34.9972s / 73403.2848 s
env0_first_0:                 episode reward: -4.0500,                 loss: 0.1496
env0_second_0:                 episode reward: 4.0500,                 loss: 0.3444
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 41881/50000 (83.7620%),                 avg. length: 581.4,                last time consumption/overall running time: 40.2199s / 73443.5047 s
env0_first_0:                 episode reward: -4.3000,                 loss: 0.1124
env0_second_0:                 episode reward: 4.3000,                 loss: 0.2729
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 41901/50000 (83.8020%),                 avg. length: 580.75,                last time consumption/overall running time: 37.3590s / 73480.8637 s
env0_first_0:                 episode reward: -2.8500,                 loss: 0.1787
env0_second_0:                 episode reward: 2.8500,                 loss: 0.3535
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 41921/50000 (83.8420%),                 avg. length: 654.4,                last time consumption/overall running time: 38.6243s / 73519.4879 s
env0_first_0:                 episode reward: -3.2500,                 loss: 0.0906
env0_second_0:                 episode reward: 3.2500,                 loss: 0.2703
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 41941/50000 (83.8820%),                 avg. length: 555.6,                last time consumption/overall running time: 34.3005s / 73553.7884 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.1235
env0_second_0:                 episode reward: 3.7000,                 loss: 0.2417
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 41961/50000 (83.9220%),                 avg. length: 552.2,                last time consumption/overall running time: 34.5826s / 73588.3710 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.1247
env0_second_0:                 episode reward: 3.6000,                 loss: 0.3131
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 41981/50000 (83.9620%),                 avg. length: 573.15,                last time consumption/overall running time: 35.0929s / 73623.4639 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.1475
env0_second_0:                 episode reward: 3.8500,                 loss: 0.3008
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 42001/50000 (84.0020%),                 avg. length: 567.35,                last time consumption/overall running time: 34.8912s / 73658.3550 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.1500
env0_second_0:                 episode reward: 3.5500,                 loss: 0.3172
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 42021/50000 (84.0420%),                 avg. length: 536.85,                last time consumption/overall running time: 33.1963s / 73691.5513 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.1368
env0_second_0:                 episode reward: 3.9500,                 loss: 0.3060
env1_first_0:                 episode reward: -4.2000,                 loss: nan
env1_second_0:                 episode reward: 4.2000,                 loss: nan
Episode: 42041/50000 (84.0820%),                 avg. length: 524.45,                last time consumption/overall running time: 33.5251s / 73725.0764 s
env0_first_0:                 episode reward: -3.3000,                 loss: 0.1278
env0_second_0:                 episode reward: 3.3000,                 loss: 0.2720
env1_first_0:                 episode reward: -4.3000,                 loss: nan
env1_second_0:                 episode reward: 4.3000,                 loss: nan
Episode: 42061/50000 (84.1220%),                 avg. length: 584.95,                last time consumption/overall running time: 36.3829s / 73761.4593 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.0913
env0_second_0:                 episode reward: 3.9000,                 loss: 0.2347
env1_first_0:                 episode reward: -4.4500,                 loss: nan
env1_second_0:                 episode reward: 4.4500,                 loss: nan
Episode: 42081/50000 (84.1620%),                 avg. length: 574.5,                last time consumption/overall running time: 37.8452s / 73799.3045 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.1281
env0_second_0:                 episode reward: 3.4500,                 loss: 0.2467
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 42101/50000 (84.2020%),                 avg. length: 599.75,                last time consumption/overall running time: 36.0384s / 73835.3429 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.1103
env0_second_0:                 episode reward: 3.5500,                 loss: 0.2791
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 42121/50000 (84.2420%),                 avg. length: 571.75,                last time consumption/overall running time: 34.6663s / 73870.0092 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.1200
env0_second_0:                 episode reward: 4.0000,                 loss: 0.2849
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 42141/50000 (84.2820%),                 avg. length: 589.75,                last time consumption/overall running time: 36.0060s / 73906.0152 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.1189
env0_second_0:                 episode reward: 3.5500,                 loss: 0.2934
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 42161/50000 (84.3220%),                 avg. length: 572.95,                last time consumption/overall running time: 34.3520s / 73940.3672 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.1626
env0_second_0:                 episode reward: 3.5500,                 loss: 0.3329
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 42181/50000 (84.3620%),                 avg. length: 541.7,                last time consumption/overall running time: 32.8820s / 73973.2492 s
env0_first_0:                 episode reward: -4.2500,                 loss: 0.1240
env0_second_0:                 episode reward: 4.2500,                 loss: 0.2727
env1_first_0:                 episode reward: -3.5000,                 loss: nan
env1_second_0:                 episode reward: 3.5000,                 loss: nan
Episode: 42201/50000 (84.4020%),                 avg. length: 559.85,                last time consumption/overall running time: 33.7881s / 74007.0373 s
env0_first_0:                 episode reward: -3.3500,                 loss: 0.1216
env0_second_0:                 episode reward: 3.3500,                 loss: 0.2566
env1_first_0:                 episode reward: -4.3000,                 loss: nan
env1_second_0:                 episode reward: 4.3000,                 loss: nan
Episode: 42221/50000 (84.4420%),                 avg. length: 583.85,                last time consumption/overall running time: 35.4782s / 74042.5155 s
env0_first_0:                 episode reward: -3.2500,                 loss: 0.1133
env0_second_0:                 episode reward: 3.2500,                 loss: 0.2275
env1_first_0:                 episode reward: -4.2000,                 loss: nan
env1_second_0:                 episode reward: 4.2000,                 loss: nan
Episode: 42241/50000 (84.4820%),                 avg. length: 562.4,                last time consumption/overall running time: 34.2883s / 74076.8038 s
env0_first_0:                 episode reward: -4.3000,                 loss: 0.0801
env0_second_0:                 episode reward: 4.3000,                 loss: 0.1730
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 42261/50000 (84.5220%),                 avg. length: 583.65,                last time consumption/overall running time: 36.2601s / 74113.0639 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.1283
env0_second_0:                 episode reward: 3.5000,                 loss: 0.2489
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 42281/50000 (84.5620%),                 avg. length: 575.5,                last time consumption/overall running time: 35.3420s / 74148.4059 s
env0_first_0:                 episode reward: -3.1000,                 loss: 0.1113
env0_second_0:                 episode reward: 3.1000,                 loss: 0.4270
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 42301/50000 (84.6020%),                 avg. length: 587.25,                last time consumption/overall running time: 36.0362s / 74184.4421 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.1237
env0_second_0:                 episode reward: 3.5500,                 loss: 0.5254
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 42321/50000 (84.6420%),                 avg. length: 597.85,                last time consumption/overall running time: 38.1793s / 74222.6213 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.0983
env0_second_0:                 episode reward: 3.8500,                 loss: 0.3614
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 42341/50000 (84.6820%),                 avg. length: 561.95,                last time consumption/overall running time: 34.3062s / 74256.9275 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.1423
env0_second_0:                 episode reward: 3.5500,                 loss: 0.3234
env1_first_0:                 episode reward: -3.2500,                 loss: nan
env1_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 42361/50000 (84.7220%),                 avg. length: 606.75,                last time consumption/overall running time: 36.7002s / 74293.6277 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.1288
env0_second_0:                 episode reward: 3.5500,                 loss: 0.4279
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 42381/50000 (84.7620%),                 avg. length: 605.85,                last time consumption/overall running time: 37.0650s / 74330.6927 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.1320
env0_second_0:                 episode reward: 3.9500,                 loss: 1.0759
env1_first_0:                 episode reward: -3.0000,                 loss: nan
env1_second_0:                 episode reward: 3.0000,                 loss: nan
Episode: 42401/50000 (84.8020%),                 avg. length: 571.25,                last time consumption/overall running time: 36.4822s / 74367.1750 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.1223
env0_second_0:                 episode reward: 3.8500,                 loss: 0.4015
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 42421/50000 (84.8420%),                 avg. length: 569.0,                last time consumption/overall running time: 34.1611s / 74401.3361 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.1089
env0_second_0:                 episode reward: 3.9500,                 loss: 0.3108
env1_first_0:                 episode reward: -4.1500,                 loss: nan
env1_second_0:                 episode reward: 4.1500,                 loss: nan
Episode: 42441/50000 (84.8820%),                 avg. length: 550.35,                last time consumption/overall running time: 33.3326s / 74434.6687 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.0962
env0_second_0:                 episode reward: 3.6000,                 loss: 0.2494
env1_first_0:                 episode reward: -4.4000,                 loss: nan
env1_second_0:                 episode reward: 4.4000,                 loss: nan
Episode: 42461/50000 (84.9220%),                 avg. length: 607.15,                last time consumption/overall running time: 36.6564s / 74471.3251 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.1232
env0_second_0:                 episode reward: 3.8500,                 loss: 0.2941
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 42481/50000 (84.9620%),                 avg. length: 560.15,                last time consumption/overall running time: 35.0100s / 74506.3351 s
env0_first_0:                 episode reward: -3.2500,                 loss: 0.1218
env0_second_0:                 episode reward: 3.2500,                 loss: 0.4196
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 42501/50000 (85.0020%),                 avg. length: 561.8,                last time consumption/overall running time: 35.5457s / 74541.8808 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.1382
env0_second_0:                 episode reward: 3.8000,                 loss: 0.3288
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 42521/50000 (85.0420%),                 avg. length: 512.3,                last time consumption/overall running time: 31.9405s / 74573.8214 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.1411
env0_second_0:                 episode reward: 4.0000,                 loss: 0.2994
env1_first_0:                 episode reward: -4.2500,                 loss: nan
env1_second_0:                 episode reward: 4.2500,                 loss: nan
Episode: 42541/50000 (85.0820%),                 avg. length: 564.75,                last time consumption/overall running time: 34.2491s / 74608.0704 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.1118
env0_second_0:                 episode reward: 3.4500,                 loss: 0.3066
env1_first_0:                 episode reward: -4.1500,                 loss: nan
env1_second_0:                 episode reward: 4.1500,                 loss: nan
Episode: 42561/50000 (85.1220%),                 avg. length: 625.5,                last time consumption/overall running time: 38.5125s / 74646.5830 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.0998
env0_second_0:                 episode reward: 3.5500,                 loss: 0.3782
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 42581/50000 (85.1620%),                 avg. length: 585.95,                last time consumption/overall running time: 36.0961s / 74682.6791 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.1084
env0_second_0:                 episode reward: 3.6000,                 loss: 0.3780
env1_first_0:                 episode reward: -4.2500,                 loss: nan
env1_second_0:                 episode reward: 4.2500,                 loss: nan
Episode: 42601/50000 (85.2020%),                 avg. length: 599.1,                last time consumption/overall running time: 35.8093s / 74718.4884 s
env0_first_0:                 episode reward: -4.1500,                 loss: 0.1088
env0_second_0:                 episode reward: 4.1500,                 loss: 0.4576
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 42621/50000 (85.2420%),                 avg. length: 561.7,                last time consumption/overall running time: 34.0360s / 74752.5244 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.0970
env0_second_0:                 episode reward: 3.9000,                 loss: 0.2824
env1_first_0:                 episode reward: -4.1500,                 loss: nan
env1_second_0:                 episode reward: 4.1500,                 loss: nan
Episode: 42641/50000 (85.2820%),                 avg. length: 543.1,                last time consumption/overall running time: 34.1214s / 74786.6458 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.1021
env0_second_0:                 episode reward: 3.9500,                 loss: 0.3455
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 42661/50000 (85.3220%),                 avg. length: 575.7,                last time consumption/overall running time: 36.4132s / 74823.0590 s
env0_first_0:                 episode reward: -4.0500,                 loss: 0.0804
env0_second_0:                 episode reward: 4.0500,                 loss: 0.3162
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 42681/50000 (85.3620%),                 avg. length: 567.85,                last time consumption/overall running time: 34.8475s / 74857.9064 s
env0_first_0:                 episode reward: -3.3500,                 loss: 0.1200
env0_second_0:                 episode reward: 3.3500,                 loss: 0.4336
env1_first_0:                 episode reward: -4.2500,                 loss: nan
env1_second_0:                 episode reward: 4.2500,                 loss: nan
Episode: 42701/50000 (85.4020%),                 avg. length: 578.75,                last time consumption/overall running time: 35.1699s / 74893.0763 s
env0_first_0:                 episode reward: -4.2000,                 loss: 0.1165
env0_second_0:                 episode reward: 4.2000,                 loss: 0.7736
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 42721/50000 (85.4420%),                 avg. length: 594.0,                last time consumption/overall running time: 35.8750s / 74928.9513 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.1457
env0_second_0:                 episode reward: 3.5000,                 loss: 0.4522
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 42741/50000 (85.4820%),                 avg. length: 594.0,                last time consumption/overall running time: 35.5670s / 74964.5184 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.1509
env0_second_0:                 episode reward: 3.6500,                 loss: 0.9603
env1_first_0:                 episode reward: -3.1500,                 loss: nan
env1_second_0:                 episode reward: 3.1500,                 loss: nan
Episode: 42761/50000 (85.5220%),                 avg. length: 639.1,                last time consumption/overall running time: 38.6092s / 75003.1276 s
env0_first_0:                 episode reward: -2.5500,                 loss: 0.1624
env0_second_0:                 episode reward: 2.5500,                 loss: 0.4303
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 42781/50000 (85.5620%),                 avg. length: 582.75,                last time consumption/overall running time: 35.0659s / 75038.1934 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.1337
env0_second_0:                 episode reward: 3.5500,                 loss: 0.3270
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 42801/50000 (85.6020%),                 avg. length: 580.85,                last time consumption/overall running time: 36.4072s / 75074.6006 s
env0_first_0:                 episode reward: -3.3000,                 loss: 0.1318
env0_second_0:                 episode reward: 3.3000,                 loss: 0.3358
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 42821/50000 (85.6420%),                 avg. length: 582.95,                last time consumption/overall running time: 37.0671s / 75111.6677 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.0914
env0_second_0:                 episode reward: 3.5500,                 loss: 0.2945
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 42841/50000 (85.6820%),                 avg. length: 551.25,                last time consumption/overall running time: 36.5456s / 75148.2133 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.1067
env0_second_0:                 episode reward: 3.4500,                 loss: 0.2743
env1_first_0:                 episode reward: -4.2500,                 loss: nan
env1_second_0:                 episode reward: 4.2500,                 loss: nan
Episode: 42861/50000 (85.7220%),                 avg. length: 603.2,                last time consumption/overall running time: 36.6117s / 75184.8250 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.1376
env0_second_0:                 episode reward: 3.8500,                 loss: 0.2953
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 42881/50000 (85.7620%),                 avg. length: 538.55,                last time consumption/overall running time: 32.8974s / 75217.7225 s
env0_first_0:                 episode reward: -2.6000,                 loss: 0.1491
env0_second_0:                 episode reward: 2.6000,                 loss: 0.3338
env1_first_0:                 episode reward: -4.3000,                 loss: nan
env1_second_0:                 episode reward: 4.3000,                 loss: nan
Episode: 42901/50000 (85.8020%),                 avg. length: 567.75,                last time consumption/overall running time: 34.5363s / 75252.2588 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.1131
env0_second_0:                 episode reward: 3.6500,                 loss: 0.3263
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 42921/50000 (85.8420%),                 avg. length: 624.6,                last time consumption/overall running time: 38.3153s / 75290.5741 s
env0_first_0:                 episode reward: -4.1500,                 loss: 0.1071
env0_second_0:                 episode reward: 4.1500,                 loss: 0.3081
env1_first_0:                 episode reward: -3.3500,                 loss: nan
env1_second_0:                 episode reward: 3.3500,                 loss: nan
Episode: 42941/50000 (85.8820%),                 avg. length: 606.1,                last time consumption/overall running time: 36.9838s / 75327.5579 s
env0_first_0:                 episode reward: -4.3000,                 loss: 0.0969
env0_second_0:                 episode reward: 4.3000,                 loss: 0.2772
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 42961/50000 (85.9220%),                 avg. length: 578.1,                last time consumption/overall running time: 34.9794s / 75362.5373 s
env0_first_0:                 episode reward: -3.2000,                 loss: 0.1031
env0_second_0:                 episode reward: 3.2000,                 loss: 0.3881
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 42981/50000 (85.9620%),                 avg. length: 613.85,                last time consumption/overall running time: 36.9347s / 75399.4720 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.0981
env0_second_0:                 episode reward: 3.9000,                 loss: 0.3896
env1_first_0:                 episode reward: -4.2500,                 loss: nan
env1_second_0:                 episode reward: 4.2500,                 loss: nan
Episode: 43001/50000 (86.0020%),                 avg. length: 593.25,                last time consumption/overall running time: 36.2897s / 75435.7618 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.1360
env0_second_0:                 episode reward: 3.5500,                 loss: 0.4227
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 43021/50000 (86.0420%),                 avg. length: 567.1,                last time consumption/overall running time: 34.7638s / 75470.5256 s
env0_first_0:                 episode reward: -4.2000,                 loss: 0.1401
env0_second_0:                 episode reward: 4.2000,                 loss: 0.3743
env1_first_0:                 episode reward: -2.8500,                 loss: nan
env1_second_0:                 episode reward: 2.8500,                 loss: nan
Episode: 43041/50000 (86.0820%),                 avg. length: 611.3,                last time consumption/overall running time: 36.7555s / 75507.2811 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.1024
env0_second_0:                 episode reward: 3.8000,                 loss: 0.3342
env1_first_0:                 episode reward: -3.5000,                 loss: nan
env1_second_0:                 episode reward: 3.5000,                 loss: nan
Episode: 43061/50000 (86.1220%),                 avg. length: 611.15,                last time consumption/overall running time: 37.3252s / 75544.6062 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.1394
env0_second_0:                 episode reward: 3.9000,                 loss: 0.3568
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 43081/50000 (86.1620%),                 avg. length: 621.8,                last time consumption/overall running time: 36.7822s / 75581.3884 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.1379
env0_second_0:                 episode reward: 4.0000,                 loss: 0.3064
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 43101/50000 (86.2020%),                 avg. length: 619.25,                last time consumption/overall running time: 37.0150s / 75618.4034 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.1015
env0_second_0:                 episode reward: 3.6500,                 loss: 0.4238
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 43121/50000 (86.2420%),                 avg. length: 556.15,                last time consumption/overall running time: 34.1002s / 75652.5036 s
env0_first_0:                 episode reward: -3.7500,                 loss: 0.1259
env0_second_0:                 episode reward: 3.7500,                 loss: 0.3659
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 43141/50000 (86.2820%),                 avg. length: 578.35,                last time consumption/overall running time: 35.0745s / 75687.5781 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.1053
env0_second_0:                 episode reward: 3.8000,                 loss: 0.3347
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 43161/50000 (86.3220%),                 avg. length: 588.05,                last time consumption/overall running time: 37.3453s / 75724.9234 s
env0_first_0:                 episode reward: -4.4000,                 loss: 0.0966
env0_second_0:                 episode reward: 4.4000,                 loss: 0.2630
env1_first_0:                 episode reward: -3.5000,                 loss: nan
env1_second_0:                 episode reward: 3.5000,                 loss: nan
Episode: 43181/50000 (86.3620%),                 avg. length: 656.85,                last time consumption/overall running time: 40.7378s / 75765.6612 s
env0_first_0:                 episode reward: -3.1000,                 loss: 0.1593
env0_second_0:                 episode reward: 3.1000,                 loss: 0.3571
env1_first_0:                 episode reward: -3.5000,                 loss: nan
env1_second_0:                 episode reward: 3.5000,                 loss: nan
Episode: 43201/50000 (86.4020%),                 avg. length: 656.0,                last time consumption/overall running time: 39.2947s / 75804.9559 s
env0_first_0:                 episode reward: -3.2500,                 loss: 0.1321
env0_second_0:                 episode reward: 3.2500,                 loss: 0.3062
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 43221/50000 (86.4420%),                 avg. length: 641.55,                last time consumption/overall running time: 39.0321s / 75843.9880 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.1531
env0_second_0:                 episode reward: 3.8500,                 loss: 0.3814
env1_first_0:                 episode reward: -2.7000,                 loss: nan
env1_second_0:                 episode reward: 2.7000,                 loss: nan
Episode: 43241/50000 (86.4820%),                 avg. length: 552.5,                last time consumption/overall running time: 35.3871s / 75879.3751 s
env0_first_0:                 episode reward: -3.0000,                 loss: 0.2129
env0_second_0:                 episode reward: 3.0000,                 loss: 0.4026
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 43261/50000 (86.5220%),                 avg. length: 668.55,                last time consumption/overall running time: 41.5407s / 75920.9158 s
env0_first_0:                 episode reward: -3.2000,                 loss: 0.1182
env0_second_0:                 episode reward: 3.2000,                 loss: 0.3319
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 43281/50000 (86.5620%),                 avg. length: 633.7,                last time consumption/overall running time: 39.2375s / 75960.1533 s
env0_first_0:                 episode reward: -3.3500,                 loss: 0.0886
env0_second_0:                 episode reward: 3.3500,                 loss: 0.2921
env1_first_0:                 episode reward: -4.3000,                 loss: nan
env1_second_0:                 episode reward: 4.3000,                 loss: nan
Episode: 43301/50000 (86.6020%),                 avg. length: 585.8,                last time consumption/overall running time: 36.1167s / 75996.2700 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.1216
env0_second_0:                 episode reward: 3.4500,                 loss: 0.3004
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 43321/50000 (86.6420%),                 avg. length: 611.65,                last time consumption/overall running time: 36.4853s / 76032.7553 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.1315
env0_second_0:                 episode reward: 3.5500,                 loss: 0.2795
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 43341/50000 (86.6820%),                 avg. length: 597.35,                last time consumption/overall running time: 35.8628s / 76068.6180 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.1397
env0_second_0:                 episode reward: 3.8500,                 loss: 0.2852
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 43361/50000 (86.7220%),                 avg. length: 580.0,                last time consumption/overall running time: 34.8385s / 76103.4565 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.1389
env0_second_0:                 episode reward: 3.9000,                 loss: 0.3454
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 43381/50000 (86.7620%),                 avg. length: 587.7,                last time consumption/overall running time: 35.4625s / 76138.9190 s
env0_first_0:                 episode reward: -4.2000,                 loss: 0.1068
env0_second_0:                 episode reward: 4.2000,                 loss: 0.4444
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 43401/50000 (86.8020%),                 avg. length: 578.05,                last time consumption/overall running time: 35.5106s / 76174.4296 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.1201
env0_second_0:                 episode reward: 4.0000,                 loss: 0.3496
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 43421/50000 (86.8420%),                 avg. length: 563.25,                last time consumption/overall running time: 34.3271s / 76208.7567 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.1275
env0_second_0:                 episode reward: 3.8500,                 loss: 0.3073
env1_first_0:                 episode reward: -3.1500,                 loss: nan
env1_second_0:                 episode reward: 3.1500,                 loss: nan
Episode: 43441/50000 (86.8820%),                 avg. length: 561.0,                last time consumption/overall running time: 38.9655s / 76247.7222 s
env0_first_0:                 episode reward: -3.7500,                 loss: 0.1266
env0_second_0:                 episode reward: 3.7500,                 loss: 0.2966
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 43461/50000 (86.9220%),                 avg. length: 568.45,                last time consumption/overall running time: 34.1942s / 76281.9164 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.1055
env0_second_0:                 episode reward: 4.0000,                 loss: 0.2787
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 43481/50000 (86.9620%),                 avg. length: 559.2,                last time consumption/overall running time: 34.2547s / 76316.1712 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.1328
env0_second_0:                 episode reward: 3.9500,                 loss: 0.3361
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 43501/50000 (87.0020%),                 avg. length: 567.6,                last time consumption/overall running time: 35.9096s / 76352.0808 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.0975
env0_second_0:                 episode reward: 3.7000,                 loss: 0.2814
env1_first_0:                 episode reward: -4.5000,                 loss: nan
env1_second_0:                 episode reward: 4.5000,                 loss: nan
Episode: 43521/50000 (87.0420%),                 avg. length: 576.9,                last time consumption/overall running time: 37.4969s / 76389.5777 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.1000
env0_second_0:                 episode reward: 3.6500,                 loss: 0.2893
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 43541/50000 (87.0820%),                 avg. length: 627.45,                last time consumption/overall running time: 37.5929s / 76427.1706 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.0926
env0_second_0:                 episode reward: 3.6000,                 loss: 0.3081
env1_first_0:                 episode reward: -4.1500,                 loss: nan
env1_second_0:                 episode reward: 4.1500,                 loss: nan
Episode: 43561/50000 (87.1220%),                 avg. length: 629.7,                last time consumption/overall running time: 38.6028s / 76465.7733 s
env0_first_0:                 episode reward: -2.4500,                 loss: 0.1732
env0_second_0:                 episode reward: 2.4500,                 loss: 0.3934
env1_first_0:                 episode reward: -2.1500,                 loss: nan
env1_second_0:                 episode reward: 2.1500,                 loss: nan
Episode: 43581/50000 (87.1620%),                 avg. length: 600.75,                last time consumption/overall running time: 36.4292s / 76502.2025 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.1123
env0_second_0:                 episode reward: 3.6000,                 loss: 0.3586
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 43601/50000 (87.2020%),                 avg. length: 671.6,                last time consumption/overall running time: 39.7507s / 76541.9531 s
env0_first_0:                 episode reward: -2.8500,                 loss: 0.1650
env0_second_0:                 episode reward: 2.8500,                 loss: 0.4516
env1_first_0:                 episode reward: -2.8000,                 loss: nan
env1_second_0:                 episode reward: 2.8000,                 loss: nan
Episode: 43621/50000 (87.2420%),                 avg. length: 600.85,                last time consumption/overall running time: 36.0195s / 76577.9726 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.1363
env0_second_0:                 episode reward: 3.4500,                 loss: 0.3172
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 43641/50000 (87.2820%),                 avg. length: 592.4,                last time consumption/overall running time: 35.6287s / 76613.6013 s
env0_first_0:                 episode reward: -4.1500,                 loss: 0.1301
env0_second_0:                 episode reward: 4.1500,                 loss: 0.3137
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 43661/50000 (87.3220%),                 avg. length: 603.35,                last time consumption/overall running time: 36.7753s / 76650.3766 s
env0_first_0:                 episode reward: -3.4000,                 loss: 0.1420
env0_second_0:                 episode reward: 3.4000,                 loss: 0.3534
env1_first_0:                 episode reward: -4.4500,                 loss: nan
env1_second_0:                 episode reward: 4.4500,                 loss: nan
Episode: 43681/50000 (87.3620%),                 avg. length: 599.9,                last time consumption/overall running time: 36.4190s / 76686.7957 s
env0_first_0:                 episode reward: -4.0500,                 loss: 0.1299
env0_second_0:                 episode reward: 4.0500,                 loss: 0.2972
env1_first_0:                 episode reward: -2.8500,                 loss: nan
env1_second_0:                 episode reward: 2.8500,                 loss: nan
Episode: 43701/50000 (87.4020%),                 avg. length: 583.8,                last time consumption/overall running time: 35.2682s / 76722.0639 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.1199
env0_second_0:                 episode reward: 3.5500,                 loss: 0.2574
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 43721/50000 (87.4420%),                 avg. length: 594.65,                last time consumption/overall running time: 35.8360s / 76757.8999 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.1169
env0_second_0:                 episode reward: 3.6000,                 loss: 0.3363
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 43741/50000 (87.4820%),                 avg. length: 588.5,                last time consumption/overall running time: 35.3581s / 76793.2580 s
env0_first_0:                 episode reward: -3.4000,                 loss: 0.1015
env0_second_0:                 episode reward: 3.4000,                 loss: 0.2641
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 43761/50000 (87.5220%),                 avg. length: 599.0,                last time consumption/overall running time: 38.3407s / 76831.5988 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.1007
env0_second_0:                 episode reward: 3.7000,                 loss: 0.2824
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 43781/50000 (87.5620%),                 avg. length: 639.1,                last time consumption/overall running time: 38.0031s / 76869.6019 s
env0_first_0:                 episode reward: -2.8000,                 loss: 0.1632
env0_second_0:                 episode reward: 2.8000,                 loss: 0.4068
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 43801/50000 (87.6020%),                 avg. length: 618.3,                last time consumption/overall running time: 37.2871s / 76906.8889 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.1212
env0_second_0:                 episode reward: 3.7000,                 loss: 0.2427
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 43821/50000 (87.6420%),                 avg. length: 676.5,                last time consumption/overall running time: 40.1794s / 76947.0684 s
env0_first_0:                 episode reward: -3.3500,                 loss: 0.1405
env0_second_0:                 episode reward: 3.3500,                 loss: 0.2803
env1_first_0:                 episode reward: -3.3500,                 loss: nan
env1_second_0:                 episode reward: 3.3500,                 loss: nan
Episode: 43841/50000 (87.6820%),                 avg. length: 652.25,                last time consumption/overall running time: 40.3175s / 76987.3858 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.1014
env0_second_0:                 episode reward: 3.9500,                 loss: 0.2792
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 43861/50000 (87.7220%),                 avg. length: 609.55,                last time consumption/overall running time: 36.9520s / 77024.3379 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.1133
env0_second_0:                 episode reward: 3.5000,                 loss: 0.2731
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 43881/50000 (87.7620%),                 avg. length: 632.05,                last time consumption/overall running time: 37.9840s / 77062.3219 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.1410
env0_second_0:                 episode reward: 3.5000,                 loss: 0.3394
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 43901/50000 (87.8020%),                 avg. length: 643.1,                last time consumption/overall running time: 39.8571s / 77102.1790 s
env0_first_0:                 episode reward: -3.0000,                 loss: 0.0955
env0_second_0:                 episode reward: 3.0000,                 loss: 0.2283
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 43921/50000 (87.8420%),                 avg. length: 672.35,                last time consumption/overall running time: 43.0137s / 77145.1927 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.0777
env0_second_0:                 episode reward: 3.5500,                 loss: 0.3084
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 43941/50000 (87.8820%),                 avg. length: 603.75,                last time consumption/overall running time: 37.3475s / 77182.5402 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.1103
env0_second_0:                 episode reward: 3.9500,                 loss: 0.3024
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 43961/50000 (87.9220%),                 avg. length: 633.4,                last time consumption/overall running time: 37.6584s / 77220.1985 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.1299
env0_second_0:                 episode reward: 3.8000,                 loss: 0.4208
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 43981/50000 (87.9620%),                 avg. length: 596.35,                last time consumption/overall running time: 36.0549s / 77256.2535 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.1163
env0_second_0:                 episode reward: 3.9000,                 loss: 0.2745
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 44001/50000 (88.0020%),                 avg. length: 615.5,                last time consumption/overall running time: 37.2564s / 77293.5099 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.1008
env0_second_0:                 episode reward: 3.4500,                 loss: 0.2239
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 44021/50000 (88.0420%),                 avg. length: 619.3,                last time consumption/overall running time: 38.6479s / 77332.1578 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.1168
env0_second_0:                 episode reward: 3.8000,                 loss: 0.2274
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 44041/50000 (88.0820%),                 avg. length: 612.05,                last time consumption/overall running time: 37.4933s / 77369.6511 s
env0_first_0:                 episode reward: -3.2000,                 loss: 0.1268
env0_second_0:                 episode reward: 3.2000,                 loss: 0.2396
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 44061/50000 (88.1220%),                 avg. length: 559.9,                last time consumption/overall running time: 34.5507s / 77404.2017 s
env0_first_0:                 episode reward: -4.1000,                 loss: 0.1471
env0_second_0:                 episode reward: 4.1000,                 loss: 0.2665
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 44081/50000 (88.1620%),                 avg. length: 647.3,                last time consumption/overall running time: 39.4889s / 77443.6907 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.1152
env0_second_0:                 episode reward: 3.8500,                 loss: 0.4267
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 44101/50000 (88.2020%),                 avg. length: 679.05,                last time consumption/overall running time: 39.9606s / 77483.6513 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.1292
env0_second_0:                 episode reward: 3.9000,                 loss: 0.2609
env1_first_0:                 episode reward: -3.5000,                 loss: nan
env1_second_0:                 episode reward: 3.5000,                 loss: nan
Episode: 44121/50000 (88.2420%),                 avg. length: 604.75,                last time consumption/overall running time: 36.3055s / 77519.9568 s
env0_first_0:                 episode reward: -4.2000,                 loss: 0.1538
env0_second_0:                 episode reward: 4.2000,                 loss: 0.2414
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 44141/50000 (88.2820%),                 avg. length: 614.75,                last time consumption/overall running time: 37.1175s / 77557.0743 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.1264
env0_second_0:                 episode reward: 3.6500,                 loss: 0.2751
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 44161/50000 (88.3220%),                 avg. length: 609.05,                last time consumption/overall running time: 37.0285s / 77594.1028 s
env0_first_0:                 episode reward: -4.2500,                 loss: 0.1180
env0_second_0:                 episode reward: 4.2500,                 loss: 0.2455
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 44181/50000 (88.3620%),                 avg. length: 586.35,                last time consumption/overall running time: 36.2755s / 77630.3783 s
env0_first_0:                 episode reward: -3.3500,                 loss: 0.1406
env0_second_0:                 episode reward: 3.3500,                 loss: 0.3101
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 44201/50000 (88.4020%),                 avg. length: 652.45,                last time consumption/overall running time: 38.5704s / 77668.9487 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.0566
env0_second_0:                 episode reward: 3.4500,                 loss: 0.2099
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 44221/50000 (88.4420%),                 avg. length: 632.85,                last time consumption/overall running time: 38.2331s / 77707.1818 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.0817
env0_second_0:                 episode reward: 3.6500,                 loss: 0.1874
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 44241/50000 (88.4820%),                 avg. length: 661.6,                last time consumption/overall running time: 40.4604s / 77747.6422 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.0930
env0_second_0:                 episode reward: 3.4500,                 loss: 0.2299
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 44261/50000 (88.5220%),                 avg. length: 586.85,                last time consumption/overall running time: 36.4848s / 77784.1270 s
env0_first_0:                 episode reward: -4.2500,                 loss: 0.1253
env0_second_0:                 episode reward: 4.2500,                 loss: 0.2811
env1_first_0:                 episode reward: -3.5000,                 loss: nan
env1_second_0:                 episode reward: 3.5000,                 loss: nan
Episode: 44281/50000 (88.5620%),                 avg. length: 640.35,                last time consumption/overall running time: 38.4177s / 77822.5447 s
env0_first_0:                 episode reward: -3.2000,                 loss: 0.1117
env0_second_0:                 episode reward: 3.2000,                 loss: 0.2508
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 44301/50000 (88.6020%),                 avg. length: 616.1,                last time consumption/overall running time: 37.5349s / 77860.0796 s
env0_first_0:                 episode reward: -4.0500,                 loss: 0.1177
env0_second_0:                 episode reward: 4.0500,                 loss: 0.2783
env1_first_0:                 episode reward: -3.0000,                 loss: nan
env1_second_0:                 episode reward: 3.0000,                 loss: nan
Episode: 44321/50000 (88.6420%),                 avg. length: 660.45,                last time consumption/overall running time: 40.7547s / 77900.8343 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.1055
env0_second_0:                 episode reward: 3.7000,                 loss: 0.2561
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 44341/50000 (88.6820%),                 avg. length: 619.95,                last time consumption/overall running time: 37.7930s / 77938.6273 s
env0_first_0:                 episode reward: -3.4000,                 loss: 0.0825
env0_second_0:                 episode reward: 3.4000,                 loss: 0.2530
env1_first_0:                 episode reward: -4.5000,                 loss: nan
env1_second_0:                 episode reward: 4.5000,                 loss: nan
Episode: 44361/50000 (88.7220%),                 avg. length: 637.35,                last time consumption/overall running time: 37.5374s / 77976.1647 s
env0_first_0:                 episode reward: -4.0500,                 loss: 0.1148
env0_second_0:                 episode reward: 4.0500,                 loss: 0.2291
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 44381/50000 (88.7620%),                 avg. length: 638.25,                last time consumption/overall running time: 38.0157s / 78014.1804 s
env0_first_0:                 episode reward: -4.1500,                 loss: 0.0881
env0_second_0:                 episode reward: 4.1500,                 loss: 0.1925
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 44401/50000 (88.8020%),                 avg. length: 650.1,                last time consumption/overall running time: 40.2088s / 78054.3892 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.0837
env0_second_0:                 episode reward: 3.9000,                 loss: 0.2140
env1_first_0:                 episode reward: -4.1000,                 loss: nan
env1_second_0:                 episode reward: 4.1000,                 loss: nan
Episode: 44421/50000 (88.8420%),                 avg. length: 634.85,                last time consumption/overall running time: 38.8681s / 78093.2573 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.1371
env0_second_0:                 episode reward: 3.6500,                 loss: 0.2803
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 44441/50000 (88.8820%),                 avg. length: 655.45,                last time consumption/overall running time: 38.7345s / 78131.9918 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.0995
env0_second_0:                 episode reward: 3.9000,                 loss: 0.3004
env1_first_0:                 episode reward: -3.3500,                 loss: nan
env1_second_0:                 episode reward: 3.3500,                 loss: nan
Episode: 44461/50000 (88.9220%),                 avg. length: 698.55,                last time consumption/overall running time: 40.7534s / 78172.7452 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.0605
env0_second_0:                 episode reward: 3.6000,                 loss: 0.2301
env1_first_0:                 episode reward: -4.1500,                 loss: nan
env1_second_0:                 episode reward: 4.1500,                 loss: nan
Episode: 44481/50000 (88.9620%),                 avg. length: 736.1,                last time consumption/overall running time: 42.8686s / 78215.6139 s
env0_first_0:                 episode reward: -3.4000,                 loss: 0.0564
env0_second_0:                 episode reward: 3.4000,                 loss: 0.2236
env1_first_0:                 episode reward: -4.1000,                 loss: nan
env1_second_0:                 episode reward: 4.1000,                 loss: nan
Episode: 44501/50000 (89.0020%),                 avg. length: 653.95,                last time consumption/overall running time: 38.5574s / 78254.1713 s
env0_first_0:                 episode reward: -4.1500,                 loss: 0.0748
env0_second_0:                 episode reward: 4.1500,                 loss: 0.2623
env1_first_0:                 episode reward: -4.2500,                 loss: nan
env1_second_0:                 episode reward: 4.2500,                 loss: nan
Episode: 44521/50000 (89.0420%),                 avg. length: 674.75,                last time consumption/overall running time: 39.5667s / 78293.7380 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.1101
env0_second_0:                 episode reward: 3.6500,                 loss: 0.2588
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 44541/50000 (89.0820%),                 avg. length: 636.25,                last time consumption/overall running time: 38.8407s / 78332.5787 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.0935
env0_second_0:                 episode reward: 3.7000,                 loss: 0.2972
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 44561/50000 (89.1220%),                 avg. length: 685.6,                last time consumption/overall running time: 40.3075s / 78372.8862 s
env0_first_0:                 episode reward: -3.1000,                 loss: 0.1086
env0_second_0:                 episode reward: 3.1000,                 loss: 0.3884
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 44581/50000 (89.1620%),                 avg. length: 688.3,                last time consumption/overall running time: 41.4815s / 78414.3677 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.1005
env0_second_0:                 episode reward: 4.0000,                 loss: 0.2674
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 44601/50000 (89.2020%),                 avg. length: 687.7,                last time consumption/overall running time: 39.8970s / 78454.2647 s
env0_first_0:                 episode reward: -4.1500,                 loss: 0.0520
env0_second_0:                 episode reward: 4.1500,                 loss: 0.2015
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 44621/50000 (89.2420%),                 avg. length: 622.85,                last time consumption/overall running time: 37.1963s / 78491.4610 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.0934
env0_second_0:                 episode reward: 3.9000,                 loss: 0.2595
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 44641/50000 (89.2820%),                 avg. length: 702.75,                last time consumption/overall running time: 40.9660s / 78532.4270 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.0838
env0_second_0:                 episode reward: 3.8500,                 loss: 0.2482
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 44661/50000 (89.3220%),                 avg. length: 754.4,                last time consumption/overall running time: 43.8289s / 78576.2560 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.0877
env0_second_0:                 episode reward: 4.0000,                 loss: 0.2393
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 44681/50000 (89.3620%),                 avg. length: 645.05,                last time consumption/overall running time: 38.4108s / 78614.6668 s
env0_first_0:                 episode reward: -3.1500,                 loss: 0.1038
env0_second_0:                 episode reward: 3.1500,                 loss: 0.2516
env1_first_0:                 episode reward: -4.1000,                 loss: nan
env1_second_0:                 episode reward: 4.1000,                 loss: nan
Episode: 44701/50000 (89.4020%),                 avg. length: 704.25,                last time consumption/overall running time: 41.0592s / 78655.7260 s
env0_first_0:                 episode reward: -3.0500,                 loss: 0.0974
env0_second_0:                 episode reward: 3.0500,                 loss: 0.2294
env1_first_0:                 episode reward: -3.5000,                 loss: nan
env1_second_0:                 episode reward: 3.5000,                 loss: nan
Episode: 44721/50000 (89.4420%),                 avg. length: 687.9,                last time consumption/overall running time: 40.6692s / 78696.3952 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.0796
env0_second_0:                 episode reward: 3.5000,                 loss: 0.2138
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 44741/50000 (89.4820%),                 avg. length: 722.25,                last time consumption/overall running time: 42.6330s / 78739.0282 s
env0_first_0:                 episode reward: -4.1000,                 loss: 0.0748
env0_second_0:                 episode reward: 4.1000,                 loss: 0.2424
env1_first_0:                 episode reward: -2.8000,                 loss: nan
env1_second_0:                 episode reward: 2.8000,                 loss: nan
Episode: 44761/50000 (89.5220%),                 avg. length: 701.6,                last time consumption/overall running time: 43.2115s / 78782.2397 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.0825
env0_second_0:                 episode reward: 3.8000,                 loss: 0.3965
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 44781/50000 (89.5620%),                 avg. length: 722.6,                last time consumption/overall running time: 44.5882s / 78826.8280 s
env0_first_0:                 episode reward: -3.4000,                 loss: 0.0702
env0_second_0:                 episode reward: 3.4000,                 loss: 0.2233
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 44801/50000 (89.6020%),                 avg. length: 684.7,                last time consumption/overall running time: 40.6931s / 78867.5211 s
env0_first_0:                 episode reward: -4.5000,                 loss: 0.0470
env0_second_0:                 episode reward: 4.5000,                 loss: 0.2552
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 44821/50000 (89.6420%),                 avg. length: 726.55,                last time consumption/overall running time: 43.1480s / 78910.6691 s
env0_first_0:                 episode reward: -4.3500,                 loss: 0.0635
env0_second_0:                 episode reward: 4.3500,                 loss: 0.2510
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 44841/50000 (89.6820%),                 avg. length: 705.85,                last time consumption/overall running time: 42.9917s / 78953.6608 s
env0_first_0:                 episode reward: -3.7500,                 loss: 0.0778
env0_second_0:                 episode reward: 3.7500,                 loss: 0.2827
env1_first_0:                 episode reward: -3.3500,                 loss: nan
env1_second_0:                 episode reward: 3.3500,                 loss: nan
Episode: 44861/50000 (89.7220%),                 avg. length: 632.0,                last time consumption/overall running time: 39.5650s / 78993.2258 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.0638
env0_second_0:                 episode reward: 3.8500,                 loss: 0.2440
env1_first_0:                 episode reward: -4.1500,                 loss: nan
env1_second_0:                 episode reward: 4.1500,                 loss: nan
Episode: 44881/50000 (89.7620%),                 avg. length: 780.3,                last time consumption/overall running time: 44.6285s / 79037.8543 s
env0_first_0:                 episode reward: -3.2000,                 loss: 0.0393
env0_second_0:                 episode reward: 3.2000,                 loss: 0.2833
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 44901/50000 (89.8020%),                 avg. length: 748.15,                last time consumption/overall running time: 42.9782s / 79080.8325 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.0576
env0_second_0:                 episode reward: 3.6500,                 loss: 0.2490
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 44921/50000 (89.8420%),                 avg. length: 784.7,                last time consumption/overall running time: 47.3203s / 79128.1527 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.0427
env0_second_0:                 episode reward: 4.0000,                 loss: 0.1883
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 44941/50000 (89.8820%),                 avg. length: 781.7,                last time consumption/overall running time: 45.2792s / 79173.4320 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.0454
env0_second_0:                 episode reward: 3.6500,                 loss: 0.2238
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 44961/50000 (89.9220%),                 avg. length: 870.1,                last time consumption/overall running time: 48.7383s / 79222.1703 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.0465
env0_second_0:                 episode reward: 3.9500,                 loss: 0.3113
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 44981/50000 (89.9620%),                 avg. length: 964.8,                last time consumption/overall running time: 54.3881s / 79276.5584 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.0391
env0_second_0:                 episode reward: 3.6000,                 loss: 0.2502
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 45001/50000 (90.0020%),                 avg. length: 853.05,                last time consumption/overall running time: 49.1467s / 79325.7051 s
env0_first_0:                 episode reward: -3.3500,                 loss: 0.0645
env0_second_0:                 episode reward: 3.3500,                 loss: 0.2622
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 45021/50000 (90.0420%),                 avg. length: 958.7,                last time consumption/overall running time: 53.7093s / 79379.4145 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.0412
env0_second_0:                 episode reward: 3.9000,                 loss: 0.2948
env1_first_0:                 episode reward: -2.9500,                 loss: nan
env1_second_0:                 episode reward: 2.9500,                 loss: nan
Episode: 45041/50000 (90.0820%),                 avg. length: 1021.65,                last time consumption/overall running time: 58.0911s / 79437.5056 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.0261
env0_second_0:                 episode reward: 3.4500,                 loss: 0.2263
env1_first_0:                 episode reward: -3.1500,                 loss: nan
env1_second_0:                 episode reward: 3.1500,                 loss: nan
Episode: 45061/50000 (90.1220%),                 avg. length: 968.55,                last time consumption/overall running time: 54.4800s / 79491.9856 s
env0_first_0:                 episode reward: -3.2000,                 loss: 0.0238
env0_second_0:                 episode reward: 3.2000,                 loss: 0.2854
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 45081/50000 (90.1620%),                 avg. length: 1081.95,                last time consumption/overall running time: 59.6971s / 79551.6827 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.0178
env0_second_0:                 episode reward: 3.5500,                 loss: 0.2468
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 45101/50000 (90.2020%),                 avg. length: 1112.25,                last time consumption/overall running time: 61.8421s / 79613.5248 s
env0_first_0:                 episode reward: -3.0500,                 loss: 0.0625
env0_second_0:                 episode reward: 3.0500,                 loss: 0.3650
env1_first_0:                 episode reward: -2.9500,                 loss: nan
env1_second_0:                 episode reward: 2.9500,                 loss: nan
Episode: 45121/50000 (90.2420%),                 avg. length: 1148.4,                last time consumption/overall running time: 62.9529s / 79676.4777 s
env0_first_0:                 episode reward: -3.3500,                 loss: 0.0438
env0_second_0:                 episode reward: 3.3500,                 loss: 0.2908
env1_first_0:                 episode reward: -2.8000,                 loss: nan
env1_second_0:                 episode reward: 2.8000,                 loss: nan
Episode: 45141/50000 (90.2820%),                 avg. length: 1398.6,                last time consumption/overall running time: 76.9086s / 79753.3863 s
env0_first_0:                 episode reward: -3.7500,                 loss: -0.0292
env0_second_0:                 episode reward: 3.7500,                 loss: 0.2066
env1_first_0:                 episode reward: -3.1500,                 loss: nan
env1_second_0:                 episode reward: 3.1500,                 loss: nan
Episode: 45161/50000 (90.3220%),                 avg. length: 1345.15,                last time consumption/overall running time: 73.0327s / 79826.4190 s
env0_first_0:                 episode reward: -3.5500,                 loss: -0.0153
env0_second_0:                 episode reward: 3.5500,                 loss: 0.1948
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 45181/50000 (90.3620%),                 avg. length: 1162.6,                last time consumption/overall running time: 65.3310s / 79891.7500 s
env0_first_0:                 episode reward: -2.9000,                 loss: 0.0219
env0_second_0:                 episode reward: 2.9000,                 loss: 0.2505
env1_first_0:                 episode reward: -3.0000,                 loss: nan
env1_second_0:                 episode reward: 3.0000,                 loss: nan
Episode: 45201/50000 (90.4020%),                 avg. length: 1315.35,                last time consumption/overall running time: 71.9994s / 79963.7494 s
env0_first_0:                 episode reward: -3.1000,                 loss: -0.0303
env0_second_0:                 episode reward: 3.1000,                 loss: 0.1499
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 45221/50000 (90.4420%),                 avg. length: 1754.5,                last time consumption/overall running time: 93.5563s / 80057.3057 s
env0_first_0:                 episode reward: -2.4000,                 loss: -0.0625
env0_second_0:                 episode reward: 2.4000,                 loss: 0.0995
env1_first_0:                 episode reward: -4.3000,                 loss: nan
env1_second_0:                 episode reward: 4.3000,                 loss: nan
Episode: 45241/50000 (90.4820%),                 avg. length: 1883.7,                last time consumption/overall running time: 101.8280s / 80159.1336 s
env0_first_0:                 episode reward: -3.2500,                 loss: -0.0650
env0_second_0:                 episode reward: 3.2500,                 loss: 0.0894
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 45261/50000 (90.5220%),                 avg. length: 1939.25,                last time consumption/overall running time: 104.2351s / 80263.3688 s
env0_first_0:                 episode reward: -2.9000,                 loss: -0.0384
env0_second_0:                 episode reward: 2.9000,                 loss: 0.1294
env1_first_0:                 episode reward: -2.7500,                 loss: nan
env1_second_0:                 episode reward: 2.7500,                 loss: nan
Episode: 45281/50000 (90.5620%),                 avg. length: 2000.4,                last time consumption/overall running time: 108.9070s / 80372.2758 s
env0_first_0:                 episode reward: -2.8000,                 loss: -0.0590
env0_second_0:                 episode reward: 2.8000,                 loss: 0.1004
env1_first_0:                 episode reward: -3.1500,                 loss: nan
env1_second_0:                 episode reward: 3.1500,                 loss: nan
Episode: 45301/50000 (90.6020%),                 avg. length: 2054.4,                last time consumption/overall running time: 110.2966s / 80482.5724 s
env0_first_0:                 episode reward: -3.0000,                 loss: -0.0746
env0_second_0:                 episode reward: 3.0000,                 loss: 0.0799
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 45321/50000 (90.6420%),                 avg. length: 2082.55,                last time consumption/overall running time: 114.6208s / 80597.1932 s
env0_first_0:                 episode reward: -3.5500,                 loss: -0.0833
env0_second_0:                 episode reward: 3.5500,                 loss: 0.0664
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 45341/50000 (90.6820%),                 avg. length: 2165.1,                last time consumption/overall running time: 117.7129s / 80714.9061 s
env0_first_0:                 episode reward: -2.0500,                 loss: -0.0829
env0_second_0:                 episode reward: 2.0500,                 loss: 0.0633
env1_first_0:                 episode reward: -2.8500,                 loss: nan
env1_second_0:                 episode reward: 2.8500,                 loss: nan
Episode: 45361/50000 (90.7220%),                 avg. length: 2376.8,                last time consumption/overall running time: 126.2534s / 80841.1595 s
env0_first_0:                 episode reward: -3.1500,                 loss: -0.0977
env0_second_0:                 episode reward: 3.1500,                 loss: 0.0520
env1_first_0:                 episode reward: -2.8000,                 loss: nan
env1_second_0:                 episode reward: 2.8000,                 loss: nan
Episode: 45381/50000 (90.7620%),                 avg. length: 2554.45,                last time consumption/overall running time: 138.2837s / 80979.4432 s
env0_first_0:                 episode reward: -3.0500,                 loss: -0.0942
env0_second_0:                 episode reward: 3.0500,                 loss: 0.0352
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 45401/50000 (90.8020%),                 avg. length: 2342.6,                last time consumption/overall running time: 127.3546s / 81106.7978 s
env0_first_0:                 episode reward: -3.1500,                 loss: -0.0983
env0_second_0:                 episode reward: 3.1500,                 loss: 0.0491
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 45421/50000 (90.8420%),                 avg. length: 2272.2,                last time consumption/overall running time: 121.2154s / 81228.0132 s
env0_first_0:                 episode reward: -3.7000,                 loss: -0.0936
env0_second_0:                 episode reward: 3.7000,                 loss: 0.0488
env1_first_0:                 episode reward: -2.6000,                 loss: nan
env1_second_0:                 episode reward: 2.6000,                 loss: nan
Episode: 45441/50000 (90.8820%),                 avg. length: 2417.55,                last time consumption/overall running time: 128.4540s / 81356.4671 s
env0_first_0:                 episode reward: -2.7500,                 loss: -0.1144
env0_second_0:                 episode reward: 2.7500,                 loss: 0.0262
env1_first_0:                 episode reward: -2.3500,                 loss: nan
env1_second_0:                 episode reward: 2.3500,                 loss: nan
Episode: 45461/50000 (90.9220%),                 avg. length: 2724.2,                last time consumption/overall running time: 143.5829s / 81500.0501 s
env0_first_0:                 episode reward: -3.0500,                 loss: -0.1246
env0_second_0:                 episode reward: 3.0500,                 loss: 0.0084
env1_first_0:                 episode reward: -2.3000,                 loss: nan
env1_second_0:                 episode reward: 2.3000,                 loss: nan
Episode: 45481/50000 (90.9620%),                 avg. length: 2662.9,                last time consumption/overall running time: 141.3488s / 81641.3989 s
env0_first_0:                 episode reward: -2.5500,                 loss: -0.1114
env0_second_0:                 episode reward: 2.5500,                 loss: 0.0151
env1_first_0:                 episode reward: -2.5500,                 loss: nan
env1_second_0:                 episode reward: 2.5500,                 loss: nan
Episode: 45501/50000 (91.0020%),                 avg. length: 2723.0,                last time consumption/overall running time: 145.5785s / 81786.9774 s
env0_first_0:                 episode reward: -2.6500,                 loss: -0.1110
env0_second_0:                 episode reward: 2.6500,                 loss: 0.0094
env1_first_0:                 episode reward: -2.1000,                 loss: nan
env1_second_0:                 episode reward: 2.1000,                 loss: nan
Episode: 45521/50000 (91.0420%),                 avg. length: 2498.55,                last time consumption/overall running time: 133.9697s / 81920.9470 s
env0_first_0:                 episode reward: -2.0500,                 loss: -0.1022
env0_second_0:                 episode reward: 2.0500,                 loss: 0.0239
env1_first_0:                 episode reward: -2.6000,                 loss: nan
env1_second_0:                 episode reward: 2.6000,                 loss: nan
Episode: 45541/50000 (91.0820%),                 avg. length: 2691.5,                last time consumption/overall running time: 143.0517s / 82063.9987 s
env0_first_0:                 episode reward: -2.0500,                 loss: -0.1110
env0_second_0:                 episode reward: 2.0500,                 loss: 0.0092
env1_first_0:                 episode reward: -2.7500,                 loss: nan
env1_second_0:                 episode reward: 2.7500,                 loss: nan
Episode: 45561/50000 (91.1220%),                 avg. length: 2787.35,                last time consumption/overall running time: 148.3504s / 82212.3492 s
env0_first_0:                 episode reward: -1.9500,                 loss: -0.1113
env0_second_0:                 episode reward: 1.9500,                 loss: 0.0119
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 45581/50000 (91.1620%),                 avg. length: 2711.75,                last time consumption/overall running time: 145.1234s / 82357.4726 s
env0_first_0:                 episode reward: -2.5000,                 loss: -0.1122
env0_second_0:                 episode reward: 2.5000,                 loss: 0.0082
env1_first_0:                 episode reward: -2.5500,                 loss: nan
env1_second_0:                 episode reward: 2.5500,                 loss: nan
Episode: 45601/50000 (91.2020%),                 avg. length: 2939.7,                last time consumption/overall running time: 159.0085s / 82516.4811 s
env0_first_0:                 episode reward: -1.6000,                 loss: -0.1313
env0_second_0:                 episode reward: 1.6000,                 loss: -0.0070
env1_first_0:                 episode reward: -1.9000,                 loss: nan
env1_second_0:                 episode reward: 1.9000,                 loss: nan
Episode: 45621/50000 (91.2420%),                 avg. length: 2999.0,                last time consumption/overall running time: 158.3427s / 82674.8238 s
env0_first_0:                 episode reward: -1.9500,                 loss: -0.1396
env0_second_0:                 episode reward: 1.9500,                 loss: -0.0182
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 45641/50000 (91.2820%),                 avg. length: 2871.85,                last time consumption/overall running time: 152.6116s / 82827.4354 s
env0_first_0:                 episode reward: -1.5500,                 loss: -0.1442
env0_second_0:                 episode reward: 1.5500,                 loss: -0.0262
env1_first_0:                 episode reward: -2.4000,                 loss: nan
env1_second_0:                 episode reward: 2.4000,                 loss: nan
Episode: 45661/50000 (91.3220%),                 avg. length: 2876.6,                last time consumption/overall running time: 153.6218s / 82981.0572 s
env0_first_0:                 episode reward: -1.3500,                 loss: -0.1474
env0_second_0:                 episode reward: 1.3500,                 loss: -0.0599
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 45681/50000 (91.3620%),                 avg. length: 2929.65,                last time consumption/overall running time: 157.6660s / 83138.7232 s
env0_first_0:                 episode reward: -1.0500,                 loss: -0.1557
env0_second_0:                 episode reward: 1.0500,                 loss: -0.0371
env1_first_0:                 episode reward: -2.3000,                 loss: nan
env1_second_0:                 episode reward: 2.3000,                 loss: nan
Episode: 45701/50000 (91.4020%),                 avg. length: 2845.55,                last time consumption/overall running time: 153.1788s / 83291.9019 s
env0_first_0:                 episode reward: -1.7500,                 loss: -0.1515
env0_second_0:                 episode reward: 1.7500,                 loss: -0.0395
env1_first_0:                 episode reward: -2.0500,                 loss: nan
env1_second_0:                 episode reward: 2.0500,                 loss: nan
Episode: 45721/50000 (91.4420%),                 avg. length: 2930.2,                last time consumption/overall running time: 154.8861s / 83446.7881 s
env0_first_0:                 episode reward: -2.2000,                 loss: -0.1510
env0_second_0:                 episode reward: 2.2000,                 loss: -0.0423
env1_first_0:                 episode reward: -1.8500,                 loss: nan
env1_second_0:                 episode reward: 1.8500,                 loss: nan
Episode: 45741/50000 (91.4820%),                 avg. length: 2821.7,                last time consumption/overall running time: 148.7917s / 83595.5798 s
env0_first_0:                 episode reward: -1.2500,                 loss: -0.1625
env0_second_0:                 episode reward: 1.2500,                 loss: -0.0485
env1_first_0:                 episode reward: -2.2000,                 loss: nan
env1_second_0:                 episode reward: 2.2000,                 loss: nan
Episode: 45761/50000 (91.5220%),                 avg. length: 2830.6,                last time consumption/overall running time: 148.7907s / 83744.3704 s
env0_first_0:                 episode reward: -2.3500,                 loss: -0.1532
env0_second_0:                 episode reward: 2.3500,                 loss: -0.0470
env1_first_0:                 episode reward: -2.0500,                 loss: nan
env1_second_0:                 episode reward: 2.0500,                 loss: nan
Episode: 45781/50000 (91.5620%),                 avg. length: 2866.9,                last time consumption/overall running time: 151.5045s / 83895.8750 s
env0_first_0:                 episode reward: -1.0000,                 loss: -0.1593
env0_second_0:                 episode reward: 1.0000,                 loss: -0.0633
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 45801/50000 (91.6020%),                 avg. length: 2688.15,                last time consumption/overall running time: 143.8079s / 84039.6829 s
env0_first_0:                 episode reward: -2.3000,                 loss: -0.1565
env0_second_0:                 episode reward: 2.3000,                 loss: -0.0284
env1_first_0:                 episode reward: -1.9000,                 loss: nan
env1_second_0:                 episode reward: 1.9000,                 loss: nan
Episode: 45821/50000 (91.6420%),                 avg. length: 2954.5,                last time consumption/overall running time: 155.2901s / 84194.9730 s
env0_first_0:                 episode reward: -1.3500,                 loss: -0.1717
env0_second_0:                 episode reward: 1.3500,                 loss: -0.0631
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 45841/50000 (91.6820%),                 avg. length: 2992.65,                last time consumption/overall running time: 159.8264s / 84354.7994 s
env0_first_0:                 episode reward: -1.3500,                 loss: -0.1744
env0_second_0:                 episode reward: 1.3500,                 loss: -0.0728
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 45861/50000 (91.7220%),                 avg. length: 2973.6,                last time consumption/overall running time: 156.4068s / 84511.2062 s
env0_first_0:                 episode reward: -1.2000,                 loss: -0.1889
env0_second_0:                 episode reward: 1.2000,                 loss: -0.0790
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 45881/50000 (91.7620%),                 avg. length: 2961.55,                last time consumption/overall running time: 155.9269s / 84667.1331 s
env0_first_0:                 episode reward: -1.4500,                 loss: -0.1634
env0_second_0:                 episode reward: 1.4500,                 loss: -0.0451
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 45901/50000 (91.8020%),                 avg. length: 2903.0,                last time consumption/overall running time: 154.1371s / 84821.2703 s
env0_first_0:                 episode reward: -1.4500,                 loss: -0.1714
env0_second_0:                 episode reward: 1.4500,                 loss: -0.0247
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 45921/50000 (91.8420%),                 avg. length: 2914.0,                last time consumption/overall running time: 156.7532s / 84978.0234 s
env0_first_0:                 episode reward: -1.2500,                 loss: -0.1710
env0_second_0:                 episode reward: 1.2500,                 loss: -0.0419
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 45941/50000 (91.8820%),                 avg. length: 2918.2,                last time consumption/overall running time: 157.2391s / 85135.2625 s
env0_first_0:                 episode reward: -1.0000,                 loss: -0.1674
env0_second_0:                 episode reward: 1.0000,                 loss: -0.0584
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 45961/50000 (91.9220%),                 avg. length: 2999.0,                last time consumption/overall running time: 157.6485s / 85292.9110 s
env0_first_0:                 episode reward: -1.1000,                 loss: -0.1771
env0_second_0:                 episode reward: 1.1000,                 loss: -0.0607
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 45981/50000 (91.9620%),                 avg. length: 2803.65,                last time consumption/overall running time: 147.5581s / 85440.4691 s
env0_first_0:                 episode reward: -1.2000,                 loss: -0.1553
env0_second_0:                 episode reward: 1.2000,                 loss: -0.0264
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 46001/50000 (92.0020%),                 avg. length: 2959.0,                last time consumption/overall running time: 154.5382s / 85595.0073 s
env0_first_0:                 episode reward: -0.6000,                 loss: -0.1937
env0_second_0:                 episode reward: 0.6000,                 loss: -0.0850
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 46021/50000 (92.0420%),                 avg. length: 2986.85,                last time consumption/overall running time: 156.8585s / 85751.8658 s
env0_first_0:                 episode reward: -1.0000,                 loss: -0.1908
env0_second_0:                 episode reward: 1.0000,                 loss: -0.0801
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 46041/50000 (92.0820%),                 avg. length: 2954.85,                last time consumption/overall running time: 154.2766s / 85906.1424 s
env0_first_0:                 episode reward: -1.2000,                 loss: -0.1760
env0_second_0:                 episode reward: 1.2000,                 loss: -0.0508
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 46061/50000 (92.1220%),                 avg. length: 2999.0,                last time consumption/overall running time: 160.4796s / 86066.6221 s
env0_first_0:                 episode reward: -0.6500,                 loss: -0.1801
env0_second_0:                 episode reward: 0.6500,                 loss: -0.0577
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 46081/50000 (92.1620%),                 avg. length: 2988.3,                last time consumption/overall running time: 161.1606s / 86227.7826 s
env0_first_0:                 episode reward: -0.4000,                 loss: -0.1860
env0_second_0:                 episode reward: 0.4000,                 loss: -0.0684
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 46101/50000 (92.2020%),                 avg. length: 2928.7,                last time consumption/overall running time: 154.1983s / 86381.9809 s
env0_first_0:                 episode reward: -1.1000,                 loss: -0.1662
env0_second_0:                 episode reward: 1.1000,                 loss: -0.0350
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 46121/50000 (92.2420%),                 avg. length: 2977.7,                last time consumption/overall running time: 156.6001s / 86538.5810 s
env0_first_0:                 episode reward: -0.6000,                 loss: -0.1745
env0_second_0:                 episode reward: 0.6000,                 loss: -0.0470
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 46141/50000 (92.2820%),                 avg. length: 2999.0,                last time consumption/overall running time: 158.4503s / 86697.0313 s
env0_first_0:                 episode reward: -0.8500,                 loss: -0.1823
env0_second_0:                 episode reward: 0.8500,                 loss: -0.0688
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 46161/50000 (92.3220%),                 avg. length: 2999.0,                last time consumption/overall running time: 157.1356s / 86854.1670 s
env0_first_0:                 episode reward: -0.7000,                 loss: -0.1896
env0_second_0:                 episode reward: 0.7000,                 loss: -0.0750
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 46181/50000 (92.3620%),                 avg. length: 2970.1,                last time consumption/overall running time: 156.0766s / 87010.2436 s
env0_first_0:                 episode reward: -1.4500,                 loss: -0.1822
env0_second_0:                 episode reward: 1.4500,                 loss: -0.0676
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 46201/50000 (92.4020%),                 avg. length: 2999.0,                last time consumption/overall running time: 157.1128s / 87167.3564 s
env0_first_0:                 episode reward: -1.0000,                 loss: -0.1868
env0_second_0:                 episode reward: 1.0000,                 loss: -0.0871
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 46221/50000 (92.4420%),                 avg. length: 2999.0,                last time consumption/overall running time: 158.6690s / 87326.0254 s
env0_first_0:                 episode reward: -0.9500,                 loss: -0.1880
env0_second_0:                 episode reward: 0.9500,                 loss: -0.0736
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 46241/50000 (92.4820%),                 avg. length: 2999.0,                last time consumption/overall running time: 159.9505s / 87485.9759 s
env0_first_0:                 episode reward: -0.6500,                 loss: -0.1828
env0_second_0:                 episode reward: 0.6500,                 loss: -0.0896
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 46261/50000 (92.5220%),                 avg. length: 2999.0,                last time consumption/overall running time: 160.3222s / 87646.2981 s
env0_first_0:                 episode reward: -0.4500,                 loss: -0.1813
env0_second_0:                 episode reward: 0.4500,                 loss: -0.0763
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 46281/50000 (92.5620%),                 avg. length: 2999.0,                last time consumption/overall running time: 156.6645s / 87802.9626 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.1900
env0_second_0:                 episode reward: 0.2000,                 loss: -0.0903
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 46301/50000 (92.6020%),                 avg. length: 2999.0,                last time consumption/overall running time: 156.4396s / 87959.4022 s
env0_first_0:                 episode reward: -0.7000,                 loss: -0.1931
env0_second_0:                 episode reward: 0.7000,                 loss: -0.0882
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 46321/50000 (92.6420%),                 avg. length: 2999.0,                last time consumption/overall running time: 156.0010s / 88115.4033 s
env0_first_0:                 episode reward: -1.0000,                 loss: -0.2030
env0_second_0:                 episode reward: 1.0000,                 loss: -0.1037
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 46341/50000 (92.6820%),                 avg. length: 2978.75,                last time consumption/overall running time: 155.9621s / 88271.3653 s
env0_first_0:                 episode reward: -1.0500,                 loss: -0.2026
env0_second_0:                 episode reward: 1.0500,                 loss: -0.0787
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 46361/50000 (92.7220%),                 avg. length: 2999.0,                last time consumption/overall running time: 156.0967s / 88427.4620 s
env0_first_0:                 episode reward: -0.4500,                 loss: -0.1925
env0_second_0:                 episode reward: 0.4500,                 loss: -0.0764
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 46381/50000 (92.7620%),                 avg. length: 2999.0,                last time consumption/overall running time: 156.8966s / 88584.3586 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.1904
env0_second_0:                 episode reward: 0.2000,                 loss: -0.0672
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 46401/50000 (92.8020%),                 avg. length: 2999.0,                last time consumption/overall running time: 156.2644s / 88740.6230 s
env0_first_0:                 episode reward: -0.4000,                 loss: -0.2021
env0_second_0:                 episode reward: 0.4000,                 loss: -0.0849
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 46421/50000 (92.8420%),                 avg. length: 2999.0,                last time consumption/overall running time: 157.7003s / 88898.3233 s
env0_first_0:                 episode reward: -0.9500,                 loss: -0.1879
env0_second_0:                 episode reward: 0.9500,                 loss: -0.0934
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 46441/50000 (92.8820%),                 avg. length: 2999.0,                last time consumption/overall running time: 158.6508s / 89056.9742 s
env0_first_0:                 episode reward: -0.7500,                 loss: -0.1922
env0_second_0:                 episode reward: 0.7500,                 loss: -0.1099
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 46461/50000 (92.9220%),                 avg. length: 2972.45,                last time consumption/overall running time: 156.6535s / 89213.6276 s
env0_first_0:                 episode reward: -1.2000,                 loss: -0.1958
env0_second_0:                 episode reward: 1.2000,                 loss: -0.0878
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 46481/50000 (92.9620%),                 avg. length: 2999.0,                last time consumption/overall running time: 157.1335s / 89370.7611 s
env0_first_0:                 episode reward: -0.4500,                 loss: -0.2000
env0_second_0:                 episode reward: 0.4500,                 loss: -0.1041
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 46501/50000 (93.0020%),                 avg. length: 2999.0,                last time consumption/overall running time: 157.3569s / 89528.1180 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.1933
env0_second_0:                 episode reward: 0.0500,                 loss: -0.1053
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 46521/50000 (93.0420%),                 avg. length: 2999.0,                last time consumption/overall running time: 159.9003s / 89688.0183 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.2052
env0_second_0:                 episode reward: 0.2000,                 loss: -0.1100
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 46541/50000 (93.0820%),                 avg. length: 2999.0,                last time consumption/overall running time: 160.8006s / 89848.8189 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.2131
env0_second_0:                 episode reward: 0.1000,                 loss: -0.1155
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 46561/50000 (93.1220%),                 avg. length: 2999.0,                last time consumption/overall running time: 163.0435s / 90011.8624 s
env0_first_0:                 episode reward: -0.5500,                 loss: -0.2026
env0_second_0:                 episode reward: 0.5500,                 loss: -0.0929
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 46581/50000 (93.1620%),                 avg. length: 2925.95,                last time consumption/overall running time: 153.1755s / 90165.0379 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.1962
env0_second_0:                 episode reward: 0.2000,                 loss: -0.0828
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 46601/50000 (93.2020%),                 avg. length: 2999.0,                last time consumption/overall running time: 157.0350s / 90322.0729 s
env0_first_0:                 episode reward: -0.4500,                 loss: -0.2090
env0_second_0:                 episode reward: 0.4500,                 loss: -0.1026
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 46621/50000 (93.2420%),                 avg. length: 2872.55,                last time consumption/overall running time: 150.5695s / 90472.6424 s
env0_first_0:                 episode reward: -1.1000,                 loss: -0.1885
env0_second_0:                 episode reward: 1.1000,                 loss: -0.0979
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 46641/50000 (93.2820%),                 avg. length: 2999.0,                last time consumption/overall running time: 157.0031s / 90629.6455 s
env0_first_0:                 episode reward: -0.6500,                 loss: -0.1917
env0_second_0:                 episode reward: 0.6500,                 loss: -0.1008
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 46661/50000 (93.3220%),                 avg. length: 2999.0,                last time consumption/overall running time: 156.5079s / 90786.1534 s
env0_first_0:                 episode reward: -0.4000,                 loss: -0.1909
env0_second_0:                 episode reward: 0.4000,                 loss: -0.1073
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 46681/50000 (93.3620%),                 avg. length: 2999.0,                last time consumption/overall running time: 157.4168s / 90943.5702 s
env0_first_0:                 episode reward: -0.6000,                 loss: -0.2076
env0_second_0:                 episode reward: 0.6000,                 loss: -0.1104
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 46701/50000 (93.4020%),                 avg. length: 2999.0,                last time consumption/overall running time: 158.5781s / 91102.1483 s
env0_first_0:                 episode reward: -0.7000,                 loss: -0.1969
env0_second_0:                 episode reward: 0.7000,                 loss: -0.0958
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 46721/50000 (93.4420%),                 avg. length: 2999.0,                last time consumption/overall running time: 162.0743s / 91264.2226 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.1719
env0_second_0:                 episode reward: 0.0000,                 loss: -0.0912
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 46741/50000 (93.4820%),                 avg. length: 2999.0,                last time consumption/overall running time: 159.1683s / 91423.3910 s
env0_first_0:                 episode reward: -0.7000,                 loss: -0.1967
env0_second_0:                 episode reward: 0.7000,                 loss: -0.1088
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 46761/50000 (93.5220%),                 avg. length: 2999.0,                last time consumption/overall running time: 161.4118s / 91584.8028 s
env0_first_0:                 episode reward: -0.3000,                 loss: -0.2088
env0_second_0:                 episode reward: 0.3000,                 loss: -0.1127
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 46781/50000 (93.5620%),                 avg. length: 2999.0,                last time consumption/overall running time: 156.9089s / 91741.7118 s
env0_first_0:                 episode reward: -0.9500,                 loss: -0.1914
env0_second_0:                 episode reward: 0.9500,                 loss: -0.0971
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 46801/50000 (93.6020%),                 avg. length: 2999.0,                last time consumption/overall running time: 161.1430s / 91902.8548 s
env0_first_0:                 episode reward: -0.3500,                 loss: -0.2063
env0_second_0:                 episode reward: 0.3500,                 loss: -0.1056
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 46821/50000 (93.6420%),                 avg. length: 2999.0,                last time consumption/overall running time: 159.1938s / 92062.0486 s
env0_first_0:                 episode reward: -0.7000,                 loss: -0.2023
env0_second_0:                 episode reward: 0.7000,                 loss: -0.0997
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 46841/50000 (93.6820%),                 avg. length: 2999.0,                last time consumption/overall running time: 160.0423s / 92222.0909 s
env0_first_0:                 episode reward: -0.4500,                 loss: -0.2116
env0_second_0:                 episode reward: 0.4500,                 loss: -0.1121
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 46861/50000 (93.7220%),                 avg. length: 2999.0,                last time consumption/overall running time: 158.0995s / 92380.1904 s
env0_first_0:                 episode reward: -0.4500,                 loss: -0.2122
env0_second_0:                 episode reward: 0.4500,                 loss: -0.1283
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 46881/50000 (93.7620%),                 avg. length: 2999.0,                last time consumption/overall running time: 160.6479s / 92540.8383 s
env0_first_0:                 episode reward: -0.3500,                 loss: -0.2088
env0_second_0:                 episode reward: 0.3500,                 loss: -0.1082
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 46901/50000 (93.8020%),                 avg. length: 2999.0,                last time consumption/overall running time: 157.5988s / 92698.4371 s
env0_first_0:                 episode reward: -0.5000,                 loss: -0.2090
env0_second_0:                 episode reward: 0.5000,                 loss: -0.1183
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 46921/50000 (93.8420%),                 avg. length: 2999.0,                last time consumption/overall running time: 157.8320s / 92856.2691 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.2000
env0_second_0:                 episode reward: 0.2000,                 loss: -0.1113
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 46941/50000 (93.8820%),                 avg. length: 2999.0,                last time consumption/overall running time: 162.2365s / 93018.5056 s
env0_first_0:                 episode reward: -0.4500,                 loss: -0.2024
env0_second_0:                 episode reward: 0.4500,                 loss: -0.1154
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 46961/50000 (93.9220%),                 avg. length: 2999.0,                last time consumption/overall running time: 159.3177s / 93177.8233 s
env0_first_0:                 episode reward: -0.8000,                 loss: -0.1928
env0_second_0:                 episode reward: 0.8000,                 loss: -0.1131
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 46981/50000 (93.9620%),                 avg. length: 2994.3,                last time consumption/overall running time: 160.5269s / 93338.3502 s
env0_first_0:                 episode reward: -0.8000,                 loss: -0.2023
env0_second_0:                 episode reward: 0.8000,                 loss: -0.1184
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 47001/50000 (94.0020%),                 avg. length: 2992.15,                last time consumption/overall running time: 161.0859s / 93499.4361 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.1899
env0_second_0:                 episode reward: 0.1500,                 loss: -0.1177
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 47021/50000 (94.0420%),                 avg. length: 2999.0,                last time consumption/overall running time: 160.4994s / 93659.9355 s
env0_first_0:                 episode reward: -0.2500,                 loss: -0.2032
env0_second_0:                 episode reward: 0.2500,                 loss: -0.0985
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 47041/50000 (94.0820%),                 avg. length: 2999.0,                last time consumption/overall running time: 158.8267s / 93818.7623 s
env0_first_0:                 episode reward: -0.8000,                 loss: -0.1915
env0_second_0:                 episode reward: 0.8000,                 loss: -0.0973
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 47061/50000 (94.1220%),                 avg. length: 2999.0,                last time consumption/overall running time: 158.9018s / 93977.6641 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.2123
env0_second_0:                 episode reward: 0.0500,                 loss: -0.0949
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 47081/50000 (94.1620%),                 avg. length: 2999.0,                last time consumption/overall running time: 159.1088s / 94136.7729 s
env0_first_0:                 episode reward: -0.3000,                 loss: -0.2176
env0_second_0:                 episode reward: 0.3000,                 loss: -0.1200
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 47101/50000 (94.2020%),                 avg. length: 2999.0,                last time consumption/overall running time: 157.4227s / 94294.1956 s
env0_first_0:                 episode reward: -0.2500,                 loss: -0.2132
env0_second_0:                 episode reward: 0.2500,                 loss: -0.1088
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 47121/50000 (94.2420%),                 avg. length: 2999.0,                last time consumption/overall running time: 158.9695s / 94453.1651 s
env0_first_0:                 episode reward: -0.5500,                 loss: -0.2077
env0_second_0:                 episode reward: 0.5500,                 loss: -0.1028
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 47141/50000 (94.2820%),                 avg. length: 2999.0,                last time consumption/overall running time: 160.0378s / 94613.2030 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.1938
env0_second_0:                 episode reward: 0.2000,                 loss: -0.1011
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 47161/50000 (94.3220%),                 avg. length: 2999.0,                last time consumption/overall running time: 159.1782s / 94772.3812 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.1889
env0_second_0:                 episode reward: 0.1500,                 loss: -0.1100
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 47181/50000 (94.3620%),                 avg. length: 2999.0,                last time consumption/overall running time: 158.9467s / 94931.3279 s
env0_first_0:                 episode reward: 0.3000,                 loss: -0.2008
env0_second_0:                 episode reward: -0.3000,                 loss: -0.0798
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 47201/50000 (94.4020%),                 avg. length: 2999.0,                last time consumption/overall running time: 158.4077s / 95089.7357 s
env0_first_0:                 episode reward: -0.4000,                 loss: -0.2032
env0_second_0:                 episode reward: 0.4000,                 loss: -0.1232
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 47221/50000 (94.4420%),                 avg. length: 2999.0,                last time consumption/overall running time: 156.8796s / 95246.6153 s
env0_first_0:                 episode reward: -0.3000,                 loss: -0.2125
env0_second_0:                 episode reward: 0.3000,                 loss: -0.1018
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 47241/50000 (94.4820%),                 avg. length: 2999.0,                last time consumption/overall running time: 157.6763s / 95404.2916 s
env0_first_0:                 episode reward: -0.6000,                 loss: -0.1993
env0_second_0:                 episode reward: 0.6000,                 loss: -0.0927
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 47261/50000 (94.5220%),                 avg. length: 2999.0,                last time consumption/overall running time: 161.9524s / 95566.2440 s
env0_first_0:                 episode reward: -0.7500,                 loss: -0.1933
env0_second_0:                 episode reward: 0.7500,                 loss: -0.1016
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 47281/50000 (94.5620%),                 avg. length: 2999.0,                last time consumption/overall running time: 162.8655s / 95729.1095 s
env0_first_0:                 episode reward: -0.2500,                 loss: -0.2099
env0_second_0:                 episode reward: 0.2500,                 loss: -0.0965
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 47301/50000 (94.6020%),                 avg. length: 2999.0,                last time consumption/overall running time: 160.5603s / 95889.6698 s
env0_first_0:                 episode reward: -0.3500,                 loss: -0.2051
env0_second_0:                 episode reward: 0.3500,                 loss: -0.1032
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 47321/50000 (94.6420%),                 avg. length: 2999.0,                last time consumption/overall running time: 161.4400s / 96051.1098 s
env0_first_0:                 episode reward: -0.5500,                 loss: -0.1948
env0_second_0:                 episode reward: 0.5500,                 loss: -0.1154
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 47341/50000 (94.6820%),                 avg. length: 2999.0,                last time consumption/overall running time: 160.5136s / 96211.6234 s
env0_first_0:                 episode reward: -0.5500,                 loss: -0.2037
env0_second_0:                 episode reward: 0.5500,                 loss: -0.1170
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 47361/50000 (94.7220%),                 avg. length: 2999.0,                last time consumption/overall running time: 159.7328s / 96371.3561 s
env0_first_0:                 episode reward: -0.5000,                 loss: -0.1935
env0_second_0:                 episode reward: 0.5000,                 loss: -0.1007
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 47381/50000 (94.7620%),                 avg. length: 2999.0,                last time consumption/overall running time: 159.4407s / 96530.7969 s
env0_first_0:                 episode reward: -0.4000,                 loss: -0.2178
env0_second_0:                 episode reward: 0.4000,                 loss: -0.1214
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 47401/50000 (94.8020%),                 avg. length: 2999.0,                last time consumption/overall running time: 160.3198s / 96691.1166 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.1971
env0_second_0:                 episode reward: 0.0000,                 loss: -0.0358
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 47421/50000 (94.8420%),                 avg. length: 2999.0,                last time consumption/overall running time: 158.4036s / 96849.5203 s
env0_first_0:                 episode reward: -0.7500,                 loss: -0.2017
env0_second_0:                 episode reward: 0.7500,                 loss: -0.0971
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 47441/50000 (94.8820%),                 avg. length: 2999.0,                last time consumption/overall running time: 162.5006s / 97012.0208 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.1967
env0_second_0:                 episode reward: 0.0500,                 loss: -0.1044
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 47461/50000 (94.9220%),                 avg. length: 2999.0,                last time consumption/overall running time: 168.0214s / 97180.0422 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.2018
env0_second_0:                 episode reward: 0.1500,                 loss: -0.1125
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 47481/50000 (94.9620%),                 avg. length: 2999.0,                last time consumption/overall running time: 170.6627s / 97350.7049 s
env0_first_0:                 episode reward: -0.3000,                 loss: -0.1876
env0_second_0:                 episode reward: 0.3000,                 loss: -0.0844
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 47501/50000 (95.0020%),                 avg. length: 2999.0,                last time consumption/overall running time: 172.0706s / 97522.7755 s
env0_first_0:                 episode reward: -0.4500,                 loss: -0.2152
env0_second_0:                 episode reward: 0.4500,                 loss: -0.1230
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 47521/50000 (95.0420%),                 avg. length: 2999.0,                last time consumption/overall running time: 164.1314s / 97686.9069 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.2158
env0_second_0:                 episode reward: 0.1000,                 loss: -0.1252
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 47541/50000 (95.0820%),                 avg. length: 2999.0,                last time consumption/overall running time: 165.8790s / 97852.7859 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.2180
env0_second_0:                 episode reward: 0.1000,                 loss: -0.1170
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 47561/50000 (95.1220%),                 avg. length: 2999.0,                last time consumption/overall running time: 174.3886s / 98027.1745 s
env0_first_0:                 episode reward: 0.5000,                 loss: -0.1945
env0_second_0:                 episode reward: -0.5000,                 loss: -0.1041
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 47581/50000 (95.1620%),                 avg. length: 2999.0,                last time consumption/overall running time: 159.8261s / 98187.0006 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.2095
env0_second_0:                 episode reward: 0.0500,                 loss: -0.1005
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 47601/50000 (95.2020%),                 avg. length: 2999.0,                last time consumption/overall running time: 158.0385s / 98345.0391 s
env0_first_0:                 episode reward: -0.2500,                 loss: -0.2135
env0_second_0:                 episode reward: 0.2500,                 loss: -0.1211
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 47621/50000 (95.2420%),                 avg. length: 2999.0,                last time consumption/overall running time: 157.3126s / 98502.3517 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.2137
env0_second_0:                 episode reward: 0.1500,                 loss: -0.0967
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 47641/50000 (95.2820%),                 avg. length: 2999.0,                last time consumption/overall running time: 159.9398s / 98662.2915 s
env0_first_0:                 episode reward: -0.5000,                 loss: -0.2031
env0_second_0:                 episode reward: 0.5000,                 loss: -0.1263
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 47661/50000 (95.3220%),                 avg. length: 2999.0,                last time consumption/overall running time: 159.1249s / 98821.4164 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.2166
env0_second_0:                 episode reward: -0.0500,                 loss: -0.1094
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 47681/50000 (95.3620%),                 avg. length: 2999.0,                last time consumption/overall running time: 161.3463s / 98982.7627 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.2143
env0_second_0:                 episode reward: 0.0500,                 loss: -0.1023
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 47701/50000 (95.4020%),                 avg. length: 2999.0,                last time consumption/overall running time: 171.6515s / 99154.4142 s
env0_first_0:                 episode reward: -0.4500,                 loss: -0.2045
env0_second_0:                 episode reward: 0.4500,                 loss: -0.0908
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 47721/50000 (95.4420%),                 avg. length: 2999.0,                last time consumption/overall running time: 176.7620s / 99331.1762 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.2128
env0_second_0:                 episode reward: 0.1500,                 loss: -0.0874
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 47741/50000 (95.4820%),                 avg. length: 2999.0,                last time consumption/overall running time: 181.6995s / 99512.8757 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.2161
env0_second_0:                 episode reward: 0.2000,                 loss: -0.1157
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 47761/50000 (95.5220%),                 avg. length: 2985.4,                last time consumption/overall running time: 172.4896s / 99685.3653 s
env0_first_0:                 episode reward: -0.7000,                 loss: -0.2062
env0_second_0:                 episode reward: 0.7000,                 loss: -0.0950
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 47781/50000 (95.5620%),                 avg. length: 2999.0,                last time consumption/overall running time: 172.9756s / 99858.3409 s
env0_first_0:                 episode reward: -0.7000,                 loss: -0.2001
env0_second_0:                 episode reward: 0.7000,                 loss: -0.1011
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 47801/50000 (95.6020%),                 avg. length: 2999.0,                last time consumption/overall running time: 179.6054s / 100037.9462 s
env0_first_0:                 episode reward: -0.3000,                 loss: -0.2032
env0_second_0:                 episode reward: 0.3000,                 loss: -0.1108
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 47821/50000 (95.6420%),                 avg. length: 2807.3,                last time consumption/overall running time: 159.8246s / 100197.7709 s
env0_first_0:                 episode reward: 0.4500,                 loss: -0.1792
env0_second_0:                 episode reward: -0.4500,                 loss: -0.0789
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 47841/50000 (95.6820%),                 avg. length: 2999.0,                last time consumption/overall running time: 170.7673s / 100368.5382 s
env0_first_0:                 episode reward: -0.3500,                 loss: -0.2037
env0_second_0:                 episode reward: 0.3500,                 loss: -0.1293
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 47861/50000 (95.7220%),                 avg. length: 2999.0,                last time consumption/overall running time: 176.8392s / 100545.3774 s
env0_first_0:                 episode reward: -0.3500,                 loss: -0.2134
env0_second_0:                 episode reward: 0.3500,                 loss: -0.0461
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 47881/50000 (95.7620%),                 avg. length: 2999.0,                last time consumption/overall running time: 165.1264s / 100710.5038 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.2078
env0_second_0:                 episode reward: 0.1500,                 loss: -0.1130
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 47901/50000 (95.8020%),                 avg. length: 2999.0,                last time consumption/overall running time: 193.5910s / 100904.0948 s
env0_first_0:                 episode reward: -0.3000,                 loss: -0.2056
env0_second_0:                 episode reward: 0.3000,                 loss: -0.1247
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 47921/50000 (95.8420%),                 avg. length: 2999.0,                last time consumption/overall running time: 174.2934s / 101078.3883 s
env0_first_0:                 episode reward: -0.4000,                 loss: -0.2168
env0_second_0:                 episode reward: 0.4000,                 loss: -0.1211
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 47941/50000 (95.8820%),                 avg. length: 2999.0,                last time consumption/overall running time: 173.6479s / 101252.0362 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.2158
env0_second_0:                 episode reward: 0.2000,                 loss: -0.1330
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 47961/50000 (95.9220%),                 avg. length: 2999.0,                last time consumption/overall running time: 170.4968s / 101422.5330 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.2202
env0_second_0:                 episode reward: 0.1500,                 loss: -0.1240
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 47981/50000 (95.9620%),                 avg. length: 2999.0,                last time consumption/overall running time: 172.6126s / 101595.1456 s
env0_first_0:                 episode reward: -0.4000,                 loss: -0.2138
env0_second_0:                 episode reward: 0.4000,                 loss: -0.1165
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 48001/50000 (96.0020%),                 avg. length: 2999.0,                last time consumption/overall running time: 161.5053s / 101756.6509 s
env0_first_0:                 episode reward: -0.2500,                 loss: -0.2158
env0_second_0:                 episode reward: 0.2500,                 loss: -0.1286
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 48021/50000 (96.0420%),                 avg. length: 2999.0,                last time consumption/overall running time: 160.0634s / 101916.7143 s
env0_first_0:                 episode reward: -0.3500,                 loss: -0.2198
env0_second_0:                 episode reward: 0.3500,                 loss: -0.1250
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 48041/50000 (96.0820%),                 avg. length: 2999.0,                last time consumption/overall running time: 157.8370s / 102074.5513 s
env0_first_0:                 episode reward: 0.2500,                 loss: -0.2119
env0_second_0:                 episode reward: -0.2500,                 loss: -0.1198
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 48061/50000 (96.1220%),                 avg. length: 2999.0,                last time consumption/overall running time: 157.9996s / 102232.5509 s
env0_first_0:                 episode reward: -0.5000,                 loss: -0.2073
env0_second_0:                 episode reward: 0.5000,                 loss: -0.1237
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 48081/50000 (96.1620%),                 avg. length: 2999.0,                last time consumption/overall running time: 156.8184s / 102389.3693 s
env0_first_0:                 episode reward: -0.4500,                 loss: -0.2187
env0_second_0:                 episode reward: 0.4500,                 loss: -0.1284
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 48101/50000 (96.2020%),                 avg. length: 2999.0,                last time consumption/overall running time: 157.5936s / 102546.9630 s
env0_first_0:                 episode reward: -0.2500,                 loss: -0.2196
env0_second_0:                 episode reward: 0.2500,                 loss: -0.1394
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 48121/50000 (96.2420%),                 avg. length: 2999.0,                last time consumption/overall running time: 158.7639s / 102705.7268 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.2211
env0_second_0:                 episode reward: 0.2000,                 loss: -0.1442
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 48141/50000 (96.2820%),                 avg. length: 2999.0,                last time consumption/overall running time: 157.2921s / 102863.0189 s
env0_first_0:                 episode reward: -0.3500,                 loss: -0.2151
env0_second_0:                 episode reward: 0.3500,                 loss: -0.1365
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 48161/50000 (96.3220%),                 avg. length: 2999.0,                last time consumption/overall running time: 156.1404s / 103019.1593 s
env0_first_0:                 episode reward: -0.6000,                 loss: -0.2087
env0_second_0:                 episode reward: 0.6000,                 loss: -0.1250
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 48181/50000 (96.3620%),                 avg. length: 2999.0,                last time consumption/overall running time: 160.8487s / 103180.0080 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.2231
env0_second_0:                 episode reward: 0.1000,                 loss: -0.1319
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 48201/50000 (96.4020%),                 avg. length: 2999.0,                last time consumption/overall running time: 161.3727s / 103341.3808 s
env0_first_0:                 episode reward: -0.3000,                 loss: -0.2108
env0_second_0:                 episode reward: 0.3000,                 loss: -0.1252
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 48221/50000 (96.4420%),                 avg. length: 2999.0,                last time consumption/overall running time: 157.5144s / 103498.8952 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.2192
env0_second_0:                 episode reward: 0.2000,                 loss: -0.1317
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 48241/50000 (96.4820%),                 avg. length: 2999.0,                last time consumption/overall running time: 158.4744s / 103657.3696 s
env0_first_0:                 episode reward: -0.3000,                 loss: -0.2206
env0_second_0:                 episode reward: 0.3000,                 loss: -0.1332
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 48261/50000 (96.5220%),                 avg. length: 2999.0,                last time consumption/overall running time: 156.7366s / 103814.1062 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.2165
env0_second_0:                 episode reward: 0.1500,                 loss: -0.1161
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 48281/50000 (96.5620%),                 avg. length: 2999.0,                last time consumption/overall running time: 160.8895s / 103974.9957 s
env0_first_0:                 episode reward: -0.3500,                 loss: -0.2080
env0_second_0:                 episode reward: 0.3500,                 loss: -0.1335
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 48301/50000 (96.6020%),                 avg. length: 2999.0,                last time consumption/overall running time: 164.2263s / 104139.2220 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.2173
env0_second_0:                 episode reward: 0.1500,                 loss: -0.1234
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 48321/50000 (96.6420%),                 avg. length: 2999.0,                last time consumption/overall running time: 158.7365s / 104297.9585 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.2148
env0_second_0:                 episode reward: 0.2000,                 loss: -0.1335
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 48341/50000 (96.6820%),                 avg. length: 2999.0,                last time consumption/overall running time: 161.2638s / 104459.2223 s
env0_first_0:                 episode reward: -0.4000,                 loss: -0.2198
env0_second_0:                 episode reward: 0.4000,                 loss: -0.1426
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 48361/50000 (96.7220%),                 avg. length: 2820.65,                last time consumption/overall running time: 153.4666s / 104612.6888 s
env0_first_0:                 episode reward: 0.5000,                 loss: -0.1907
env0_second_0:                 episode reward: -0.5000,                 loss: -0.1178
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 48381/50000 (96.7620%),                 avg. length: 2999.0,                last time consumption/overall running time: 159.1705s / 104771.8593 s
env0_first_0:                 episode reward: -0.3500,                 loss: -0.2196
env0_second_0:                 episode reward: 0.3500,                 loss: -0.1423
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 48401/50000 (96.8020%),                 avg. length: 2999.0,                last time consumption/overall running time: 157.3750s / 104929.2343 s
env0_first_0:                 episode reward: -0.7500,                 loss: -0.2029
env0_second_0:                 episode reward: 0.7500,                 loss: -0.1373
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 48421/50000 (96.8420%),                 avg. length: 2999.0,                last time consumption/overall running time: 158.2602s / 105087.4945 s
env0_first_0:                 episode reward: -0.8000,                 loss: -0.2078
env0_second_0:                 episode reward: 0.8000,                 loss: -0.1373
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 48441/50000 (96.8820%),                 avg. length: 2999.0,                last time consumption/overall running time: 158.4179s / 105245.9123 s
env0_first_0:                 episode reward: -0.2500,                 loss: -0.2170
env0_second_0:                 episode reward: 0.2500,                 loss: -0.1481
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 48461/50000 (96.9220%),                 avg. length: 2999.0,                last time consumption/overall running time: 163.5266s / 105409.4389 s
env0_first_0:                 episode reward: -0.5500,                 loss: -0.2102
env0_second_0:                 episode reward: 0.5500,                 loss: -0.1292
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 48481/50000 (96.9620%),                 avg. length: 2999.0,                last time consumption/overall running time: 163.2257s / 105572.6646 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.2122
env0_second_0:                 episode reward: 0.1000,                 loss: -0.1467
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 48501/50000 (97.0020%),                 avg. length: 2999.0,                last time consumption/overall running time: 161.8768s / 105734.5414 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.2148
env0_second_0:                 episode reward: 0.1000,                 loss: -0.1300
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 48521/50000 (97.0420%),                 avg. length: 2999.0,                last time consumption/overall running time: 163.8043s / 105898.3458 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.2068
env0_second_0:                 episode reward: 0.2000,                 loss: -0.1429
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 48541/50000 (97.0820%),                 avg. length: 2999.0,                last time consumption/overall running time: 158.2418s / 106056.5875 s
env0_first_0:                 episode reward: -0.2500,                 loss: -0.2138
env0_second_0:                 episode reward: 0.2500,                 loss: -0.1383
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 48561/50000 (97.1220%),                 avg. length: 2999.0,                last time consumption/overall running time: 156.6348s / 106213.2224 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.2088
env0_second_0:                 episode reward: -0.0500,                 loss: -0.1233
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 48581/50000 (97.1620%),                 avg. length: 2999.0,                last time consumption/overall running time: 157.7336s / 106370.9560 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.2103
env0_second_0:                 episode reward: 0.2000,                 loss: -0.1147
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 48601/50000 (97.2020%),                 avg. length: 2999.0,                last time consumption/overall running time: 156.8568s / 106527.8128 s
env0_first_0:                 episode reward: -0.2500,                 loss: -0.2081
env0_second_0:                 episode reward: 0.2500,                 loss: -0.1471
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 48621/50000 (97.2420%),                 avg. length: 2999.0,                last time consumption/overall running time: 158.3736s / 106686.1864 s
env0_first_0:                 episode reward: -0.5000,                 loss: -0.2067
env0_second_0:                 episode reward: 0.5000,                 loss: -0.1284
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 48641/50000 (97.2820%),                 avg. length: 2999.0,                last time consumption/overall running time: 157.0156s / 106843.2020 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.2125
env0_second_0:                 episode reward: 0.1000,                 loss: -0.1415
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 48661/50000 (97.3220%),                 avg. length: 2999.0,                last time consumption/overall running time: 157.6158s / 107000.8178 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2072
env0_second_0:                 episode reward: 0.0000,                 loss: -0.1371
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 48681/50000 (97.3620%),                 avg. length: 2999.0,                last time consumption/overall running time: 157.1354s / 107157.9532 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.2198
env0_second_0:                 episode reward: -0.0500,                 loss: -0.1352
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 48701/50000 (97.4020%),                 avg. length: 2999.0,                last time consumption/overall running time: 157.3225s / 107315.2757 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.2103
env0_second_0:                 episode reward: -0.0500,                 loss: -0.1518
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 48721/50000 (97.4420%),                 avg. length: 2999.0,                last time consumption/overall running time: 158.2841s / 107473.5598 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.2097
env0_second_0:                 episode reward: 0.1500,                 loss: -0.1331
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 48741/50000 (97.4820%),                 avg. length: 2999.0,                last time consumption/overall running time: 156.2019s / 107629.7617 s
env0_first_0:                 episode reward: -0.2500,                 loss: -0.2099
env0_second_0:                 episode reward: 0.2500,                 loss: -0.1335
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 48761/50000 (97.5220%),                 avg. length: 2999.0,                last time consumption/overall running time: 158.7003s / 107788.4620 s
env0_first_0:                 episode reward: -0.4500,                 loss: -0.2039
env0_second_0:                 episode reward: 0.4500,                 loss: -0.1292
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 48781/50000 (97.5620%),                 avg. length: 2999.0,                last time consumption/overall running time: 162.5551s / 107951.0171 s
env0_first_0:                 episode reward: -0.3500,                 loss: -0.2028
env0_second_0:                 episode reward: 0.3500,                 loss: -0.1357
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 48801/50000 (97.6020%),                 avg. length: 2999.0,                last time consumption/overall running time: 161.4746s / 108112.4917 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2107
env0_second_0:                 episode reward: 0.0000,                 loss: -0.1388
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 48821/50000 (97.6420%),                 avg. length: 2999.0,                last time consumption/overall running time: 157.8618s / 108270.3535 s
env0_first_0:                 episode reward: 0.1500,                 loss: -0.2214
env0_second_0:                 episode reward: -0.1500,                 loss: -0.1457
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 48841/50000 (97.6820%),                 avg. length: 2999.0,                last time consumption/overall running time: 159.3051s / 108429.6585 s
env0_first_0:                 episode reward: -0.3500,                 loss: -0.2127
env0_second_0:                 episode reward: 0.3500,                 loss: -0.1566
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 48861/50000 (97.7220%),                 avg. length: 2999.0,                last time consumption/overall running time: 158.5789s / 108588.2374 s
env0_first_0:                 episode reward: -0.4000,                 loss: -0.2065
env0_second_0:                 episode reward: 0.4000,                 loss: -0.1325
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 48881/50000 (97.7620%),                 avg. length: 2999.0,                last time consumption/overall running time: 158.7389s / 108746.9763 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.2062
env0_second_0:                 episode reward: 0.2000,                 loss: -0.1308
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 48901/50000 (97.8020%),                 avg. length: 2999.0,                last time consumption/overall running time: 160.5957s / 108907.5720 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.2173
env0_second_0:                 episode reward: 0.1000,                 loss: -0.1517
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 48921/50000 (97.8420%),                 avg. length: 2999.0,                last time consumption/overall running time: 159.9883s / 109067.5603 s
env0_first_0:                 episode reward: -0.3000,                 loss: -0.2070
env0_second_0:                 episode reward: 0.3000,                 loss: -0.1294
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 48941/50000 (97.8820%),                 avg. length: 2999.0,                last time consumption/overall running time: 158.5049s / 109226.0652 s
env0_first_0:                 episode reward: -0.5000,                 loss: -0.2068
env0_second_0:                 episode reward: 0.5000,                 loss: -0.1347
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 48961/50000 (97.9220%),                 avg. length: 2999.0,                last time consumption/overall running time: 159.5974s / 109385.6626 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.2177
env0_second_0:                 episode reward: 0.1500,                 loss: -0.1390
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 48981/50000 (97.9620%),                 avg. length: 2999.0,                last time consumption/overall running time: 158.6492s / 109544.3118 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.2193
env0_second_0:                 episode reward: 0.1500,                 loss: -0.1341
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 49001/50000 (98.0020%),                 avg. length: 2999.0,                last time consumption/overall running time: 160.4314s / 109704.7432 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.2229
env0_second_0:                 episode reward: -0.0500,                 loss: -0.1484
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 49021/50000 (98.0420%),                 avg. length: 2999.0,                last time consumption/overall running time: 160.0842s / 109864.8274 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.2171
env0_second_0:                 episode reward: 0.1500,                 loss: -0.1304
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 49041/50000 (98.0820%),                 avg. length: 2999.0,                last time consumption/overall running time: 163.2491s / 110028.0765 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2125
env0_second_0:                 episode reward: 0.0000,                 loss: -0.1105
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 49061/50000 (98.1220%),                 avg. length: 2999.0,                last time consumption/overall running time: 162.3926s / 110190.4691 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.2020
env0_second_0:                 episode reward: 0.2000,                 loss: -0.1151
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 49081/50000 (98.1620%),                 avg. length: 2999.0,                last time consumption/overall running time: 159.6845s / 110350.1536 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.2021
env0_second_0:                 episode reward: 0.2000,                 loss: -0.1312
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 49101/50000 (98.2020%),                 avg. length: 2999.0,                last time consumption/overall running time: 160.2755s / 110510.4291 s
env0_first_0:                 episode reward: -0.2500,                 loss: -0.2105
env0_second_0:                 episode reward: 0.2500,                 loss: -0.1231
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 49121/50000 (98.2420%),                 avg. length: 2999.0,                last time consumption/overall running time: 160.2038s / 110670.6329 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.2124
env0_second_0:                 episode reward: 0.0500,                 loss: -0.1314
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 49141/50000 (98.2820%),                 avg. length: 2999.0,                last time consumption/overall running time: 160.2344s / 110830.8673 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.2204
env0_second_0:                 episode reward: 0.1500,                 loss: -0.1500
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 49161/50000 (98.3220%),                 avg. length: 2999.0,                last time consumption/overall running time: 158.0817s / 110988.9491 s
env0_first_0:                 episode reward: -0.7000,                 loss: -0.2185
env0_second_0:                 episode reward: 0.7000,                 loss: -0.1518
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 49181/50000 (98.3620%),                 avg. length: 2999.0,                last time consumption/overall running time: 160.3101s / 111149.2592 s
env0_first_0:                 episode reward: -0.3000,                 loss: -0.2126
env0_second_0:                 episode reward: 0.3000,                 loss: -0.1399
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 49201/50000 (98.4020%),                 avg. length: 2999.0,                last time consumption/overall running time: 158.6329s / 111307.8920 s
env0_first_0:                 episode reward: -0.4500,                 loss: -0.2075
env0_second_0:                 episode reward: 0.4500,                 loss: -0.1483
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 49221/50000 (98.4420%),                 avg. length: 2999.0,                last time consumption/overall running time: 159.4286s / 111467.3207 s
env0_first_0:                 episode reward: -0.4000,                 loss: -0.2122
env0_second_0:                 episode reward: 0.4000,                 loss: -0.1406
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 49241/50000 (98.4820%),                 avg. length: 2999.0,                last time consumption/overall running time: 158.7053s / 111626.0260 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.2141
env0_second_0:                 episode reward: 0.2000,                 loss: -0.1375
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 49261/50000 (98.5220%),                 avg. length: 2999.0,                last time consumption/overall running time: 157.9172s / 111783.9432 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.2174
env0_second_0:                 episode reward: 0.1000,                 loss: -0.1609
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 49281/50000 (98.5620%),                 avg. length: 2939.05,                last time consumption/overall running time: 153.3555s / 111937.2987 s
env0_first_0:                 episode reward: 0.2500,                 loss: -0.2138
env0_second_0:                 episode reward: -0.2500,                 loss: -0.1403
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 49301/50000 (98.6020%),                 avg. length: 2999.0,                last time consumption/overall running time: 155.5112s / 112092.8099 s
env0_first_0:                 episode reward: -0.5000,                 loss: -0.2053
env0_second_0:                 episode reward: 0.5000,                 loss: -0.1518
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 49321/50000 (98.6420%),                 avg. length: 2999.0,                last time consumption/overall running time: 156.5148s / 112249.3247 s
env0_first_0:                 episode reward: -0.3000,                 loss: -0.2221
env0_second_0:                 episode reward: 0.3000,                 loss: -0.1270
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 49341/50000 (98.6820%),                 avg. length: 2999.0,                last time consumption/overall running time: 158.6181s / 112407.9428 s
env0_first_0:                 episode reward: -0.4000,                 loss: -0.2140
env0_second_0:                 episode reward: 0.4000,                 loss: -0.1342
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 49361/50000 (98.7220%),                 avg. length: 2999.0,                last time consumption/overall running time: 157.2305s / 112565.1733 s
env0_first_0:                 episode reward: -0.6000,                 loss: -0.2042
env0_second_0:                 episode reward: 0.6000,                 loss: -0.1273
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 49381/50000 (98.7620%),                 avg. length: 2999.0,                last time consumption/overall running time: 158.8220s / 112723.9952 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2159
env0_second_0:                 episode reward: 0.0000,                 loss: -0.1358
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 49401/50000 (98.8020%),                 avg. length: 2999.0,                last time consumption/overall running time: 158.9742s / 112882.9694 s
env0_first_0:                 episode reward: -0.4000,                 loss: -0.2240
env0_second_0:                 episode reward: 0.4000,                 loss: -0.1606
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 49421/50000 (98.8420%),                 avg. length: 2999.0,                last time consumption/overall running time: 158.8949s / 113041.8643 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.2216
env0_second_0:                 episode reward: 0.0500,                 loss: -0.1466
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 49441/50000 (98.8820%),                 avg. length: 2999.0,                last time consumption/overall running time: 159.8599s / 113201.7242 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.2177
env0_second_0:                 episode reward: 0.1000,                 loss: -0.1386
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 49461/50000 (98.9220%),                 avg. length: 2999.0,                last time consumption/overall running time: 157.9247s / 113359.6490 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.2165
env0_second_0:                 episode reward: 0.1500,                 loss: -0.1471
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 49481/50000 (98.9620%),                 avg. length: 2999.0,                last time consumption/overall running time: 157.2003s / 113516.8493 s
env0_first_0:                 episode reward: -0.3500,                 loss: -0.2107
env0_second_0:                 episode reward: 0.3500,                 loss: -0.1516
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 49501/50000 (99.0020%),                 avg. length: 2999.0,                last time consumption/overall running time: 155.7226s / 113672.5719 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.2178
env0_second_0:                 episode reward: 0.1000,                 loss: -0.1561
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 49521/50000 (99.0420%),                 avg. length: 2999.0,                last time consumption/overall running time: 157.6566s / 113830.2285 s
env0_first_0:                 episode reward: -0.2500,                 loss: -0.2110
env0_second_0:                 episode reward: 0.2500,                 loss: -0.1332
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 49541/50000 (99.0820%),                 avg. length: 2999.0,                last time consumption/overall running time: 158.2548s / 113988.4833 s
env0_first_0:                 episode reward: -0.3500,                 loss: -0.2218
env0_second_0:                 episode reward: 0.3500,                 loss: -0.1495
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 49561/50000 (99.1220%),                 avg. length: 2999.0,                last time consumption/overall running time: 157.5061s / 114145.9894 s
env0_first_0:                 episode reward: -0.5000,                 loss: -0.2156
env0_second_0:                 episode reward: 0.5000,                 loss: -0.1630
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 49581/50000 (99.1620%),                 avg. length: 2999.0,                last time consumption/overall running time: 159.4789s / 114305.4683 s
env0_first_0:                 episode reward: -0.5000,                 loss: -0.2276
env0_second_0:                 episode reward: 0.5000,                 loss: -0.1569
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 49601/50000 (99.2020%),                 avg. length: 2999.0,                last time consumption/overall running time: 159.2691s / 114464.7374 s
env0_first_0:                 episode reward: -0.3500,                 loss: -0.2189
env0_second_0:                 episode reward: 0.3500,                 loss: -0.1497
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 49621/50000 (99.2420%),                 avg. length: 2999.0,                last time consumption/overall running time: 157.3899s / 114622.1274 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.2261
env0_second_0:                 episode reward: -0.0500,                 loss: -0.1618
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 49641/50000 (99.2820%),                 avg. length: 2999.0,                last time consumption/overall running time: 156.7799s / 114778.9073 s
env0_first_0:                 episode reward: -0.2500,                 loss: -0.2104
env0_second_0:                 episode reward: 0.2500,                 loss: -0.1412
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 49661/50000 (99.3220%),                 avg. length: 2999.0,                last time consumption/overall running time: 158.8544s / 114937.7617 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.2279
env0_second_0:                 episode reward: 0.2000,                 loss: -0.1652
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 49681/50000 (99.3620%),                 avg. length: 2999.0,                last time consumption/overall running time: 159.4897s / 115097.2514 sLoad SlimeVolley-v0 environment in type slimevolley.
Env observation space: Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (12,), float32) action space: Discrete(6)
Load SlimeVolley-v0 environment in type slimevolley.
Env observation space: Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (12,), float32) action space: Discrete(6)
/home/zihan/research/MARS/mars/rl/agents/nash_ppo.py:181: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1641801999604/work/torch/csrc/utils/tensor_new.cpp:210.)
  s,a,r,s_prime,prob_a,done_mask =    torch.tensor(s_lst, dtype=torch.float).to(self.device), torch.tensor(a_lst).to(self.device), \
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

env0_first_0:                 episode reward: -0.1000,                 loss: -0.2323
env0_second_0:                 episode reward: 0.1000,                 loss: -0.1606
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 49701/50000 (99.4020%),                 avg. length: 2999.0,                last time consumption/overall running time: 159.6520s / 115256.9034 s
env0_first_0:                 episode reward: -0.9000,                 loss: -0.2089
env0_second_0:                 episode reward: 0.9000,                 loss: -0.1594
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 49721/50000 (99.4420%),                 avg. length: 2999.0,                last time consumption/overall running time: 160.3844s / 115417.2877 s
env0_first_0:                 episode reward: -0.3500,                 loss: -0.2033
env0_second_0:                 episode reward: 0.3500,                 loss: -0.1463
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 49741/50000 (99.4820%),                 avg. length: 2999.0,                last time consumption/overall running time: 160.1927s / 115577.4804 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.2191
env0_second_0:                 episode reward: 0.0500,                 loss: -0.1560
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 49761/50000 (99.5220%),                 avg. length: 2999.0,                last time consumption/overall running time: 160.9251s / 115738.4055 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.2255
env0_second_0:                 episode reward: -0.0500,                 loss: -0.1521
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 49781/50000 (99.5620%),                 avg. length: 2999.0,                last time consumption/overall running time: 159.5785s / 115897.9840 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.2220
env0_second_0:                 episode reward: 0.2000,                 loss: -0.1538
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 49801/50000 (99.6020%),                 avg. length: 2999.0,                last time consumption/overall running time: 157.9410s / 116055.9250 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.2288
env0_second_0:                 episode reward: -0.0500,                 loss: -0.1560
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 49821/50000 (99.6420%),                 avg. length: 2999.0,                last time consumption/overall running time: 162.1117s / 116218.0367 s
env0_first_0:                 episode reward: -0.4000,                 loss: -0.2255
env0_second_0:                 episode reward: 0.4000,                 loss: -0.1593
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 49841/50000 (99.6820%),                 avg. length: 2999.0,                last time consumption/overall running time: 158.3390s / 116376.3757 s
env0_first_0:                 episode reward: -0.3000,                 loss: -0.2273
env0_second_0:                 episode reward: 0.3000,                 loss: -0.1581
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 49861/50000 (99.7220%),                 avg. length: 2999.0,                last time consumption/overall running time: 158.4534s / 116534.8290 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.2249
env0_second_0:                 episode reward: 0.2000,                 loss: -0.1462
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 49881/50000 (99.7620%),                 avg. length: 2999.0,                last time consumption/overall running time: 158.1424s / 116692.9714 s
env0_first_0:                 episode reward: -0.3500,                 loss: -0.2196
env0_second_0:                 episode reward: 0.3500,                 loss: -0.1375
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 49901/50000 (99.8020%),                 avg. length: 2999.0,                last time consumption/overall running time: 165.9177s / 116858.8892 s
env0_first_0:                 episode reward: -0.3000,                 loss: -0.2163
env0_second_0:                 episode reward: 0.3000,                 loss: -0.1527
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 49921/50000 (99.8420%),                 avg. length: 2999.0,                last time consumption/overall running time: 157.0731s / 117015.9622 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.2279
env0_second_0:                 episode reward: 0.1500,                 loss: -0.1582
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 49941/50000 (99.8820%),                 avg. length: 2947.5,                last time consumption/overall running time: 154.1272s / 117170.0894 s
env0_first_0:                 episode reward: -0.7000,                 loss: -0.2117
env0_second_0:                 episode reward: 0.7000,                 loss: -0.1521
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 49961/50000 (99.9220%),                 avg. length: 2999.0,                last time consumption/overall running time: 160.4322s / 117330.5216 s
env0_first_0:                 episode reward: -0.2500,                 loss: -0.2196
env0_second_0:                 episode reward: 0.2500,                 loss: -0.1503
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 49981/50000 (99.9620%),                 avg. length: 2999.0,                last time consumption/overall running time: 158.9803s / 117489.5019 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.2223
env0_second_0:                 episode reward: 0.1000,                 loss: -0.1634
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
