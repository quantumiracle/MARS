pygame 2.0.0 (SDL 2.0.12, python 3.7.10)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 12.0, (1,), float32) action space: Discrete(3)
random seed: 91
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7fad47b999d0>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
Agents No. [0] (index starting from 0) are not learnable.
Load meta strategy:  [array([0.241, 0.082, 0.128, ..., 0.015, 0.185, 0.061]) array([0.059, 0.   , 0.135, ..., 0.   , 0.   , 0.011])]
Load checkpoints (policy family):  [list(['83', '5753', '6419', '9691', '12712', '16446', '20191', '20772', '24729', '28587', '35631', '38431', '38946', '39041', '39808', '40118', '40412', '41100', '41478', '41778', '41983', '42076', '42433', '42768', '43151', '43229', '43949', '44117', '44258', '44846', '45166', '45962', '46596', '46667', '47327', '47599', '47724', '48094', '48455', '48649', '48828', '49089', '49310', '49568'])
 list(['121', '6342', '6627', '9768', '12785', '16467', '20231', '20802', '24751', '28619', '35652', '38452', '38973', '39078', '39831', '40164', '40433', '41156', '41501', '41819', '42011', '42097', '42458', '42797', '43176', '43250', '44010', '44146', '44297', '44888', '45313', '45997', '46620', '46694', '47431', '47654', '47771', '48131', '48485', '48670', '48949', '49156', '49349'])]
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': 'random', 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000, 'update_itr': 1}, 'batch_size': 640, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'cpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220116204408/epi_50000/', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nxdo2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'selfplay_score_delta': 1.5, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'against_baseline': False}
Save models to : /home/zihan/research/MARS/data/model/20220116204408_exploit_50000/mdp_arbitrary_mdp_nxdo2. 
 Save logs to: /home/zihan/research/MARS/data/log/20220116204408_exploit_50000/mdp_arbitrary_mdp_nxdo2.
Episode: 1/30000 (0.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 1.4024s / 1.4024 s
agent0:                 episode reward: -1.1778,                 loss: nan
agent1:                 episode reward: 1.1778,                 loss: nan
Episode: 21/30000 (0.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3351s / 1.7375 s
agent0:                 episode reward: -0.3436,                 loss: nan
agent1:                 episode reward: 0.3436,                 loss: nan
Episode: 41/30000 (0.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2593s / 1.9968 s
agent0:                 episode reward: -0.0865,                 loss: nan
agent1:                 episode reward: 0.0865,                 loss: nan
Episode: 61/30000 (0.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5830s / 2.5798 s
agent0:                 episode reward: 0.0463,                 loss: nan
agent1:                 episode reward: -0.0463,                 loss: nan
Episode: 81/30000 (0.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6286s / 3.2084 s
agent0:                 episode reward: 0.4358,                 loss: nan
agent1:                 episode reward: -0.4358,                 loss: nan
Episode: 101/30000 (0.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5781s / 3.7865 s
agent0:                 episode reward: 0.0265,                 loss: nan
agent1:                 episode reward: -0.0265,                 loss: nan
Episode: 121/30000 (0.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5671s / 4.3535 s
agent0:                 episode reward: -0.3469,                 loss: nan
agent1:                 episode reward: 0.3469,                 loss: nan
Episode: 141/30000 (0.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4948s / 4.8483 s
agent0:                 episode reward: 0.2239,                 loss: nan
agent1:                 episode reward: -0.2239,                 loss: nan
Episode: 161/30000 (0.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 1.1210s / 5.9693 s
agent0:                 episode reward: -0.0502,                 loss: nan
agent1:                 episode reward: 0.0502,                 loss: nan
Episode: 181/30000 (0.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 1.1916s / 7.1609 s
agent0:                 episode reward: 0.1800,                 loss: nan
agent1:                 episode reward: -0.1800,                 loss: nan
Episode: 201/30000 (0.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 2.5921s / 9.7531 s
agent0:                 episode reward: -0.0115,                 loss: nan
agent1:                 episode reward: 0.0115,                 loss: nan
Episode: 221/30000 (0.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 39.5858s / 49.3389 s
agent0:                 episode reward: -0.1703,                 loss: nan
agent1:                 episode reward: 0.1703,                 loss: 0.2371
Episode: 241/30000 (0.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 97.3310s / 146.6699 s
agent0:                 episode reward: -0.1343,                 loss: nan
agent1:                 episode reward: 0.1343,                 loss: 0.2064
Episode: 261/30000 (0.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 100.1885s / 246.8584 s
agent0:                 episode reward: -0.2983,                 loss: nan
agent1:                 episode reward: 0.2983,                 loss: 0.1665
Episode: 281/30000 (0.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 101.4226s / 348.2810 s
agent0:                 episode reward: 0.0313,                 loss: nan
agent1:                 episode reward: -0.0313,                 loss: 0.1576
Episode: 301/30000 (1.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 101.7278s / 450.0089 s
agent0:                 episode reward: 0.1651,                 loss: nan
agent1:                 episode reward: -0.1651,                 loss: 0.1561
Episode: 321/30000 (1.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 99.2116s / 549.2205 s
agent0:                 episode reward: -0.0397,                 loss: nan
agent1:                 episode reward: 0.0397,                 loss: 0.1544
Episode: 341/30000 (1.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 101.1972s / 650.4177 s
agent0:                 episode reward: -0.1015,                 loss: nan
agent1:                 episode reward: 0.1015,                 loss: 0.1526
Episode: 361/30000 (1.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 98.7647s / 749.1824 s
agent0:                 episode reward: 0.2505,                 loss: nan
agent1:                 episode reward: -0.2505,                 loss: 0.1516
Episode: 381/30000 (1.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 92.3106s / 841.4929 s
agent0:                 episode reward: 0.1335,                 loss: nan
agent1:                 episode reward: -0.1335,                 loss: 0.1500
Episode: 401/30000 (1.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 99.1707s / 940.6636 s
agent0:                 episode reward: 0.0477,                 loss: nan
agent1:                 episode reward: -0.0477,                 loss: 0.1512
Episode: 421/30000 (1.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 103.2721s / 1043.9357 s
agent0:                 episode reward: 0.0740,                 loss: nan
agent1:                 episode reward: -0.0740,                 loss: 0.1508
Episode: 441/30000 (1.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 101.7447s / 1145.6804 s
agent0:                 episode reward: -0.0588,                 loss: nan
agent1:                 episode reward: 0.0588,                 loss: 0.1496
Episode: 461/30000 (1.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 107.1487s / 1252.8291 s
agent0:                 episode reward: 0.2256,                 loss: nan
agent1:                 episode reward: -0.2256,                 loss: 0.1502
Episode: 481/30000 (1.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 112.7069s / 1365.5360 s
agent0:                 episode reward: -0.0336,                 loss: nan
agent1:                 episode reward: 0.0336,                 loss: 0.1498
Episode: 501/30000 (1.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 110.1338s / 1475.6698 s
agent0:                 episode reward: 0.3375,                 loss: nan
agent1:                 episode reward: -0.3375,                 loss: 0.1494
Episode: 521/30000 (1.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 108.0043s / 1583.6741 s
agent0:                 episode reward: -0.1477,                 loss: nan
agent1:                 episode reward: 0.1477,                 loss: 0.1487
Episode: 541/30000 (1.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 106.4389s / 1690.1129 s
agent0:                 episode reward: 0.1565,                 loss: nan
agent1:                 episode reward: -0.1565,                 loss: 0.1488
Episode: 561/30000 (1.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 107.3535s / 1797.4665 s
agent0:                 episode reward: 0.0716,                 loss: nan
agent1:                 episode reward: -0.0716,                 loss: 0.1708
Episode: 581/30000 (1.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 110.7413s / 1908.2078 s
agent0:                 episode reward: -0.3726,                 loss: nan
agent1:                 episode reward: 0.3726,                 loss: 0.1644
Episode: 601/30000 (2.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 108.3504s / 2016.5582 s
agent0:                 episode reward: 0.2499,                 loss: nan
agent1:                 episode reward: -0.2499,                 loss: 0.1625
Episode: 621/30000 (2.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 108.5462s / 2125.1044 s
agent0:                 episode reward: 0.1083,                 loss: nan
agent1:                 episode reward: -0.1083,                 loss: 0.1599
Episode: 641/30000 (2.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 107.4276s / 2232.5320 s
agent0:                 episode reward: 0.0251,                 loss: nan
agent1:                 episode reward: -0.0251,                 loss: 0.1596
Episode: 661/30000 (2.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 108.0672s / 2340.5992 s
agent0:                 episode reward: -0.3295,                 loss: nan
agent1:                 episode reward: 0.3295,                 loss: 0.1596
Episode: 681/30000 (2.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 109.4122s / 2450.0114 s
agent0:                 episode reward: -0.3419,                 loss: nan
agent1:                 episode reward: 0.3419,                 loss: 0.1593
Episode: 701/30000 (2.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 108.1691s / 2558.1805 s
agent0:                 episode reward: -0.0095,                 loss: nan
agent1:                 episode reward: 0.0095,                 loss: 0.1615
Episode: 721/30000 (2.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 109.9478s / 2668.1283 s
agent0:                 episode reward: -0.0949,                 loss: nan
agent1:                 episode reward: 0.0949,                 loss: 0.1593
Episode: 741/30000 (2.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 162.7601s / 2830.8884 s
agent0:                 episode reward: -0.5710,                 loss: nan
agent1:                 episode reward: 0.5710,                 loss: 0.1612
Episode: 761/30000 (2.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 236.4185s / 3067.3069 s
agent0:                 episode reward: 0.3184,                 loss: nan
agent1:                 episode reward: -0.3184,                 loss: 0.1596
Episode: 781/30000 (2.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 235.4596s / 3302.7666 s
agent0:                 episode reward: 0.2327,                 loss: nan
agent1:                 episode reward: -0.2327,                 loss: 0.1601
Episode: 801/30000 (2.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 238.3849s / 3541.1515 s
agent0:                 episode reward: 0.1113,                 loss: nan
agent1:                 episode reward: -0.1113,                 loss: 0.1620
Episode: 821/30000 (2.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 239.7796s / 3780.9311 s
agent0:                 episode reward: 0.0002,                 loss: nan
agent1:                 episode reward: -0.0002,                 loss: 0.1614
Episode: 841/30000 (2.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 234.9784s / 4015.9095 s
agent0:                 episode reward: 0.1662,                 loss: nan
agent1:                 episode reward: -0.1662,                 loss: 0.1597
Episode: 861/30000 (2.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 239.4611s / 4255.3706 s
agent0:                 episode reward: -0.1411,                 loss: nan
agent1:                 episode reward: 0.1411,                 loss: 0.1611
Episode: 881/30000 (2.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 235.5219s / 4490.8926 s
agent0:                 episode reward: 0.1748,                 loss: nan
agent1:                 episode reward: -0.1748,                 loss: 0.1610
Episode: 901/30000 (3.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 232.7814s / 4723.6739 s
agent0:                 episode reward: 0.0482,                 loss: nan
agent1:                 episode reward: -0.0482,                 loss: 0.1561
Episode: 921/30000 (3.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.6606s / 4965.3346 s
agent0:                 episode reward: 0.2333,                 loss: nan
agent1:                 episode reward: -0.2333,                 loss: 0.1544
Episode: 941/30000 (3.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 240.6308s / 5205.9654 s
agent0:                 episode reward: 0.2503,                 loss: nan
agent1:                 episode reward: -0.2503,                 loss: 0.1556
Episode: 961/30000 (3.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 237.7147s / 5443.6801 s
agent0:                 episode reward: -0.0227,                 loss: nan
agent1:                 episode reward: 0.0227,                 loss: 0.1557
Episode: 981/30000 (3.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.2940s / 5684.9741 s
agent0:                 episode reward: -0.0288,                 loss: nan
agent1:                 episode reward: 0.0288,                 loss: 0.1548
Episode: 1001/30000 (3.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 239.8587s / 5924.8328 s
agent0:                 episode reward: -0.1700,                 loss: nan
agent1:                 episode reward: 0.1700,                 loss: 0.1551
Episode: 1021/30000 (3.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.6409s / 6173.4736 s
agent0:                 episode reward: -0.0976,                 loss: nan
agent1:                 episode reward: 0.0976,                 loss: 0.1538
Episode: 1041/30000 (3.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 239.4786s / 6412.9522 s
agent0:                 episode reward: -0.2066,                 loss: nan
agent1:                 episode reward: 0.2066,                 loss: 0.1551
Episode: 1061/30000 (3.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.2821s / 6659.2343 s
agent0:                 episode reward: 0.0009,                 loss: nan
agent1:                 episode reward: -0.0009,                 loss: 0.1546
Episode: 1081/30000 (3.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 237.4427s / 6896.6770 s
agent0:                 episode reward: 0.3022,                 loss: nan
agent1:                 episode reward: -0.3022,                 loss: 0.1545
Episode: 1101/30000 (3.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.6317s / 7141.3087 s
agent0:                 episode reward: 0.2276,                 loss: nan
agent1:                 episode reward: -0.2276,                 loss: 0.1547
Episode: 1121/30000 (3.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.1247s / 7384.4334 s
agent0:                 episode reward: 0.1497,                 loss: nan
agent1:                 episode reward: -0.1497,                 loss: 0.1531
Episode: 1141/30000 (3.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 240.5623s / 7624.9956 s
agent0:                 episode reward: -0.1272,                 loss: nan
agent1:                 episode reward: 0.1272,                 loss: 0.1543
Episode: 1161/30000 (3.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 234.6991s / 7859.6947 s
agent0:                 episode reward: -0.0839,                 loss: nan
agent1:                 episode reward: 0.0839,                 loss: 0.1537
Episode: 1181/30000 (3.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.5848s / 8110.2795 s
agent0:                 episode reward: -0.0334,                 loss: nan
agent1:                 episode reward: 0.0334,                 loss: 0.1550
Episode: 1201/30000 (4.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 237.2136s / 8347.4931 s
agent0:                 episode reward: 0.1108,                 loss: nan
agent1:                 episode reward: -0.1108,                 loss: 0.1537
Episode: 1221/30000 (4.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.7252s / 8591.2183 s
agent0:                 episode reward: -0.1656,                 loss: nan
agent1:                 episode reward: 0.1656,                 loss: 0.1531
Episode: 1241/30000 (4.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.3599s / 8836.5782 s
agent0:                 episode reward: -0.1100,                 loss: nan
agent1:                 episode reward: 0.1100,                 loss: 0.1547
Episode: 1261/30000 (4.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 239.0566s / 9075.6349 s
agent0:                 episode reward: 0.1736,                 loss: nan
agent1:                 episode reward: -0.1736,                 loss: 0.1544
Episode: 1281/30000 (4.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 240.3313s / 9315.9662 s
agent0:                 episode reward: -0.0653,                 loss: nan
agent1:                 episode reward: 0.0653,                 loss: 0.1557
Episode: 1301/30000 (4.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.6282s / 9559.5944 s
agent0:                 episode reward: 0.2361,                 loss: nan
agent1:                 episode reward: -0.2361,                 loss: 0.1539
Episode: 1321/30000 (4.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.2935s / 9800.8879 s
agent0:                 episode reward: -0.2536,                 loss: nan
agent1:                 episode reward: 0.2536,                 loss: 0.1529
Episode: 1341/30000 (4.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.5741s / 10048.4620 s
agent0:                 episode reward: -0.2056,                 loss: nan
agent1:                 episode reward: 0.2056,                 loss: 0.1533
Episode: 1361/30000 (4.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 234.9452s / 10283.4072 s
agent0:                 episode reward: 0.2097,                 loss: nan
agent1:                 episode reward: -0.2097,                 loss: 0.1511
Episode: 1381/30000 (4.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 239.8173s / 10523.2245 s
agent0:                 episode reward: -0.4008,                 loss: nan
agent1:                 episode reward: 0.4008,                 loss: 0.1532
Episode: 1401/30000 (4.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.3949s / 10771.6194 s
agent0:                 episode reward: -0.2228,                 loss: nan
agent1:                 episode reward: 0.2228,                 loss: 0.1522
Episode: 1421/30000 (4.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.2701s / 11020.8895 s
agent0:                 episode reward: -0.1907,                 loss: nan
agent1:                 episode reward: 0.1907,                 loss: 0.1529
Episode: 1441/30000 (4.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.0923s / 11266.9818 s
agent0:                 episode reward: 0.1543,                 loss: nan
agent1:                 episode reward: -0.1543,                 loss: 0.1510
Episode: 1461/30000 (4.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.4522s / 11512.4340 s
agent0:                 episode reward: -0.4018,                 loss: nan
agent1:                 episode reward: 0.4018,                 loss: 0.1521
Episode: 1481/30000 (4.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.9217s / 11756.3557 s
agent0:                 episode reward: 0.0013,                 loss: nan
agent1:                 episode reward: -0.0013,                 loss: 0.1517
Episode: 1501/30000 (5.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.8007s / 12005.1564 s
agent0:                 episode reward: 0.2395,                 loss: nan
agent1:                 episode reward: -0.2395,                 loss: 0.1521
Episode: 1521/30000 (5.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 239.7014s / 12244.8579 s
agent0:                 episode reward: -0.0780,                 loss: nan
agent1:                 episode reward: 0.0780,                 loss: 0.1519
Episode: 1541/30000 (5.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 238.6697s / 12483.5276 s
agent0:                 episode reward: -0.2639,                 loss: nan
agent1:                 episode reward: 0.2639,                 loss: 0.1522
Episode: 1561/30000 (5.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.9843s / 12728.5119 s
agent0:                 episode reward: 0.1668,                 loss: nan
agent1:                 episode reward: -0.1668,                 loss: 0.1523
Episode: 1581/30000 (5.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.7419s / 12973.2537 s
agent0:                 episode reward: -0.2464,                 loss: nan
agent1:                 episode reward: 0.2464,                 loss: 0.1529
Episode: 1601/30000 (5.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.6330s / 13215.8868 s
agent0:                 episode reward: 0.0606,                 loss: nan
agent1:                 episode reward: -0.0606,                 loss: 0.1521
Episode: 1621/30000 (5.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.9520s / 13458.8388 s
agent0:                 episode reward: -0.2363,                 loss: nan
agent1:                 episode reward: 0.2363,                 loss: 0.1520
Episode: 1641/30000 (5.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.4165s / 13700.2553 s
agent0:                 episode reward: -0.1241,                 loss: nan
agent1:                 episode reward: 0.1241,                 loss: 0.1530
Episode: 1661/30000 (5.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 236.0906s / 13936.3459 s
agent0:                 episode reward: -0.3776,                 loss: nan
agent1:                 episode reward: 0.3776,                 loss: 0.1523
Episode: 1681/30000 (5.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.0464s / 14178.3923 s
agent0:                 episode reward: -0.0716,                 loss: nan
agent1:                 episode reward: 0.0716,                 loss: 0.1530
Episode: 1701/30000 (5.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.5533s / 14420.9456 s
agent0:                 episode reward: -0.1497,                 loss: nan
agent1:                 episode reward: 0.1497,                 loss: 0.1514
Episode: 1721/30000 (5.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.2120s / 14667.1576 s
agent0:                 episode reward: 0.0445,                 loss: nan
agent1:                 episode reward: -0.0445,                 loss: 0.1514
Episode: 1741/30000 (5.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 240.4828s / 14907.6404 s
agent0:                 episode reward: 0.0903,                 loss: nan
agent1:                 episode reward: -0.0903,                 loss: 0.1515
Episode: 1761/30000 (5.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.4060s / 15150.0464 s
agent0:                 episode reward: 0.1097,                 loss: nan
agent1:                 episode reward: -0.1097,                 loss: 0.1511
Episode: 1781/30000 (5.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.9619s / 15395.0083 s
agent0:                 episode reward: 0.0072,                 loss: nan
agent1:                 episode reward: -0.0072,                 loss: 0.1501
Episode: 1801/30000 (6.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.6447s / 15639.6529 s
agent0:                 episode reward: 0.0507,                 loss: nan
agent1:                 episode reward: -0.0507,                 loss: 0.1503
Episode: 1821/30000 (6.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.2912s / 15880.9442 s
agent0:                 episode reward: -0.0110,                 loss: nan
agent1:                 episode reward: 0.0110,                 loss: 0.1496
Episode: 1841/30000 (6.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 237.3858s / 16118.3300 s
agent0:                 episode reward: 0.3606,                 loss: nan
agent1:                 episode reward: -0.3606,                 loss: 0.1494
Episode: 1861/30000 (6.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.9683s / 16360.2982 s
agent0:                 episode reward: -0.1710,                 loss: nan
agent1:                 episode reward: 0.1710,                 loss: 0.1507
Episode: 1881/30000 (6.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.2467s / 16605.5449 s
agent0:                 episode reward: -0.1274,                 loss: nan
agent1:                 episode reward: 0.1274,                 loss: 0.1497
Episode: 1901/30000 (6.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.7962s / 16852.3411 s
agent0:                 episode reward: 0.2715,                 loss: nan
agent1:                 episode reward: -0.2715,                 loss: 0.1522
Episode: 1921/30000 (6.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.8902s / 17098.2314 s
agent0:                 episode reward: 0.0879,                 loss: nan
agent1:                 episode reward: -0.0879,                 loss: 0.1514
Episode: 1941/30000 (6.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.0063s / 17339.2377 s
agent0:                 episode reward: 0.0037,                 loss: nan
agent1:                 episode reward: -0.0037,                 loss: 0.1521
Episode: 1961/30000 (6.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 237.9175s / 17577.1551 s
agent0:                 episode reward: 0.1820,                 loss: nan
agent1:                 episode reward: -0.1820,                 loss: 0.1504
Episode: 1981/30000 (6.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.3718s / 17828.5270 s
agent0:                 episode reward: 0.1466,                 loss: nan
agent1:                 episode reward: -0.1466,                 loss: 0.1482
Episode: 2001/30000 (6.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.7578s / 18074.2847 s
agent0:                 episode reward: -0.1202,                 loss: nan
agent1:                 episode reward: 0.1202,                 loss: 0.1490
Episode: 2021/30000 (6.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.2213s / 18320.5060 s
agent0:                 episode reward: -0.3199,                 loss: nan
agent1:                 episode reward: 0.3199,                 loss: 0.1494
Episode: 2041/30000 (6.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.5603s / 18564.0663 s
agent0:                 episode reward: 0.1032,                 loss: nan
agent1:                 episode reward: -0.1032,                 loss: 0.1509
Episode: 2061/30000 (6.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 238.3799s / 18802.4461 s
agent0:                 episode reward: 0.0741,                 loss: nan
agent1:                 episode reward: -0.0741,                 loss: 0.1493
Episode: 2081/30000 (6.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.1734s / 19048.6195 s
agent0:                 episode reward: 0.1021,                 loss: nan
agent1:                 episode reward: -0.1021,                 loss: 0.1494
Episode: 2101/30000 (7.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.9851s / 19297.6046 s
agent0:                 episode reward: 0.0936,                 loss: nan
agent1:                 episode reward: -0.0936,                 loss: 0.1500
Episode: 2121/30000 (7.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 238.8057s / 19536.4103 s
agent0:                 episode reward: -0.3939,                 loss: nan
agent1:                 episode reward: 0.3939,                 loss: 0.1492
Episode: 2141/30000 (7.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.7196s / 19785.1300 s
agent0:                 episode reward: 0.0942,                 loss: nan
agent1:                 episode reward: -0.0942,                 loss: 0.1486
Episode: 2161/30000 (7.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.0496s / 20036.1796 s
agent0:                 episode reward: -0.2110,                 loss: nan
agent1:                 episode reward: 0.2110,                 loss: 0.1504
Episode: 2181/30000 (7.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.0912s / 20288.2708 s
agent0:                 episode reward: -0.0757,                 loss: nan
agent1:                 episode reward: 0.0757,                 loss: 0.1487
Episode: 2201/30000 (7.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.7213s / 20536.9922 s
agent0:                 episode reward: -0.3206,                 loss: nan
agent1:                 episode reward: 0.3206,                 loss: 0.1513
Episode: 2221/30000 (7.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.6271s / 20781.6192 s
agent0:                 episode reward: 0.0421,                 loss: nan
agent1:                 episode reward: -0.0421,                 loss: 0.1514
Episode: 2241/30000 (7.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.6651s / 21026.2843 s
agent0:                 episode reward: -0.1178,                 loss: nan
agent1:                 episode reward: 0.1178,                 loss: 0.1521
Episode: 2261/30000 (7.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.2635s / 21274.5477 s
agent0:                 episode reward: 0.1908,                 loss: nan
agent1:                 episode reward: -0.1908,                 loss: 0.1533
Episode: 2281/30000 (7.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 238.1612s / 21512.7089 s
agent0:                 episode reward: -0.0905,                 loss: nan
agent1:                 episode reward: 0.0905,                 loss: 0.1524
Episode: 2301/30000 (7.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.9746s / 21757.6835 s
agent0:                 episode reward: -0.5744,                 loss: nan
agent1:                 episode reward: 0.5744,                 loss: 0.1519
Episode: 2321/30000 (7.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 256.8884s / 22014.5719 s
agent0:                 episode reward: -0.0087,                 loss: nan
agent1:                 episode reward: 0.0087,                 loss: 0.1535
Episode: 2341/30000 (7.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 258.4488s / 22273.0207 s
agent0:                 episode reward: -0.1674,                 loss: nan
agent1:                 episode reward: 0.1674,                 loss: 0.1535
Episode: 2361/30000 (7.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 254.9678s / 22527.9885 s
agent0:                 episode reward: -0.0655,                 loss: nan
agent1:                 episode reward: 0.0655,                 loss: 0.1547
Episode: 2381/30000 (7.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.1193s / 22780.1078 s
agent0:                 episode reward: -0.2932,                 loss: nan
agent1:                 episode reward: 0.2932,                 loss: 0.1531
Episode: 2401/30000 (8.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.0040s / 23022.1117 s
agent0:                 episode reward: 0.1622,                 loss: nan
agent1:                 episode reward: -0.1622,                 loss: 0.1536
Episode: 2421/30000 (8.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.2940s / 23267.4057 s
agent0:                 episode reward: -0.2025,                 loss: nan
agent1:                 episode reward: 0.2025,                 loss: 0.1517
Episode: 2441/30000 (8.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.0664s / 23519.4722 s
agent0:                 episode reward: -0.2021,                 loss: nan
agent1:                 episode reward: 0.2021,                 loss: 0.1519
Episode: 2461/30000 (8.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 237.3942s / 23756.8663 s
agent0:                 episode reward: 0.3882,                 loss: nan
agent1:                 episode reward: -0.3882,                 loss: 0.1527
Episode: 2481/30000 (8.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 240.1814s / 23997.0477 s
agent0:                 episode reward: -0.2395,                 loss: nan
agent1:                 episode reward: 0.2395,                 loss: 0.1526
Episode: 2501/30000 (8.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 238.8811s / 24235.9287 s
agent0:                 episode reward: 0.2673,                 loss: nan
agent1:                 episode reward: -0.2673,                 loss: 0.1521
Episode: 2521/30000 (8.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 239.0847s / 24475.0135 s
agent0:                 episode reward: -0.2770,                 loss: nan
agent1:                 episode reward: 0.2770,                 loss: 0.1535
Episode: 2541/30000 (8.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.5215s / 24716.5350 s
agent0:                 episode reward: 0.0979,                 loss: nan
agent1:                 episode reward: -0.0979,                 loss: 0.1524
Episode: 2561/30000 (8.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.4417s / 24965.9767 s
agent0:                 episode reward: 0.0593,                 loss: nan
agent1:                 episode reward: -0.0593,                 loss: 0.1524
Episode: 2581/30000 (8.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.2351s / 25208.2118 s
agent0:                 episode reward: -0.2362,                 loss: nan
agent1:                 episode reward: 0.2362,                 loss: 0.1544
Episode: 2601/30000 (8.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.6105s / 25454.8222 s
agent0:                 episode reward: -0.1783,                 loss: nan
agent1:                 episode reward: 0.1783,                 loss: 0.1550
Episode: 2621/30000 (8.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 241.9813s / 25696.8035 s
agent0:                 episode reward: -0.1881,                 loss: nan
agent1:                 episode reward: 0.1881,                 loss: 0.1528
Episode: 2641/30000 (8.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.5239s / 25941.3273 s
agent0:                 episode reward: -0.0398,                 loss: nan
agent1:                 episode reward: 0.0398,                 loss: 0.1535
Episode: 2661/30000 (8.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.9312s / 26186.2586 s
agent0:                 episode reward: -0.4287,                 loss: nan
agent1:                 episode reward: 0.4287,                 loss: 0.1539
Episode: 2681/30000 (8.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 238.9486s / 26425.2071 s
agent0:                 episode reward: -0.4271,                 loss: nan
agent1:                 episode reward: 0.4271,                 loss: 0.1534
Episode: 2701/30000 (9.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.8770s / 26671.0842 s
agent0:                 episode reward: -0.2000,                 loss: nan
agent1:                 episode reward: 0.2000,                 loss: 0.1524
Episode: 2721/30000 (9.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.0017s / 26913.0859 s
agent0:                 episode reward: 0.0866,                 loss: nan
agent1:                 episode reward: -0.0866,                 loss: 0.1535
Episode: 2741/30000 (9.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.1403s / 27156.2261 s
agent0:                 episode reward: -0.3407,                 loss: nan
agent1:                 episode reward: 0.3407,                 loss: 0.1538
Episode: 2761/30000 (9.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.6075s / 27405.8337 s
agent0:                 episode reward: -0.2445,                 loss: nan
agent1:                 episode reward: 0.2445,                 loss: 0.1523
Episode: 2781/30000 (9.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.6512s / 27652.4849 s
agent0:                 episode reward: -0.1680,                 loss: nan
agent1:                 episode reward: 0.1680,                 loss: 0.1541
Episode: 2801/30000 (9.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.1446s / 27897.6294 s
agent0:                 episode reward: -0.4449,                 loss: nan
agent1:                 episode reward: 0.4449,                 loss: 0.1540
Episode: 2821/30000 (9.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 239.3710s / 28137.0004 s
agent0:                 episode reward: -0.0978,                 loss: nan
agent1:                 episode reward: 0.0978,                 loss: 0.1530
Episode: 2841/30000 (9.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.9955s / 28379.9960 s
agent0:                 episode reward: -0.3169,                 loss: nan
agent1:                 episode reward: 0.3169,                 loss: 0.1539
Episode: 2861/30000 (9.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.1014s / 28628.0973 s
agent0:                 episode reward: -0.4639,                 loss: nan
agent1:                 episode reward: 0.4639,                 loss: 0.1528
Episode: 2881/30000 (9.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.9562s / 28872.0535 s
agent0:                 episode reward: -0.0879,                 loss: nan
agent1:                 episode reward: 0.0879,                 loss: 0.1533
Episode: 2901/30000 (9.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.8806s / 29116.9341 s
agent0:                 episode reward: 0.0527,                 loss: nan
agent1:                 episode reward: -0.0527,                 loss: 0.1531
Episode: 2921/30000 (9.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.5599s / 29365.4939 s
agent0:                 episode reward: -0.1810,                 loss: nan
agent1:                 episode reward: 0.1810,                 loss: 0.1537
Episode: 2941/30000 (9.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.8410s / 29610.3349 s
agent0:                 episode reward: -0.1351,                 loss: nan
agent1:                 episode reward: 0.1351,                 loss: 0.1530
Episode: 2961/30000 (9.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.6017s / 29853.9366 s
agent0:                 episode reward: -0.3518,                 loss: nan
agent1:                 episode reward: 0.3518,                 loss: 0.1535
Episode: 2981/30000 (9.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 253.9255s / 30107.8621 s
agent0:                 episode reward: 0.0152,                 loss: nan
agent1:                 episode reward: -0.0152,                 loss: 0.1536
Episode: 3001/30000 (10.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.5532s / 30360.4153 s
agent0:                 episode reward: 0.1131,                 loss: nan
agent1:                 episode reward: -0.1131,                 loss: 0.1532
Episode: 3021/30000 (10.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.3314s / 30604.7467 s
agent0:                 episode reward: -0.1132,                 loss: nan
agent1:                 episode reward: 0.1132,                 loss: 0.1526
Episode: 3041/30000 (10.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.6566s / 30852.4034 s
agent0:                 episode reward: -0.0071,                 loss: nan
agent1:                 episode reward: 0.0071,                 loss: 0.1528
Episode: 3061/30000 (10.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.4709s / 31099.8743 s
agent0:                 episode reward: -0.0497,                 loss: nan
agent1:                 episode reward: 0.0497,                 loss: 0.1524
Episode: 3081/30000 (10.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.3921s / 31345.2663 s
agent0:                 episode reward: 0.0064,                 loss: nan
agent1:                 episode reward: -0.0064,                 loss: 0.1531
Episode: 3101/30000 (10.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.1475s / 31594.4139 s
agent0:                 episode reward: -0.1997,                 loss: nan
agent1:                 episode reward: 0.1997,                 loss: 0.1543
Episode: 3121/30000 (10.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 240.9799s / 31835.3938 s
agent0:                 episode reward: -0.3555,                 loss: nan
agent1:                 episode reward: 0.3555,                 loss: 0.1540
Episode: 3141/30000 (10.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.0343s / 32086.4281 s
agent0:                 episode reward: -0.1078,                 loss: nan
agent1:                 episode reward: 0.1078,                 loss: 0.1539
Episode: 3161/30000 (10.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.2833s / 32331.7114 s
agent0:                 episode reward: -0.0955,                 loss: nan
agent1:                 episode reward: 0.0955,                 loss: 0.1522
Episode: 3181/30000 (10.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.7091s / 32574.4205 s
agent0:                 episode reward: 0.0705,                 loss: nan
agent1:                 episode reward: -0.0705,                 loss: 0.1533
Episode: 3201/30000 (10.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.6286s / 32821.0491 s
agent0:                 episode reward: 0.0910,                 loss: nan
agent1:                 episode reward: -0.0910,                 loss: 0.1524
Episode: 3221/30000 (10.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.0644s / 33071.1135 s
agent0:                 episode reward: -0.1799,                 loss: nan
agent1:                 episode reward: 0.1799,                 loss: 0.1521
Episode: 3241/30000 (10.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.8274s / 33313.9409 s
agent0:                 episode reward: -0.1038,                 loss: nan
agent1:                 episode reward: 0.1038,                 loss: 0.1518
Episode: 3261/30000 (10.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.7754s / 33555.7164 s
agent0:                 episode reward: -0.6124,                 loss: nan
agent1:                 episode reward: 0.6124,                 loss: 0.1521
Episode: 3281/30000 (10.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.1204s / 33801.8368 s
agent0:                 episode reward: -0.3364,                 loss: nan
agent1:                 episode reward: 0.3364,                 loss: 0.1527
Episode: 3301/30000 (11.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 231.7635s / 34033.6003 s
agent0:                 episode reward: 0.3191,                 loss: nan
agent1:                 episode reward: -0.3191,                 loss: 0.1524
Episode: 3321/30000 (11.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.3602s / 34277.9605 s
agent0:                 episode reward: -0.2034,                 loss: nan
agent1:                 episode reward: 0.2034,                 loss: 0.1531
Episode: 3341/30000 (11.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.5079s / 34529.4685 s
agent0:                 episode reward: -0.5942,                 loss: nan
agent1:                 episode reward: 0.5942,                 loss: 0.1531
Episode: 3361/30000 (11.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.3290s / 34778.7975 s
agent0:                 episode reward: -0.1131,                 loss: nan
agent1:                 episode reward: 0.1131,                 loss: 0.1520
Episode: 3381/30000 (11.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 240.3442s / 35019.1417 s
agent0:                 episode reward: 0.0327,                 loss: nan
agent1:                 episode reward: -0.0327,                 loss: 0.1533
Episode: 3401/30000 (11.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.3227s / 35268.4644 s
agent0:                 episode reward: 0.0969,                 loss: nan
agent1:                 episode reward: -0.0969,                 loss: 0.1530
Episode: 3421/30000 (11.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.2073s / 35512.6717 s
agent0:                 episode reward: -0.1871,                 loss: nan
agent1:                 episode reward: 0.1871,                 loss: 0.1504
Episode: 3441/30000 (11.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.1512s / 35758.8229 s
agent0:                 episode reward: 0.1287,                 loss: nan
agent1:                 episode reward: -0.1287,                 loss: 0.1528
Episode: 3461/30000 (11.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.3530s / 36001.1759 s
agent0:                 episode reward: -0.2451,                 loss: nan
agent1:                 episode reward: 0.2451,                 loss: 0.1514
Episode: 3481/30000 (11.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.0742s / 36245.2501 s
agent0:                 episode reward: -0.5237,                 loss: nan
agent1:                 episode reward: 0.5237,                 loss: 0.1516
Episode: 3501/30000 (11.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 238.1449s / 36483.3950 s
agent0:                 episode reward: 0.2062,                 loss: nan
agent1:                 episode reward: -0.2062,                 loss: 0.1519
Episode: 3521/30000 (11.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.8469s / 36728.2420 s
agent0:                 episode reward: -0.3306,                 loss: nan
agent1:                 episode reward: 0.3306,                 loss: 0.1517
Episode: 3541/30000 (11.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.0766s / 36975.3185 s
agent0:                 episode reward: -0.5169,                 loss: nan
agent1:                 episode reward: 0.5169,                 loss: 0.1516
Episode: 3561/30000 (11.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.2466s / 37221.5652 s
agent0:                 episode reward: -0.2273,                 loss: nan
agent1:                 episode reward: 0.2273,                 loss: 0.1544
Episode: 3581/30000 (11.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 239.7077s / 37461.2729 s
agent0:                 episode reward: 0.1393,                 loss: nan
agent1:                 episode reward: -0.1393,                 loss: 0.1552
Episode: 3601/30000 (12.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.6974s / 37710.9703 s
agent0:                 episode reward: -0.0121,                 loss: nan
agent1:                 episode reward: 0.0121,                 loss: 0.1544
Episode: 3621/30000 (12.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.6710s / 37956.6413 s
agent0:                 episode reward: 0.0006,                 loss: nan
agent1:                 episode reward: -0.0006,                 loss: 0.1544
Episode: 3641/30000 (12.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.6939s / 38204.3352 s
agent0:                 episode reward: -0.0143,                 loss: nan
agent1:                 episode reward: 0.0143,                 loss: 0.1553
Episode: 3661/30000 (12.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.9838s / 38447.3190 s
agent0:                 episode reward: 0.0959,                 loss: nan
agent1:                 episode reward: -0.0959,                 loss: 0.1540
Episode: 3681/30000 (12.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.5231s / 38695.8421 s
agent0:                 episode reward: 0.1907,                 loss: nan
agent1:                 episode reward: -0.1907,                 loss: 0.1543
Episode: 3701/30000 (12.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.1325s / 38941.9746 s
agent0:                 episode reward: -0.1869,                 loss: nan
agent1:                 episode reward: 0.1869,                 loss: 0.1545
Episode: 3721/30000 (12.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.6003s / 39185.5749 s
agent0:                 episode reward: 0.3083,                 loss: nan
agent1:                 episode reward: -0.3083,                 loss: 0.1536
Episode: 3741/30000 (12.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.6154s / 39436.1902 s
agent0:                 episode reward: -0.0179,                 loss: nan
agent1:                 episode reward: 0.0179,                 loss: 0.1548
Episode: 3761/30000 (12.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 239.5466s / 39675.7368 s
agent0:                 episode reward: -0.0704,                 loss: nan
agent1:                 episode reward: 0.0704,                 loss: 0.1553
Episode: 3781/30000 (12.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.0602s / 39916.7970 s
agent0:                 episode reward: -0.1067,                 loss: nan
agent1:                 episode reward: 0.1067,                 loss: 0.1540
Episode: 3801/30000 (12.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.4111s / 40165.2082 s
agent0:                 episode reward: -0.5895,                 loss: nan
agent1:                 episode reward: 0.5895,                 loss: 0.1549
Episode: 3821/30000 (12.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.0294s / 40415.2376 s
agent0:                 episode reward: -0.0933,                 loss: nan
agent1:                 episode reward: 0.0933,                 loss: 0.1553
Episode: 3841/30000 (12.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.3893s / 40661.6268 s
agent0:                 episode reward: -0.4993,                 loss: nan
agent1:                 episode reward: 0.4993,                 loss: 0.1538
Episode: 3861/30000 (12.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 235.4846s / 40897.1114 s
agent0:                 episode reward: 0.1358,                 loss: nan
agent1:                 episode reward: -0.1358,                 loss: 0.1556
Episode: 3881/30000 (12.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.2670s / 41144.3785 s
agent0:                 episode reward: -0.1140,                 loss: nan
agent1:                 episode reward: 0.1140,                 loss: 0.1544
Episode: 3901/30000 (13.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.6531s / 41387.0316 s
agent0:                 episode reward: -0.3124,                 loss: nan
agent1:                 episode reward: 0.3124,                 loss: 0.1547
Episode: 3921/30000 (13.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.5009s / 41632.5324 s
agent0:                 episode reward: -0.3385,                 loss: nan
agent1:                 episode reward: 0.3385,                 loss: 0.1551
Episode: 3941/30000 (13.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.5868s / 41876.1193 s
agent0:                 episode reward: -0.0550,                 loss: nan
agent1:                 episode reward: 0.0550,                 loss: 0.1562
Episode: 3961/30000 (13.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.5649s / 42119.6842 s
agent0:                 episode reward: -0.2336,                 loss: nan
agent1:                 episode reward: 0.2336,                 loss: 0.1552
Episode: 3981/30000 (13.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.2780s / 42361.9622 s
agent0:                 episode reward: -0.2732,                 loss: nan
agent1:                 episode reward: 0.2732,                 loss: 0.1562
Episode: 4001/30000 (13.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.9309s / 42610.8931 s
agent0:                 episode reward: -0.1032,                 loss: nan
agent1:                 episode reward: 0.1032,                 loss: 0.1533
Episode: 4021/30000 (13.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.6421s / 42853.5352 s
agent0:                 episode reward: -0.1504,                 loss: nan
agent1:                 episode reward: 0.1504,                 loss: 0.1560
Episode: 4041/30000 (13.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.1271s / 43099.6623 s
agent0:                 episode reward: 0.3384,                 loss: nan
agent1:                 episode reward: -0.3384,                 loss: 0.1535
Episode: 4061/30000 (13.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.6539s / 43350.3162 s
agent0:                 episode reward: -0.2814,                 loss: nan
agent1:                 episode reward: 0.2814,                 loss: 0.1545
Episode: 4081/30000 (13.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.4342s / 43595.7504 s
agent0:                 episode reward: -0.1167,                 loss: nan
agent1:                 episode reward: 0.1167,                 loss: 0.1546
Episode: 4101/30000 (13.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 240.9398s / 43836.6901 s
agent0:                 episode reward: 0.0885,                 loss: nan
agent1:                 episode reward: -0.0885,                 loss: 0.1549
Episode: 4121/30000 (13.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 232.7617s / 44069.4518 s
agent0:                 episode reward: -0.3189,                 loss: nan
agent1:                 episode reward: 0.3189,                 loss: 0.1549
Episode: 4141/30000 (13.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.2530s / 44312.7048 s
agent0:                 episode reward: -0.1467,                 loss: nan
agent1:                 episode reward: 0.1467,                 loss: 0.1546
Episode: 4161/30000 (13.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.6016s / 44563.3065 s
agent0:                 episode reward: -0.2935,                 loss: nan
agent1:                 episode reward: 0.2935,                 loss: 0.1538
Episode: 4181/30000 (13.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 254.2454s / 44817.5519 s
agent0:                 episode reward: -0.5523,                 loss: nan
agent1:                 episode reward: 0.5523,                 loss: 0.1530
Episode: 4201/30000 (14.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.6960s / 45064.2479 s
agent0:                 episode reward: -0.0898,                 loss: nan
agent1:                 episode reward: 0.0898,                 loss: 0.1543
Episode: 4221/30000 (14.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.7758s / 45314.0238 s
agent0:                 episode reward: -0.1736,                 loss: nan
agent1:                 episode reward: 0.1736,                 loss: 0.1544
Episode: 4241/30000 (14.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 241.1551s / 45555.1789 s
agent0:                 episode reward: -0.3822,                 loss: nan
agent1:                 episode reward: 0.3822,                 loss: 0.1544
Episode: 4261/30000 (14.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 253.3453s / 45808.5242 s
agent0:                 episode reward: -0.2099,                 loss: nan
agent1:                 episode reward: 0.2099,                 loss: 0.1549
Episode: 4281/30000 (14.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.8739s / 46057.3981 s
agent0:                 episode reward: 0.0344,                 loss: nan
agent1:                 episode reward: -0.0344,                 loss: 0.1547
Episode: 4301/30000 (14.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 239.9173s / 46297.3154 s
agent0:                 episode reward: -0.3662,                 loss: nan
agent1:                 episode reward: 0.3662,                 loss: 0.1544
Episode: 4321/30000 (14.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.4536s / 46544.7690 s
agent0:                 episode reward: -0.0737,                 loss: nan
agent1:                 episode reward: 0.0737,                 loss: 0.1555
Episode: 4341/30000 (14.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.6969s / 46786.4659 s
agent0:                 episode reward: -0.3716,                 loss: nan
agent1:                 episode reward: 0.3716,                 loss: 0.1553
Episode: 4361/30000 (14.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.4250s / 47033.8910 s
agent0:                 episode reward: -0.2827,                 loss: nan
agent1:                 episode reward: 0.2827,                 loss: 0.1538
Episode: 4381/30000 (14.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 236.5529s / 47270.4439 s
agent0:                 episode reward: -0.4953,                 loss: nan
agent1:                 episode reward: 0.4953,                 loss: 0.1537
Episode: 4401/30000 (14.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 239.2108s / 47509.6547 s
agent0:                 episode reward: -0.0069,                 loss: nan
agent1:                 episode reward: 0.0069,                 loss: 0.1533
Episode: 4421/30000 (14.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 255.4173s / 47765.0720 s
agent0:                 episode reward: 0.3405,                 loss: nan
agent1:                 episode reward: -0.3405,                 loss: 0.1547
Episode: 4441/30000 (14.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.2986s / 48010.3706 s
agent0:                 episode reward: 0.2996,                 loss: nan
agent1:                 episode reward: -0.2996,                 loss: 0.1539
Episode: 4461/30000 (14.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.8989s / 48256.2695 s
agent0:                 episode reward: 0.2559,                 loss: nan
agent1:                 episode reward: -0.2559,                 loss: 0.1550
Episode: 4481/30000 (14.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.6787s / 48499.9481 s
agent0:                 episode reward: -0.2794,                 loss: nan
agent1:                 episode reward: 0.2794,                 loss: 0.1559
Episode: 4501/30000 (15.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.0885s / 48747.0366 s
agent0:                 episode reward: -0.5746,                 loss: nan
agent1:                 episode reward: 0.5746,                 loss: 0.1552
Episode: 4521/30000 (15.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.2230s / 48989.2597 s
agent0:                 episode reward: 0.0360,                 loss: nan
agent1:                 episode reward: -0.0360,                 loss: 0.1546
Episode: 4541/30000 (15.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 259.5302s / 49248.7899 s
agent0:                 episode reward: -0.5346,                 loss: nan
agent1:                 episode reward: 0.5346,                 loss: 0.1544
Episode: 4561/30000 (15.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.0883s / 49500.8782 s
agent0:                 episode reward: -0.1321,                 loss: nan
agent1:                 episode reward: 0.1321,                 loss: 0.1546
Episode: 4581/30000 (15.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.4363s / 49749.3145 s
agent0:                 episode reward: -0.0202,                 loss: nan
agent1:                 episode reward: 0.0202,                 loss: 0.1548
Episode: 4601/30000 (15.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.5878s / 49994.9023 s
agent0:                 episode reward: -0.3653,                 loss: nan
agent1:                 episode reward: 0.3653,                 loss: 0.1543
Episode: 4621/30000 (15.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.7966s / 50237.6989 s
agent0:                 episode reward: -0.0989,                 loss: nan
agent1:                 episode reward: 0.0989,                 loss: 0.1542
Episode: 4641/30000 (15.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.9458s / 50482.6447 s
agent0:                 episode reward: -0.2460,                 loss: nan
agent1:                 episode reward: 0.2460,                 loss: 0.1542
Episode: 4661/30000 (15.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.1988s / 50729.8435 s
agent0:                 episode reward: -0.3877,                 loss: nan
agent1:                 episode reward: 0.3877,                 loss: 0.1546
Episode: 4681/30000 (15.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 253.7585s / 50983.6020 s
agent0:                 episode reward: -0.3777,                 loss: nan
agent1:                 episode reward: 0.3777,                 loss: 0.1548
Episode: 4701/30000 (15.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.3816s / 51224.9835 s
agent0:                 episode reward: -0.4125,                 loss: nan
agent1:                 episode reward: 0.4125,                 loss: 0.1547
Episode: 4721/30000 (15.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.5401s / 51476.5236 s
agent0:                 episode reward: 0.0180,                 loss: nan
agent1:                 episode reward: -0.0180,                 loss: 0.1531
Episode: 4741/30000 (15.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 240.9296s / 51717.4532 s
agent0:                 episode reward: -0.2223,                 loss: nan
agent1:                 episode reward: 0.2223,                 loss: 0.1536
Episode: 4761/30000 (15.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.7152s / 51965.1685 s
agent0:                 episode reward: -0.1490,                 loss: nan
agent1:                 episode reward: 0.1490,                 loss: 0.1527
Episode: 4781/30000 (15.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 253.2052s / 52218.3736 s
agent0:                 episode reward: -0.4650,                 loss: nan
agent1:                 episode reward: 0.4650,                 loss: 0.1535
Episode: 4801/30000 (16.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.5857s / 52461.9594 s
agent0:                 episode reward: -0.2010,                 loss: nan
agent1:                 episode reward: 0.2010,                 loss: 0.1544
Episode: 4821/30000 (16.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.9146s / 52709.8740 s
agent0:                 episode reward: -0.1886,                 loss: nan
agent1:                 episode reward: 0.1886,                 loss: 0.1530
Episode: 4841/30000 (16.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.9409s / 52956.8148 s
agent0:                 episode reward: 0.0318,                 loss: nan
agent1:                 episode reward: -0.0318,                 loss: 0.1546
Episode: 4861/30000 (16.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.4982s / 53206.3130 s
agent0:                 episode reward: 0.0893,                 loss: nan
agent1:                 episode reward: -0.0893,                 loss: 0.1537
Episode: 4881/30000 (16.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.5411s / 53454.8541 s
agent0:                 episode reward: -0.2086,                 loss: nan
agent1:                 episode reward: 0.2086,                 loss: 0.1549
Episode: 4901/30000 (16.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 239.5800s / 53694.4341 s
agent0:                 episode reward: -0.0378,                 loss: nan
agent1:                 episode reward: 0.0378,                 loss: 0.1581
Episode: 4921/30000 (16.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.5650s / 53944.9990 s
agent0:                 episode reward: 0.2427,                 loss: nan
agent1:                 episode reward: -0.2427,                 loss: 0.1595
Episode: 4941/30000 (16.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 239.9289s / 54184.9279 s
agent0:                 episode reward: -0.2897,                 loss: nan
agent1:                 episode reward: 0.2897,                 loss: 0.1591
Episode: 4961/30000 (16.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.8331s / 54431.7610 s
agent0:                 episode reward: -0.2856,                 loss: nan
agent1:                 episode reward: 0.2856,                 loss: 0.1581
Episode: 4981/30000 (16.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.0271s / 54674.7882 s
agent0:                 episode reward: -0.4433,                 loss: nan
agent1:                 episode reward: 0.4433,                 loss: 0.1585
Episode: 5001/30000 (16.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.3937s / 54923.1819 s
agent0:                 episode reward: -0.1541,                 loss: nan
agent1:                 episode reward: 0.1541,                 loss: 0.1579
Episode: 5021/30000 (16.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.9632s / 55173.1451 s
agent0:                 episode reward: -0.2691,                 loss: nan
agent1:                 episode reward: 0.2691,                 loss: 0.1594
Episode: 5041/30000 (16.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.0554s / 55422.2005 s
agent0:                 episode reward: -0.3726,                 loss: nan
agent1:                 episode reward: 0.3726,                 loss: 0.1580
Episode: 5061/30000 (16.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.3700s / 55665.5705 s
agent0:                 episode reward: -0.2507,                 loss: nan
agent1:                 episode reward: 0.2507,                 loss: 0.1591
Episode: 5081/30000 (16.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 235.4499s / 55901.0204 s
agent0:                 episode reward: -0.1944,                 loss: nan
agent1:                 episode reward: 0.1944,                 loss: 0.1582
Episode: 5101/30000 (17.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.0338s / 56146.0542 s
agent0:                 episode reward: -0.3832,                 loss: nan
agent1:                 episode reward: 0.3832,                 loss: 0.1591
Episode: 5121/30000 (17.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.1369s / 56388.1912 s
agent0:                 episode reward: -0.2660,                 loss: nan
agent1:                 episode reward: 0.2660,                 loss: 0.1579
Episode: 5141/30000 (17.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 239.3711s / 56627.5623 s
agent0:                 episode reward: -0.2438,                 loss: nan
agent1:                 episode reward: 0.2438,                 loss: 0.1580
Episode: 5161/30000 (17.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.0558s / 56873.6181 s
agent0:                 episode reward: -0.4857,                 loss: nan
agent1:                 episode reward: 0.4857,                 loss: 0.1595
Episode: 5181/30000 (17.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.6524s / 57121.2704 s
agent0:                 episode reward: -0.5036,                 loss: nan
agent1:                 episode reward: 0.5036,                 loss: 0.1582
Episode: 5201/30000 (17.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.9987s / 57366.2691 s
agent0:                 episode reward: -0.2075,                 loss: nan
agent1:                 episode reward: 0.2075,                 loss: 0.1585
Episode: 5221/30000 (17.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.3164s / 57613.5855 s
agent0:                 episode reward: -0.0736,                 loss: nan
agent1:                 episode reward: 0.0736,                 loss: 0.1585
Episode: 5241/30000 (17.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.2933s / 57865.8788 s
agent0:                 episode reward: -0.5485,                 loss: nan
agent1:                 episode reward: 0.5485,                 loss: 0.1558
Episode: 5261/30000 (17.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.1594s / 58111.0382 s
agent0:                 episode reward: 0.0984,                 loss: nan
agent1:                 episode reward: -0.0984,                 loss: 0.1569
Episode: 5281/30000 (17.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.8304s / 58359.8686 s
agent0:                 episode reward: 0.1733,                 loss: nan
agent1:                 episode reward: -0.1733,                 loss: 0.1563
Episode: 5301/30000 (17.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.4622s / 58603.3308 s
agent0:                 episode reward: -0.0732,                 loss: nan
agent1:                 episode reward: 0.0732,                 loss: 0.1556
Episode: 5321/30000 (17.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 253.5487s / 58856.8795 s
agent0:                 episode reward: -0.0184,                 loss: nan
agent1:                 episode reward: 0.0184,                 loss: 0.1578
Episode: 5341/30000 (17.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 235.7238s / 59092.6033 s
agent0:                 episode reward: -0.4344,                 loss: nan
agent1:                 episode reward: 0.4344,                 loss: 0.1593
Episode: 5361/30000 (17.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.2907s / 59340.8939 s
agent0:                 episode reward: 0.3402,                 loss: nan
agent1:                 episode reward: -0.3402,                 loss: 0.1575
Episode: 5381/30000 (17.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 239.8141s / 59580.7081 s
agent0:                 episode reward: -0.0589,                 loss: nan
agent1:                 episode reward: 0.0589,                 loss: 0.1565
Episode: 5401/30000 (18.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.9029s / 59827.6110 s
agent0:                 episode reward: -0.1789,                 loss: nan
agent1:                 episode reward: 0.1789,                 loss: 0.1570
Episode: 5421/30000 (18.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 253.0470s / 60080.6580 s
agent0:                 episode reward: -0.1015,                 loss: nan
agent1:                 episode reward: 0.1015,                 loss: 0.1572
Episode: 5441/30000 (18.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 255.7276s / 60336.3856 s
agent0:                 episode reward: -0.4273,                 loss: nan
agent1:                 episode reward: 0.4273,                 loss: 0.1577
Episode: 5461/30000 (18.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 240.7674s / 60577.1530 s
agent0:                 episode reward: -0.1892,                 loss: nan
agent1:                 episode reward: 0.1892,                 loss: 0.1556
Episode: 5481/30000 (18.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.0323s / 60829.1852 s
agent0:                 episode reward: -0.2223,                 loss: nan
agent1:                 episode reward: 0.2223,                 loss: 0.1571
Episode: 5501/30000 (18.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.2542s / 61075.4395 s
agent0:                 episode reward: -0.1390,                 loss: nan
agent1:                 episode reward: 0.1390,                 loss: 0.1579
Episode: 5521/30000 (18.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 240.4858s / 61315.9252 s
agent0:                 episode reward: -0.2820,                 loss: nan
agent1:                 episode reward: 0.2820,                 loss: 0.1581
Episode: 5541/30000 (18.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.2133s / 61560.1385 s
agent0:                 episode reward: 0.0446,                 loss: nan
agent1:                 episode reward: -0.0446,                 loss: 0.1570
Episode: 5561/30000 (18.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 235.5557s / 61795.6942 s
agent0:                 episode reward: 0.0333,                 loss: nan
agent1:                 episode reward: -0.0333,                 loss: 0.1567
Episode: 5581/30000 (18.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.6174s / 62042.3117 s
agent0:                 episode reward: -0.0281,                 loss: nan
agent1:                 episode reward: 0.0281,                 loss: 0.1593
Episode: 5601/30000 (18.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 236.9381s / 62279.2497 s
agent0:                 episode reward: -0.3856,                 loss: nan
agent1:                 episode reward: 0.3856,                 loss: 0.1575
Episode: 5621/30000 (18.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.5936s / 62526.8433 s
agent0:                 episode reward: -0.3846,                 loss: nan
agent1:                 episode reward: 0.3846,                 loss: 0.1583
Episode: 5641/30000 (18.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.5978s / 62769.4411 s
agent0:                 episode reward: -0.2258,                 loss: nan
agent1:                 episode reward: 0.2258,                 loss: 0.1594
Episode: 5661/30000 (18.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.2502s / 63014.6913 s
agent0:                 episode reward: -0.2496,                 loss: nan
agent1:                 episode reward: 0.2496,                 loss: 0.1560
Episode: 5681/30000 (18.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 237.3010s / 63251.9923 s
agent0:                 episode reward: -0.3234,                 loss: nan
agent1:                 episode reward: 0.3234,                 loss: 0.1584
Episode: 5701/30000 (19.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 253.4187s / 63505.4110 s
agent0:                 episode reward: -0.1969,                 loss: nan
agent1:                 episode reward: 0.1969,                 loss: 0.1570
Episode: 5721/30000 (19.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.3821s / 63754.7931 s
agent0:                 episode reward: -0.2577,                 loss: nan
agent1:                 episode reward: 0.2577,                 loss: 0.1580
Episode: 5741/30000 (19.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 238.0892s / 63992.8823 s
agent0:                 episode reward: 0.2009,                 loss: nan
agent1:                 episode reward: -0.2009,                 loss: 0.1584
Episode: 5761/30000 (19.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 254.9382s / 64247.8204 s
agent0:                 episode reward: -0.2723,                 loss: nan
agent1:                 episode reward: 0.2723,                 loss: 0.1581
Episode: 5781/30000 (19.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 240.3930s / 64488.2135 s
agent0:                 episode reward: -0.1256,                 loss: nan
agent1:                 episode reward: 0.1256,                 loss: 0.1575
Episode: 5801/30000 (19.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.5446s / 64730.7581 s
agent0:                 episode reward: -0.1534,                 loss: nan
agent1:                 episode reward: 0.1534,                 loss: 0.1593
Episode: 5821/30000 (19.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.4802s / 64973.2383 s
agent0:                 episode reward: -0.2751,                 loss: nan
agent1:                 episode reward: 0.2751,                 loss: 0.1598
Episode: 5841/30000 (19.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.5811s / 65214.8194 s
agent0:                 episode reward: -0.1513,                 loss: nan
agent1:                 episode reward: 0.1513,                 loss: 0.1583
Episode: 5861/30000 (19.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.5697s / 65467.3891 s
agent0:                 episode reward: -0.2143,                 loss: nan
agent1:                 episode reward: 0.2143,                 loss: 0.1577
Episode: 5881/30000 (19.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 253.8698s / 65721.2589 s
agent0:                 episode reward: 0.2495,                 loss: nan
agent1:                 episode reward: -0.2495,                 loss: 0.1580
Episode: 5901/30000 (19.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.1854s / 65963.4444 s
agent0:                 episode reward: -0.0289,                 loss: nan
agent1:                 episode reward: 0.0289,                 loss: 0.1560
Episode: 5921/30000 (19.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.7849s / 66209.2293 s
agent0:                 episode reward: -0.3614,                 loss: nan
agent1:                 episode reward: 0.3614,                 loss: 0.1551
Episode: 5941/30000 (19.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 254.2672s / 66463.4965 s
agent0:                 episode reward: -0.3243,                 loss: nan
agent1:                 episode reward: 0.3243,                 loss: 0.1554
Episode: 5961/30000 (19.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.8718s / 66715.3683 s
agent0:                 episode reward: -0.1802,                 loss: nan
agent1:                 episode reward: 0.1802,                 loss: 0.1561
Episode: 5981/30000 (19.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 238.9625s / 66954.3308 s
agent0:                 episode reward: -0.2413,                 loss: nan
agent1:                 episode reward: 0.2413,                 loss: 0.1553
Episode: 6001/30000 (20.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 240.5236s / 67194.8545 s
agent0:                 episode reward: -0.1382,                 loss: nan
agent1:                 episode reward: 0.1382,                 loss: 0.1544
Episode: 6021/30000 (20.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.5992s / 67443.4537 s
agent0:                 episode reward: 0.0326,                 loss: nan
agent1:                 episode reward: -0.0326,                 loss: 0.1563
Episode: 6041/30000 (20.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.7657s / 67690.2193 s
agent0:                 episode reward: -0.1749,                 loss: nan
agent1:                 episode reward: 0.1749,                 loss: 0.1566
Episode: 6061/30000 (20.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 238.1004s / 67928.3197 s
agent0:                 episode reward: 0.0978,                 loss: nan
agent1:                 episode reward: -0.0978,                 loss: 0.1548
Episode: 6081/30000 (20.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 253.9892s / 68182.3089 s
agent0:                 episode reward: -0.2786,                 loss: nan
agent1:                 episode reward: 0.2786,                 loss: 0.1561
Episode: 6101/30000 (20.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 253.7268s / 68436.0358 s
agent0:                 episode reward: 0.0650,                 loss: nan
agent1:                 episode reward: -0.0650,                 loss: 0.1551
Episode: 6121/30000 (20.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.2492s / 68681.2849 s
agent0:                 episode reward: -0.1978,                 loss: nan
agent1:                 episode reward: 0.1978,                 loss: 0.1565
Episode: 6141/30000 (20.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.6638s / 68929.9487 s
agent0:                 episode reward: 0.0387,                 loss: nan
agent1:                 episode reward: -0.0387,                 loss: 0.1553
Episode: 6161/30000 (20.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.2449s / 69177.1936 s
agent0:                 episode reward: 0.3184,                 loss: nan
agent1:                 episode reward: -0.3184,                 loss: 0.1560
Episode: 6181/30000 (20.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.5826s / 69424.7762 s
agent0:                 episode reward: -0.4187,                 loss: nan
agent1:                 episode reward: 0.4187,                 loss: 0.1566
Episode: 6201/30000 (20.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 253.6352s / 69678.4113 s
agent0:                 episode reward: 0.1396,                 loss: nan
agent1:                 episode reward: -0.1396,                 loss: 0.1575
Episode: 6221/30000 (20.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.3578s / 69924.7691 s
agent0:                 episode reward: -0.2736,                 loss: nan
agent1:                 episode reward: 0.2736,                 loss: 0.1572
Episode: 6241/30000 (20.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 239.8649s / 70164.6340 s
agent0:                 episode reward: -0.0671,                 loss: nan
agent1:                 episode reward: 0.0671,                 loss: 0.1576
Episode: 6261/30000 (20.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.9497s / 70417.5837 s
agent0:                 episode reward: -0.2169,                 loss: nan
agent1:                 episode reward: 0.2169,                 loss: 0.1589
Episode: 6281/30000 (20.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.7247s / 70668.3085 s
agent0:                 episode reward: -0.7639,                 loss: nan
agent1:                 episode reward: 0.7639,                 loss: 0.1563
Episode: 6301/30000 (21.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.0295s / 70913.3379 s
agent0:                 episode reward: -0.5711,                 loss: nan
agent1:                 episode reward: 0.5711,                 loss: 0.1571
Episode: 6321/30000 (21.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 253.0744s / 71166.4124 s
agent0:                 episode reward: -0.0468,                 loss: nan
agent1:                 episode reward: 0.0468,                 loss: 0.1563
Episode: 6341/30000 (21.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.3039s / 71418.7163 s
agent0:                 episode reward: -0.0814,                 loss: nan
agent1:                 episode reward: 0.0814,                 loss: 0.1582
Episode: 6361/30000 (21.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.9565s / 71664.6728 s
agent0:                 episode reward: -0.0274,                 loss: nan
agent1:                 episode reward: 0.0274,                 loss: 0.1569
Episode: 6381/30000 (21.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.9676s / 71914.6403 s
agent0:                 episode reward: -0.2912,                 loss: nan
agent1:                 episode reward: 0.2912,                 loss: 0.1585
Episode: 6401/30000 (21.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.3588s / 72164.9991 s
agent0:                 episode reward: -0.2594,                 loss: nan
agent1:                 episode reward: 0.2594,                 loss: 0.1576
Episode: 6421/30000 (21.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.6072s / 72417.6063 s
agent0:                 episode reward: -0.2756,                 loss: nan
agent1:                 episode reward: 0.2756,                 loss: 0.1566
Episode: 6441/30000 (21.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 264.4216s / 72682.0279 s
agent0:                 episode reward: -0.0771,                 loss: nan
agent1:                 episode reward: 0.0771,                 loss: 0.1580
Episode: 6461/30000 (21.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.6413s / 72931.6692 s
agent0:                 episode reward: 0.2019,                 loss: nan
agent1:                 episode reward: -0.2019,                 loss: 0.1592
Episode: 6481/30000 (21.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.9201s / 73173.5893 s
agent0:                 episode reward: -0.1837,                 loss: nan
agent1:                 episode reward: 0.1837,                 loss: 0.1600
Episode: 6501/30000 (21.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 238.5117s / 73412.1010 s
agent0:                 episode reward: -0.6313,                 loss: nan
agent1:                 episode reward: 0.6313,                 loss: 0.1590
Episode: 6521/30000 (21.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.3899s / 73663.4909 s
agent0:                 episode reward: -0.1079,                 loss: nan
agent1:                 episode reward: 0.1079,                 loss: 0.1570
Episode: 6541/30000 (21.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.1241s / 73914.6149 s
agent0:                 episode reward: -0.2125,                 loss: nan
agent1:                 episode reward: 0.2125,                 loss: 0.1561
Episode: 6561/30000 (21.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.5482s / 74157.1632 s
agent0:                 episode reward: -0.3908,                 loss: nan
agent1:                 episode reward: 0.3908,                 loss: 0.1581
Episode: 6581/30000 (21.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.0450s / 74409.2082 s
agent0:                 episode reward: -0.2987,                 loss: nan
agent1:                 episode reward: 0.2987,                 loss: 0.1592
Episode: 6601/30000 (22.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.5211s / 74657.7292 s
agent0:                 episode reward: -0.4578,                 loss: nan
agent1:                 episode reward: 0.4578,                 loss: 0.1583
Episode: 6621/30000 (22.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.3099s / 74905.0391 s
agent0:                 episode reward: -0.2189,                 loss: nan
agent1:                 episode reward: 0.2189,                 loss: 0.1583
Episode: 6641/30000 (22.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 255.3015s / 75160.3406 s
agent0:                 episode reward: -0.0560,                 loss: nan
agent1:                 episode reward: 0.0560,                 loss: 0.1586
Episode: 6661/30000 (22.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.0897s / 75411.4303 s
agent0:                 episode reward: -0.4845,                 loss: nan
agent1:                 episode reward: 0.4845,                 loss: 0.1579
Episode: 6681/30000 (22.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 254.4168s / 75665.8471 s
agent0:                 episode reward: 0.0183,                 loss: nan
agent1:                 episode reward: -0.0183,                 loss: 0.1587
Episode: 6701/30000 (22.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.3385s / 75909.1856 s
agent0:                 episode reward: -0.1812,                 loss: nan
agent1:                 episode reward: 0.1812,                 loss: 0.1580
Episode: 6721/30000 (22.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.9705s / 76157.1561 s
agent0:                 episode reward: -0.7082,                 loss: nan
agent1:                 episode reward: 0.7082,                 loss: 0.1577
Episode: 6741/30000 (22.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.9342s / 76405.0903 s
agent0:                 episode reward: -0.0971,                 loss: nan
agent1:                 episode reward: 0.0971,                 loss: 0.1589
Episode: 6761/30000 (22.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.8536s / 76657.9439 s
agent0:                 episode reward: -0.5837,                 loss: nan
agent1:                 episode reward: 0.5837,                 loss: 0.1563
Episode: 6781/30000 (22.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 232.7472s / 76890.6911 s
agent0:                 episode reward: -0.0150,                 loss: nan
agent1:                 episode reward: 0.0150,                 loss: 0.1581
Episode: 6801/30000 (22.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 240.7638s / 77131.4549 s
agent0:                 episode reward: -0.4376,                 loss: nan
agent1:                 episode reward: 0.4376,                 loss: 0.1585
Episode: 6821/30000 (22.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 254.9817s / 77386.4366 s
agent0:                 episode reward: -0.0936,                 loss: nan
agent1:                 episode reward: 0.0936,                 loss: 0.1580
Episode: 6841/30000 (22.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.8265s / 77633.2631 s
agent0:                 episode reward: -0.1251,                 loss: nan
agent1:                 episode reward: 0.1251,                 loss: 0.1580
Episode: 6861/30000 (22.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.3057s / 77883.5688 s
agent0:                 episode reward: 0.0793,                 loss: nan
agent1:                 episode reward: -0.0793,                 loss: 0.1596
Episode: 6881/30000 (22.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 253.9312s / 78137.5000 s
agent0:                 episode reward: -0.5231,                 loss: nan
agent1:                 episode reward: 0.5231,                 loss: 0.1582
Episode: 6901/30000 (23.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 259.9054s / 78397.4054 s
agent0:                 episode reward: -0.0171,                 loss: nan
agent1:                 episode reward: 0.0171,                 loss: 0.1570
Episode: 6921/30000 (23.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.7980s / 78646.2034 s
agent0:                 episode reward: -0.2856,                 loss: nan
agent1:                 episode reward: 0.2856,                 loss: 0.1557
Episode: 6941/30000 (23.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.1523s / 78892.3558 s
agent0:                 episode reward: -0.1454,                 loss: nan
agent1:                 episode reward: 0.1454,                 loss: 0.1572
Episode: 6961/30000 (23.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.3312s / 79138.6870 s
agent0:                 episode reward: -0.7285,                 loss: nan
agent1:                 episode reward: 0.7285,                 loss: 0.1587
Episode: 6981/30000 (23.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 240.8517s / 79379.5386 s
agent0:                 episode reward: 0.1319,                 loss: nan
agent1:                 episode reward: -0.1319,                 loss: 0.1585
Episode: 7001/30000 (23.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 255.6437s / 79635.1823 s
agent0:                 episode reward: -0.2006,                 loss: nan
agent1:                 episode reward: 0.2006,                 loss: 0.1577
Episode: 7021/30000 (23.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.0507s / 79879.2330 s
agent0:                 episode reward: -0.2405,                 loss: nan
agent1:                 episode reward: 0.2405,                 loss: 0.1560
Episode: 7041/30000 (23.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.3506s / 80131.5836 s
agent0:                 episode reward: -0.0887,                 loss: nan
agent1:                 episode reward: 0.0887,                 loss: 0.1596
Episode: 7061/30000 (23.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.6006s / 80379.1843 s
agent0:                 episode reward: 0.1223,                 loss: nan
agent1:                 episode reward: -0.1223,                 loss: 0.1568
Episode: 7081/30000 (23.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.3212s / 80624.5055 s
agent0:                 episode reward: 0.2895,                 loss: nan
agent1:                 episode reward: -0.2895,                 loss: 0.1569
Episode: 7101/30000 (23.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.8236s / 80875.3291 s
agent0:                 episode reward: -0.3687,                 loss: nan
agent1:                 episode reward: 0.3687,                 loss: 0.1576
Episode: 7121/30000 (23.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.0029s / 81124.3320 s
agent0:                 episode reward: -0.1184,                 loss: nan
agent1:                 episode reward: 0.1184,                 loss: 0.1583
Episode: 7141/30000 (23.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.1725s / 81374.5044 s
agent0:                 episode reward: -0.3669,                 loss: nan
agent1:                 episode reward: 0.3669,                 loss: 0.1590
Episode: 7161/30000 (23.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.4555s / 81618.9599 s
agent0:                 episode reward: -0.3201,                 loss: nan
agent1:                 episode reward: 0.3201,                 loss: 0.1588
Episode: 7181/30000 (23.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 257.5152s / 81876.4751 s
agent0:                 episode reward: -0.0258,                 loss: nan
agent1:                 episode reward: 0.0258,                 loss: 0.1580
Episode: 7201/30000 (24.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 233.9647s / 82110.4398 s
agent0:                 episode reward: -0.4348,                 loss: nan
agent1:                 episode reward: 0.4348,                 loss: 0.1568
Episode: 7221/30000 (24.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 258.2212s / 82368.6610 s
agent0:                 episode reward: -0.3603,                 loss: nan
agent1:                 episode reward: 0.3603,                 loss: 0.1569
Episode: 7241/30000 (24.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.4760s / 82617.1370 s
agent0:                 episode reward: -0.0791,                 loss: nan
agent1:                 episode reward: 0.0791,                 loss: 0.1586
Episode: 7261/30000 (24.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.6794s / 82858.8164 s
agent0:                 episode reward: -0.4495,                 loss: nan
agent1:                 episode reward: 0.4495,                 loss: 0.1584
Episode: 7281/30000 (24.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 254.6536s / 83113.4700 s
agent0:                 episode reward: -0.2022,                 loss: nan
agent1:                 episode reward: 0.2022,                 loss: 0.1569
Episode: 7301/30000 (24.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.5444s / 83361.0144 s
agent0:                 episode reward: -0.0609,                 loss: nan
agent1:                 episode reward: 0.0609,                 loss: 0.1585
Episode: 7321/30000 (24.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.7186s / 83605.7330 s
agent0:                 episode reward: -0.1803,                 loss: nan
agent1:                 episode reward: 0.1803,                 loss: 0.1569
Episode: 7341/30000 (24.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 255.3297s / 83861.0627 s
agent0:                 episode reward: -0.5545,                 loss: nan
agent1:                 episode reward: 0.5545,                 loss: 0.1570
Episode: 7361/30000 (24.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.1947s / 84111.2574 s
agent0:                 episode reward: -0.3234,                 loss: nan
agent1:                 episode reward: 0.3234,                 loss: 0.1581
Episode: 7381/30000 (24.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.5432s / 84359.8006 s
agent0:                 episode reward: 0.0351,                 loss: nan
agent1:                 episode reward: -0.0351,                 loss: 0.1595
Episode: 7401/30000 (24.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.3116s / 84602.1122 s
agent0:                 episode reward: -0.5087,                 loss: nan
agent1:                 episode reward: 0.5087,                 loss: 0.1582
Episode: 7421/30000 (24.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.2787s / 84851.3909 s
agent0:                 episode reward: -0.2811,                 loss: nan
agent1:                 episode reward: 0.2811,                 loss: 0.1588
Episode: 7441/30000 (24.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.5481s / 85097.9390 s
agent0:                 episode reward: 0.1384,                 loss: nan
agent1:                 episode reward: -0.1384,                 loss: 0.1577
Episode: 7461/30000 (24.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 238.6048s / 85336.5438 s
agent0:                 episode reward: -0.1029,                 loss: nan
agent1:                 episode reward: 0.1029,                 loss: 0.1592
Episode: 7481/30000 (24.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.5546s / 85585.0984 s
agent0:                 episode reward: -0.4360,                 loss: nan
agent1:                 episode reward: 0.4360,                 loss: 0.1579
Episode: 7501/30000 (25.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.0053s / 85835.1036 s
agent0:                 episode reward: -0.2167,                 loss: nan
agent1:                 episode reward: 0.2167,                 loss: 0.1588
Episode: 7521/30000 (25.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.6674s / 86076.7710 s
agent0:                 episode reward: -0.2174,                 loss: nan
agent1:                 episode reward: 0.2174,                 loss: 0.1591
Episode: 7541/30000 (25.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.0879s / 86323.8589 s
agent0:                 episode reward: 0.0220,                 loss: nan
agent1:                 episode reward: -0.0220,                 loss: 0.1575
Episode: 7561/30000 (25.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 256.0801s / 86579.9390 s
agent0:                 episode reward: -0.1572,                 loss: nan
agent1:                 episode reward: 0.1572,                 loss: 0.1584
Episode: 7581/30000 (25.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 256.7553s / 86836.6943 s
agent0:                 episode reward: -0.3432,                 loss: nan
agent1:                 episode reward: 0.3432,                 loss: 0.1567
Episode: 7601/30000 (25.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 256.7692s / 87093.4635 s
agent0:                 episode reward: -0.0949,                 loss: nan
agent1:                 episode reward: 0.0949,                 loss: 0.1560
Episode: 7621/30000 (25.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.7925s / 87337.2560 s
agent0:                 episode reward: 0.0291,                 loss: nan
agent1:                 episode reward: -0.0291,                 loss: 0.1571
Episode: 7641/30000 (25.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 262.2283s / 87599.4843 s
agent0:                 episode reward: -0.4696,                 loss: nan
agent1:                 episode reward: 0.4696,                 loss: 0.1574
Episode: 7661/30000 (25.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.7525s / 87843.2368 s
agent0:                 episode reward: -0.3411,                 loss: nan
agent1:                 episode reward: 0.3411,                 loss: 0.1579
Episode: 7681/30000 (25.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.7383s / 88094.9751 s
agent0:                 episode reward: -0.3394,                 loss: nan
agent1:                 episode reward: 0.3394,                 loss: 0.1568
Episode: 7701/30000 (25.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.9403s / 88344.9155 s
agent0:                 episode reward: -0.3970,                 loss: nan
agent1:                 episode reward: 0.3970,                 loss: 0.1567
Episode: 7721/30000 (25.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 253.2040s / 88598.1195 s
agent0:                 episode reward: -0.1697,                 loss: nan
agent1:                 episode reward: 0.1697,                 loss: 0.1575
Episode: 7741/30000 (25.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.7767s / 88848.8962 s
agent0:                 episode reward: -0.2521,                 loss: nan
agent1:                 episode reward: 0.2521,                 loss: 0.1572
Episode: 7761/30000 (25.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 255.1269s / 89104.0231 s
agent0:                 episode reward: -0.3188,                 loss: nan
agent1:                 episode reward: 0.3188,                 loss: 0.1569
Episode: 7781/30000 (25.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.0760s / 89349.0991 s
agent0:                 episode reward: -0.2914,                 loss: nan
agent1:                 episode reward: 0.2914,                 loss: 0.1572
Episode: 7801/30000 (26.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 254.7807s / 89603.8798 s
agent0:                 episode reward: 0.1798,                 loss: nan
agent1:                 episode reward: -0.1798,                 loss: 0.1580
Episode: 7821/30000 (26.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.6102s / 89849.4901 s
agent0:                 episode reward: -0.2208,                 loss: nan
agent1:                 episode reward: 0.2208,                 loss: 0.1559
Episode: 7841/30000 (26.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.7187s / 90098.2088 s
agent0:                 episode reward: -0.2951,                 loss: nan
agent1:                 episode reward: 0.2951,                 loss: 0.1568
Episode: 7861/30000 (26.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.0397s / 90348.2485 s
agent0:                 episode reward: -0.3972,                 loss: nan
agent1:                 episode reward: 0.3972,                 loss: 0.1570
Episode: 7881/30000 (26.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.8734s / 90596.1220 s
agent0:                 episode reward: 0.3404,                 loss: nan
agent1:                 episode reward: -0.3404,                 loss: 0.1562
Episode: 7901/30000 (26.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.1062s / 90839.2281 s
agent0:                 episode reward: -0.1976,                 loss: nan
agent1:                 episode reward: 0.1976,                 loss: 0.1561
Episode: 7921/30000 (26.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.8111s / 91092.0393 s
agent0:                 episode reward: -0.4263,                 loss: nan
agent1:                 episode reward: 0.4263,                 loss: 0.1564
Episode: 7941/30000 (26.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.4205s / 91335.4598 s
agent0:                 episode reward: -0.1571,                 loss: nan
agent1:                 episode reward: 0.1571,                 loss: 0.1572
Episode: 7961/30000 (26.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 259.4811s / 91594.9408 s
agent0:                 episode reward: -0.1192,                 loss: nan
agent1:                 episode reward: 0.1192,                 loss: 0.1568
Episode: 7981/30000 (26.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.4142s / 91846.3550 s