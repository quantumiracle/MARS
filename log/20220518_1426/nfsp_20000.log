pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 12.0, (1,), float32) action space: Discrete(3)
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7f2420e4dc88>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
Error: no exploited model index given!
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  data/model/20220518033032/mdp_arbitrary_mdp_nfsp/20000_0
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': '1i', 'algorithm': 'NFSP', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.0, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 640, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 10000, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220518033032/mdp_arbitrary_mdp_nfsp/20000_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False, 'policy': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': 'Softmax'}}, 'marl_method': 'nfsp', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'eta': 0.1}, 'against_baseline': False}
Save models to : /home/zihan/research/MARS/data/model/20220518033032_exploit_20000/mdp_arbitrary_mdp_nfsp. 
 Save logs to: /home/zihan/research/MARS/data/log/20220518033032_exploit_20000/mdp_arbitrary_mdp_nfsp.
Episode: 1/30000 (0.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6048s / 0.6048 s
agent0:                 episode reward: -1.2083,                 loss: nan
agent1:                 episode reward: 1.2083,                 loss: nan
Episode: 21/30000 (0.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0770s / 0.6819 s
agent0:                 episode reward: 0.2218,                 loss: nan
agent1:                 episode reward: -0.2218,                 loss: nan
Episode: 41/30000 (0.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0735s / 0.7554 s
agent0:                 episode reward: 0.3444,                 loss: nan
agent1:                 episode reward: -0.3444,                 loss: nan
Episode: 61/30000 (0.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0748s / 0.8301 s
agent0:                 episode reward: 0.6733,                 loss: nan
agent1:                 episode reward: -0.6733,                 loss: nan
Episode: 81/30000 (0.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0764s / 0.9065 s
agent0:                 episode reward: 0.3650,                 loss: nan
agent1:                 episode reward: -0.3650,                 loss: nan
Episode: 101/30000 (0.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0723s / 0.9788 s
agent0:                 episode reward: 0.3405,                 loss: nan
agent1:                 episode reward: -0.3405,                 loss: nan
Episode: 121/30000 (0.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1844s / 1.1632 s
agent0:                 episode reward: 0.3658,                 loss: nan
agent1:                 episode reward: -0.3658,                 loss: nan
Episode: 141/30000 (0.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1920s / 1.3552 s
agent0:                 episode reward: 0.3632,                 loss: nan
agent1:                 episode reward: -0.3632,                 loss: nan
Episode: 161/30000 (0.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1995s / 1.5547 s
agent0:                 episode reward: 0.5353,                 loss: nan
agent1:                 episode reward: -0.5353,                 loss: nan
Episode: 181/30000 (0.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2018s / 1.7565 s
agent0:                 episode reward: -0.1854,                 loss: nan
agent1:                 episode reward: 0.1854,                 loss: nan
Episode: 201/30000 (0.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1995s / 1.9560 s
agent0:                 episode reward: 0.4126,                 loss: nan
agent1:                 episode reward: -0.4126,                 loss: nan
Episode: 221/30000 (0.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1987s / 2.1547 s
agent0:                 episode reward: 0.5383,                 loss: nan
agent1:                 episode reward: -0.5383,                 loss: nan
Episode: 241/30000 (0.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1983s / 2.3530 s
agent0:                 episode reward: 0.1711,                 loss: nan
agent1:                 episode reward: -0.1711,                 loss: nan
Episode: 261/30000 (0.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1994s / 2.5524 s
agent0:                 episode reward: 0.1237,                 loss: nan
agent1:                 episode reward: -0.1237,                 loss: nan
Episode: 281/30000 (0.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2072s / 2.7596 s
agent0:                 episode reward: 0.6210,                 loss: nan
agent1:                 episode reward: -0.6210,                 loss: nan
Episode: 301/30000 (1.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1923s / 2.9519 s
agent0:                 episode reward: 0.5683,                 loss: nan
agent1:                 episode reward: -0.5683,                 loss: nan
Episode: 321/30000 (1.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2006s / 3.1524 s
agent0:                 episode reward: 0.0854,                 loss: nan
agent1:                 episode reward: -0.0854,                 loss: nan
Episode: 341/30000 (1.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1993s / 3.3517 s
agent0:                 episode reward: 0.0852,                 loss: nan
agent1:                 episode reward: -0.0852,                 loss: nan
Episode: 361/30000 (1.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1978s / 3.5496 s
agent0:                 episode reward: 0.2835,                 loss: nan
agent1:                 episode reward: -0.2835,                 loss: nan
Episode: 381/30000 (1.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2001s / 3.7497 s
agent0:                 episode reward: 0.4471,                 loss: nan
agent1:                 episode reward: -0.4471,                 loss: nan
Episode: 401/30000 (1.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2018s / 3.9515 s
agent0:                 episode reward: 0.3725,                 loss: nan
agent1:                 episode reward: -0.3725,                 loss: nan
Episode: 421/30000 (1.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2014s / 4.1529 s
agent0:                 episode reward: 0.3843,                 loss: nan
agent1:                 episode reward: -0.3843,                 loss: nan
Episode: 441/30000 (1.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2025s / 4.3554 s
agent0:                 episode reward: 0.2241,                 loss: nan
agent1:                 episode reward: -0.2241,                 loss: nan
Episode: 461/30000 (1.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1963s / 4.5518 s
agent0:                 episode reward: 0.1629,                 loss: nan
agent1:                 episode reward: -0.1629,                 loss: nan
Episode: 481/30000 (1.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2009s / 4.7527 s
agent0:                 episode reward: 0.3831,                 loss: nan
agent1:                 episode reward: -0.3831,                 loss: nan
Episode: 501/30000 (1.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2017s / 4.9544 s
agent0:                 episode reward: 0.0714,                 loss: nan
agent1:                 episode reward: -0.0714,                 loss: nan
Episode: 521/30000 (1.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1968s / 5.1512 s
agent0:                 episode reward: 0.3827,                 loss: nan
agent1:                 episode reward: -0.3827,                 loss: nan
Episode: 541/30000 (1.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1955s / 5.3467 s
agent0:                 episode reward: 0.3010,                 loss: nan
agent1:                 episode reward: -0.3010,                 loss: nan
Episode: 561/30000 (1.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2026s / 5.5493 s
agent0:                 episode reward: 0.5354,                 loss: nan
agent1:                 episode reward: -0.5354,                 loss: nan
Episode: 581/30000 (1.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2004s / 5.7497 s
agent0:                 episode reward: 0.2698,                 loss: nan
agent1:                 episode reward: -0.2698,                 loss: nan
Episode: 601/30000 (2.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1972s / 5.9469 s
agent0:                 episode reward: 0.1995,                 loss: nan
agent1:                 episode reward: -0.1995,                 loss: nan
Episode: 621/30000 (2.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1997s / 6.1466 s
agent0:                 episode reward: -0.0593,                 loss: nan
agent1:                 episode reward: 0.0593,                 loss: nan
Episode: 641/30000 (2.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1997s / 6.3463 s
agent0:                 episode reward: 0.4536,                 loss: nan
agent1:                 episode reward: -0.4536,                 loss: nan
Episode: 661/30000 (2.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1942s / 6.5405 s
agent0:                 episode reward: 0.8738,                 loss: nan
agent1:                 episode reward: -0.8738,                 loss: nan
Episode: 681/30000 (2.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2015s / 6.7420 s
agent0:                 episode reward: 0.1316,                 loss: nan
agent1:                 episode reward: -0.1316,                 loss: nan
Episode: 701/30000 (2.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2000s / 6.9419 s
agent0:                 episode reward: 0.3763,                 loss: nan
agent1:                 episode reward: -0.3763,                 loss: nan
Episode: 721/30000 (2.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2012s / 7.1431 s
agent0:                 episode reward: -0.1188,                 loss: nan
agent1:                 episode reward: 0.1188,                 loss: nan
Episode: 741/30000 (2.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1995s / 7.3427 s
agent0:                 episode reward: 0.5845,                 loss: nan
agent1:                 episode reward: -0.5845,                 loss: nan
Episode: 761/30000 (2.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1974s / 7.5401 s
agent0:                 episode reward: 0.4824,                 loss: nan
agent1:                 episode reward: -0.4824,                 loss: nan
Episode: 781/30000 (2.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2007s / 7.7408 s
agent0:                 episode reward: 0.4322,                 loss: nan
agent1:                 episode reward: -0.4322,                 loss: nan
Episode: 801/30000 (2.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1980s / 7.9388 s
agent0:                 episode reward: 0.2314,                 loss: nan
agent1:                 episode reward: -0.2314,                 loss: nan
Episode: 821/30000 (2.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2005s / 8.1393 s
agent0:                 episode reward: 0.1263,                 loss: nan
agent1:                 episode reward: -0.1263,                 loss: nan
Episode: 841/30000 (2.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2015s / 8.3408 s
agent0:                 episode reward: 0.2339,                 loss: nan
agent1:                 episode reward: -0.2339,                 loss: nan
Episode: 861/30000 (2.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1985s / 8.5392 s
agent0:                 episode reward: 0.3614,                 loss: nan
agent1:                 episode reward: -0.3614,                 loss: nan
Episode: 881/30000 (2.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2027s / 8.7419 s
agent0:                 episode reward: 0.5081,                 loss: nan
agent1:                 episode reward: -0.5081,                 loss: nan
Episode: 901/30000 (3.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1965s / 8.9384 s
agent0:                 episode reward: 0.5848,                 loss: nan
agent1:                 episode reward: -0.5848,                 loss: nan
Episode: 921/30000 (3.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1998s / 9.1382 s
agent0:                 episode reward: 0.2791,                 loss: nan
agent1:                 episode reward: -0.2791,                 loss: nan
Episode: 941/30000 (3.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2011s / 9.3393 s
agent0:                 episode reward: 0.6109,                 loss: nan
agent1:                 episode reward: -0.6109,                 loss: nan
Episode: 961/30000 (3.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1996s / 9.5389 s
agent0:                 episode reward: 0.1301,                 loss: nan
agent1:                 episode reward: -0.1301,                 loss: nan
Episode: 981/30000 (3.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1978s / 9.7367 s
agent0:                 episode reward: 0.2965,                 loss: nan
agent1:                 episode reward: -0.2965,                 loss: nan
Episode: 1001/30000 (3.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1980s / 9.9347 s
agent0:                 episode reward: 0.4249,                 loss: nan
agent1:                 episode reward: -0.4249,                 loss: nan
Episode: 1021/30000 (3.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1981s / 10.1328 s
agent0:                 episode reward: 0.7064,                 loss: nan
agent1:                 episode reward: -0.7064,                 loss: nan
Episode: 1041/30000 (3.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1981s / 10.3309 s
agent0:                 episode reward: 0.0948,                 loss: nan
agent1:                 episode reward: -0.0948,                 loss: nan
Episode: 1061/30000 (3.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2046s / 10.5355 s
agent0:                 episode reward: 0.1463,                 loss: nan
agent1:                 episode reward: -0.1463,                 loss: nan
Episode: 1081/30000 (3.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2021s / 10.7377 s
agent0:                 episode reward: 0.5752,                 loss: nan
agent1:                 episode reward: -0.5752,                 loss: nan
Episode: 1101/30000 (3.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1983s / 10.9359 s
agent0:                 episode reward: 0.4144,                 loss: nan
agent1:                 episode reward: -0.4144,                 loss: nan
Episode: 1121/30000 (3.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1994s / 11.1353 s
agent0:                 episode reward: 0.3765,                 loss: nan
agent1:                 episode reward: -0.3765,                 loss: nan
Episode: 1141/30000 (3.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1977s / 11.3330 s
agent0:                 episode reward: 0.6678,                 loss: nan
agent1:                 episode reward: -0.6678,                 loss: nan
Episode: 1161/30000 (3.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1947s / 11.5277 s
agent0:                 episode reward: 0.4321,                 loss: nan
agent1:                 episode reward: -0.4321,                 loss: nan
Episode: 1181/30000 (3.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1947s / 11.7224 s
agent0:                 episode reward: 0.4151,                 loss: nan
agent1:                 episode reward: -0.4151,                 loss: nan
Episode: 1201/30000 (4.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1983s / 11.9206 s
agent0:                 episode reward: 0.4461,                 loss: nan
agent1:                 episode reward: -0.4461,                 loss: nan
Episode: 1221/30000 (4.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1998s / 12.1204 s
agent0:                 episode reward: 0.4198,                 loss: nan
agent1:                 episode reward: -0.4198,                 loss: nan
Episode: 1241/30000 (4.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1991s / 12.3195 s
agent0:                 episode reward: 0.3353,                 loss: nan
agent1:                 episode reward: -0.3353,                 loss: nan
Episode: 1261/30000 (4.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1980s / 12.5176 s
agent0:                 episode reward: 0.4562,                 loss: nan
agent1:                 episode reward: -0.4562,                 loss: nan
Episode: 1281/30000 (4.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1965s / 12.7141 s
agent0:                 episode reward: 0.2789,                 loss: nan
agent1:                 episode reward: -0.2789,                 loss: nan
Episode: 1301/30000 (4.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2034s / 12.9175 s
agent0:                 episode reward: -0.1129,                 loss: nan
agent1:                 episode reward: 0.1129,                 loss: nan
Episode: 1321/30000 (4.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1959s / 13.1134 s
agent0:                 episode reward: -0.1163,                 loss: nan
agent1:                 episode reward: 0.1163,                 loss: nan
Episode: 1341/30000 (4.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2000s / 13.3135 s
agent0:                 episode reward: 0.6905,                 loss: nan
agent1:                 episode reward: -0.6905,                 loss: nan
Episode: 1361/30000 (4.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2000s / 13.5135 s
agent0:                 episode reward: 0.3796,                 loss: nan
agent1:                 episode reward: -0.3796,                 loss: nan
Episode: 1381/30000 (4.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1945s / 13.7079 s
agent0:                 episode reward: 0.5687,                 loss: nan
agent1:                 episode reward: -0.5687,                 loss: nan
Episode: 1401/30000 (4.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1993s / 13.9072 s
agent0:                 episode reward: 0.1839,                 loss: nan
agent1:                 episode reward: -0.1839,                 loss: nan
Episode: 1421/30000 (4.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1955s / 14.1027 s
agent0:                 episode reward: 0.0593,                 loss: nan
agent1:                 episode reward: -0.0593,                 loss: nan
Episode: 1441/30000 (4.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1989s / 14.3016 s
agent0:                 episode reward: 0.1794,                 loss: nan
agent1:                 episode reward: -0.1794,                 loss: nan
Episode: 1461/30000 (4.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1992s / 14.5008 s
agent0:                 episode reward: -0.0111,                 loss: nan
agent1:                 episode reward: 0.0111,                 loss: nan
Episode: 1481/30000 (4.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2004s / 14.7012 s
agent0:                 episode reward: 0.6101,                 loss: nan
agent1:                 episode reward: -0.6101,                 loss: nan
Episode: 1501/30000 (5.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1964s / 14.8975 s
agent0:                 episode reward: 0.1835,                 loss: nan
agent1:                 episode reward: -0.1835,                 loss: nan
Episode: 1521/30000 (5.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1990s / 15.0966 s
agent0:                 episode reward: 0.5630,                 loss: nan
agent1:                 episode reward: -0.5630,                 loss: nan
Episode: 1541/30000 (5.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2011s / 15.2977 s
agent0:                 episode reward: -0.0663,                 loss: nan
agent1:                 episode reward: 0.0663,                 loss: nan
Episode: 1561/30000 (5.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2028s / 15.5005 s
agent0:                 episode reward: 0.5389,                 loss: nan
agent1:                 episode reward: -0.5389,                 loss: nan
Episode: 1581/30000 (5.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1960s / 15.6965 s
agent0:                 episode reward: 0.4483,                 loss: nan
agent1:                 episode reward: -0.4483,                 loss: nan
Episode: 1601/30000 (5.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2007s / 15.8972 s
agent0:                 episode reward: 0.2732,                 loss: nan
agent1:                 episode reward: -0.2732,                 loss: nan
Episode: 1621/30000 (5.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2025s / 16.0997 s
agent0:                 episode reward: 0.5238,                 loss: nan
agent1:                 episode reward: -0.5238,                 loss: nan
Episode: 1641/30000 (5.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1973s / 16.2971 s
agent0:                 episode reward: 0.7121,                 loss: nan
agent1:                 episode reward: -0.7121,                 loss: nan
Episode: 1661/30000 (5.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1987s / 16.4958 s
agent0:                 episode reward: 0.3108,                 loss: nan
agent1:                 episode reward: -0.3108,                 loss: nan
Episode: 1681/30000 (5.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1999s / 16.6957 s
agent0:                 episode reward: 0.4522,                 loss: nan
agent1:                 episode reward: -0.4522,                 loss: nan
Episode: 1701/30000 (5.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2019s / 16.8975 s
agent0:                 episode reward: 0.5645,                 loss: nan
agent1:                 episode reward: -0.5645,                 loss: nan
Episode: 1721/30000 (5.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2003s / 17.0978 s
agent0:                 episode reward: 0.3566,                 loss: nan
agent1:                 episode reward: -0.3566,                 loss: nan
Episode: 1741/30000 (5.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1985s / 17.2964 s
agent0:                 episode reward: 0.1651,                 loss: nan
agent1:                 episode reward: -0.1651,                 loss: nan
Episode: 1761/30000 (5.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1981s / 17.4944 s
agent0:                 episode reward: -0.3345,                 loss: nan
agent1:                 episode reward: 0.3345,                 loss: nan
Episode: 1781/30000 (5.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1934s / 17.6879 s
agent0:                 episode reward: 0.4107,                 loss: nan
agent1:                 episode reward: -0.4107,                 loss: nan
Episode: 1801/30000 (6.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1966s / 17.8845 s
agent0:                 episode reward: 0.3263,                 loss: nan
agent1:                 episode reward: -0.3263,                 loss: nan
Episode: 1821/30000 (6.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2011s / 18.0856 s
agent0:                 episode reward: 0.6303,                 loss: nan
agent1:                 episode reward: -0.6303,                 loss: nan
Episode: 1841/30000 (6.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1995s / 18.2851 s
agent0:                 episode reward: -0.1563,                 loss: nan
agent1:                 episode reward: 0.1563,                 loss: nan
Episode: 1861/30000 (6.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1986s / 18.4837 s
agent0:                 episode reward: 0.5764,                 loss: nan
agent1:                 episode reward: -0.5764,                 loss: nan
Episode: 1881/30000 (6.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2015s / 18.6852 s
agent0:                 episode reward: 0.4596,                 loss: nan
agent1:                 episode reward: -0.4596,                 loss: nan
Episode: 1901/30000 (6.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1961s / 18.8813 s
agent0:                 episode reward: 0.0778,                 loss: nan
agent1:                 episode reward: -0.0778,                 loss: nan
Episode: 1921/30000 (6.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1983s / 19.0796 s
agent0:                 episode reward: 0.3248,                 loss: nan
agent1:                 episode reward: -0.3248,                 loss: nan
Episode: 1941/30000 (6.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1991s / 19.2787 s
agent0:                 episode reward: 0.1840,                 loss: nan
agent1:                 episode reward: -0.1840,                 loss: nan
Episode: 1961/30000 (6.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1979s / 19.4766 s
agent0:                 episode reward: 0.7070,                 loss: nan
agent1:                 episode reward: -0.7070,                 loss: nan
Episode: 1981/30000 (6.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2058s / 19.6823 s
agent0:                 episode reward: 0.4344,                 loss: nan
agent1:                 episode reward: -0.4344,                 loss: nan
Episode: 2001/30000 (6.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1940s / 19.8763 s
agent0:                 episode reward: 0.4122,                 loss: nan
agent1:                 episode reward: -0.4122,                 loss: nan
Episode: 2021/30000 (6.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2017s / 20.0780 s
agent0:                 episode reward: 0.2331,                 loss: nan
agent1:                 episode reward: -0.2331,                 loss: nan
Episode: 2041/30000 (6.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1993s / 20.2774 s
agent0:                 episode reward: 0.1595,                 loss: nan
agent1:                 episode reward: -0.1595,                 loss: nan
Episode: 2061/30000 (6.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1961s / 20.4735 s
agent0:                 episode reward: 0.4286,                 loss: nan
agent1:                 episode reward: -0.4286,                 loss: nan
Episode: 2081/30000 (6.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1997s / 20.6733 s
agent0:                 episode reward: 0.5854,                 loss: nan
agent1:                 episode reward: -0.5854,                 loss: nan
Episode: 2101/30000 (7.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2001s / 20.8734 s
agent0:                 episode reward: 0.2913,                 loss: nan
agent1:                 episode reward: -0.2913,                 loss: nan
Episode: 2121/30000 (7.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1967s / 21.0701 s
agent0:                 episode reward: 0.3876,                 loss: nan
agent1:                 episode reward: -0.3876,                 loss: nan
Episode: 2141/30000 (7.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1994s / 21.2694 s
agent0:                 episode reward: 0.3935,                 loss: nan
agent1:                 episode reward: -0.3935,                 loss: nan
Episode: 2161/30000 (7.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1914s / 21.4608 s
agent0:                 episode reward: 0.1438,                 loss: nan
agent1:                 episode reward: -0.1438,                 loss: nan
Episode: 2181/30000 (7.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2007s / 21.6615 s
agent0:                 episode reward: 0.2963,                 loss: nan
agent1:                 episode reward: -0.2963,                 loss: nan
Episode: 2201/30000 (7.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1994s / 21.8609 s
agent0:                 episode reward: -0.0104,                 loss: nan
agent1:                 episode reward: 0.0104,                 loss: nan
Episode: 2221/30000 (7.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1950s / 22.0559 s
agent0:                 episode reward: 0.3830,                 loss: nan
agent1:                 episode reward: -0.3830,                 loss: nan
Episode: 2241/30000 (7.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1979s / 22.2538 s
agent0:                 episode reward: 0.4509,                 loss: nan
agent1:                 episode reward: -0.4509,                 loss: nan
Episode: 2261/30000 (7.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1997s / 22.4535 s
agent0:                 episode reward: -0.0302,                 loss: nan
agent1:                 episode reward: 0.0302,                 loss: nan
Episode: 2281/30000 (7.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2005s / 22.6540 s
agent0:                 episode reward: 0.4583,                 loss: nan
agent1:                 episode reward: -0.4583,                 loss: nan
Episode: 2301/30000 (7.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1972s / 22.8512 s
agent0:                 episode reward: 0.1698,                 loss: nan
agent1:                 episode reward: -0.1698,                 loss: nan
Episode: 2321/30000 (7.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1968s / 23.0480 s
agent0:                 episode reward: 0.3935,                 loss: nan
agent1:                 episode reward: -0.3935,                 loss: nan
Episode: 2341/30000 (7.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1933s / 23.2412 s
agent0:                 episode reward: 0.1557,                 loss: nan
agent1:                 episode reward: -0.1557,                 loss: nan
Episode: 2361/30000 (7.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1997s / 23.4410 s
agent0:                 episode reward: 0.3066,                 loss: nan
agent1:                 episode reward: -0.3066,                 loss: nan
Episode: 2381/30000 (7.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1953s / 23.6363 s
agent0:                 episode reward: 0.6016,                 loss: nan
agent1:                 episode reward: -0.6016,                 loss: nan
Episode: 2401/30000 (8.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1958s / 23.8321 s
agent0:                 episode reward: 0.1531,                 loss: nan
agent1:                 episode reward: -0.1531,                 loss: nan
Episode: 2421/30000 (8.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2019s / 24.0340 s
agent0:                 episode reward: 0.6223,                 loss: nan
agent1:                 episode reward: -0.6223,                 loss: nan
Episode: 2441/30000 (8.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2021s / 24.2361 s
agent0:                 episode reward: -0.0506,                 loss: nan
agent1:                 episode reward: 0.0506,                 loss: nan
Episode: 2461/30000 (8.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1964s / 24.4326 s
agent0:                 episode reward: 0.2888,                 loss: nan
agent1:                 episode reward: -0.2888,                 loss: nan
Episode: 2481/30000 (8.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1988s / 24.6314 s
agent0:                 episode reward: 0.1997,                 loss: nan
agent1:                 episode reward: -0.1997,                 loss: nan
Episode: 2501/30000 (8.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1978s / 24.8292 s
agent0:                 episode reward: 0.2426,                 loss: nan
agent1:                 episode reward: -0.2426,                 loss: nan
Episode: 2521/30000 (8.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1959s / 25.0251 s
agent0:                 episode reward: 0.3770,                 loss: nan
agent1:                 episode reward: -0.3770,                 loss: nan
Episode: 2541/30000 (8.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1996s / 25.2247 s
agent0:                 episode reward: 0.2791,                 loss: nan
agent1:                 episode reward: -0.2791,                 loss: nan
Episode: 2561/30000 (8.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1990s / 25.4237 s
agent0:                 episode reward: 0.2591,                 loss: nan
agent1:                 episode reward: -0.2591,                 loss: nan
Episode: 2581/30000 (8.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2011s / 25.6247 s
agent0:                 episode reward: 0.1965,                 loss: nan
agent1:                 episode reward: -0.1965,                 loss: nan
Episode: 2601/30000 (8.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1984s / 25.8231 s
agent0:                 episode reward: 0.4729,                 loss: nan
agent1:                 episode reward: -0.4729,                 loss: nan
Episode: 2621/30000 (8.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2000s / 26.0231 s
agent0:                 episode reward: -0.0166,                 loss: nan
agent1:                 episode reward: 0.0166,                 loss: nan
Episode: 2641/30000 (8.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1961s / 26.2193 s
agent0:                 episode reward: 0.2290,                 loss: nan
agent1:                 episode reward: -0.2290,                 loss: nan
Episode: 2661/30000 (8.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1990s / 26.4183 s
agent0:                 episode reward: 0.1716,                 loss: nan
agent1:                 episode reward: -0.1716,                 loss: nan
Episode: 2681/30000 (8.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2201s / 26.6384 s
agent0:                 episode reward: 0.3536,                 loss: nan
agent1:                 episode reward: -0.3536,                 loss: nan
Episode: 2701/30000 (9.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2054s / 26.8438 s
agent0:                 episode reward: 0.2611,                 loss: nan
agent1:                 episode reward: -0.2611,                 loss: nan
Episode: 2721/30000 (9.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2065s / 27.0503 s
agent0:                 episode reward: 0.3783,                 loss: nan
agent1:                 episode reward: -0.3783,                 loss: nan
Episode: 2741/30000 (9.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2055s / 27.2558 s
agent0:                 episode reward: 0.4341,                 loss: nan
agent1:                 episode reward: -0.4341,                 loss: nan
Episode: 2761/30000 (9.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2812s / 27.5370 s
agent0:                 episode reward: 0.5741,                 loss: nan
agent1:                 episode reward: -0.5741,                 loss: nan
Episode: 2781/30000 (9.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2036s / 27.7407 s
agent0:                 episode reward: 0.2805,                 loss: nan
agent1:                 episode reward: -0.2805,                 loss: nan
Episode: 2801/30000 (9.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2013s / 27.9420 s
agent0:                 episode reward: 0.3473,                 loss: nan
agent1:                 episode reward: -0.3473,                 loss: nan
Episode: 2821/30000 (9.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2010s / 28.1430 s
agent0:                 episode reward: 0.0454,                 loss: nan
agent1:                 episode reward: -0.0454,                 loss: nan
Episode: 2841/30000 (9.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1566s / 28.2997 s
agent0:                 episode reward: 0.1258,                 loss: nan
agent1:                 episode reward: -0.1258,                 loss: nan
Episode: 2861/30000 (9.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1935s / 28.4931 s
agent0:                 episode reward: 0.4224,                 loss: nan
agent1:                 episode reward: -0.4224,                 loss: nan
Episode: 2881/30000 (9.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1986s / 28.6917 s
agent0:                 episode reward: 0.5528,                 loss: nan
agent1:                 episode reward: -0.5528,                 loss: nan
Episode: 2901/30000 (9.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1958s / 28.8875 s
agent0:                 episode reward: 0.2618,                 loss: nan
agent1:                 episode reward: -0.2618,                 loss: nan
Episode: 2921/30000 (9.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1954s / 29.0829 s
agent0:                 episode reward: 0.3950,                 loss: nan
agent1:                 episode reward: -0.3950,                 loss: nan
Episode: 2941/30000 (9.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1948s / 29.2777 s
agent0:                 episode reward: 0.1289,                 loss: nan
agent1:                 episode reward: -0.1289,                 loss: nan
Episode: 2961/30000 (9.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1963s / 29.4740 s
agent0:                 episode reward: -0.1363,                 loss: nan
agent1:                 episode reward: 0.1363,                 loss: nan
Episode: 2981/30000 (9.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1996s / 29.6736 s
agent0:                 episode reward: 0.6906,                 loss: nan
agent1:                 episode reward: -0.6906,                 loss: nan
Episode: 3001/30000 (10.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2046s / 29.8783 s
agent0:                 episode reward: 0.3157,                 loss: nan
agent1:                 episode reward: -0.3157,                 loss: nan
Episode: 3021/30000 (10.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2024s / 30.0807 s
agent0:                 episode reward: 0.1884,                 loss: nan
agent1:                 episode reward: -0.1884,                 loss: nan
Episode: 3041/30000 (10.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1975s / 30.2782 s
agent0:                 episode reward: 0.2810,                 loss: nan
agent1:                 episode reward: -0.2810,                 loss: nan
Episode: 3061/30000 (10.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1964s / 30.4746 s
agent0:                 episode reward: 0.3504,                 loss: nan
agent1:                 episode reward: -0.3504,                 loss: nan
Episode: 3081/30000 (10.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2010s / 30.6755 s
agent0:                 episode reward: 0.2402,                 loss: nan
agent1:                 episode reward: -0.2402,                 loss: nan
Episode: 3101/30000 (10.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1987s / 30.8742 s
agent0:                 episode reward: 0.4081,                 loss: nan
agent1:                 episode reward: -0.4081,                 loss: nan
Episode: 3121/30000 (10.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2041s / 31.0782 s
agent0:                 episode reward: 0.2370,                 loss: nan
agent1:                 episode reward: -0.2370,                 loss: nan
Episode: 3141/30000 (10.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2002s / 31.2785 s
agent0:                 episode reward: 0.1579,                 loss: nan
agent1:                 episode reward: -0.1579,                 loss: nan
Episode: 3161/30000 (10.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1981s / 31.4765 s
agent0:                 episode reward: 0.1887,                 loss: nan
agent1:                 episode reward: -0.1887,                 loss: nan
Episode: 3181/30000 (10.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1988s / 31.6753 s
agent0:                 episode reward: 0.1335,                 loss: nan
agent1:                 episode reward: -0.1335,                 loss: nan
Episode: 3201/30000 (10.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1988s / 31.8742 s
agent0:                 episode reward: 0.3105,                 loss: nan
agent1:                 episode reward: -0.3105,                 loss: nan
Episode: 3221/30000 (10.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1998s / 32.0740 s
agent0:                 episode reward: 0.2624,                 loss: nan
agent1:                 episode reward: -0.2624,                 loss: nan
Episode: 3241/30000 (10.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1965s / 32.2706 s
agent0:                 episode reward: 0.3027,                 loss: nan
agent1:                 episode reward: -0.3027,                 loss: nan
Episode: 3261/30000 (10.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2012s / 32.4717 s
agent0:                 episode reward: 0.1520,                 loss: nan
agent1:                 episode reward: -0.1520,                 loss: nan
Episode: 3281/30000 (10.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2022s / 32.6739 s
agent0:                 episode reward: 0.2160,                 loss: nan
agent1:                 episode reward: -0.2160,                 loss: nan
Episode: 3301/30000 (11.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1985s / 32.8724 s
agent0:                 episode reward: 0.2911,                 loss: nan
agent1:                 episode reward: -0.2911,                 loss: nan
Episode: 3321/30000 (11.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2031s / 33.0754 s
agent0:                 episode reward: 0.6193,                 loss: nan
agent1:                 episode reward: -0.6193,                 loss: nan
Episode: 3341/30000 (11.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3638s / 33.4393 s
agent0:                 episode reward: 0.5440,                 loss: nan
agent1:                 episode reward: -0.5440,                 loss: 0.4466
Episode: 3361/30000 (11.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6162s / 34.0554 s
agent0:                 episode reward: -0.0430,                 loss: nan
agent1:                 episode reward: 0.0430,                 loss: 0.4333
Episode: 3381/30000 (11.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5859s / 34.6413 s
agent0:                 episode reward: -0.3088,                 loss: nan
agent1:                 episode reward: 0.3088,                 loss: 0.4264
Episode: 3401/30000 (11.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5762s / 35.2176 s
agent0:                 episode reward: 0.3321,                 loss: nan
agent1:                 episode reward: -0.3321,                 loss: 0.4248
Episode: 3421/30000 (11.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5941s / 35.8116 s
agent0:                 episode reward: 0.0663,                 loss: nan
agent1:                 episode reward: -0.0663,                 loss: 0.4183
Episode: 3441/30000 (11.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5775s / 36.3891 s
agent0:                 episode reward: 0.4157,                 loss: nan
agent1:                 episode reward: -0.4157,                 loss: 0.4148
Episode: 3461/30000 (11.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5807s / 36.9697 s
agent0:                 episode reward: 0.0851,                 loss: nan
agent1:                 episode reward: -0.0851,                 loss: 0.4102
Episode: 3481/30000 (11.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5886s / 37.5583 s
agent0:                 episode reward: -0.0761,                 loss: nan
agent1:                 episode reward: 0.0761,                 loss: 0.4059
Episode: 3501/30000 (11.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5707s / 38.1291 s
agent0:                 episode reward: 0.1778,                 loss: nan
agent1:                 episode reward: -0.1778,                 loss: 0.4021
Episode: 3521/30000 (11.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5818s / 38.7109 s
agent0:                 episode reward: 0.1498,                 loss: nan
agent1:                 episode reward: -0.1498,                 loss: 0.3983
Episode: 3541/30000 (11.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5882s / 39.2991 s
agent0:                 episode reward: -0.0498,                 loss: nan
agent1:                 episode reward: 0.0498,                 loss: 0.3972
Episode: 3561/30000 (11.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5737s / 39.8728 s
agent0:                 episode reward: -0.0380,                 loss: nan
agent1:                 episode reward: 0.0380,                 loss: 0.3945
Episode: 3581/30000 (11.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5909s / 40.4637 s
agent0:                 episode reward: -0.0225,                 loss: nan
agent1:                 episode reward: 0.0225,                 loss: 0.3952
Episode: 3601/30000 (12.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5749s / 41.0386 s
agent0:                 episode reward: 0.0767,                 loss: nan
agent1:                 episode reward: -0.0767,                 loss: 0.3909
Episode: 3621/30000 (12.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5758s / 41.6144 s
agent0:                 episode reward: 0.1141,                 loss: nan
agent1:                 episode reward: -0.1141,                 loss: 0.3898
Episode: 3641/30000 (12.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5791s / 42.1935 s
agent0:                 episode reward: 0.0255,                 loss: nan
agent1:                 episode reward: -0.0255,                 loss: 0.3903
Episode: 3661/30000 (12.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5900s / 42.7835 s
agent0:                 episode reward: -0.0346,                 loss: nan
agent1:                 episode reward: 0.0346,                 loss: 0.3862
Episode: 3681/30000 (12.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5849s / 43.3684 s
agent0:                 episode reward: 0.0541,                 loss: nan
agent1:                 episode reward: -0.0541,                 loss: 0.3956
Episode: 3701/30000 (12.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5833s / 43.9517 s
agent0:                 episode reward: 0.2500,                 loss: nan
agent1:                 episode reward: -0.2500,                 loss: 0.3828
Episode: 3721/30000 (12.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5860s / 44.5377 s
agent0:                 episode reward: -0.1408,                 loss: nan
agent1:                 episode reward: 0.1408,                 loss: 0.3817
Episode: 3741/30000 (12.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5832s / 45.1209 s
agent0:                 episode reward: -0.4834,                 loss: nan
agent1:                 episode reward: 0.4834,                 loss: 0.3780
Episode: 3761/30000 (12.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5794s / 45.7003 s
agent0:                 episode reward: -0.0901,                 loss: nan
agent1:                 episode reward: 0.0901,                 loss: 0.3803
Episode: 3781/30000 (12.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5838s / 46.2841 s
agent0:                 episode reward: -0.3120,                 loss: nan
agent1:                 episode reward: 0.3120,                 loss: 0.3779
Episode: 3801/30000 (12.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5885s / 46.8726 s
agent0:                 episode reward: -0.1289,                 loss: nan
agent1:                 episode reward: 0.1289,                 loss: 0.3768
Episode: 3821/30000 (12.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5797s / 47.4523 s
agent0:                 episode reward: -0.4172,                 loss: nan
agent1:                 episode reward: 0.4172,                 loss: 0.3791
Episode: 3841/30000 (12.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5772s / 48.0295 s
agent0:                 episode reward: -0.1146,                 loss: nan
agent1:                 episode reward: 0.1146,                 loss: 0.3777
Episode: 3861/30000 (12.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5810s / 48.6105 s
agent0:                 episode reward: 0.1615,                 loss: nan
agent1:                 episode reward: -0.1615,                 loss: 0.3799
Episode: 3881/30000 (12.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5792s / 49.1897 s
agent0:                 episode reward: -0.0372,                 loss: nan
agent1:                 episode reward: 0.0372,                 loss: 0.3785
Episode: 3901/30000 (13.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5746s / 49.7642 s
agent0:                 episode reward: 0.0941,                 loss: nan
agent1:                 episode reward: -0.0941,                 loss: 0.3781
Episode: 3921/30000 (13.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5759s / 50.3401 s
agent0:                 episode reward: -0.3379,                 loss: nan
agent1:                 episode reward: 0.3379,                 loss: 0.3766
Episode: 3941/30000 (13.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5784s / 50.9185 s
agent0:                 episode reward: -0.2251,                 loss: nan
agent1:                 episode reward: 0.2251,                 loss: 0.3746
Episode: 3961/30000 (13.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5830s / 51.5015 s
agent0:                 episode reward: 0.0880,                 loss: nan
agent1:                 episode reward: -0.0880,                 loss: 0.3780
Episode: 3981/30000 (13.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5789s / 52.0804 s
agent0:                 episode reward: -0.0403,                 loss: nan
agent1:                 episode reward: 0.0403,                 loss: 0.3741
Episode: 4001/30000 (13.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5745s / 52.6549 s
agent0:                 episode reward: 0.2596,                 loss: nan
agent1:                 episode reward: -0.2596,                 loss: 0.3748
Episode: 4021/30000 (13.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5795s / 53.2344 s
agent0:                 episode reward: -0.1184,                 loss: nan
agent1:                 episode reward: 0.1184,                 loss: 0.3988
Episode: 4041/30000 (13.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5736s / 53.8080 s
agent0:                 episode reward: -0.4163,                 loss: nan
agent1:                 episode reward: 0.4163,                 loss: 0.3979
Episode: 4061/30000 (13.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5893s / 54.3972 s
agent0:                 episode reward: -0.0188,                 loss: nan
agent1:                 episode reward: 0.0188,                 loss: 0.3978
Episode: 4081/30000 (13.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5792s / 54.9765 s
agent0:                 episode reward: -0.2008,                 loss: nan
agent1:                 episode reward: 0.2008,                 loss: 0.3960
Episode: 4101/30000 (13.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5800s / 55.5565 s
agent0:                 episode reward: 0.0213,                 loss: nan
agent1:                 episode reward: -0.0213,                 loss: 0.3926
Episode: 4121/30000 (13.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5771s / 56.1336 s
agent0:                 episode reward: -0.0646,                 loss: nan
agent1:                 episode reward: 0.0646,                 loss: 0.3906
Episode: 4141/30000 (13.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5801s / 56.7138 s
agent0:                 episode reward: -0.2177,                 loss: nan
agent1:                 episode reward: 0.2177,                 loss: 0.3880
Episode: 4161/30000 (13.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5778s / 57.2915 s
agent0:                 episode reward: -0.0867,                 loss: nan
agent1:                 episode reward: 0.0867,                 loss: 0.3902
Episode: 4181/30000 (13.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5979s / 57.8894 s
agent0:                 episode reward: 0.0343,                 loss: nan
agent1:                 episode reward: -0.0343,                 loss: 0.3877
Episode: 4201/30000 (14.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5922s / 58.4816 s
agent0:                 episode reward: 0.0311,                 loss: nan
agent1:                 episode reward: -0.0311,                 loss: 0.3938
Episode: 4221/30000 (14.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5853s / 59.0669 s
agent0:                 episode reward: -0.2736,                 loss: nan
agent1:                 episode reward: 0.2736,                 loss: 0.3881
Episode: 4241/30000 (14.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5902s / 59.6571 s
agent0:                 episode reward: -0.1462,                 loss: nan
agent1:                 episode reward: 0.1462,                 loss: 0.3871
Episode: 4261/30000 (14.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5904s / 60.2475 s
agent0:                 episode reward: -0.2448,                 loss: nan
agent1:                 episode reward: 0.2448,                 loss: 0.3872
Episode: 4281/30000 (14.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5803s / 60.8278 s
agent0:                 episode reward: -0.3187,                 loss: nan
agent1:                 episode reward: 0.3187,                 loss: 0.3858
Episode: 4301/30000 (14.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6176s / 61.4454 s
agent0:                 episode reward: -0.2950,                 loss: nan
agent1:                 episode reward: 0.2950,                 loss: 0.3865
Episode: 4321/30000 (14.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6897s / 62.1351 s
agent0:                 episode reward: -0.1317,                 loss: nan
agent1:                 episode reward: 0.1317,                 loss: 0.3826
Episode: 4341/30000 (14.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6584s / 62.7935 s
agent0:                 episode reward: -0.2096,                 loss: nan
agent1:                 episode reward: 0.2096,                 loss: 0.3785
Episode: 4361/30000 (14.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6070s / 63.4005 s
agent0:                 episode reward: 0.4250,                 loss: nan
agent1:                 episode reward: -0.4250,                 loss: 0.3666
Episode: 4381/30000 (14.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6201s / 64.0206 s
agent0:                 episode reward: 0.0549,                 loss: nan
agent1:                 episode reward: -0.0549,                 loss: 0.3642
Episode: 4401/30000 (14.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5919s / 64.6125 s
agent0:                 episode reward: 0.0138,                 loss: nan
agent1:                 episode reward: -0.0138,                 loss: 0.3663
Episode: 4421/30000 (14.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5838s / 65.1963 s
agent0:                 episode reward: 0.0774,                 loss: nan
agent1:                 episode reward: -0.0774,                 loss: 0.3637
Episode: 4441/30000 (14.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5842s / 65.7804 s
agent0:                 episode reward: -0.5588,                 loss: nan
agent1:                 episode reward: 0.5588,                 loss: 0.3641
Episode: 4461/30000 (14.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5896s / 66.3700 s
agent0:                 episode reward: -0.0266,                 loss: nan
agent1:                 episode reward: 0.0266,                 loss: 0.3607
Episode: 4481/30000 (14.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5879s / 66.9579 s
agent0:                 episode reward: -0.4460,                 loss: nan
agent1:                 episode reward: 0.4460,                 loss: 0.3603
Episode: 4501/30000 (15.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5867s / 67.5446 s
agent0:                 episode reward: -0.1548,                 loss: nan
agent1:                 episode reward: 0.1548,                 loss: 0.3550
Episode: 4521/30000 (15.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5976s / 68.1422 s
agent0:                 episode reward: -0.1778,                 loss: nan
agent1:                 episode reward: 0.1778,                 loss: 0.3583
Episode: 4541/30000 (15.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5851s / 68.7273 s
agent0:                 episode reward: -0.3828,                 loss: nan
agent1:                 episode reward: 0.3828,                 loss: 0.3561
Episode: 4561/30000 (15.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5871s / 69.3143 s
agent0:                 episode reward: -0.0553,                 loss: nan
agent1:                 episode reward: 0.0553,                 loss: 0.3565
Episode: 4581/30000 (15.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5896s / 69.9039 s
agent0:                 episode reward: 0.0616,                 loss: nan
agent1:                 episode reward: -0.0616,                 loss: 0.3597
Episode: 4601/30000 (15.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5869s / 70.4909 s
agent0:                 episode reward: -0.4415,                 loss: nan
agent1:                 episode reward: 0.4415,                 loss: 0.3539
Episode: 4621/30000 (15.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5843s / 71.0752 s
agent0:                 episode reward: -0.2135,                 loss: nan
agent1:                 episode reward: 0.2135,                 loss: 0.3535
Episode: 4641/30000 (15.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5959s / 71.6710 s
agent0:                 episode reward: -0.0154,                 loss: nan
agent1:                 episode reward: 0.0154,                 loss: 0.3563
Episode: 4661/30000 (15.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5898s / 72.2609 s
agent0:                 episode reward: -0.4098,                 loss: nan
agent1:                 episode reward: 0.4098,                 loss: 0.3565
Episode: 4681/30000 (15.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5931s / 72.8540 s
agent0:                 episode reward: -0.4359,                 loss: nan
agent1:                 episode reward: 0.4359,                 loss: 0.3579
Episode: 4701/30000 (15.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5881s / 73.4421 s
agent0:                 episode reward: -0.4796,                 loss: nan
agent1:                 episode reward: 0.4796,                 loss: 0.3482
Episode: 4721/30000 (15.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5978s / 74.0399 s
agent0:                 episode reward: -0.1881,                 loss: nan
agent1:                 episode reward: 0.1881,                 loss: 0.3528
Episode: 4741/30000 (15.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5902s / 74.6300 s
agent0:                 episode reward: -0.3880,                 loss: nan
agent1:                 episode reward: 0.3880,                 loss: 0.3501
Episode: 4761/30000 (15.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5837s / 75.2137 s
agent0:                 episode reward: 0.0087,                 loss: nan
agent1:                 episode reward: -0.0087,                 loss: 0.3501
Episode: 4781/30000 (15.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5798s / 75.7935 s
agent0:                 episode reward: -0.3917,                 loss: nan
agent1:                 episode reward: 0.3917,                 loss: 0.3472
Episode: 4801/30000 (16.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5867s / 76.3802 s
agent0:                 episode reward: -0.3120,                 loss: nan
agent1:                 episode reward: 0.3120,                 loss: 0.3468
Episode: 4821/30000 (16.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5799s / 76.9601 s
agent0:                 episode reward: -0.2208,                 loss: nan
agent1:                 episode reward: 0.2208,                 loss: 0.3451
Episode: 4841/30000 (16.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5942s / 77.5543 s
agent0:                 episode reward: -0.4332,                 loss: nan
agent1:                 episode reward: 0.4332,                 loss: 0.3472
Episode: 4861/30000 (16.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5845s / 78.1388 s
agent0:                 episode reward: -0.2665,                 loss: nan
agent1:                 episode reward: 0.2665,                 loss: 0.3484
Episode: 4881/30000 (16.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5999s / 78.7388 s
agent0:                 episode reward: -0.3759,                 loss: nan
agent1:                 episode reward: 0.3759,                 loss: 0.3454
Episode: 4901/30000 (16.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5877s / 79.3265 s
agent0:                 episode reward: -0.0018,                 loss: nan
agent1:                 episode reward: 0.0018,                 loss: 0.3424
Episode: 4921/30000 (16.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5806s / 79.9071 s
agent0:                 episode reward: -0.6149,                 loss: nan
agent1:                 episode reward: 0.6149,                 loss: 0.3463
Episode: 4941/30000 (16.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5947s / 80.5018 s
agent0:                 episode reward: -0.1480,                 loss: nan
agent1:                 episode reward: 0.1480,                 loss: 0.3435
Episode: 4961/30000 (16.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5935s / 81.0953 s
agent0:                 episode reward: -0.5220,                 loss: nan
agent1:                 episode reward: 0.5220,                 loss: 0.3385
Episode: 4981/30000 (16.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5832s / 81.6785 s
agent0:                 episode reward: -0.7992,                 loss: nan
agent1:                 episode reward: 0.7992,                 loss: 0.3394
Episode: 5001/30000 (16.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5910s / 82.2695 s
agent0:                 episode reward: -0.6255,                 loss: nan
agent1:                 episode reward: 0.6255,                 loss: 0.3469
Episode: 5021/30000 (16.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5880s / 82.8575 s
agent0:                 episode reward: -0.3696,                 loss: nan
agent1:                 episode reward: 0.3696,                 loss: 0.3621
Episode: 5041/30000 (16.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5879s / 83.4454 s
agent0:                 episode reward: 0.1996,                 loss: nan
agent1:                 episode reward: -0.1996,                 loss: 0.3597
Episode: 5061/30000 (16.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6010s / 84.0464 s
agent0:                 episode reward: -0.3798,                 loss: nan
agent1:                 episode reward: 0.3798,                 loss: 0.3567
Episode: 5081/30000 (16.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5768s / 84.6231 s
agent0:                 episode reward: -0.0609,                 loss: nan
agent1:                 episode reward: 0.0609,                 loss: 0.3603
Episode: 5101/30000 (17.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5853s / 85.2084 s
agent0:                 episode reward: -0.1986,                 loss: nan
agent1:                 episode reward: 0.1986,                 loss: 0.3601
Episode: 5121/30000 (17.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5956s / 85.8040 s
agent0:                 episode reward: -0.9376,                 loss: nan
agent1:                 episode reward: 0.9376,                 loss: 0.3563
Episode: 5141/30000 (17.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5967s / 86.4007 s
agent0:                 episode reward: -0.6559,                 loss: nan
agent1:                 episode reward: 0.6559,                 loss: 0.3618
Episode: 5161/30000 (17.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5942s / 86.9949 s
agent0:                 episode reward: -0.4808,                 loss: nan
agent1:                 episode reward: 0.4808,                 loss: 0.3584
Episode: 5181/30000 (17.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5906s / 87.5855 s
agent0:                 episode reward: -0.6700,                 loss: nan
agent1:                 episode reward: 0.6700,                 loss: 0.3573
Episode: 5201/30000 (17.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5952s / 88.1807 s
agent0:                 episode reward: -0.6509,                 loss: nan
agent1:                 episode reward: 0.6509,                 loss: 0.3553
Episode: 5221/30000 (17.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5988s / 88.7795 s
agent0:                 episode reward: -0.5039,                 loss: nan
agent1:                 episode reward: 0.5039,                 loss: 0.3558
Episode: 5241/30000 (17.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5939s / 89.3734 s
agent0:                 episode reward: -0.8069,                 loss: nan
agent1:                 episode reward: 0.8069,                 loss: 0.3563
Episode: 5261/30000 (17.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5922s / 89.9655 s
agent0:                 episode reward: -0.9469,                 loss: nan
agent1:                 episode reward: 0.9469,                 loss: 0.3532
Episode: 5281/30000 (17.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5919s / 90.5575 s
agent0:                 episode reward: -0.5245,                 loss: nan
agent1:                 episode reward: 0.5245,                 loss: 0.3569
Episode: 5301/30000 (17.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5947s / 91.1521 s
agent0:                 episode reward: -0.5273,                 loss: nan
agent1:                 episode reward: 0.5273,                 loss: 0.3523
Episode: 5321/30000 (17.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5905s / 91.7426 s
agent0:                 episode reward: -0.6660,                 loss: nan
agent1:                 episode reward: 0.6660,                 loss: 0.3534
Episode: 5341/30000 (17.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5982s / 92.3408 s
agent0:                 episode reward: -0.7455,                 loss: nan
agent1:                 episode reward: 0.7455,                 loss: 0.3376
Episode: 5361/30000 (17.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5975s / 92.9383 s
agent0:                 episode reward: -0.7614,                 loss: nan
agent1:                 episode reward: 0.7614,                 loss: 0.3098
Episode: 5381/30000 (17.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5945s / 93.5328 s
agent0:                 episode reward: -0.6963,                 loss: nan
agent1:                 episode reward: 0.6963,                 loss: 0.3111
Episode: 5401/30000 (18.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5947s / 94.1275 s
agent0:                 episode reward: -0.7786,                 loss: nan
agent1:                 episode reward: 0.7786,                 loss: 0.3068
Episode: 5421/30000 (18.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5923s / 94.7199 s
agent0:                 episode reward: -0.5005,                 loss: nan
agent1:                 episode reward: 0.5005,                 loss: 0.3124
Episode: 5441/30000 (18.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5962s / 95.3161 s
agent0:                 episode reward: -0.5393,                 loss: nan
agent1:                 episode reward: 0.5393,                 loss: 0.3145
Episode: 5461/30000 (18.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5912s / 95.9073 s
agent0:                 episode reward: -0.5522,                 loss: nan
agent1:                 episode reward: 0.5522,                 loss: 0.3108
Episode: 5481/30000 (18.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5954s / 96.5027 s
agent0:                 episode reward: -0.2577,                 loss: nan
agent1:                 episode reward: 0.2577,                 loss: 0.3089
Episode: 5501/30000 (18.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5899s / 97.0925 s
agent0:                 episode reward: -0.4861,                 loss: nan
agent1:                 episode reward: 0.4861,                 loss: 0.3091
Episode: 5521/30000 (18.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5936s / 97.6861 s
agent0:                 episode reward: -0.4539,                 loss: nan
agent1:                 episode reward: 0.4539,                 loss: 0.3081
Episode: 5541/30000 (18.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5936s / 98.2798 s
agent0:                 episode reward: -0.2332,                 loss: nan
agent1:                 episode reward: 0.2332,                 loss: 0.3086
Episode: 5561/30000 (18.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5896s / 98.8693 s
agent0:                 episode reward: -0.3816,                 loss: nan
agent1:                 episode reward: 0.3816,                 loss: 0.3090
Episode: 5581/30000 (18.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5993s / 99.4687 s
agent0:                 episode reward: -0.3378,                 loss: nan
agent1:                 episode reward: 0.3378,                 loss: 0.3052
Episode: 5601/30000 (18.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5822s / 100.0508 s
agent0:                 episode reward: -0.3470,                 loss: nan
agent1:                 episode reward: 0.3470,                 loss: 0.3120
Episode: 5621/30000 (18.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5910s / 100.6418 s
agent0:                 episode reward: -0.4053,                 loss: nan
agent1:                 episode reward: 0.4053,                 loss: 0.3083
Episode: 5641/30000 (18.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5954s / 101.2372 s
agent0:                 episode reward: -0.4974,                 loss: nan
agent1:                 episode reward: 0.4974,                 loss: 0.3107
Episode: 5661/30000 (18.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5946s / 101.8319 s
agent0:                 episode reward: -0.6311,                 loss: nan
agent1:                 episode reward: 0.6311,                 loss: 0.3094
Episode: 5681/30000 (18.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5856s / 102.4175 s
agent0:                 episode reward: -0.4375,                 loss: nan
agent1:                 episode reward: 0.4375,                 loss: 0.3096
Episode: 5701/30000 (19.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5932s / 103.0107 s
agent0:                 episode reward: -0.0581,                 loss: nan
agent1:                 episode reward: 0.0581,                 loss: 0.3081
Episode: 5721/30000 (19.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5889s / 103.5996 s
agent0:                 episode reward: -0.6232,                 loss: nan
agent1:                 episode reward: 0.6232,                 loss: 0.3113
Episode: 5741/30000 (19.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5908s / 104.1904 s
agent0:                 episode reward: -0.2344,                 loss: nan
agent1:                 episode reward: 0.2344,                 loss: 0.3067
Episode: 5761/30000 (19.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5943s / 104.7847 s
agent0:                 episode reward: -0.8480,                 loss: nan
agent1:                 episode reward: 0.8480,                 loss: 0.3058
Episode: 5781/30000 (19.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5969s / 105.3816 s
agent0:                 episode reward: -0.1148,                 loss: nan
agent1:                 episode reward: 0.1148,                 loss: 0.3107
Episode: 5801/30000 (19.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5942s / 105.9758 s
agent0:                 episode reward: -0.2945,                 loss: nan
agent1:                 episode reward: 0.2945,                 loss: 0.3095
Episode: 5821/30000 (19.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5893s / 106.5651 s
agent0:                 episode reward: -0.4196,                 loss: nan
agent1:                 episode reward: 0.4196,                 loss: 0.3113
Episode: 5841/30000 (19.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5941s / 107.1592 s
agent0:                 episode reward: -0.5185,                 loss: nan
agent1:                 episode reward: 0.5185,                 loss: 0.3114
Episode: 5861/30000 (19.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5864s / 107.7456 s
agent0:                 episode reward: -0.3778,                 loss: nan
agent1:                 episode reward: 0.3778,                 loss: 0.3091
Episode: 5881/30000 (19.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5926s / 108.3382 s
agent0:                 episode reward: -0.0044,                 loss: nan
agent1:                 episode reward: 0.0044,                 loss: 0.3093
Episode: 5901/30000 (19.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5876s / 108.9259 s
agent0:                 episode reward: -0.3433,                 loss: nan
agent1:                 episode reward: 0.3433,                 loss: 0.3095
Episode: 5921/30000 (19.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5898s / 109.5157 s
agent0:                 episode reward: -0.2588,                 loss: nan
agent1:                 episode reward: 0.2588,                 loss: 0.3133
Episode: 5941/30000 (19.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5895s / 110.1051 s
agent0:                 episode reward: -0.4571,                 loss: nan
agent1:                 episode reward: 0.4571,                 loss: 0.3109
Episode: 5961/30000 (19.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5984s / 110.7036 s
agent0:                 episode reward: -0.2704,                 loss: nan
agent1:                 episode reward: 0.2704,                 loss: 0.3123
Episode: 5981/30000 (19.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5904s / 111.2939 s
agent0:                 episode reward: -0.9099,                 loss: nan
agent1:                 episode reward: 0.9099,                 loss: 0.3136
Episode: 6001/30000 (20.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6087s / 111.9026 s
agent0:                 episode reward: -0.1702,                 loss: nan
agent1:                 episode reward: 0.1702,                 loss: 0.3101
Episode: 6021/30000 (20.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6124s / 112.5151 s
agent0:                 episode reward: -0.5787,                 loss: nan
agent1:                 episode reward: 0.5787,                 loss: 0.3356
Episode: 6041/30000 (20.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6075s / 113.1226 s
agent0:                 episode reward: -0.3629,                 loss: nan
agent1:                 episode reward: 0.3629,                 loss: 0.3319
Episode: 6061/30000 (20.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5999s / 113.7225 s
agent0:                 episode reward: -0.7119,                 loss: nan
agent1:                 episode reward: 0.7119,                 loss: 0.3347
Episode: 6081/30000 (20.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6033s / 114.3257 s
agent0:                 episode reward: -0.5485,                 loss: nan
agent1:                 episode reward: 0.5485,                 loss: 0.3312
Episode: 6101/30000 (20.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6002s / 114.9260 s
agent0:                 episode reward: -0.6801,                 loss: nan
agent1:                 episode reward: 0.6801,                 loss: 0.3313
Episode: 6121/30000 (20.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5903s / 115.5162 s
agent0:                 episode reward: -0.3092,                 loss: nan
agent1:                 episode reward: 0.3092,                 loss: 0.3349
Episode: 6141/30000 (20.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5976s / 116.1138 s
agent0:                 episode reward: -0.3439,                 loss: nan
agent1:                 episode reward: 0.3439,                 loss: 0.3337
Episode: 6161/30000 (20.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5942s / 116.7080 s
agent0:                 episode reward: -0.7064,                 loss: nan
agent1:                 episode reward: 0.7064,                 loss: 0.3303
Episode: 6181/30000 (20.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5970s / 117.3050 s
agent0:                 episode reward: -0.6825,                 loss: nan
agent1:                 episode reward: 0.6825,                 loss: 0.3352
Episode: 6201/30000 (20.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6018s / 117.9069 s
agent0:                 episode reward: -0.7604,                 loss: nan
agent1:                 episode reward: 0.7604,                 loss: 0.3322
Episode: 6221/30000 (20.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5902s / 118.4971 s
agent0:                 episode reward: -0.3110,                 loss: nan
agent1:                 episode reward: 0.3110,                 loss: 0.3334
Episode: 6241/30000 (20.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5848s / 119.0819 s
agent0:                 episode reward: -0.5285,                 loss: nan
agent1:                 episode reward: 0.5285,                 loss: 0.3297
Episode: 6261/30000 (20.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6004s / 119.6823 s
agent0:                 episode reward: -0.9015,                 loss: nan
agent1:                 episode reward: 0.9015,                 loss: 0.3311
Episode: 6281/30000 (20.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5920s / 120.2743 s
agent0:                 episode reward: -0.5823,                 loss: nan
agent1:                 episode reward: 0.5823,                 loss: 0.3337
Episode: 6301/30000 (21.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5910s / 120.8653 s
agent0:                 episode reward: -0.4498,                 loss: nan
agent1:                 episode reward: 0.4498,                 loss: 0.3359
Episode: 6321/30000 (21.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5930s / 121.4584 s
agent0:                 episode reward: -0.5983,                 loss: nan
agent1:                 episode reward: 0.5983,                 loss: 0.3341
Episode: 6341/30000 (21.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5989s / 122.0573 s
agent0:                 episode reward: -0.4465,                 loss: nan
agent1:                 episode reward: 0.4465,                 loss: 0.3276
Episode: 6361/30000 (21.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6053s / 122.6626 s
agent0:                 episode reward: -0.5202,                 loss: nan
agent1:                 episode reward: 0.5202,                 loss: 0.3224
Episode: 6381/30000 (21.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5993s / 123.2619 s
agent0:                 episode reward: -0.4303,                 loss: nan
agent1:                 episode reward: 0.4303,                 loss: 0.3216
Episode: 6401/30000 (21.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6019s / 123.8639 s
agent0:                 episode reward: -0.2643,                 loss: nan
agent1:                 episode reward: 0.2643,                 loss: 0.3248
Episode: 6421/30000 (21.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5948s / 124.4586 s
agent0:                 episode reward: -0.4023,                 loss: nan
agent1:                 episode reward: 0.4023,                 loss: 0.3245
Episode: 6441/30000 (21.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5979s / 125.0565 s
agent0:                 episode reward: -0.6471,                 loss: nan
agent1:                 episode reward: 0.6471,                 loss: 0.3184
Episode: 6461/30000 (21.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6039s / 125.6604 s
agent0:                 episode reward: -0.2282,                 loss: nan
agent1:                 episode reward: 0.2282,                 loss: 0.3225
Episode: 6481/30000 (21.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5968s / 126.2573 s
agent0:                 episode reward: -0.4697,                 loss: nan
agent1:                 episode reward: 0.4697,                 loss: 0.3236
Episode: 6501/30000 (21.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5980s / 126.8552 s
agent0:                 episode reward: -0.5969,                 loss: nan
agent1:                 episode reward: 0.5969,                 loss: 0.3248
Episode: 6521/30000 (21.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5984s / 127.4537 s
agent0:                 episode reward: -0.2844,                 loss: nan
agent1:                 episode reward: 0.2844,                 loss: 0.3229
Episode: 6541/30000 (21.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5969s / 128.0506 s
agent0:                 episode reward: -0.6261,                 loss: nan
agent1:                 episode reward: 0.6261,                 loss: 0.3215
Episode: 6561/30000 (21.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6149s / 128.6656 s
agent0:                 episode reward: -0.8002,                 loss: nan
agent1:                 episode reward: 0.8002,                 loss: 0.3240
Episode: 6581/30000 (21.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5976s / 129.2632 s
agent0:                 episode reward: -0.9330,                 loss: nan
agent1:                 episode reward: 0.9330,                 loss: 0.3176
Episode: 6601/30000 (22.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5964s / 129.8596 s
agent0:                 episode reward: -0.4585,                 loss: nan
agent1:                 episode reward: 0.4585,                 loss: 0.3203
Episode: 6621/30000 (22.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5982s / 130.4577 s
agent0:                 episode reward: -0.4819,                 loss: nan
agent1:                 episode reward: 0.4819,                 loss: 0.3218
Episode: 6641/30000 (22.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6006s / 131.0583 s
agent0:                 episode reward: -0.3299,                 loss: nan
agent1:                 episode reward: 0.3299,                 loss: 0.3203
Episode: 6661/30000 (22.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5968s / 131.6551 s
agent0:                 episode reward: -0.5191,                 loss: nan
agent1:                 episode reward: 0.5191,                 loss: 0.3192
Episode: 6681/30000 (22.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6051s / 132.2602 s
agent0:                 episode reward: -0.5444,                 loss: nan
agent1:                 episode reward: 0.5444,                 loss: 0.3163
Episode: 6701/30000 (22.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6003s / 132.8605 s
agent0:                 episode reward: -0.1813,                 loss: nan
agent1:                 episode reward: 0.1813,                 loss: 0.3206
Episode: 6721/30000 (22.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5900s / 133.4505 s
agent0:                 episode reward: -0.5471,                 loss: nan
agent1:                 episode reward: 0.5471,                 loss: 0.3225
Episode: 6741/30000 (22.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5942s / 134.0447 s
agent0:                 episode reward: -0.6469,                 loss: nan
agent1:                 episode reward: 0.6469,                 loss: 0.3202
Episode: 6761/30000 (22.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5995s / 134.6442 s
agent0:                 episode reward: -0.6443,                 loss: nan
agent1:                 episode reward: 0.6443,                 loss: 0.3193
Episode: 6781/30000 (22.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5935s / 135.2377 s
agent0:                 episode reward: -0.4789,                 loss: nan
agent1:                 episode reward: 0.4789,                 loss: 0.3193
Episode: 6801/30000 (22.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5913s / 135.8290 s
agent0:                 episode reward: -0.4838,                 loss: nan
agent1:                 episode reward: 0.4838,                 loss: 0.3222
Episode: 6821/30000 (22.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6484s / 136.4774 s
agent0:                 episode reward: -0.6226,                 loss: nan
agent1:                 episode reward: 0.6226,                 loss: 0.3234
Episode: 6841/30000 (22.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6147s / 137.0921 s
agent0:                 episode reward: -0.5750,                 loss: nan
agent1:                 episode reward: 0.5750,                 loss: 0.3229
Episode: 6861/30000 (22.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5928s / 137.6850 s
agent0:                 episode reward: -0.6856,                 loss: nan
agent1:                 episode reward: 0.6856,                 loss: 0.3214
Episode: 6881/30000 (22.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5972s / 138.2822 s
agent0:                 episode reward: -0.7307,                 loss: nan
agent1:                 episode reward: 0.7307,                 loss: 0.3208
Episode: 6901/30000 (23.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5973s / 138.8795 s
agent0:                 episode reward: -0.4659,                 loss: nan
agent1:                 episode reward: 0.4659,                 loss: 0.3208
Episode: 6921/30000 (23.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5874s / 139.4669 s
agent0:                 episode reward: -0.5531,                 loss: nan
agent1:                 episode reward: 0.5531,                 loss: 0.3216
Episode: 6941/30000 (23.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6047s / 140.0717 s
agent0:                 episode reward: -0.2388,                 loss: nan
agent1:                 episode reward: 0.2388,                 loss: 0.3210
Episode: 6961/30000 (23.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5980s / 140.6697 s
agent0:                 episode reward: -0.3111,                 loss: nan
agent1:                 episode reward: 0.3111,                 loss: 0.3199
Episode: 6981/30000 (23.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5969s / 141.2666 s
agent0:                 episode reward: -0.2603,                 loss: nan
agent1:                 episode reward: 0.2603,                 loss: 0.3196
Episode: 7001/30000 (23.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5987s / 141.8654 s
agent0:                 episode reward: -0.5373,                 loss: nan
agent1:                 episode reward: 0.5373,                 loss: 0.3232
Episode: 7021/30000 (23.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5943s / 142.4597 s
agent0:                 episode reward: -0.4541,                 loss: nan
agent1:                 episode reward: 0.4541,                 loss: 0.3282
Episode: 7041/30000 (23.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6019s / 143.0616 s
agent0:                 episode reward: -0.8932,                 loss: nan
agent1:                 episode reward: 0.8932,                 loss: 0.3276
Episode: 7061/30000 (23.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5990s / 143.6606 s
agent0:                 episode reward: -0.9510,                 loss: nan
agent1:                 episode reward: 0.9510,                 loss: 0.3338
Episode: 7081/30000 (23.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6038s / 144.2645 s
agent0:                 episode reward: -0.7673,                 loss: nan
agent1:                 episode reward: 0.7673,                 loss: 0.3359
Episode: 7101/30000 (23.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5994s / 144.8638 s
agent0:                 episode reward: -0.3948,                 loss: nan
agent1:                 episode reward: 0.3948,                 loss: 0.3345
Episode: 7121/30000 (23.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6024s / 145.4662 s
agent0:                 episode reward: -0.4208,                 loss: nan
agent1:                 episode reward: 0.4208,                 loss: 0.3294
Episode: 7141/30000 (23.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6009s / 146.0670 s
agent0:                 episode reward: -0.6918,                 loss: nan
agent1:                 episode reward: 0.6918,                 loss: 0.3323
Episode: 7161/30000 (23.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6057s / 146.6727 s
agent0:                 episode reward: -0.6652,                 loss: nan
agent1:                 episode reward: 0.6652,                 loss: 0.3318
Episode: 7181/30000 (23.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6057s / 147.2784 s
agent0:                 episode reward: -0.6062,                 loss: nan
agent1:                 episode reward: 0.6062,                 loss: 0.3324
Episode: 7201/30000 (24.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6035s / 147.8819 s
agent0:                 episode reward: -0.6003,                 loss: nan
agent1:                 episode reward: 0.6003,                 loss: 0.3315
Episode: 7221/30000 (24.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6025s / 148.4844 s
agent0:                 episode reward: -0.6768,                 loss: nan
agent1:                 episode reward: 0.6768,                 loss: 0.3362
Episode: 7241/30000 (24.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5967s / 149.0811 s
agent0:                 episode reward: -0.8894,                 loss: nan
agent1:                 episode reward: 0.8894,                 loss: 0.3363
Episode: 7261/30000 (24.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5984s / 149.6794 s
agent0:                 episode reward: -0.5689,                 loss: nan
agent1:                 episode reward: 0.5689,                 loss: 0.3322
Episode: 7281/30000 (24.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6197s / 150.2992 s
agent0:                 episode reward: -0.5043,                 loss: nan
agent1:                 episode reward: 0.5043,                 loss: 0.3348
Episode: 7301/30000 (24.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 1.0260s / 151.3252 s
agent0:                 episode reward: -1.1341,                 loss: nan
agent1:                 episode reward: 1.1341,                 loss: 0.3295
Episode: 7321/30000 (24.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9816s / 152.3067 s
agent0:                 episode reward: -0.8945,                 loss: nan
agent1:                 episode reward: 0.8945,                 loss: 0.3356
Episode: 7341/30000 (24.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8989s / 153.2056 s
agent0:                 episode reward: -0.6336,                 loss: nan
agent1:                 episode reward: 0.6336,                 loss: 0.3292
Episode: 7361/30000 (24.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8232s / 154.0288 s
agent0:                 episode reward: -0.3971,                 loss: nan
agent1:                 episode reward: 0.3971,                 loss: 0.3246
Episode: 7381/30000 (24.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7403s / 154.7691 s
agent0:                 episode reward: -0.7199,                 loss: nan
agent1:                 episode reward: 0.7199,                 loss: 0.3252
Episode: 7401/30000 (24.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6900s / 155.4591 s
agent0:                 episode reward: -0.5531,                 loss: nan
agent1:                 episode reward: 0.5531,                 loss: 0.3227
Episode: 7421/30000 (24.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6405s / 156.0996 s
agent0:                 episode reward: -0.5907,                 loss: nan
agent1:                 episode reward: 0.5907,                 loss: 0.3234
Episode: 7441/30000 (24.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6064s / 156.7061 s
agent0:                 episode reward: -0.8001,                 loss: nan
agent1:                 episode reward: 0.8001,                 loss: 0.3273
Episode: 7461/30000 (24.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5995s / 157.3056 s
agent0:                 episode reward: -0.4507,                 loss: nan
agent1:                 episode reward: 0.4507,                 loss: 0.3246
Episode: 7481/30000 (24.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5964s / 157.9020 s
agent0:                 episode reward: -0.6043,                 loss: nan
agent1:                 episode reward: 0.6043,                 loss: 0.3287
Episode: 7501/30000 (25.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6044s / 158.5063 s
agent0:                 episode reward: -0.3660,                 loss: nan
agent1:                 episode reward: 0.3660,                 loss: 0.3250
Episode: 7521/30000 (25.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5990s / 159.1053 s
agent0:                 episode reward: -0.3584,                 loss: nan
agent1:                 episode reward: 0.3584,                 loss: 0.3242
Episode: 7541/30000 (25.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6010s / 159.7063 s
agent0:                 episode reward: -0.6971,                 loss: nan
agent1:                 episode reward: 0.6971,                 loss: 0.3273
Episode: 7561/30000 (25.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5937s / 160.3000 s
agent0:                 episode reward: -0.6447,                 loss: nan
agent1:                 episode reward: 0.6447,                 loss: 0.3239
Episode: 7581/30000 (25.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6078s / 160.9078 s
agent0:                 episode reward: -0.5961,                 loss: nan
agent1:                 episode reward: 0.5961,                 loss: 0.3247
Episode: 7601/30000 (25.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6058s / 161.5136 s
agent0:                 episode reward: -0.6365,                 loss: nan
agent1:                 episode reward: 0.6365,                 loss: 0.3247
Episode: 7621/30000 (25.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5926s / 162.1062 s
agent0:                 episode reward: -0.4154,                 loss: nan
agent1:                 episode reward: 0.4154,                 loss: 0.3244