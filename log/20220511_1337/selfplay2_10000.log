2022-05-11 13:37:49.573621: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia:/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia
2022-05-11 13:37:49.573683: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia:/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia
2022-05-11 13:37:49.573688: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
pygame 2.0.1 (SDL 2.0.14, Python 3.6.13)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 12.0, (1,), float32) action space: Discrete(3)
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7fc155f3a128>
3 3 3
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
Error: no exploited model index given!
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  data/model/20220511131205/mdp_arbitrary_mdp_selfplay2/10000_0
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': 1, 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 1.0, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 8000}, 'num_process': 1, 'batch_size': 640, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220511131205/mdp_arbitrary_mdp_selfplay2/10000_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 1000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'selfplay2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'selfplay_score_delta': 1.5, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'against_baseline': False}
Save models to : /home/quantumiracle/research/MARS/data/model/20220511131205_exploit_10000/mdp_arbitrary_mdp_selfplay2. 
 Save logs to: /home/quantumiracle/research/MARS/data/log/20220511131205_exploit_10000/mdp_arbitrary_mdp_selfplay2.
Episode: 1/30000 (0.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8444s / 0.8444 s
agent0:                 episode reward: 0.1899,                 loss: nan
agent1:                 episode reward: -0.1899,                 loss: nan
Episode: 21/30000 (0.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0223s / 0.8667 s
agent0:                 episode reward: 0.0402,                 loss: nan
agent1:                 episode reward: -0.0402,                 loss: nan
Episode: 41/30000 (0.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0283s / 0.8949 s
agent0:                 episode reward: -0.0033,                 loss: nan
agent1:                 episode reward: 0.0033,                 loss: nan
Episode: 61/30000 (0.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0237s / 0.9186 s
agent0:                 episode reward: -0.0160,                 loss: nan
agent1:                 episode reward: 0.0160,                 loss: nan
Episode: 81/30000 (0.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0231s / 0.9417 s
agent0:                 episode reward: 0.1569,                 loss: nan
agent1:                 episode reward: -0.1569,                 loss: nan
Episode: 101/30000 (0.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0232s / 0.9649 s
agent0:                 episode reward: 0.2851,                 loss: nan
agent1:                 episode reward: -0.2851,                 loss: nan
Episode: 121/30000 (0.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0227s / 0.9876 s
agent0:                 episode reward: -0.3480,                 loss: nan
agent1:                 episode reward: 0.3480,                 loss: nan
Episode: 141/30000 (0.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0230s / 1.0106 s
agent0:                 episode reward: -0.1635,                 loss: nan
agent1:                 episode reward: 0.1635,                 loss: nan
Episode: 161/30000 (0.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0308s / 1.0414 s
agent0:                 episode reward: 0.0837,                 loss: nan
agent1:                 episode reward: -0.0837,                 loss: nan
Episode: 181/30000 (0.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0247s / 1.0661 s
agent0:                 episode reward: -0.5198,                 loss: nan
agent1:                 episode reward: 0.5198,                 loss: nan
Episode: 201/30000 (0.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0290s / 1.0951 s
agent0:                 episode reward: 0.2144,                 loss: nan
agent1:                 episode reward: -0.2144,                 loss: nan
Episode: 221/30000 (0.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0978s / 1.1929 s
agent0:                 episode reward: -0.1178,                 loss: nan
agent1:                 episode reward: 0.1178,                 loss: 0.4445
Episode: 241/30000 (0.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2461s / 1.4389 s
agent0:                 episode reward: 0.2350,                 loss: nan
agent1:                 episode reward: -0.2350,                 loss: 0.4234
Episode: 261/30000 (0.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2215s / 1.6604 s
agent0:                 episode reward: -0.0125,                 loss: nan
agent1:                 episode reward: 0.0125,                 loss: 0.4002
Episode: 281/30000 (0.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2137s / 1.8741 s
agent0:                 episode reward: -0.3209,                 loss: nan
agent1:                 episode reward: 0.3209,                 loss: 0.3842
Episode: 301/30000 (1.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2163s / 2.0904 s
agent0:                 episode reward: 0.3370,                 loss: nan
agent1:                 episode reward: -0.3370,                 loss: 0.3734
Episode: 321/30000 (1.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2129s / 2.3033 s
agent0:                 episode reward: -0.0497,                 loss: nan
agent1:                 episode reward: 0.0497,                 loss: 0.3592
Episode: 341/30000 (1.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2156s / 2.5188 s
agent0:                 episode reward: -0.2559,                 loss: nan
agent1:                 episode reward: 0.2559,                 loss: 0.3481
Episode: 361/30000 (1.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2408s / 2.7596 s
agent0:                 episode reward: 0.1501,                 loss: nan
agent1:                 episode reward: -0.1501,                 loss: 0.3359
Episode: 381/30000 (1.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2218s / 2.9815 s
agent0:                 episode reward: -0.7217,                 loss: nan
agent1:                 episode reward: 0.7217,                 loss: 0.3289
Episode: 401/30000 (1.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2134s / 3.1949 s
agent0:                 episode reward: 0.1936,                 loss: nan
agent1:                 episode reward: -0.1936,                 loss: 0.3263
Episode: 421/30000 (1.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2255s / 3.4204 s
agent0:                 episode reward: -0.6856,                 loss: nan
agent1:                 episode reward: 0.6856,                 loss: 0.3218
Episode: 441/30000 (1.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2271s / 3.6476 s
agent0:                 episode reward: 0.1563,                 loss: nan
agent1:                 episode reward: -0.1563,                 loss: 0.3197
Episode: 461/30000 (1.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2226s / 3.8702 s
agent0:                 episode reward: -0.4946,                 loss: nan
agent1:                 episode reward: 0.4946,                 loss: 0.3221
Episode: 481/30000 (1.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2209s / 4.0911 s
agent0:                 episode reward: -0.1442,                 loss: nan
agent1:                 episode reward: 0.1442,                 loss: 0.3181
Episode: 501/30000 (1.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2223s / 4.3134 s
agent0:                 episode reward: -0.0379,                 loss: nan
agent1:                 episode reward: 0.0379,                 loss: 0.3166
Episode: 521/30000 (1.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2168s / 4.5301 s
agent0:                 episode reward: -0.4148,                 loss: nan
agent1:                 episode reward: 0.4148,                 loss: 0.3111
Episode: 541/30000 (1.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2229s / 4.7531 s
agent0:                 episode reward: -0.2632,                 loss: nan
agent1:                 episode reward: 0.2632,                 loss: 0.3122
Episode: 561/30000 (1.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2212s / 4.9743 s
agent0:                 episode reward: -0.0153,                 loss: nan
agent1:                 episode reward: 0.0153,                 loss: 0.2838
Episode: 581/30000 (1.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2188s / 5.1931 s
agent0:                 episode reward: -0.2844,                 loss: nan
agent1:                 episode reward: 0.2844,                 loss: 0.2631
Episode: 601/30000 (2.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2254s / 5.4184 s
agent0:                 episode reward: 0.2814,                 loss: nan
agent1:                 episode reward: -0.2814,                 loss: 0.2579
Episode: 621/30000 (2.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2235s / 5.6420 s
agent0:                 episode reward: -0.6054,                 loss: nan
agent1:                 episode reward: 0.6054,                 loss: 0.2560
Episode: 641/30000 (2.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2275s / 5.8694 s
agent0:                 episode reward: -0.2772,                 loss: nan
agent1:                 episode reward: 0.2772,                 loss: 0.2531
Episode: 661/30000 (2.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2200s / 6.0894 s
agent0:                 episode reward: -0.1863,                 loss: nan
agent1:                 episode reward: 0.1863,                 loss: 0.2506
Episode: 681/30000 (2.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2225s / 6.3119 s
agent0:                 episode reward: -0.4302,                 loss: nan
agent1:                 episode reward: 0.4302,                 loss: 0.2478
Episode: 701/30000 (2.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2260s / 6.5379 s
agent0:                 episode reward: -0.3727,                 loss: nan
agent1:                 episode reward: 0.3727,                 loss: 0.2455
Episode: 721/30000 (2.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2253s / 6.7632 s
agent0:                 episode reward: -0.1500,                 loss: nan
agent1:                 episode reward: 0.1500,                 loss: 0.2460
Episode: 741/30000 (2.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2255s / 6.9887 s
agent0:                 episode reward: -0.3206,                 loss: nan
agent1:                 episode reward: 0.3206,                 loss: 0.2460
Episode: 761/30000 (2.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2249s / 7.2136 s
agent0:                 episode reward: -0.4255,                 loss: nan
agent1:                 episode reward: 0.4255,                 loss: 0.2450
Episode: 781/30000 (2.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2143s / 7.4278 s
agent0:                 episode reward: -0.2128,                 loss: nan
agent1:                 episode reward: 0.2128,                 loss: 0.2444
Episode: 801/30000 (2.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2233s / 7.6511 s
agent0:                 episode reward: -0.6121,                 loss: nan
agent1:                 episode reward: 0.6121,                 loss: 0.2426
Episode: 821/30000 (2.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2294s / 7.8805 s
agent0:                 episode reward: -0.7123,                 loss: nan
agent1:                 episode reward: 0.7123,                 loss: 0.2419
Episode: 841/30000 (2.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2267s / 8.1072 s
agent0:                 episode reward: 0.0338,                 loss: nan
agent1:                 episode reward: -0.0338,                 loss: 0.2433
Episode: 861/30000 (2.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2269s / 8.3341 s
agent0:                 episode reward: -0.1718,                 loss: nan
agent1:                 episode reward: 0.1718,                 loss: 0.2458
Episode: 881/30000 (2.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2865s / 8.6206 s
agent0:                 episode reward: -0.4031,                 loss: nan
agent1:                 episode reward: 0.4031,                 loss: 0.2458
Episode: 901/30000 (3.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2343s / 8.8549 s
agent0:                 episode reward: 0.0526,                 loss: nan
agent1:                 episode reward: -0.0526,                 loss: 0.2645
Episode: 921/30000 (3.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2298s / 9.0847 s
agent0:                 episode reward: -0.4079,                 loss: nan
agent1:                 episode reward: 0.4079,                 loss: 0.2590
Episode: 941/30000 (3.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2448s / 9.3295 s
agent0:                 episode reward: -0.3848,                 loss: nan
agent1:                 episode reward: 0.3848,                 loss: 0.2563
Episode: 961/30000 (3.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2341s / 9.5636 s
agent0:                 episode reward: -0.6307,                 loss: nan
agent1:                 episode reward: 0.6307,                 loss: 0.2539
Episode: 981/30000 (3.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2284s / 9.7919 s
agent0:                 episode reward: -0.4382,                 loss: nan
agent1:                 episode reward: 0.4382,                 loss: 0.2568
Episode: 1001/30000 (3.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2320s / 10.0239 s
agent0:                 episode reward: -0.4633,                 loss: nan
agent1:                 episode reward: 0.4633,                 loss: 0.2533
Episode: 1021/30000 (3.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2311s / 10.2550 s
agent0:                 episode reward: -0.4371,                 loss: nan
agent1:                 episode reward: 0.4371,                 loss: 0.2500
Episode: 1041/30000 (3.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2333s / 10.4883 s
agent0:                 episode reward: -0.3424,                 loss: nan
agent1:                 episode reward: 0.3424,                 loss: 0.2502
Episode: 1061/30000 (3.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2299s / 10.7182 s
agent0:                 episode reward: -0.6778,                 loss: nan
agent1:                 episode reward: 0.6778,                 loss: 0.2481
Episode: 1081/30000 (3.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2532s / 10.9714 s
agent0:                 episode reward: -0.3094,                 loss: nan
agent1:                 episode reward: 0.3094,                 loss: 0.2451
Episode: 1101/30000 (3.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2311s / 11.2026 s
agent0:                 episode reward: 0.0558,                 loss: nan
agent1:                 episode reward: -0.0558,                 loss: 0.2464
Episode: 1121/30000 (3.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2409s / 11.4435 s
agent0:                 episode reward: -0.3207,                 loss: nan
agent1:                 episode reward: 0.3207,                 loss: 0.2429
Episode: 1141/30000 (3.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2387s / 11.6823 s
agent0:                 episode reward: -0.5545,                 loss: nan
agent1:                 episode reward: 0.5545,                 loss: 0.2449
Episode: 1161/30000 (3.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2327s / 11.9150 s
agent0:                 episode reward: -0.1355,                 loss: nan
agent1:                 episode reward: 0.1355,                 loss: 0.2473
Episode: 1181/30000 (3.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2324s / 12.1474 s
agent0:                 episode reward: -0.4238,                 loss: nan
agent1:                 episode reward: 0.4238,                 loss: 0.2439
Episode: 1201/30000 (4.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2337s / 12.3810 s
agent0:                 episode reward: -0.5474,                 loss: nan
agent1:                 episode reward: 0.5474,                 loss: 0.2457
Episode: 1221/30000 (4.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2380s / 12.6190 s
agent0:                 episode reward: -0.4456,                 loss: nan
agent1:                 episode reward: 0.4456,                 loss: 0.2568
Episode: 1241/30000 (4.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2287s / 12.8478 s
agent0:                 episode reward: -0.4774,                 loss: nan
agent1:                 episode reward: 0.4774,                 loss: 0.2564
Episode: 1261/30000 (4.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2297s / 13.0775 s
agent0:                 episode reward: -0.4836,                 loss: nan
agent1:                 episode reward: 0.4836,                 loss: 0.2574
Episode: 1281/30000 (4.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2347s / 13.3122 s
agent0:                 episode reward: -0.3121,                 loss: nan
agent1:                 episode reward: 0.3121,                 loss: 0.2531
Episode: 1301/30000 (4.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2395s / 13.5517 s
agent0:                 episode reward: -0.2819,                 loss: nan
agent1:                 episode reward: 0.2819,                 loss: 0.2550
Episode: 1321/30000 (4.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2413s / 13.7930 s
agent0:                 episode reward: -0.6139,                 loss: nan
agent1:                 episode reward: 0.6139,                 loss: 0.2529
Episode: 1341/30000 (4.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2400s / 14.0329 s
agent0:                 episode reward: -0.6710,                 loss: nan
agent1:                 episode reward: 0.6710,                 loss: 0.2523
Episode: 1361/30000 (4.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2326s / 14.2655 s
agent0:                 episode reward: -0.5151,                 loss: nan
agent1:                 episode reward: 0.5151,                 loss: 0.2525
Episode: 1381/30000 (4.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2364s / 14.5019 s
agent0:                 episode reward: -0.4618,                 loss: nan
agent1:                 episode reward: 0.4618,                 loss: 0.2530
Episode: 1401/30000 (4.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2447s / 14.7466 s
agent0:                 episode reward: -0.6315,                 loss: nan
agent1:                 episode reward: 0.6315,                 loss: 0.2531
Episode: 1421/30000 (4.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2511s / 14.9977 s
agent0:                 episode reward: -0.4010,                 loss: nan
agent1:                 episode reward: 0.4010,                 loss: 0.2516
Episode: 1441/30000 (4.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2323s / 15.2300 s
agent0:                 episode reward: -0.2445,                 loss: nan
agent1:                 episode reward: 0.2445,                 loss: 0.2503
Episode: 1461/30000 (4.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2387s / 15.4686 s
agent0:                 episode reward: -0.5117,                 loss: nan
agent1:                 episode reward: 0.5117,                 loss: 0.2468
Episode: 1481/30000 (4.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2570s / 15.7256 s
agent0:                 episode reward: -0.4114,                 loss: nan
agent1:                 episode reward: 0.4114,                 loss: 0.2467
Episode: 1501/30000 (5.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2393s / 15.9649 s
agent0:                 episode reward: -0.6153,                 loss: nan
agent1:                 episode reward: 0.6153,                 loss: 0.2464
Episode: 1521/30000 (5.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2355s / 16.2004 s
agent0:                 episode reward: -0.4572,                 loss: nan
agent1:                 episode reward: 0.4572,                 loss: 0.2447
Episode: 1541/30000 (5.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2360s / 16.4364 s
agent0:                 episode reward: -0.1828,                 loss: nan
agent1:                 episode reward: 0.1828,                 loss: 0.2470
Episode: 1561/30000 (5.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2397s / 16.6761 s
agent0:                 episode reward: -0.6319,                 loss: nan
agent1:                 episode reward: 0.6319,                 loss: 0.2294
Episode: 1581/30000 (5.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2598s / 16.9359 s
agent0:                 episode reward: -0.4664,                 loss: nan
agent1:                 episode reward: 0.4664,                 loss: 0.2150
Episode: 1601/30000 (5.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2427s / 17.1786 s
agent0:                 episode reward: -0.8249,                 loss: nan
agent1:                 episode reward: 0.8249,                 loss: 0.2159
Episode: 1621/30000 (5.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2398s / 17.4184 s
agent0:                 episode reward: -0.2906,                 loss: nan
agent1:                 episode reward: 0.2906,                 loss: 0.2110
Episode: 1641/30000 (5.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2375s / 17.6559 s
agent0:                 episode reward: -0.8780,                 loss: nan
agent1:                 episode reward: 0.8780,                 loss: 0.2124
Episode: 1661/30000 (5.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2463s / 17.9022 s
agent0:                 episode reward: -0.7275,                 loss: nan
agent1:                 episode reward: 0.7275,                 loss: 0.2147
Episode: 1681/30000 (5.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2419s / 18.1441 s
agent0:                 episode reward: -0.4932,                 loss: nan
agent1:                 episode reward: 0.4932,                 loss: 0.2076
Episode: 1701/30000 (5.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2442s / 18.3883 s
agent0:                 episode reward: -0.5975,                 loss: nan
agent1:                 episode reward: 0.5975,                 loss: 0.2102
Episode: 1721/30000 (5.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2624s / 18.6506 s
agent0:                 episode reward: -0.5083,                 loss: nan
agent1:                 episode reward: 0.5083,                 loss: 0.2086
Episode: 1741/30000 (5.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2811s / 18.9317 s
agent0:                 episode reward: -0.6683,                 loss: nan
agent1:                 episode reward: 0.6683,                 loss: 0.2094
Episode: 1761/30000 (5.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2461s / 19.1778 s
agent0:                 episode reward: -0.6168,                 loss: nan
agent1:                 episode reward: 0.6168,                 loss: 0.2029
Episode: 1781/30000 (5.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2478s / 19.4256 s
agent0:                 episode reward: -0.0993,                 loss: nan
agent1:                 episode reward: 0.0993,                 loss: 0.2074
Episode: 1801/30000 (6.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2476s / 19.6731 s
agent0:                 episode reward: -0.7573,                 loss: nan
agent1:                 episode reward: 0.7573,                 loss: 0.2082
Episode: 1821/30000 (6.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2445s / 19.9176 s
agent0:                 episode reward: -0.3505,                 loss: nan
agent1:                 episode reward: 0.3505,                 loss: 0.2075
Episode: 1841/30000 (6.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2451s / 20.1627 s
agent0:                 episode reward: -0.3838,                 loss: nan
agent1:                 episode reward: 0.3838,                 loss: 0.2037
Episode: 1861/30000 (6.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2484s / 20.4111 s
agent0:                 episode reward: -0.3521,                 loss: nan
agent1:                 episode reward: 0.3521,                 loss: 0.2052
Episode: 1881/30000 (6.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2516s / 20.6627 s
agent0:                 episode reward: -0.8059,                 loss: nan
agent1:                 episode reward: 0.8059,                 loss: 0.2070
Episode: 1901/30000 (6.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2727s / 20.9354 s
agent0:                 episode reward: -0.4137,                 loss: nan
agent1:                 episode reward: 0.4137,                 loss: 0.2264
Episode: 1921/30000 (6.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2513s / 21.1868 s
agent0:                 episode reward: -0.6785,                 loss: nan
agent1:                 episode reward: 0.6785,                 loss: 0.2267
Episode: 1941/30000 (6.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2436s / 21.4303 s
agent0:                 episode reward: -0.1815,                 loss: nan
agent1:                 episode reward: 0.1815,                 loss: 0.2260
Episode: 1961/30000 (6.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2472s / 21.6775 s
agent0:                 episode reward: -0.8753,                 loss: nan
agent1:                 episode reward: 0.8753,                 loss: 0.2247
Episode: 1981/30000 (6.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2473s / 21.9248 s
agent0:                 episode reward: -0.3672,                 loss: nan
agent1:                 episode reward: 0.3672,                 loss: 0.2255
Episode: 2001/30000 (6.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2481s / 22.1729 s
agent0:                 episode reward: -0.4838,                 loss: nan
agent1:                 episode reward: 0.4838,                 loss: 0.2232
Episode: 2021/30000 (6.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2519s / 22.4248 s
agent0:                 episode reward: -0.8815,                 loss: nan
agent1:                 episode reward: 0.8815,                 loss: 0.2218
Episode: 2041/30000 (6.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2447s / 22.6695 s
agent0:                 episode reward: -0.6757,                 loss: nan
agent1:                 episode reward: 0.6757,                 loss: 0.2210
Episode: 2061/30000 (6.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2458s / 22.9153 s
agent0:                 episode reward: -0.7070,                 loss: nan
agent1:                 episode reward: 0.7070,                 loss: 0.2216
Episode: 2081/30000 (6.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2505s / 23.1659 s
agent0:                 episode reward: -1.1008,                 loss: nan
agent1:                 episode reward: 1.1008,                 loss: 0.2197
Episode: 2101/30000 (7.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2557s / 23.4215 s
agent0:                 episode reward: -0.7896,                 loss: nan
agent1:                 episode reward: 0.7896,                 loss: 0.2180
Episode: 2121/30000 (7.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2540s / 23.6756 s
agent0:                 episode reward: -0.5756,                 loss: nan
agent1:                 episode reward: 0.5756,                 loss: 0.2201
Episode: 2141/30000 (7.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2667s / 23.9422 s
agent0:                 episode reward: -0.5287,                 loss: nan
agent1:                 episode reward: 0.5287,                 loss: 0.2177
Episode: 2161/30000 (7.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2556s / 24.1979 s
agent0:                 episode reward: -0.1363,                 loss: nan
agent1:                 episode reward: 0.1363,                 loss: 0.2182
Episode: 2181/30000 (7.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2531s / 24.4509 s
agent0:                 episode reward: -0.5100,                 loss: nan
agent1:                 episode reward: 0.5100,                 loss: 0.2167
Episode: 2201/30000 (7.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2510s / 24.7020 s
agent0:                 episode reward: -0.5533,                 loss: nan
agent1:                 episode reward: 0.5533,                 loss: 0.2181
Episode: 2221/30000 (7.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2521s / 24.9540 s
agent0:                 episode reward: -0.3295,                 loss: nan
agent1:                 episode reward: 0.3295,                 loss: 0.2339
Episode: 2241/30000 (7.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2723s / 25.2263 s
agent0:                 episode reward: -0.5281,                 loss: nan
agent1:                 episode reward: 0.5281,                 loss: 0.2486
Episode: 2261/30000 (7.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2532s / 25.4795 s
agent0:                 episode reward: -0.5357,                 loss: nan
agent1:                 episode reward: 0.5357,                 loss: 0.2497
Episode: 2281/30000 (7.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2498s / 25.7293 s
agent0:                 episode reward: -0.1414,                 loss: nan
agent1:                 episode reward: 0.1414,                 loss: 0.2454
Episode: 2301/30000 (7.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2495s / 25.9788 s
agent0:                 episode reward: -0.6784,                 loss: nan
agent1:                 episode reward: 0.6784,                 loss: 0.2451
Episode: 2321/30000 (7.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2465s / 26.2253 s
agent0:                 episode reward: -0.8978,                 loss: nan
agent1:                 episode reward: 0.8978,                 loss: 0.2489
Episode: 2341/30000 (7.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2508s / 26.4761 s
agent0:                 episode reward: -0.2982,                 loss: nan
agent1:                 episode reward: 0.2982,                 loss: 0.2449
Episode: 2361/30000 (7.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2526s / 26.7286 s
agent0:                 episode reward: -0.8563,                 loss: nan
agent1:                 episode reward: 0.8563,                 loss: 0.2432
Episode: 2381/30000 (7.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2648s / 26.9935 s
agent0:                 episode reward: -0.5505,                 loss: nan
agent1:                 episode reward: 0.5505,                 loss: 0.2410
Episode: 2401/30000 (8.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2518s / 27.2453 s
agent0:                 episode reward: -0.7803,                 loss: nan
agent1:                 episode reward: 0.7803,                 loss: 0.2417
Episode: 2421/30000 (8.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2576s / 27.5029 s
agent0:                 episode reward: -0.4892,                 loss: nan
agent1:                 episode reward: 0.4892,                 loss: 0.2457
Episode: 2441/30000 (8.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2574s / 27.7603 s
agent0:                 episode reward: -0.8017,                 loss: nan
agent1:                 episode reward: 0.8017,                 loss: 0.2407
Episode: 2461/30000 (8.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2569s / 28.0172 s
agent0:                 episode reward: -0.8066,                 loss: nan
agent1:                 episode reward: 0.8066,                 loss: 0.2419
Episode: 2481/30000 (8.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2531s / 28.2703 s
agent0:                 episode reward: -0.1267,                 loss: nan
agent1:                 episode reward: 0.1267,                 loss: 0.2405
Episode: 2501/30000 (8.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2581s / 28.5284 s
agent0:                 episode reward: -0.3291,                 loss: nan
agent1:                 episode reward: 0.3291,                 loss: 0.2416
Episode: 2521/30000 (8.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2559s / 28.7843 s
agent0:                 episode reward: -0.7539,                 loss: nan
agent1:                 episode reward: 0.7539,                 loss: 0.2410
Episode: 2541/30000 (8.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3206s / 29.1049 s
agent0:                 episode reward: -0.7829,                 loss: nan
agent1:                 episode reward: 0.7829,                 loss: 0.2392
Episode: 2561/30000 (8.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2609s / 29.3658 s
agent0:                 episode reward: -0.8434,                 loss: nan
agent1:                 episode reward: 0.8434,                 loss: 0.2339
Episode: 2581/30000 (8.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2581s / 29.6239 s
agent0:                 episode reward: -0.5358,                 loss: nan
agent1:                 episode reward: 0.5358,                 loss: 0.2315
Episode: 2601/30000 (8.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2594s / 29.8832 s
agent0:                 episode reward: -0.7326,                 loss: nan
agent1:                 episode reward: 0.7326,                 loss: 0.2287
Episode: 2621/30000 (8.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2612s / 30.1445 s
agent0:                 episode reward: -0.8298,                 loss: nan
agent1:                 episode reward: 0.8298,                 loss: 0.2302
Episode: 2641/30000 (8.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2582s / 30.4026 s
agent0:                 episode reward: -0.6092,                 loss: nan
agent1:                 episode reward: 0.6092,                 loss: 0.2283
Episode: 2661/30000 (8.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2826s / 30.6852 s
agent0:                 episode reward: -0.9970,                 loss: nan
agent1:                 episode reward: 0.9970,                 loss: 0.2260
Episode: 2681/30000 (8.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2568s / 30.9421 s
agent0:                 episode reward: -0.8436,                 loss: nan
agent1:                 episode reward: 0.8436,                 loss: 0.2285
Episode: 2701/30000 (9.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2596s / 31.2017 s
agent0:                 episode reward: -0.7546,                 loss: nan
agent1:                 episode reward: 0.7546,                 loss: 0.2278
Episode: 2721/30000 (9.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2629s / 31.4646 s
agent0:                 episode reward: -0.8720,                 loss: nan
agent1:                 episode reward: 0.8720,                 loss: 0.2271
Episode: 2741/30000 (9.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2577s / 31.7222 s
agent0:                 episode reward: -0.7154,                 loss: nan
agent1:                 episode reward: 0.7154,                 loss: 0.2288
Episode: 2761/30000 (9.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2630s / 31.9852 s
agent0:                 episode reward: -0.3724,                 loss: nan
agent1:                 episode reward: 0.3724,                 loss: 0.2299
Episode: 2781/30000 (9.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2548s / 32.2401 s
agent0:                 episode reward: -0.3621,                 loss: nan
agent1:                 episode reward: 0.3621,                 loss: 0.2299
Episode: 2801/30000 (9.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2604s / 32.5005 s
agent0:                 episode reward: -0.8305,                 loss: nan
agent1:                 episode reward: 0.8305,                 loss: 0.2282
Episode: 2821/30000 (9.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2561s / 32.7566 s
agent0:                 episode reward: -0.6565,                 loss: nan
agent1:                 episode reward: 0.6565,                 loss: 0.2266
Episode: 2841/30000 (9.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2715s / 33.0281 s
agent0:                 episode reward: -1.0378,                 loss: nan
agent1:                 episode reward: 1.0378,                 loss: 0.2261
Episode: 2861/30000 (9.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2793s / 33.3074 s
agent0:                 episode reward: -1.1066,                 loss: nan
agent1:                 episode reward: 1.1066,                 loss: 0.2296
Episode: 2881/30000 (9.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2665s / 33.5740 s
agent0:                 episode reward: -0.7195,                 loss: nan
agent1:                 episode reward: 0.7195,                 loss: 0.2283
Episode: 2901/30000 (9.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2650s / 33.8389 s
agent0:                 episode reward: -0.3490,                 loss: nan
agent1:                 episode reward: 0.3490,                 loss: 0.2583
Episode: 2921/30000 (9.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2640s / 34.1029 s
agent0:                 episode reward: -0.7776,                 loss: nan
agent1:                 episode reward: 0.7776,                 loss: 0.2633
Episode: 2941/30000 (9.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2611s / 34.3641 s
agent0:                 episode reward: -1.0719,                 loss: nan
agent1:                 episode reward: 1.0719,                 loss: 0.2618
Episode: 2961/30000 (9.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2601s / 34.6242 s
agent0:                 episode reward: -0.5774,                 loss: nan
agent1:                 episode reward: 0.5774,                 loss: 0.2596
Episode: 2981/30000 (9.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2607s / 34.8849 s
agent0:                 episode reward: -0.3104,                 loss: nan
agent1:                 episode reward: 0.3104,                 loss: 0.2604
Episode: 3001/30000 (10.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2631s / 35.1480 s
agent0:                 episode reward: -0.6007,                 loss: nan
agent1:                 episode reward: 0.6007,                 loss: 0.2609
Episode: 3021/30000 (10.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2618s / 35.4097 s
agent0:                 episode reward: -0.7096,                 loss: nan
agent1:                 episode reward: 0.7096,                 loss: 0.2638
Episode: 3041/30000 (10.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2696s / 35.6793 s
agent0:                 episode reward: -0.7206,                 loss: nan
agent1:                 episode reward: 0.7206,                 loss: 0.2566
Episode: 3061/30000 (10.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2758s / 35.9551 s
agent0:                 episode reward: -0.9858,                 loss: nan
agent1:                 episode reward: 0.9858,                 loss: 0.2582
Episode: 3081/30000 (10.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2684s / 36.2235 s
agent0:                 episode reward: -1.0021,                 loss: nan
agent1:                 episode reward: 1.0021,                 loss: 0.2590
Episode: 3101/30000 (10.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2633s / 36.4868 s
agent0:                 episode reward: -0.6149,                 loss: nan
agent1:                 episode reward: 0.6149,                 loss: 0.2583
Episode: 3121/30000 (10.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2631s / 36.7499 s
agent0:                 episode reward: -1.0163,                 loss: nan
agent1:                 episode reward: 1.0163,                 loss: 0.2558
Episode: 3141/30000 (10.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2640s / 37.0139 s
agent0:                 episode reward: -0.7230,                 loss: nan
agent1:                 episode reward: 0.7230,                 loss: 0.2610
Episode: 3161/30000 (10.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2659s / 37.2798 s
agent0:                 episode reward: -0.8003,                 loss: nan
agent1:                 episode reward: 0.8003,                 loss: 0.2601
Episode: 3181/30000 (10.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2636s / 37.5434 s
agent0:                 episode reward: -1.0464,                 loss: nan
agent1:                 episode reward: 1.0464,                 loss: 0.2601
Episode: 3201/30000 (10.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2623s / 37.8058 s
agent0:                 episode reward: -0.5852,                 loss: nan
agent1:                 episode reward: 0.5852,                 loss: 0.2615
Episode: 3221/30000 (10.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2643s / 38.0701 s
agent0:                 episode reward: -1.0974,                 loss: nan
agent1:                 episode reward: 1.0974,                 loss: 0.2615
Episode: 3241/30000 (10.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2651s / 38.3352 s
agent0:                 episode reward: -1.0174,                 loss: nan
agent1:                 episode reward: 1.0174,                 loss: 0.2609
Episode: 3261/30000 (10.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2643s / 38.5995 s
agent0:                 episode reward: -0.8351,                 loss: nan
agent1:                 episode reward: 0.8351,                 loss: 0.2584
Episode: 3281/30000 (10.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2605s / 38.8600 s
agent0:                 episode reward: -0.7877,                 loss: nan
agent1:                 episode reward: 0.7877,                 loss: 0.2580
Episode: 3301/30000 (11.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2934s / 39.1534 s
agent0:                 episode reward: -0.8790,                 loss: nan
agent1:                 episode reward: 0.8790,                 loss: 0.2557
Episode: 3321/30000 (11.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3321s / 39.4855 s
agent0:                 episode reward: -0.7488,                 loss: nan
agent1:                 episode reward: 0.7488,                 loss: 0.2587
Episode: 3341/30000 (11.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2643s / 39.7498 s
agent0:                 episode reward: -1.1366,                 loss: nan
agent1:                 episode reward: 1.1366,                 loss: 0.2573
Episode: 3361/30000 (11.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2789s / 40.0287 s
agent0:                 episode reward: -0.5196,                 loss: nan
agent1:                 episode reward: 0.5196,                 loss: 0.2574
Episode: 3381/30000 (11.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2674s / 40.2962 s
agent0:                 episode reward: -1.1679,                 loss: nan
agent1:                 episode reward: 1.1679,                 loss: 0.2568
Episode: 3401/30000 (11.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2737s / 40.5699 s
agent0:                 episode reward: -0.9316,                 loss: nan
agent1:                 episode reward: 0.9316,                 loss: 0.2547
Episode: 3421/30000 (11.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2716s / 40.8415 s
agent0:                 episode reward: -1.0974,                 loss: nan
agent1:                 episode reward: 1.0974,                 loss: 0.2546
Episode: 3441/30000 (11.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2715s / 41.1130 s
agent0:                 episode reward: -0.5263,                 loss: nan
agent1:                 episode reward: 0.5263,                 loss: 0.2594
Episode: 3461/30000 (11.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2730s / 41.3859 s
agent0:                 episode reward: -0.9812,                 loss: nan
agent1:                 episode reward: 0.9812,                 loss: 0.2562
Episode: 3481/30000 (11.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3142s / 41.7001 s
agent0:                 episode reward: -0.8698,                 loss: nan
agent1:                 episode reward: 0.8698,                 loss: 0.2580
Episode: 3501/30000 (11.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3330s / 42.0331 s
agent0:                 episode reward: -0.7995,                 loss: nan
agent1:                 episode reward: 0.7995,                 loss: 0.2568
Episode: 3521/30000 (11.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2794s / 42.3124 s
agent0:                 episode reward: -0.5179,                 loss: nan
agent1:                 episode reward: 0.5179,                 loss: 0.2592
Episode: 3541/30000 (11.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2756s / 42.5881 s
agent0:                 episode reward: -0.9478,                 loss: nan
agent1:                 episode reward: 0.9478,                 loss: 0.2562
Episode: 3561/30000 (11.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2733s / 42.8613 s
agent0:                 episode reward: -1.0449,                 loss: nan
agent1:                 episode reward: 1.0449,                 loss: 0.2589
Episode: 3581/30000 (11.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2704s / 43.1317 s
agent0:                 episode reward: -0.8057,                 loss: nan
agent1:                 episode reward: 0.8057,                 loss: 0.2613
Episode: 3601/30000 (12.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2725s / 43.4042 s
agent0:                 episode reward: -0.8706,                 loss: nan
agent1:                 episode reward: 0.8706,                 loss: 0.2640
Episode: 3621/30000 (12.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2740s / 43.6782 s
agent0:                 episode reward: -0.4355,                 loss: nan
agent1:                 episode reward: 0.4355,                 loss: 0.2627
Episode: 3641/30000 (12.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2767s / 43.9549 s
agent0:                 episode reward: -0.8128,                 loss: nan
agent1:                 episode reward: 0.8128,                 loss: 0.2631
Episode: 3661/30000 (12.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2812s / 44.2362 s
agent0:                 episode reward: -0.8486,                 loss: nan
agent1:                 episode reward: 0.8486,                 loss: 0.2630
Episode: 3681/30000 (12.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2768s / 44.5130 s
agent0:                 episode reward: -0.9421,                 loss: nan
agent1:                 episode reward: 0.9421,                 loss: 0.2622
Episode: 3701/30000 (12.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2727s / 44.7857 s
agent0:                 episode reward: -0.6675,                 loss: nan
agent1:                 episode reward: 0.6675,                 loss: 0.2589
Episode: 3721/30000 (12.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2859s / 45.0716 s
agent0:                 episode reward: -1.3329,                 loss: nan
agent1:                 episode reward: 1.3329,                 loss: 0.2612
Episode: 3741/30000 (12.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2748s / 45.3464 s
agent0:                 episode reward: -0.6475,                 loss: nan
agent1:                 episode reward: 0.6475,                 loss: 0.2597
Episode: 3761/30000 (12.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2735s / 45.6199 s
agent0:                 episode reward: -0.6747,                 loss: nan
agent1:                 episode reward: 0.6747,                 loss: 0.2601
Episode: 3781/30000 (12.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2745s / 45.8944 s
agent0:                 episode reward: -0.6702,                 loss: nan
agent1:                 episode reward: 0.6702,                 loss: 0.2620
Episode: 3801/30000 (12.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2753s / 46.1697 s
agent0:                 episode reward: -0.9626,                 loss: nan
agent1:                 episode reward: 0.9626,                 loss: 0.2614
Episode: 3821/30000 (12.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2714s / 46.4411 s
agent0:                 episode reward: -1.0005,                 loss: nan
agent1:                 episode reward: 1.0005,                 loss: 0.2596
Episode: 3841/30000 (12.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2766s / 46.7177 s
agent0:                 episode reward: -1.1488,                 loss: nan
agent1:                 episode reward: 1.1488,                 loss: 0.2579
Episode: 3861/30000 (12.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2776s / 46.9953 s
agent0:                 episode reward: -0.4029,                 loss: nan
agent1:                 episode reward: 0.4029,                 loss: 0.2594
Episode: 3881/30000 (12.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2748s / 47.2701 s
agent0:                 episode reward: -0.7769,                 loss: nan
agent1:                 episode reward: 0.7769,                 loss: 0.2605
Episode: 3901/30000 (13.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2806s / 47.5508 s
agent0:                 episode reward: -1.0947,                 loss: nan
agent1:                 episode reward: 1.0947,                 loss: 0.2540
Episode: 3921/30000 (13.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2751s / 47.8259 s
agent0:                 episode reward: -0.9454,                 loss: nan
agent1:                 episode reward: 0.9454,                 loss: 0.2592
Episode: 3941/30000 (13.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2975s / 48.1234 s
agent0:                 episode reward: -0.8143,                 loss: nan
agent1:                 episode reward: 0.8143,                 loss: 0.2552
Episode: 3961/30000 (13.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2764s / 48.3998 s
agent0:                 episode reward: -0.6547,                 loss: nan
agent1:                 episode reward: 0.6547,                 loss: 0.2607
Episode: 3981/30000 (13.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2781s / 48.6779 s
agent0:                 episode reward: -0.9116,                 loss: nan
agent1:                 episode reward: 0.9116,                 loss: 0.2573
Episode: 4001/30000 (13.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2837s / 48.9616 s
agent0:                 episode reward: -0.4149,                 loss: nan
agent1:                 episode reward: 0.4149,                 loss: 0.2577
Episode: 4021/30000 (13.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2766s / 49.2382 s
agent0:                 episode reward: -1.1513,                 loss: nan
agent1:                 episode reward: 1.1513,                 loss: 0.2521
Episode: 4041/30000 (13.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3518s / 49.5900 s
agent0:                 episode reward: -0.8699,                 loss: nan
agent1:                 episode reward: 0.8699,                 loss: 0.2554
Episode: 4061/30000 (13.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2818s / 49.8718 s
agent0:                 episode reward: -0.7253,                 loss: nan
agent1:                 episode reward: 0.7253,                 loss: 0.2576
Episode: 4081/30000 (13.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3070s / 50.1789 s
agent0:                 episode reward: -0.7887,                 loss: nan
agent1:                 episode reward: 0.7887,                 loss: 0.2582
Episode: 4101/30000 (13.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2803s / 50.4591 s
agent0:                 episode reward: -1.0030,                 loss: nan
agent1:                 episode reward: 1.0030,                 loss: 0.2567
Episode: 4121/30000 (13.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2823s / 50.7415 s
agent0:                 episode reward: -0.7089,                 loss: nan
agent1:                 episode reward: 0.7089,                 loss: 0.2544
Episode: 4141/30000 (13.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2863s / 51.0277 s
agent0:                 episode reward: -0.8484,                 loss: nan
agent1:                 episode reward: 0.8484,                 loss: 0.2584
Episode: 4161/30000 (13.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2871s / 51.3148 s
agent0:                 episode reward: -0.5192,                 loss: nan
agent1:                 episode reward: 0.5192,                 loss: 0.2555
Episode: 4181/30000 (13.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2784s / 51.5932 s
agent0:                 episode reward: -0.6203,                 loss: nan
agent1:                 episode reward: 0.6203,                 loss: 0.2567
Episode: 4201/30000 (14.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2806s / 51.8738 s
agent0:                 episode reward: -0.7459,                 loss: nan
agent1:                 episode reward: 0.7459,                 loss: 0.2582
Episode: 4221/30000 (14.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2985s / 52.1723 s
agent0:                 episode reward: -0.6636,                 loss: nan
agent1:                 episode reward: 0.6636,                 loss: 0.2561
Episode: 4241/30000 (14.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2808s / 52.4531 s
agent0:                 episode reward: -0.9165,                 loss: nan
agent1:                 episode reward: 0.9165,                 loss: 0.2569
Episode: 4261/30000 (14.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2797s / 52.7328 s
agent0:                 episode reward: -0.6679,                 loss: nan
agent1:                 episode reward: 0.6679,                 loss: 0.2585
Episode: 4281/30000 (14.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2832s / 53.0161 s
agent0:                 episode reward: -0.6635,                 loss: nan
agent1:                 episode reward: 0.6635,                 loss: 0.2557
Episode: 4301/30000 (14.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2831s / 53.2992 s
agent0:                 episode reward: -1.1390,                 loss: nan
agent1:                 episode reward: 1.1390,                 loss: 0.2562
Episode: 4321/30000 (14.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2821s / 53.5813 s
agent0:                 episode reward: -1.4120,                 loss: nan
agent1:                 episode reward: 1.4120,                 loss: 0.2586
Episode: 4341/30000 (14.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2785s / 53.8598 s
agent0:                 episode reward: -0.7247,                 loss: nan
agent1:                 episode reward: 0.7247,                 loss: 0.2583
Episode: 4361/30000 (14.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3147s / 54.1745 s
agent0:                 episode reward: -0.5836,                 loss: nan
agent1:                 episode reward: 0.5836,                 loss: 0.2563
Episode: 4381/30000 (14.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3139s / 54.4885 s
agent0:                 episode reward: -0.5356,                 loss: nan
agent1:                 episode reward: 0.5356,                 loss: 0.2534
Episode: 4401/30000 (14.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2820s / 54.7704 s
agent0:                 episode reward: -0.8126,                 loss: nan
agent1:                 episode reward: 0.8126,                 loss: 0.2556
Episode: 4421/30000 (14.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2837s / 55.0541 s
agent0:                 episode reward: -0.8563,                 loss: nan
agent1:                 episode reward: 0.8563,                 loss: 0.2547
Episode: 4441/30000 (14.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2822s / 55.3363 s
agent0:                 episode reward: -0.7242,                 loss: nan
agent1:                 episode reward: 0.7242,                 loss: 0.2564
Episode: 4461/30000 (14.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2851s / 55.6214 s
agent0:                 episode reward: -0.7346,                 loss: nan
agent1:                 episode reward: 0.7346,                 loss: 0.2586
Episode: 4481/30000 (14.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2863s / 55.9078 s
agent0:                 episode reward: -0.7092,                 loss: nan
agent1:                 episode reward: 0.7092,                 loss: 0.2542
Episode: 4501/30000 (15.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2860s / 56.1938 s
agent0:                 episode reward: -0.9154,                 loss: nan
agent1:                 episode reward: 0.9154,                 loss: 0.2562
Episode: 4521/30000 (15.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2839s / 56.4776 s
agent0:                 episode reward: -1.2070,                 loss: nan
agent1:                 episode reward: 1.2070,                 loss: 0.2505
Episode: 4541/30000 (15.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2907s / 56.7683 s
agent0:                 episode reward: -0.9203,                 loss: nan
agent1:                 episode reward: 0.9203,                 loss: 0.2564
Episode: 4561/30000 (15.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2940s / 57.0624 s
agent0:                 episode reward: -1.0624,                 loss: nan
agent1:                 episode reward: 1.0624,                 loss: 0.2535
Episode: 4581/30000 (15.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3094s / 57.3718 s
agent0:                 episode reward: -1.1080,                 loss: nan
agent1:                 episode reward: 1.1080,                 loss: 0.2521
Episode: 4601/30000 (15.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3089s / 57.6807 s
agent0:                 episode reward: -0.8058,                 loss: nan
agent1:                 episode reward: 0.8058,                 loss: 0.2536
Episode: 4621/30000 (15.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2933s / 57.9739 s
agent0:                 episode reward: -1.3219,                 loss: nan
agent1:                 episode reward: 1.3219,                 loss: 0.2535
Episode: 4641/30000 (15.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3186s / 58.2925 s
agent0:                 episode reward: -0.8960,                 loss: nan
agent1:                 episode reward: 0.8960,                 loss: 0.2523
Episode: 4661/30000 (15.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2920s / 58.5845 s
agent0:                 episode reward: -0.9553,                 loss: nan
agent1:                 episode reward: 0.9553,                 loss: 0.2526
Episode: 4681/30000 (15.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2887s / 58.8733 s
agent0:                 episode reward: -0.9939,                 loss: nan
agent1:                 episode reward: 0.9939,                 loss: 0.2548
Episode: 4701/30000 (15.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2892s / 59.1625 s
agent0:                 episode reward: -0.7852,                 loss: nan
agent1:                 episode reward: 0.7852,                 loss: 0.2552
Episode: 4721/30000 (15.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2895s / 59.4520 s
agent0:                 episode reward: -0.6988,                 loss: nan
agent1:                 episode reward: 0.6988,                 loss: 0.2565
Episode: 4741/30000 (15.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3582s / 59.8102 s
agent0:                 episode reward: -1.1900,                 loss: nan
agent1:                 episode reward: 1.1900,                 loss: 0.2529
Episode: 4761/30000 (15.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2978s / 60.1080 s
agent0:                 episode reward: -0.8951,                 loss: nan
agent1:                 episode reward: 0.8951,                 loss: 0.2533
Episode: 4781/30000 (15.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3010s / 60.4090 s
agent0:                 episode reward: -0.4429,                 loss: nan
agent1:                 episode reward: 0.4429,                 loss: 0.2541
Episode: 4801/30000 (16.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3258s / 60.7348 s
agent0:                 episode reward: -0.5198,                 loss: nan
agent1:                 episode reward: 0.5198,                 loss: 0.2538
Episode: 4821/30000 (16.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2952s / 61.0300 s
agent0:                 episode reward: -0.7845,                 loss: nan
agent1:                 episode reward: 0.7845,                 loss: 0.2567
Episode: 4841/30000 (16.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2875s / 61.3175 s
agent0:                 episode reward: -0.9320,                 loss: nan
agent1:                 episode reward: 0.9320,                 loss: 0.2524
Episode: 4861/30000 (16.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2904s / 61.6079 s
agent0:                 episode reward: -0.7083,                 loss: nan
agent1:                 episode reward: 0.7083,                 loss: 0.2542
Episode: 4881/30000 (16.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2917s / 61.8996 s
agent0:                 episode reward: -0.9939,                 loss: nan
agent1:                 episode reward: 0.9939,                 loss: 0.2518
Episode: 4901/30000 (16.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2899s / 62.1895 s
agent0:                 episode reward: -0.8151,                 loss: nan
agent1:                 episode reward: 0.8151,                 loss: 0.2679
Episode: 4921/30000 (16.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2915s / 62.4810 s
agent0:                 episode reward: -0.8304,                 loss: nan
agent1:                 episode reward: 0.8304,                 loss: 0.2679
Episode: 4941/30000 (16.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2903s / 62.7712 s
agent0:                 episode reward: -0.9031,                 loss: nan
agent1:                 episode reward: 0.9031,                 loss: 0.2680
Episode: 4961/30000 (16.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2924s / 63.0637 s
agent0:                 episode reward: -1.1259,                 loss: nan
agent1:                 episode reward: 1.1259,                 loss: 0.2654
Episode: 4981/30000 (16.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3048s / 63.3685 s
agent0:                 episode reward: -1.2119,                 loss: nan
agent1:                 episode reward: 1.2119,                 loss: 0.2696
Episode: 5001/30000 (16.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3017s / 63.6702 s
agent0:                 episode reward: -1.2235,                 loss: nan
agent1:                 episode reward: 1.2235,                 loss: 0.2665
Episode: 5021/30000 (16.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2883s / 63.9585 s
agent0:                 episode reward: -0.8106,                 loss: nan
agent1:                 episode reward: 0.8106,                 loss: 0.2656
Episode: 5041/30000 (16.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3001s / 64.2586 s
agent0:                 episode reward: -1.1060,                 loss: nan
agent1:                 episode reward: 1.1060,                 loss: 0.2675
Episode: 5061/30000 (16.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2974s / 64.5560 s
agent0:                 episode reward: -0.6015,                 loss: nan
agent1:                 episode reward: 0.6015,                 loss: 0.2694
Episode: 5081/30000 (16.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2882s / 64.8442 s
agent0:                 episode reward: -0.5149,                 loss: nan
agent1:                 episode reward: 0.5149,                 loss: 0.2674
Episode: 5101/30000 (17.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2894s / 65.1336 s
agent0:                 episode reward: -0.6819,                 loss: nan
agent1:                 episode reward: 0.6819,                 loss: 0.2702
Episode: 5121/30000 (17.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2937s / 65.4272 s
agent0:                 episode reward: -0.4643,                 loss: nan
agent1:                 episode reward: 0.4643,                 loss: 0.2667
Episode: 5141/30000 (17.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2927s / 65.7199 s
agent0:                 episode reward: -0.9132,                 loss: nan
agent1:                 episode reward: 0.9132,                 loss: 0.2668
Episode: 5161/30000 (17.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2943s / 66.0142 s
agent0:                 episode reward: -0.6253,                 loss: nan
agent1:                 episode reward: 0.6253,                 loss: 0.2682
Episode: 5181/30000 (17.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3004s / 66.3147 s
agent0:                 episode reward: -1.0269,                 loss: nan
agent1:                 episode reward: 1.0269,                 loss: 0.2671
Episode: 5201/30000 (17.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3851s / 66.6998 s
agent0:                 episode reward: -0.9791,                 loss: nan
agent1:                 episode reward: 0.9791,                 loss: 0.2666
Episode: 5221/30000 (17.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3135s / 67.0134 s
agent0:                 episode reward: -0.8168,                 loss: nan
agent1:                 episode reward: 0.8168,                 loss: 0.2630
Episode: 5241/30000 (17.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3095s / 67.3229 s
agent0:                 episode reward: -0.9432,                 loss: nan
agent1:                 episode reward: 0.9432,                 loss: 0.2585
Episode: 5261/30000 (17.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2955s / 67.6184 s
agent0:                 episode reward: -0.6838,                 loss: nan
agent1:                 episode reward: 0.6838,                 loss: 0.2589
Episode: 5281/30000 (17.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2988s / 67.9172 s
agent0:                 episode reward: -0.7429,                 loss: nan
agent1:                 episode reward: 0.7429,                 loss: 0.2599
Episode: 5301/30000 (17.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2982s / 68.2154 s
agent0:                 episode reward: -1.0250,                 loss: nan
agent1:                 episode reward: 1.0250,                 loss: 0.2652
Episode: 5321/30000 (17.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2975s / 68.5129 s
agent0:                 episode reward: -1.1228,                 loss: nan
agent1:                 episode reward: 1.1228,                 loss: 0.2596
Episode: 5341/30000 (17.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3007s / 68.8136 s
agent0:                 episode reward: -1.1010,                 loss: nan
agent1:                 episode reward: 1.1010,                 loss: 0.2571
Episode: 5361/30000 (17.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3011s / 69.1146 s
agent0:                 episode reward: -0.8146,                 loss: nan
agent1:                 episode reward: 0.8146,                 loss: 0.2568
Episode: 5381/30000 (17.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3011s / 69.4158 s
agent0:                 episode reward: -0.7696,                 loss: nan
agent1:                 episode reward: 0.7696,                 loss: 0.2598
Episode: 5401/30000 (18.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3019s / 69.7177 s
agent0:                 episode reward: -0.9964,                 loss: nan
agent1:                 episode reward: 0.9964,                 loss: 0.2590
Episode: 5421/30000 (18.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3694s / 70.0871 s
agent0:                 episode reward: -1.0954,                 loss: nan
agent1:                 episode reward: 1.0954,                 loss: 0.2595
Episode: 5441/30000 (18.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3058s / 70.3929 s
agent0:                 episode reward: -0.8987,                 loss: nan
agent1:                 episode reward: 0.8987,                 loss: 0.2602
Episode: 5461/30000 (18.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3344s / 70.7273 s
agent0:                 episode reward: -1.0569,                 loss: nan
agent1:                 episode reward: 1.0569,                 loss: 0.2582
Episode: 5481/30000 (18.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2979s / 71.0252 s
agent0:                 episode reward: -0.7789,                 loss: nan
agent1:                 episode reward: 0.7789,                 loss: 0.2597
Episode: 5501/30000 (18.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2962s / 71.3214 s
agent0:                 episode reward: -0.8250,                 loss: nan
agent1:                 episode reward: 0.8250,                 loss: 0.2606
Episode: 5521/30000 (18.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2975s / 71.6189 s
agent0:                 episode reward: -0.9622,                 loss: nan
agent1:                 episode reward: 0.9622,                 loss: 0.2625
Episode: 5541/30000 (18.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2934s / 71.9122 s
agent0:                 episode reward: -0.9181,                 loss: nan
agent1:                 episode reward: 0.9181,                 loss: 0.2568
Episode: 5561/30000 (18.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3119s / 72.2241 s
agent0:                 episode reward: -1.0723,                 loss: nan
agent1:                 episode reward: 1.0723,                 loss: 0.2565
Episode: 5581/30000 (18.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3097s / 72.5338 s
agent0:                 episode reward: -0.8037,                 loss: nan
agent1:                 episode reward: 0.8037,                 loss: 0.2475
Episode: 5601/30000 (18.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2964s / 72.8302 s
agent0:                 episode reward: -1.0177,                 loss: nan
agent1:                 episode reward: 1.0177,                 loss: 0.2483
Episode: 5621/30000 (18.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2989s / 73.1291 s
agent0:                 episode reward: -0.8138,                 loss: nan
agent1:                 episode reward: 0.8138,                 loss: 0.2462
Episode: 5641/30000 (18.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2981s / 73.4272 s
agent0:                 episode reward: -0.9519,                 loss: nan
agent1:                 episode reward: 0.9519,                 loss: 0.2456
Episode: 5661/30000 (18.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2994s / 73.7265 s
agent0:                 episode reward: -0.9874,                 loss: nan
agent1:                 episode reward: 0.9874,                 loss: 0.2455
Episode: 5681/30000 (18.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3185s / 74.0450 s
agent0:                 episode reward: -0.9676,                 loss: nan
agent1:                 episode reward: 0.9676,                 loss: 0.2485
Episode: 5701/30000 (19.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3028s / 74.3479 s
agent0:                 episode reward: -1.3510,                 loss: nan
agent1:                 episode reward: 1.3510,                 loss: 0.2471
Episode: 5721/30000 (19.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3112s / 74.6590 s
agent0:                 episode reward: -1.2120,                 loss: nan
agent1:                 episode reward: 1.2120,                 loss: 0.2472
Episode: 5741/30000 (19.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3279s / 74.9870 s
agent0:                 episode reward: -0.8526,                 loss: nan
agent1:                 episode reward: 0.8526,                 loss: 0.2435
Episode: 5761/30000 (19.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3133s / 75.3003 s
agent0:                 episode reward: -1.2097,                 loss: nan
agent1:                 episode reward: 1.2097,                 loss: 0.2456
Episode: 5781/30000 (19.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2993s / 75.5996 s
agent0:                 episode reward: -0.9610,                 loss: nan
agent1:                 episode reward: 0.9610,                 loss: 0.2429
Episode: 5801/30000 (19.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3002s / 75.8998 s
agent0:                 episode reward: -1.0340,                 loss: nan
agent1:                 episode reward: 1.0340,                 loss: 0.2469
Episode: 5821/30000 (19.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3036s / 76.2033 s
agent0:                 episode reward: -0.4848,                 loss: nan
agent1:                 episode reward: 0.4848,                 loss: 0.2453
Episode: 5841/30000 (19.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3069s / 76.5103 s
agent0:                 episode reward: -0.7593,                 loss: nan
agent1:                 episode reward: 0.7593,                 loss: 0.2464
Episode: 5861/30000 (19.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3085s / 76.8187 s
agent0:                 episode reward: -1.3378,                 loss: nan
agent1:                 episode reward: 1.3378,                 loss: 0.2426
Episode: 5881/30000 (19.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3104s / 77.1292 s
agent0:                 episode reward: -1.1503,                 loss: nan
agent1:                 episode reward: 1.1503,                 loss: 0.2464
Episode: 5901/30000 (19.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3093s / 77.4384 s
agent0:                 episode reward: -1.1311,                 loss: nan
agent1:                 episode reward: 1.1311,                 loss: 0.2642
Episode: 5921/30000 (19.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3106s / 77.7491 s
agent0:                 episode reward: -1.4083,                 loss: nan
agent1:                 episode reward: 1.4083,                 loss: 0.2670
Episode: 5941/30000 (19.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3080s / 78.0570 s
agent0:                 episode reward: -0.7827,                 loss: nan
agent1:                 episode reward: 0.7827,                 loss: 0.2663
Episode: 5961/30000 (19.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3182s / 78.3752 s
agent0:                 episode reward: -0.7462,                 loss: nan
agent1:                 episode reward: 0.7462,                 loss: 0.2631
Episode: 5981/30000 (19.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3107s / 78.6859 s
agent0:                 episode reward: -0.8694,                 loss: nan
agent1:                 episode reward: 0.8694,                 loss: 0.2674
Episode: 6001/30000 (20.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3089s / 78.9948 s
agent0:                 episode reward: -1.0582,                 loss: nan
agent1:                 episode reward: 1.0582,                 loss: 0.2593
Episode: 6021/30000 (20.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3090s / 79.3038 s
agent0:                 episode reward: -0.7098,                 loss: nan
agent1:                 episode reward: 0.7098,                 loss: 0.2638
Episode: 6041/30000 (20.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3107s / 79.6145 s
agent0:                 episode reward: -1.1466,                 loss: nan
agent1:                 episode reward: 1.1466,                 loss: 0.2627
Episode: 6061/30000 (20.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3076s / 79.9221 s
agent0:                 episode reward: -0.8585,                 loss: nan
agent1:                 episode reward: 0.8585,                 loss: 0.2629
Episode: 6081/30000 (20.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3472s / 80.2693 s
agent0:                 episode reward: -0.7764,                 loss: nan
agent1:                 episode reward: 0.7764,                 loss: 0.2634
Episode: 6101/30000 (20.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3518s / 80.6212 s
agent0:                 episode reward: -1.0553,                 loss: nan
agent1:                 episode reward: 1.0553,                 loss: 0.2659
Episode: 6121/30000 (20.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3091s / 80.9303 s
agent0:                 episode reward: -1.1054,                 loss: nan
agent1:                 episode reward: 1.1054,                 loss: 0.2622
Episode: 6141/30000 (20.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3339s / 81.2642 s
agent0:                 episode reward: -0.8570,                 loss: nan
agent1:                 episode reward: 0.8570,                 loss: 0.2635
Episode: 6161/30000 (20.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3182s / 81.5824 s
agent0:                 episode reward: -1.2840,                 loss: nan
agent1:                 episode reward: 1.2840,                 loss: 0.2662
Episode: 6181/30000 (20.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3091s / 81.8915 s
agent0:                 episode reward: -0.8266,                 loss: nan
agent1:                 episode reward: 0.8266,                 loss: 0.2677
Episode: 6201/30000 (20.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3201s / 82.2116 s
agent0:                 episode reward: -1.1786,                 loss: nan
agent1:                 episode reward: 1.1786,                 loss: 0.2660
Episode: 6221/30000 (20.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3128s / 82.5244 s
agent0:                 episode reward: -1.0505,                 loss: nan
agent1:                 episode reward: 1.0505,                 loss: 0.2631
Episode: 6241/30000 (20.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3053s / 82.8296 s
agent0:                 episode reward: -1.1892,                 loss: nan
agent1:                 episode reward: 1.1892,                 loss: 0.2584
Episode: 6261/30000 (20.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3281s / 83.1578 s
agent0:                 episode reward: -1.2825,                 loss: nan
agent1:                 episode reward: 1.2825,                 loss: 0.2577
Episode: 6281/30000 (20.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3186s / 83.4764 s
agent0:                 episode reward: -1.0858,                 loss: nan
agent1:                 episode reward: 1.0858,                 loss: 0.2592
Episode: 6301/30000 (21.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3092s / 83.7856 s
agent0:                 episode reward: -1.0460,                 loss: nan
agent1:                 episode reward: 1.0460,                 loss: 0.2600
Episode: 6321/30000 (21.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3140s / 84.0995 s
agent0:                 episode reward: -0.9666,                 loss: nan
agent1:                 episode reward: 0.9666,                 loss: 0.2618
Episode: 6341/30000 (21.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3230s / 84.4226 s
agent0:                 episode reward: -1.0243,                 loss: nan
agent1:                 episode reward: 1.0243,                 loss: 0.2598
Episode: 6361/30000 (21.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3256s / 84.7482 s
agent0:                 episode reward: -1.0787,                 loss: nan
agent1:                 episode reward: 1.0787,                 loss: 0.2605
Episode: 6381/30000 (21.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3155s / 85.0636 s
agent0:                 episode reward: -1.1135,                 loss: nan
agent1:                 episode reward: 1.1135,                 loss: 0.2593
Episode: 6401/30000 (21.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3117s / 85.3753 s
agent0:                 episode reward: -0.8587,                 loss: nan
agent1:                 episode reward: 0.8587,                 loss: 0.2610
Episode: 6421/30000 (21.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3121s / 85.6874 s
agent0:                 episode reward: -0.9781,                 loss: nan
agent1:                 episode reward: 0.9781,                 loss: 0.2579
Episode: 6441/30000 (21.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3665s / 86.0539 s
agent0:                 episode reward: -1.0856,                 loss: nan
agent1:                 episode reward: 1.0856,                 loss: 0.2621
Episode: 6461/30000 (21.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3147s / 86.3686 s
agent0:                 episode reward: -0.8911,                 loss: nan
agent1:                 episode reward: 0.8911,                 loss: 0.2600
Episode: 6481/30000 (21.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3113s / 86.6799 s
agent0:                 episode reward: -1.1292,                 loss: nan
agent1:                 episode reward: 1.1292,                 loss: 0.2612
Episode: 6501/30000 (21.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3141s / 86.9941 s
agent0:                 episode reward: -0.8767,                 loss: nan
agent1:                 episode reward: 0.8767,                 loss: 0.2593
Episode: 6521/30000 (21.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3245s / 87.3186 s
agent0:                 episode reward: -0.9274,                 loss: nan
agent1:                 episode reward: 0.9274,                 loss: 0.2612
Episode: 6541/30000 (21.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3188s / 87.6374 s
agent0:                 episode reward: -0.9824,                 loss: nan
agent1:                 episode reward: 0.9824,                 loss: 0.2580
Episode: 6561/30000 (21.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3137s / 87.9511 s
agent0:                 episode reward: -0.8329,                 loss: nan
agent1:                 episode reward: 0.8329,                 loss: 0.2644
Episode: 6581/30000 (21.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3121s / 88.2632 s
agent0:                 episode reward: -0.6308,                 loss: nan
agent1:                 episode reward: 0.6308,                 loss: 0.2667
Episode: 6601/30000 (22.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3238s / 88.5870 s
agent0:                 episode reward: -0.9464,                 loss: nan
agent1:                 episode reward: 0.9464,                 loss: 0.2632
Episode: 6621/30000 (22.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3197s / 88.9067 s
agent0:                 episode reward: -1.0048,                 loss: nan
agent1:                 episode reward: 1.0048,                 loss: 0.2651
Episode: 6641/30000 (22.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3153s / 89.2220 s
agent0:                 episode reward: -1.2007,                 loss: nan
agent1:                 episode reward: 1.2007,                 loss: 0.2593
Episode: 6661/30000 (22.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3186s / 89.5406 s
agent0:                 episode reward: -1.0767,                 loss: nan
agent1:                 episode reward: 1.0767,                 loss: 0.2649
Episode: 6681/30000 (22.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3127s / 89.8533 s
agent0:                 episode reward: -0.8604,                 loss: nan
agent1:                 episode reward: 0.8604,                 loss: 0.2646
Episode: 6701/30000 (22.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3245s / 90.1778 s
agent0:                 episode reward: -1.1409,                 loss: nan
agent1:                 episode reward: 1.1409,                 loss: 0.2662
Episode: 6721/30000 (22.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3448s / 90.5226 s
agent0:                 episode reward: -0.8478,                 loss: nan
agent1:                 episode reward: 0.8478,                 loss: 0.2650
Episode: 6741/30000 (22.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3743s / 90.8970 s
agent0:                 episode reward: -1.3262,                 loss: nan
agent1:                 episode reward: 1.3262,                 loss: 0.2614
Episode: 6761/30000 (22.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3164s / 91.2134 s
agent0:                 episode reward: -0.7982,                 loss: nan
agent1:                 episode reward: 0.7982,                 loss: 0.2652
Episode: 6781/30000 (22.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3661s / 91.5795 s
agent0:                 episode reward: -1.0182,                 loss: nan
agent1:                 episode reward: 1.0182,                 loss: 0.2639
Episode: 6801/30000 (22.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3159s / 91.8954 s
agent0:                 episode reward: -0.8638,                 loss: nan
agent1:                 episode reward: 0.8638,                 loss: 0.2650
Episode: 6821/30000 (22.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3167s / 92.2121 s
agent0:                 episode reward: -1.2625,                 loss: nan
agent1:                 episode reward: 1.2625,                 loss: 0.2640
Episode: 6841/30000 (22.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3191s / 92.5312 s
agent0:                 episode reward: -1.1183,                 loss: nan
agent1:                 episode reward: 1.1183,                 loss: 0.2662
Episode: 6861/30000 (22.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3161s / 92.8473 s
agent0:                 episode reward: -0.9085,                 loss: nan
agent1:                 episode reward: 0.9085,                 loss: 0.2617
Episode: 6881/30000 (22.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3298s / 93.1771 s
agent0:                 episode reward: -1.1377,                 loss: nan
agent1:                 episode reward: 1.1377,                 loss: 0.2609
Episode: 6901/30000 (23.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3256s / 93.5027 s
agent0:                 episode reward: -1.1658,                 loss: nan
agent1:                 episode reward: 1.1658,                 loss: 0.2658
Episode: 6921/30000 (23.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3146s / 93.8173 s
agent0:                 episode reward: -0.9431,                 loss: nan
agent1:                 episode reward: 0.9431,                 loss: 0.2671
Episode: 6941/30000 (23.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3191s / 94.1365 s
agent0:                 episode reward: -0.8950,                 loss: nan
agent1:                 episode reward: 0.8950,                 loss: 0.2679
Episode: 6961/30000 (23.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3167s / 94.4531 s
agent0:                 episode reward: -1.0717,                 loss: nan
agent1:                 episode reward: 1.0717,                 loss: 0.2646
Episode: 6981/30000 (23.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3280s / 94.7811 s
agent0:                 episode reward: -0.8073,                 loss: nan
agent1:                 episode reward: 0.8073,                 loss: 0.2652
Episode: 7001/30000 (23.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3215s / 95.1026 s
agent0:                 episode reward: -0.9945,                 loss: nan
agent1:                 episode reward: 0.9945,                 loss: 0.2604
Episode: 7021/30000 (23.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3239s / 95.4265 s
agent0:                 episode reward: -1.0800,                 loss: nan
agent1:                 episode reward: 1.0800,                 loss: 0.2660
Episode: 7041/30000 (23.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3184s / 95.7450 s
agent0:                 episode reward: -0.8621,                 loss: nan
agent1:                 episode reward: 0.8621,                 loss: 0.2638
Episode: 7061/30000 (23.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3260s / 96.0710 s
agent0:                 episode reward: -0.6880,                 loss: nan
agent1:                 episode reward: 0.6880,                 loss: 0.2643
Episode: 7081/30000 (23.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3551s / 96.4261 s
agent0:                 episode reward: -0.9427,                 loss: nan
agent1:                 episode reward: 0.9427,                 loss: 0.2632
Episode: 7101/30000 (23.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3287s / 96.7548 s
agent0:                 episode reward: -0.6693,                 loss: nan
agent1:                 episode reward: 0.6693,                 loss: 0.2645
Episode: 7121/30000 (23.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3229s / 97.0776 s
agent0:                 episode reward: -0.6257,                 loss: nan
agent1:                 episode reward: 0.6257,                 loss: 0.2668
Episode: 7141/30000 (23.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3251s / 97.4027 s
agent0:                 episode reward: -0.7457,                 loss: nan
agent1:                 episode reward: 0.7457,                 loss: 0.2697
Episode: 7161/30000 (23.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3202s / 97.7229 s
agent0:                 episode reward: -0.9965,                 loss: nan
agent1:                 episode reward: 0.9965,                 loss: 0.2653
Episode: 7181/30000 (23.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3228s / 98.0457 s
agent0:                 episode reward: -0.9489,                 loss: nan
agent1:                 episode reward: 0.9489,                 loss: 0.2623
Episode: 7201/30000 (24.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3247s / 98.3704 s
agent0:                 episode reward: -1.1349,                 loss: nan
agent1:                 episode reward: 1.1349,                 loss: 0.2653
Episode: 7221/30000 (24.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3249s / 98.6953 s
agent0:                 episode reward: -1.2021,                 loss: nan
agent1:                 episode reward: 1.2021,                 loss: 0.2669
Episode: 7241/30000 (24.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3279s / 99.0232 s
agent0:                 episode reward: -1.1772,                 loss: nan
agent1:                 episode reward: 1.1772,                 loss: 0.2643
Episode: 7261/30000 (24.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3236s / 99.3468 s
agent0:                 episode reward: -1.5079,                 loss: nan
agent1:                 episode reward: 1.5079,                 loss: 0.2598
Episode: 7281/30000 (24.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3245s / 99.6713 s
agent0:                 episode reward: -1.2401,                 loss: nan
agent1:                 episode reward: 1.2401,                 loss: 0.2624
Episode: 7301/30000 (24.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3499s / 100.0211 s
agent0:                 episode reward: -1.0412,                 loss: nan
agent1:                 episode reward: 1.0412,                 loss: 0.2650
Episode: 7321/30000 (24.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3297s / 100.3509 s
agent0:                 episode reward: -0.8988,                 loss: nan
agent1:                 episode reward: 0.8988,                 loss: 0.2680
Episode: 7341/30000 (24.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3246s / 100.6754 s
agent0:                 episode reward: -1.1013,                 loss: nan
agent1:                 episode reward: 1.1013,                 loss: 0.2621
Episode: 7361/30000 (24.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4160s / 101.0914 s
agent0:                 episode reward: -1.0226,                 loss: nan
agent1:                 episode reward: 1.0226,                 loss: 0.2649
Episode: 7381/30000 (24.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3231s / 101.4145 s
agent0:                 episode reward: -1.1840,                 loss: nan
agent1:                 episode reward: 1.1840,                 loss: 0.2655
Episode: 7401/30000 (24.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3218s / 101.7364 s
agent0:                 episode reward: -1.0608,                 loss: nan
agent1:                 episode reward: 1.0608,                 loss: 0.2653
Episode: 7421/30000 (24.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3630s / 102.0994 s
agent0:                 episode reward: -1.0240,                 loss: nan
agent1:                 episode reward: 1.0240,                 loss: 0.2623
Episode: 7441/30000 (24.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3303s / 102.4296 s
agent0:                 episode reward: -1.2812,                 loss: nan
agent1:                 episode reward: 1.2812,                 loss: 0.2608
Episode: 7461/30000 (24.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3530s / 102.7826 s
agent0:                 episode reward: -1.1418,                 loss: nan
agent1:                 episode reward: 1.1418,                 loss: 0.2634
Episode: 7481/30000 (24.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3300s / 103.1127 s
agent0:                 episode reward: -0.6767,                 loss: nan
agent1:                 episode reward: 0.6767,                 loss: 0.2625
Episode: 7501/30000 (25.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3306s / 103.4432 s
agent0:                 episode reward: -0.9223,                 loss: nan
agent1:                 episode reward: 0.9223,                 loss: 0.2640
Episode: 7521/30000 (25.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3249s / 103.7681 s
agent0:                 episode reward: -1.2130,                 loss: nan
agent1:                 episode reward: 1.2130,                 loss: 0.2642
Episode: 7541/30000 (25.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3329s / 104.1010 s
agent0:                 episode reward: -0.8729,                 loss: nan
agent1:                 episode reward: 0.8729,                 loss: 0.2632
Episode: 7561/30000 (25.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3305s / 104.4316 s
agent0:                 episode reward: -1.1577,                 loss: nan
agent1:                 episode reward: 1.1577,                 loss: 0.2625
Episode: 7581/30000 (25.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3310s / 104.7626 s
agent0:                 episode reward: -1.1305,                 loss: nan
agent1:                 episode reward: 1.1305,                 loss: 0.2677
Episode: 7601/30000 (25.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3366s / 105.0992 s
agent0:                 episode reward: -1.2789,                 loss: nan
agent1:                 episode reward: 1.2789,                 loss: 0.2662
Episode: 7621/30000 (25.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3380s / 105.4372 s
agent0:                 episode reward: -1.1376,                 loss: nan
agent1:                 episode reward: 1.1376,                 loss: 0.2656
Episode: 7641/30000 (25.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3278s / 105.7650 s
agent0:                 episode reward: -1.1196,                 loss: nan
agent1:                 episode reward: 1.1196,                 loss: 0.2637
Episode: 7661/30000 (25.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3273s / 106.0923 s
agent0:                 episode reward: -1.0044,                 loss: nan
agent1:                 episode reward: 1.0044,                 loss: 0.2655
Episode: 7681/30000 (25.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3299s / 106.4223 s
agent0:                 episode reward: -0.7908,                 loss: nan
agent1:                 episode reward: 0.7908,                 loss: 0.2665
Episode: 7701/30000 (25.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3274s / 106.7497 s
agent0:                 episode reward: -0.8947,                 loss: nan
agent1:                 episode reward: 0.8947,                 loss: 0.2684
Episode: 7721/30000 (25.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3257s / 107.0754 s
agent0:                 episode reward: -0.8093,                 loss: nan
agent1:                 episode reward: 0.8093,                 loss: 0.2651
Episode: 7741/30000 (25.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3315s / 107.4069 s
agent0:                 episode reward: -0.8762,                 loss: nan
agent1:                 episode reward: 0.8762,                 loss: 0.2681
Episode: 7761/30000 (25.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3282s / 107.7350 s
agent0:                 episode reward: -1.0490,                 loss: nan
agent1:                 episode reward: 1.0490,                 loss: 0.2646
Episode: 7781/30000 (25.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3520s / 108.0870 s
agent0:                 episode reward: -0.9684,                 loss: nan
agent1:                 episode reward: 0.9684,                 loss: 0.2689
Episode: 7801/30000 (26.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3545s / 108.4415 s
agent0:                 episode reward: -1.1133,                 loss: nan
agent1:                 episode reward: 1.1133,                 loss: 0.2702
Episode: 7821/30000 (26.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3589s / 108.8004 s
agent0:                 episode reward: -1.0429,                 loss: nan
agent1:                 episode reward: 1.0429,                 loss: 0.2665
Episode: 7841/30000 (26.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3313s / 109.1317 s
agent0:                 episode reward: -0.8153,                 loss: nan
agent1:                 episode reward: 0.8153,                 loss: 0.2667
Episode: 7861/30000 (26.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3339s / 109.4656 s
agent0:                 episode reward: -1.1490,                 loss: nan
agent1:                 episode reward: 1.1490,                 loss: 0.2650
Episode: 7881/30000 (26.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3835s / 109.8491 s
agent0:                 episode reward: -0.9963,                 loss: nan
agent1:                 episode reward: 0.9963,                 loss: 0.2663
Episode: 7901/30000 (26.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3272s / 110.1763 s
agent0:                 episode reward: -1.1022,                 loss: nan
agent1:                 episode reward: 1.1022,                 loss: 0.2664
Episode: 7921/30000 (26.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3313s / 110.5076 s
agent0:                 episode reward: -1.2533,                 loss: nan
agent1:                 episode reward: 1.2533,                 loss: 0.2657
Episode: 7941/30000 (26.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3296s / 110.8373 s
agent0:                 episode reward: -1.0167,                 loss: nan
agent1:                 episode reward: 1.0167,                 loss: 0.2644
Episode: 7961/30000 (26.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4110s / 111.2483 s
agent0:                 episode reward: -1.1852,                 loss: nan
agent1:                 episode reward: 1.1852,                 loss: 0.2676
Episode: 7981/30000 (26.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3456s / 111.5939 s
agent0:                 episode reward: -0.9897,                 loss: nan
agent1:                 episode reward: 0.9897,                 loss: 0.2688
Episode: 8001/30000 (26.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3317s / 111.9256 s
agent0:                 episode reward: -0.8623,                 loss: nan
agent1:                 episode reward: 0.8623,                 loss: 0.2701
Episode: 8021/30000 (26.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3326s / 112.2583 s
agent0:                 episode reward: -1.3007,                 loss: nan
agent1:                 episode reward: 1.3007,                 loss: 0.2658
Episode: 8041/30000 (26.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3342s / 112.5925 s
agent0:                 episode reward: -1.1133,                 loss: nan
agent1:                 episode reward: 1.1133,                 loss: 0.2689
Episode: 8061/30000 (26.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3332s / 112.9256 s
agent0:                 episode reward: -0.8095,                 loss: nan
agent1:                 episode reward: 0.8095,                 loss: 0.2665
Episode: 8081/30000 (26.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3374s / 113.2630 s
agent0:                 episode reward: -1.0421,                 loss: nan
agent1:                 episode reward: 1.0421,                 loss: 0.2673
Episode: 8101/30000 (27.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3386s / 113.6017 s
agent0:                 episode reward: -1.1529,                 loss: nan
agent1:                 episode reward: 1.1529,                 loss: 0.2685
Episode: 8121/30000 (27.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3349s / 113.9365 s
agent0:                 episode reward: -0.9518,                 loss: nan
agent1:                 episode reward: 0.9518,                 loss: 0.2670
Episode: 8141/30000 (27.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3420s / 114.2785 s
agent0:                 episode reward: -1.0532,                 loss: nan
agent1:                 episode reward: 1.0532,                 loss: 0.2646
Episode: 8161/30000 (27.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3517s / 114.6302 s
agent0:                 episode reward: -1.1202,                 loss: nan
agent1:                 episode reward: 1.1202,                 loss: 0.2654
Episode: 8181/30000 (27.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3439s / 114.9741 s
agent0:                 episode reward: -0.9747,                 loss: nan
agent1:                 episode reward: 0.9747,                 loss: 0.2652
Episode: 8201/30000 (27.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3391s / 115.3132 s
agent0:                 episode reward: -1.3627,                 loss: nan
agent1:                 episode reward: 1.3627,                 loss: 0.2660
Episode: 8221/30000 (27.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3486s / 115.6618 s
agent0:                 episode reward: -0.7355,                 loss: nan
agent1:                 episode reward: 0.7355,                 loss: 0.2704
Episode: 8241/30000 (27.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3395s / 116.0014 s
agent0:                 episode reward: -0.8264,                 loss: nan
agent1:                 episode reward: 0.8264,                 loss: 0.2633
Episode: 8261/30000 (27.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3494s / 116.3508 s
agent0:                 episode reward: -1.1342,                 loss: nan
agent1:                 episode reward: 1.1342,                 loss: 0.2649
Episode: 8281/30000 (27.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3394s / 116.6902 s
agent0:                 episode reward: -1.0662,                 loss: nan
agent1:                 episode reward: 1.0662,                 loss: 0.2606
Episode: 8301/30000 (27.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3604s / 117.0506 s
agent0:                 episode reward: -0.9901,                 loss: nan
agent1:                 episode reward: 0.9901,                 loss: 0.2661
Episode: 8321/30000 (27.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3431s / 117.3936 s
agent0:                 episode reward: -0.9976,                 loss: nan
agent1:                 episode reward: 0.9976,                 loss: 0.2614
Episode: 8341/30000 (27.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3329s / 117.7265 s
agent0:                 episode reward: -0.7880,                 loss: nan
agent1:                 episode reward: 0.7880,                 loss: 0.2644
Episode: 8361/30000 (27.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3382s / 118.0647 s
agent0:                 episode reward: -0.9129,                 loss: nan
agent1:                 episode reward: 0.9129,                 loss: 0.2629
Episode: 8381/30000 (27.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3389s / 118.4036 s
agent0:                 episode reward: -1.2718,                 loss: nan
agent1:                 episode reward: 1.2718,                 loss: 0.2609
Episode: 8401/30000 (28.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3391s / 118.7427 s
agent0:                 episode reward: -1.3336,                 loss: nan
agent1:                 episode reward: 1.3336,                 loss: 0.2621
Episode: 8421/30000 (28.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3388s / 119.0815 s
agent0:                 episode reward: -1.5020,                 loss: nan
agent1:                 episode reward: 1.5020,                 loss: 0.2600
Episode: 8441/30000 (28.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3378s / 119.4193 s
agent0:                 episode reward: -1.0200,                 loss: nan
agent1:                 episode reward: 1.0200,                 loss: 0.2637
Episode: 8461/30000 (28.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3377s / 119.7570 s
agent0:                 episode reward: -0.8214,                 loss: nan
agent1:                 episode reward: 0.8214,                 loss: 0.2650
Episode: 8481/30000 (28.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3462s / 120.1032 s
agent0:                 episode reward: -0.9413,                 loss: nan
agent1:                 episode reward: 0.9413,                 loss: 0.2651
Episode: 8501/30000 (28.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3705s / 120.4738 s
agent0:                 episode reward: -1.0525,                 loss: nan
agent1:                 episode reward: 1.0525,                 loss: 0.2605
Episode: 8521/30000 (28.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3398s / 120.8136 s
agent0:                 episode reward: -1.3215,                 loss: nan
agent1:                 episode reward: 1.3215,                 loss: 0.2640
Episode: 8541/30000 (28.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3463s / 121.1599 s
agent0:                 episode reward: -1.4472,                 loss: nan
agent1:                 episode reward: 1.4472,                 loss: 0.2635
Episode: 8561/30000 (28.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4374s / 121.5974 s
agent0:                 episode reward: -1.2666,                 loss: nan
agent1:                 episode reward: 1.2666,                 loss: 0.2654
Episode: 8581/30000 (28.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3387s / 121.9360 s
agent0:                 episode reward: -1.2414,                 loss: nan
agent1:                 episode reward: 1.2414,                 loss: 0.2665
Episode: 8601/30000 (28.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3698s / 122.3059 s
agent0:                 episode reward: -0.9233,                 loss: nan
agent1:                 episode reward: 0.9233,                 loss: 0.2670
Episode: 8621/30000 (28.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3435s / 122.6493 s
agent0:                 episode reward: -1.0841,                 loss: nan
agent1:                 episode reward: 1.0841,                 loss: 0.2666
Episode: 8641/30000 (28.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3460s / 122.9954 s
agent0:                 episode reward: -0.7621,                 loss: nan
agent1:                 episode reward: 0.7621,                 loss: 0.2669
Episode: 8661/30000 (28.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3469s / 123.3422 s
agent0:                 episode reward: -1.0679,                 loss: nan
agent1:                 episode reward: 1.0679,                 loss: 0.2729
Episode: 8681/30000 (28.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3477s / 123.6900 s
agent0:                 episode reward: -0.5080,                 loss: nan
agent1:                 episode reward: 0.5080,                 loss: 0.2688
Episode: 8701/30000 (29.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3447s / 124.0347 s
agent0:                 episode reward: -0.8809,                 loss: nan
agent1:                 episode reward: 0.8809,                 loss: 0.2659
Episode: 8721/30000 (29.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3418s / 124.3765 s
agent0:                 episode reward: -1.0482,                 loss: nan
agent1:                 episode reward: 1.0482,                 loss: 0.2678
Episode: 8741/30000 (29.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3924s / 124.7689 s
agent0:                 episode reward: -0.9224,                 loss: nan
agent1:                 episode reward: 0.9224,                 loss: 0.2679
Episode: 8761/30000 (29.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3562s / 125.1251 s
agent0:                 episode reward: -1.0672,                 loss: nan
agent1:                 episode reward: 1.0672,                 loss: 0.2674
Episode: 8781/30000 (29.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3443s / 125.4694 s
agent0:                 episode reward: -1.2221,                 loss: nan
agent1:                 episode reward: 1.2221,                 loss: 0.2685
Episode: 8801/30000 (29.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3421s / 125.8115 s
agent0:                 episode reward: -1.0203,                 loss: nan
agent1:                 episode reward: 1.0203,                 loss: 0.2688
Episode: 8821/30000 (29.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3486s / 126.1601 s
agent0:                 episode reward: -1.3007,                 loss: nan
agent1:                 episode reward: 1.3007,                 loss: 0.2654
Episode: 8841/30000 (29.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3544s / 126.5145 s
agent0:                 episode reward: -0.9354,                 loss: nan
agent1:                 episode reward: 0.9354,                 loss: 0.2703
Episode: 8861/30000 (29.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3421s / 126.8567 s
agent0:                 episode reward: -0.8113,                 loss: nan
agent1:                 episode reward: 0.8113,                 loss: 0.2654
Episode: 8881/30000 (29.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3482s / 127.2048 s
agent0:                 episode reward: -0.8092,                 loss: nan
agent1:                 episode reward: 0.8092,                 loss: 0.2668
Episode: 8901/30000 (29.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3435s / 127.5484 s
agent0:                 episode reward: -0.8595,                 loss: nan
agent1:                 episode reward: 0.8595,                 loss: 0.2611
Episode: 8921/30000 (29.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3424s / 127.8907 s
agent0:                 episode reward: -1.4352,                 loss: nan
agent1:                 episode reward: 1.4352,                 loss: 0.2606
Episode: 8941/30000 (29.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3479s / 128.2387 s
agent0:                 episode reward: -0.7520,                 loss: nan
agent1:                 episode reward: 0.7520,                 loss: 0.2599
Episode: 8961/30000 (29.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3490s / 128.5876 s
agent0:                 episode reward: -1.1758,                 loss: nan
agent1:                 episode reward: 1.1758,                 loss: 0.2589
Episode: 8981/30000 (29.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3396s / 128.9272 s
agent0:                 episode reward: -1.0370,                 loss: nan
agent1:                 episode reward: 1.0370,                 loss: 0.2594
Episode: 9001/30000 (30.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3420s / 129.2691 s
agent0:                 episode reward: -1.0376,                 loss: nan
agent1:                 episode reward: 1.0376,                 loss: 0.2572
Episode: 9021/30000 (30.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3565s / 129.6256 s
agent0:                 episode reward: -1.2281,                 loss: nan
agent1:                 episode reward: 1.2281,                 loss: 0.2636
Episode: 9041/30000 (30.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3442s / 129.9698 s
agent0:                 episode reward: -0.9542,                 loss: nan
agent1:                 episode reward: 0.9542,                 loss: 0.2587
Episode: 9061/30000 (30.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3445s / 130.3143 s
agent0:                 episode reward: -0.7230,                 loss: nan
agent1:                 episode reward: 0.7230,                 loss: 0.2611
Episode: 9081/30000 (30.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3455s / 130.6598 s
agent0:                 episode reward: -1.1390,                 loss: nan
agent1:                 episode reward: 1.1390,                 loss: 0.2627
Episode: 9101/30000 (30.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3486s / 131.0085 s
agent0:                 episode reward: -1.0793,                 loss: nan
agent1:                 episode reward: 1.0793,                 loss: 0.2611
Episode: 9121/30000 (30.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3774s / 131.3858 s
agent0:                 episode reward: -1.0551,                 loss: nan
agent1:                 episode reward: 1.0551,                 loss: 0.2569
Episode: 9141/30000 (30.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4177s / 131.8035 s
agent0:                 episode reward: -1.5426,                 loss: nan
agent1:                 episode reward: 1.5426,                 loss: 0.2599
Episode: 9161/30000 (30.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3490s / 132.1526 s
agent0:                 episode reward: -1.2429,                 loss: nan
agent1:                 episode reward: 1.2429,                 loss: 0.2599
Episode: 9181/30000 (30.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3852s / 132.5377 s
agent0:                 episode reward: -1.0169,                 loss: nan
agent1:                 episode reward: 1.0169,                 loss: 0.2606
Episode: 9201/30000 (30.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3498s / 132.8876 s
agent0:                 episode reward: -0.6930,                 loss: nan
agent1:                 episode reward: 0.6930,                 loss: 0.2618
Episode: 9221/30000 (30.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3830s / 133.2705 s
agent0:                 episode reward: -1.0947,                 loss: nan
agent1:                 episode reward: 1.0947,                 loss: 0.2671
Episode: 9241/30000 (30.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3481s / 133.6187 s
agent0:                 episode reward: -1.0416,                 loss: nan
agent1:                 episode reward: 1.0416,                 loss: 0.2729
Episode: 9261/30000 (30.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3701s / 133.9888 s
agent0:                 episode reward: -1.1532,                 loss: nan
agent1:                 episode reward: 1.1532,                 loss: 0.2768
Episode: 9281/30000 (30.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3547s / 134.3435 s
agent0:                 episode reward: -1.2481,                 loss: nan
agent1:                 episode reward: 1.2481,                 loss: 0.2728
Episode: 9301/30000 (31.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3539s / 134.6974 s
agent0:                 episode reward: -0.8516,                 loss: nan
agent1:                 episode reward: 0.8516,                 loss: 0.2747
Episode: 9321/30000 (31.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3530s / 135.0504 s
agent0:                 episode reward: -0.8804,                 loss: nan
agent1:                 episode reward: 0.8804,                 loss: 0.2731
Episode: 9341/30000 (31.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3701s / 135.4204 s
agent0:                 episode reward: -0.7820,                 loss: nan
agent1:                 episode reward: 0.7820,                 loss: 0.2763
Episode: 9361/30000 (31.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3681s / 135.7886 s
agent0:                 episode reward: -0.9893,                 loss: nan
agent1:                 episode reward: 0.9893,                 loss: 0.2739
Episode: 9381/30000 (31.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3574s / 136.1460 s
agent0:                 episode reward: -0.9428,                 loss: nan
agent1:                 episode reward: 0.9428,                 loss: 0.2765
Episode: 9401/30000 (31.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3504s / 136.4963 s
agent0:                 episode reward: -1.1489,                 loss: nan
agent1:                 episode reward: 1.1489,                 loss: 0.2763
Episode: 9421/30000 (31.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3516s / 136.8479 s
agent0:                 episode reward: -1.3160,                 loss: nan
agent1:                 episode reward: 1.3160,                 loss: 0.2788
Episode: 9441/30000 (31.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3627s / 137.2107 s
agent0:                 episode reward: -1.2790,                 loss: nan
agent1:                 episode reward: 1.2790,                 loss: 0.2747
Episode: 9461/30000 (31.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3522s / 137.5629 s
agent0:                 episode reward: -1.0306,                 loss: nan
agent1:                 episode reward: 1.0306,                 loss: 0.2700
Episode: 9481/30000 (31.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3474s / 137.9103 s
agent0:                 episode reward: -1.4983,                 loss: nan
agent1:                 episode reward: 1.4983,                 loss: 0.2753
Episode: 9501/30000 (31.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3513s / 138.2616 s
agent0:                 episode reward: -0.8989,                 loss: nan
agent1:                 episode reward: 0.8989,                 loss: 0.2786
Episode: 9521/30000 (31.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3612s / 138.6227 s
agent0:                 episode reward: -1.1671,                 loss: nan
agent1:                 episode reward: 1.1671,                 loss: 0.2734
Episode: 9541/30000 (31.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3622s / 138.9849 s
agent0:                 episode reward: -1.1246,                 loss: nan
agent1:                 episode reward: 1.1246,                 loss: 0.2739
Episode: 9561/30000 (31.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3605s / 139.3454 s
agent0:                 episode reward: -0.8377,                 loss: nan
agent1:                 episode reward: 0.8377,                 loss: 0.2700
Episode: 9581/30000 (31.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3566s / 139.7020 s
agent0:                 episode reward: -0.9882,                 loss: nan
agent1:                 episode reward: 0.9882,                 loss: 0.2650
Episode: 9601/30000 (32.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3550s / 140.0570 s
agent0:                 episode reward: -1.3251,                 loss: nan
agent1:                 episode reward: 1.3251,                 loss: 0.2678
Episode: 9621/30000 (32.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3618s / 140.4188 s
agent0:                 episode reward: -0.7965,                 loss: nan
agent1:                 episode reward: 0.7965,                 loss: 0.2621
Episode: 9641/30000 (32.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3580s / 140.7767 s
agent0:                 episode reward: -1.2675,                 loss: nan
agent1:                 episode reward: 1.2675,                 loss: 0.2667
Episode: 9661/30000 (32.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3537s / 141.1304 s
agent0:                 episode reward: -1.1314,                 loss: nan
agent1:                 episode reward: 1.1314,                 loss: 0.2653
Episode: 9681/30000 (32.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3705s / 141.5009 s
agent0:                 episode reward: -0.9074,                 loss: nan
agent1:                 episode reward: 0.9074,                 loss: 0.2662
Episode: 9701/30000 (32.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3640s / 141.8648 s
agent0:                 episode reward: -1.0038,                 loss: nan
agent1:                 episode reward: 1.0038,                 loss: 0.2679
Episode: 9721/30000 (32.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4350s / 142.2998 s
agent0:                 episode reward: -0.9609,                 loss: nan
agent1:                 episode reward: 0.9609,                 loss: 0.2674
Episode: 9741/30000 (32.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3591s / 142.6589 s
agent0:                 episode reward: -0.9657,                 loss: nan
agent1:                 episode reward: 0.9657,                 loss: 0.2645
Episode: 9761/30000 (32.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3560s / 143.0149 s
agent0:                 episode reward: -1.1555,                 loss: nan
agent1:                 episode reward: 1.1555,                 loss: 0.2652
Episode: 9781/30000 (32.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3564s / 143.3713 s
agent0:                 episode reward: -0.8258,                 loss: nan
agent1:                 episode reward: 0.8258,                 loss: 0.2662
Episode: 9801/30000 (32.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3592s / 143.7304 s
agent0:                 episode reward: -1.2284,                 loss: nan
agent1:                 episode reward: 1.2284,                 loss: 0.2659
Episode: 9821/30000 (32.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3537s / 144.0841 s
agent0:                 episode reward: -1.0139,                 loss: nan
agent1:                 episode reward: 1.0139,                 loss: 0.2656
Episode: 9841/30000 (32.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3634s / 144.4476 s
agent0:                 episode reward: -0.7496,                 loss: nan
agent1:                 episode reward: 0.7496,                 loss: 0.2646
Episode: 9861/30000 (32.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3626s / 144.8101 s
agent0:                 episode reward: -0.8937,                 loss: nan
agent1:                 episode reward: 0.8937,                 loss: 0.2647
Episode: 9881/30000 (32.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3589s / 145.1690 s
agent0:                 episode reward: -1.2118,                 loss: nan
agent1:                 episode reward: 1.2118,                 loss: 0.2660
Episode: 9901/30000 (33.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3758s / 145.5448 s
agent0:                 episode reward: -1.2771,                 loss: nan
agent1:                 episode reward: 1.2771,                 loss: 0.2510
Episode: 9921/30000 (33.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3630s / 145.9078 s
agent0:                 episode reward: -0.7284,                 loss: nan
agent1:                 episode reward: 0.7284,                 loss: 0.2583
Episode: 9941/30000 (33.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3680s / 146.2758 s
agent0:                 episode reward: -1.1227,                 loss: nan
agent1:                 episode reward: 1.1227,                 loss: 0.2540
Episode: 9961/30000 (33.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3686s / 146.6444 s
agent0:                 episode reward: -1.5113,                 loss: nan
agent1:                 episode reward: 1.5113,                 loss: 0.2543
Episode: 9981/30000 (33.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3735s / 147.0179 s
agent0:                 episode reward: -1.0221,                 loss: nan
agent1:                 episode reward: 1.0221,                 loss: 0.2528
Episode: 10001/30000 (33.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3617s / 147.3796 s
agent0:                 episode reward: -0.9150,                 loss: nan
agent1:                 episode reward: 0.9150,                 loss: 0.2565
Episode: 10021/30000 (33.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3821s / 147.7617 s
agent0:                 episode reward: -1.0458,                 loss: nan
agent1:                 episode reward: 1.0458,                 loss: 0.2568
Episode: 10041/30000 (33.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4056s / 148.1673 s
agent0:                 episode reward: -1.3687,                 loss: nan
agent1:                 episode reward: 1.3687,                 loss: 0.2537
Episode: 10061/30000 (33.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4348s / 148.6021 s
agent0:                 episode reward: -1.2537,                 loss: nan
agent1:                 episode reward: 1.2537,                 loss: 0.2534
Episode: 10081/30000 (33.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4131s / 149.0152 s
agent0:                 episode reward: -0.7759,                 loss: nan
agent1:                 episode reward: 0.7759,                 loss: 0.2546
Episode: 10101/30000 (33.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3618s / 149.3770 s
agent0:                 episode reward: -0.8415,                 loss: nan
agent1:                 episode reward: 0.8415,                 loss: 0.2571
Episode: 10121/30000 (33.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3950s / 149.7721 s
agent0:                 episode reward: -0.8293,                 loss: nan
agent1:                 episode reward: 0.8293,                 loss: 0.2511
Episode: 10141/30000 (33.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3748s / 150.1469 s
agent0:                 episode reward: -1.0789,                 loss: nan
agent1:                 episode reward: 1.0789,                 loss: 0.2568
Episode: 10161/30000 (33.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4028s / 150.5496 s
agent0:                 episode reward: -1.1992,                 loss: nan
agent1:                 episode reward: 1.1992,                 loss: 0.2558
Episode: 10181/30000 (33.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3699s / 150.9196 s
agent0:                 episode reward: -0.9543,                 loss: nan
agent1:                 episode reward: 0.9543,                 loss: 0.2542
Episode: 10201/30000 (34.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3674s / 151.2870 s
agent0:                 episode reward: -1.0798,                 loss: nan
agent1:                 episode reward: 1.0798,                 loss: 0.2551
Episode: 10221/30000 (34.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4189s / 151.7058 s
agent0:                 episode reward: -1.4229,                 loss: nan
agent1:                 episode reward: 1.4229,                 loss: 0.2616
Episode: 10241/30000 (34.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3821s / 152.0879 s
agent0:                 episode reward: -1.0552,                 loss: nan
agent1:                 episode reward: 1.0552,                 loss: 0.2765
Episode: 10261/30000 (34.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4568s / 152.5447 s
agent0:                 episode reward: -1.1501,                 loss: nan
agent1:                 episode reward: 1.1501,                 loss: 0.2761
Episode: 10281/30000 (34.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3641s / 152.9088 s
agent0:                 episode reward: -1.4715,                 loss: nan
agent1:                 episode reward: 1.4715,                 loss: 0.2737
Episode: 10301/30000 (34.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3884s / 153.2973 s
agent0:                 episode reward: -1.1627,                 loss: nan
agent1:                 episode reward: 1.1627,                 loss: 0.2757
Episode: 10321/30000 (34.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3867s / 153.6840 s
agent0:                 episode reward: -1.1184,                 loss: nan
agent1:                 episode reward: 1.1184,                 loss: 0.2733
Episode: 10341/30000 (34.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3836s / 154.0676 s
agent0:                 episode reward: -0.9684,                 loss: nan
agent1:                 episode reward: 0.9684,                 loss: 0.2755
Episode: 10361/30000 (34.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3671s / 154.4347 s
agent0:                 episode reward: -1.2586,                 loss: nan
agent1:                 episode reward: 1.2586,                 loss: 0.2728
Episode: 10381/30000 (34.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3785s / 154.8132 s
agent0:                 episode reward: -0.7470,                 loss: nan
agent1:                 episode reward: 0.7470,                 loss: 0.2754
Episode: 10401/30000 (34.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3912s / 155.2044 s
agent0:                 episode reward: -0.9226,                 loss: nan
agent1:                 episode reward: 0.9226,                 loss: 0.2713
Episode: 10421/30000 (34.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3857s / 155.5901 s
agent0:                 episode reward: -0.9808,                 loss: nan
agent1:                 episode reward: 0.9808,                 loss: 0.2748
Episode: 10441/30000 (34.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3875s / 155.9775 s
agent0:                 episode reward: -1.2265,                 loss: nan
agent1:                 episode reward: 1.2265,                 loss: 0.2734
Episode: 10461/30000 (34.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4293s / 156.4068 s
agent0:                 episode reward: -1.2134,                 loss: nan
agent1:                 episode reward: 1.2134,                 loss: 0.2738
Episode: 10481/30000 (34.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3819s / 156.7887 s
agent0:                 episode reward: -0.7408,                 loss: nan
agent1:                 episode reward: 0.7408,                 loss: 0.2715
Episode: 10501/30000 (35.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3650s / 157.1538 s
agent0:                 episode reward: -1.3643,                 loss: nan
agent1:                 episode reward: 1.3643,                 loss: 0.2717
Episode: 10521/30000 (35.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3701s / 157.5239 s
agent0:                 episode reward: -0.7880,                 loss: nan
agent1:                 episode reward: 0.7880,                 loss: 0.2705
Episode: 10541/30000 (35.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3816s / 157.9055 s
agent0:                 episode reward: -1.2016,                 loss: nan
agent1:                 episode reward: 1.2016,                 loss: 0.2757
Episode: 10561/30000 (35.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3849s / 158.2903 s
agent0:                 episode reward: -1.0040,                 loss: nan
agent1:                 episode reward: 1.0040,                 loss: 0.2711
Episode: 10581/30000 (35.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3651s / 158.6555 s
agent0:                 episode reward: -0.9451,                 loss: nan
agent1:                 episode reward: 0.9451,                 loss: 0.2687
Episode: 10601/30000 (35.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3656s / 159.0211 s
agent0:                 episode reward: -1.1252,                 loss: nan
agent1:                 episode reward: 1.1252,                 loss: 0.2676
Episode: 10621/30000 (35.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3656s / 159.3867 s
agent0:                 episode reward: -1.3807,                 loss: nan
agent1:                 episode reward: 1.3807,                 loss: 0.2686
Episode: 10641/30000 (35.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3944s / 159.7811 s
agent0:                 episode reward: -1.1336,                 loss: nan
agent1:                 episode reward: 1.1336,                 loss: 0.2649
Episode: 10661/30000 (35.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3634s / 160.1444 s
agent0:                 episode reward: -0.7991,                 loss: nan
agent1:                 episode reward: 0.7991,                 loss: 0.2663
Episode: 10681/30000 (35.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3643s / 160.5087 s
agent0:                 episode reward: -1.2570,                 loss: nan
agent1:                 episode reward: 1.2570,                 loss: 0.2660
Episode: 10701/30000 (35.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3678s / 160.8765 s
agent0:                 episode reward: -1.1074,                 loss: nan
agent1:                 episode reward: 1.1074,                 loss: 0.2629
Episode: 10721/30000 (35.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3719s / 161.2484 s
agent0:                 episode reward: -0.8674,                 loss: nan
agent1:                 episode reward: 0.8674,                 loss: 0.2680
Episode: 10741/30000 (35.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3726s / 161.6210 s
agent0:                 episode reward: -0.9545,                 loss: nan
agent1:                 episode reward: 0.9545,                 loss: 0.2673
Episode: 10761/30000 (35.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3668s / 161.9878 s
agent0:                 episode reward: -1.0264,                 loss: nan
agent1:                 episode reward: 1.0264,                 loss: 0.2680
Episode: 10781/30000 (35.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3731s / 162.3609 s
agent0:                 episode reward: -1.2302,                 loss: nan
agent1:                 episode reward: 1.2302,                 loss: 0.2682
Episode: 10801/30000 (36.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4466s / 162.8075 s
agent0:                 episode reward: -1.1382,                 loss: nan
agent1:                 episode reward: 1.1382,                 loss: 0.2669
Episode: 10821/30000 (36.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3696s / 163.1771 s
agent0:                 episode reward: -0.7786,                 loss: nan
agent1:                 episode reward: 0.7786,                 loss: 0.2657
Episode: 10841/30000 (36.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3657s / 163.5429 s
agent0:                 episode reward: -1.2973,                 loss: nan
agent1:                 episode reward: 1.2973,                 loss: 0.2653
Episode: 10861/30000 (36.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3791s / 163.9219 s
agent0:                 episode reward: -1.0089,                 loss: nan
agent1:                 episode reward: 1.0089,                 loss: 0.2656
Episode: 10881/30000 (36.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3736s / 164.2956 s
agent0:                 episode reward: -1.0804,                 loss: nan
agent1:                 episode reward: 1.0804,                 loss: 0.2632
Episode: 10901/30000 (36.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3643s / 164.6599 s
agent0:                 episode reward: -1.1835,                 loss: nan
agent1:                 episode reward: 1.1835,                 loss: 0.2619
Episode: 10921/30000 (36.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3791s / 165.0390 s
agent0:                 episode reward: -1.2917,                 loss: nan
agent1:                 episode reward: 1.2917,                 loss: 0.2604
Episode: 10941/30000 (36.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3727s / 165.4118 s
agent0:                 episode reward: -1.0736,                 loss: nan
agent1:                 episode reward: 1.0736,                 loss: 0.2594
Episode: 10961/30000 (36.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4025s / 165.8143 s
agent0:                 episode reward: -0.9632,                 loss: nan
agent1:                 episode reward: 0.9632,                 loss: 0.2616
Episode: 10981/30000 (36.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3938s / 166.2081 s
agent0:                 episode reward: -1.0482,                 loss: nan
agent1:                 episode reward: 1.0482,                 loss: 0.2598
Episode: 11001/30000 (36.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3738s / 166.5819 s
agent0:                 episode reward: -1.0987,                 loss: nan
agent1:                 episode reward: 1.0987,                 loss: 0.2632
Episode: 11021/30000 (36.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3683s / 166.9502 s
agent0:                 episode reward: -1.0359,                 loss: nan
agent1:                 episode reward: 1.0359,                 loss: 0.2626
Episode: 11041/30000 (36.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3670s / 167.3172 s
agent0:                 episode reward: -1.1303,                 loss: nan
agent1:                 episode reward: 1.1303,                 loss: 0.2598
Episode: 11061/30000 (36.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3777s / 167.6950 s
agent0:                 episode reward: -1.4309,                 loss: nan
agent1:                 episode reward: 1.4309,                 loss: 0.2621
Episode: 11081/30000 (36.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3765s / 168.0714 s
agent0:                 episode reward: -0.8244,                 loss: nan
agent1:                 episode reward: 0.8244,                 loss: 0.2611
Episode: 11101/30000 (37.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3756s / 168.4470 s
agent0:                 episode reward: -1.0458,                 loss: nan
agent1:                 episode reward: 1.0458,                 loss: 0.2594
Episode: 11121/30000 (37.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3829s / 168.8299 s
agent0:                 episode reward: -1.0084,                 loss: nan
agent1:                 episode reward: 1.0084,                 loss: 0.2621
Episode: 11141/30000 (37.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3807s / 169.2106 s
agent0:                 episode reward: -1.0850,                 loss: nan
agent1:                 episode reward: 1.0850,                 loss: 0.2596
Episode: 11161/30000 (37.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3786s / 169.5892 s
agent0:                 episode reward: -1.0899,                 loss: nan
agent1:                 episode reward: 1.0899,                 loss: 0.2605
Episode: 11181/30000 (37.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3869s / 169.9761 s
agent0:                 episode reward: -1.3045,                 loss: nan
agent1:                 episode reward: 1.3045,                 loss: 0.2611
Episode: 11201/30000 (37.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3786s / 170.3547 s
agent0:                 episode reward: -1.5759,                 loss: nan
agent1:                 episode reward: 1.5759,                 loss: 0.2608
Episode: 11221/30000 (37.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3900s / 170.7447 s
agent0:                 episode reward: -0.9761,                 loss: nan
agent1:                 episode reward: 0.9761,                 loss: 0.2692
Episode: 11241/30000 (37.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3825s / 171.1272 s
agent0:                 episode reward: -1.1028,                 loss: nan
agent1:                 episode reward: 1.1028,                 loss: 0.2715
Episode: 11261/30000 (37.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3819s / 171.5091 s
agent0:                 episode reward: -1.2536,                 loss: nan
agent1:                 episode reward: 1.2536,                 loss: 0.2703
Episode: 11281/30000 (37.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4095s / 171.9187 s
agent0:                 episode reward: -1.3573,                 loss: nan
agent1:                 episode reward: 1.3573,                 loss: 0.2730
Episode: 11301/30000 (37.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3881s / 172.3067 s
agent0:                 episode reward: -1.5672,                 loss: nan
agent1:                 episode reward: 1.5672,                 loss: 0.2736
Episode: 11321/30000 (37.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3824s / 172.6891 s
agent0:                 episode reward: -1.0938,                 loss: nan
agent1:                 episode reward: 1.0938,                 loss: 0.2764
Episode: 11341/30000 (37.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4925s / 173.1816 s
agent0:                 episode reward: -1.2952,                 loss: nan
agent1:                 episode reward: 1.2952,                 loss: 0.2729
Episode: 11361/30000 (37.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3956s / 173.5772 s
agent0:                 episode reward: -0.8633,                 loss: nan
agent1:                 episode reward: 0.8633,                 loss: 0.2737
Episode: 11381/30000 (37.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4235s / 174.0007 s
agent0:                 episode reward: -0.9403,                 loss: nan
agent1:                 episode reward: 0.9403,                 loss: 0.2703
Episode: 11401/30000 (38.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4001s / 174.4008 s
agent0:                 episode reward: -1.2541,                 loss: nan
agent1:                 episode reward: 1.2541,                 loss: 0.2760
Episode: 11421/30000 (38.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4480s / 174.8488 s
agent0:                 episode reward: -1.2482,                 loss: nan
agent1:                 episode reward: 1.2482,                 loss: 0.2733
Episode: 11441/30000 (38.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3911s / 175.2399 s
agent0:                 episode reward: -1.1830,                 loss: nan
agent1:                 episode reward: 1.1830,                 loss: 0.2696
Episode: 11461/30000 (38.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3944s / 175.6343 s
agent0:                 episode reward: -0.9108,                 loss: nan
agent1:                 episode reward: 0.9108,                 loss: 0.2720
Episode: 11481/30000 (38.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4408s / 176.0751 s
agent0:                 episode reward: -0.7561,                 loss: nan
agent1:                 episode reward: 0.7561,                 loss: 0.2725
Episode: 11501/30000 (38.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3860s / 176.4612 s
agent0:                 episode reward: -0.7744,                 loss: nan
agent1:                 episode reward: 0.7744,                 loss: 0.2699
Episode: 11521/30000 (38.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3731s / 176.8342 s
agent0:                 episode reward: -0.5466,                 loss: nan
agent1:                 episode reward: 0.5466,                 loss: 0.2718
Episode: 11541/30000 (38.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3733s / 177.2075 s
agent0:                 episode reward: -1.1901,                 loss: nan
agent1:                 episode reward: 1.1901,                 loss: 0.2731
Episode: 11561/30000 (38.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3787s / 177.5862 s
agent0:                 episode reward: -1.0056,                 loss: nan
agent1:                 episode reward: 1.0056,                 loss: 0.2674
Episode: 11581/30000 (38.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3880s / 177.9742 s
agent0:                 episode reward: -0.7455,                 loss: nan
agent1:                 episode reward: 0.7455,                 loss: 0.2647
Episode: 11601/30000 (38.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3766s / 178.3508 s
agent0:                 episode reward: -0.8762,                 loss: nan
agent1:                 episode reward: 0.8762,                 loss: 0.2669
Episode: 11621/30000 (38.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3788s / 178.7297 s
agent0:                 episode reward: -0.9352,                 loss: nan
agent1:                 episode reward: 0.9352,                 loss: 0.2669
Episode: 11641/30000 (38.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3779s / 179.1075 s
agent0:                 episode reward: -0.9527,                 loss: nan
agent1:                 episode reward: 0.9527,                 loss: 0.2680
Episode: 11661/30000 (38.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3785s / 179.4860 s
agent0:                 episode reward: -0.8287,                 loss: nan
agent1:                 episode reward: 0.8287,                 loss: 0.2693
Episode: 11681/30000 (38.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3776s / 179.8636 s
agent0:                 episode reward: -1.0491,                 loss: nan
agent1:                 episode reward: 1.0491,                 loss: 0.2669
Episode: 11701/30000 (39.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3776s / 180.2412 s
agent0:                 episode reward: -1.0559,                 loss: nan
agent1:                 episode reward: 1.0559,                 loss: 0.2681
Episode: 11721/30000 (39.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3745s / 180.6158 s
agent0:                 episode reward: -0.9388,                 loss: nan
agent1:                 episode reward: 0.9388,                 loss: 0.2670
Episode: 11741/30000 (39.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3947s / 181.0105 s
agent0:                 episode reward: -1.1359,                 loss: nan
agent1:                 episode reward: 1.1359,                 loss: 0.2647
Episode: 11761/30000 (39.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3751s / 181.3856 s
agent0:                 episode reward: -1.0365,                 loss: nan
agent1:                 episode reward: 1.0365,                 loss: 0.2620
Episode: 11781/30000 (39.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3836s / 181.7692 s
agent0:                 episode reward: -1.0675,                 loss: nan
agent1:                 episode reward: 1.0675,                 loss: 0.2649
Episode: 11801/30000 (39.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3771s / 182.1462 s
agent0:                 episode reward: -1.3005,                 loss: nan
agent1:                 episode reward: 1.3005,                 loss: 0.2673
Episode: 11821/30000 (39.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3880s / 182.5343 s
agent0:                 episode reward: -1.0846,                 loss: nan
agent1:                 episode reward: 1.0846,                 loss: 0.2654
Episode: 11841/30000 (39.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4179s / 182.9521 s
agent0:                 episode reward: -1.4928,                 loss: nan
agent1:                 episode reward: 1.4928,                 loss: 0.2679
Episode: 11861/30000 (39.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4681s / 183.4202 s
agent0:                 episode reward: -1.0037,                 loss: nan
agent1:                 episode reward: 1.0037,                 loss: 0.2640
Episode: 11881/30000 (39.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3857s / 183.8059 s
agent0:                 episode reward: -1.2500,                 loss: nan
agent1:                 episode reward: 1.2500,                 loss: 0.2662
Episode: 11901/30000 (39.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3901s / 184.1960 s
agent0:                 episode reward: -0.9484,                 loss: nan
agent1:                 episode reward: 0.9484,                 loss: 0.2693
Episode: 11921/30000 (39.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3795s / 184.5756 s
agent0:                 episode reward: -0.8890,                 loss: nan
agent1:                 episode reward: 0.8890,                 loss: 0.2714
Episode: 11941/30000 (39.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3830s / 184.9586 s
agent0:                 episode reward: -1.2301,                 loss: nan
agent1:                 episode reward: 1.2301,                 loss: 0.2727
Episode: 11961/30000 (39.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3857s / 185.3443 s
agent0:                 episode reward: -0.9527,                 loss: nan
agent1:                 episode reward: 0.9527,                 loss: 0.2725
Episode: 11981/30000 (39.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3842s / 185.7284 s
agent0:                 episode reward: -1.0399,                 loss: nan
agent1:                 episode reward: 1.0399,                 loss: 0.2713
Episode: 12001/30000 (40.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3987s / 186.1272 s
agent0:                 episode reward: -1.0145,                 loss: nan
agent1:                 episode reward: 1.0145,                 loss: 0.2685
Episode: 12021/30000 (40.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3842s / 186.5114 s
agent0:                 episode reward: -1.2404,                 loss: nan
agent1:                 episode reward: 1.2404,                 loss: 0.2743
Episode: 12041/30000 (40.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3971s / 186.9084 s
agent0:                 episode reward: -1.1328,                 loss: nan
agent1:                 episode reward: 1.1328,                 loss: 0.2693
Episode: 12061/30000 (40.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3846s / 187.2930 s
agent0:                 episode reward: -1.0612,                 loss: nan
agent1:                 episode reward: 1.0612,                 loss: 0.2664
Episode: 12081/30000 (40.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3883s / 187.6814 s
agent0:                 episode reward: -1.3152,                 loss: nan
agent1:                 episode reward: 1.3152,                 loss: 0.2684
Episode: 12101/30000 (40.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3843s / 188.0656 s
agent0:                 episode reward: -0.9598,                 loss: nan
agent1:                 episode reward: 0.9598,                 loss: 0.2710
Episode: 12121/30000 (40.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3866s / 188.4523 s
agent0:                 episode reward: -1.1389,                 loss: nan
agent1:                 episode reward: 1.1389,                 loss: 0.2707
Episode: 12141/30000 (40.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3819s / 188.8342 s
agent0:                 episode reward: -1.2279,                 loss: nan
agent1:                 episode reward: 1.2279,                 loss: 0.2717
Episode: 12161/30000 (40.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4161s / 189.2503 s
agent0:                 episode reward: -0.8386,                 loss: nan
agent1:                 episode reward: 0.8386,                 loss: 0.2716
Episode: 12181/30000 (40.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3991s / 189.6494 s
agent0:                 episode reward: -1.0300,                 loss: nan
agent1:                 episode reward: 1.0300,                 loss: 0.2666
Episode: 12201/30000 (40.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4493s / 190.0988 s
agent0:                 episode reward: -1.2107,                 loss: nan
agent1:                 episode reward: 1.2107,                 loss: 0.2733
Episode: 12221/30000 (40.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3935s / 190.4922 s
agent0:                 episode reward: -1.0666,                 loss: nan
agent1:                 episode reward: 1.0666,                 loss: 0.2662
Episode: 12241/30000 (40.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3961s / 190.8883 s
agent0:                 episode reward: -1.3429,                 loss: nan
agent1:                 episode reward: 1.3429,                 loss: 0.2514
Episode: 12261/30000 (40.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4123s / 191.3006 s
agent0:                 episode reward: -1.1540,                 loss: nan
agent1:                 episode reward: 1.1540,                 loss: 0.2536
Episode: 12281/30000 (40.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3972s / 191.6977 s
agent0:                 episode reward: -1.0679,                 loss: nan
agent1:                 episode reward: 1.0679,                 loss: 0.2536
Episode: 12301/30000 (41.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3915s / 192.0892 s
agent0:                 episode reward: -1.3232,                 loss: nan
agent1:                 episode reward: 1.3232,                 loss: 0.2519
Episode: 12321/30000 (41.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4004s / 192.4896 s
agent0:                 episode reward: -1.3927,                 loss: nan
agent1:                 episode reward: 1.3927,                 loss: 0.2551
Episode: 12341/30000 (41.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4096s / 192.8992 s
agent0:                 episode reward: -1.0949,                 loss: nan
agent1:                 episode reward: 1.0949,                 loss: 0.2576
Episode: 12361/30000 (41.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4326s / 193.3317 s
agent0:                 episode reward: -1.0316,                 loss: nan
agent1:                 episode reward: 1.0316,                 loss: 0.2559
Episode: 12381/30000 (41.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4259s / 193.7576 s
agent0:                 episode reward: -0.9480,                 loss: nan
agent1:                 episode reward: 0.9480,                 loss: 0.2535
Episode: 12401/30000 (41.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3975s / 194.1552 s
agent0:                 episode reward: -1.0234,                 loss: nan
agent1:                 episode reward: 1.0234,                 loss: 0.2552
Episode: 12421/30000 (41.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3900s / 194.5452 s
agent0:                 episode reward: -1.2197,                 loss: nan
agent1:                 episode reward: 1.2197,                 loss: 0.2539
Episode: 12441/30000 (41.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4007s / 194.9459 s
agent0:                 episode reward: -1.1565,                 loss: nan
agent1:                 episode reward: 1.1565,                 loss: 0.2548
Episode: 12461/30000 (41.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3885s / 195.3345 s
agent0:                 episode reward: -1.0643,                 loss: nan
agent1:                 episode reward: 1.0643,                 loss: 0.2527
Episode: 12481/30000 (41.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3927s / 195.7271 s
agent0:                 episode reward: -0.8784,                 loss: nan
agent1:                 episode reward: 0.8784,                 loss: 0.2536
Episode: 12501/30000 (41.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4361s / 196.1633 s
agent0:                 episode reward: -1.2524,                 loss: nan
agent1:                 episode reward: 1.2524,                 loss: 0.2550
Episode: 12521/30000 (41.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3942s / 196.5575 s
agent0:                 episode reward: -1.0171,                 loss: nan
agent1:                 episode reward: 1.0171,                 loss: 0.2537
Episode: 12541/30000 (41.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4205s / 196.9780 s
agent0:                 episode reward: -1.1836,                 loss: nan
agent1:                 episode reward: 1.1836,                 loss: 0.2540
Episode: 12561/30000 (41.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3888s / 197.3667 s
agent0:                 episode reward: -1.0080,                 loss: nan
agent1:                 episode reward: 1.0080,                 loss: 0.2663
Episode: 12581/30000 (41.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3911s / 197.7578 s
agent0:                 episode reward: -1.2112,                 loss: nan
agent1:                 episode reward: 1.2112,                 loss: 0.2704
Episode: 12601/30000 (42.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3908s / 198.1486 s
agent0:                 episode reward: -1.0098,                 loss: nan
agent1:                 episode reward: 1.0098,                 loss: 0.2663
Episode: 12621/30000 (42.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3888s / 198.5375 s
agent0:                 episode reward: -1.1181,                 loss: nan
agent1:                 episode reward: 1.1181,                 loss: 0.2683
Episode: 12641/30000 (42.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4014s / 198.9388 s
agent0:                 episode reward: -0.9501,                 loss: nan
agent1:                 episode reward: 0.9501,                 loss: 0.2680
Episode: 12661/30000 (42.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4101s / 199.3489 s
agent0:                 episode reward: -0.7195,                 loss: nan
agent1:                 episode reward: 0.7195,                 loss: 0.2707
Episode: 12681/30000 (42.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4032s / 199.7522 s
agent0:                 episode reward: -1.0678,                 loss: nan
agent1:                 episode reward: 1.0678,                 loss: 0.2692
Episode: 12701/30000 (42.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3954s / 200.1476 s
agent0:                 episode reward: -0.7831,                 loss: nan
agent1:                 episode reward: 0.7831,                 loss: 0.2672
Episode: 12721/30000 (42.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3966s / 200.5442 s
agent0:                 episode reward: -1.0053,                 loss: nan
agent1:                 episode reward: 1.0053,                 loss: 0.2727
Episode: 12741/30000 (42.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3914s / 200.9355 s
agent0:                 episode reward: -0.9468,                 loss: nan
agent1:                 episode reward: 0.9468,                 loss: 0.2712
Episode: 12761/30000 (42.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4007s / 201.3363 s
agent0:                 episode reward: -1.2999,                 loss: nan
agent1:                 episode reward: 1.2999,                 loss: 0.2664
Episode: 12781/30000 (42.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3948s / 201.7310 s
agent0:                 episode reward: -1.3012,                 loss: nan
agent1:                 episode reward: 1.3012,                 loss: 0.2688
Episode: 12801/30000 (42.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4060s / 202.1370 s
agent0:                 episode reward: -1.2136,                 loss: nan
agent1:                 episode reward: 1.2136,                 loss: 0.2694
Episode: 12821/30000 (42.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3919s / 202.5289 s
agent0:                 episode reward: -0.9247,                 loss: nan
agent1:                 episode reward: 0.9247,                 loss: 0.2710
Episode: 12841/30000 (42.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3983s / 202.9271 s
agent0:                 episode reward: -1.0856,                 loss: nan
agent1:                 episode reward: 1.0856,                 loss: 0.2751
Episode: 12861/30000 (42.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3944s / 203.3216 s
agent0:                 episode reward: -1.0900,                 loss: nan
agent1:                 episode reward: 1.0900,                 loss: 0.2695
Episode: 12881/30000 (42.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4795s / 203.8010 s
agent0:                 episode reward: -1.1698,                 loss: nan
agent1:                 episode reward: 1.1698,                 loss: 0.2717
Episode: 12901/30000 (43.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4258s / 204.2269 s
agent0:                 episode reward: -0.9264,                 loss: nan
agent1:                 episode reward: 0.9264,                 loss: 0.2691
Episode: 12921/30000 (43.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4057s / 204.6326 s
agent0:                 episode reward: -1.1758,                 loss: nan
agent1:                 episode reward: 1.1758,                 loss: 0.2642
Episode: 12941/30000 (43.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4125s / 205.0451 s
agent0:                 episode reward: -0.9147,                 loss: nan
agent1:                 episode reward: 0.9147,                 loss: 0.2633
Episode: 12961/30000 (43.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4018s / 205.4468 s
agent0:                 episode reward: -1.1910,                 loss: nan
agent1:                 episode reward: 1.1910,                 loss: 0.2650
Episode: 12981/30000 (43.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4000s / 205.8468 s
agent0:                 episode reward: -1.0182,                 loss: nan
agent1:                 episode reward: 1.0182,                 loss: 0.2689
Episode: 13001/30000 (43.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4067s / 206.2536 s
agent0:                 episode reward: -1.0967,                 loss: nan
agent1:                 episode reward: 1.0967,                 loss: 0.2621
Episode: 13021/30000 (43.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3979s / 206.6514 s
agent0:                 episode reward: -1.1894,                 loss: nan
agent1:                 episode reward: 1.1894,                 loss: 0.2660
Episode: 13041/30000 (43.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3962s / 207.0477 s
agent0:                 episode reward: -0.9567,                 loss: nan
agent1:                 episode reward: 0.9567,                 loss: 0.2635
Episode: 13061/30000 (43.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3984s / 207.4460 s
agent0:                 episode reward: -0.8836,                 loss: nan
agent1:                 episode reward: 0.8836,                 loss: 0.2666
Episode: 13081/30000 (43.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4207s / 207.8667 s
agent0:                 episode reward: -1.2240,                 loss: nan
agent1:                 episode reward: 1.2240,                 loss: 0.2659
Episode: 13101/30000 (43.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4237s / 208.2905 s
agent0:                 episode reward: -1.0841,                 loss: nan
agent1:                 episode reward: 1.0841,                 loss: 0.2631
Episode: 13121/30000 (43.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3992s / 208.6896 s
agent0:                 episode reward: -0.9934,                 loss: nan
agent1:                 episode reward: 0.9934,                 loss: 0.2652
Episode: 13141/30000 (43.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4003s / 209.0899 s
agent0:                 episode reward: -0.9362,                 loss: nan
agent1:                 episode reward: 0.9362,                 loss: 0.2658
Episode: 13161/30000 (43.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4068s / 209.4967 s
agent0:                 episode reward: -1.3319,                 loss: nan
agent1:                 episode reward: 1.3319,                 loss: 0.2685
Episode: 13181/30000 (43.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4007s / 209.8974 s
agent0:                 episode reward: -0.9130,                 loss: nan
agent1:                 episode reward: 0.9130,                 loss: 0.2668
Episode: 13201/30000 (44.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4010s / 210.2984 s
agent0:                 episode reward: -1.1840,                 loss: nan
agent1:                 episode reward: 1.1840,                 loss: 0.2672
Episode: 13221/30000 (44.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4280s / 210.7264 s
agent0:                 episode reward: -1.1257,                 loss: nan
agent1:                 episode reward: 1.1257,                 loss: 0.2611
Episode: 13241/30000 (44.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4283s / 211.1547 s
agent0:                 episode reward: -1.0697,                 loss: nan
agent1:                 episode reward: 1.0697,                 loss: 0.2628
Episode: 13261/30000 (44.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4058s / 211.5606 s
agent0:                 episode reward: -1.3304,                 loss: nan
agent1:                 episode reward: 1.3304,                 loss: 0.2627
Episode: 13281/30000 (44.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3999s / 211.9605 s
agent0:                 episode reward: -1.2056,                 loss: nan
agent1:                 episode reward: 1.2056,                 loss: 0.2605
Episode: 13301/30000 (44.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4023s / 212.3628 s
agent0:                 episode reward: -0.8809,                 loss: nan
agent1:                 episode reward: 0.8809,                 loss: 0.2614
Episode: 13321/30000 (44.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3960s / 212.7589 s
agent0:                 episode reward: -0.8663,                 loss: nan
agent1:                 episode reward: 0.8663,                 loss: 0.2586
Episode: 13341/30000 (44.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4029s / 213.1618 s
agent0:                 episode reward: -1.2862,                 loss: nan
agent1:                 episode reward: 1.2862,                 loss: 0.2613
Episode: 13361/30000 (44.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4011s / 213.5629 s
agent0:                 episode reward: -1.1391,                 loss: nan
agent1:                 episode reward: 1.1391,                 loss: 0.2624
Episode: 13381/30000 (44.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4716s / 214.0345 s
agent0:                 episode reward: -1.1961,                 loss: nan
agent1:                 episode reward: 1.1961,                 loss: 0.2612
Episode: 13401/30000 (44.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4143s / 214.4488 s
agent0:                 episode reward: -0.9614,                 loss: nan
agent1:                 episode reward: 0.9614,                 loss: 0.2628
Episode: 13421/30000 (44.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3993s / 214.8481 s
agent0:                 episode reward: -1.0791,                 loss: nan
agent1:                 episode reward: 1.0791,                 loss: 0.2619
Episode: 13441/30000 (44.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4093s / 215.2574 s
agent0:                 episode reward: -0.8243,                 loss: nan
agent1:                 episode reward: 0.8243,                 loss: 0.2583
Episode: 13461/30000 (44.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4038s / 215.6613 s
agent0:                 episode reward: -1.0425,                 loss: nan
agent1:                 episode reward: 1.0425,                 loss: 0.2612
Episode: 13481/30000 (44.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4326s / 216.0938 s
agent0:                 episode reward: -0.7088,                 loss: nan
agent1:                 episode reward: 0.7088,                 loss: 0.2604
Episode: 13501/30000 (45.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4176s / 216.5114 s
agent0:                 episode reward: -1.3222,                 loss: nan
agent1:                 episode reward: 1.3222,                 loss: 0.2605
Episode: 13521/30000 (45.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4022s / 216.9136 s
agent0:                 episode reward: -1.1854,                 loss: nan
agent1:                 episode reward: 1.1854,                 loss: 0.2601
Episode: 13541/30000 (45.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4145s / 217.3281 s
agent0:                 episode reward: -1.0017,                 loss: nan
agent1:                 episode reward: 1.0017,                 loss: 0.2605
Episode: 13561/30000 (45.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4016s / 217.7297 s
agent0:                 episode reward: -0.7875,                 loss: nan
agent1:                 episode reward: 0.7875,                 loss: 0.2699
Episode: 13581/30000 (45.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4030s / 218.1327 s
agent0:                 episode reward: -1.0211,                 loss: nan
agent1:                 episode reward: 1.0211,                 loss: 0.2762
Episode: 13601/30000 (45.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4098s / 218.5425 s
agent0:                 episode reward: -0.7981,                 loss: nan
agent1:                 episode reward: 0.7981,                 loss: 0.2775
Episode: 13621/30000 (45.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4062s / 218.9487 s
agent0:                 episode reward: -1.0209,                 loss: nan
agent1:                 episode reward: 1.0209,                 loss: 0.2792
Episode: 13641/30000 (45.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4084s / 219.3571 s
agent0:                 episode reward: -1.1134,                 loss: nan
agent1:                 episode reward: 1.1134,                 loss: 0.2754
Episode: 13661/30000 (45.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4177s / 219.7748 s
agent0:                 episode reward: -0.8707,                 loss: nan
agent1:                 episode reward: 0.8707,                 loss: 0.2771
Episode: 13681/30000 (45.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4206s / 220.1953 s
agent0:                 episode reward: -0.9624,                 loss: nan
agent1:                 episode reward: 0.9624,                 loss: 0.2772
Episode: 13701/30000 (45.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4095s / 220.6049 s
agent0:                 episode reward: -0.8480,                 loss: nan
agent1:                 episode reward: 0.8480,                 loss: 0.2763
Episode: 13721/30000 (45.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4073s / 221.0121 s
agent0:                 episode reward: -0.9299,                 loss: nan
agent1:                 episode reward: 0.9299,                 loss: 0.2791
Episode: 13741/30000 (45.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4124s / 221.4245 s
agent0:                 episode reward: -0.9847,                 loss: nan
agent1:                 episode reward: 0.9847,                 loss: 0.2800
Episode: 13761/30000 (45.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4049s / 221.8294 s
agent0:                 episode reward: -1.0616,                 loss: nan
agent1:                 episode reward: 1.0616,                 loss: 0.2757
Episode: 13781/30000 (45.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4078s / 222.2372 s
agent0:                 episode reward: -0.8541,                 loss: nan
agent1:                 episode reward: 0.8541,                 loss: 0.2757
Episode: 13801/30000 (46.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4117s / 222.6490 s
agent0:                 episode reward: -1.0921,                 loss: nan
agent1:                 episode reward: 1.0921,                 loss: 0.2774
Episode: 13821/30000 (46.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4097s / 223.0587 s
agent0:                 episode reward: -1.1328,                 loss: nan
agent1:                 episode reward: 1.1328,                 loss: 0.2773
Episode: 13841/30000 (46.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4197s / 223.4784 s
agent0:                 episode reward: -1.0931,                 loss: nan
agent1:                 episode reward: 1.0931,                 loss: 0.2765
Episode: 13861/30000 (46.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4052s / 223.8836 s
agent0:                 episode reward: -1.1631,                 loss: nan
agent1:                 episode reward: 1.1631,                 loss: 0.2786
Episode: 13881/30000 (46.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5126s / 224.3962 s
agent0:                 episode reward: -1.1934,                 loss: nan
agent1:                 episode reward: 1.1934,                 loss: 0.2804
Episode: 13901/30000 (46.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4091s / 224.8053 s
agent0:                 episode reward: -0.9286,                 loss: nan
agent1:                 episode reward: 0.9286,                 loss: 0.2628
Episode: 13921/30000 (46.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4086s / 225.2139 s
agent0:                 episode reward: -0.6633,                 loss: nan
agent1:                 episode reward: 0.6633,                 loss: 0.2597
Episode: 13941/30000 (46.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4153s / 225.6292 s
agent0:                 episode reward: -1.3760,                 loss: nan
agent1:                 episode reward: 1.3760,                 loss: 0.2585
Episode: 13961/30000 (46.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4114s / 226.0407 s
agent0:                 episode reward: -1.1470,                 loss: nan
agent1:                 episode reward: 1.1470,                 loss: 0.2579
Episode: 13981/30000 (46.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4251s / 226.4657 s
agent0:                 episode reward: -1.1851,                 loss: nan
agent1:                 episode reward: 1.1851,                 loss: 0.2575
Episode: 14001/30000 (46.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4215s / 226.8873 s
agent0:                 episode reward: -0.8009,                 loss: nan
agent1:                 episode reward: 0.8009,                 loss: 0.2587
Episode: 14021/30000 (46.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4127s / 227.3000 s
agent0:                 episode reward: -1.0313,                 loss: nan
agent1:                 episode reward: 1.0313,                 loss: 0.2572
Episode: 14041/30000 (46.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4122s / 227.7122 s
agent0:                 episode reward: -1.0217,                 loss: nan
agent1:                 episode reward: 1.0217,                 loss: 0.2600
Episode: 14061/30000 (46.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4127s / 228.1248 s
agent0:                 episode reward: -0.5893,                 loss: nan
agent1:                 episode reward: 0.5893,                 loss: 0.2628
Episode: 14081/30000 (46.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4131s / 228.5379 s
agent0:                 episode reward: -1.0858,                 loss: nan
agent1:                 episode reward: 1.0858,                 loss: 0.2610
Episode: 14101/30000 (47.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4174s / 228.9553 s
agent0:                 episode reward: -1.2957,                 loss: nan
agent1:                 episode reward: 1.2957,                 loss: 0.2571
Episode: 14121/30000 (47.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4180s / 229.3733 s
agent0:                 episode reward: -1.1264,                 loss: nan
agent1:                 episode reward: 1.1264,                 loss: 0.2584
Episode: 14141/30000 (47.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4135s / 229.7869 s
agent0:                 episode reward: -1.2389,                 loss: nan
agent1:                 episode reward: 1.2389,                 loss: 0.2548
Episode: 14161/30000 (47.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4159s / 230.2028 s
agent0:                 episode reward: -1.4732,                 loss: nan
agent1:                 episode reward: 1.4732,                 loss: 0.2591
Episode: 14181/30000 (47.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4119s / 230.6147 s
agent0:                 episode reward: -0.9977,                 loss: nan
agent1:                 episode reward: 0.9977,                 loss: 0.2624
Episode: 14201/30000 (47.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4152s / 231.0299 s
agent0:                 episode reward: -0.9373,                 loss: nan
agent1:                 episode reward: 0.9373,                 loss: 0.2596
Episode: 14221/30000 (47.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4146s / 231.4445 s
agent0:                 episode reward: -1.3115,                 loss: nan
agent1:                 episode reward: 1.3115,                 loss: 0.2640
Episode: 14241/30000 (47.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4126s / 231.8571 s
agent0:                 episode reward: -1.0883,                 loss: nan
agent1:                 episode reward: 1.0883,                 loss: 0.2692
Episode: 14261/30000 (47.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4255s / 232.2827 s
agent0:                 episode reward: -1.2128,                 loss: nan
agent1:                 episode reward: 1.2128,                 loss: 0.2677
Episode: 14281/30000 (47.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4315s / 232.7141 s
agent0:                 episode reward: -1.0470,                 loss: nan
agent1:                 episode reward: 1.0470,                 loss: 0.2665
Episode: 14301/30000 (47.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4157s / 233.1298 s
agent0:                 episode reward: -0.6012,                 loss: nan
agent1:                 episode reward: 0.6012,                 loss: 0.2703
Episode: 14321/30000 (47.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4191s / 233.5489 s
agent0:                 episode reward: -1.0154,                 loss: nan
agent1:                 episode reward: 1.0154,                 loss: 0.2685
Episode: 14341/30000 (47.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4130s / 233.9618 s
agent0:                 episode reward: -1.0004,                 loss: nan
agent1:                 episode reward: 1.0004,                 loss: 0.2659
Episode: 14361/30000 (47.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4656s / 234.4274 s
agent0:                 episode reward: -1.1865,                 loss: nan
agent1:                 episode reward: 1.1865,                 loss: 0.2675
Episode: 14381/30000 (47.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4365s / 234.8639 s
agent0:                 episode reward: -1.0031,                 loss: nan
agent1:                 episode reward: 1.0031,                 loss: 0.2676
Episode: 14401/30000 (48.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4570s / 235.3209 s
agent0:                 episode reward: -1.1922,                 loss: nan
agent1:                 episode reward: 1.1922,                 loss: 0.2657
Episode: 14421/30000 (48.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4392s / 235.7601 s
agent0:                 episode reward: -1.1143,                 loss: nan
agent1:                 episode reward: 1.1143,                 loss: 0.2691
Episode: 14441/30000 (48.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4195s / 236.1796 s
agent0:                 episode reward: -0.8958,                 loss: nan
agent1:                 episode reward: 0.8958,                 loss: 0.2665
Episode: 14461/30000 (48.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4299s / 236.6095 s
agent0:                 episode reward: -1.3062,                 loss: nan
agent1:                 episode reward: 1.3062,                 loss: 0.2696
Episode: 14481/30000 (48.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4248s / 237.0343 s
agent0:                 episode reward: -1.0064,                 loss: nan
agent1:                 episode reward: 1.0064,                 loss: 0.2694
Episode: 14501/30000 (48.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4166s / 237.4509 s
agent0:                 episode reward: -0.8489,                 loss: nan
agent1:                 episode reward: 0.8489,                 loss: 0.2705
Episode: 14521/30000 (48.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4146s / 237.8655 s
agent0:                 episode reward: -1.2638,                 loss: nan
agent1:                 episode reward: 1.2638,                 loss: 0.2697
Episode: 14541/30000 (48.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4276s / 238.2931 s
agent0:                 episode reward: -0.9127,                 loss: nan
agent1:                 episode reward: 0.9127,                 loss: 0.2695
Episode: 14561/30000 (48.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4149s / 238.7080 s
agent0:                 episode reward: -1.2395,                 loss: nan
agent1:                 episode reward: 1.2395,                 loss: 0.2714
Episode: 14581/30000 (48.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4196s / 239.1276 s
agent0:                 episode reward: -1.1854,                 loss: nan
agent1:                 episode reward: 1.1854,                 loss: 0.2687
Episode: 14601/30000 (48.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4187s / 239.5463 s
agent0:                 episode reward: -0.7718,                 loss: nan
agent1:                 episode reward: 0.7718,                 loss: 0.2696
Episode: 14621/30000 (48.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4176s / 239.9638 s
agent0:                 episode reward: -0.6988,                 loss: nan
agent1:                 episode reward: 0.6988,                 loss: 0.2712
Episode: 14641/30000 (48.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4200s / 240.3839 s
agent0:                 episode reward: -1.0511,                 loss: nan
agent1:                 episode reward: 1.0511,                 loss: 0.2708
Episode: 14661/30000 (48.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4182s / 240.8021 s
agent0:                 episode reward: -1.0164,                 loss: nan
agent1:                 episode reward: 1.0164,                 loss: 0.2694
Episode: 14681/30000 (48.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4510s / 241.2531 s
agent0:                 episode reward: -1.0603,                 loss: nan
agent1:                 episode reward: 1.0603,                 loss: 0.2704
Episode: 14701/30000 (49.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4256s / 241.6787 s
agent0:                 episode reward: -1.0409,                 loss: nan
agent1:                 episode reward: 1.0409,                 loss: 0.2708
Episode: 14721/30000 (49.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4168s / 242.0955 s
agent0:                 episode reward: -1.1186,                 loss: nan
agent1:                 episode reward: 1.1186,                 loss: 0.2741
Episode: 14741/30000 (49.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4245s / 242.5200 s
agent0:                 episode reward: -1.2562,                 loss: nan
agent1:                 episode reward: 1.2562,                 loss: 0.2702
Episode: 14761/30000 (49.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4153s / 242.9352 s
agent0:                 episode reward: -1.1136,                 loss: nan
agent1:                 episode reward: 1.1136,                 loss: 0.2674
Episode: 14781/30000 (49.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4163s / 243.3516 s
agent0:                 episode reward: -1.3903,                 loss: nan
agent1:                 episode reward: 1.3903,                 loss: 0.2723
Episode: 14801/30000 (49.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4242s / 243.7758 s
agent0:                 episode reward: -1.2751,                 loss: nan
agent1:                 episode reward: 1.2751,                 loss: 0.2711
Episode: 14821/30000 (49.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4285s / 244.2043 s
agent0:                 episode reward: -1.1287,                 loss: nan
agent1:                 episode reward: 1.1287,                 loss: 0.2722
Episode: 14841/30000 (49.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4400s / 244.6443 s
agent0:                 episode reward: -0.7566,                 loss: nan
agent1:                 episode reward: 0.7566,                 loss: 0.2708
Episode: 14861/30000 (49.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4910s / 245.1353 s
agent0:                 episode reward: -1.1772,                 loss: nan
agent1:                 episode reward: 1.1772,                 loss: 0.2710
Episode: 14881/30000 (49.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4230s / 245.5583 s
agent0:                 episode reward: -1.2670,                 loss: nan
agent1:                 episode reward: 1.2670,                 loss: 0.2713
Episode: 14901/30000 (49.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4241s / 245.9824 s
agent0:                 episode reward: -0.9705,                 loss: nan
agent1:                 episode reward: 0.9705,                 loss: 0.2708
Episode: 14921/30000 (49.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4218s / 246.4043 s
agent0:                 episode reward: -0.8877,                 loss: nan
agent1:                 episode reward: 0.8877,                 loss: 0.2726
Episode: 14941/30000 (49.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4328s / 246.8371 s
agent0:                 episode reward: -1.1550,                 loss: nan
agent1:                 episode reward: 1.1550,                 loss: 0.2727
Episode: 14961/30000 (49.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4384s / 247.2755 s
agent0:                 episode reward: -1.1919,                 loss: nan
agent1:                 episode reward: 1.1919,                 loss: 0.2704
Episode: 14981/30000 (49.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4239s / 247.6994 s
agent0:                 episode reward: -1.0811,                 loss: nan
agent1:                 episode reward: 1.0811,                 loss: 0.2701
Episode: 15001/30000 (50.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4231s / 248.1225 s
agent0:                 episode reward: -1.1956,                 loss: nan
agent1:                 episode reward: 1.1956,                 loss: 0.2718
Episode: 15021/30000 (50.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4249s / 248.5474 s
agent0:                 episode reward: -1.1801,                 loss: nan
agent1:                 episode reward: 1.1801,                 loss: 0.2706
Episode: 15041/30000 (50.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4275s / 248.9749 s
agent0:                 episode reward: -1.1054,                 loss: nan
agent1:                 episode reward: 1.1054,                 loss: 0.2731
Episode: 15061/30000 (50.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4438s / 249.4187 s
agent0:                 episode reward: -1.0706,                 loss: nan
agent1:                 episode reward: 1.0706,                 loss: 0.2744
Episode: 15081/30000 (50.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4218s / 249.8405 s
agent0:                 episode reward: -1.1078,                 loss: nan
agent1:                 episode reward: 1.1078,                 loss: 0.2727
Episode: 15101/30000 (50.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4593s / 250.2998 s
agent0:                 episode reward: -1.1723,                 loss: nan
agent1:                 episode reward: 1.1723,                 loss: 0.2723
Episode: 15121/30000 (50.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4262s / 250.7260 s
agent0:                 episode reward: -1.3993,                 loss: nan
agent1:                 episode reward: 1.3993,                 loss: 0.2723
Episode: 15141/30000 (50.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4272s / 251.1532 s
agent0:                 episode reward: -1.2162,                 loss: nan
agent1:                 episode reward: 1.2162,                 loss: 0.2748
Episode: 15161/30000 (50.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4260s / 251.5792 s
agent0:                 episode reward: -0.9416,                 loss: nan
agent1:                 episode reward: 0.9416,                 loss: 0.2733
Episode: 15181/30000 (50.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4260s / 252.0052 s
agent0:                 episode reward: -1.2689,                 loss: nan
agent1:                 episode reward: 1.2689,                 loss: 0.2708
Episode: 15201/30000 (50.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4254s / 252.4306 s
agent0:                 episode reward: -1.3116,                 loss: nan
agent1:                 episode reward: 1.3116,                 loss: 0.2732
Episode: 15221/30000 (50.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4282s / 252.8588 s
agent0:                 episode reward: -0.8424,                 loss: nan
agent1:                 episode reward: 0.8424,                 loss: 0.2710
Episode: 15241/30000 (50.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4353s / 253.2941 s
agent0:                 episode reward: -1.1900,                 loss: nan
agent1:                 episode reward: 1.1900,                 loss: 0.2635
Episode: 15261/30000 (50.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4284s / 253.7225 s
agent0:                 episode reward: -1.3587,                 loss: nan
agent1:                 episode reward: 1.3587,                 loss: 0.2675
Episode: 15281/30000 (50.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4324s / 254.1549 s
agent0:                 episode reward: -1.1878,                 loss: nan
agent1:                 episode reward: 1.1878,                 loss: 0.2691
Episode: 15301/30000 (51.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4288s / 254.5837 s
agent0:                 episode reward: -1.0751,                 loss: nan
agent1:                 episode reward: 1.0751,                 loss: 0.2662
Episode: 15321/30000 (51.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4853s / 255.0690 s
agent0:                 episode reward: -0.9082,                 loss: nan
agent1:                 episode reward: 0.9082,                 loss: 0.2638
Episode: 15341/30000 (51.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4396s / 255.5086 s
agent0:                 episode reward: -0.6024,                 loss: nan
agent1:                 episode reward: 0.6024,                 loss: 0.2662
Episode: 15361/30000 (51.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4317s / 255.9403 s
agent0:                 episode reward: -0.9887,                 loss: nan
agent1:                 episode reward: 0.9887,                 loss: 0.2635
Episode: 15381/30000 (51.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4369s / 256.3772 s
agent0:                 episode reward: -1.2317,                 loss: nan
agent1:                 episode reward: 1.2317,                 loss: 0.2651
Episode: 15401/30000 (51.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4336s / 256.8108 s
agent0:                 episode reward: -1.3116,                 loss: nan
agent1:                 episode reward: 1.3116,                 loss: 0.2644
Episode: 15421/30000 (51.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4400s / 257.2508 s
agent0:                 episode reward: -1.1207,                 loss: nan
agent1:                 episode reward: 1.1207,                 loss: 0.2639
Episode: 15441/30000 (51.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4507s / 257.7015 s
agent0:                 episode reward: -1.1204,                 loss: nan
agent1:                 episode reward: 1.1204,                 loss: 0.2648
Episode: 15461/30000 (51.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4354s / 258.1368 s
agent0:                 episode reward: -0.9478,                 loss: nan
agent1:                 episode reward: 0.9478,                 loss: 0.2640
Episode: 15481/30000 (51.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4376s / 258.5744 s
agent0:                 episode reward: -1.0797,                 loss: nan
agent1:                 episode reward: 1.0797,                 loss: 0.2685
Episode: 15501/30000 (51.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4325s / 259.0069 s
agent0:                 episode reward: -0.8979,                 loss: nan
agent1:                 episode reward: 0.8979,                 loss: 0.2687
Episode: 15521/30000 (51.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4452s / 259.4522 s
agent0:                 episode reward: -0.8227,                 loss: nan
agent1:                 episode reward: 0.8227,                 loss: 0.2678
Episode: 15541/30000 (51.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4301s / 259.8822 s
agent0:                 episode reward: -0.9895,                 loss: nan
agent1:                 episode reward: 0.9895,                 loss: 0.2659
Episode: 15561/30000 (51.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4313s / 260.3136 s
agent0:                 episode reward: -1.3084,                 loss: nan
agent1:                 episode reward: 1.3084,                 loss: 0.2705
Episode: 15581/30000 (51.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4301s / 260.7437 s
agent0:                 episode reward: -1.1128,                 loss: nan
agent1:                 episode reward: 1.1128,                 loss: 0.2686
Episode: 15601/30000 (52.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4320s / 261.1757 s
agent0:                 episode reward: -1.0108,                 loss: nan
agent1:                 episode reward: 1.0108,                 loss: 0.2680
Episode: 15621/30000 (52.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4400s / 261.6157 s
agent0:                 episode reward: -1.1207,                 loss: nan
agent1:                 episode reward: 1.1207,                 loss: 0.2647
Episode: 15641/30000 (52.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4313s / 262.0470 s
agent0:                 episode reward: -1.0570,                 loss: nan
agent1:                 episode reward: 1.0570,                 loss: 0.2659
Episode: 15661/30000 (52.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4413s / 262.4883 s
agent0:                 episode reward: -1.1907,                 loss: nan
agent1:                 episode reward: 1.1907,                 loss: 0.2671
Episode: 15681/30000 (52.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4338s / 262.9221 s
agent0:                 episode reward: -0.9307,                 loss: nan
agent1:                 episode reward: 0.9307,                 loss: 0.2681
Episode: 15701/30000 (52.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4286s / 263.3507 s
agent0:                 episode reward: -1.2753,                 loss: nan
agent1:                 episode reward: 1.2753,                 loss: 0.2647
Episode: 15721/30000 (52.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4295s / 263.7801 s
agent0:                 episode reward: -1.0917,                 loss: nan
agent1:                 episode reward: 1.0917,                 loss: 0.2658
Episode: 15741/30000 (52.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4399s / 264.2200 s
agent0:                 episode reward: -1.1078,                 loss: nan
agent1:                 episode reward: 1.1078,                 loss: 0.2669
Episode: 15761/30000 (52.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4325s / 264.6525 s
agent0:                 episode reward: -0.8712,                 loss: nan
agent1:                 episode reward: 0.8712,                 loss: 0.2720
Episode: 15781/30000 (52.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4281s / 265.0806 s
agent0:                 episode reward: -1.1187,                 loss: nan
agent1:                 episode reward: 1.1187,                 loss: 0.2669
Episode: 15801/30000 (52.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5270s / 265.6076 s
agent0:                 episode reward: -1.1480,                 loss: nan
agent1:                 episode reward: 1.1480,                 loss: 0.2678
Episode: 15821/30000 (52.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4626s / 266.0701 s
agent0:                 episode reward: -1.1523,                 loss: nan
agent1:                 episode reward: 1.1523,                 loss: 0.2674
Episode: 15841/30000 (52.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4375s / 266.5076 s
agent0:                 episode reward: -0.9752,                 loss: nan
agent1:                 episode reward: 0.9752,                 loss: 0.2642
Episode: 15861/30000 (52.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4379s / 266.9455 s
agent0:                 episode reward: -1.0020,                 loss: nan
agent1:                 episode reward: 1.0020,                 loss: 0.2707
Episode: 15881/30000 (52.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4416s / 267.3871 s
agent0:                 episode reward: -1.2689,                 loss: nan
agent1:                 episode reward: 1.2689,                 loss: 0.2665
Episode: 15901/30000 (53.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4318s / 267.8189 s
agent0:                 episode reward: -1.3112,                 loss: nan
agent1:                 episode reward: 1.3112,                 loss: 0.2732
Episode: 15921/30000 (53.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4390s / 268.2580 s
agent0:                 episode reward: -1.0877,                 loss: nan
agent1:                 episode reward: 1.0877,                 loss: 0.2742
Episode: 15941/30000 (53.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4638s / 268.7217 s
agent0:                 episode reward: -1.3735,                 loss: nan
agent1:                 episode reward: 1.3735,                 loss: 0.2719
Episode: 15961/30000 (53.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4383s / 269.1601 s
agent0:                 episode reward: -0.8986,                 loss: nan
agent1:                 episode reward: 0.8986,                 loss: 0.2742
Episode: 15981/30000 (53.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4385s / 269.5986 s
agent0:                 episode reward: -1.2708,                 loss: nan
agent1:                 episode reward: 1.2708,                 loss: 0.2705
Episode: 16001/30000 (53.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4350s / 270.0336 s
agent0:                 episode reward: -1.0689,                 loss: nan
agent1:                 episode reward: 1.0689,                 loss: 0.2712
Episode: 16021/30000 (53.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4419s / 270.4756 s
agent0:                 episode reward: -0.9756,                 loss: nan
agent1:                 episode reward: 0.9756,                 loss: 0.2703
Episode: 16041/30000 (53.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4354s / 270.9110 s
agent0:                 episode reward: -1.2150,                 loss: nan
agent1:                 episode reward: 1.2150,                 loss: 0.2694
Episode: 16061/30000 (53.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4346s / 271.3456 s
agent0:                 episode reward: -1.2910,                 loss: nan
agent1:                 episode reward: 1.2910,                 loss: 0.2695
Episode: 16081/30000 (53.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4699s / 271.8154 s
agent0:                 episode reward: -1.3668,                 loss: nan
agent1:                 episode reward: 1.3668,                 loss: 0.2704
Episode: 16101/30000 (53.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4451s / 272.2605 s
agent0:                 episode reward: -1.1779,                 loss: nan
agent1:                 episode reward: 1.1779,                 loss: 0.2691
Episode: 16121/30000 (53.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4584s / 272.7189 s
agent0:                 episode reward: -1.3651,                 loss: nan
agent1:                 episode reward: 1.3651,                 loss: 0.2679
Episode: 16141/30000 (53.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4582s / 273.1771 s
agent0:                 episode reward: -1.0314,                 loss: nan
agent1:                 episode reward: 1.0314,                 loss: 0.2706
Episode: 16161/30000 (53.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4419s / 273.6189 s
agent0:                 episode reward: -1.1017,                 loss: nan
agent1:                 episode reward: 1.1017,                 loss: 0.2724
Episode: 16181/30000 (53.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4566s / 274.0755 s
agent0:                 episode reward: -0.8162,                 loss: nan
agent1:                 episode reward: 0.8162,                 loss: 0.2710
Episode: 16201/30000 (54.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4498s / 274.5254 s
agent0:                 episode reward: -1.0849,                 loss: nan
agent1:                 episode reward: 1.0849,                 loss: 0.2693
Episode: 16221/30000 (54.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4432s / 274.9685 s
agent0:                 episode reward: -1.1788,                 loss: nan
agent1:                 episode reward: 1.1788,                 loss: 0.2755
Episode: 16241/30000 (54.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4485s / 275.4170 s
agent0:                 episode reward: -1.2021,                 loss: nan
agent1:                 episode reward: 1.2021,                 loss: 0.2790
Episode: 16261/30000 (54.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5276s / 275.9447 s
agent0:                 episode reward: -1.0429,                 loss: nan
agent1:                 episode reward: 1.0429,                 loss: 0.2814
Episode: 16281/30000 (54.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4397s / 276.3843 s
agent0:                 episode reward: -0.9913,                 loss: nan
agent1:                 episode reward: 0.9913,                 loss: 0.2817
Episode: 16301/30000 (54.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4411s / 276.8255 s
agent0:                 episode reward: -1.1148,                 loss: nan
agent1:                 episode reward: 1.1148,                 loss: 0.2821
Episode: 16321/30000 (54.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4513s / 277.2768 s
agent0:                 episode reward: -0.9646,                 loss: nan
agent1:                 episode reward: 0.9646,                 loss: 0.2766
Episode: 16341/30000 (54.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4570s / 277.7338 s
agent0:                 episode reward: -1.0189,                 loss: nan
agent1:                 episode reward: 1.0189,                 loss: 0.2796
Episode: 16361/30000 (54.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4406s / 278.1744 s
agent0:                 episode reward: -1.0931,                 loss: nan
agent1:                 episode reward: 1.0931,                 loss: 0.2792
Episode: 16381/30000 (54.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4398s / 278.6142 s
agent0:                 episode reward: -1.2699,                 loss: nan
agent1:                 episode reward: 1.2699,                 loss: 0.2786
Episode: 16401/30000 (54.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4454s / 279.0596 s
agent0:                 episode reward: -1.0874,                 loss: nan
agent1:                 episode reward: 1.0874,                 loss: 0.2774
Episode: 16421/30000 (54.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4477s / 279.5072 s
agent0:                 episode reward: -1.0571,                 loss: nan
agent1:                 episode reward: 1.0571,                 loss: 0.2803
Episode: 16441/30000 (54.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4369s / 279.9442 s
agent0:                 episode reward: -0.8257,                 loss: nan
agent1:                 episode reward: 0.8257,                 loss: 0.2794
Episode: 16461/30000 (54.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4410s / 280.3852 s
agent0:                 episode reward: -1.0655,                 loss: nan
agent1:                 episode reward: 1.0655,                 loss: 0.2787
Episode: 16481/30000 (54.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4499s / 280.8350 s
agent0:                 episode reward: -1.0928,                 loss: nan
agent1:                 episode reward: 1.0928,                 loss: 0.2810
Episode: 16501/30000 (55.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4458s / 281.2808 s
agent0:                 episode reward: -0.7375,                 loss: nan
agent1:                 episode reward: 0.7375,                 loss: 0.2837
Episode: 16521/30000 (55.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4443s / 281.7252 s
agent0:                 episode reward: -0.8859,                 loss: nan
agent1:                 episode reward: 0.8859,                 loss: 0.2800
Episode: 16541/30000 (55.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4524s / 282.1775 s
agent0:                 episode reward: -1.1825,                 loss: nan
agent1:                 episode reward: 1.1825,                 loss: 0.2830
Episode: 16561/30000 (55.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4743s / 282.6518 s
agent0:                 episode reward: -0.9456,                 loss: nan
agent1:                 episode reward: 0.9456,                 loss: 0.2692
Episode: 16581/30000 (55.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4467s / 283.0985 s
agent0:                 episode reward: -1.3761,                 loss: nan
agent1:                 episode reward: 1.3761,                 loss: 0.2588
Episode: 16601/30000 (55.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4488s / 283.5473 s
agent0:                 episode reward: -0.8722,                 loss: nan
agent1:                 episode reward: 0.8722,                 loss: 0.2633
Episode: 16621/30000 (55.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4462s / 283.9935 s
agent0:                 episode reward: -0.8632,                 loss: nan
agent1:                 episode reward: 0.8632,                 loss: 0.2606
Episode: 16641/30000 (55.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4477s / 284.4411 s
agent0:                 episode reward: -1.3784,                 loss: nan
agent1:                 episode reward: 1.3784,                 loss: 0.2608
Episode: 16661/30000 (55.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4465s / 284.8876 s
agent0:                 episode reward: -1.1690,                 loss: nan
agent1:                 episode reward: 1.1690,                 loss: 0.2600
Episode: 16681/30000 (55.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4525s / 285.3402 s
agent0:                 episode reward: -1.3905,                 loss: nan
agent1:                 episode reward: 1.3905,                 loss: 0.2591
Episode: 16701/30000 (55.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4872s / 285.8274 s
agent0:                 episode reward: -0.9412,                 loss: nan
agent1:                 episode reward: 0.9412,                 loss: 0.2576
Episode: 16721/30000 (55.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4611s / 286.2885 s
agent0:                 episode reward: -1.1940,                 loss: nan
agent1:                 episode reward: 1.1940,                 loss: 0.2632
Episode: 16741/30000 (55.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4619s / 286.7504 s
agent0:                 episode reward: -1.0304,                 loss: nan
agent1:                 episode reward: 1.0304,                 loss: 0.2595
Episode: 16761/30000 (55.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4439s / 287.1943 s
agent0:                 episode reward: -0.9989,                 loss: nan
agent1:                 episode reward: 0.9989,                 loss: 0.2588
Episode: 16781/30000 (55.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4584s / 287.6527 s
agent0:                 episode reward: -1.5081,                 loss: nan
agent1:                 episode reward: 1.5081,                 loss: 0.2582
Episode: 16801/30000 (56.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4482s / 288.1009 s
agent0:                 episode reward: -0.8238,                 loss: nan
agent1:                 episode reward: 0.8238,                 loss: 0.2633
Episode: 16821/30000 (56.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4502s / 288.5511 s
agent0:                 episode reward: -1.3199,                 loss: nan
agent1:                 episode reward: 1.3199,                 loss: 0.2595
Episode: 16841/30000 (56.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4458s / 288.9969 s
agent0:                 episode reward: -1.3207,                 loss: nan
agent1:                 episode reward: 1.3207,                 loss: 0.2610
Episode: 16861/30000 (56.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4551s / 289.4520 s
agent0:                 episode reward: -1.1209,                 loss: nan
agent1:                 episode reward: 1.1209,                 loss: 0.2623
Episode: 16881/30000 (56.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4720s / 289.9239 s
agent0:                 episode reward: -1.0194,                 loss: nan
agent1:                 episode reward: 1.0194,                 loss: 0.2616
Episode: 16901/30000 (56.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4474s / 290.3713 s
agent0:                 episode reward: -1.2231,                 loss: nan
agent1:                 episode reward: 1.2231,                 loss: 0.2752
Episode: 16921/30000 (56.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4744s / 290.8456 s
agent0:                 episode reward: -1.1738,                 loss: nan
agent1:                 episode reward: 1.1738,                 loss: 0.2736
Episode: 16941/30000 (56.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4557s / 291.3013 s
agent0:                 episode reward: -1.0326,                 loss: nan
agent1:                 episode reward: 1.0326,                 loss: 0.2745
Episode: 16961/30000 (56.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4558s / 291.7572 s
agent0:                 episode reward: -1.2757,                 loss: nan
agent1:                 episode reward: 1.2757,                 loss: 0.2708
Episode: 16981/30000 (56.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4514s / 292.2086 s
agent0:                 episode reward: -1.2813,                 loss: nan
agent1:                 episode reward: 1.2813,                 loss: 0.2732
Episode: 17001/30000 (56.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4661s / 292.6748 s
agent0:                 episode reward: -1.1048,                 loss: nan
agent1:                 episode reward: 1.1048,                 loss: 0.2707
Episode: 17021/30000 (56.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4549s / 293.1297 s
agent0:                 episode reward: -1.0468,                 loss: nan
agent1:                 episode reward: 1.0468,                 loss: 0.2720
Episode: 17041/30000 (56.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4571s / 293.5867 s
agent0:                 episode reward: -1.1547,                 loss: nan
agent1:                 episode reward: 1.1547,                 loss: 0.2770
Episode: 17061/30000 (56.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4510s / 294.0377 s
agent0:                 episode reward: -1.0826,                 loss: nan
agent1:                 episode reward: 1.0826,                 loss: 0.2717
Episode: 17081/30000 (56.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4492s / 294.4869 s
agent0:                 episode reward: -1.2580,                 loss: nan
agent1:                 episode reward: 1.2580,                 loss: 0.2749
Episode: 17101/30000 (57.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4509s / 294.9378 s
agent0:                 episode reward: -0.9031,                 loss: nan
agent1:                 episode reward: 0.9031,                 loss: 0.2741
Episode: 17121/30000 (57.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4576s / 295.3954 s
agent0:                 episode reward: -1.2434,                 loss: nan
agent1:                 episode reward: 1.2434,                 loss: 0.2739
Episode: 17141/30000 (57.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4658s / 295.8612 s
agent0:                 episode reward: -1.0098,                 loss: nan
agent1:                 episode reward: 1.0098,                 loss: 0.2722
Episode: 17161/30000 (57.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5115s / 296.3727 s
agent0:                 episode reward: -0.9537,                 loss: nan
agent1:                 episode reward: 0.9537,                 loss: 0.2725
Episode: 17181/30000 (57.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4543s / 296.8269 s
agent0:                 episode reward: -1.2492,                 loss: nan
agent1:                 episode reward: 1.2492,                 loss: 0.2710
Episode: 17201/30000 (57.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4792s / 297.3061 s
agent0:                 episode reward: -1.1726,                 loss: nan
agent1:                 episode reward: 1.1726,                 loss: 0.2684
Episode: 17221/30000 (57.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4645s / 297.7706 s
agent0:                 episode reward: -0.9899,                 loss: nan
agent1:                 episode reward: 0.9899,                 loss: 0.2769
Episode: 17241/30000 (57.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4546s / 298.2253 s
agent0:                 episode reward: -1.2074,                 loss: nan
agent1:                 episode reward: 1.2074,                 loss: 0.2785
Episode: 17261/30000 (57.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4624s / 298.6877 s
agent0:                 episode reward: -1.0387,                 loss: nan
agent1:                 episode reward: 1.0387,                 loss: 0.2801
Episode: 17281/30000 (57.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4754s / 299.1631 s
agent0:                 episode reward: -1.2293,                 loss: nan
agent1:                 episode reward: 1.2293,                 loss: 0.2775
Episode: 17301/30000 (57.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4810s / 299.6441 s
agent0:                 episode reward: -0.8676,                 loss: nan
agent1:                 episode reward: 0.8676,                 loss: 0.2836
Episode: 17321/30000 (57.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4550s / 300.0991 s
agent0:                 episode reward: -1.2618,                 loss: nan
agent1:                 episode reward: 1.2618,                 loss: 0.2801
Episode: 17341/30000 (57.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4514s / 300.5505 s
agent0:                 episode reward: -1.1165,                 loss: nan
agent1:                 episode reward: 1.1165,                 loss: 0.2827
Episode: 17361/30000 (57.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4542s / 301.0047 s
agent0:                 episode reward: -1.3417,                 loss: nan
agent1:                 episode reward: 1.3417,                 loss: 0.2790
Episode: 17381/30000 (57.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4762s / 301.4809 s
agent0:                 episode reward: -1.0683,                 loss: nan
agent1:                 episode reward: 1.0683,                 loss: 0.2811
Episode: 17401/30000 (58.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4595s / 301.9404 s
agent0:                 episode reward: -1.0196,                 loss: nan
agent1:                 episode reward: 1.0196,                 loss: 0.2836
Episode: 17421/30000 (58.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4677s / 302.4081 s
agent0:                 episode reward: -1.1089,                 loss: nan
agent1:                 episode reward: 1.1089,                 loss: 0.2820
Episode: 17441/30000 (58.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4564s / 302.8645 s
agent0:                 episode reward: -1.1960,                 loss: nan
agent1:                 episode reward: 1.1960,                 loss: 0.2794
Episode: 17461/30000 (58.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4637s / 303.3281 s
agent0:                 episode reward: -0.9293,                 loss: nan
agent1:                 episode reward: 0.9293,                 loss: 0.2794
Episode: 17481/30000 (58.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4604s / 303.7885 s
agent0:                 episode reward: -1.0585,                 loss: nan
agent1:                 episode reward: 1.0585,                 loss: 0.2785
Episode: 17501/30000 (58.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4724s / 304.2610 s
agent0:                 episode reward: -0.9746,                 loss: nan
agent1:                 episode reward: 0.9746,                 loss: 0.2769
Episode: 17521/30000 (58.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4861s / 304.7470 s
agent0:                 episode reward: -0.8659,                 loss: nan
agent1:                 episode reward: 0.8659,                 loss: 0.2817
Episode: 17541/30000 (58.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4602s / 305.2072 s
agent0:                 episode reward: -1.4400,                 loss: nan
agent1:                 episode reward: 1.4400,                 loss: 0.2811
Episode: 17561/30000 (58.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4609s / 305.6681 s
agent0:                 episode reward: -0.9359,                 loss: nan
agent1:                 episode reward: 0.9359,                 loss: 0.2789
Episode: 17581/30000 (58.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4572s / 306.1253 s
agent0:                 episode reward: -1.0382,                 loss: nan
agent1:                 episode reward: 1.0382,                 loss: 0.2734
Episode: 17601/30000 (58.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5250s / 306.6503 s
agent0:                 episode reward: -0.8788,                 loss: nan
agent1:                 episode reward: 0.8788,                 loss: 0.2747
Episode: 17621/30000 (58.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4654s / 307.1157 s
agent0:                 episode reward: -0.9394,                 loss: nan
agent1:                 episode reward: 0.9394,                 loss: 0.2743
Episode: 17641/30000 (58.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4923s / 307.6081 s
agent0:                 episode reward: -1.0468,                 loss: nan
agent1:                 episode reward: 1.0468,                 loss: 0.2731
Episode: 17661/30000 (58.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4755s / 308.0836 s
agent0:                 episode reward: -1.0923,                 loss: nan
agent1:                 episode reward: 1.0923,                 loss: 0.2751
Episode: 17681/30000 (58.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4618s / 308.5454 s
agent0:                 episode reward: -1.1325,                 loss: nan
agent1:                 episode reward: 1.1325,                 loss: 0.2785
Episode: 17701/30000 (59.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4862s / 309.0316 s
agent0:                 episode reward: -1.1828,                 loss: nan
agent1:                 episode reward: 1.1828,                 loss: 0.2747
Episode: 17721/30000 (59.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4628s / 309.4944 s
agent0:                 episode reward: -0.9100,                 loss: nan
agent1:                 episode reward: 0.9100,                 loss: 0.2773
Episode: 17741/30000 (59.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4569s / 309.9513 s
agent0:                 episode reward: -1.1963,                 loss: nan
agent1:                 episode reward: 1.1963,                 loss: 0.2721
Episode: 17761/30000 (59.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4567s / 310.4080 s
agent0:                 episode reward: -0.9579,                 loss: nan
agent1:                 episode reward: 0.9579,                 loss: 0.2726
Episode: 17781/30000 (59.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4710s / 310.8789 s
agent0:                 episode reward: -0.9943,                 loss: nan
agent1:                 episode reward: 0.9943,                 loss: 0.2727
Episode: 17801/30000 (59.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4607s / 311.3397 s
agent0:                 episode reward: -1.0890,                 loss: nan
agent1:                 episode reward: 1.0890,                 loss: 0.2733
Episode: 17821/30000 (59.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4625s / 311.8021 s
agent0:                 episode reward: -1.0171,                 loss: nan
agent1:                 episode reward: 1.0171,                 loss: 0.2736
Episode: 17841/30000 (59.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4634s / 312.2655 s
agent0:                 episode reward: -1.2275,                 loss: nan
agent1:                 episode reward: 1.2275,                 loss: 0.2749
Episode: 17861/30000 (59.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4617s / 312.7273 s
agent0:                 episode reward: -0.9019,                 loss: nan
agent1:                 episode reward: 0.9019,                 loss: 0.2764
Episode: 17881/30000 (59.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4621s / 313.1894 s
agent0:                 episode reward: -0.8557,                 loss: nan
agent1:                 episode reward: 0.8557,                 loss: 0.2729
Episode: 17901/30000 (59.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4619s / 313.6513 s
agent0:                 episode reward: -1.1509,                 loss: nan
agent1:                 episode reward: 1.1509,                 loss: 0.2588
Episode: 17921/30000 (59.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4755s / 314.1268 s
agent0:                 episode reward: -0.8884,                 loss: nan
agent1:                 episode reward: 0.8884,                 loss: 0.2595
Episode: 17941/30000 (59.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4666s / 314.5934 s
agent0:                 episode reward: -1.1672,                 loss: nan
agent1:                 episode reward: 1.1672,                 loss: 0.2579
Episode: 17961/30000 (59.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4656s / 315.0590 s
agent0:                 episode reward: -1.3867,                 loss: nan
agent1:                 episode reward: 1.3867,                 loss: 0.2631
Episode: 17981/30000 (59.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4656s / 315.5246 s
agent0:                 episode reward: -0.8289,                 loss: nan
agent1:                 episode reward: 0.8289,                 loss: 0.2561
Episode: 18001/30000 (60.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4867s / 316.0114 s
agent0:                 episode reward: -1.3270,                 loss: nan
agent1:                 episode reward: 1.3270,                 loss: 0.2610
Episode: 18021/30000 (60.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4751s / 316.4865 s
agent0:                 episode reward: -1.0530,                 loss: nan
agent1:                 episode reward: 1.0530,                 loss: 0.2571
Episode: 18041/30000 (60.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5617s / 317.0482 s
agent0:                 episode reward: -1.0991,                 loss: nan
agent1:                 episode reward: 1.0991,                 loss: 0.2588
Episode: 18061/30000 (60.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4736s / 317.5218 s
agent0:                 episode reward: -1.0277,                 loss: nan
agent1:                 episode reward: 1.0277,                 loss: 0.2617
Episode: 18081/30000 (60.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4851s / 318.0069 s
agent0:                 episode reward: -0.9636,                 loss: nan
agent1:                 episode reward: 0.9636,                 loss: 0.2567
Episode: 18101/30000 (60.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4686s / 318.4755 s
agent0:                 episode reward: -1.1204,                 loss: nan
agent1:                 episode reward: 1.1204,                 loss: 0.2625
Episode: 18121/30000 (60.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4729s / 318.9484 s
agent0:                 episode reward: -1.0741,                 loss: nan
agent1:                 episode reward: 1.0741,                 loss: 0.2563
Episode: 18141/30000 (60.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4741s / 319.4225 s
agent0:                 episode reward: -0.9662,                 loss: nan
agent1:                 episode reward: 0.9662,                 loss: 0.2545
Episode: 18161/30000 (60.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4942s / 319.9167 s
agent0:                 episode reward: -1.1094,                 loss: nan
agent1:                 episode reward: 1.1094,                 loss: 0.2580
Episode: 18181/30000 (60.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4737s / 320.3904 s
agent0:                 episode reward: -0.8490,                 loss: nan
agent1:                 episode reward: 0.8490,                 loss: 0.2557
Episode: 18201/30000 (60.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4767s / 320.8672 s
agent0:                 episode reward: -0.9798,                 loss: nan
agent1:                 episode reward: 0.9798,                 loss: 0.2580
Episode: 18221/30000 (60.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4658s / 321.3330 s
agent0:                 episode reward: -1.0566,                 loss: nan
agent1:                 episode reward: 1.0566,                 loss: 0.2644
Episode: 18241/30000 (60.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4725s / 321.8055 s
agent0:                 episode reward: -1.1047,                 loss: nan
agent1:                 episode reward: 1.1047,                 loss: 0.2779
Episode: 18261/30000 (60.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5262s / 322.3317 s
agent0:                 episode reward: -0.9568,                 loss: nan
agent1:                 episode reward: 0.9568,                 loss: 0.2773
Episode: 18281/30000 (60.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4778s / 322.8095 s
agent0:                 episode reward: -1.0184,                 loss: nan
agent1:                 episode reward: 1.0184,                 loss: 0.2771
Episode: 18301/30000 (61.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4746s / 323.2841 s
agent0:                 episode reward: -1.2203,                 loss: nan
agent1:                 episode reward: 1.2203,                 loss: 0.2801
Episode: 18321/30000 (61.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4733s / 323.7574 s
agent0:                 episode reward: -0.9073,                 loss: nan
agent1:                 episode reward: 0.9073,                 loss: 0.2765
Episode: 18341/30000 (61.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4892s / 324.2466 s
agent0:                 episode reward: -0.8985,                 loss: nan
agent1:                 episode reward: 0.8985,                 loss: 0.2779
Episode: 18361/30000 (61.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4739s / 324.7205 s
agent0:                 episode reward: -1.1606,                 loss: nan
agent1:                 episode reward: 1.1606,                 loss: 0.2779
Episode: 18381/30000 (61.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4787s / 325.1992 s
agent0:                 episode reward: -1.0018,                 loss: nan
agent1:                 episode reward: 1.0018,                 loss: 0.2776
Episode: 18401/30000 (61.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4669s / 325.6661 s
agent0:                 episode reward: -0.8669,                 loss: nan
agent1:                 episode reward: 0.8669,                 loss: 0.2758
Episode: 18421/30000 (61.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4695s / 326.1356 s
agent0:                 episode reward: -0.7930,                 loss: nan
agent1:                 episode reward: 0.7930,                 loss: 0.2767
Episode: 18441/30000 (61.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4700s / 326.6056 s
agent0:                 episode reward: -0.8426,                 loss: nan
agent1:                 episode reward: 0.8426,                 loss: 0.2782
Episode: 18461/30000 (61.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5266s / 327.1322 s
agent0:                 episode reward: -1.0766,                 loss: nan
agent1:                 episode reward: 1.0766,                 loss: 0.2764
Episode: 18481/30000 (61.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4713s / 327.6035 s
agent0:                 episode reward: -1.1391,                 loss: nan
agent1:                 episode reward: 1.1391,                 loss: 0.2773
Episode: 18501/30000 (61.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4812s / 328.0847 s
agent0:                 episode reward: -1.0085,                 loss: nan
agent1:                 episode reward: 1.0085,                 loss: 0.2779
Episode: 18521/30000 (61.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4697s / 328.5544 s
agent0:                 episode reward: -1.0098,                 loss: nan
agent1:                 episode reward: 1.0098,                 loss: 0.2767
Episode: 18541/30000 (61.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5059s / 329.0603 s
agent0:                 episode reward: -1.1088,                 loss: nan
agent1:                 episode reward: 1.1088,                 loss: 0.2790
Episode: 18561/30000 (61.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4825s / 329.5429 s
agent0:                 episode reward: -1.1756,                 loss: nan
agent1:                 episode reward: 1.1756,                 loss: 0.2720
Episode: 18581/30000 (61.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4762s / 330.0190 s
agent0:                 episode reward: -1.1813,                 loss: nan
agent1:                 episode reward: 1.1813,                 loss: 0.2686
Episode: 18601/30000 (62.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4985s / 330.5175 s
agent0:                 episode reward: -1.0533,                 loss: nan
agent1:                 episode reward: 1.0533,                 loss: 0.2640
Episode: 18621/30000 (62.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4772s / 330.9948 s
agent0:                 episode reward: -0.9421,                 loss: nan
agent1:                 episode reward: 0.9421,                 loss: 0.2666
Episode: 18641/30000 (62.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4720s / 331.4667 s
agent0:                 episode reward: -0.8890,                 loss: nan
agent1:                 episode reward: 0.8890,                 loss: 0.2679
Episode: 18661/30000 (62.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5040s / 331.9708 s
agent0:                 episode reward: -0.9094,                 loss: nan
agent1:                 episode reward: 0.9094,                 loss: 0.2680
Episode: 18681/30000 (62.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4989s / 332.4697 s
agent0:                 episode reward: -1.1981,                 loss: nan
agent1:                 episode reward: 1.1981,                 loss: 0.2697
Episode: 18701/30000 (62.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5059s / 332.9756 s
agent0:                 episode reward: -1.2521,                 loss: nan
agent1:                 episode reward: 1.2521,                 loss: 0.2669
Episode: 18721/30000 (62.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4751s / 333.4507 s
agent0:                 episode reward: -0.9969,                 loss: nan
agent1:                 episode reward: 0.9969,                 loss: 0.2677
Episode: 18741/30000 (62.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4724s / 333.9231 s
agent0:                 episode reward: -1.4187,                 loss: nan
agent1:                 episode reward: 1.4187,                 loss: 0.2672
Episode: 18761/30000 (62.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4785s / 334.4016 s
agent0:                 episode reward: -0.9581,                 loss: nan
agent1:                 episode reward: 0.9581,                 loss: 0.2639
Episode: 18781/30000 (62.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4862s / 334.8878 s
agent0:                 episode reward: -0.9344,                 loss: nan
agent1:                 episode reward: 0.9344,                 loss: 0.2664
Episode: 18801/30000 (62.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4806s / 335.3684 s
agent0:                 episode reward: -1.1316,                 loss: nan
agent1:                 episode reward: 1.1316,                 loss: 0.2651
Episode: 18821/30000 (62.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4748s / 335.8433 s
agent0:                 episode reward: -1.0430,                 loss: nan
agent1:                 episode reward: 1.0430,                 loss: 0.2673
Episode: 18841/30000 (62.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4797s / 336.3229 s
agent0:                 episode reward: -1.0447,                 loss: nan
agent1:                 episode reward: 1.0447,                 loss: 0.2643
Episode: 18861/30000 (62.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4797s / 336.8026 s
agent0:                 episode reward: -1.0940,                 loss: nan
agent1:                 episode reward: 1.0940,                 loss: 0.2674
Episode: 18881/30000 (62.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5467s / 337.3493 s
agent0:                 episode reward: -0.9774,                 loss: nan
agent1:                 episode reward: 0.9774,                 loss: 0.2669
Episode: 18901/30000 (63.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4965s / 337.8458 s
agent0:                 episode reward: -1.0991,                 loss: nan
agent1:                 episode reward: 1.0991,                 loss: 0.2669
Episode: 18921/30000 (63.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4941s / 338.3399 s
agent0:                 episode reward: -1.1111,                 loss: nan
agent1:                 episode reward: 1.1111,                 loss: 0.2642
Episode: 18941/30000 (63.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4869s / 338.8268 s
agent0:                 episode reward: -1.1828,                 loss: nan
agent1:                 episode reward: 1.1828,                 loss: 0.2644
Episode: 18961/30000 (63.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4838s / 339.3106 s
agent0:                 episode reward: -0.9346,                 loss: nan
agent1:                 episode reward: 0.9346,                 loss: 0.2661
Episode: 18981/30000 (63.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4848s / 339.7953 s
agent0:                 episode reward: -0.7725,                 loss: nan
agent1:                 episode reward: 0.7725,                 loss: 0.2639
Episode: 19001/30000 (63.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4791s / 340.2744 s
agent0:                 episode reward: -1.0584,                 loss: nan
agent1:                 episode reward: 1.0584,                 loss: 0.2664
Episode: 19021/30000 (63.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5060s / 340.7804 s
agent0:                 episode reward: -1.0944,                 loss: nan
agent1:                 episode reward: 1.0944,                 loss: 0.2654
Episode: 19041/30000 (63.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4809s / 341.2613 s
agent0:                 episode reward: -1.2923,                 loss: nan
agent1:                 episode reward: 1.2923,                 loss: 0.2639
Episode: 19061/30000 (63.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4801s / 341.7414 s
agent0:                 episode reward: -1.0966,                 loss: nan
agent1:                 episode reward: 1.0966,                 loss: 0.2637
Episode: 19081/30000 (63.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4814s / 342.2228 s
agent0:                 episode reward: -1.2156,                 loss: nan
agent1:                 episode reward: 1.2156,                 loss: 0.2639
Episode: 19101/30000 (63.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4837s / 342.7065 s
agent0:                 episode reward: -1.0899,                 loss: nan
agent1:                 episode reward: 1.0899,                 loss: 0.2654
Episode: 19121/30000 (63.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4844s / 343.1909 s
agent0:                 episode reward: -0.8092,                 loss: nan
agent1:                 episode reward: 0.8092,                 loss: 0.2652
Episode: 19141/30000 (63.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4830s / 343.6739 s
agent0:                 episode reward: -0.7752,                 loss: nan
agent1:                 episode reward: 0.7752,                 loss: 0.2681
Episode: 19161/30000 (63.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5030s / 344.1769 s
agent0:                 episode reward: -0.9493,                 loss: nan
agent1:                 episode reward: 0.9493,                 loss: 0.2643
Episode: 19181/30000 (63.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4773s / 344.6542 s
agent0:                 episode reward: -1.0314,                 loss: nan
agent1:                 episode reward: 1.0314,                 loss: 0.2633
Episode: 19201/30000 (64.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4775s / 345.1318 s
agent0:                 episode reward: -0.9584,                 loss: nan
agent1:                 episode reward: 0.9584,                 loss: 0.2632
Episode: 19221/30000 (64.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4832s / 345.6150 s
agent0:                 episode reward: -0.8784,                 loss: nan
agent1:                 episode reward: 0.8784,                 loss: 0.2690
Episode: 19241/30000 (64.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4876s / 346.1025 s
agent0:                 episode reward: -1.5037,                 loss: nan
agent1:                 episode reward: 1.5037,                 loss: 0.2712
Episode: 19261/30000 (64.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4839s / 346.5865 s
agent0:                 episode reward: -1.4165,                 loss: nan
agent1:                 episode reward: 1.4165,                 loss: 0.2687
Episode: 19281/30000 (64.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4909s / 347.0774 s
agent0:                 episode reward: -1.1556,                 loss: nan
agent1:                 episode reward: 1.1556,                 loss: 0.2680
Episode: 19301/30000 (64.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5557s / 347.6331 s
agent0:                 episode reward: -1.1615,                 loss: nan
agent1:                 episode reward: 1.1615,                 loss: 0.2694
Episode: 19321/30000 (64.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4864s / 348.1196 s
agent0:                 episode reward: -0.8131,                 loss: nan
agent1:                 episode reward: 0.8131,                 loss: 0.2726
Episode: 19341/30000 (64.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4846s / 348.6042 s
agent0:                 episode reward: -1.3278,                 loss: nan
agent1:                 episode reward: 1.3278,                 loss: 0.2666
Episode: 19361/30000 (64.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5049s / 349.1091 s
agent0:                 episode reward: -0.9903,                 loss: nan
agent1:                 episode reward: 0.9903,                 loss: 0.2718
Episode: 19381/30000 (64.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4819s / 349.5910 s
agent0:                 episode reward: -0.6637,                 loss: nan
agent1:                 episode reward: 0.6637,                 loss: 0.2672
Episode: 19401/30000 (64.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4892s / 350.0803 s
agent0:                 episode reward: -1.1887,                 loss: nan
agent1:                 episode reward: 1.1887,                 loss: 0.2681
Episode: 19421/30000 (64.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4819s / 350.5621 s
agent0:                 episode reward: -1.0437,                 loss: nan
agent1:                 episode reward: 1.0437,                 loss: 0.2712
Episode: 19441/30000 (64.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4821s / 351.0442 s
agent0:                 episode reward: -0.9665,                 loss: nan
agent1:                 episode reward: 0.9665,                 loss: 0.2736
Episode: 19461/30000 (64.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5083s / 351.5525 s
agent0:                 episode reward: -1.0691,                 loss: nan
agent1:                 episode reward: 1.0691,                 loss: 0.2684
Episode: 19481/30000 (64.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4862s / 352.0387 s
agent0:                 episode reward: -0.7763,                 loss: nan
agent1:                 episode reward: 0.7763,                 loss: 0.2695
Episode: 19501/30000 (65.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4886s / 352.5273 s
agent0:                 episode reward: -1.2368,                 loss: nan
agent1:                 episode reward: 1.2368,                 loss: 0.2725
Episode: 19521/30000 (65.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4962s / 353.0234 s
agent0:                 episode reward: -1.1305,                 loss: nan
agent1:                 episode reward: 1.1305,                 loss: 0.2712
Episode: 19541/30000 (65.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4915s / 353.5149 s
agent0:                 episode reward: -1.0719,                 loss: nan
agent1:                 episode reward: 1.0719,                 loss: 0.2690
Episode: 19561/30000 (65.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4890s / 354.0039 s
agent0:                 episode reward: -0.7508,                 loss: nan
agent1:                 episode reward: 0.7508,                 loss: 0.2704
Episode: 19581/30000 (65.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4952s / 354.4992 s
agent0:                 episode reward: -0.8628,                 loss: nan
agent1:                 episode reward: 0.8628,                 loss: 0.2704
Episode: 19601/30000 (65.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4939s / 354.9931 s
agent0:                 episode reward: -1.0025,                 loss: nan
agent1:                 episode reward: 1.0025,                 loss: 0.2718
Episode: 19621/30000 (65.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5022s / 355.4953 s
agent0:                 episode reward: -1.1068,                 loss: nan
agent1:                 episode reward: 1.1068,                 loss: 0.2685
Episode: 19641/30000 (65.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5041s / 355.9994 s
agent0:                 episode reward: -1.6350,                 loss: nan
agent1:                 episode reward: 1.6350,                 loss: 0.2691
Episode: 19661/30000 (65.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5041s / 356.5035 s
agent0:                 episode reward: -1.1532,                 loss: nan
agent1:                 episode reward: 1.1532,                 loss: 0.2637
Episode: 19681/30000 (65.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4925s / 356.9961 s
agent0:                 episode reward: -0.9395,                 loss: nan
agent1:                 episode reward: 0.9395,                 loss: 0.2709
Episode: 19701/30000 (65.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5044s / 357.5005 s
agent0:                 episode reward: -0.8338,                 loss: nan
agent1:                 episode reward: 0.8338,                 loss: 0.2689
Episode: 19721/30000 (65.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5374s / 358.0379 s
agent0:                 episode reward: -0.8556,                 loss: nan
agent1:                 episode reward: 0.8556,                 loss: 0.2713
Episode: 19741/30000 (65.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5080s / 358.5459 s
agent0:                 episode reward: -1.1219,                 loss: nan
agent1:                 episode reward: 1.1219,                 loss: 0.2689
Episode: 19761/30000 (65.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5006s / 359.0465 s
agent0:                 episode reward: -1.0191,                 loss: nan
agent1:                 episode reward: 1.0191,                 loss: 0.2696
Episode: 19781/30000 (65.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4945s / 359.5410 s
agent0:                 episode reward: -1.1827,                 loss: nan
agent1:                 episode reward: 1.1827,                 loss: 0.2703
Episode: 19801/30000 (66.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4920s / 360.0330 s
agent0:                 episode reward: -0.8959,                 loss: nan
agent1:                 episode reward: 0.8959,                 loss: 0.2713
Episode: 19821/30000 (66.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4933s / 360.5263 s
agent0:                 episode reward: -1.0309,                 loss: nan
agent1:                 episode reward: 1.0309,                 loss: 0.2705
Episode: 19841/30000 (66.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4933s / 361.0196 s
agent0:                 episode reward: -1.1072,                 loss: nan
agent1:                 episode reward: 1.1072,                 loss: 0.2685
Episode: 19861/30000 (66.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4887s / 361.5083 s
agent0:                 episode reward: -1.0581,                 loss: nan
agent1:                 episode reward: 1.0581,                 loss: 0.2712
Episode: 19881/30000 (66.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5060s / 362.0143 s
agent0:                 episode reward: -0.9804,                 loss: nan
agent1:                 episode reward: 0.9804,                 loss: 0.2711
Episode: 19901/30000 (66.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5153s / 362.5296 s
agent0:                 episode reward: -0.7981,                 loss: nan
agent1:                 episode reward: 0.7981,                 loss: 0.2648
Episode: 19921/30000 (66.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4977s / 363.0274 s
agent0:                 episode reward: -1.3784,                 loss: nan
agent1:                 episode reward: 1.3784,                 loss: 0.2652
Episode: 19941/30000 (66.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4989s / 363.5263 s
agent0:                 episode reward: -0.9990,                 loss: nan
agent1:                 episode reward: 0.9990,                 loss: 0.2646
Episode: 19961/30000 (66.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5014s / 364.0277 s
agent0:                 episode reward: -0.9504,                 loss: nan
agent1:                 episode reward: 0.9504,                 loss: 0.2652
Episode: 19981/30000 (66.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4991s / 364.5267 s
agent0:                 episode reward: -0.9617,                 loss: nan
agent1:                 episode reward: 0.9617,                 loss: 0.2679
Episode: 20001/30000 (66.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5009s / 365.0277 s
agent0:                 episode reward: -1.1943,                 loss: nan
agent1:                 episode reward: 1.1943,                 loss: 0.2658
Episode: 20021/30000 (66.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5275s / 365.5552 s
agent0:                 episode reward: -1.2079,                 loss: nan
agent1:                 episode reward: 1.2079,                 loss: 0.2669
Episode: 20041/30000 (66.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5035s / 366.0587 s
agent0:                 episode reward: -0.8706,                 loss: nan
agent1:                 episode reward: 0.8706,                 loss: 0.2648
Episode: 20061/30000 (66.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5046s / 366.5633 s
agent0:                 episode reward: -0.7600,                 loss: nan
agent1:                 episode reward: 0.7600,                 loss: 0.2658
Episode: 20081/30000 (66.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5055s / 367.0689 s
agent0:                 episode reward: -0.8140,                 loss: nan
agent1:                 episode reward: 0.8140,                 loss: 0.2687
Episode: 20101/30000 (67.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5017s / 367.5705 s
agent0:                 episode reward: -1.0149,                 loss: nan
agent1:                 episode reward: 1.0149,                 loss: 0.2667
Episode: 20121/30000 (67.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5508s / 368.1214 s
agent0:                 episode reward: -1.0965,                 loss: nan
agent1:                 episode reward: 1.0965,                 loss: 0.2655
Episode: 20141/30000 (67.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5184s / 368.6398 s
agent0:                 episode reward: -1.2259,                 loss: nan
agent1:                 episode reward: 1.2259,                 loss: 0.2684
Episode: 20161/30000 (67.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5002s / 369.1400 s
agent0:                 episode reward: -1.1097,                 loss: nan
agent1:                 episode reward: 1.1097,                 loss: 0.2637
Episode: 20181/30000 (67.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5004s / 369.6404 s
agent0:                 episode reward: -0.6330,                 loss: nan
agent1:                 episode reward: 0.6330,                 loss: 0.2661
Episode: 20201/30000 (67.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4998s / 370.1402 s
agent0:                 episode reward: -0.7941,                 loss: nan
agent1:                 episode reward: 0.7941,                 loss: 0.2650
Episode: 20221/30000 (67.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5055s / 370.6457 s
agent0:                 episode reward: -1.1263,                 loss: nan
agent1:                 episode reward: 1.1263,                 loss: 0.2669
Episode: 20241/30000 (67.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5071s / 371.1528 s
agent0:                 episode reward: -1.1444,                 loss: nan
agent1:                 episode reward: 1.1444,                 loss: 0.2785
Episode: 20261/30000 (67.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5029s / 371.6557 s
agent0:                 episode reward: -1.0703,                 loss: nan
agent1:                 episode reward: 1.0703,                 loss: 0.2795
Episode: 20281/30000 (67.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4989s / 372.1545 s
agent0:                 episode reward: -1.0993,                 loss: nan
agent1:                 episode reward: 1.0993,                 loss: 0.2753
Episode: 20301/30000 (67.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5000s / 372.6546 s
agent0:                 episode reward: -0.8418,                 loss: nan
agent1:                 episode reward: 0.8418,                 loss: 0.2738
Episode: 20321/30000 (67.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4945s / 373.1490 s
agent0:                 episode reward: -0.8738,                 loss: nan
agent1:                 episode reward: 0.8738,                 loss: 0.2759
Episode: 20341/30000 (67.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5078s / 373.6569 s
agent0:                 episode reward: -1.1950,                 loss: nan
agent1:                 episode reward: 1.1950,                 loss: 0.2765
Episode: 20361/30000 (67.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5095s / 374.1664 s
agent0:                 episode reward: -0.9377,                 loss: nan
agent1:                 episode reward: 0.9377,                 loss: 0.2770
Episode: 20381/30000 (67.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5047s / 374.6710 s
agent0:                 episode reward: -1.0046,                 loss: nan
agent1:                 episode reward: 1.0046,                 loss: 0.2781
Episode: 20401/30000 (68.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5010s / 375.1721 s
agent0:                 episode reward: -1.0810,                 loss: nan
agent1:                 episode reward: 1.0810,                 loss: 0.2745
Episode: 20421/30000 (68.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5042s / 375.6763 s
agent0:                 episode reward: -1.1430,                 loss: nan
agent1:                 episode reward: 1.1430,                 loss: 0.2743
Episode: 20441/30000 (68.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5017s / 376.1780 s
agent0:                 episode reward: -1.1694,                 loss: nan
agent1:                 episode reward: 1.1694,                 loss: 0.2799
Episode: 20461/30000 (68.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4983s / 376.6763 s
agent0:                 episode reward: -1.0218,                 loss: nan
agent1:                 episode reward: 1.0218,                 loss: 0.2763
Episode: 20481/30000 (68.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5002s / 377.1765 s
agent0:                 episode reward: -0.9103,                 loss: nan
agent1:                 episode reward: 0.9103,                 loss: 0.2783
Episode: 20501/30000 (68.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5074s / 377.6839 s
agent0:                 episode reward: -1.3247,                 loss: nan
agent1:                 episode reward: 1.3247,                 loss: 0.2764
Episode: 20521/30000 (68.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5386s / 378.2225 s
agent0:                 episode reward: -1.1920,                 loss: nan
agent1:                 episode reward: 1.1920,                 loss: 0.2794
Episode: 20541/30000 (68.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5203s / 378.7428 s
agent0:                 episode reward: -1.2041,                 loss: nan
agent1:                 episode reward: 1.2041,                 loss: 0.2757
Episode: 20561/30000 (68.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4985s / 379.2413 s
agent0:                 episode reward: -0.9948,                 loss: nan
agent1:                 episode reward: 0.9948,                 loss: 0.2743
Episode: 20581/30000 (68.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4962s / 379.7375 s
agent0:                 episode reward: -1.2889,                 loss: nan
agent1:                 episode reward: 1.2889,                 loss: 0.2717
Episode: 20601/30000 (68.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5331s / 380.2706 s
agent0:                 episode reward: -1.0309,                 loss: nan
agent1:                 episode reward: 1.0309,                 loss: 0.2674
Episode: 20621/30000 (68.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5003s / 380.7709 s
agent0:                 episode reward: -1.1156,                 loss: nan
agent1:                 episode reward: 1.1156,                 loss: 0.2687
Episode: 20641/30000 (68.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5038s / 381.2747 s
agent0:                 episode reward: -1.0607,                 loss: nan
agent1:                 episode reward: 1.0607,                 loss: 0.2708
Episode: 20661/30000 (68.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5084s / 381.7830 s
agent0:                 episode reward: -1.3017,                 loss: nan
agent1:                 episode reward: 1.3017,                 loss: 0.2704
Episode: 20681/30000 (68.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5240s / 382.3070 s
agent0:                 episode reward: -0.9967,                 loss: nan
agent1:                 episode reward: 0.9967,                 loss: 0.2691
Episode: 20701/30000 (69.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5137s / 382.8207 s
agent0:                 episode reward: -1.0338,                 loss: nan
agent1:                 episode reward: 1.0338,                 loss: 0.2719
Episode: 20721/30000 (69.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5358s / 383.3565 s
agent0:                 episode reward: -1.2402,                 loss: nan
agent1:                 episode reward: 1.2402,                 loss: 0.2694
Episode: 20741/30000 (69.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5103s / 383.8668 s
agent0:                 episode reward: -1.0183,                 loss: nan
agent1:                 episode reward: 1.0183,                 loss: 0.2675
Episode: 20761/30000 (69.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5110s / 384.3778 s
agent0:                 episode reward: -1.1242,                 loss: nan
agent1:                 episode reward: 1.1242,                 loss: 0.2740
Episode: 20781/30000 (69.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5083s / 384.8861 s
agent0:                 episode reward: -1.1610,                 loss: nan
agent1:                 episode reward: 1.1610,                 loss: 0.2746
Episode: 20801/30000 (69.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5025s / 385.3886 s
agent0:                 episode reward: -1.2839,                 loss: nan
agent1:                 episode reward: 1.2839,                 loss: 0.2704
Episode: 20821/30000 (69.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5091s / 385.8977 s
agent0:                 episode reward: -1.0929,                 loss: nan
agent1:                 episode reward: 1.0929,                 loss: 0.2693
Episode: 20841/30000 (69.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5124s / 386.4101 s
agent0:                 episode reward: -1.2755,                 loss: nan
agent1:                 episode reward: 1.2755,                 loss: 0.2676
Episode: 20861/30000 (69.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5046s / 386.9147 s
agent0:                 episode reward: -1.1799,                 loss: nan
agent1:                 episode reward: 1.1799,                 loss: 0.2714
Episode: 20881/30000 (69.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5058s / 387.4205 s
agent0:                 episode reward: -0.8419,                 loss: nan
agent1:                 episode reward: 0.8419,                 loss: 0.2703
Episode: 20901/30000 (69.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5327s / 387.9532 s
agent0:                 episode reward: -1.0503,                 loss: nan
agent1:                 episode reward: 1.0503,                 loss: 0.2732
Episode: 20921/30000 (69.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5384s / 388.4917 s
agent0:                 episode reward: -1.0019,                 loss: nan
agent1:                 episode reward: 1.0019,                 loss: 0.2731
Episode: 20941/30000 (69.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5246s / 389.0162 s
agent0:                 episode reward: -1.1368,                 loss: nan
agent1:                 episode reward: 1.1368,                 loss: 0.2709
Episode: 20961/30000 (69.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5256s / 389.5419 s
agent0:                 episode reward: -1.1892,                 loss: nan
agent1:                 episode reward: 1.1892,                 loss: 0.2720
Episode: 20981/30000 (69.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5078s / 390.0497 s
agent0:                 episode reward: -0.9864,                 loss: nan
agent1:                 episode reward: 0.9864,                 loss: 0.2737
Episode: 21001/30000 (70.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5279s / 390.5776 s
agent0:                 episode reward: -1.1530,                 loss: nan
agent1:                 episode reward: 1.1530,                 loss: 0.2692
Episode: 21021/30000 (70.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5086s / 391.0861 s
agent0:                 episode reward: -0.8152,                 loss: nan
agent1:                 episode reward: 0.8152,                 loss: 0.2721
Episode: 21041/30000 (70.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5092s / 391.5954 s
agent0:                 episode reward: -1.2576,                 loss: nan
agent1:                 episode reward: 1.2576,                 loss: 0.2713
Episode: 21061/30000 (70.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5116s / 392.1070 s
agent0:                 episode reward: -1.1088,                 loss: nan
agent1:                 episode reward: 1.1088,                 loss: 0.2694
Episode: 21081/30000 (70.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5221s / 392.6291 s
agent0:                 episode reward: -1.1435,                 loss: nan
agent1:                 episode reward: 1.1435,                 loss: 0.2706
Episode: 21101/30000 (70.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5080s / 393.1372 s
agent0:                 episode reward: -1.3689,                 loss: nan
agent1:                 episode reward: 1.3689,                 loss: 0.2731
Episode: 21121/30000 (70.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5094s / 393.6465 s
agent0:                 episode reward: -0.8302,                 loss: nan
agent1:                 episode reward: 0.8302,                 loss: 0.2727
Episode: 21141/30000 (70.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5118s / 394.1584 s
agent0:                 episode reward: -1.1164,                 loss: nan
agent1:                 episode reward: 1.1164,                 loss: 0.2725
Episode: 21161/30000 (70.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5133s / 394.6717 s
agent0:                 episode reward: -1.2600,                 loss: nan
agent1:                 episode reward: 1.2600,                 loss: 0.2711
Episode: 21181/30000 (70.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5119s / 395.1836 s
agent0:                 episode reward: -1.2616,                 loss: nan
agent1:                 episode reward: 1.2616,                 loss: 0.2694
Episode: 21201/30000 (70.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5163s / 395.6999 s
agent0:                 episode reward: -1.0437,                 loss: nan
agent1:                 episode reward: 1.0437,                 loss: 0.2744
Episode: 21221/30000 (70.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5096s / 396.2095 s
agent0:                 episode reward: -1.1027,                 loss: nan
agent1:                 episode reward: 1.1027,                 loss: 0.2714
Episode: 21241/30000 (70.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5100s / 396.7195 s
agent0:                 episode reward: -0.8896,                 loss: nan
agent1:                 episode reward: 0.8896,                 loss: 0.2696
Episode: 21261/30000 (70.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5495s / 397.2691 s
agent0:                 episode reward: -1.0518,                 loss: nan
agent1:                 episode reward: 1.0518,                 loss: 0.2730
Episode: 21281/30000 (70.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5612s / 397.8303 s
agent0:                 episode reward: -0.8467,                 loss: nan
agent1:                 episode reward: 0.8467,                 loss: 0.2731
Episode: 21301/30000 (71.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5165s / 398.3468 s
agent0:                 episode reward: -1.0713,                 loss: nan
agent1:                 episode reward: 1.0713,                 loss: 0.2724
Episode: 21321/30000 (71.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5817s / 398.9284 s
agent0:                 episode reward: -1.0015,                 loss: nan
agent1:                 episode reward: 1.0015,                 loss: 0.2742
Episode: 21341/30000 (71.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5553s / 399.4838 s
agent0:                 episode reward: -0.9740,                 loss: nan
agent1:                 episode reward: 0.9740,                 loss: 0.2711
Episode: 21361/30000 (71.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5180s / 400.0017 s
agent0:                 episode reward: -0.9058,                 loss: nan
agent1:                 episode reward: 0.9058,                 loss: 0.2731
Episode: 21381/30000 (71.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5096s / 400.5113 s
agent0:                 episode reward: -1.3754,                 loss: nan
agent1:                 episode reward: 1.3754,                 loss: 0.2692
Episode: 21401/30000 (71.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5131s / 401.0244 s
agent0:                 episode reward: -0.9787,                 loss: nan
agent1:                 episode reward: 0.9787,                 loss: 0.2728
Episode: 21421/30000 (71.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5629s / 401.5874 s
agent0:                 episode reward: -0.7117,                 loss: nan
agent1:                 episode reward: 0.7117,                 loss: 0.2695
Episode: 21441/30000 (71.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5169s / 402.1043 s
agent0:                 episode reward: -1.1900,                 loss: nan
agent1:                 episode reward: 1.1900,                 loss: 0.2692
Episode: 21461/30000 (71.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5087s / 402.6130 s
agent0:                 episode reward: -1.3257,                 loss: nan
agent1:                 episode reward: 1.3257,                 loss: 0.2707
Episode: 21481/30000 (71.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5062s / 403.1191 s
agent0:                 episode reward: -1.1393,                 loss: nan
agent1:                 episode reward: 1.1393,                 loss: 0.2727
Episode: 21501/30000 (71.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5132s / 403.6324 s
agent0:                 episode reward: -0.7552,                 loss: nan
agent1:                 episode reward: 0.7552,                 loss: 0.2702
Episode: 21521/30000 (71.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5180s / 404.1504 s
agent0:                 episode reward: -0.8729,                 loss: nan
agent1:                 episode reward: 0.8729,                 loss: 0.2725
Episode: 21541/30000 (71.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5676s / 404.7180 s
agent0:                 episode reward: -0.8062,                 loss: nan
agent1:                 episode reward: 0.8062,                 loss: 0.2680
Episode: 21561/30000 (71.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5120s / 405.2300 s
agent0:                 episode reward: -1.2380,                 loss: nan
agent1:                 episode reward: 1.2380,                 loss: 0.2733
Episode: 21581/30000 (71.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5145s / 405.7445 s
agent0:                 episode reward: -0.9667,                 loss: nan
agent1:                 episode reward: 0.9667,                 loss: 0.2711
Episode: 21601/30000 (72.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5155s / 406.2599 s
agent0:                 episode reward: -1.3955,                 loss: nan
agent1:                 episode reward: 1.3955,                 loss: 0.2709
Episode: 21621/30000 (72.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5497s / 406.8096 s
agent0:                 episode reward: -1.1270,                 loss: nan
agent1:                 episode reward: 1.1270,                 loss: 0.2725
Episode: 21641/30000 (72.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5389s / 407.3485 s
agent0:                 episode reward: -1.1306,                 loss: nan
agent1:                 episode reward: 1.1306,                 loss: 0.2701
Episode: 21661/30000 (72.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5281s / 407.8766 s
agent0:                 episode reward: -0.8660,                 loss: nan
agent1:                 episode reward: 0.8660,                 loss: 0.2704
Episode: 21681/30000 (72.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5203s / 408.3969 s
agent0:                 episode reward: -1.0047,                 loss: nan
agent1:                 episode reward: 1.0047,                 loss: 0.2731
Episode: 21701/30000 (72.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5640s / 408.9609 s
agent0:                 episode reward: -0.8232,                 loss: nan
agent1:                 episode reward: 0.8232,                 loss: 0.2729
Episode: 21721/30000 (72.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5294s / 409.4903 s
agent0:                 episode reward: -0.9802,                 loss: nan
agent1:                 episode reward: 0.9802,                 loss: 0.2690
Episode: 21741/30000 (72.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5250s / 410.0154 s
agent0:                 episode reward: -1.1299,                 loss: nan
agent1:                 episode reward: 1.1299,                 loss: 0.2691
Episode: 21761/30000 (72.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5299s / 410.5452 s
agent0:                 episode reward: -1.1760,                 loss: nan
agent1:                 episode reward: 1.1760,                 loss: 0.2686
Episode: 21781/30000 (72.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5210s / 411.0662 s
agent0:                 episode reward: -0.9341,                 loss: nan
agent1:                 episode reward: 0.9341,                 loss: 0.2688
Episode: 21801/30000 (72.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5193s / 411.5855 s
agent0:                 episode reward: -1.2025,                 loss: nan
agent1:                 episode reward: 1.2025,                 loss: 0.2724
Episode: 21821/30000 (72.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5175s / 412.1030 s
agent0:                 episode reward: -1.0932,                 loss: nan
agent1:                 episode reward: 1.0932,                 loss: 0.2690
Episode: 21841/30000 (72.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5439s / 412.6469 s
agent0:                 episode reward: -1.2228,                 loss: nan
agent1:                 episode reward: 1.2228,                 loss: 0.2713
Episode: 21861/30000 (72.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5167s / 413.1637 s
agent0:                 episode reward: -1.0704,                 loss: nan
agent1:                 episode reward: 1.0704,                 loss: 0.2717
Episode: 21881/30000 (72.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5264s / 413.6900 s
agent0:                 episode reward: -1.3303,                 loss: nan
agent1:                 episode reward: 1.3303,                 loss: 0.2697
Episode: 21901/30000 (73.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5183s / 414.2083 s
agent0:                 episode reward: -1.1236,                 loss: nan
agent1:                 episode reward: 1.1236,                 loss: 0.2768
Episode: 21921/30000 (73.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5208s / 414.7291 s
agent0:                 episode reward: -1.3026,                 loss: nan
agent1:                 episode reward: 1.3026,                 loss: 0.2743
Episode: 21941/30000 (73.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5329s / 415.2620 s
agent0:                 episode reward: -0.9823,                 loss: nan
agent1:                 episode reward: 0.9823,                 loss: 0.2710
Episode: 21961/30000 (73.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5219s / 415.7839 s
agent0:                 episode reward: -0.9347,                 loss: nan
agent1:                 episode reward: 0.9347,                 loss: 0.2702
Episode: 21981/30000 (73.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5187s / 416.3027 s
agent0:                 episode reward: -1.1953,                 loss: nan
agent1:                 episode reward: 1.1953,                 loss: 0.2765
Episode: 22001/30000 (73.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5262s / 416.8289 s
agent0:                 episode reward: -1.2111,                 loss: nan
agent1:                 episode reward: 1.2111,                 loss: 0.2740
Episode: 22021/30000 (73.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5296s / 417.3585 s
agent0:                 episode reward: -0.7493,                 loss: nan
agent1:                 episode reward: 0.7493,                 loss: 0.2700
Episode: 22041/30000 (73.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5280s / 417.8865 s
agent0:                 episode reward: -1.1956,                 loss: nan
agent1:                 episode reward: 1.1956,                 loss: 0.2749
Episode: 22061/30000 (73.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5197s / 418.4062 s
agent0:                 episode reward: -1.2501,                 loss: nan
agent1:                 episode reward: 1.2501,                 loss: 0.2730
Episode: 22081/30000 (73.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5142s / 418.9204 s
agent0:                 episode reward: -1.1238,                 loss: nan
agent1:                 episode reward: 1.1238,                 loss: 0.2720
Episode: 22101/30000 (73.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6071s / 419.5275 s
agent0:                 episode reward: -1.0346,                 loss: nan
agent1:                 episode reward: 1.0346,                 loss: 0.2755
Episode: 22121/30000 (73.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5441s / 420.0716 s
agent0:                 episode reward: -0.8547,                 loss: nan
agent1:                 episode reward: 0.8547,                 loss: 0.2731
Episode: 22141/30000 (73.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5314s / 420.6031 s
agent0:                 episode reward: -1.0070,                 loss: nan
agent1:                 episode reward: 1.0070,                 loss: 0.2717
Episode: 22161/30000 (73.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5269s / 421.1300 s
agent0:                 episode reward: -1.0098,                 loss: nan
agent1:                 episode reward: 1.0098,                 loss: 0.2733
Episode: 22181/30000 (73.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5312s / 421.6612 s
agent0:                 episode reward: -1.2604,                 loss: nan
agent1:                 episode reward: 1.2604,                 loss: 0.2710
Episode: 22201/30000 (74.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5299s / 422.1911 s
agent0:                 episode reward: -1.1944,                 loss: nan
agent1:                 episode reward: 1.1944,                 loss: 0.2719
Episode: 22221/30000 (74.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5356s / 422.7267 s
agent0:                 episode reward: -1.2408,                 loss: nan
agent1:                 episode reward: 1.2408,                 loss: 0.2760
Episode: 22241/30000 (74.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5259s / 423.2526 s
agent0:                 episode reward: -0.9746,                 loss: nan
agent1:                 episode reward: 0.9746,                 loss: 0.2787
Episode: 22261/30000 (74.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5555s / 423.8081 s
agent0:                 episode reward: -1.1636,                 loss: nan
agent1:                 episode reward: 1.1636,                 loss: 0.2770
Episode: 22281/30000 (74.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5336s / 424.3416 s
agent0:                 episode reward: -0.6839,                 loss: nan
agent1:                 episode reward: 0.6839,                 loss: 0.2761
Episode: 22301/30000 (74.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5237s / 424.8654 s
agent0:                 episode reward: -0.9707,                 loss: nan
agent1:                 episode reward: 0.9707,                 loss: 0.2754
Episode: 22321/30000 (74.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5291s / 425.3945 s
agent0:                 episode reward: -1.0147,                 loss: nan
agent1:                 episode reward: 1.0147,                 loss: 0.2750
Episode: 22341/30000 (74.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5366s / 425.9311 s
agent0:                 episode reward: -1.0570,                 loss: nan
agent1:                 episode reward: 1.0570,                 loss: 0.2723
Episode: 22361/30000 (74.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5229s / 426.4540 s
agent0:                 episode reward: -1.1284,                 loss: nan
agent1:                 episode reward: 1.1284,                 loss: 0.2726
Episode: 22381/30000 (74.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5253s / 426.9794 s
agent0:                 episode reward: -1.1487,                 loss: nan
agent1:                 episode reward: 1.1487,                 loss: 0.2732
Episode: 22401/30000 (74.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5306s / 427.5099 s
agent0:                 episode reward: -1.2179,                 loss: nan
agent1:                 episode reward: 1.2179,                 loss: 0.2706
Episode: 22421/30000 (74.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5249s / 428.0349 s
agent0:                 episode reward: -1.0447,                 loss: nan
agent1:                 episode reward: 1.0447,                 loss: 0.2734
Episode: 22441/30000 (74.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5247s / 428.5596 s
agent0:                 episode reward: -0.9562,                 loss: nan
agent1:                 episode reward: 0.9562,                 loss: 0.2774
Episode: 22461/30000 (74.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5312s / 429.0908 s
agent0:                 episode reward: -0.6462,                 loss: nan
agent1:                 episode reward: 0.6462,                 loss: 0.2751
Episode: 22481/30000 (74.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5852s / 429.6760 s
agent0:                 episode reward: -1.0536,                 loss: nan
agent1:                 episode reward: 1.0536,                 loss: 0.2720
Episode: 22501/30000 (75.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5355s / 430.2115 s
agent0:                 episode reward: -1.0389,                 loss: nan
agent1:                 episode reward: 1.0389,                 loss: 0.2735
Episode: 22521/30000 (75.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5283s / 430.7398 s
agent0:                 episode reward: -0.8197,                 loss: nan
agent1:                 episode reward: 0.8197,                 loss: 0.2727
Episode: 22541/30000 (75.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5294s / 431.2692 s
agent0:                 episode reward: -1.0036,                 loss: nan
agent1:                 episode reward: 1.0036,                 loss: 0.2764
Episode: 22561/30000 (75.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5659s / 431.8351 s
agent0:                 episode reward: -1.0730,                 loss: nan
agent1:                 episode reward: 1.0730,                 loss: 0.2753
Episode: 22581/30000 (75.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5280s / 432.3631 s
agent0:                 episode reward: -1.0835,                 loss: nan
agent1:                 episode reward: 1.0835,                 loss: 0.2733
Episode: 22601/30000 (75.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5715s / 432.9346 s
agent0:                 episode reward: -1.1372,                 loss: nan
agent1:                 episode reward: 1.1372,                 loss: 0.2716
Episode: 22621/30000 (75.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5317s / 433.4663 s
agent0:                 episode reward: -1.0761,                 loss: nan
agent1:                 episode reward: 1.0761,                 loss: 0.2744
Episode: 22641/30000 (75.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5573s / 434.0235 s
agent0:                 episode reward: -0.9767,                 loss: nan
agent1:                 episode reward: 0.9767,                 loss: 0.2743
Episode: 22661/30000 (75.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5359s / 434.5594 s
agent0:                 episode reward: -0.7919,                 loss: nan
agent1:                 episode reward: 0.7919,                 loss: 0.2727
Episode: 22681/30000 (75.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5568s / 435.1162 s
agent0:                 episode reward: -0.9732,                 loss: nan
agent1:                 episode reward: 0.9732,                 loss: 0.2746
Episode: 22701/30000 (75.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5356s / 435.6518 s
agent0:                 episode reward: -1.1329,                 loss: nan
agent1:                 episode reward: 1.1329,                 loss: 0.2750
Episode: 22721/30000 (75.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5302s / 436.1820 s
agent0:                 episode reward: -1.2002,                 loss: nan
agent1:                 episode reward: 1.2002,                 loss: 0.2709
Episode: 22741/30000 (75.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5322s / 436.7142 s
agent0:                 episode reward: -1.2318,                 loss: nan
agent1:                 episode reward: 1.2318,                 loss: 0.2746
Episode: 22761/30000 (75.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5662s / 437.2803 s
agent0:                 episode reward: -1.0359,                 loss: nan
agent1:                 episode reward: 1.0359,                 loss: 0.2713
Episode: 22781/30000 (75.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5458s / 437.8261 s
agent0:                 episode reward: -1.0695,                 loss: nan
agent1:                 episode reward: 1.0695,                 loss: 0.2762
Episode: 22801/30000 (76.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5545s / 438.3807 s
agent0:                 episode reward: -1.0677,                 loss: nan
agent1:                 episode reward: 1.0677,                 loss: 0.2770
Episode: 22821/30000 (76.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5385s / 438.9192 s
agent0:                 episode reward: -1.1269,                 loss: nan
agent1:                 episode reward: 1.1269,                 loss: 0.2688
Episode: 22841/30000 (76.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5411s / 439.4603 s
agent0:                 episode reward: -1.1121,                 loss: nan
agent1:                 episode reward: 1.1121,                 loss: 0.2733
Episode: 22861/30000 (76.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6477s / 440.1080 s
agent0:                 episode reward: -1.1753,                 loss: nan
agent1:                 episode reward: 1.1753,                 loss: 0.2723
Episode: 22881/30000 (76.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5343s / 440.6423 s
agent0:                 episode reward: -0.9786,                 loss: nan
agent1:                 episode reward: 0.9786,                 loss: 0.2730
Episode: 22901/30000 (76.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5583s / 441.2006 s
agent0:                 episode reward: -0.9254,                 loss: nan
agent1:                 episode reward: 0.9254,                 loss: 0.2675
Episode: 22921/30000 (76.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5359s / 441.7365 s
agent0:                 episode reward: -0.6768,                 loss: nan
agent1:                 episode reward: 0.6768,                 loss: 0.2663
Episode: 22941/30000 (76.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5463s / 442.2828 s
agent0:                 episode reward: -1.1797,                 loss: nan
agent1:                 episode reward: 1.1797,                 loss: 0.2649
Episode: 22961/30000 (76.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5325s / 442.8152 s
agent0:                 episode reward: -1.1258,                 loss: nan
agent1:                 episode reward: 1.1258,                 loss: 0.2728
Episode: 22981/30000 (76.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5328s / 443.3480 s
agent0:                 episode reward: -1.2511,                 loss: nan
agent1:                 episode reward: 1.2511,                 loss: 0.2654
Episode: 23001/30000 (76.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5567s / 443.9048 s
agent0:                 episode reward: -0.8326,                 loss: nan
agent1:                 episode reward: 0.8326,                 loss: 0.2635
Episode: 23021/30000 (76.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5429s / 444.4477 s
agent0:                 episode reward: -1.2000,                 loss: nan
agent1:                 episode reward: 1.2000,                 loss: 0.2679
Episode: 23041/30000 (76.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5473s / 444.9950 s
agent0:                 episode reward: -0.9495,                 loss: nan
agent1:                 episode reward: 0.9495,                 loss: 0.2648
Episode: 23061/30000 (76.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5340s / 445.5290 s
agent0:                 episode reward: -1.2117,                 loss: nan
agent1:                 episode reward: 1.2117,                 loss: 0.2684
Episode: 23081/30000 (76.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5353s / 446.0643 s
agent0:                 episode reward: -0.8382,                 loss: nan
agent1:                 episode reward: 0.8382,                 loss: 0.2664
Episode: 23101/30000 (77.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5430s / 446.6073 s
agent0:                 episode reward: -1.1821,                 loss: nan
agent1:                 episode reward: 1.1821,                 loss: 0.2672
Episode: 23121/30000 (77.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5360s / 447.1433 s
agent0:                 episode reward: -1.4812,                 loss: nan
agent1:                 episode reward: 1.4812,                 loss: 0.2647
Episode: 23141/30000 (77.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5392s / 447.6825 s
agent0:                 episode reward: -1.4259,                 loss: nan
agent1:                 episode reward: 1.4259,                 loss: 0.2653
Episode: 23161/30000 (77.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5352s / 448.2177 s
agent0:                 episode reward: -1.0474,                 loss: nan
agent1:                 episode reward: 1.0474,                 loss: 0.2641
Episode: 23181/30000 (77.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5576s / 448.7753 s
agent0:                 episode reward: -0.9677,                 loss: nan
agent1:                 episode reward: 0.9677,                 loss: 0.2687
Episode: 23201/30000 (77.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5418s / 449.3171 s
agent0:                 episode reward: -0.8449,                 loss: nan
agent1:                 episode reward: 0.8449,                 loss: 0.2696
Episode: 23221/30000 (77.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5920s / 449.9090 s
agent0:                 episode reward: -1.0863,                 loss: nan
agent1:                 episode reward: 1.0863,                 loss: 0.2711
Episode: 23241/30000 (77.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5632s / 450.4722 s
agent0:                 episode reward: -0.7513,                 loss: nan
agent1:                 episode reward: 0.7513,                 loss: 0.2720
Episode: 23261/30000 (77.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5480s / 451.0202 s
agent0:                 episode reward: -1.0688,                 loss: nan
agent1:                 episode reward: 1.0688,                 loss: 0.2752
Episode: 23281/30000 (77.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5439s / 451.5641 s
agent0:                 episode reward: -0.6049,                 loss: nan
agent1:                 episode reward: 0.6049,                 loss: 0.2712
Episode: 23301/30000 (77.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5378s / 452.1019 s
agent0:                 episode reward: -1.0468,                 loss: nan
agent1:                 episode reward: 1.0468,                 loss: 0.2676
Episode: 23321/30000 (77.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5519s / 452.6539 s
agent0:                 episode reward: -1.2821,                 loss: nan
agent1:                 episode reward: 1.2821,                 loss: 0.2703
Episode: 23341/30000 (77.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5429s / 453.1968 s
agent0:                 episode reward: -0.7667,                 loss: nan
agent1:                 episode reward: 0.7667,                 loss: 0.2738
Episode: 23361/30000 (77.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5424s / 453.7392 s
agent0:                 episode reward: -0.9399,                 loss: nan
agent1:                 episode reward: 0.9399,                 loss: 0.2750
Episode: 23381/30000 (77.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5413s / 454.2805 s
agent0:                 episode reward: -1.2899,                 loss: nan
agent1:                 episode reward: 1.2899,                 loss: 0.2691
Episode: 23401/30000 (78.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5412s / 454.8217 s
agent0:                 episode reward: -1.2600,                 loss: nan
agent1:                 episode reward: 1.2600,                 loss: 0.2721
Episode: 23421/30000 (78.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5456s / 455.3673 s
agent0:                 episode reward: -1.2326,                 loss: nan
agent1:                 episode reward: 1.2326,                 loss: 0.2750
Episode: 23441/30000 (78.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5519s / 455.9192 s
agent0:                 episode reward: -1.0191,                 loss: nan
agent1:                 episode reward: 1.0191,                 loss: 0.2691
Episode: 23461/30000 (78.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5366s / 456.4559 s
agent0:                 episode reward: -1.1751,                 loss: nan
agent1:                 episode reward: 1.1751,                 loss: 0.2723
Episode: 23481/30000 (78.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5851s / 457.0410 s
agent0:                 episode reward: -1.0382,                 loss: nan
agent1:                 episode reward: 1.0382,                 loss: 0.2733
Episode: 23501/30000 (78.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5450s / 457.5859 s
agent0:                 episode reward: -1.5185,                 loss: nan
agent1:                 episode reward: 1.5185,                 loss: 0.2715
Episode: 23521/30000 (78.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5500s / 458.1360 s
agent0:                 episode reward: -1.3055,                 loss: nan
agent1:                 episode reward: 1.3055,                 loss: 0.2703
Episode: 23541/30000 (78.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5867s / 458.7227 s
agent0:                 episode reward: -1.4358,                 loss: nan
agent1:                 episode reward: 1.4358,                 loss: 0.2712
Episode: 23561/30000 (78.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5470s / 459.2697 s
agent0:                 episode reward: -1.2171,                 loss: nan
agent1:                 episode reward: 1.2171,                 loss: 0.2772
Episode: 23581/30000 (78.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5519s / 459.8216 s
agent0:                 episode reward: -1.0594,                 loss: nan
agent1:                 episode reward: 1.0594,                 loss: 0.2793
Episode: 23601/30000 (78.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6010s / 460.4227 s
agent0:                 episode reward: -1.1190,                 loss: nan
agent1:                 episode reward: 1.1190,                 loss: 0.2778
Episode: 23621/30000 (78.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5541s / 460.9768 s
agent0:                 episode reward: -1.2015,                 loss: nan
agent1:                 episode reward: 1.2015,                 loss: 0.2787
Episode: 23641/30000 (78.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5598s / 461.5366 s
agent0:                 episode reward: -1.0676,                 loss: nan
agent1:                 episode reward: 1.0676,                 loss: 0.2785
Episode: 23661/30000 (78.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5503s / 462.0869 s
agent0:                 episode reward: -0.9114,                 loss: nan
agent1:                 episode reward: 0.9114,                 loss: 0.2769
Episode: 23681/30000 (78.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5597s / 462.6466 s
agent0:                 episode reward: -1.1528,                 loss: nan
agent1:                 episode reward: 1.1528,                 loss: 0.2825
Episode: 23701/30000 (79.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5608s / 463.2074 s
agent0:                 episode reward: -1.2040,                 loss: nan
agent1:                 episode reward: 1.2040,                 loss: 0.2792
Episode: 23721/30000 (79.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5517s / 463.7591 s
agent0:                 episode reward: -1.2662,                 loss: nan
agent1:                 episode reward: 1.2662,                 loss: 0.2788
Episode: 23741/30000 (79.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5535s / 464.3127 s
agent0:                 episode reward: -0.8175,                 loss: nan
agent1:                 episode reward: 0.8175,                 loss: 0.2787
Episode: 23761/30000 (79.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5599s / 464.8726 s
agent0:                 episode reward: -0.9403,                 loss: nan
agent1:                 episode reward: 0.9403,                 loss: 0.2774
Episode: 23781/30000 (79.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5691s / 465.4417 s
agent0:                 episode reward: -1.1527,                 loss: nan
agent1:                 episode reward: 1.1527,                 loss: 0.2787
Episode: 23801/30000 (79.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5534s / 465.9951 s
agent0:                 episode reward: -1.0383,                 loss: nan
agent1:                 episode reward: 1.0383,                 loss: 0.2799
Episode: 23821/30000 (79.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5509s / 466.5460 s
agent0:                 episode reward: -0.9949,                 loss: nan
agent1:                 episode reward: 0.9949,                 loss: 0.2789
Episode: 23841/30000 (79.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5606s / 467.1066 s
agent0:                 episode reward: -0.8899,                 loss: nan
agent1:                 episode reward: 0.8899,                 loss: 0.2795
Episode: 23861/30000 (79.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5666s / 467.6732 s
agent0:                 episode reward: -1.0590,                 loss: nan
agent1:                 episode reward: 1.0590,                 loss: 0.2754
Episode: 23881/30000 (79.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5536s / 468.2267 s
agent0:                 episode reward: -1.0903,                 loss: nan
agent1:                 episode reward: 1.0903,                 loss: 0.2774
Episode: 23901/30000 (79.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5507s / 468.7774 s
agent0:                 episode reward: -1.1261,                 loss: nan
agent1:                 episode reward: 1.1261,                 loss: 0.2728
Episode: 23921/30000 (79.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5549s / 469.3323 s
agent0:                 episode reward: -1.1611,                 loss: nan
agent1:                 episode reward: 1.1611,                 loss: 0.2727
Episode: 23941/30000 (79.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5600s / 469.8923 s
agent0:                 episode reward: -1.3245,                 loss: nan
agent1:                 episode reward: 1.3245,                 loss: 0.2731
Episode: 23961/30000 (79.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5988s / 470.4911 s
agent0:                 episode reward: -1.1986,                 loss: nan
agent1:                 episode reward: 1.1986,                 loss: 0.2708
Episode: 23981/30000 (79.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5698s / 471.0609 s
agent0:                 episode reward: -1.1230,                 loss: nan
agent1:                 episode reward: 1.1230,                 loss: 0.2689
Episode: 24001/30000 (80.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5637s / 471.6246 s
agent0:                 episode reward: -1.2297,                 loss: nan
agent1:                 episode reward: 1.2297,                 loss: 0.2708
Episode: 24021/30000 (80.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5600s / 472.1847 s
agent0:                 episode reward: -1.0761,                 loss: nan
agent1:                 episode reward: 1.0761,                 loss: 0.2711
Episode: 24041/30000 (80.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5559s / 472.7406 s
agent0:                 episode reward: -1.1690,                 loss: nan
agent1:                 episode reward: 1.1690,                 loss: 0.2751
Episode: 24061/30000 (80.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5635s / 473.3041 s
agent0:                 episode reward: -0.9215,                 loss: nan
agent1:                 episode reward: 0.9215,                 loss: 0.2681
Episode: 24081/30000 (80.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5586s / 473.8627 s
agent0:                 episode reward: -1.0065,                 loss: nan
agent1:                 episode reward: 1.0065,                 loss: 0.2736
Episode: 24101/30000 (80.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5557s / 474.4184 s
agent0:                 episode reward: -1.2026,                 loss: nan
agent1:                 episode reward: 1.2026,                 loss: 0.2755
Episode: 24121/30000 (80.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5525s / 474.9709 s
agent0:                 episode reward: -0.9019,                 loss: nan
agent1:                 episode reward: 0.9019,                 loss: 0.2718
Episode: 24141/30000 (80.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5585s / 475.5295 s
agent0:                 episode reward: -1.1622,                 loss: nan
agent1:                 episode reward: 1.1622,                 loss: 0.2722
Episode: 24161/30000 (80.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5799s / 476.1093 s
agent0:                 episode reward: -1.4098,                 loss: nan
agent1:                 episode reward: 1.4098,                 loss: 0.2703
Episode: 24181/30000 (80.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5625s / 476.6718 s
agent0:                 episode reward: -0.9568,                 loss: nan
agent1:                 episode reward: 0.9568,                 loss: 0.2724
Episode: 24201/30000 (80.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5634s / 477.2352 s
agent0:                 episode reward: -1.1904,                 loss: nan
agent1:                 episode reward: 1.1904,                 loss: 0.2719
Episode: 24221/30000 (80.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5592s / 477.7944 s
agent0:                 episode reward: -1.1530,                 loss: nan
agent1:                 episode reward: 1.1530,                 loss: 0.2722
Episode: 24241/30000 (80.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5534s / 478.3478 s
agent0:                 episode reward: -1.1159,                 loss: nan
agent1:                 episode reward: 1.1159,                 loss: 0.2746
Episode: 24261/30000 (80.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5554s / 478.9032 s
agent0:                 episode reward: -1.1850,                 loss: nan
agent1:                 episode reward: 1.1850,                 loss: 0.2747
Episode: 24281/30000 (80.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5479s / 479.4510 s
agent0:                 episode reward: -1.1329,                 loss: nan
agent1:                 episode reward: 1.1329,                 loss: 0.2724
Episode: 24301/30000 (81.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5751s / 480.0262 s
agent0:                 episode reward: -1.0598,                 loss: nan
agent1:                 episode reward: 1.0598,                 loss: 0.2701
Episode: 24321/30000 (81.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6022s / 480.6283 s
agent0:                 episode reward: -1.0681,                 loss: nan
agent1:                 episode reward: 1.0681,                 loss: 0.2720
Episode: 24341/30000 (81.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6104s / 481.2387 s
agent0:                 episode reward: -1.0576,                 loss: nan
agent1:                 episode reward: 1.0576,                 loss: 0.2730
Episode: 24361/30000 (81.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5729s / 481.8116 s
agent0:                 episode reward: -1.0527,                 loss: nan
agent1:                 episode reward: 1.0527,                 loss: 0.2720
Episode: 24381/30000 (81.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5628s / 482.3745 s
agent0:                 episode reward: -0.9848,                 loss: nan
agent1:                 episode reward: 0.9848,                 loss: 0.2701
Episode: 24401/30000 (81.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5857s / 482.9602 s
agent0:                 episode reward: -0.9885,                 loss: nan
agent1:                 episode reward: 0.9885,                 loss: 0.2694
Episode: 24421/30000 (81.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5660s / 483.5261 s
agent0:                 episode reward: -1.0228,                 loss: nan
agent1:                 episode reward: 1.0228,                 loss: 0.2692
Episode: 24441/30000 (81.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5647s / 484.0908 s
agent0:                 episode reward: -0.8873,                 loss: nan
agent1:                 episode reward: 0.8873,                 loss: 0.2699
Episode: 24461/30000 (81.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5567s / 484.6475 s
agent0:                 episode reward: -1.1674,                 loss: nan
agent1:                 episode reward: 1.1674,                 loss: 0.2686
Episode: 24481/30000 (81.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5621s / 485.2096 s
agent0:                 episode reward: -0.9243,                 loss: nan
agent1:                 episode reward: 0.9243,                 loss: 0.2726
Episode: 24501/30000 (81.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5684s / 485.7780 s
agent0:                 episode reward: -1.0275,                 loss: nan
agent1:                 episode reward: 1.0275,                 loss: 0.2713
Episode: 24521/30000 (81.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5643s / 486.3423 s
agent0:                 episode reward: -1.0106,                 loss: nan
agent1:                 episode reward: 1.0106,                 loss: 0.2729
Episode: 24541/30000 (81.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5637s / 486.9060 s
agent0:                 episode reward: -0.9016,                 loss: nan
agent1:                 episode reward: 0.9016,                 loss: 0.2671
Episode: 24561/30000 (81.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5546s / 487.4606 s
agent0:                 episode reward: -0.8480,                 loss: nan
agent1:                 episode reward: 0.8480,                 loss: 0.2729
Episode: 24581/30000 (81.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5659s / 488.0265 s
agent0:                 episode reward: -1.1161,                 loss: nan
agent1:                 episode reward: 1.1161,                 loss: 0.2772
Episode: 24601/30000 (82.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5726s / 488.5991 s
agent0:                 episode reward: -1.2206,                 loss: nan
agent1:                 episode reward: 1.2206,                 loss: 0.2763
Episode: 24621/30000 (82.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5693s / 489.1683 s
agent0:                 episode reward: -0.9771,                 loss: nan
agent1:                 episode reward: 0.9771,                 loss: 0.2754
Episode: 24641/30000 (82.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5741s / 489.7424 s
agent0:                 episode reward: -1.0993,                 loss: nan
agent1:                 episode reward: 1.0993,                 loss: 0.2736
Episode: 24661/30000 (82.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5941s / 490.3365 s
agent0:                 episode reward: -1.3992,                 loss: nan
agent1:                 episode reward: 1.3992,                 loss: 0.2767
Episode: 24681/30000 (82.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6184s / 490.9549 s
agent0:                 episode reward: -0.9050,                 loss: nan
agent1:                 episode reward: 0.9050,                 loss: 0.2777
Episode: 24701/30000 (82.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5722s / 491.5270 s
agent0:                 episode reward: -0.6762,                 loss: nan
agent1:                 episode reward: 0.6762,                 loss: 0.2759
Episode: 24721/30000 (82.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5813s / 492.1084 s
agent0:                 episode reward: -1.0278,                 loss: nan
agent1:                 episode reward: 1.0278,                 loss: 0.2768
Episode: 24741/30000 (82.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6081s / 492.7165 s
agent0:                 episode reward: -1.2729,                 loss: nan
agent1:                 episode reward: 1.2729,                 loss: 0.2773
Episode: 24761/30000 (82.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5709s / 493.2874 s
agent0:                 episode reward: -1.0210,                 loss: nan
agent1:                 episode reward: 1.0210,                 loss: 0.2763
Episode: 24781/30000 (82.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5760s / 493.8635 s
agent0:                 episode reward: -1.3640,                 loss: nan
agent1:                 episode reward: 1.3640,                 loss: 0.2766
Episode: 24801/30000 (82.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5711s / 494.4345 s
agent0:                 episode reward: -1.0141,                 loss: nan
agent1:                 episode reward: 1.0141,                 loss: 0.2754
Episode: 24821/30000 (82.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5791s / 495.0136 s
agent0:                 episode reward: -1.0521,                 loss: nan
agent1:                 episode reward: 1.0521,                 loss: 0.2723
Episode: 24841/30000 (82.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5741s / 495.5877 s
agent0:                 episode reward: -1.1114,                 loss: nan
agent1:                 episode reward: 1.1114,                 loss: 0.2758
Episode: 24861/30000 (82.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5674s / 496.1551 s
agent0:                 episode reward: -1.0260,                 loss: nan
agent1:                 episode reward: 1.0260,                 loss: 0.2763
Episode: 24881/30000 (82.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5660s / 496.7211 s
agent0:                 episode reward: -1.0298,                 loss: nan
agent1:                 episode reward: 1.0298,                 loss: 0.2746
Episode: 24901/30000 (83.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5666s / 497.2877 s
agent0:                 episode reward: -1.1784,                 loss: nan
agent1:                 episode reward: 1.1784,                 loss: 0.2778
Episode: 24921/30000 (83.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5837s / 497.8714 s
agent0:                 episode reward: -0.7884,                 loss: nan
agent1:                 episode reward: 0.7884,                 loss: 0.2796
Episode: 24941/30000 (83.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5951s / 498.4665 s
agent0:                 episode reward: -1.1592,                 loss: nan
agent1:                 episode reward: 1.1592,                 loss: 0.2780
Episode: 24961/30000 (83.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5759s / 499.0424 s
agent0:                 episode reward: -0.9444,                 loss: nan
agent1:                 episode reward: 0.9444,                 loss: 0.2756
Episode: 24981/30000 (83.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5712s / 499.6136 s
agent0:                 episode reward: -0.9812,                 loss: nan
agent1:                 episode reward: 0.9812,                 loss: 0.2772
Episode: 25001/30000 (83.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5740s / 500.1876 s
agent0:                 episode reward: -0.7841,                 loss: nan
agent1:                 episode reward: 0.7841,                 loss: 0.2750
Episode: 25021/30000 (83.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5762s / 500.7638 s
agent0:                 episode reward: -1.1217,                 loss: nan
agent1:                 episode reward: 1.1217,                 loss: 0.2783
Episode: 25041/30000 (83.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6336s / 501.3974 s
agent0:                 episode reward: -1.0707,                 loss: nan
agent1:                 episode reward: 1.0707,                 loss: 0.2805
Episode: 25061/30000 (83.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5693s / 501.9666 s
agent0:                 episode reward: -1.2719,                 loss: nan
agent1:                 episode reward: 1.2719,                 loss: 0.2773
Episode: 25081/30000 (83.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5894s / 502.5560 s
agent0:                 episode reward: -1.0782,                 loss: nan
agent1:                 episode reward: 1.0782,                 loss: 0.2741
Episode: 25101/30000 (83.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5697s / 503.1257 s
agent0:                 episode reward: -0.8731,                 loss: nan
agent1:                 episode reward: 0.8731,                 loss: 0.2773
Episode: 25121/30000 (83.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5715s / 503.6972 s
agent0:                 episode reward: -1.1282,                 loss: nan
agent1:                 episode reward: 1.1282,                 loss: 0.2733
Episode: 25141/30000 (83.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5783s / 504.2755 s
agent0:                 episode reward: -1.1239,                 loss: nan
agent1:                 episode reward: 1.1239,                 loss: 0.2803
Episode: 25161/30000 (83.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5711s / 504.8466 s
agent0:                 episode reward: -0.8233,                 loss: nan
agent1:                 episode reward: 0.8233,                 loss: 0.2765
Episode: 25181/30000 (83.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5726s / 505.4192 s
agent0:                 episode reward: -1.3843,                 loss: nan
agent1:                 episode reward: 1.3843,                 loss: 0.2786
Episode: 25201/30000 (84.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5768s / 505.9960 s
agent0:                 episode reward: -1.2394,                 loss: nan
agent1:                 episode reward: 1.2394,                 loss: 0.2739
Episode: 25221/30000 (84.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5881s / 506.5841 s
agent0:                 episode reward: -1.1369,                 loss: nan
agent1:                 episode reward: 1.1369,                 loss: 0.2748
Episode: 25241/30000 (84.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5805s / 507.1646 s
agent0:                 episode reward: -1.2789,                 loss: nan
agent1:                 episode reward: 1.2789,                 loss: 0.2674
Episode: 25261/30000 (84.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5767s / 507.7412 s
agent0:                 episode reward: -1.0309,                 loss: nan
agent1:                 episode reward: 1.0309,                 loss: 0.2668
Episode: 25281/30000 (84.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5756s / 508.3169 s
agent0:                 episode reward: -1.3562,                 loss: nan
agent1:                 episode reward: 1.3562,                 loss: 0.2688
Episode: 25301/30000 (84.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6081s / 508.9250 s
agent0:                 episode reward: -1.3394,                 loss: nan
agent1:                 episode reward: 1.3394,                 loss: 0.2667
Episode: 25321/30000 (84.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5767s / 509.5017 s
agent0:                 episode reward: -1.3610,                 loss: nan
agent1:                 episode reward: 1.3610,                 loss: 0.2637
Episode: 25341/30000 (84.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5926s / 510.0943 s
agent0:                 episode reward: -1.0964,                 loss: nan
agent1:                 episode reward: 1.0964,                 loss: 0.2660
Episode: 25361/30000 (84.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5803s / 510.6746 s
agent0:                 episode reward: -0.9687,                 loss: nan
agent1:                 episode reward: 0.9687,                 loss: 0.2655
Episode: 25381/30000 (84.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5741s / 511.2487 s
agent0:                 episode reward: -1.1191,                 loss: nan
agent1:                 episode reward: 1.1191,                 loss: 0.2657
Episode: 25401/30000 (84.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6579s / 511.9066 s
agent0:                 episode reward: -1.0259,                 loss: nan
agent1:                 episode reward: 1.0259,                 loss: 0.2653
Episode: 25421/30000 (84.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5808s / 512.4874 s
agent0:                 episode reward: -1.1603,                 loss: nan
agent1:                 episode reward: 1.1603,                 loss: 0.2634
Episode: 25441/30000 (84.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5883s / 513.0757 s
agent0:                 episode reward: -0.8415,                 loss: nan
agent1:                 episode reward: 0.8415,                 loss: 0.2644
Episode: 25461/30000 (84.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5791s / 513.6548 s
agent0:                 episode reward: -0.9799,                 loss: nan
agent1:                 episode reward: 0.9799,                 loss: 0.2623
Episode: 25481/30000 (84.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5857s / 514.2406 s
agent0:                 episode reward: -1.1056,                 loss: nan
agent1:                 episode reward: 1.1056,                 loss: 0.2637
Episode: 25501/30000 (85.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6184s / 514.8589 s
agent0:                 episode reward: -1.2840,                 loss: nan
agent1:                 episode reward: 1.2840,                 loss: 0.2693
Episode: 25521/30000 (85.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5846s / 515.4435 s
agent0:                 episode reward: -1.2067,                 loss: nan
agent1:                 episode reward: 1.2067,                 loss: 0.2656
Episode: 25541/30000 (85.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5826s / 516.0262 s
agent0:                 episode reward: -1.1362,                 loss: nan
agent1:                 episode reward: 1.1362,                 loss: 0.2648
Episode: 25561/30000 (85.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5820s / 516.6081 s
agent0:                 episode reward: -1.1547,                 loss: nan
agent1:                 episode reward: 1.1547,                 loss: 0.2773
Episode: 25581/30000 (85.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5827s / 517.1908 s
agent0:                 episode reward: -1.1946,                 loss: nan
agent1:                 episode reward: 1.1946,                 loss: 0.2793
Episode: 25601/30000 (85.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5824s / 517.7732 s
agent0:                 episode reward: -0.9321,                 loss: nan
agent1:                 episode reward: 0.9321,                 loss: 0.2844
Episode: 25621/30000 (85.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5877s / 518.3609 s
agent0:                 episode reward: -1.1946,                 loss: nan
agent1:                 episode reward: 1.1946,                 loss: 0.2834
Episode: 25641/30000 (85.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5798s / 518.9407 s
agent0:                 episode reward: -1.0423,                 loss: nan
agent1:                 episode reward: 1.0423,                 loss: 0.2824
Episode: 25661/30000 (85.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6029s / 519.5436 s
agent0:                 episode reward: -1.1469,                 loss: nan
agent1:                 episode reward: 1.1469,                 loss: 0.2836
Episode: 25681/30000 (85.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5783s / 520.1219 s
agent0:                 episode reward: -0.7875,                 loss: nan
agent1:                 episode reward: 0.7875,                 loss: 0.2810
Episode: 25701/30000 (85.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6165s / 520.7384 s
agent0:                 episode reward: -1.2889,                 loss: nan
agent1:                 episode reward: 1.2889,                 loss: 0.2812
Episode: 25721/30000 (85.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5878s / 521.3262 s
agent0:                 episode reward: -1.4109,                 loss: nan
agent1:                 episode reward: 1.4109,                 loss: 0.2794
Episode: 25741/30000 (85.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6319s / 521.9581 s
agent0:                 episode reward: -0.7525,                 loss: nan
agent1:                 episode reward: 0.7525,                 loss: 0.2854
Episode: 25761/30000 (85.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5977s / 522.5558 s
agent0:                 episode reward: -0.9417,                 loss: nan
agent1:                 episode reward: 0.9417,                 loss: 0.2824
Episode: 25781/30000 (85.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6072s / 523.1630 s
agent0:                 episode reward: -0.9537,                 loss: nan
agent1:                 episode reward: 0.9537,                 loss: 0.2831
Episode: 25801/30000 (86.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5954s / 523.7584 s
agent0:                 episode reward: -1.2537,                 loss: nan
agent1:                 episode reward: 1.2537,                 loss: 0.2841
Episode: 25821/30000 (86.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5854s / 524.3438 s
agent0:                 episode reward: -1.0132,                 loss: nan
agent1:                 episode reward: 1.0132,                 loss: 0.2838
Episode: 25841/30000 (86.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5819s / 524.9257 s
agent0:                 episode reward: -0.9122,                 loss: nan
agent1:                 episode reward: 0.9122,                 loss: 0.2818
Episode: 25861/30000 (86.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5940s / 525.5197 s
agent0:                 episode reward: -1.0894,                 loss: nan
agent1:                 episode reward: 1.0894,                 loss: 0.2794
Episode: 25881/30000 (86.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5897s / 526.1094 s
agent0:                 episode reward: -1.0550,                 loss: nan
agent1:                 episode reward: 1.0550,                 loss: 0.2848
Episode: 25901/30000 (86.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5863s / 526.6957 s
agent0:                 episode reward: -0.7587,                 loss: nan
agent1:                 episode reward: 0.7587,                 loss: 0.2706
Episode: 25921/30000 (86.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5935s / 527.2892 s
agent0:                 episode reward: -1.4739,                 loss: nan
agent1:                 episode reward: 1.4739,                 loss: 0.2644
Episode: 25941/30000 (86.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5929s / 527.8821 s
agent0:                 episode reward: -1.1067,                 loss: nan
agent1:                 episode reward: 1.1067,                 loss: 0.2621
Episode: 25961/30000 (86.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6007s / 528.4828 s
agent0:                 episode reward: -0.8919,                 loss: nan
agent1:                 episode reward: 0.8919,                 loss: 0.2612
Episode: 25981/30000 (86.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5928s / 529.0756 s
agent0:                 episode reward: -0.9194,                 loss: nan
agent1:                 episode reward: 0.9194,                 loss: 0.2625
Episode: 26001/30000 (86.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5921s / 529.6677 s
agent0:                 episode reward: -0.9290,                 loss: nan
agent1:                 episode reward: 0.9290,                 loss: 0.2614
Episode: 26021/30000 (86.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5838s / 530.2514 s
agent0:                 episode reward: -1.0301,                 loss: nan
agent1:                 episode reward: 1.0301,                 loss: 0.2631
Episode: 26041/30000 (86.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5988s / 530.8502 s
agent0:                 episode reward: -1.1733,                 loss: nan
agent1:                 episode reward: 1.1733,                 loss: 0.2647
Episode: 26061/30000 (86.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6191s / 531.4694 s
agent0:                 episode reward: -1.0662,                 loss: nan
agent1:                 episode reward: 1.0662,                 loss: 0.2669
Episode: 26081/30000 (86.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6429s / 532.1123 s
agent0:                 episode reward: -0.7394,                 loss: nan
agent1:                 episode reward: 0.7394,                 loss: 0.2623
Episode: 26101/30000 (87.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5964s / 532.7087 s
agent0:                 episode reward: -1.1725,                 loss: nan
agent1:                 episode reward: 1.1725,                 loss: 0.2668
Episode: 26121/30000 (87.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6000s / 533.3087 s
agent0:                 episode reward: -1.0668,                 loss: nan
agent1:                 episode reward: 1.0668,                 loss: 0.2648
Episode: 26141/30000 (87.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5939s / 533.9026 s
agent0:                 episode reward: -1.1233,                 loss: nan
agent1:                 episode reward: 1.1233,                 loss: 0.2648
Episode: 26161/30000 (87.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5947s / 534.4973 s
agent0:                 episode reward: -0.8165,                 loss: nan
agent1:                 episode reward: 0.8165,                 loss: 0.2638
Episode: 26181/30000 (87.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5926s / 535.0900 s
agent0:                 episode reward: -0.8382,                 loss: nan
agent1:                 episode reward: 0.8382,                 loss: 0.2662
Episode: 26201/30000 (87.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5922s / 535.6821 s
agent0:                 episode reward: -1.0948,                 loss: nan
agent1:                 episode reward: 1.0948,                 loss: 0.2675
Episode: 26221/30000 (87.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5954s / 536.2776 s
agent0:                 episode reward: -1.4669,                 loss: nan
agent1:                 episode reward: 1.4669,                 loss: 0.2668
Episode: 26241/30000 (87.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5923s / 536.8699 s
agent0:                 episode reward: -1.1235,                 loss: nan
agent1:                 episode reward: 1.1235,                 loss: 0.2728
Episode: 26261/30000 (87.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6197s / 537.4896 s
agent0:                 episode reward: -1.0750,                 loss: nan
agent1:                 episode reward: 1.0750,                 loss: 0.2727
Episode: 26281/30000 (87.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5994s / 538.0890 s
agent0:                 episode reward: -1.0459,                 loss: nan
agent1:                 episode reward: 1.0459,                 loss: 0.2744
Episode: 26301/30000 (87.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5991s / 538.6880 s
agent0:                 episode reward: -1.2246,                 loss: nan
agent1:                 episode reward: 1.2246,                 loss: 0.2709
Episode: 26321/30000 (87.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5992s / 539.2872 s
agent0:                 episode reward: -1.1570,                 loss: nan
agent1:                 episode reward: 1.1570,                 loss: 0.2674
Episode: 26341/30000 (87.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6196s / 539.9069 s
agent0:                 episode reward: -1.0781,                 loss: nan
agent1:                 episode reward: 1.0781,                 loss: 0.2763
Episode: 26361/30000 (87.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6057s / 540.5126 s
agent0:                 episode reward: -1.1890,                 loss: nan
agent1:                 episode reward: 1.1890,                 loss: 0.2731
Episode: 26381/30000 (87.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6102s / 541.1228 s
agent0:                 episode reward: -1.1472,                 loss: nan
agent1:                 episode reward: 1.1472,                 loss: 0.2747
Episode: 26401/30000 (88.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6046s / 541.7274 s
agent0:                 episode reward: -1.3801,                 loss: nan
agent1:                 episode reward: 1.3801,                 loss: 0.2673
Episode: 26421/30000 (88.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6477s / 542.3751 s
agent0:                 episode reward: -1.1386,                 loss: nan
agent1:                 episode reward: 1.1386,                 loss: 0.2729
Episode: 26441/30000 (88.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6047s / 542.9799 s
agent0:                 episode reward: -0.9565,                 loss: nan
agent1:                 episode reward: 0.9565,                 loss: 0.2736
Episode: 26461/30000 (88.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6138s / 543.5936 s
agent0:                 episode reward: -1.2434,                 loss: nan
agent1:                 episode reward: 1.2434,                 loss: 0.2714
Episode: 26481/30000 (88.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5994s / 544.1930 s
agent0:                 episode reward: -1.2950,                 loss: nan
agent1:                 episode reward: 1.2950,                 loss: 0.2724
Episode: 26501/30000 (88.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5985s / 544.7916 s
agent0:                 episode reward: -0.9957,                 loss: nan
agent1:                 episode reward: 0.9957,                 loss: 0.2734
Episode: 26521/30000 (88.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5965s / 545.3881 s
agent0:                 episode reward: -1.0654,                 loss: nan
agent1:                 episode reward: 1.0654,                 loss: 0.2746
Episode: 26541/30000 (88.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5942s / 545.9822 s
agent0:                 episode reward: -1.2578,                 loss: nan
agent1:                 episode reward: 1.2578,                 loss: 0.2721
Episode: 26561/30000 (88.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6052s / 546.5874 s
agent0:                 episode reward: -0.7577,                 loss: nan
agent1:                 episode reward: 0.7577,                 loss: 0.2722
Episode: 26581/30000 (88.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5935s / 547.1810 s
agent0:                 episode reward: -1.0219,                 loss: nan
agent1:                 episode reward: 1.0219,                 loss: 0.2700
Episode: 26601/30000 (88.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5963s / 547.7772 s
agent0:                 episode reward: -0.9072,                 loss: nan
agent1:                 episode reward: 0.9072,                 loss: 0.2716
Episode: 26621/30000 (88.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6104s / 548.3876 s
agent0:                 episode reward: -1.0951,                 loss: nan
agent1:                 episode reward: 1.0951,                 loss: 0.2730
Episode: 26641/30000 (88.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5952s / 548.9828 s
agent0:                 episode reward: -1.1416,                 loss: nan
agent1:                 episode reward: 1.1416,                 loss: 0.2700
Episode: 26661/30000 (88.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6037s / 549.5865 s
agent0:                 episode reward: -1.2369,                 loss: nan
agent1:                 episode reward: 1.2369,                 loss: 0.2696
Episode: 26681/30000 (88.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5910s / 550.1775 s
agent0:                 episode reward: -0.9227,                 loss: nan
agent1:                 episode reward: 0.9227,                 loss: 0.2710
Episode: 26701/30000 (89.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5970s / 550.7745 s
agent0:                 episode reward: -1.0370,                 loss: nan
agent1:                 episode reward: 1.0370,                 loss: 0.2728
Episode: 26721/30000 (89.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6104s / 551.3849 s
agent0:                 episode reward: -1.3644,                 loss: nan
agent1:                 episode reward: 1.3644,                 loss: 0.2706
Episode: 26741/30000 (89.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5980s / 551.9829 s
agent0:                 episode reward: -1.1685,                 loss: nan
agent1:                 episode reward: 1.1685,                 loss: 0.2684
Episode: 26761/30000 (89.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6668s / 552.6496 s
agent0:                 episode reward: -1.1314,                 loss: nan
agent1:                 episode reward: 1.1314,                 loss: 0.2695
Episode: 26781/30000 (89.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6043s / 553.2539 s
agent0:                 episode reward: -0.9293,                 loss: nan
agent1:                 episode reward: 0.9293,                 loss: 0.2693
Episode: 26801/30000 (89.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6022s / 553.8561 s
agent0:                 episode reward: -1.1966,                 loss: nan
agent1:                 episode reward: 1.1966,                 loss: 0.2700
Episode: 26821/30000 (89.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6007s / 554.4568 s
agent0:                 episode reward: -1.0033,                 loss: nan
agent1:                 episode reward: 1.0033,                 loss: 0.2736
Episode: 26841/30000 (89.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6023s / 555.0591 s
agent0:                 episode reward: -1.5554,                 loss: nan
agent1:                 episode reward: 1.5554,                 loss: 0.2730
Episode: 26861/30000 (89.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6228s / 555.6819 s
agent0:                 episode reward: -1.0657,                 loss: nan
agent1:                 episode reward: 1.0657,                 loss: 0.2696
Episode: 26881/30000 (89.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6246s / 556.3065 s
agent0:                 episode reward: -1.0031,                 loss: nan
agent1:                 episode reward: 1.0031,                 loss: 0.2722
Episode: 26901/30000 (89.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5996s / 556.9060 s
agent0:                 episode reward: -1.2907,                 loss: nan
agent1:                 episode reward: 1.2907,                 loss: 0.2730
Episode: 26921/30000 (89.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6039s / 557.5100 s
agent0:                 episode reward: -0.9692,                 loss: nan
agent1:                 episode reward: 0.9692,                 loss: 0.2748
Episode: 26941/30000 (89.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6039s / 558.1139 s
agent0:                 episode reward: -1.0720,                 loss: nan
agent1:                 episode reward: 1.0720,                 loss: 0.2733
Episode: 26961/30000 (89.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6195s / 558.7335 s
agent0:                 episode reward: -0.9888,                 loss: nan
agent1:                 episode reward: 0.9888,                 loss: 0.2723
Episode: 26981/30000 (89.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6011s / 559.3346 s
agent0:                 episode reward: -1.3025,                 loss: nan
agent1:                 episode reward: 1.3025,                 loss: 0.2730
Episode: 27001/30000 (90.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6005s / 559.9351 s
agent0:                 episode reward: -1.2136,                 loss: nan
agent1:                 episode reward: 1.2136,                 loss: 0.2759
Episode: 27021/30000 (90.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6006s / 560.5357 s
agent0:                 episode reward: -1.3306,                 loss: nan
agent1:                 episode reward: 1.3306,                 loss: 0.2730
Episode: 27041/30000 (90.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6116s / 561.1473 s
agent0:                 episode reward: -0.9934,                 loss: nan
agent1:                 episode reward: 0.9934,                 loss: 0.2753
Episode: 27061/30000 (90.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6186s / 561.7658 s
agent0:                 episode reward: -1.1388,                 loss: nan
agent1:                 episode reward: 1.1388,                 loss: 0.2746
Episode: 27081/30000 (90.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6643s / 562.4301 s
agent0:                 episode reward: -1.1133,                 loss: nan
agent1:                 episode reward: 1.1133,                 loss: 0.2724
Episode: 27101/30000 (90.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6610s / 563.0911 s
agent0:                 episode reward: -1.0349,                 loss: nan
agent1:                 episode reward: 1.0349,                 loss: 0.2757
Episode: 27121/30000 (90.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6101s / 563.7013 s
agent0:                 episode reward: -1.4703,                 loss: nan
agent1:                 episode reward: 1.4703,                 loss: 0.2751
Episode: 27141/30000 (90.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6028s / 564.3041 s
agent0:                 episode reward: -1.1622,                 loss: nan
agent1:                 episode reward: 1.1622,                 loss: 0.2763
Episode: 27161/30000 (90.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6639s / 564.9680 s
agent0:                 episode reward: -1.0517,                 loss: nan
agent1:                 episode reward: 1.0517,                 loss: 0.2764
Episode: 27181/30000 (90.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6077s / 565.5758 s
agent0:                 episode reward: -0.8819,                 loss: nan
agent1:                 episode reward: 0.8819,                 loss: 0.2758
Episode: 27201/30000 (90.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6111s / 566.1869 s
agent0:                 episode reward: -1.0541,                 loss: nan
agent1:                 episode reward: 1.0541,                 loss: 0.2775
Episode: 27221/30000 (90.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6136s / 566.8004 s
agent0:                 episode reward: -1.2452,                 loss: nan
agent1:                 episode reward: 1.2452,                 loss: 0.2731
Episode: 27241/30000 (90.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6074s / 567.4078 s
agent0:                 episode reward: -1.0996,                 loss: nan
agent1:                 episode reward: 1.0996,                 loss: 0.2659
Episode: 27261/30000 (90.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6033s / 568.0111 s
agent0:                 episode reward: -1.0649,                 loss: nan
agent1:                 episode reward: 1.0649,                 loss: 0.2685
Episode: 27281/30000 (90.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6508s / 568.6619 s
agent0:                 episode reward: -1.1427,                 loss: nan
agent1:                 episode reward: 1.1427,                 loss: 0.2675
Episode: 27301/30000 (91.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6122s / 569.2741 s
agent0:                 episode reward: -1.2914,                 loss: nan
agent1:                 episode reward: 1.2914,                 loss: 0.2635
Episode: 27321/30000 (91.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6207s / 569.8948 s
agent0:                 episode reward: -1.1906,                 loss: nan
agent1:                 episode reward: 1.1906,                 loss: 0.2697
Episode: 27341/30000 (91.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6316s / 570.5264 s
agent0:                 episode reward: -1.2594,                 loss: nan
agent1:                 episode reward: 1.2594,                 loss: 0.2703
Episode: 27361/30000 (91.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6417s / 571.1682 s
agent0:                 episode reward: -1.0376,                 loss: nan
agent1:                 episode reward: 1.0376,                 loss: 0.2704
Episode: 27381/30000 (91.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6130s / 571.7812 s
agent0:                 episode reward: -1.4850,                 loss: nan
agent1:                 episode reward: 1.4850,                 loss: 0.2694
Episode: 27401/30000 (91.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6127s / 572.3939 s
agent0:                 episode reward: -0.7499,                 loss: nan
agent1:                 episode reward: 0.7499,                 loss: 0.2701
Episode: 27421/30000 (91.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6684s / 573.0623 s
agent0:                 episode reward: -1.3338,                 loss: nan
agent1:                 episode reward: 1.3338,                 loss: 0.2666
Episode: 27441/30000 (91.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6268s / 573.6891 s
agent0:                 episode reward: -0.8115,                 loss: nan
agent1:                 episode reward: 0.8115,                 loss: 0.2644
Episode: 27461/30000 (91.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6170s / 574.3061 s
agent0:                 episode reward: -1.0055,                 loss: nan
agent1:                 episode reward: 1.0055,                 loss: 0.2680
Episode: 27481/30000 (91.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6093s / 574.9154 s
agent0:                 episode reward: -1.0862,                 loss: nan
agent1:                 episode reward: 1.0862,                 loss: 0.2667
Episode: 27501/30000 (91.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6424s / 575.5578 s
agent0:                 episode reward: -1.1663,                 loss: nan
agent1:                 episode reward: 1.1663,                 loss: 0.2670
Episode: 27521/30000 (91.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6115s / 576.1693 s
agent0:                 episode reward: -1.0408,                 loss: nan
agent1:                 episode reward: 1.0408,                 loss: 0.2680
Episode: 27541/30000 (91.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6340s / 576.8033 s
agent0:                 episode reward: -0.9593,                 loss: nan
agent1:                 episode reward: 0.9593,                 loss: 0.2651
Episode: 27561/30000 (91.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6145s / 577.4178 s
agent0:                 episode reward: -0.7904,                 loss: nan
agent1:                 episode reward: 0.7904,                 loss: 0.2732
Episode: 27581/30000 (91.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6181s / 578.0358 s
agent0:                 episode reward: -1.1524,                 loss: nan
agent1:                 episode reward: 1.1524,                 loss: 0.2720
Episode: 27601/30000 (92.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6133s / 578.6492 s
agent0:                 episode reward: -1.2612,                 loss: nan
agent1:                 episode reward: 1.2612,                 loss: 0.2734
Episode: 27621/30000 (92.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6134s / 579.2626 s
agent0:                 episode reward: -1.1506,                 loss: nan
agent1:                 episode reward: 1.1506,                 loss: 0.2711
Episode: 27641/30000 (92.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6311s / 579.8937 s
agent0:                 episode reward: -1.6254,                 loss: nan
agent1:                 episode reward: 1.6254,                 loss: 0.2713
Episode: 27661/30000 (92.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6166s / 580.5102 s
agent0:                 episode reward: -1.1150,                 loss: nan
agent1:                 episode reward: 1.1150,                 loss: 0.2738
Episode: 27681/30000 (92.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6393s / 581.1495 s
agent0:                 episode reward: -1.1409,                 loss: nan
agent1:                 episode reward: 1.1409,                 loss: 0.2686
Episode: 27701/30000 (92.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6336s / 581.7831 s
agent0:                 episode reward: -0.9401,                 loss: nan
agent1:                 episode reward: 0.9401,                 loss: 0.2732
Episode: 27721/30000 (92.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6154s / 582.3985 s
agent0:                 episode reward: -1.3907,                 loss: nan
agent1:                 episode reward: 1.3907,                 loss: 0.2724
Episode: 27741/30000 (92.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6218s / 583.0202 s
agent0:                 episode reward: -1.2740,                 loss: nan
agent1:                 episode reward: 1.2740,                 loss: 0.2733
Episode: 27761/30000 (92.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6804s / 583.7006 s
agent0:                 episode reward: -1.0780,                 loss: nan
agent1:                 episode reward: 1.0780,                 loss: 0.2698
Episode: 27781/30000 (92.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6183s / 584.3190 s
agent0:                 episode reward: -0.9514,                 loss: nan
agent1:                 episode reward: 0.9514,                 loss: 0.2711
Episode: 27801/30000 (92.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6252s / 584.9442 s
agent0:                 episode reward: -0.6841,                 loss: nan
agent1:                 episode reward: 0.6841,                 loss: 0.2705
Episode: 27821/30000 (92.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6255s / 585.5697 s
agent0:                 episode reward: -1.1665,                 loss: nan
agent1:                 episode reward: 1.1665,                 loss: 0.2683
Episode: 27841/30000 (92.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6184s / 586.1881 s
agent0:                 episode reward: -0.9360,                 loss: nan
agent1:                 episode reward: 0.9360,                 loss: 0.2703
Episode: 27861/30000 (92.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6166s / 586.8047 s
agent0:                 episode reward: -0.8559,                 loss: nan
agent1:                 episode reward: 0.8559,                 loss: 0.2740
Episode: 27881/30000 (92.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6277s / 587.4324 s
agent0:                 episode reward: -0.9511,                 loss: nan
agent1:                 episode reward: 0.9511,                 loss: 0.2744
Episode: 27901/30000 (93.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6220s / 588.0545 s
agent0:                 episode reward: -1.3242,                 loss: nan
agent1:                 episode reward: 1.3242,                 loss: 0.2821
Episode: 27921/30000 (93.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6312s / 588.6856 s
agent0:                 episode reward: -0.9130,                 loss: nan
agent1:                 episode reward: 0.9130,                 loss: 0.2782
Episode: 27941/30000 (93.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6163s / 589.3020 s
agent0:                 episode reward: -0.8844,                 loss: nan
agent1:                 episode reward: 0.8844,                 loss: 0.2814
Episode: 27961/30000 (93.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6396s / 589.9416 s
agent0:                 episode reward: -0.8686,                 loss: nan
agent1:                 episode reward: 0.8686,                 loss: 0.2805
Episode: 27981/30000 (93.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6200s / 590.5616 s
agent0:                 episode reward: -1.0944,                 loss: nan
agent1:                 episode reward: 1.0944,                 loss: 0.2793
Episode: 28001/30000 (93.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6291s / 591.1906 s
agent0:                 episode reward: -0.8707,                 loss: nan
agent1:                 episode reward: 0.8707,                 loss: 0.2786
Episode: 28021/30000 (93.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6315s / 591.8221 s
agent0:                 episode reward: -0.9160,                 loss: nan
agent1:                 episode reward: 0.9160,                 loss: 0.2792
Episode: 28041/30000 (93.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6256s / 592.4477 s
agent0:                 episode reward: -1.2945,                 loss: nan
agent1:                 episode reward: 1.2945,                 loss: 0.2777
Episode: 28061/30000 (93.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6225s / 593.0702 s
agent0:                 episode reward: -1.0797,                 loss: nan
agent1:                 episode reward: 1.0797,                 loss: 0.2784
Episode: 28081/30000 (93.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6808s / 593.7510 s
agent0:                 episode reward: -1.1418,                 loss: nan
agent1:                 episode reward: 1.1418,                 loss: 0.2794
Episode: 28101/30000 (93.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6309s / 594.3819 s
agent0:                 episode reward: -0.9931,                 loss: nan
agent1:                 episode reward: 0.9931,                 loss: 0.2821
Episode: 28121/30000 (93.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6494s / 595.0313 s
agent0:                 episode reward: -1.1181,                 loss: nan
agent1:                 episode reward: 1.1181,                 loss: 0.2789
Episode: 28141/30000 (93.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6285s / 595.6598 s
agent0:                 episode reward: -1.0833,                 loss: nan
agent1:                 episode reward: 1.0833,                 loss: 0.2789
Episode: 28161/30000 (93.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6500s / 596.3098 s
agent0:                 episode reward: -0.9660,                 loss: nan
agent1:                 episode reward: 0.9660,                 loss: 0.2790
Episode: 28181/30000 (93.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6230s / 596.9328 s
agent0:                 episode reward: -1.1642,                 loss: nan
agent1:                 episode reward: 1.1642,                 loss: 0.2803
Episode: 28201/30000 (94.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6356s / 597.5684 s
agent0:                 episode reward: -1.0855,                 loss: nan
agent1:                 episode reward: 1.0855,                 loss: 0.2810
Episode: 28221/30000 (94.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6526s / 598.2210 s
agent0:                 episode reward: -1.0513,                 loss: nan
agent1:                 episode reward: 1.0513,                 loss: 0.2748
Episode: 28241/30000 (94.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6291s / 598.8501 s
agent0:                 episode reward: -1.1618,                 loss: nan
agent1:                 episode reward: 1.1618,                 loss: 0.2675
Episode: 28261/30000 (94.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6265s / 599.4766 s
agent0:                 episode reward: -1.0498,                 loss: nan
agent1:                 episode reward: 1.0498,                 loss: 0.2678
Episode: 28281/30000 (94.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6246s / 600.1012 s
agent0:                 episode reward: -1.1269,                 loss: nan
agent1:                 episode reward: 1.1269,                 loss: 0.2686
Episode: 28301/30000 (94.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6319s / 600.7331 s
agent0:                 episode reward: -1.1349,                 loss: nan
agent1:                 episode reward: 1.1349,                 loss: 0.2698
Episode: 28321/30000 (94.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6276s / 601.3607 s
agent0:                 episode reward: -0.9808,                 loss: nan
agent1:                 episode reward: 0.9808,                 loss: 0.2639
Episode: 28341/30000 (94.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6329s / 601.9936 s
agent0:                 episode reward: -1.0452,                 loss: nan
agent1:                 episode reward: 1.0452,                 loss: 0.2668
Episode: 28361/30000 (94.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6298s / 602.6234 s
agent0:                 episode reward: -1.3010,                 loss: nan
agent1:                 episode reward: 1.3010,                 loss: 0.2668
Episode: 28381/30000 (94.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6227s / 603.2461 s
agent0:                 episode reward: -1.1734,                 loss: nan
agent1:                 episode reward: 1.1734,                 loss: 0.2650
Episode: 28401/30000 (94.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6927s / 603.9388 s
agent0:                 episode reward: -1.0507,                 loss: nan
agent1:                 episode reward: 1.0507,                 loss: 0.2645
Episode: 28421/30000 (94.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6312s / 604.5700 s
agent0:                 episode reward: -0.8711,                 loss: nan
agent1:                 episode reward: 0.8711,                 loss: 0.2660
Episode: 28441/30000 (94.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6202s / 605.1902 s
agent0:                 episode reward: -1.1880,                 loss: nan
agent1:                 episode reward: 1.1880,                 loss: 0.2664
Episode: 28461/30000 (94.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6351s / 605.8253 s
agent0:                 episode reward: -0.9246,                 loss: nan
agent1:                 episode reward: 0.9246,                 loss: 0.2682
Episode: 28481/30000 (94.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6590s / 606.4843 s
agent0:                 episode reward: -1.0894,                 loss: nan
agent1:                 episode reward: 1.0894,                 loss: 0.2662
Episode: 28501/30000 (95.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6332s / 607.1174 s
agent0:                 episode reward: -1.1239,                 loss: nan
agent1:                 episode reward: 1.1239,                 loss: 0.2664
Episode: 28521/30000 (95.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6356s / 607.7530 s
agent0:                 episode reward: -1.3083,                 loss: nan
agent1:                 episode reward: 1.3083,                 loss: 0.2671
Episode: 28541/30000 (95.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6375s / 608.3906 s
agent0:                 episode reward: -1.2908,                 loss: nan
agent1:                 episode reward: 1.2908,                 loss: 0.2656
Episode: 28561/30000 (95.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6280s / 609.0185 s
agent0:                 episode reward: -1.2534,                 loss: nan
agent1:                 episode reward: 1.2534,                 loss: 0.2750
Episode: 28581/30000 (95.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6550s / 609.6735 s
agent0:                 episode reward: -0.8494,                 loss: nan
agent1:                 episode reward: 0.8494,                 loss: 0.2781
Episode: 28601/30000 (95.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6320s / 610.3055 s
agent0:                 episode reward: -1.4057,                 loss: nan
agent1:                 episode reward: 1.4057,                 loss: 0.2750
Episode: 28621/30000 (95.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6383s / 610.9438 s
agent0:                 episode reward: -1.0319,                 loss: nan
agent1:                 episode reward: 1.0319,                 loss: 0.2765
Episode: 28641/30000 (95.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6365s / 611.5802 s
agent0:                 episode reward: -0.9331,                 loss: nan
agent1:                 episode reward: 0.9331,                 loss: 0.2768
Episode: 28661/30000 (95.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6402s / 612.2204 s
agent0:                 episode reward: -0.9307,                 loss: nan
agent1:                 episode reward: 0.9307,                 loss: 0.2732
Episode: 28681/30000 (95.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6389s / 612.8593 s
agent0:                 episode reward: -1.1101,                 loss: nan
agent1:                 episode reward: 1.1101,                 loss: 0.2750
Episode: 28701/30000 (95.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6412s / 613.5004 s
agent0:                 episode reward: -1.0708,                 loss: nan
agent1:                 episode reward: 1.0708,                 loss: 0.2791
Episode: 28721/30000 (95.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6913s / 614.1917 s
agent0:                 episode reward: -1.1379,                 loss: nan
agent1:                 episode reward: 1.1379,                 loss: 0.2755
Episode: 28741/30000 (95.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6565s / 614.8482 s
agent0:                 episode reward: -0.9372,                 loss: nan
agent1:                 episode reward: 0.9372,                 loss: 0.2785
Episode: 28761/30000 (95.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6450s / 615.4933 s
agent0:                 episode reward: -1.0583,                 loss: nan
agent1:                 episode reward: 1.0583,                 loss: 0.2746
Episode: 28781/30000 (95.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6311s / 616.1244 s
agent0:                 episode reward: -1.1302,                 loss: nan
agent1:                 episode reward: 1.1302,                 loss: 0.2790
Episode: 28801/30000 (96.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6382s / 616.7625 s
agent0:                 episode reward: -1.1100,                 loss: nan
agent1:                 episode reward: 1.1100,                 loss: 0.2746
Episode: 28821/30000 (96.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6357s / 617.3983 s
agent0:                 episode reward: -1.2079,                 loss: nan
agent1:                 episode reward: 1.2079,                 loss: 0.2758
Episode: 28841/30000 (96.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6351s / 618.0334 s
agent0:                 episode reward: -0.9925,                 loss: nan
agent1:                 episode reward: 0.9925,                 loss: 0.2766
Episode: 28861/30000 (96.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6654s / 618.6987 s
agent0:                 episode reward: -1.2848,                 loss: nan
agent1:                 episode reward: 1.2848,                 loss: 0.2766
Episode: 28881/30000 (96.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6348s / 619.3335 s
agent0:                 episode reward: -1.0765,                 loss: nan
agent1:                 episode reward: 1.0765,                 loss: 0.2751
Episode: 28901/30000 (96.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6351s / 619.9686 s
agent0:                 episode reward: -1.1187,                 loss: nan
agent1:                 episode reward: 1.1187,                 loss: 0.2691
Episode: 28921/30000 (96.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6344s / 620.6030 s
agent0:                 episode reward: -1.1236,                 loss: nan
agent1:                 episode reward: 1.1236,                 loss: 0.2701
Episode: 28941/30000 (96.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6388s / 621.2418 s
agent0:                 episode reward: -0.9145,                 loss: nan
agent1:                 episode reward: 0.9145,                 loss: 0.2689
Episode: 28961/30000 (96.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6483s / 621.8901 s
agent0:                 episode reward: -1.1878,                 loss: nan
agent1:                 episode reward: 1.1878,                 loss: 0.2675
Episode: 28981/30000 (96.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6579s / 622.5480 s
agent0:                 episode reward: -1.3972,                 loss: nan
agent1:                 episode reward: 1.3972,                 loss: 0.2694
Episode: 29001/30000 (96.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6432s / 623.1912 s
agent0:                 episode reward: -1.0715,                 loss: nan
agent1:                 episode reward: 1.0715,                 loss: 0.2707
Episode: 29021/30000 (96.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6910s / 623.8822 s
agent0:                 episode reward: -0.9371,                 loss: nan
agent1:                 episode reward: 0.9371,                 loss: 0.2695
Episode: 29041/30000 (96.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7184s / 624.6006 s
agent0:                 episode reward: -1.1304,                 loss: nan
agent1:                 episode reward: 1.1304,                 loss: 0.2691
Episode: 29061/30000 (96.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6479s / 625.2485 s
agent0:                 episode reward: -1.0338,                 loss: nan
agent1:                 episode reward: 1.0338,                 loss: 0.2668
Episode: 29081/30000 (96.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6488s / 625.8972 s
agent0:                 episode reward: -1.3677,                 loss: nan
agent1:                 episode reward: 1.3677,                 loss: 0.2674
Episode: 29101/30000 (97.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6357s / 626.5329 s
agent0:                 episode reward: -1.0584,                 loss: nan
agent1:                 episode reward: 1.0584,                 loss: 0.2674
Episode: 29121/30000 (97.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6401s / 627.1730 s
agent0:                 episode reward: -1.2236,                 loss: nan
agent1:                 episode reward: 1.2236,                 loss: 0.2665
Episode: 29141/30000 (97.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6461s / 627.8191 s
agent0:                 episode reward: -1.4215,                 loss: nan
agent1:                 episode reward: 1.4215,                 loss: 0.2687
Episode: 29161/30000 (97.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6568s / 628.4759 s
agent0:                 episode reward: -0.9605,                 loss: nan
agent1:                 episode reward: 0.9605,                 loss: 0.2695
Episode: 29181/30000 (97.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6476s / 629.1235 s
agent0:                 episode reward: -0.9937,                 loss: nan
agent1:                 episode reward: 0.9937,                 loss: 0.2695
Episode: 29201/30000 (97.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6320s / 629.7555 s
agent0:                 episode reward: -1.2369,                 loss: nan
agent1:                 episode reward: 1.2369,                 loss: 0.2642
Episode: 29221/30000 (97.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6376s / 630.3931 s
agent0:                 episode reward: -1.4149,                 loss: nan
agent1:                 episode reward: 1.4149,                 loss: 0.2727
Episode: 29241/30000 (97.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6946s / 631.0877 s
agent0:                 episode reward: -0.9556,                 loss: nan
agent1:                 episode reward: 0.9556,                 loss: 0.2766
Episode: 29261/30000 (97.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6568s / 631.7445 s
agent0:                 episode reward: -1.0628,                 loss: nan
agent1:                 episode reward: 1.0628,                 loss: 0.2778
Episode: 29281/30000 (97.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6514s / 632.3959 s
agent0:                 episode reward: -1.1333,                 loss: nan
agent1:                 episode reward: 1.1333,                 loss: 0.2777
Episode: 29301/30000 (97.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6441s / 633.0401 s
agent0:                 episode reward: -1.1544,                 loss: nan
agent1:                 episode reward: 1.1544,                 loss: 0.2775
Episode: 29321/30000 (97.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6521s / 633.6922 s
agent0:                 episode reward: -1.3742,                 loss: nan
agent1:                 episode reward: 1.3742,                 loss: 0.2761
Episode: 29341/30000 (97.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6602s / 634.3525 s
agent0:                 episode reward: -1.1736,                 loss: nan
agent1:                 episode reward: 1.1736,                 loss: 0.2755
Episode: 29361/30000 (97.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6848s / 635.0372 s
agent0:                 episode reward: -1.3197,                 loss: nan
agent1:                 episode reward: 1.3197,                 loss: 0.2748
Episode: 29381/30000 (97.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6493s / 635.6865 s
agent0:                 episode reward: -1.2171,                 loss: nan
agent1:                 episode reward: 1.2171,                 loss: 0.2767
Episode: 29401/30000 (98.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6457s / 636.3322 s
agent0:                 episode reward: -1.1631,                 loss: nan
agent1:                 episode reward: 1.1631,                 loss: 0.2819
Episode: 29421/30000 (98.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6815s / 637.0138 s
agent0:                 episode reward: -1.2447,                 loss: nan
agent1:                 episode reward: 1.2447,                 loss: 0.2776
Episode: 29441/30000 (98.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6481s / 637.6619 s
agent0:                 episode reward: -1.1866,                 loss: nan
agent1:                 episode reward: 1.1866,                 loss: 0.2784
Episode: 29461/30000 (98.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6435s / 638.3054 s
agent0:                 episode reward: -1.2660,                 loss: nan
agent1:                 episode reward: 1.2660,                 loss: 0.2760
Episode: 29481/30000 (98.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6464s / 638.9518 s
agent0:                 episode reward: -0.8524,                 loss: nan
agent1:                 episode reward: 0.8524,                 loss: 0.2814
Episode: 29501/30000 (98.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6647s / 639.6165 s
agent0:                 episode reward: -0.9924,                 loss: nan
agent1:                 episode reward: 0.9924,                 loss: 0.2782
Episode: 29521/30000 (98.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6529s / 640.2694 s
agent0:                 episode reward: -0.7266,                 loss: nan
agent1:                 episode reward: 0.7266,                 loss: 0.2779
Episode: 29541/30000 (98.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6464s / 640.9158 s
agent0:                 episode reward: -0.8034,                 loss: nan
agent1:                 episode reward: 0.8034,                 loss: 0.2751
Episode: 29561/30000 (98.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6494s / 641.5652 s
agent0:                 episode reward: -1.0695,                 loss: nan
agent1:                 episode reward: 1.0695,                 loss: 0.2774
Episode: 29581/30000 (98.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6632s / 642.2284 s
agent0:                 episode reward: -1.4505,                 loss: nan
agent1:                 episode reward: 1.4505,                 loss: 0.2801
Episode: 29601/30000 (98.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6620s / 642.8903 s
agent0:                 episode reward: -0.9776,                 loss: nan
agent1:                 episode reward: 0.9776,                 loss: 0.2811
Episode: 29621/30000 (98.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6471s / 643.5374 s
agent0:                 episode reward: -0.9053,                 loss: nan
agent1:                 episode reward: 0.9053,                 loss: 0.2775
Episode: 29641/30000 (98.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6487s / 644.1861 s
agent0:                 episode reward: -1.2408,                 loss: nan
agent1:                 episode reward: 1.2408,                 loss: 0.2788
Episode: 29661/30000 (98.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7388s / 644.9249 s/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

agent0:                 episode reward: -1.3376,                 loss: nan
agent1:                 episode reward: 1.3376,                 loss: 0.2787
Episode: 29681/30000 (98.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6538s / 645.5788 s
agent0:                 episode reward: -1.0624,                 loss: nan
agent1:                 episode reward: 1.0624,                 loss: 0.2785
Episode: 29701/30000 (99.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6565s / 646.2353 s
agent0:                 episode reward: -1.5213,                 loss: nan
agent1:                 episode reward: 1.5213,                 loss: 0.2787
Episode: 29721/30000 (99.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6559s / 646.8912 s
agent0:                 episode reward: -1.2628,                 loss: nan
agent1:                 episode reward: 1.2628,                 loss: 0.2794
Episode: 29741/30000 (99.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6692s / 647.5604 s
agent0:                 episode reward: -1.3885,                 loss: nan
agent1:                 episode reward: 1.3885,                 loss: 0.2787
Episode: 29761/30000 (99.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6529s / 648.2132 s
agent0:                 episode reward: -1.1871,                 loss: nan
agent1:                 episode reward: 1.1871,                 loss: 0.2766
Episode: 29781/30000 (99.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6597s / 648.8730 s
agent0:                 episode reward: -1.3064,                 loss: nan
agent1:                 episode reward: 1.3064,                 loss: 0.2805
Episode: 29801/30000 (99.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6596s / 649.5326 s
agent0:                 episode reward: -0.9117,                 loss: nan
agent1:                 episode reward: 0.9117,                 loss: 0.2769
Episode: 29821/30000 (99.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6505s / 650.1831 s
agent0:                 episode reward: -0.9309,                 loss: nan
agent1:                 episode reward: 0.9309,                 loss: 0.2804
Episode: 29841/30000 (99.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6500s / 650.8331 s
agent0:                 episode reward: -0.9394,                 loss: nan
agent1:                 episode reward: 0.9394,                 loss: 0.2775
Episode: 29861/30000 (99.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6568s / 651.4899 s
agent0:                 episode reward: -1.1555,                 loss: nan
agent1:                 episode reward: 1.1555,                 loss: 0.2787
Episode: 29881/30000 (99.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6665s / 652.1564 s
agent0:                 episode reward: -1.1895,                 loss: nan
agent1:                 episode reward: 1.1895,                 loss: 0.2784
Episode: 29901/30000 (99.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6549s / 652.8113 s
agent0:                 episode reward: -1.3294,                 loss: nan
agent1:                 episode reward: 1.3294,                 loss: 0.2783
Episode: 29921/30000 (99.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6600s / 653.4713 s
agent0:                 episode reward: -1.0233,                 loss: nan
agent1:                 episode reward: 1.0233,                 loss: 0.2748
Episode: 29941/30000 (99.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6490s / 654.1202 s
agent0:                 episode reward: -0.9189,                 loss: nan
agent1:                 episode reward: 0.9189,                 loss: 0.2748
Episode: 29961/30000 (99.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6536s / 654.7739 s
agent0:                 episode reward: -1.2026,                 loss: nan
agent1:                 episode reward: 1.2026,                 loss: 0.2755
Episode: 29981/30000 (99.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7386s / 655.5124 s
agent0:                 episode reward: -0.8414,                 loss: nan
agent1:                 episode reward: 0.8414,                 loss: 0.2775
