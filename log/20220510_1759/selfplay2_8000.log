2022-05-10 18:31:12.424547: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia:/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia
2022-05-10 18:31:12.424643: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia:/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia
2022-05-10 18:31:12.424650: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
pygame 2.0.1 (SDL 2.0.14, Python 3.6.13)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 33.0, (1,), float32) action space: Discrete(3)
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7ff8d382c710>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=32, bias=True)
      (3): ReLU()
      (4): Linear(in_features=32, out_features=32, bias=True)
      (5): ReLU()
      (6): Linear(in_features=32, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=32, bias=True)
      (3): ReLU()
      (4): Linear(in_features=32, out_features=32, bias=True)
      (5): ReLU()
      (6): Linear(in_features=32, out_features=3, bias=True)
    )
  )
)
Error: no exploited model index given!
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  data/model/20220510161908/mdp_arbitrary_mdp_selfplay2/8000_0
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': 1, 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 1.0, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 640, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-3', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220510161908/mdp_arbitrary_mdp_selfplay2/8000_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 1000, 'net_architecture': {'hidden_dim_list': [32, 32, 32], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'selfplay2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'selfplay_score_delta': 1.5, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'against_baseline': False}
Save models to : /home/quantumiracle/research/MARS/data/model/20220510161908_exploit_8000/mdp_arbitrary_mdp_selfplay2. 
 Save logs to: /home/quantumiracle/research/MARS/data/log/20220510161908_exploit_8000/mdp_arbitrary_mdp_selfplay2.
Episode: 1/10000 (0.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8154s / 0.8154 s
agent0:                 episode reward: 0.8637,                 loss: nan
agent1:                 episode reward: -0.8637,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.0646s / 0.8800 s
agent0:                 episode reward: 1.5339,                 loss: nan
agent1:                 episode reward: -1.5339,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.0684s / 0.9484 s
agent0:                 episode reward: 1.3075,                 loss: nan
agent1:                 episode reward: -1.3075,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.0714s / 1.0198 s
agent0:                 episode reward: 0.9816,                 loss: nan
agent1:                 episode reward: -0.9816,                 loss: nan
Episode: 81/10000 (0.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5824s / 1.6021 s
agent0:                 episode reward: 0.9751,                 loss: nan
agent1:                 episode reward: -0.9751,                 loss: 0.4174
Episode: 101/10000 (1.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6794s / 2.2815 s
agent0:                 episode reward: -0.5848,                 loss: nan
agent1:                 episode reward: 0.5848,                 loss: 0.4090
Episode: 121/10000 (1.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6912s / 2.9727 s
agent0:                 episode reward: 1.3926,                 loss: nan
agent1:                 episode reward: -1.3926,                 loss: 0.4039
Episode: 141/10000 (1.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6891s / 3.6619 s
agent0:                 episode reward: 1.2497,                 loss: nan
agent1:                 episode reward: -1.2497,                 loss: 0.4021
Episode: 161/10000 (1.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6873s / 4.3492 s
agent0:                 episode reward: 1.3774,                 loss: nan
agent1:                 episode reward: -1.3774,                 loss: 0.3957
Episode: 181/10000 (1.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7192s / 5.0684 s
agent0:                 episode reward: 0.5881,                 loss: nan
agent1:                 episode reward: -0.5881,                 loss: 0.3984
Episode: 201/10000 (2.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6881s / 5.7565 s
agent0:                 episode reward: 0.7390,                 loss: nan
agent1:                 episode reward: -0.7390,                 loss: 0.4000
Episode: 221/10000 (2.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7387s / 6.4951 s
agent0:                 episode reward: 1.4753,                 loss: nan
agent1:                 episode reward: -1.4753,                 loss: 0.3984
Episode: 241/10000 (2.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7170s / 7.2121 s
agent0:                 episode reward: 1.0500,                 loss: nan
agent1:                 episode reward: -1.0500,                 loss: 0.3968
Episode: 261/10000 (2.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7064s / 7.9185 s
agent0:                 episode reward: 0.5663,                 loss: nan
agent1:                 episode reward: -0.5663,                 loss: 0.3977
Episode: 281/10000 (2.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7137s / 8.6322 s
agent0:                 episode reward: 0.9163,                 loss: nan
agent1:                 episode reward: -0.9163,                 loss: 0.3710
Episode: 301/10000 (3.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6990s / 9.3312 s
agent0:                 episode reward: 0.5460,                 loss: nan
agent1:                 episode reward: -0.5460,                 loss: 0.3664
Episode: 321/10000 (3.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7063s / 10.0375 s
agent0:                 episode reward: 0.0646,                 loss: nan
agent1:                 episode reward: -0.0646,                 loss: 0.3666
Episode: 341/10000 (3.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7029s / 10.7403 s
agent0:                 episode reward: 1.0114,                 loss: nan
agent1:                 episode reward: -1.0114,                 loss: 0.3664
Episode: 361/10000 (3.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7052s / 11.4456 s
agent0:                 episode reward: 0.3035,                 loss: nan
agent1:                 episode reward: -0.3035,                 loss: 0.3673
Episode: 381/10000 (3.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7131s / 12.1587 s
agent0:                 episode reward: 1.0116,                 loss: nan
agent1:                 episode reward: -1.0116,                 loss: 0.3560
Episode: 401/10000 (4.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7129s / 12.8716 s
agent0:                 episode reward: 0.6601,                 loss: nan
agent1:                 episode reward: -0.6601,                 loss: 0.3529
Episode: 421/10000 (4.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7199s / 13.5915 s
agent0:                 episode reward: 0.9137,                 loss: nan
agent1:                 episode reward: -0.9137,                 loss: 0.3548
Episode: 441/10000 (4.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7318s / 14.3233 s
agent0:                 episode reward: 0.4291,                 loss: nan
agent1:                 episode reward: -0.4291,                 loss: 0.3550
Episode: 461/10000 (4.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7323s / 15.0556 s
agent0:                 episode reward: 0.4465,                 loss: nan
agent1:                 episode reward: -0.4465,                 loss: 0.3526
Episode: 481/10000 (4.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7494s / 15.8050 s
agent0:                 episode reward: 0.7247,                 loss: nan
agent1:                 episode reward: -0.7247,                 loss: 0.3352
Episode: 501/10000 (5.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7617s / 16.5667 s
agent0:                 episode reward: 0.7720,                 loss: nan
agent1:                 episode reward: -0.7720,                 loss: 0.3349
Episode: 521/10000 (5.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7850s / 17.3517 s
agent0:                 episode reward: 0.8211,                 loss: nan
agent1:                 episode reward: -0.8211,                 loss: 0.3340
Episode: 541/10000 (5.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7337s / 18.0854 s
agent0:                 episode reward: 1.4071,                 loss: nan
agent1:                 episode reward: -1.4071,                 loss: 0.3316
Episode: 561/10000 (5.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7770s / 18.8624 s
agent0:                 episode reward: 0.6951,                 loss: nan
agent1:                 episode reward: -0.6951,                 loss: 0.3338
Episode: 581/10000 (5.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7379s / 19.6003 s
agent0:                 episode reward: 1.0475,                 loss: nan
agent1:                 episode reward: -1.0475,                 loss: 0.3369
Episode: 601/10000 (6.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7528s / 20.3531 s
agent0:                 episode reward: 0.5214,                 loss: nan
agent1:                 episode reward: -0.5214,                 loss: 0.3366
Episode: 621/10000 (6.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7414s / 21.0945 s
agent0:                 episode reward: 1.2229,                 loss: nan
agent1:                 episode reward: -1.2229,                 loss: 0.3364
Episode: 641/10000 (6.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7477s / 21.8422 s
agent0:                 episode reward: 0.7498,                 loss: nan
agent1:                 episode reward: -0.7498,                 loss: 0.3361
Episode: 661/10000 (6.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7507s / 22.5929 s
agent0:                 episode reward: 1.1110,                 loss: nan
agent1:                 episode reward: -1.1110,                 loss: 0.3340
Episode: 681/10000 (6.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7619s / 23.3548 s
agent0:                 episode reward: 1.2522,                 loss: nan
agent1:                 episode reward: -1.2522,                 loss: 0.3478
Episode: 701/10000 (7.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8039s / 24.1586 s
agent0:                 episode reward: 0.3159,                 loss: nan
agent1:                 episode reward: -0.3159,                 loss: 0.3487
Episode: 721/10000 (7.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7650s / 24.9236 s
agent0:                 episode reward: 0.6320,                 loss: nan
agent1:                 episode reward: -0.6320,                 loss: 0.3445
Episode: 741/10000 (7.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7611s / 25.6847 s
agent0:                 episode reward: 0.4347,                 loss: nan
agent1:                 episode reward: -0.4347,                 loss: 0.3438
Episode: 761/10000 (7.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7733s / 26.4580 s
agent0:                 episode reward: 0.5660,                 loss: nan
agent1:                 episode reward: -0.5660,                 loss: 0.3421
Episode: 781/10000 (7.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8156s / 27.2736 s
agent0:                 episode reward: 0.7441,                 loss: nan
agent1:                 episode reward: -0.7441,                 loss: 0.3694
Episode: 801/10000 (8.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7673s / 28.0410 s
agent0:                 episode reward: 0.9045,                 loss: nan
agent1:                 episode reward: -0.9045,                 loss: 0.3694
Episode: 821/10000 (8.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7961s / 28.8370 s
agent0:                 episode reward: 1.3895,                 loss: nan
agent1:                 episode reward: -1.3895,                 loss: 0.3692
Episode: 841/10000 (8.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7724s / 29.6095 s
agent0:                 episode reward: 0.3516,                 loss: nan
agent1:                 episode reward: -0.3516,                 loss: 0.3677
Episode: 861/10000 (8.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7743s / 30.3838 s
agent0:                 episode reward: 1.1849,                 loss: nan
agent1:                 episode reward: -1.1849,                 loss: 0.3661
Episode: 881/10000 (8.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7736s / 31.1574 s
agent0:                 episode reward: 0.8080,                 loss: nan
agent1:                 episode reward: -0.8080,                 loss: 0.3304
Episode: 901/10000 (9.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7743s / 31.9317 s
agent0:                 episode reward: 0.9823,                 loss: nan
agent1:                 episode reward: -0.9823,                 loss: 0.3180
Episode: 921/10000 (9.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8100s / 32.7417 s
agent0:                 episode reward: 1.3574,                 loss: nan
agent1:                 episode reward: -1.3574,                 loss: 0.3177
Episode: 941/10000 (9.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7798s / 33.5215 s
agent0:                 episode reward: 1.0943,                 loss: nan
agent1:                 episode reward: -1.0943,                 loss: 0.3179
Episode: 961/10000 (9.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7829s / 34.3044 s
agent0:                 episode reward: 0.7025,                 loss: nan
agent1:                 episode reward: -0.7025,                 loss: 0.3164
Episode: 981/10000 (9.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7869s / 35.0913 s
agent0:                 episode reward: 0.4450,                 loss: nan
agent1:                 episode reward: -0.4450,                 loss: 0.3113
Episode: 1001/10000 (10.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7863s / 35.8776 s
agent0:                 episode reward: 0.7050,                 loss: nan
agent1:                 episode reward: -0.7050,                 loss: 0.3068
Episode: 1021/10000 (10.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7851s / 36.6627 s
agent0:                 episode reward: 0.2859,                 loss: nan
agent1:                 episode reward: -0.2859,                 loss: 0.3027
Episode: 1041/10000 (10.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8495s / 37.5122 s
agent0:                 episode reward: 0.6818,                 loss: nan
agent1:                 episode reward: -0.6818,                 loss: 0.3003
Episode: 1061/10000 (10.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8041s / 38.3163 s
agent0:                 episode reward: 0.7726,                 loss: nan
agent1:                 episode reward: -0.7726,                 loss: 0.2976
Episode: 1081/10000 (10.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8119s / 39.1283 s
agent0:                 episode reward: 1.2342,                 loss: nan
agent1:                 episode reward: -1.2342,                 loss: 0.3154
Episode: 1101/10000 (11.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8000s / 39.9282 s
agent0:                 episode reward: 0.8453,                 loss: nan
agent1:                 episode reward: -0.8453,                 loss: 0.3151
Episode: 1121/10000 (11.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8226s / 40.7509 s
agent0:                 episode reward: 0.3177,                 loss: nan
agent1:                 episode reward: -0.3177,                 loss: 0.3133
Episode: 1141/10000 (11.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8142s / 41.5651 s
agent0:                 episode reward: 0.8072,                 loss: nan
agent1:                 episode reward: -0.8072,                 loss: 0.3128
Episode: 1161/10000 (11.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8084s / 42.3735 s
agent0:                 episode reward: 0.4298,                 loss: nan
agent1:                 episode reward: -0.4298,                 loss: 0.3088
Episode: 1181/10000 (11.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8065s / 43.1801 s
agent0:                 episode reward: 0.9965,                 loss: nan
agent1:                 episode reward: -0.9965,                 loss: 0.3135
Episode: 1201/10000 (12.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8095s / 43.9895 s
agent0:                 episode reward: 0.3654,                 loss: nan
agent1:                 episode reward: -0.3654,                 loss: 0.3113
Episode: 1221/10000 (12.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8195s / 44.8091 s
agent0:                 episode reward: 0.9364,                 loss: nan
agent1:                 episode reward: -0.9364,                 loss: 0.3104
Episode: 1241/10000 (12.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8054s / 45.6144 s
agent0:                 episode reward: 0.4128,                 loss: nan
agent1:                 episode reward: -0.4128,                 loss: 0.3087
Episode: 1261/10000 (12.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8417s / 46.4561 s
agent0:                 episode reward: 1.6285,                 loss: nan
agent1:                 episode reward: -1.6285,                 loss: 0.3053
Episode: 1281/10000 (12.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9156s / 47.3717 s
agent0:                 episode reward: 0.4031,                 loss: nan
agent1:                 episode reward: -0.4031,                 loss: 0.3325
Episode: 1301/10000 (13.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8377s / 48.2094 s
agent0:                 episode reward: 0.0324,                 loss: nan
agent1:                 episode reward: -0.0324,                 loss: 0.3329
Episode: 1321/10000 (13.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8861s / 49.0955 s
agent0:                 episode reward: 1.2422,                 loss: nan
agent1:                 episode reward: -1.2422,                 loss: 0.3289
Episode: 1341/10000 (13.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8314s / 49.9269 s
agent0:                 episode reward: 0.7228,                 loss: nan
agent1:                 episode reward: -0.7228,                 loss: 0.3257
Episode: 1361/10000 (13.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8495s / 50.7763 s
agent0:                 episode reward: 0.0264,                 loss: nan
agent1:                 episode reward: -0.0264,                 loss: 0.3223
Episode: 1381/10000 (13.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8360s / 51.6123 s
agent0:                 episode reward: 0.6324,                 loss: nan
agent1:                 episode reward: -0.6324,                 loss: 0.2899
Episode: 1401/10000 (14.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8309s / 52.4432 s
agent0:                 episode reward: 0.6378,                 loss: nan
agent1:                 episode reward: -0.6378,                 loss: 0.2832
Episode: 1421/10000 (14.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8444s / 53.2876 s
agent0:                 episode reward: 0.5458,                 loss: nan
agent1:                 episode reward: -0.5458,                 loss: 0.2790
Episode: 1441/10000 (14.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8412s / 54.1288 s
agent0:                 episode reward: 0.9026,                 loss: nan
agent1:                 episode reward: -0.9026,                 loss: 0.2774
Episode: 1461/10000 (14.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8392s / 54.9680 s
agent0:                 episode reward: 0.2540,                 loss: nan
agent1:                 episode reward: -0.2540,                 loss: 0.2769
Episode: 1481/10000 (14.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8407s / 55.8087 s
agent0:                 episode reward: 0.9015,                 loss: nan
agent1:                 episode reward: -0.9015,                 loss: 0.2029
Episode: 1501/10000 (15.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8640s / 56.6728 s
agent0:                 episode reward: 1.2596,                 loss: nan
agent1:                 episode reward: -1.2596,                 loss: 0.1867
Episode: 1521/10000 (15.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8724s / 57.5451 s
agent0:                 episode reward: -0.0130,                 loss: nan
agent1:                 episode reward: 0.0130,                 loss: 0.1841
Episode: 1541/10000 (15.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8880s / 58.4331 s
agent0:                 episode reward: 0.5690,                 loss: nan
agent1:                 episode reward: -0.5690,                 loss: 0.1846
Episode: 1561/10000 (15.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8790s / 59.3121 s
agent0:                 episode reward: 0.4745,                 loss: nan
agent1:                 episode reward: -0.4745,                 loss: 0.1828
Episode: 1581/10000 (15.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8641s / 60.1762 s
agent0:                 episode reward: 0.7071,                 loss: nan
agent1:                 episode reward: -0.7071,                 loss: 0.1720
Episode: 1601/10000 (16.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8539s / 61.0301 s
agent0:                 episode reward: 0.5061,                 loss: nan
agent1:                 episode reward: -0.5061,                 loss: 0.1693
Episode: 1621/10000 (16.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8534s / 61.8835 s
agent0:                 episode reward: 0.5856,                 loss: nan
agent1:                 episode reward: -0.5856,                 loss: 0.1700
Episode: 1641/10000 (16.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8575s / 62.7410 s
agent0:                 episode reward: 1.1260,                 loss: nan
agent1:                 episode reward: -1.1260,                 loss: 0.1682
Episode: 1661/10000 (16.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8516s / 63.5926 s
agent0:                 episode reward: 1.4019,                 loss: nan
agent1:                 episode reward: -1.4019,                 loss: 0.1690
Episode: 1681/10000 (16.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8516s / 64.4443 s
agent0:                 episode reward: 0.6269,                 loss: nan
agent1:                 episode reward: -0.6269,                 loss: 0.1710
Episode: 1701/10000 (17.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9292s / 65.3735 s
agent0:                 episode reward: 0.6105,                 loss: nan
agent1:                 episode reward: -0.6105,                 loss: 0.1713
Episode: 1721/10000 (17.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8686s / 66.2421 s
agent0:                 episode reward: -0.0765,                 loss: nan
agent1:                 episode reward: 0.0765,                 loss: 0.1696
Episode: 1741/10000 (17.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8677s / 67.1098 s
agent0:                 episode reward: 0.9909,                 loss: nan
agent1:                 episode reward: -0.9909,                 loss: 0.1710
Episode: 1761/10000 (17.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9307s / 68.0405 s
agent0:                 episode reward: 0.8953,                 loss: nan
agent1:                 episode reward: -0.8953,                 loss: 0.1710
Episode: 1781/10000 (17.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8821s / 68.9227 s
agent0:                 episode reward: 0.8280,                 loss: nan
agent1:                 episode reward: -0.8280,                 loss: 0.2007
Episode: 1801/10000 (18.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8900s / 69.8127 s
agent0:                 episode reward: 0.6862,                 loss: nan
agent1:                 episode reward: -0.6862,                 loss: 0.2064
Episode: 1821/10000 (18.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8744s / 70.6871 s
agent0:                 episode reward: 0.8285,                 loss: nan
agent1:                 episode reward: -0.8285,                 loss: 0.2063
Episode: 1841/10000 (18.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8803s / 71.5674 s
agent0:                 episode reward: 0.0279,                 loss: nan
agent1:                 episode reward: -0.0279,                 loss: 0.2066
Episode: 1861/10000 (18.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9044s / 72.4718 s
agent0:                 episode reward: 1.4631,                 loss: nan
agent1:                 episode reward: -1.4631,                 loss: 0.2058
Episode: 1881/10000 (18.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8901s / 73.3619 s
agent0:                 episode reward: 0.4460,                 loss: nan
agent1:                 episode reward: -0.4460,                 loss: 0.2301
Episode: 1901/10000 (19.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8953s / 74.2572 s
agent0:                 episode reward: 0.6775,                 loss: nan
agent1:                 episode reward: -0.6775,                 loss: 0.2364
Episode: 1921/10000 (19.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9039s / 75.1611 s
agent0:                 episode reward: 0.4527,                 loss: nan
agent1:                 episode reward: -0.4527,                 loss: 0.2371
Episode: 1941/10000 (19.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8908s / 76.0519 s
agent0:                 episode reward: 0.6921,                 loss: nan
agent1:                 episode reward: -0.6921,                 loss: 0.2349
Episode: 1961/10000 (19.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8926s / 76.9445 s
agent0:                 episode reward: 0.4874,                 loss: nan
agent1:                 episode reward: -0.4874,                 loss: 0.2348
Episode: 1981/10000 (19.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9300s / 77.8745 s
agent0:                 episode reward: 0.2573,                 loss: nan
agent1:                 episode reward: -0.2573,                 loss: 0.2605
Episode: 2001/10000 (20.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9799s / 78.8544 s
agent0:                 episode reward: 0.3174,                 loss: nan
agent1:                 episode reward: -0.3174,                 loss: 0.2643
Episode: 2021/10000 (20.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9254s / 79.7798 s
agent0:                 episode reward: -0.2379,                 loss: nan
agent1:                 episode reward: 0.2379,                 loss: 0.2613
Episode: 2041/10000 (20.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9382s / 80.7180 s
agent0:                 episode reward: 0.3719,                 loss: nan
agent1:                 episode reward: -0.3719,                 loss: 0.2626
Episode: 2061/10000 (20.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9105s / 81.6285 s
agent0:                 episode reward: 0.5353,                 loss: nan
agent1:                 episode reward: -0.5353,                 loss: 0.2616
Episode: 2081/10000 (20.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9268s / 82.5554 s
agent0:                 episode reward: 0.9825,                 loss: nan
agent1:                 episode reward: -0.9825,                 loss: 0.2683
Episode: 2101/10000 (21.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9221s / 83.4775 s
agent0:                 episode reward: 0.8998,                 loss: nan
agent1:                 episode reward: -0.8998,                 loss: 0.2649
Episode: 2121/10000 (21.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9210s / 84.3984 s
agent0:                 episode reward: 0.7711,                 loss: nan
agent1:                 episode reward: -0.7711,                 loss: 0.2651
Episode: 2141/10000 (21.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9206s / 85.3190 s
agent0:                 episode reward: 0.2496,                 loss: nan
agent1:                 episode reward: -0.2496,                 loss: 0.2625
Episode: 2161/10000 (21.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9298s / 86.2488 s
agent0:                 episode reward: 0.6530,                 loss: nan
agent1:                 episode reward: -0.6530,                 loss: 0.2626
Episode: 2181/10000 (21.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9262s / 87.1750 s
agent0:                 episode reward: 0.7289,                 loss: nan
agent1:                 episode reward: -0.7289,                 loss: 0.2615
Episode: 2201/10000 (22.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9241s / 88.0991 s
agent0:                 episode reward: 0.6885,                 loss: nan
agent1:                 episode reward: -0.6885,                 loss: 0.2555
Episode: 2221/10000 (22.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0170s / 89.1161 s
agent0:                 episode reward: 0.5878,                 loss: nan
agent1:                 episode reward: -0.5878,                 loss: 0.2555
Episode: 2241/10000 (22.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9915s / 90.1076 s
agent0:                 episode reward: 0.9488,                 loss: nan
agent1:                 episode reward: -0.9488,                 loss: 0.2573
Episode: 2261/10000 (22.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9137s / 91.0213 s
agent0:                 episode reward: 0.2217,                 loss: nan
agent1:                 episode reward: -0.2217,                 loss: 0.2561
Episode: 2281/10000 (22.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9408s / 91.9621 s
agent0:                 episode reward: 0.4624,                 loss: nan
agent1:                 episode reward: -0.4624,                 loss: 0.2475
Episode: 2301/10000 (23.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9390s / 92.9011 s
agent0:                 episode reward: -0.1419,                 loss: nan
agent1:                 episode reward: 0.1419,                 loss: 0.2419
Episode: 2321/10000 (23.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9214s / 93.8225 s
agent0:                 episode reward: 1.4803,                 loss: nan
agent1:                 episode reward: -1.4803,                 loss: 0.2408
Episode: 2341/10000 (23.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9275s / 94.7501 s
agent0:                 episode reward: 0.5151,                 loss: nan
agent1:                 episode reward: -0.5151,                 loss: 0.2412
Episode: 2361/10000 (23.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9791s / 95.7292 s
agent0:                 episode reward: 0.3565,                 loss: nan
agent1:                 episode reward: -0.3565,                 loss: 0.2416
Episode: 2381/10000 (23.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9464s / 96.6756 s
agent0:                 episode reward: -0.6617,                 loss: nan
agent1:                 episode reward: 0.6617,                 loss: 0.1833
Episode: 2401/10000 (24.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9391s / 97.6147 s
agent0:                 episode reward: 0.2937,                 loss: nan
agent1:                 episode reward: -0.2937,                 loss: 0.1714
Episode: 2421/10000 (24.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0225s / 98.6372 s
agent0:                 episode reward: 0.6087,                 loss: nan
agent1:                 episode reward: -0.6087,                 loss: 0.1712
Episode: 2441/10000 (24.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0000s / 99.6371 s
agent0:                 episode reward: 0.2914,                 loss: nan
agent1:                 episode reward: -0.2914,                 loss: 0.1717
Episode: 2461/10000 (24.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9502s / 100.5873 s
agent0:                 episode reward: 0.7891,                 loss: nan
agent1:                 episode reward: -0.7891,                 loss: 0.1702
Episode: 2481/10000 (24.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9711s / 101.5585 s
agent0:                 episode reward: 1.1711,                 loss: nan
agent1:                 episode reward: -1.1711,                 loss: 0.1601
Episode: 2501/10000 (25.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9625s / 102.5210 s
agent0:                 episode reward: 0.8007,                 loss: nan
agent1:                 episode reward: -0.8007,                 loss: 0.1570
Episode: 2521/10000 (25.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9798s / 103.5008 s
agent0:                 episode reward: 0.2942,                 loss: nan
agent1:                 episode reward: -0.2942,                 loss: 0.1555
Episode: 2541/10000 (25.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9734s / 104.4742 s
agent0:                 episode reward: -0.0227,                 loss: nan
agent1:                 episode reward: 0.0227,                 loss: 0.1568
Episode: 2561/10000 (25.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9520s / 105.4262 s
agent0:                 episode reward: 0.8483,                 loss: nan
agent1:                 episode reward: -0.8483,                 loss: 0.1555
Episode: 2581/10000 (25.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9533s / 106.3795 s
agent0:                 episode reward: 0.1539,                 loss: nan
agent1:                 episode reward: -0.1539,                 loss: 0.1673
Episode: 2601/10000 (26.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9662s / 107.3457 s
agent0:                 episode reward: 0.8338,                 loss: nan
agent1:                 episode reward: -0.8338,                 loss: 0.1681
Episode: 2621/10000 (26.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9671s / 108.3128 s
agent0:                 episode reward: 0.6250,                 loss: nan
agent1:                 episode reward: -0.6250,                 loss: 0.1695
Episode: 2641/10000 (26.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0249s / 109.3377 s
agent0:                 episode reward: 0.4047,                 loss: nan
agent1:                 episode reward: -0.4047,                 loss: 0.1677
Episode: 2661/10000 (26.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9777s / 110.3154 s
agent0:                 episode reward: 0.6735,                 loss: nan
agent1:                 episode reward: -0.6735,                 loss: 0.1675
Episode: 2681/10000 (26.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9639s / 111.2793 s
agent0:                 episode reward: 0.7642,                 loss: nan
agent1:                 episode reward: -0.7642,                 loss: 0.2088
Episode: 2701/10000 (27.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9710s / 112.2503 s
agent0:                 episode reward: -0.4761,                 loss: nan
agent1:                 episode reward: 0.4761,                 loss: 0.2152
Episode: 2721/10000 (27.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9881s / 113.2384 s
agent0:                 episode reward: 0.4368,                 loss: nan
agent1:                 episode reward: -0.4368,                 loss: 0.2149
Episode: 2741/10000 (27.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9820s / 114.2203 s
agent0:                 episode reward: 0.3665,                 loss: nan
agent1:                 episode reward: -0.3665,                 loss: 0.2156
Episode: 2761/10000 (27.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0046s / 115.2249 s
agent0:                 episode reward: -0.0768,                 loss: nan
agent1:                 episode reward: 0.0768,                 loss: 0.2146
Episode: 2781/10000 (27.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0165s / 116.2414 s
agent0:                 episode reward: 0.1411,                 loss: nan
agent1:                 episode reward: -0.1411,                 loss: 0.2359
Episode: 2801/10000 (28.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9809s / 117.2224 s
agent0:                 episode reward: 0.4675,                 loss: nan
agent1:                 episode reward: -0.4675,                 loss: 0.2387
Episode: 2821/10000 (28.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9821s / 118.2044 s
agent0:                 episode reward: -0.0745,                 loss: nan
agent1:                 episode reward: 0.0745,                 loss: 0.2371
Episode: 2841/10000 (28.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0643s / 119.2687 s
agent0:                 episode reward: 0.8201,                 loss: nan
agent1:                 episode reward: -0.8201,                 loss: 0.2379
Episode: 2861/10000 (28.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0085s / 120.2771 s
agent0:                 episode reward: 0.6379,                 loss: nan
agent1:                 episode reward: -0.6379,                 loss: 0.2396
Episode: 2881/10000 (28.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9890s / 121.2661 s
agent0:                 episode reward: -0.0940,                 loss: nan
agent1:                 episode reward: 0.0940,                 loss: 0.2279
Episode: 2901/10000 (29.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9878s / 122.2539 s
agent0:                 episode reward: -0.3213,                 loss: nan
agent1:                 episode reward: 0.3213,                 loss: 0.2235
Episode: 2921/10000 (29.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0204s / 123.2743 s
agent0:                 episode reward: 0.6395,                 loss: nan
agent1:                 episode reward: -0.6395,                 loss: 0.2237
Episode: 2941/10000 (29.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9980s / 124.2723 s
agent0:                 episode reward: 0.1226,                 loss: nan
agent1:                 episode reward: -0.1226,                 loss: 0.2222
Episode: 2961/10000 (29.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9987s / 125.2711 s
agent0:                 episode reward: 0.3270,                 loss: nan
agent1:                 episode reward: -0.3270,                 loss: 0.2224
Episode: 2981/10000 (29.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0095s / 126.2805 s
agent0:                 episode reward: 0.5828,                 loss: nan
agent1:                 episode reward: -0.5828,                 loss: 0.2133
Episode: 3001/10000 (30.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9961s / 127.2766 s
agent0:                 episode reward: 0.1406,                 loss: nan
agent1:                 episode reward: -0.1406,                 loss: 0.2105
Episode: 3021/10000 (30.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9938s / 128.2704 s
agent0:                 episode reward: 1.1475,                 loss: nan
agent1:                 episode reward: -1.1475,                 loss: 0.2110
Episode: 3041/10000 (30.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0587s / 129.3290 s
agent0:                 episode reward: -0.4818,                 loss: nan
agent1:                 episode reward: 0.4818,                 loss: 0.2101
Episode: 3061/10000 (30.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0396s / 130.3686 s
agent0:                 episode reward: 0.7783,                 loss: nan
agent1:                 episode reward: -0.7783,                 loss: 0.2082
Episode: 3081/10000 (30.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0359s / 131.4045 s
agent0:                 episode reward: 0.6221,                 loss: nan
agent1:                 episode reward: -0.6221,                 loss: 0.1998
Episode: 3101/10000 (31.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0136s / 132.4181 s
agent0:                 episode reward: 0.2097,                 loss: nan
agent1:                 episode reward: -0.2097,                 loss: 0.1949
Episode: 3121/10000 (31.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9975s / 133.4155 s
agent0:                 episode reward: 0.2682,                 loss: nan
agent1:                 episode reward: -0.2682,                 loss: 0.1943
Episode: 3141/10000 (31.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0260s / 134.4415 s
agent0:                 episode reward: 1.3415,                 loss: nan
agent1:                 episode reward: -1.3415,                 loss: 0.1925
Episode: 3161/10000 (31.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0177s / 135.4592 s
agent0:                 episode reward: 0.1376,                 loss: nan
agent1:                 episode reward: -0.1376,                 loss: 0.1919
Episode: 3181/10000 (31.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0130s / 136.4723 s
agent0:                 episode reward: -0.2612,                 loss: nan
agent1:                 episode reward: 0.2612,                 loss: 0.1872
Episode: 3201/10000 (32.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0341s / 137.5064 s
agent0:                 episode reward: -0.0748,                 loss: nan
agent1:                 episode reward: 0.0748,                 loss: 0.1845
Episode: 3221/10000 (32.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0200s / 138.5264 s
agent0:                 episode reward: 0.3875,                 loss: nan
agent1:                 episode reward: -0.3875,                 loss: 0.1833
Episode: 3241/10000 (32.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0677s / 139.5941 s
agent0:                 episode reward: 0.5321,                 loss: nan
agent1:                 episode reward: -0.5321,                 loss: 0.1827
Episode: 3261/10000 (32.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0450s / 140.6391 s
agent0:                 episode reward: 0.0095,                 loss: nan
agent1:                 episode reward: -0.0095,                 loss: 0.1833
Episode: 3281/10000 (32.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0302s / 141.6693 s
agent0:                 episode reward: 1.0113,                 loss: nan
agent1:                 episode reward: -1.0113,                 loss: 0.2133
Episode: 3301/10000 (33.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0231s / 142.6924 s
agent0:                 episode reward: 0.3989,                 loss: nan
agent1:                 episode reward: -0.3989,                 loss: 0.2153
Episode: 3321/10000 (33.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0393s / 143.7317 s
agent0:                 episode reward: -0.7753,                 loss: nan
agent1:                 episode reward: 0.7753,                 loss: 0.2166
Episode: 3341/10000 (33.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0307s / 144.7624 s
agent0:                 episode reward: 0.5687,                 loss: nan
agent1:                 episode reward: -0.5687,                 loss: 0.2147
Episode: 3361/10000 (33.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0265s / 145.7889 s
agent0:                 episode reward: 0.0166,                 loss: nan
agent1:                 episode reward: -0.0166,                 loss: 0.2163
Episode: 3381/10000 (33.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0633s / 146.8522 s
agent0:                 episode reward: 0.2489,                 loss: nan
agent1:                 episode reward: -0.2489,                 loss: 0.1954
Episode: 3401/10000 (34.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0486s / 147.9008 s
agent0:                 episode reward: 0.3822,                 loss: nan
agent1:                 episode reward: -0.3822,                 loss: 0.1936
Episode: 3421/10000 (34.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0440s / 148.9447 s
agent0:                 episode reward: -0.2317,                 loss: nan
agent1:                 episode reward: 0.2317,                 loss: 0.1912
Episode: 3441/10000 (34.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1259s / 150.0707 s
agent0:                 episode reward: 0.7490,                 loss: nan
agent1:                 episode reward: -0.7490,                 loss: 0.1926
Episode: 3461/10000 (34.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0606s / 151.1313 s
agent0:                 episode reward: -0.0932,                 loss: nan
agent1:                 episode reward: 0.0932,                 loss: 0.1931
Episode: 3481/10000 (34.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0488s / 152.1801 s
agent0:                 episode reward: 0.5152,                 loss: nan
agent1:                 episode reward: -0.5152,                 loss: 0.1919
Episode: 3501/10000 (35.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0531s / 153.2331 s
agent0:                 episode reward: 0.2160,                 loss: nan
agent1:                 episode reward: -0.2160,                 loss: 0.1891
Episode: 3521/10000 (35.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0443s / 154.2774 s
agent0:                 episode reward: 0.4485,                 loss: nan
agent1:                 episode reward: -0.4485,                 loss: 0.1886
Episode: 3541/10000 (35.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0559s / 155.3333 s
agent0:                 episode reward: -0.2174,                 loss: nan
agent1:                 episode reward: 0.2174,                 loss: 0.1894
Episode: 3561/10000 (35.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0754s / 156.4088 s
agent0:                 episode reward: -0.0247,                 loss: nan
agent1:                 episode reward: 0.0247,                 loss: 0.1878
Episode: 3581/10000 (35.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0560s / 157.4648 s
agent0:                 episode reward: -0.2427,                 loss: nan
agent1:                 episode reward: 0.2427,                 loss: 0.2020
Episode: 3601/10000 (36.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0677s / 158.5325 s
agent0:                 episode reward: 0.4845,                 loss: nan
agent1:                 episode reward: -0.4845,                 loss: 0.2014
Episode: 3621/10000 (36.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0619s / 159.5945 s
agent0:                 episode reward: -0.1548,                 loss: nan
agent1:                 episode reward: 0.1548,                 loss: 0.2021
Episode: 3641/10000 (36.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1307s / 160.7252 s
agent0:                 episode reward: 0.6351,                 loss: nan
agent1:                 episode reward: -0.6351,                 loss: 0.2012
Episode: 3661/10000 (36.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0674s / 161.7926 s
agent0:                 episode reward: 0.8960,                 loss: nan
agent1:                 episode reward: -0.8960,                 loss: 0.2019
Episode: 3681/10000 (36.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0648s / 162.8574 s
agent0:                 episode reward: 0.0668,                 loss: nan
agent1:                 episode reward: -0.0668,                 loss: 0.2043
Episode: 3701/10000 (37.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0684s / 163.9259 s
agent0:                 episode reward: 0.2766,                 loss: nan
agent1:                 episode reward: -0.2766,                 loss: 0.2035
Episode: 3721/10000 (37.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1087s / 165.0346 s
agent0:                 episode reward: -0.0856,                 loss: nan
agent1:                 episode reward: 0.0856,                 loss: 0.2035
Episode: 3741/10000 (37.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0758s / 166.1104 s
agent0:                 episode reward: -0.3376,                 loss: nan
agent1:                 episode reward: 0.3376,                 loss: 0.2033
Episode: 3761/10000 (37.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0795s / 167.1899 s
agent0:                 episode reward: -0.3349,                 loss: nan
agent1:                 episode reward: 0.3349,                 loss: 0.2011
Episode: 3781/10000 (37.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0988s / 168.2886 s
agent0:                 episode reward: 0.1615,                 loss: nan
agent1:                 episode reward: -0.1615,                 loss: 0.2204
Episode: 3801/10000 (38.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1001s / 169.3887 s
agent0:                 episode reward: 0.4312,                 loss: nan
agent1:                 episode reward: -0.4312,                 loss: 0.2211
Episode: 3821/10000 (38.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1491s / 170.5378 s
agent0:                 episode reward: 0.5719,                 loss: nan
agent1:                 episode reward: -0.5719,                 loss: 0.2205
Episode: 3841/10000 (38.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1011s / 171.6389 s
agent0:                 episode reward: -0.3109,                 loss: nan
agent1:                 episode reward: 0.3109,                 loss: 0.2200
Episode: 3861/10000 (38.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1102s / 172.7491 s
agent0:                 episode reward: 0.1059,                 loss: nan
agent1:                 episode reward: -0.1059,                 loss: 0.2195
Episode: 3881/10000 (38.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1064s / 173.8556 s
agent0:                 episode reward: 0.2871,                 loss: nan
agent1:                 episode reward: -0.2871,                 loss: 0.2282
Episode: 3901/10000 (39.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0974s / 174.9530 s
agent0:                 episode reward: 0.4677,                 loss: nan
agent1:                 episode reward: -0.4677,                 loss: 0.2268
Episode: 3921/10000 (39.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1044s / 176.0574 s
agent0:                 episode reward: 0.1349,                 loss: nan
agent1:                 episode reward: -0.1349,                 loss: 0.2248
Episode: 3941/10000 (39.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1222s / 177.1796 s
agent0:                 episode reward: 0.3607,                 loss: nan
agent1:                 episode reward: -0.3607,                 loss: 0.2239
Episode: 3961/10000 (39.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0812s / 178.2608 s
agent0:                 episode reward: -0.6258,                 loss: nan
agent1:                 episode reward: 0.6258,                 loss: 0.2243
Episode: 3981/10000 (39.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0966s / 179.3573 s
agent0:                 episode reward: -0.0654,                 loss: nan
agent1:                 episode reward: 0.0654,                 loss: 0.1818
Episode: 4001/10000 (40.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1266s / 180.4839 s
agent0:                 episode reward: 0.9498,                 loss: nan
agent1:                 episode reward: -0.9498,                 loss: 0.1721
Episode: 4021/10000 (40.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1796s / 181.6636 s
agent0:                 episode reward: -0.1050,                 loss: nan
agent1:                 episode reward: 0.1050,                 loss: 0.1712
Episode: 4041/10000 (40.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1519s / 182.8154 s
agent0:                 episode reward: -0.5805,                 loss: nan
agent1:                 episode reward: 0.5805,                 loss: 0.1706
Episode: 4061/10000 (40.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1200s / 183.9354 s
agent0:                 episode reward: -0.2901,                 loss: nan
agent1:                 episode reward: 0.2901,                 loss: 0.1708
Episode: 4081/10000 (40.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1261s / 185.0615 s
agent0:                 episode reward: 0.3689,                 loss: nan
agent1:                 episode reward: -0.3689,                 loss: 0.1575
Episode: 4101/10000 (41.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1352s / 186.1967 s
agent0:                 episode reward: -0.2010,                 loss: nan
agent1:                 episode reward: 0.2010,                 loss: 0.1543
Episode: 4121/10000 (41.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1289s / 187.3257 s
agent0:                 episode reward: -0.0014,                 loss: nan
agent1:                 episode reward: 0.0014,                 loss: 0.1537
Episode: 4141/10000 (41.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1328s / 188.4585 s
agent0:                 episode reward: 0.2721,                 loss: nan
agent1:                 episode reward: -0.2721,                 loss: 0.1522
Episode: 4161/10000 (41.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1413s / 189.5997 s
agent0:                 episode reward: -0.4628,                 loss: nan
agent1:                 episode reward: 0.4628,                 loss: 0.1519
Episode: 4181/10000 (41.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1310s / 190.7307 s
agent0:                 episode reward: 0.0003,                 loss: nan
agent1:                 episode reward: -0.0003,                 loss: 0.1914
Episode: 4201/10000 (42.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1962s / 191.9269 s
agent0:                 episode reward: -0.2093,                 loss: nan
agent1:                 episode reward: 0.2093,                 loss: 0.1986
Episode: 4221/10000 (42.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1236s / 193.0505 s
agent0:                 episode reward: 0.0912,                 loss: nan
agent1:                 episode reward: -0.0912,                 loss: 0.1968
Episode: 4241/10000 (42.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1285s / 194.1790 s
agent0:                 episode reward: 0.3446,                 loss: nan
agent1:                 episode reward: -0.3446,                 loss: 0.1950
Episode: 4261/10000 (42.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1280s / 195.3071 s
agent0:                 episode reward: 0.1506,                 loss: nan
agent1:                 episode reward: -0.1506,                 loss: 0.1963
Episode: 4281/10000 (42.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1209s / 196.4279 s
agent0:                 episode reward: -0.5313,                 loss: nan
agent1:                 episode reward: 0.5313,                 loss: 0.2061
Episode: 4301/10000 (43.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1269s / 197.5549 s
agent0:                 episode reward: 0.2384,                 loss: nan
agent1:                 episode reward: -0.2384,                 loss: 0.2061
Episode: 4321/10000 (43.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1376s / 198.6924 s
agent0:                 episode reward: -0.1542,                 loss: nan
agent1:                 episode reward: 0.1542,                 loss: 0.2072
Episode: 4341/10000 (43.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1311s / 199.8235 s
agent0:                 episode reward: -0.2655,                 loss: nan
agent1:                 episode reward: 0.2655,                 loss: 0.2054
Episode: 4361/10000 (43.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2013s / 201.0248 s
agent0:                 episode reward: -0.3485,                 loss: nan
agent1:                 episode reward: 0.3485,                 loss: 0.2036
Episode: 4381/10000 (43.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1721s / 202.1969 s
agent0:                 episode reward: -0.6978,                 loss: nan
agent1:                 episode reward: 0.6978,                 loss: 0.2086
Episode: 4401/10000 (44.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1474s / 203.3443 s
agent0:                 episode reward: 0.3260,                 loss: nan
agent1:                 episode reward: -0.3260,                 loss: 0.2113
Episode: 4421/10000 (44.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1538s / 204.4980 s
agent0:                 episode reward: 0.6159,                 loss: nan
agent1:                 episode reward: -0.6159,                 loss: 0.2096
Episode: 4441/10000 (44.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1514s / 205.6495 s
agent0:                 episode reward: -0.3040,                 loss: nan
agent1:                 episode reward: 0.3040,                 loss: 0.2088
Episode: 4461/10000 (44.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1833s / 206.8328 s
agent0:                 episode reward: 0.7291,                 loss: nan
agent1:                 episode reward: -0.7291,                 loss: 0.2094
Episode: 4481/10000 (44.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1400s / 207.9728 s
agent0:                 episode reward: -0.0870,                 loss: nan
agent1:                 episode reward: 0.0870,                 loss: 0.1933
Episode: 4501/10000 (45.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1426s / 209.1153 s
agent0:                 episode reward: -0.3346,                 loss: nan
agent1:                 episode reward: 0.3346,                 loss: 0.1913
Episode: 4521/10000 (45.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1539s / 210.2693 s
agent0:                 episode reward: 0.3367,                 loss: nan
agent1:                 episode reward: -0.3367,                 loss: 0.1932
Episode: 4541/10000 (45.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2057s / 211.4750 s
agent0:                 episode reward: 0.2925,                 loss: nan
agent1:                 episode reward: -0.2925,                 loss: 0.1906
Episode: 4561/10000 (45.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1628s / 212.6378 s
agent0:                 episode reward: 0.6922,                 loss: nan
agent1:                 episode reward: -0.6922,                 loss: 0.1899
Episode: 4581/10000 (45.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1593s / 213.7971 s
agent0:                 episode reward: 0.6593,                 loss: nan
agent1:                 episode reward: -0.6593,                 loss: 0.1837
Episode: 4601/10000 (46.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2203s / 215.0173 s
agent0:                 episode reward: -0.1256,                 loss: nan
agent1:                 episode reward: 0.1256,                 loss: 0.1786
Episode: 4621/10000 (46.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2158s / 216.2331 s
agent0:                 episode reward: -0.3206,                 loss: nan
agent1:                 episode reward: 0.3206,                 loss: 0.1800
Episode: 4641/10000 (46.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1708s / 217.4039 s
agent0:                 episode reward: 0.2219,                 loss: nan
agent1:                 episode reward: -0.2219,                 loss: 0.1803
Episode: 4661/10000 (46.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1990s / 218.6030 s
agent0:                 episode reward: -0.2082,                 loss: nan
agent1:                 episode reward: 0.2082,                 loss: 0.1780
Episode: 4681/10000 (46.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1980s / 219.8010 s
agent0:                 episode reward: -0.3085,                 loss: nan
agent1:                 episode reward: 0.3085,                 loss: 0.1640
Episode: 4701/10000 (47.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1991s / 221.0001 s
agent0:                 episode reward: -0.2359,                 loss: nan
agent1:                 episode reward: 0.2359,                 loss: 0.1606
Episode: 4721/10000 (47.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2843s / 222.2844 s
agent0:                 episode reward: 0.3644,                 loss: nan
agent1:                 episode reward: -0.3644,                 loss: 0.1588
Episode: 4741/10000 (47.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2007s / 223.4851 s
agent0:                 episode reward: 0.4132,                 loss: nan
agent1:                 episode reward: -0.4132,                 loss: 0.1588
Episode: 4761/10000 (47.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2234s / 224.7084 s
agent0:                 episode reward: 0.3692,                 loss: nan
agent1:                 episode reward: -0.3692,                 loss: 0.1605
Episode: 4781/10000 (47.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2053s / 225.9138 s
agent0:                 episode reward: 0.1959,                 loss: nan
agent1:                 episode reward: -0.1959,                 loss: 0.1938
Episode: 4801/10000 (48.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1793s / 227.0931 s
agent0:                 episode reward: -0.3368,                 loss: nan
agent1:                 episode reward: 0.3368,                 loss: 0.1993
Episode: 4821/10000 (48.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1931s / 228.2861 s
agent0:                 episode reward: 0.2895,                 loss: nan
agent1:                 episode reward: -0.2895,                 loss: 0.1981
Episode: 4841/10000 (48.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1973s / 229.4834 s
agent0:                 episode reward: 0.5718,                 loss: nan
agent1:                 episode reward: -0.5718,                 loss: 0.1965
Episode: 4861/10000 (48.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1954s / 230.6788 s
agent0:                 episode reward: -0.6379,                 loss: nan
agent1:                 episode reward: 0.6379,                 loss: 0.1977
Episode: 4881/10000 (48.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3066s / 231.9854 s
agent0:                 episode reward: 0.6678,                 loss: nan
agent1:                 episode reward: -0.6678,                 loss: 0.2393
Episode: 4901/10000 (49.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2018s / 233.1872 s
agent0:                 episode reward: -0.3792,                 loss: nan
agent1:                 episode reward: 0.3792,                 loss: 0.2451
Episode: 4921/10000 (49.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2219s / 234.4092 s
agent0:                 episode reward: -0.2874,                 loss: nan
agent1:                 episode reward: 0.2874,                 loss: 0.2434
Episode: 4941/10000 (49.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1984s / 235.6076 s
agent0:                 episode reward: -0.2837,                 loss: nan
agent1:                 episode reward: 0.2837,                 loss: 0.2449
Episode: 4961/10000 (49.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2039s / 236.8115 s
agent0:                 episode reward: 0.2971,                 loss: nan
agent1:                 episode reward: -0.2971,                 loss: 0.2415
Episode: 4981/10000 (49.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1999s / 238.0113 s
agent0:                 episode reward: 0.2436,                 loss: nan
agent1:                 episode reward: -0.2436,                 loss: 0.2483
Episode: 5001/10000 (50.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2236s / 239.2349 s
agent0:                 episode reward: -0.4572,                 loss: nan
agent1:                 episode reward: 0.4572,                 loss: 0.2466
Episode: 5021/10000 (50.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2129s / 240.4478 s
agent0:                 episode reward: 0.1786,                 loss: nan
agent1:                 episode reward: -0.1786,                 loss: 0.2454
Episode: 5041/10000 (50.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2175s / 241.6653 s
agent0:                 episode reward: 0.1271,                 loss: nan
agent1:                 episode reward: -0.1271,                 loss: 0.2460
Episode: 5061/10000 (50.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2687s / 242.9340 s
agent0:                 episode reward: -0.3750,                 loss: nan
agent1:                 episode reward: 0.3750,                 loss: 0.2439
Episode: 5081/10000 (50.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2104s / 244.1443 s
agent0:                 episode reward: -0.0055,                 loss: nan
agent1:                 episode reward: 0.0055,                 loss: 0.2652
Episode: 5101/10000 (51.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2123s / 245.3566 s
agent0:                 episode reward: 0.1928,                 loss: nan
agent1:                 episode reward: -0.1928,                 loss: 0.2615
Episode: 5121/10000 (51.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2281s / 246.5847 s
agent0:                 episode reward: 0.0080,                 loss: nan
agent1:                 episode reward: -0.0080,                 loss: 0.2602
Episode: 5141/10000 (51.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2357s / 247.8203 s
agent0:                 episode reward: -0.5252,                 loss: nan
agent1:                 episode reward: 0.5252,                 loss: 0.2604
Episode: 5161/10000 (51.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2529s / 249.0733 s
agent0:                 episode reward: -0.7911,                 loss: nan
agent1:                 episode reward: 0.7911,                 loss: 0.2609
Episode: 5181/10000 (51.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2249s / 250.2981 s
agent0:                 episode reward: -0.5164,                 loss: nan
agent1:                 episode reward: 0.5164,                 loss: 0.2242
Episode: 5201/10000 (52.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2330s / 251.5312 s
agent0:                 episode reward: 0.5725,                 loss: nan
agent1:                 episode reward: -0.5725,                 loss: 0.2076
Episode: 5221/10000 (52.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2978s / 252.8290 s
agent0:                 episode reward: -0.1079,                 loss: nan
agent1:                 episode reward: 0.1079,                 loss: 0.2094
Episode: 5241/10000 (52.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2686s / 254.0976 s
agent0:                 episode reward: -0.4506,                 loss: nan
agent1:                 episode reward: 0.4506,                 loss: 0.2063
Episode: 5261/10000 (52.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2441s / 255.3417 s
agent0:                 episode reward: 0.0843,                 loss: nan
agent1:                 episode reward: -0.0843,                 loss: 0.2070
Episode: 5281/10000 (52.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3019s / 256.6436 s
agent0:                 episode reward: -0.3978,                 loss: nan
agent1:                 episode reward: 0.3978,                 loss: 0.1581
Episode: 5301/10000 (53.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2481s / 257.8917 s
agent0:                 episode reward: -1.0265,                 loss: nan
agent1:                 episode reward: 1.0265,                 loss: 0.1435
Episode: 5321/10000 (53.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2342s / 259.1258 s
agent0:                 episode reward: -0.0843,                 loss: nan
agent1:                 episode reward: 0.0843,                 loss: 0.1417
Episode: 5341/10000 (53.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2346s / 260.3604 s
agent0:                 episode reward: 0.6037,                 loss: nan
agent1:                 episode reward: -0.6037,                 loss: 0.1430
Episode: 5361/10000 (53.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2512s / 261.6116 s
agent0:                 episode reward: 0.0439,                 loss: nan
agent1:                 episode reward: -0.0439,                 loss: 0.1403
Episode: 5381/10000 (53.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3001s / 262.9117 s
agent0:                 episode reward: -0.2731,                 loss: nan
agent1:                 episode reward: 0.2731,                 loss: 0.1371
Episode: 5401/10000 (54.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2823s / 264.1940 s
agent0:                 episode reward: -0.0985,                 loss: nan
agent1:                 episode reward: 0.0985,                 loss: 0.1299
Episode: 5421/10000 (54.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2666s / 265.4606 s
agent0:                 episode reward: 0.8230,                 loss: nan
agent1:                 episode reward: -0.8230,                 loss: 0.1299
Episode: 5441/10000 (54.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2633s / 266.7238 s
agent0:                 episode reward: 0.0567,                 loss: nan
agent1:                 episode reward: -0.0567,                 loss: 0.1296
Episode: 5461/10000 (54.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2501s / 267.9740 s
agent0:                 episode reward: -0.0574,                 loss: nan
agent1:                 episode reward: 0.0574,                 loss: 0.1281
Episode: 5481/10000 (54.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2504s / 269.2243 s
agent0:                 episode reward: -0.3938,                 loss: nan
agent1:                 episode reward: 0.3938,                 loss: 0.1835
Episode: 5501/10000 (55.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2647s / 270.4891 s
agent0:                 episode reward: -0.4497,                 loss: nan
agent1:                 episode reward: 0.4497,                 loss: 0.1867
Episode: 5521/10000 (55.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2578s / 271.7469 s
agent0:                 episode reward: -0.9720,                 loss: nan
agent1:                 episode reward: 0.9720,                 loss: 0.1913
Episode: 5541/10000 (55.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3402s / 273.0871 s
agent0:                 episode reward: -0.3874,                 loss: nan
agent1:                 episode reward: 0.3874,                 loss: 0.1895
Episode: 5561/10000 (55.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2675s / 274.3545 s
agent0:                 episode reward: -0.4126,                 loss: nan
agent1:                 episode reward: 0.4126,                 loss: 0.1898
Episode: 5581/10000 (55.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2891s / 275.6436 s
agent0:                 episode reward: -0.2109,                 loss: nan
agent1:                 episode reward: 0.2109,                 loss: 0.2104
Episode: 5601/10000 (56.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2839s / 276.9275 s
agent0:                 episode reward: -0.9447,                 loss: nan
agent1:                 episode reward: 0.9447,                 loss: 0.2076
Episode: 5621/10000 (56.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2637s / 278.1911 s
agent0:                 episode reward: -0.6564,                 loss: nan
agent1:                 episode reward: 0.6564,                 loss: 0.2077
Episode: 5641/10000 (56.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2797s / 279.4708 s
agent0:                 episode reward: 0.1187,                 loss: nan
agent1:                 episode reward: -0.1187,                 loss: 0.2077
Episode: 5661/10000 (56.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2978s / 280.7686 s
agent0:                 episode reward: 0.2362,                 loss: nan
agent1:                 episode reward: -0.2362,                 loss: 0.2058
Episode: 5681/10000 (56.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2815s / 282.0501 s
agent0:                 episode reward: 0.6772,                 loss: nan
agent1:                 episode reward: -0.6772,                 loss: 0.1906
Episode: 5701/10000 (57.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3254s / 283.3755 s
agent0:                 episode reward: 0.0376,                 loss: nan
agent1:                 episode reward: -0.0376,                 loss: 0.1855
Episode: 5721/10000 (57.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3045s / 284.6800 s
agent0:                 episode reward: 0.0550,                 loss: nan
agent1:                 episode reward: -0.0550,                 loss: 0.1857
Episode: 5741/10000 (57.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2963s / 285.9763 s
agent0:                 episode reward: 0.1713,                 loss: nan
agent1:                 episode reward: -0.1713,                 loss: 0.1875
Episode: 5761/10000 (57.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3071s / 287.2834 s
agent0:                 episode reward: -0.1503,                 loss: nan
agent1:                 episode reward: 0.1503,                 loss: 0.1850
Episode: 5781/10000 (57.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3779s / 288.6613 s
agent0:                 episode reward: -0.1464,                 loss: nan
agent1:                 episode reward: 0.1464,                 loss: 0.2040
Episode: 5801/10000 (58.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2975s / 289.9588 s
agent0:                 episode reward: -0.2904,                 loss: nan
agent1:                 episode reward: 0.2904,                 loss: 0.2043
Episode: 5821/10000 (58.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3068s / 291.2656 s
agent0:                 episode reward: 0.0851,                 loss: nan
agent1:                 episode reward: -0.0851,                 loss: 0.2036
Episode: 5841/10000 (58.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3076s / 292.5732 s
agent0:                 episode reward: 0.8417,                 loss: nan
agent1:                 episode reward: -0.8417,                 loss: 0.2052
Episode: 5861/10000 (58.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3689s / 293.9421 s
agent0:                 episode reward: -0.3766,                 loss: nan
agent1:                 episode reward: 0.3766,                 loss: 0.2018
Episode: 5881/10000 (58.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3224s / 295.2646 s
agent0:                 episode reward: -1.4108,                 loss: nan
agent1:                 episode reward: 1.4108,                 loss: 0.2352
Episode: 5901/10000 (59.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3294s / 296.5940 s
agent0:                 episode reward: -0.3038,                 loss: nan
agent1:                 episode reward: 0.3038,                 loss: 0.2369
Episode: 5921/10000 (59.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3460s / 297.9400 s
agent0:                 episode reward: 0.1122,                 loss: nan
agent1:                 episode reward: -0.1122,                 loss: 0.2355
Episode: 5941/10000 (59.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3324s / 299.2723 s
agent0:                 episode reward: -0.2056,                 loss: nan
agent1:                 episode reward: 0.2056,                 loss: 0.2341
Episode: 5961/10000 (59.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3268s / 300.5991 s
agent0:                 episode reward: -0.5055,                 loss: nan
agent1:                 episode reward: 0.5055,                 loss: 0.2337
Episode: 5981/10000 (59.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3080s / 301.9071 s
agent0:                 episode reward: 0.4706,                 loss: nan
agent1:                 episode reward: -0.4706,                 loss: 0.2564
Episode: 6001/10000 (60.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3257s / 303.2328 s
agent0:                 episode reward: -0.3059,                 loss: nan
agent1:                 episode reward: 0.3059,                 loss: 0.2541
Episode: 6021/10000 (60.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3725s / 304.6052 s
agent0:                 episode reward: -0.1693,                 loss: nan
agent1:                 episode reward: 0.1693,                 loss: 0.2536
Episode: 6041/10000 (60.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3615s / 305.9667 s
agent0:                 episode reward: -0.4460,                 loss: nan
agent1:                 episode reward: 0.4460,                 loss: 0.2529
Episode: 6061/10000 (60.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3238s / 307.2905 s
agent0:                 episode reward: 0.0005,                 loss: nan
agent1:                 episode reward: -0.0005,                 loss: 0.2530
Episode: 6081/10000 (60.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3616s / 308.6521 s
agent0:                 episode reward: -0.0721,                 loss: nan
agent1:                 episode reward: 0.0721,                 loss: 0.2276
Episode: 6101/10000 (61.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3290s / 309.9811 s
agent0:                 episode reward: 0.5605,                 loss: nan
agent1:                 episode reward: -0.5605,                 loss: 0.2191
Episode: 6121/10000 (61.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3285s / 311.3095 s
agent0:                 episode reward: 0.2125,                 loss: nan
agent1:                 episode reward: -0.2125,                 loss: 0.2197
Episode: 6141/10000 (61.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3501s / 312.6596 s
agent0:                 episode reward: 0.2658,                 loss: nan
agent1:                 episode reward: -0.2658,                 loss: 0.2184
Episode: 6161/10000 (61.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4419s / 314.1015 s
agent0:                 episode reward: -0.3361,                 loss: nan
agent1:                 episode reward: 0.3361,                 loss: 0.2170
Episode: 6181/10000 (61.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3403s / 315.4419 s
agent0:                 episode reward: 0.0002,                 loss: nan
agent1:                 episode reward: -0.0002,                 loss: 0.2074
Episode: 6201/10000 (62.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3494s / 316.7913 s
agent0:                 episode reward: -0.1110,                 loss: nan
agent1:                 episode reward: 0.1110,                 loss: 0.1997
Episode: 6221/10000 (62.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3426s / 318.1338 s
agent0:                 episode reward: -0.7389,                 loss: nan
agent1:                 episode reward: 0.7389,                 loss: 0.1993
Episode: 6241/10000 (62.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3404s / 319.4743 s
agent0:                 episode reward: -0.6448,                 loss: nan
agent1:                 episode reward: 0.6448,                 loss: 0.1975
Episode: 6261/10000 (62.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3590s / 320.8333 s
agent0:                 episode reward: -0.4140,                 loss: nan
agent1:                 episode reward: 0.4140,                 loss: 0.1983
Episode: 6281/10000 (62.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3720s / 322.2053 s
agent0:                 episode reward: 0.4238,                 loss: nan
agent1:                 episode reward: -0.4238,                 loss: 0.1724
Episode: 6301/10000 (63.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4155s / 323.6207 s
agent0:                 episode reward: -0.1158,                 loss: nan
agent1:                 episode reward: 0.1158,                 loss: 0.1570
Episode: 6321/10000 (63.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4047s / 325.0254 s
agent0:                 episode reward: -0.2757,                 loss: nan
agent1:                 episode reward: 0.2757,                 loss: 0.1534
Episode: 6341/10000 (63.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3591s / 326.3845 s
agent0:                 episode reward: -0.3370,                 loss: nan
agent1:                 episode reward: 0.3370,                 loss: 0.1529
Episode: 6361/10000 (63.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3708s / 327.7553 s
agent0:                 episode reward: 0.2595,                 loss: nan
agent1:                 episode reward: -0.2595,                 loss: 0.1536
Episode: 6381/10000 (63.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3635s / 329.1188 s
agent0:                 episode reward: -0.4679,                 loss: nan
agent1:                 episode reward: 0.4679,                 loss: 0.1751
Episode: 6401/10000 (64.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3975s / 330.5163 s
agent0:                 episode reward: -0.2812,                 loss: nan
agent1:                 episode reward: 0.2812,                 loss: 0.1712
Episode: 6421/10000 (64.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3757s / 331.8920 s
agent0:                 episode reward: 0.2784,                 loss: nan
agent1:                 episode reward: -0.2784,                 loss: 0.1714
Episode: 6441/10000 (64.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3887s / 333.2807 s
agent0:                 episode reward: 0.0593,                 loss: nan
agent1:                 episode reward: -0.0593,                 loss: 0.1709
Episode: 6461/10000 (64.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4292s / 334.7099 s
agent0:                 episode reward: -0.1052,                 loss: nan
agent1:                 episode reward: 0.1052,                 loss: 0.1689
Episode: 6481/10000 (64.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3904s / 336.1003 s
agent0:                 episode reward: 0.0015,                 loss: nan
agent1:                 episode reward: -0.0015,                 loss: 0.2543
Episode: 6501/10000 (65.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3977s / 337.4980 s
agent0:                 episode reward: -0.4269,                 loss: nan
agent1:                 episode reward: 0.4269,                 loss: 0.2593
Episode: 6521/10000 (65.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3979s / 338.8959 s
agent0:                 episode reward: -0.3765,                 loss: nan
agent1:                 episode reward: 0.3765,                 loss: 0.2589
Episode: 6541/10000 (65.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3781s / 340.2739 s
agent0:                 episode reward: 0.0107,                 loss: nan
agent1:                 episode reward: -0.0107,                 loss: 0.2579
Episode: 6561/10000 (65.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3746s / 341.6486 s
agent0:                 episode reward: -0.2198,                 loss: nan
agent1:                 episode reward: 0.2198,                 loss: 0.2563
Episode: 6581/10000 (65.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4034s / 343.0520 s
agent0:                 episode reward: 0.2767,                 loss: nan
agent1:                 episode reward: -0.2767,                 loss: 0.2315
Episode: 6601/10000 (66.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3844s / 344.4364 s
agent0:                 episode reward: -0.7135,                 loss: nan
agent1:                 episode reward: 0.7135,                 loss: 0.2225
Episode: 6621/10000 (66.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4500s / 345.8864 s
agent0:                 episode reward: -0.6185,                 loss: nan
agent1:                 episode reward: 0.6185,                 loss: 0.2220
Episode: 6641/10000 (66.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4624s / 347.3488 s
agent0:                 episode reward: -0.0887,                 loss: nan
agent1:                 episode reward: 0.0887,                 loss: 0.2227
Episode: 6661/10000 (66.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4216s / 348.7704 s
agent0:                 episode reward: 0.2494,                 loss: nan
agent1:                 episode reward: -0.2494,                 loss: 0.2213
Episode: 6681/10000 (66.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4180s / 350.1883 s
agent0:                 episode reward: -1.2647,                 loss: nan
agent1:                 episode reward: 1.2647,                 loss: 0.1965
Episode: 6701/10000 (67.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4079s / 351.5962 s
agent0:                 episode reward: -1.0072,                 loss: nan
agent1:                 episode reward: 1.0072,                 loss: 0.1835
Episode: 6721/10000 (67.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4364s / 353.0326 s
agent0:                 episode reward: -0.2271,                 loss: nan
agent1:                 episode reward: 0.2271,                 loss: 0.1844
Episode: 6741/10000 (67.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4438s / 354.4764 s
agent0:                 episode reward: -0.2183,                 loss: nan
agent1:                 episode reward: 0.2183,                 loss: 0.1827
Episode: 6761/10000 (67.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4754s / 355.9517 s
agent0:                 episode reward: -0.9113,                 loss: nan
agent1:                 episode reward: 0.9113,                 loss: 0.1830
Episode: 6781/10000 (67.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4471s / 357.3988 s
agent0:                 episode reward: -0.4656,                 loss: nan
agent1:                 episode reward: 0.4656,                 loss: 0.2029
Episode: 6801/10000 (68.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4674s / 358.8662 s
agent0:                 episode reward: -0.0350,                 loss: nan
agent1:                 episode reward: 0.0350,                 loss: 0.1993
Episode: 6821/10000 (68.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4281s / 360.2943 s
agent0:                 episode reward: -0.2921,                 loss: nan
agent1:                 episode reward: 0.2921,                 loss: 0.2006
Episode: 6841/10000 (68.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4106s / 361.7048 s
agent0:                 episode reward: -0.8197,                 loss: nan
agent1:                 episode reward: 0.8197,                 loss: 0.2002
Episode: 6861/10000 (68.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4432s / 363.1481 s
agent0:                 episode reward: -0.2406,                 loss: nan
agent1:                 episode reward: 0.2406,                 loss: 0.2010
Episode: 6881/10000 (68.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4379s / 364.5860 s
agent0:                 episode reward: -0.9756,                 loss: nan
agent1:                 episode reward: 0.9756,                 loss: 0.1896
Episode: 6901/10000 (69.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5403s / 366.1263 s
agent0:                 episode reward: -1.1834,                 loss: nan
agent1:                 episode reward: 1.1834,                 loss: 0.1866
Episode: 6921/10000 (69.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4297s / 367.5559 s
agent0:                 episode reward: -0.4029,                 loss: nan
agent1:                 episode reward: 0.4029,                 loss: 0.1854
Episode: 6941/10000 (69.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4489s / 369.0048 s
agent0:                 episode reward: -0.5862,                 loss: nan
agent1:                 episode reward: 0.5862,                 loss: 0.1830
Episode: 6961/10000 (69.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4286s / 370.4334 s
agent0:                 episode reward: -0.9310,                 loss: nan
agent1:                 episode reward: 0.9310,                 loss: 0.1821
Episode: 6981/10000 (69.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4620s / 371.8954 s
agent0:                 episode reward: -0.5377,                 loss: nan
agent1:                 episode reward: 0.5377,                 loss: 0.2484
Episode: 7001/10000 (70.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4753s / 373.3707 s
agent0:                 episode reward: 0.0448,                 loss: nan
agent1:                 episode reward: -0.0448,                 loss: 0.2519
Episode: 7021/10000 (70.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4807s / 374.8514 s
agent0:                 episode reward: 0.3608,                 loss: nan
agent1:                 episode reward: -0.3608,                 loss: 0.2500
Episode: 7041/10000 (70.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5658s / 376.4172 s
agent0:                 episode reward: -0.3220,                 loss: nan
agent1:                 episode reward: 0.3220,                 loss: 0.2511
Episode: 7061/10000 (70.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4988s / 377.9160 s
agent0:                 episode reward: -0.8507,                 loss: nan
agent1:                 episode reward: 0.8507,                 loss: 0.2502
Episode: 7081/10000 (70.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4646s / 379.3807 s
agent0:                 episode reward: -0.3155,                 loss: nan
agent1:                 episode reward: 0.3155,                 loss: 0.2319
Episode: 7101/10000 (71.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4869s / 380.8676 s
agent0:                 episode reward: -0.3691,                 loss: nan
agent1:                 episode reward: 0.3691,                 loss: 0.2227
Episode: 7121/10000 (71.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4620s / 382.3295 s
agent0:                 episode reward: 0.0064,                 loss: nan
agent1:                 episode reward: -0.0064,                 loss: 0.2246
Episode: 7141/10000 (71.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4763s / 383.8058 s
agent0:                 episode reward: -0.2353,                 loss: nan
agent1:                 episode reward: 0.2353,                 loss: 0.2226
Episode: 7161/10000 (71.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4852s / 385.2910 s
agent0:                 episode reward: -0.1177,                 loss: nan
agent1:                 episode reward: 0.1177,                 loss: 0.2233
Episode: 7181/10000 (71.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5297s / 386.8207 s
agent0:                 episode reward: 0.2797,                 loss: nan
agent1:                 episode reward: -0.2797,                 loss: 0.1978
Episode: 7201/10000 (72.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4873s / 388.3081 s
agent0:                 episode reward: -0.5781,                 loss: nan
agent1:                 episode reward: 0.5781,                 loss: 0.1875
Episode: 7221/10000 (72.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4832s / 389.7913 s
agent0:                 episode reward: -0.1371,                 loss: nan
agent1:                 episode reward: 0.1371,                 loss: 0.1872
Episode: 7241/10000 (72.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4818s / 391.2730 s
agent0:                 episode reward: -0.9254,                 loss: nan
agent1:                 episode reward: 0.9254,                 loss: 0.1883
Episode: 7261/10000 (72.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4934s / 392.7664 s
agent0:                 episode reward: -0.1066,                 loss: nan
agent1:                 episode reward: 0.1066,                 loss: 0.1882
Episode: 7281/10000 (72.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4926s / 394.2589 s
agent0:                 episode reward: -0.3142,                 loss: nan
agent1:                 episode reward: 0.3142,                 loss: 0.1875
Episode: 7301/10000 (73.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5624s / 395.8214 s
agent0:                 episode reward: 0.0455,                 loss: nan
agent1:                 episode reward: -0.0455,                 loss: 0.1817
Episode: 7321/10000 (73.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5405s / 397.3619 s
agent0:                 episode reward: -0.5583,                 loss: nan
agent1:                 episode reward: 0.5583,                 loss: 0.1811
Episode: 7341/10000 (73.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5066s / 398.8686 s
agent0:                 episode reward: 0.1769,                 loss: nan
agent1:                 episode reward: -0.1769,                 loss: 0.1799
Episode: 7361/10000 (73.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5027s / 400.3713 s
agent0:                 episode reward: -0.7044,                 loss: nan
agent1:                 episode reward: 0.7044,                 loss: 0.1800
Episode: 7381/10000 (73.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5297s / 401.9011 s
agent0:                 episode reward: -0.5436,                 loss: nan
agent1:                 episode reward: 0.5436,                 loss: 0.1985
Episode: 7401/10000 (74.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5249s / 403.4259 s
agent0:                 episode reward: -0.7069,                 loss: nan
agent1:                 episode reward: 0.7069,                 loss: 0.1983
Episode: 7421/10000 (74.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5203s / 404.9462 s
agent0:                 episode reward: -0.2515,                 loss: nan
agent1:                 episode reward: 0.2515,                 loss: 0.1957
Episode: 7441/10000 (74.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5642s / 406.5105 s
agent0:                 episode reward: -0.6004,                 loss: nan
agent1:                 episode reward: 0.6004,                 loss: 0.1962
Episode: 7461/10000 (74.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5256s / 408.0361 s
agent0:                 episode reward: -0.1275,                 loss: nan
agent1:                 episode reward: 0.1275,                 loss: 0.1941
Episode: 7481/10000 (74.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5105s / 409.5466 s
agent0:                 episode reward: -0.5295,                 loss: nan
agent1:                 episode reward: 0.5295,                 loss: 0.2595
Episode: 7501/10000 (75.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5412s / 411.0878 s
agent0:                 episode reward: -0.0413,                 loss: nan
agent1:                 episode reward: 0.0413,                 loss: 0.2624
Episode: 7521/10000 (75.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5594s / 412.6472 s
agent0:                 episode reward: -0.2135,                 loss: nan
agent1:                 episode reward: 0.2135,                 loss: 0.2571
Episode: 7541/10000 (75.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5981s / 414.2453 s
agent0:                 episode reward: -0.4777,                 loss: nan
agent1:                 episode reward: 0.4777,                 loss: 0.2577
Episode: 7561/10000 (75.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5537s / 415.7990 s
agent0:                 episode reward: -0.9562,                 loss: nan
agent1:                 episode reward: 0.9562,                 loss: 0.2574
Episode: 7581/10000 (75.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5884s / 417.3874 s
agent0:                 episode reward: -0.0006,                 loss: nan
agent1:                 episode reward: 0.0006,                 loss: 0.2560
Episode: 7601/10000 (76.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5270s / 418.9144 s
agent0:                 episode reward: -0.6682,                 loss: nan
agent1:                 episode reward: 0.6682,                 loss: 0.2461
Episode: 7621/10000 (76.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5339s / 420.4483 s
agent0:                 episode reward: -0.2533,                 loss: nan
agent1:                 episode reward: 0.2533,                 loss: 0.2480
Episode: 7641/10000 (76.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5778s / 422.0261 s
agent0:                 episode reward: -0.2400,                 loss: nan
agent1:                 episode reward: 0.2400,                 loss: 0.2451
Episode: 7661/10000 (76.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5575s / 423.5836 s
agent0:                 episode reward: -0.6367,                 loss: nan
agent1:                 episode reward: 0.6367,                 loss: 0.2464
Episode: 7681/10000 (76.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5552s / 425.1388 s
agent0:                 episode reward: -0.7744,                 loss: nan
agent1:                 episode reward: 0.7744,                 loss: 0.2051
Episode: 7701/10000 (77.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6347s / 426.7735 s
agent0:                 episode reward: 0.0968,                 loss: nan
agent1:                 episode reward: -0.0968,                 loss: 0.1910
Episode: 7721/10000 (77.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5886s / 428.3621 s
agent0:                 episode reward: -0.2049,                 loss: nan
agent1:                 episode reward: 0.2049,                 loss: 0.1914
Episode: 7741/10000 (77.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5714s / 429.9335 s
agent0:                 episode reward: -1.1302,                 loss: nan
agent1:                 episode reward: 1.1302,                 loss: 0.1916
Episode: 7761/10000 (77.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5731s / 431.5066 s
agent0:                 episode reward: -0.2645,                 loss: nan
agent1:                 episode reward: 0.2645,                 loss: 0.1918
Episode: 7781/10000 (77.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5852s / 433.0918 s
agent0:                 episode reward: -0.1570,                 loss: nan
agent1:                 episode reward: 0.1570,                 loss: 0.1801
Episode: 7801/10000 (78.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5975s / 434.6894 s
agent0:                 episode reward: -0.4877,                 loss: nan
agent1:                 episode reward: 0.4877,                 loss: 0.1691
Episode: 7821/10000 (78.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5879s / 436.2773 s
agent0:                 episode reward: -0.6628,                 loss: nan
agent1:                 episode reward: 0.6628,                 loss: 0.1655
Episode: 7841/10000 (78.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6719s / 437.9491 s
agent0:                 episode reward: -0.9250,                 loss: nan
agent1:                 episode reward: 0.9250,                 loss: 0.1665
Episode: 7861/10000 (78.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6366s / 439.5857 s
agent0:                 episode reward: -0.2152,                 loss: nan
agent1:                 episode reward: 0.2152,                 loss: 0.1660
Episode: 7881/10000 (78.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6214s / 441.2071 s
agent0:                 episode reward: -0.8741,                 loss: nan
agent1:                 episode reward: 0.8741,                 loss: 0.1765
Episode: 7901/10000 (79.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6120s / 442.8191 s
agent0:                 episode reward: -1.0123,                 loss: nan
agent1:                 episode reward: 1.0123,                 loss: 0.1696
Episode: 7921/10000 (79.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6271s / 444.4462 s
agent0:                 episode reward: -0.3863,                 loss: nan
agent1:                 episode reward: 0.3863,                 loss: 0.1680
Episode: 7941/10000 (79.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5997s / 446.0458 s
agent0:                 episode reward: -0.0539,                 loss: nan
agent1:                 episode reward: 0.0539,                 loss: 0.1674
Episode: 7961/10000 (79.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6618s / 447.7077 s
agent0:                 episode reward: 0.1035,                 loss: nan
agent1:                 episode reward: -0.1035,                 loss: 0.1668
Episode: 7981/10000 (79.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5982s / 449.3058 s
agent0:                 episode reward: -0.4423,                 loss: nan
agent1:                 episode reward: 0.4423,                 loss: 0.2421
Episode: 8001/10000 (80.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6060s / 450.9118 s
agent0:                 episode reward: -0.7818,                 loss: nan
agent1:                 episode reward: 0.7818,                 loss: 0.2476
Episode: 8021/10000 (80.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5921s / 452.5039 s
agent0:                 episode reward: -0.5476,                 loss: nan
agent1:                 episode reward: 0.5476,                 loss: 0.2465
Episode: 8041/10000 (80.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6105s / 454.1144 s
agent0:                 episode reward: -0.7147,                 loss: nan
agent1:                 episode reward: 0.7147,                 loss: 0.2431
Episode: 8061/10000 (80.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6938s / 455.8082 s
agent0:                 episode reward: -0.7542,                 loss: nan
agent1:                 episode reward: 0.7542,                 loss: 0.2419
Episode: 8081/10000 (80.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6700s / 457.4782 s
agent0:                 episode reward: -1.0181,                 loss: nan
agent1:                 episode reward: 1.0181,                 loss: 0.2143
Episode: 8101/10000 (81.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6509s / 459.1291 s
agent0:                 episode reward: -0.8499,                 loss: nan
agent1:                 episode reward: 0.8499,                 loss: 0.2042
Episode: 8121/10000 (81.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6072s / 460.7363 s
agent0:                 episode reward: -0.6746,                 loss: nan
agent1:                 episode reward: 0.6746,                 loss: 0.2048
Episode: 8141/10000 (81.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6161s / 462.3524 s
agent0:                 episode reward: -0.5180,                 loss: nan
agent1:                 episode reward: 0.5180,                 loss: 0.2054
Episode: 8161/10000 (81.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6298s / 463.9822 s
agent0:                 episode reward: -0.4034,                 loss: nan
agent1:                 episode reward: 0.4034,                 loss: 0.2058
Episode: 8181/10000 (81.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6337s / 465.6158 s
agent0:                 episode reward: -1.2178,                 loss: nan
agent1:                 episode reward: 1.2178,                 loss: 0.1820
Episode: 8201/10000 (82.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6135s / 467.2294 s
agent0:                 episode reward: 0.3035,                 loss: nan
agent1:                 episode reward: -0.3035,                 loss: 0.1711
Episode: 8221/10000 (82.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7001s / 468.9295 s
agent0:                 episode reward: -0.2088,                 loss: nan
agent1:                 episode reward: 0.2088,                 loss: 0.1723
Episode: 8241/10000 (82.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6557s / 470.5852 s
agent0:                 episode reward: -0.4569,                 loss: nan
agent1:                 episode reward: 0.4569,                 loss: 0.1701
Episode: 8261/10000 (82.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6553s / 472.2406 s
agent0:                 episode reward: -0.8341,                 loss: nan
agent1:                 episode reward: 0.8341,                 loss: 0.1706
Episode: 8281/10000 (82.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6429s / 473.8835 s
agent0:                 episode reward: -0.9778,                 loss: nan
agent1:                 episode reward: 0.9778,                 loss: 0.1782
Episode: 8301/10000 (83.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6401s / 475.5236 s
agent0:                 episode reward: -0.9995,                 loss: nan
agent1:                 episode reward: 0.9995,                 loss: 0.1776
Episode: 8321/10000 (83.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6561s / 477.1797 s
agent0:                 episode reward: -0.6049,                 loss: nan
agent1:                 episode reward: 0.6049,                 loss: 0.1782
Episode: 8341/10000 (83.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6896s / 478.8693 s
agent0:                 episode reward: -0.3975,                 loss: nan
agent1:                 episode reward: 0.3975,                 loss: 0.1771
Episode: 8361/10000 (83.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6558s / 480.5251 s
agent0:                 episode reward: -0.5748,                 loss: nan
agent1:                 episode reward: 0.5748,                 loss: 0.1762
Episode: 8381/10000 (83.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6488s / 482.1739 s
agent0:                 episode reward: -0.4735,                 loss: nan
agent1:                 episode reward: 0.4735,                 loss: 0.2479
Episode: 8401/10000 (84.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6619s / 483.8358 s
agent0:                 episode reward: -0.8630,                 loss: nan
agent1:                 episode reward: 0.8630,                 loss: 0.2572
Episode: 8421/10000 (84.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6775s / 485.5134 s
agent0:                 episode reward: 0.2087,                 loss: nan
agent1:                 episode reward: -0.2087,                 loss: 0.2562
Episode: 8441/10000 (84.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6715s / 487.1849 s
agent0:                 episode reward: -0.3507,                 loss: nan
agent1:                 episode reward: 0.3507,                 loss: 0.2554
Episode: 8461/10000 (84.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7388s / 488.9237 s
agent0:                 episode reward: -0.5628,                 loss: nan
agent1:                 episode reward: 0.5628,                 loss: 0.2544
Episode: 8481/10000 (84.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6751s / 490.5988 s
agent0:                 episode reward: -0.9530,                 loss: nan
agent1:                 episode reward: 0.9530,                 loss: 0.2660
Episode: 8501/10000 (85.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6780s / 492.2768 s
agent0:                 episode reward: -1.2164,                 loss: nan
agent1:                 episode reward: 1.2164,                 loss: 0.2624
Episode: 8521/10000 (85.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6673s / 493.9442 s
agent0:                 episode reward: -0.8279,                 loss: nan
agent1:                 episode reward: 0.8279,                 loss: 0.2612
Episode: 8541/10000 (85.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6968s / 495.6410 s
agent0:                 episode reward: -0.6546,                 loss: nan
agent1:                 episode reward: 0.6546,                 loss: 0.2612
Episode: 8561/10000 (85.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7100s / 497.3511 s
agent0:                 episode reward: -0.6502,                 loss: nan
agent1:                 episode reward: 0.6502,                 loss: 0.2614
Episode: 8581/10000 (85.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7282s / 499.0792 s
agent0:                 episode reward: -0.6071,                 loss: nan
agent1:                 episode reward: 0.6071,                 loss: 0.2433
Episode: 8601/10000 (86.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6751s / 500.7543 s
agent0:                 episode reward: -0.4564,                 loss: nan
agent1:                 episode reward: 0.4564,                 loss: 0.2338
Episode: 8621/10000 (86.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6792s / 502.4335 s
agent0:                 episode reward: -0.8659,                 loss: nan
agent1:                 episode reward: 0.8659,                 loss: 0.2346
Episode: 8641/10000 (86.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6752s / 504.1087 s
agent0:                 episode reward: -0.8993,                 loss: nan
agent1:                 episode reward: 0.8993,                 loss: 0.2355
Episode: 8661/10000 (86.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7527s / 505.8614 s
agent0:                 episode reward: -0.4215,                 loss: nan
agent1:                 episode reward: 0.4215,                 loss: 0.2329
Episode: 8681/10000 (86.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7327s / 507.5941 s
agent0:                 episode reward: -1.0037,                 loss: nan
agent1:                 episode reward: 1.0037,                 loss: 0.2111
Episode: 8701/10000 (87.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7835s / 509.3776 s
agent0:                 episode reward: -0.5618,                 loss: nan
agent1:                 episode reward: 0.5618,                 loss: 0.2010
Episode: 8721/10000 (87.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7799s / 511.1575 s
agent0:                 episode reward: -0.5371,                 loss: nan
agent1:                 episode reward: 0.5371,                 loss: 0.2018
Episode: 8741/10000 (87.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7121s / 512.8696 s
agent0:                 episode reward: -1.2985,                 loss: nan
agent1:                 episode reward: 1.2985,                 loss: 0.2003
Episode: 8761/10000 (87.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7689s / 514.6385 s
agent0:                 episode reward: 0.1071,                 loss: nan
agent1:                 episode reward: -0.1071,                 loss: 0.2015
Episode: 8781/10000 (87.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7473s / 516.3858 s
agent0:                 episode reward: -0.6761,                 loss: nan
agent1:                 episode reward: 0.6761,                 loss: 0.2068
Episode: 8801/10000 (88.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7291s / 518.1150 s
agent0:                 episode reward: -0.7179,                 loss: nan
agent1:                 episode reward: 0.7179,                 loss: 0.1991
Episode: 8821/10000 (88.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7977s / 519.9127 s
agent0:                 episode reward: -0.4872,                 loss: nan
agent1:                 episode reward: 0.4872,                 loss: 0.1989
Episode: 8841/10000 (88.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7751s / 521.6878 s
agent0:                 episode reward: -0.5154,                 loss: nan
agent1:                 episode reward: 0.5154,                 loss: 0.2014
Episode: 8861/10000 (88.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7332s / 523.4210 s
agent0:                 episode reward: -1.0542,                 loss: nan
agent1:                 episode reward: 1.0542,                 loss: 0.1986
Episode: 8881/10000 (88.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7381s / 525.1592 s
agent0:                 episode reward: -0.5648,                 loss: nan
agent1:                 episode reward: 0.5648,                 loss: 0.1950
Episode: 8901/10000 (89.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7431s / 526.9023 s
agent0:                 episode reward: -0.2760,                 loss: nan
agent1:                 episode reward: 0.2760,                 loss: 0.1891
Episode: 8921/10000 (89.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7571s / 528.6594 s
agent0:                 episode reward: -1.0548,                 loss: nan
agent1:                 episode reward: 1.0548,                 loss: 0.1896
Episode: 8941/10000 (89.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7983s / 530.4577 s
agent0:                 episode reward: -0.0739,                 loss: nan
agent1:                 episode reward: 0.0739,                 loss: 0.1889
Episode: 8961/10000 (89.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7337s / 532.1914 s
agent0:                 episode reward: -1.2387,                 loss: nan
agent1:                 episode reward: 1.2387,                 loss: 0.1876
Episode: 8981/10000 (89.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7408s / 533.9323 s
agent0:                 episode reward: -0.2852,                 loss: nan
agent1:                 episode reward: 0.2852,                 loss: 0.1897
Episode: 9001/10000 (90.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7998s / 535.7320 s
agent0:                 episode reward: -0.7483,                 loss: nan
agent1:                 episode reward: 0.7483,                 loss: 0.1873
Episode: 9021/10000 (90.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7745s / 537.5066 s
agent0:                 episode reward: -0.6904,                 loss: nan
agent1:                 episode reward: 0.6904,                 loss: 0.1853
Episode: 9041/10000 (90.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8137s / 539.3203 s
agent0:                 episode reward: -0.2182,                 loss: nan
agent1:                 episode reward: 0.2182,                 loss: 0.1872
Episode: 9061/10000 (90.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7801s / 541.1004 s
agent0:                 episode reward: -0.1912,                 loss: nan
agent1:                 episode reward: 0.1912,                 loss: 0.1857
Episode: 9081/10000 (90.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7602s / 542.8606 s
agent0:                 episode reward: -0.4142,                 loss: nan
agent1:                 episode reward: 0.4142,                 loss: 0.1693
Episode: 9101/10000 (91.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7764s / 544.6370 s
agent0:                 episode reward: -1.0339,                 loss: nan
agent1:                 episode reward: 1.0339,                 loss: 0.1585
Episode: 9121/10000 (91.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8017s / 546.4387 s
agent0:                 episode reward: -0.6524,                 loss: nan
agent1:                 episode reward: 0.6524,                 loss: 0.1568
Episode: 9141/10000 (91.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8037s / 548.2425 s
agent0:                 episode reward: -1.2666,                 loss: nan
agent1:                 episode reward: 1.2666,                 loss: 0.1561
Episode: 9161/10000 (91.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8532s / 550.0957 s
agent0:                 episode reward: -0.7027,                 loss: nan
agent1:                 episode reward: 0.7027,                 loss: 0.1565
Episode: 9181/10000 (91.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7911s / 551.8868 s
agent0:                 episode reward: -0.5579,                 loss: nan
agent1:                 episode reward: 0.5579,                 loss: 0.1752
Episode: 9201/10000 (92.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7652s / 553.6520 s
agent0:                 episode reward: -1.3267,                 loss: nan
agent1:                 episode reward: 1.3267,                 loss: 0.1716
Episode: 9221/10000 (92.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7927s / 555.4447 s
agent0:                 episode reward: -0.9815,                 loss: nan
agent1:                 episode reward: 0.9815,                 loss: 0.1715
Episode: 9241/10000 (92.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8393s / 557.2840 s
agent0:                 episode reward: -0.9283,                 loss: nan
agent1:                 episode reward: 0.9283,                 loss: 0.1728
Episode: 9261/10000 (92.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7989s / 559.0830 s
agent0:                 episode reward: -0.7132,                 loss: nan
agent1:                 episode reward: 0.7132,                 loss: 0.1712
Episode: 9281/10000 (92.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8305s / 560.9135 s
agent0:                 episode reward: -0.7456,                 loss: nan
agent1:                 episode reward: 0.7456,                 loss: 0.2548
Episode: 9301/10000 (93.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8011s / 562.7146 s
agent0:                 episode reward: -1.0578,                 loss: nan
agent1:                 episode reward: 1.0578,                 loss: 0.2634
Episode: 9321/10000 (93.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8162s / 564.5309 s
agent0:                 episode reward: -0.9104,                 loss: nan
agent1:                 episode reward: 0.9104,                 loss: 0.2619
Episode: 9341/10000 (93.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8036s / 566.3345 s
agent0:                 episode reward: -0.1629,                 loss: nan
agent1:                 episode reward: 0.1629,                 loss: 0.2638
Episode: 9361/10000 (93.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8103s / 568.1448 s
agent0:                 episode reward: -0.3345,                 loss: nan
agent1:                 episode reward: 0.3345,                 loss: 0.2611
Episode: 9381/10000 (93.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8273s / 569.9721 s
agent0:                 episode reward: -0.5526,                 loss: nan
agent1:                 episode reward: 0.5526,                 loss: 0.2686
Episode: 9401/10000 (94.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8434s / 571.8155 s
agent0:                 episode reward: -0.3803,                 loss: nan
agent1:                 episode reward: 0.3803,                 loss: 0.2632
Episode: 9421/10000 (94.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8160s / 573.6316 s
agent0:                 episode reward: -0.4010,                 loss: nan
agent1:                 episode reward: 0.4010,                 loss: 0.2637
Episode: 9441/10000 (94.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8085s / 575.4400 s
agent0:                 episode reward: -0.9860,                 loss: nan
agent1:                 episode reward: 0.9860,                 loss: 0.2618
Episode: 9461/10000 (94.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8071s / 577.2472 s
agent0:                 episode reward: -1.2392,                 loss: nan
agent1:                 episode reward: 1.2392,                 loss: 0.2613
Episode: 9481/10000 (94.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8020s / 579.0491 s
agent0:                 episode reward: -0.7816,                 loss: nan
agent1:                 episode reward: 0.7816,                 loss: 0.2650
Episode: 9501/10000 (95.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8862s / 580.9354 s
agent0:                 episode reward: -1.1473,                 loss: nan
agent1:                 episode reward: 1.1473,                 loss: 0.2583
Episode: 9521/10000 (95.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8439s / 582.7793 s
agent0:                 episode reward: -0.3203,                 loss: nan
agent1:                 episode reward: 0.3203,                 loss: 0.2593
Episode: 9541/10000 (95.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8325s / 584.6119 s
agent0:                 episode reward: -0.5533,                 loss: nan
agent1:                 episode reward: 0.5533,                 loss: 0.2599
Episode: 9561/10000 (95.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8540s / 586.4659 s
agent0:                 episode reward: -0.3840,                 loss: nan
agent1:                 episode reward: 0.3840,                 loss: 0.2577
Episode: 9581/10000 (95.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8754s / 588.3413 s
agent0:                 episode reward: 0.1711,                 loss: nan
agent1:                 episode reward: -0.1711,                 loss: 0.2272
Episode: 9601/10000 (96.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8430s / 590.1844 s
agent0:                 episode reward: -0.0422,                 loss: nan
agent1:                 episode reward: 0.0422,                 loss: 0.2162
Episode: 9621/10000 (96.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9137s / 592.0981 s
agent0:                 episode reward: -0.8306,                 loss: nan
agent1:                 episode reward: 0.8306,                 loss: 0.2172
Episode: 9641/10000 (96.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8686s / 593.9667 s
agent0:                 episode reward: -0.4237,                 loss: nan
agent1:                 episode reward: 0.4237,                 loss: 0.2181
Episode: 9661/10000 (96.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8793s / 595.8460 s
agent0:                 episode reward: -0.8710,                 loss: nan
agent1:                 episode reward: 0.8710,                 loss: 0.2170
Episode: 9681/10000 (96.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8992s / 597.7452 s
agent0:                 episode reward: -0.9493,                 loss: nan
agent1:                 episode reward: 0.9493,                 loss: 0.1999
Episode: 9701/10000 (97.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8635s / 599.6087 s
agent0:                 episode reward: -1.0391,                 loss: nan
agent1:                 episode reward: 1.0391,                 loss: 0.1945
Episode: 9721/10000 (97.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8888s / 601.4975 s
agent0:                 episode reward: -0.4285,                 loss: nan
agent1:                 episode reward: 0.4285,                 loss: 0.1960
Episode: 9741/10000 (97.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8521s / 603.3496 s
agent0:                 episode reward: -0.7199,                 loss: nan
agent1:                 episode reward: 0.7199,                 loss: 0.1949
Episode: 9761/10000 (97.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8785s / 605.2281 s
agent0:                 episode reward: -1.0647,                 loss: nan
agent1:                 episode reward: 1.0647,                 loss: 0.1939/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

Episode: 9781/10000 (97.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8905s / 607.1186 s
agent0:                 episode reward: -1.1121,                 loss: nan
agent1:                 episode reward: 1.1121,                 loss: 0.1867
Episode: 9801/10000 (98.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8582s / 608.9769 s
agent0:                 episode reward: -1.0947,                 loss: nan
agent1:                 episode reward: 1.0947,                 loss: 0.1833
Episode: 9821/10000 (98.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8800s / 610.8569 s
agent0:                 episode reward: -0.7386,                 loss: nan
agent1:                 episode reward: 0.7386,                 loss: 0.1837
Episode: 9841/10000 (98.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9284s / 612.7852 s
agent0:                 episode reward: -1.2084,                 loss: nan
agent1:                 episode reward: 1.2084,                 loss: 0.1841
Episode: 9861/10000 (98.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8620s / 614.6472 s
agent0:                 episode reward: -0.9244,                 loss: nan
agent1:                 episode reward: 0.9244,                 loss: 0.1843
Episode: 9881/10000 (98.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8756s / 616.5227 s
agent0:                 episode reward: -0.5897,                 loss: nan
agent1:                 episode reward: 0.5897,                 loss: 0.1837
Episode: 9901/10000 (99.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8964s / 618.4192 s
agent0:                 episode reward: -0.8910,                 loss: nan
agent1:                 episode reward: 0.8910,                 loss: 0.1822
Episode: 9921/10000 (99.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8951s / 620.3142 s
agent0:                 episode reward: -0.8687,                 loss: nan
agent1:                 episode reward: 0.8687,                 loss: 0.1830
Episode: 9941/10000 (99.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9826s / 622.2968 s
agent0:                 episode reward: -0.3142,                 loss: nan
agent1:                 episode reward: 0.3142,                 loss: 0.1830
Episode: 9961/10000 (99.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9310s / 624.2278 s
agent0:                 episode reward: -0.0580,                 loss: nan
agent1:                 episode reward: 0.0580,                 loss: 0.1822
Episode: 9981/10000 (99.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9343s / 626.1621 s
agent0:                 episode reward: -1.2524,                 loss: nan
agent1:                 episode reward: 1.2524,                 loss: 0.1774
