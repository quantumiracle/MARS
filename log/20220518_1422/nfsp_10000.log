pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 12.0, (1,), float32) action space: Discrete(3)
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7fd973592ba8>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
Error: no exploited model index given!
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  data/model/20220518033032/mdp_arbitrary_mdp_nfsp/10000_0
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': '1i', 'algorithm': 'NFSP', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.0, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 640, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 10000, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220518033032/mdp_arbitrary_mdp_nfsp/10000_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False, 'policy': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': 'Softmax'}}, 'marl_method': 'nfsp', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'eta': 0.1}, 'against_baseline': False}
Save models to : /home/zihan/research/MARS/data/model/20220518033032_exploit_10000/mdp_arbitrary_mdp_nfsp. 
 Save logs to: /home/zihan/research/MARS/data/log/20220518033032_exploit_10000/mdp_arbitrary_mdp_nfsp.
Episode: 1/30000 (0.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7167s / 0.7167 s
agent0:                 episode reward: -0.9323,                 loss: nan
agent1:                 episode reward: 0.9323,                 loss: nan
Episode: 21/30000 (0.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1929s / 0.9096 s
agent0:                 episode reward: -0.2722,                 loss: nan
agent1:                 episode reward: 0.2722,                 loss: nan
Episode: 41/30000 (0.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1977s / 1.1073 s
agent0:                 episode reward: 0.0684,                 loss: nan
agent1:                 episode reward: -0.0684,                 loss: nan
Episode: 61/30000 (0.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1932s / 1.3004 s
agent0:                 episode reward: -0.2640,                 loss: nan
agent1:                 episode reward: 0.2640,                 loss: nan
Episode: 81/30000 (0.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1942s / 1.4947 s
agent0:                 episode reward: -0.1522,                 loss: nan
agent1:                 episode reward: 0.1522,                 loss: nan
Episode: 101/30000 (0.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1943s / 1.6889 s
agent0:                 episode reward: -0.3409,                 loss: nan
agent1:                 episode reward: 0.3409,                 loss: nan
Episode: 121/30000 (0.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1958s / 1.8847 s
agent0:                 episode reward: -0.2123,                 loss: nan
agent1:                 episode reward: 0.2123,                 loss: nan
Episode: 141/30000 (0.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2011s / 2.0859 s
agent0:                 episode reward: -0.3028,                 loss: nan
agent1:                 episode reward: 0.3028,                 loss: nan
Episode: 161/30000 (0.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1966s / 2.2825 s
agent0:                 episode reward: -0.4298,                 loss: nan
agent1:                 episode reward: 0.4298,                 loss: nan
Episode: 181/30000 (0.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1940s / 2.4765 s
agent0:                 episode reward: 0.1982,                 loss: nan
agent1:                 episode reward: -0.1982,                 loss: nan
Episode: 201/30000 (0.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1971s / 2.6736 s
agent0:                 episode reward: -0.0086,                 loss: nan
agent1:                 episode reward: 0.0086,                 loss: nan
Episode: 221/30000 (0.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1960s / 2.8696 s
agent0:                 episode reward: -0.3237,                 loss: nan
agent1:                 episode reward: 0.3237,                 loss: nan
Episode: 241/30000 (0.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2011s / 3.0707 s
agent0:                 episode reward: -0.2879,                 loss: nan
agent1:                 episode reward: 0.2879,                 loss: nan
Episode: 261/30000 (0.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1988s / 3.2694 s
agent0:                 episode reward: -0.5960,                 loss: nan
agent1:                 episode reward: 0.5960,                 loss: nan
Episode: 281/30000 (0.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1979s / 3.4673 s
agent0:                 episode reward: -0.1068,                 loss: nan
agent1:                 episode reward: 0.1068,                 loss: nan
Episode: 301/30000 (1.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1986s / 3.6659 s
agent0:                 episode reward: 0.1819,                 loss: nan
agent1:                 episode reward: -0.1819,                 loss: nan
Episode: 321/30000 (1.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1982s / 3.8640 s
agent0:                 episode reward: -0.2555,                 loss: nan
agent1:                 episode reward: 0.2555,                 loss: nan
Episode: 341/30000 (1.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1969s / 4.0609 s
agent0:                 episode reward: -0.1807,                 loss: nan
agent1:                 episode reward: 0.1807,                 loss: nan
Episode: 361/30000 (1.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1942s / 4.2551 s
agent0:                 episode reward: -0.3194,                 loss: nan
agent1:                 episode reward: 0.3194,                 loss: nan
Episode: 381/30000 (1.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1984s / 4.4535 s
agent0:                 episode reward: -0.3405,                 loss: nan
agent1:                 episode reward: 0.3405,                 loss: nan
Episode: 401/30000 (1.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1947s / 4.6482 s
agent0:                 episode reward: -0.2043,                 loss: nan
agent1:                 episode reward: 0.2043,                 loss: nan
Episode: 421/30000 (1.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1979s / 4.8460 s
agent0:                 episode reward: -0.5800,                 loss: nan
agent1:                 episode reward: 0.5800,                 loss: nan
Episode: 441/30000 (1.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1994s / 5.0455 s
agent0:                 episode reward: -0.4139,                 loss: nan
agent1:                 episode reward: 0.4139,                 loss: nan
Episode: 461/30000 (1.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1974s / 5.2428 s
agent0:                 episode reward: -0.3275,                 loss: nan
agent1:                 episode reward: 0.3275,                 loss: nan
Episode: 481/30000 (1.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1998s / 5.4426 s
agent0:                 episode reward: 0.0471,                 loss: nan
agent1:                 episode reward: -0.0471,                 loss: nan
Episode: 501/30000 (1.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2006s / 5.6432 s
agent0:                 episode reward: -0.5040,                 loss: nan
agent1:                 episode reward: 0.5040,                 loss: nan
Episode: 521/30000 (1.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1934s / 5.8366 s
agent0:                 episode reward: -0.2582,                 loss: nan
agent1:                 episode reward: 0.2582,                 loss: nan
Episode: 541/30000 (1.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1990s / 6.0356 s
agent0:                 episode reward: -0.0662,                 loss: nan
agent1:                 episode reward: 0.0662,                 loss: nan
Episode: 561/30000 (1.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1973s / 6.2329 s
agent0:                 episode reward: -0.4301,                 loss: nan
agent1:                 episode reward: 0.4301,                 loss: nan
Episode: 581/30000 (1.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1996s / 6.4325 s
agent0:                 episode reward: -0.2064,                 loss: nan
agent1:                 episode reward: 0.2064,                 loss: nan
Episode: 601/30000 (2.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1991s / 6.6315 s
agent0:                 episode reward: -0.5316,                 loss: nan
agent1:                 episode reward: 0.5316,                 loss: nan
Episode: 621/30000 (2.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1979s / 6.8294 s
agent0:                 episode reward: -0.0922,                 loss: nan
agent1:                 episode reward: 0.0922,                 loss: nan
Episode: 641/30000 (2.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1989s / 7.0283 s
agent0:                 episode reward: 0.2003,                 loss: nan
agent1:                 episode reward: -0.2003,                 loss: nan
Episode: 661/30000 (2.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1999s / 7.2282 s
agent0:                 episode reward: -0.0270,                 loss: nan
agent1:                 episode reward: 0.0270,                 loss: nan
Episode: 681/30000 (2.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2002s / 7.4284 s
agent0:                 episode reward: -0.4927,                 loss: nan
agent1:                 episode reward: 0.4927,                 loss: nan
Episode: 701/30000 (2.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1979s / 7.6263 s
agent0:                 episode reward: 0.2101,                 loss: nan
agent1:                 episode reward: -0.2101,                 loss: nan
Episode: 721/30000 (2.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1962s / 7.8225 s
agent0:                 episode reward: -0.4613,                 loss: nan
agent1:                 episode reward: 0.4613,                 loss: nan
Episode: 741/30000 (2.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1951s / 8.0177 s
agent0:                 episode reward: -0.1353,                 loss: nan
agent1:                 episode reward: 0.1353,                 loss: nan
Episode: 761/30000 (2.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2009s / 8.2185 s
agent0:                 episode reward: -0.1920,                 loss: nan
agent1:                 episode reward: 0.1920,                 loss: nan
Episode: 781/30000 (2.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1986s / 8.4172 s
agent0:                 episode reward: -0.1703,                 loss: nan
agent1:                 episode reward: 0.1703,                 loss: nan
Episode: 801/30000 (2.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1986s / 8.6158 s
agent0:                 episode reward: -0.4286,                 loss: nan
agent1:                 episode reward: 0.4286,                 loss: nan
Episode: 821/30000 (2.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1907s / 8.8066 s
agent0:                 episode reward: -0.3864,                 loss: nan
agent1:                 episode reward: 0.3864,                 loss: nan
Episode: 841/30000 (2.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2001s / 9.0067 s
agent0:                 episode reward: -0.2227,                 loss: nan
agent1:                 episode reward: 0.2227,                 loss: nan
Episode: 861/30000 (2.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1958s / 9.2025 s
agent0:                 episode reward: -0.2321,                 loss: nan
agent1:                 episode reward: 0.2321,                 loss: nan
Episode: 881/30000 (2.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1944s / 9.3969 s
agent0:                 episode reward: -0.5181,                 loss: nan
agent1:                 episode reward: 0.5181,                 loss: nan
Episode: 901/30000 (3.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1948s / 9.5917 s
agent0:                 episode reward: -0.0372,                 loss: nan
agent1:                 episode reward: 0.0372,                 loss: nan
Episode: 921/30000 (3.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1963s / 9.7880 s
agent0:                 episode reward: -0.0746,                 loss: nan
agent1:                 episode reward: 0.0746,                 loss: nan
Episode: 941/30000 (3.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2007s / 9.9887 s
agent0:                 episode reward: -0.5691,                 loss: nan
agent1:                 episode reward: 0.5691,                 loss: nan
Episode: 961/30000 (3.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1955s / 10.1842 s
agent0:                 episode reward: -0.1312,                 loss: nan
agent1:                 episode reward: 0.1312,                 loss: nan
Episode: 981/30000 (3.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2033s / 10.3874 s
agent0:                 episode reward: -0.2127,                 loss: nan
agent1:                 episode reward: 0.2127,                 loss: nan
Episode: 1001/30000 (3.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2013s / 10.5888 s
agent0:                 episode reward: -0.0710,                 loss: nan
agent1:                 episode reward: 0.0710,                 loss: nan
Episode: 1021/30000 (3.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1984s / 10.7871 s
agent0:                 episode reward: -0.2010,                 loss: nan
agent1:                 episode reward: 0.2010,                 loss: nan
Episode: 1041/30000 (3.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1963s / 10.9834 s
agent0:                 episode reward: -0.2424,                 loss: nan
agent1:                 episode reward: 0.2424,                 loss: nan
Episode: 1061/30000 (3.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1950s / 11.1785 s
agent0:                 episode reward: -0.4293,                 loss: nan
agent1:                 episode reward: 0.4293,                 loss: nan
Episode: 1081/30000 (3.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1948s / 11.3733 s
agent0:                 episode reward: -0.1207,                 loss: nan
agent1:                 episode reward: 0.1207,                 loss: nan
Episode: 1101/30000 (3.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1944s / 11.5677 s
agent0:                 episode reward: -0.6212,                 loss: nan
agent1:                 episode reward: 0.6212,                 loss: nan
Episode: 1121/30000 (3.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2011s / 11.7688 s
agent0:                 episode reward: -0.2577,                 loss: nan
agent1:                 episode reward: 0.2577,                 loss: nan
Episode: 1141/30000 (3.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1926s / 11.9614 s
agent0:                 episode reward: -0.4157,                 loss: nan
agent1:                 episode reward: 0.4157,                 loss: nan
Episode: 1161/30000 (3.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1973s / 12.1587 s
agent0:                 episode reward: -0.3334,                 loss: nan
agent1:                 episode reward: 0.3334,                 loss: nan
Episode: 1181/30000 (3.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1939s / 12.3526 s
agent0:                 episode reward: -0.3354,                 loss: nan
agent1:                 episode reward: 0.3354,                 loss: nan
Episode: 1201/30000 (4.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1984s / 12.5510 s
agent0:                 episode reward: -0.5258,                 loss: nan
agent1:                 episode reward: 0.5258,                 loss: nan
Episode: 1221/30000 (4.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1978s / 12.7488 s
agent0:                 episode reward: -0.2581,                 loss: nan
agent1:                 episode reward: 0.2581,                 loss: nan
Episode: 1241/30000 (4.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2006s / 12.9495 s
agent0:                 episode reward: -0.2271,                 loss: nan
agent1:                 episode reward: 0.2271,                 loss: nan
Episode: 1261/30000 (4.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1935s / 13.1430 s
agent0:                 episode reward: -0.3940,                 loss: nan
agent1:                 episode reward: 0.3940,                 loss: nan
Episode: 1281/30000 (4.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1970s / 13.3400 s
agent0:                 episode reward: -0.5360,                 loss: nan
agent1:                 episode reward: 0.5360,                 loss: nan
Episode: 1301/30000 (4.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1981s / 13.5381 s
agent0:                 episode reward: -0.5754,                 loss: nan
agent1:                 episode reward: 0.5754,                 loss: nan
Episode: 1321/30000 (4.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1968s / 13.7348 s
agent0:                 episode reward: -0.7514,                 loss: nan
agent1:                 episode reward: 0.7514,                 loss: nan
Episode: 1341/30000 (4.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1988s / 13.9337 s
agent0:                 episode reward: -0.3068,                 loss: nan
agent1:                 episode reward: 0.3068,                 loss: nan
Episode: 1361/30000 (4.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1996s / 14.1333 s
agent0:                 episode reward: 0.1532,                 loss: nan
agent1:                 episode reward: -0.1532,                 loss: nan
Episode: 1381/30000 (4.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2008s / 14.3341 s
agent0:                 episode reward: -0.1451,                 loss: nan
agent1:                 episode reward: 0.1451,                 loss: nan
Episode: 1401/30000 (4.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1954s / 14.5295 s
agent0:                 episode reward: 0.0342,                 loss: nan
agent1:                 episode reward: -0.0342,                 loss: nan
Episode: 1421/30000 (4.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2028s / 14.7323 s
agent0:                 episode reward: -0.2768,                 loss: nan
agent1:                 episode reward: 0.2768,                 loss: nan
Episode: 1441/30000 (4.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1998s / 14.9322 s
agent0:                 episode reward: -0.6267,                 loss: nan
agent1:                 episode reward: 0.6267,                 loss: nan
Episode: 1461/30000 (4.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1994s / 15.1316 s
agent0:                 episode reward: -0.4809,                 loss: nan
agent1:                 episode reward: 0.4809,                 loss: nan
Episode: 1481/30000 (4.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1966s / 15.3282 s
agent0:                 episode reward: -0.3067,                 loss: nan
agent1:                 episode reward: 0.3067,                 loss: nan
Episode: 1501/30000 (5.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1977s / 15.5259 s
agent0:                 episode reward: -0.4704,                 loss: nan
agent1:                 episode reward: 0.4704,                 loss: nan
Episode: 1521/30000 (5.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1978s / 15.7236 s
agent0:                 episode reward: -0.4369,                 loss: nan
agent1:                 episode reward: 0.4369,                 loss: nan
Episode: 1541/30000 (5.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1990s / 15.9227 s
agent0:                 episode reward: -0.5869,                 loss: nan
agent1:                 episode reward: 0.5869,                 loss: nan
Episode: 1561/30000 (5.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1994s / 16.1221 s
agent0:                 episode reward: -0.0198,                 loss: nan
agent1:                 episode reward: 0.0198,                 loss: nan
Episode: 1581/30000 (5.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1972s / 16.3193 s
agent0:                 episode reward: -0.2021,                 loss: nan
agent1:                 episode reward: 0.2021,                 loss: nan
Episode: 1601/30000 (5.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2005s / 16.5198 s
agent0:                 episode reward: -0.0179,                 loss: nan
agent1:                 episode reward: 0.0179,                 loss: nan
Episode: 1621/30000 (5.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1989s / 16.7187 s
agent0:                 episode reward: -0.1964,                 loss: nan
agent1:                 episode reward: 0.1964,                 loss: nan
Episode: 1641/30000 (5.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2026s / 16.9213 s
agent0:                 episode reward: -0.1614,                 loss: nan
agent1:                 episode reward: 0.1614,                 loss: nan
Episode: 1661/30000 (5.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2009s / 17.1222 s
agent0:                 episode reward: 0.2971,                 loss: nan
agent1:                 episode reward: -0.2971,                 loss: nan
Episode: 1681/30000 (5.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1926s / 17.3149 s
agent0:                 episode reward: -0.1031,                 loss: nan
agent1:                 episode reward: 0.1031,                 loss: nan
Episode: 1701/30000 (5.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2007s / 17.5156 s
agent0:                 episode reward: 0.0330,                 loss: nan
agent1:                 episode reward: -0.0330,                 loss: nan
Episode: 1721/30000 (5.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1939s / 17.7095 s
agent0:                 episode reward: -0.2389,                 loss: nan
agent1:                 episode reward: 0.2389,                 loss: nan
Episode: 1741/30000 (5.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1986s / 17.9080 s
agent0:                 episode reward: -0.5891,                 loss: nan
agent1:                 episode reward: 0.5891,                 loss: nan
Episode: 1761/30000 (5.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1985s / 18.1065 s
agent0:                 episode reward: -0.3283,                 loss: nan
agent1:                 episode reward: 0.3283,                 loss: nan
Episode: 1781/30000 (5.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1971s / 18.3037 s
agent0:                 episode reward: -0.2083,                 loss: nan
agent1:                 episode reward: 0.2083,                 loss: nan
Episode: 1801/30000 (6.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2004s / 18.5041 s
agent0:                 episode reward: -0.3982,                 loss: nan
agent1:                 episode reward: 0.3982,                 loss: nan
Episode: 1821/30000 (6.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1935s / 18.6976 s
agent0:                 episode reward: 0.1245,                 loss: nan
agent1:                 episode reward: -0.1245,                 loss: nan
Episode: 1841/30000 (6.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1996s / 18.8972 s
agent0:                 episode reward: -0.2300,                 loss: nan
agent1:                 episode reward: 0.2300,                 loss: nan
Episode: 1861/30000 (6.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1963s / 19.0935 s
agent0:                 episode reward: -0.1622,                 loss: nan
agent1:                 episode reward: 0.1622,                 loss: nan
Episode: 1881/30000 (6.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1994s / 19.2929 s
agent0:                 episode reward: -0.2904,                 loss: nan
agent1:                 episode reward: 0.2904,                 loss: nan
Episode: 1901/30000 (6.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1983s / 19.4912 s
agent0:                 episode reward: -0.3361,                 loss: nan
agent1:                 episode reward: 0.3361,                 loss: nan
Episode: 1921/30000 (6.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1971s / 19.6883 s
agent0:                 episode reward: -0.4418,                 loss: nan
agent1:                 episode reward: 0.4418,                 loss: nan
Episode: 1941/30000 (6.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1968s / 19.8852 s
agent0:                 episode reward: -0.7592,                 loss: nan
agent1:                 episode reward: 0.7592,                 loss: nan
Episode: 1961/30000 (6.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1963s / 20.0815 s
agent0:                 episode reward: -0.1402,                 loss: nan
agent1:                 episode reward: 0.1402,                 loss: nan
Episode: 1981/30000 (6.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2014s / 20.2828 s
agent0:                 episode reward: -0.3024,                 loss: nan
agent1:                 episode reward: 0.3024,                 loss: nan
Episode: 2001/30000 (6.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1949s / 20.4778 s
agent0:                 episode reward: 0.2538,                 loss: nan
agent1:                 episode reward: -0.2538,                 loss: nan
Episode: 2021/30000 (6.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2027s / 20.6804 s
agent0:                 episode reward: -0.0809,                 loss: nan
agent1:                 episode reward: 0.0809,                 loss: nan
Episode: 2041/30000 (6.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1979s / 20.8783 s
agent0:                 episode reward: -0.1240,                 loss: nan
agent1:                 episode reward: 0.1240,                 loss: nan
Episode: 2061/30000 (6.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2001s / 21.0784 s
agent0:                 episode reward: 0.0715,                 loss: nan
agent1:                 episode reward: -0.0715,                 loss: nan
Episode: 2081/30000 (6.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1984s / 21.2768 s
agent0:                 episode reward: -0.3421,                 loss: nan
agent1:                 episode reward: 0.3421,                 loss: nan
Episode: 2101/30000 (7.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1992s / 21.4760 s
agent0:                 episode reward: -0.3655,                 loss: nan
agent1:                 episode reward: 0.3655,                 loss: nan
Episode: 2121/30000 (7.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1994s / 21.6753 s
agent0:                 episode reward: -0.2234,                 loss: nan
agent1:                 episode reward: 0.2234,                 loss: nan
Episode: 2141/30000 (7.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1924s / 21.8677 s
agent0:                 episode reward: -0.5630,                 loss: nan
agent1:                 episode reward: 0.5630,                 loss: nan
Episode: 2161/30000 (7.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1939s / 22.0616 s
agent0:                 episode reward: -0.1373,                 loss: nan
agent1:                 episode reward: 0.1373,                 loss: nan
Episode: 2181/30000 (7.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2067s / 22.2683 s
agent0:                 episode reward: -0.2141,                 loss: nan
agent1:                 episode reward: 0.2141,                 loss: nan
Episode: 2201/30000 (7.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2031s / 22.4714 s
agent0:                 episode reward: -0.0560,                 loss: nan
agent1:                 episode reward: 0.0560,                 loss: nan
Episode: 2221/30000 (7.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1978s / 22.6692 s
agent0:                 episode reward: -0.1178,                 loss: nan
agent1:                 episode reward: 0.1178,                 loss: nan
Episode: 2241/30000 (7.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1969s / 22.8661 s
agent0:                 episode reward: 0.1773,                 loss: nan
agent1:                 episode reward: -0.1773,                 loss: nan
Episode: 2261/30000 (7.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1970s / 23.0631 s
agent0:                 episode reward: -0.4451,                 loss: nan
agent1:                 episode reward: 0.4451,                 loss: nan
Episode: 2281/30000 (7.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1967s / 23.2598 s
agent0:                 episode reward: -0.2892,                 loss: nan
agent1:                 episode reward: 0.2892,                 loss: nan
Episode: 2301/30000 (7.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1979s / 23.4577 s
agent0:                 episode reward: -0.3329,                 loss: nan
agent1:                 episode reward: 0.3329,                 loss: nan
Episode: 2321/30000 (7.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1912s / 23.6489 s
agent0:                 episode reward: -0.6420,                 loss: nan
agent1:                 episode reward: 0.6420,                 loss: nan
Episode: 2341/30000 (7.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1956s / 23.8445 s
agent0:                 episode reward: 0.1685,                 loss: nan
agent1:                 episode reward: -0.1685,                 loss: nan
Episode: 2361/30000 (7.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2021s / 24.0466 s
agent0:                 episode reward: -0.0628,                 loss: nan
agent1:                 episode reward: 0.0628,                 loss: nan
Episode: 2381/30000 (7.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2033s / 24.2499 s
agent0:                 episode reward: -0.2904,                 loss: nan
agent1:                 episode reward: 0.2904,                 loss: nan
Episode: 2401/30000 (8.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2005s / 24.4504 s
agent0:                 episode reward: -0.4192,                 loss: nan
agent1:                 episode reward: 0.4192,                 loss: nan
Episode: 2421/30000 (8.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1974s / 24.6479 s
agent0:                 episode reward: 0.2323,                 loss: nan
agent1:                 episode reward: -0.2323,                 loss: nan
Episode: 2441/30000 (8.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2019s / 24.8498 s
agent0:                 episode reward: -0.6936,                 loss: nan
agent1:                 episode reward: 0.6936,                 loss: nan
Episode: 2461/30000 (8.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1991s / 25.0489 s
agent0:                 episode reward: -0.1053,                 loss: nan
agent1:                 episode reward: 0.1053,                 loss: nan
Episode: 2481/30000 (8.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2026s / 25.2516 s
agent0:                 episode reward: -0.5715,                 loss: nan
agent1:                 episode reward: 0.5715,                 loss: nan
Episode: 2501/30000 (8.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1970s / 25.4486 s
agent0:                 episode reward: -0.3442,                 loss: nan
agent1:                 episode reward: 0.3442,                 loss: nan
Episode: 2521/30000 (8.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1967s / 25.6453 s
agent0:                 episode reward: -0.4153,                 loss: nan
agent1:                 episode reward: 0.4153,                 loss: nan
Episode: 2541/30000 (8.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2023s / 25.8476 s
agent0:                 episode reward: -0.3187,                 loss: nan
agent1:                 episode reward: 0.3187,                 loss: nan
Episode: 2561/30000 (8.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2030s / 26.0506 s
agent0:                 episode reward: -0.2807,                 loss: nan
agent1:                 episode reward: 0.2807,                 loss: nan
Episode: 2581/30000 (8.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1978s / 26.2483 s
agent0:                 episode reward: -0.2412,                 loss: nan
agent1:                 episode reward: 0.2412,                 loss: nan
Episode: 2601/30000 (8.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1913s / 26.4396 s
agent0:                 episode reward: -0.0241,                 loss: nan
agent1:                 episode reward: 0.0241,                 loss: nan
Episode: 2621/30000 (8.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2043s / 26.6440 s
agent0:                 episode reward: -0.2829,                 loss: nan
agent1:                 episode reward: 0.2829,                 loss: nan
Episode: 2641/30000 (8.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2010s / 26.8450 s
agent0:                 episode reward: -0.1284,                 loss: nan
agent1:                 episode reward: 0.1284,                 loss: nan
Episode: 2661/30000 (8.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2021s / 27.0471 s
agent0:                 episode reward: -0.0925,                 loss: nan
agent1:                 episode reward: 0.0925,                 loss: nan
Episode: 2681/30000 (8.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1999s / 27.2470 s
agent0:                 episode reward: 0.3140,                 loss: nan
agent1:                 episode reward: -0.3140,                 loss: nan
Episode: 2701/30000 (9.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1996s / 27.4466 s
agent0:                 episode reward: -0.5153,                 loss: nan
agent1:                 episode reward: 0.5153,                 loss: nan
Episode: 2721/30000 (9.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1868s / 27.6334 s
agent0:                 episode reward: -0.0364,                 loss: nan
agent1:                 episode reward: 0.0364,                 loss: nan
Episode: 2741/30000 (9.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1999s / 27.8333 s
agent0:                 episode reward: -0.2946,                 loss: nan
agent1:                 episode reward: 0.2946,                 loss: nan
Episode: 2761/30000 (9.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2345s / 28.0678 s
agent0:                 episode reward: -0.1375,                 loss: nan
agent1:                 episode reward: 0.1375,                 loss: nan
Episode: 2781/30000 (9.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2016s / 28.2694 s
agent0:                 episode reward: -0.4247,                 loss: nan
agent1:                 episode reward: 0.4247,                 loss: nan
Episode: 2801/30000 (9.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1960s / 28.4654 s
agent0:                 episode reward: -0.3957,                 loss: nan
agent1:                 episode reward: 0.3957,                 loss: nan
Episode: 2821/30000 (9.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2043s / 28.6696 s
agent0:                 episode reward: -0.3716,                 loss: nan
agent1:                 episode reward: 0.3716,                 loss: nan
Episode: 2841/30000 (9.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2071s / 28.8768 s
agent0:                 episode reward: -0.4502,                 loss: nan
agent1:                 episode reward: 0.4502,                 loss: nan
Episode: 2861/30000 (9.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2050s / 29.0817 s
agent0:                 episode reward: -0.0417,                 loss: nan
agent1:                 episode reward: 0.0417,                 loss: nan
Episode: 2881/30000 (9.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2015s / 29.2832 s
agent0:                 episode reward: -0.2997,                 loss: nan
agent1:                 episode reward: 0.2997,                 loss: nan
Episode: 2901/30000 (9.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1997s / 29.4829 s
agent0:                 episode reward: 0.0372,                 loss: nan
agent1:                 episode reward: -0.0372,                 loss: nan
Episode: 2921/30000 (9.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2006s / 29.6835 s
agent0:                 episode reward: 0.0446,                 loss: nan
agent1:                 episode reward: -0.0446,                 loss: nan
Episode: 2941/30000 (9.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1986s / 29.8822 s
agent0:                 episode reward: -0.4054,                 loss: nan
agent1:                 episode reward: 0.4054,                 loss: nan
Episode: 2961/30000 (9.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2020s / 30.0841 s
agent0:                 episode reward: -0.2622,                 loss: nan
agent1:                 episode reward: 0.2622,                 loss: nan
Episode: 2981/30000 (9.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2002s / 30.2843 s
agent0:                 episode reward: 0.0848,                 loss: nan
agent1:                 episode reward: -0.0848,                 loss: nan
Episode: 3001/30000 (10.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2020s / 30.4863 s
agent0:                 episode reward: -0.3580,                 loss: nan
agent1:                 episode reward: 0.3580,                 loss: nan
Episode: 3021/30000 (10.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2038s / 30.6901 s
agent0:                 episode reward: -0.3110,                 loss: nan
agent1:                 episode reward: 0.3110,                 loss: nan
Episode: 3041/30000 (10.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2023s / 30.8925 s
agent0:                 episode reward: 0.0383,                 loss: nan
agent1:                 episode reward: -0.0383,                 loss: nan
Episode: 3061/30000 (10.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1985s / 31.0910 s
agent0:                 episode reward: -0.3450,                 loss: nan
agent1:                 episode reward: 0.3450,                 loss: nan
Episode: 3081/30000 (10.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1988s / 31.2897 s
agent0:                 episode reward: -0.1069,                 loss: nan
agent1:                 episode reward: 0.1069,                 loss: nan
Episode: 3101/30000 (10.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1990s / 31.4887 s
agent0:                 episode reward: -0.2410,                 loss: nan
agent1:                 episode reward: 0.2410,                 loss: nan
Episode: 3121/30000 (10.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1996s / 31.6883 s
agent0:                 episode reward: -0.1038,                 loss: nan
agent1:                 episode reward: 0.1038,                 loss: nan
Episode: 3141/30000 (10.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1968s / 31.8851 s
agent0:                 episode reward: -0.3103,                 loss: nan
agent1:                 episode reward: 0.3103,                 loss: nan
Episode: 3161/30000 (10.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1972s / 32.0822 s
agent0:                 episode reward: -0.5823,                 loss: nan
agent1:                 episode reward: 0.5823,                 loss: nan
Episode: 3181/30000 (10.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1977s / 32.2799 s
agent0:                 episode reward: -0.0581,                 loss: nan
agent1:                 episode reward: 0.0581,                 loss: nan
Episode: 3201/30000 (10.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1941s / 32.4740 s
agent0:                 episode reward: -0.2824,                 loss: nan
agent1:                 episode reward: 0.2824,                 loss: nan
Episode: 3221/30000 (10.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2000s / 32.6740 s
agent0:                 episode reward: -0.4002,                 loss: nan
agent1:                 episode reward: 0.4002,                 loss: nan
Episode: 3241/30000 (10.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2018s / 32.8758 s
agent0:                 episode reward: -0.4971,                 loss: nan
agent1:                 episode reward: 0.4971,                 loss: nan
Episode: 3261/30000 (10.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1986s / 33.0744 s
agent0:                 episode reward: -0.1500,                 loss: nan
agent1:                 episode reward: 0.1500,                 loss: nan
Episode: 3281/30000 (10.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1963s / 33.2707 s
agent0:                 episode reward: -0.4910,                 loss: nan
agent1:                 episode reward: 0.4910,                 loss: nan
Episode: 3301/30000 (11.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1941s / 33.4647 s
agent0:                 episode reward: 0.0061,                 loss: nan
agent1:                 episode reward: -0.0061,                 loss: nan
Episode: 3321/30000 (11.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1890s / 33.6538 s
agent0:                 episode reward: -0.1622,                 loss: nan
agent1:                 episode reward: 0.1622,                 loss: nan
Episode: 3341/30000 (11.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3374s / 33.9912 s
agent0:                 episode reward: -0.2070,                 loss: nan
agent1:                 episode reward: 0.2070,                 loss: 0.4507
Episode: 3361/30000 (11.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5775s / 34.5687 s
agent0:                 episode reward: -0.2337,                 loss: nan
agent1:                 episode reward: 0.2337,                 loss: 0.4333
Episode: 3381/30000 (11.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5847s / 35.1534 s
agent0:                 episode reward: -0.2208,                 loss: nan
agent1:                 episode reward: 0.2208,                 loss: 0.4217
Episode: 3401/30000 (11.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5815s / 35.7349 s
agent0:                 episode reward: -0.2575,                 loss: nan
agent1:                 episode reward: 0.2575,                 loss: 0.4201
Episode: 3421/30000 (11.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5813s / 36.3162 s
agent0:                 episode reward: -0.1457,                 loss: nan
agent1:                 episode reward: 0.1457,                 loss: 0.4188
Episode: 3441/30000 (11.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5978s / 36.9140 s
agent0:                 episode reward: -0.7478,                 loss: nan
agent1:                 episode reward: 0.7478,                 loss: 0.4173
Episode: 3461/30000 (11.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5828s / 37.4968 s
agent0:                 episode reward: -0.5521,                 loss: nan
agent1:                 episode reward: 0.5521,                 loss: 0.4165
Episode: 3481/30000 (11.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5822s / 38.0790 s
agent0:                 episode reward: -0.5116,                 loss: nan
agent1:                 episode reward: 0.5116,                 loss: 0.4144
Episode: 3501/30000 (11.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5868s / 38.6658 s
agent0:                 episode reward: -0.8380,                 loss: nan
agent1:                 episode reward: 0.8380,                 loss: 0.4125
Episode: 3521/30000 (11.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5860s / 39.2517 s
agent0:                 episode reward: -0.1140,                 loss: nan
agent1:                 episode reward: 0.1140,                 loss: 0.4136
Episode: 3541/30000 (11.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5810s / 39.8328 s
agent0:                 episode reward: 0.0555,                 loss: nan
agent1:                 episode reward: -0.0555,                 loss: 0.4113
Episode: 3561/30000 (11.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5817s / 40.4145 s
agent0:                 episode reward: -0.5844,                 loss: nan
agent1:                 episode reward: 0.5844,                 loss: 0.4120
Episode: 3581/30000 (11.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5805s / 40.9949 s
agent0:                 episode reward: -0.6024,                 loss: nan
agent1:                 episode reward: 0.6024,                 loss: 0.4096
Episode: 3601/30000 (12.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5817s / 41.5766 s
agent0:                 episode reward: -0.2285,                 loss: nan
agent1:                 episode reward: 0.2285,                 loss: 0.4122
Episode: 3621/30000 (12.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5811s / 42.1577 s
agent0:                 episode reward: -0.4740,                 loss: nan
agent1:                 episode reward: 0.4740,                 loss: 0.4120
Episode: 3641/30000 (12.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5832s / 42.7409 s
agent0:                 episode reward: -0.0253,                 loss: nan
agent1:                 episode reward: 0.0253,                 loss: 0.4115
Episode: 3661/30000 (12.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5806s / 43.3215 s
agent0:                 episode reward: -0.1665,                 loss: nan
agent1:                 episode reward: 0.1665,                 loss: 0.4110
Episode: 3681/30000 (12.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5815s / 43.9029 s
agent0:                 episode reward: -0.3482,                 loss: nan
agent1:                 episode reward: 0.3482,                 loss: 0.4039
Episode: 3701/30000 (12.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5772s / 44.4802 s
agent0:                 episode reward: -0.5604,                 loss: nan
agent1:                 episode reward: 0.5604,                 loss: 0.3952
Episode: 3721/30000 (12.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5807s / 45.0609 s
agent0:                 episode reward: -0.7131,                 loss: nan
agent1:                 episode reward: 0.7131,                 loss: 0.3928
Episode: 3741/30000 (12.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5802s / 45.6411 s
agent0:                 episode reward: -0.2286,                 loss: nan
agent1:                 episode reward: 0.2286,                 loss: 0.3918
Episode: 3761/30000 (12.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5800s / 46.2211 s
agent0:                 episode reward: -0.2712,                 loss: nan
agent1:                 episode reward: 0.2712,                 loss: 0.3933
Episode: 3781/30000 (12.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5790s / 46.8001 s
agent0:                 episode reward: -0.7239,                 loss: nan
agent1:                 episode reward: 0.7239,                 loss: 0.3911
Episode: 3801/30000 (12.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5770s / 47.3770 s
agent0:                 episode reward: -0.5742,                 loss: nan
agent1:                 episode reward: 0.5742,                 loss: 0.3924
Episode: 3821/30000 (12.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5794s / 47.9565 s
agent0:                 episode reward: -0.2979,                 loss: nan
agent1:                 episode reward: 0.2979,                 loss: 0.3931
Episode: 3841/30000 (12.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5853s / 48.5417 s
agent0:                 episode reward: -0.5357,                 loss: nan
agent1:                 episode reward: 0.5357,                 loss: 0.3898
Episode: 3861/30000 (12.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5847s / 49.1265 s
agent0:                 episode reward: -0.8606,                 loss: nan
agent1:                 episode reward: 0.8606,                 loss: 0.3888
Episode: 3881/30000 (12.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5837s / 49.7102 s
agent0:                 episode reward: -0.5136,                 loss: nan
agent1:                 episode reward: 0.5136,                 loss: 0.3905
Episode: 3901/30000 (13.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5927s / 50.3029 s
agent0:                 episode reward: -0.5338,                 loss: nan
agent1:                 episode reward: 0.5338,                 loss: 0.3893
Episode: 3921/30000 (13.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5877s / 50.8906 s
agent0:                 episode reward: -0.5074,                 loss: nan
agent1:                 episode reward: 0.5074,                 loss: 0.3926
Episode: 3941/30000 (13.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5799s / 51.4705 s
agent0:                 episode reward: -0.3643,                 loss: nan
agent1:                 episode reward: 0.3643,                 loss: 0.3930
Episode: 3961/30000 (13.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5825s / 52.0530 s
agent0:                 episode reward: -0.5741,                 loss: nan
agent1:                 episode reward: 0.5741,                 loss: 0.3899
Episode: 3981/30000 (13.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5833s / 52.6363 s
agent0:                 episode reward: -0.6191,                 loss: nan
agent1:                 episode reward: 0.6191,                 loss: 0.3878
Episode: 4001/30000 (13.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5792s / 53.2156 s
agent0:                 episode reward: -0.2665,                 loss: nan
agent1:                 episode reward: 0.2665,                 loss: 0.3877
Episode: 4021/30000 (13.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5893s / 53.8049 s
agent0:                 episode reward: -0.4889,                 loss: nan
agent1:                 episode reward: 0.4889,                 loss: 0.3810
Episode: 4041/30000 (13.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5847s / 54.3895 s
agent0:                 episode reward: -0.7422,                 loss: nan
agent1:                 episode reward: 0.7422,                 loss: 0.3804
Episode: 4061/30000 (13.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5804s / 54.9699 s
agent0:                 episode reward: -0.4609,                 loss: nan
agent1:                 episode reward: 0.4609,                 loss: 0.3799
Episode: 4081/30000 (13.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5845s / 55.5544 s
agent0:                 episode reward: -0.6435,                 loss: nan
agent1:                 episode reward: 0.6435,                 loss: 0.3806
Episode: 4101/30000 (13.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5911s / 56.1455 s
agent0:                 episode reward: -0.8315,                 loss: nan
agent1:                 episode reward: 0.8315,                 loss: 0.3779
Episode: 4121/30000 (13.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5910s / 56.7365 s
agent0:                 episode reward: -0.6551,                 loss: nan
agent1:                 episode reward: 0.6551,                 loss: 0.3807
Episode: 4141/30000 (13.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5820s / 57.3184 s
agent0:                 episode reward: -0.4922,                 loss: nan
agent1:                 episode reward: 0.4922,                 loss: 0.3814
Episode: 4161/30000 (13.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5879s / 57.9063 s
agent0:                 episode reward: -0.7673,                 loss: nan
agent1:                 episode reward: 0.7673,                 loss: 0.3741
Episode: 4181/30000 (13.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5832s / 58.4895 s
agent0:                 episode reward: -0.7643,                 loss: nan
agent1:                 episode reward: 0.7643,                 loss: 0.3800
Episode: 4201/30000 (14.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5893s / 59.0788 s
agent0:                 episode reward: -0.2918,                 loss: nan
agent1:                 episode reward: 0.2918,                 loss: 0.3779
Episode: 4221/30000 (14.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5895s / 59.6683 s
agent0:                 episode reward: -0.3643,                 loss: nan
agent1:                 episode reward: 0.3643,                 loss: 0.3763
Episode: 4241/30000 (14.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5826s / 60.2509 s
agent0:                 episode reward: -0.5623,                 loss: nan
agent1:                 episode reward: 0.5623,                 loss: 0.3809
Episode: 4261/30000 (14.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5861s / 60.8370 s
agent0:                 episode reward: -0.0898,                 loss: nan
agent1:                 episode reward: 0.0898,                 loss: 0.3756
Episode: 4281/30000 (14.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5842s / 61.4212 s
agent0:                 episode reward: -1.0566,                 loss: nan
agent1:                 episode reward: 1.0566,                 loss: 0.3813
Episode: 4301/30000 (14.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5861s / 62.0073 s
agent0:                 episode reward: -0.0519,                 loss: nan
agent1:                 episode reward: 0.0519,                 loss: 0.3777
Episode: 4321/30000 (14.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5821s / 62.5894 s
agent0:                 episode reward: -0.4326,                 loss: nan
agent1:                 episode reward: 0.4326,                 loss: 0.3784
Episode: 4341/30000 (14.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5824s / 63.1718 s
agent0:                 episode reward: -0.4510,                 loss: nan
agent1:                 episode reward: 0.4510,                 loss: 0.3845
Episode: 4361/30000 (14.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5894s / 63.7612 s
agent0:                 episode reward: -0.5778,                 loss: nan
agent1:                 episode reward: 0.5778,                 loss: 0.4009
Episode: 4381/30000 (14.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5874s / 64.3486 s
agent0:                 episode reward: -0.4938,                 loss: nan
agent1:                 episode reward: 0.4938,                 loss: 0.3985
Episode: 4401/30000 (14.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5852s / 64.9338 s
agent0:                 episode reward: -0.3378,                 loss: nan
agent1:                 episode reward: 0.3378,                 loss: 0.3980
Episode: 4421/30000 (14.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5871s / 65.5208 s
agent0:                 episode reward: -0.5048,                 loss: nan
agent1:                 episode reward: 0.5048,                 loss: 0.3983
Episode: 4441/30000 (14.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5866s / 66.1074 s
agent0:                 episode reward: -0.6720,                 loss: nan
agent1:                 episode reward: 0.6720,                 loss: 0.3982
Episode: 4461/30000 (14.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5875s / 66.6949 s
agent0:                 episode reward: -0.5160,                 loss: nan
agent1:                 episode reward: 0.5160,                 loss: 0.4001
Episode: 4481/30000 (14.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5847s / 67.2796 s
agent0:                 episode reward: -0.2048,                 loss: nan
agent1:                 episode reward: 0.2048,                 loss: 0.3992
Episode: 4501/30000 (15.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5796s / 67.8592 s
agent0:                 episode reward: -0.5605,                 loss: nan
agent1:                 episode reward: 0.5605,                 loss: 0.4015
Episode: 4521/30000 (15.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5889s / 68.4482 s
agent0:                 episode reward: -0.6616,                 loss: nan
agent1:                 episode reward: 0.6616,                 loss: 0.3978
Episode: 4541/30000 (15.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5880s / 69.0362 s
agent0:                 episode reward: -0.4210,                 loss: nan
agent1:                 episode reward: 0.4210,                 loss: 0.3946
Episode: 4561/30000 (15.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5919s / 69.6281 s
agent0:                 episode reward: -0.3632,                 loss: nan
agent1:                 episode reward: 0.3632,                 loss: 0.3991
Episode: 4581/30000 (15.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5814s / 70.2095 s
agent0:                 episode reward: -0.4101,                 loss: nan
agent1:                 episode reward: 0.4101,                 loss: 0.3969
Episode: 4601/30000 (15.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5934s / 70.8029 s
agent0:                 episode reward: -0.7137,                 loss: nan
agent1:                 episode reward: 0.7137,                 loss: 0.3959
Episode: 4621/30000 (15.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5888s / 71.3917 s
agent0:                 episode reward: -0.4222,                 loss: nan
agent1:                 episode reward: 0.4222,                 loss: 0.3961
Episode: 4641/30000 (15.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5830s / 71.9747 s
agent0:                 episode reward: -0.5076,                 loss: nan
agent1:                 episode reward: 0.5076,                 loss: 0.3962
Episode: 4661/30000 (15.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5840s / 72.5587 s
agent0:                 episode reward: -0.0270,                 loss: nan
agent1:                 episode reward: 0.0270,                 loss: 0.3961
Episode: 4681/30000 (15.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5967s / 73.1553 s
agent0:                 episode reward: -0.7235,                 loss: nan
agent1:                 episode reward: 0.7235,                 loss: 0.3980
Episode: 4701/30000 (15.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5855s / 73.7408 s
agent0:                 episode reward: -0.7322,                 loss: nan
agent1:                 episode reward: 0.7322,                 loss: 0.3990
Episode: 4721/30000 (15.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5844s / 74.3252 s
agent0:                 episode reward: -0.7654,                 loss: nan
agent1:                 episode reward: 0.7654,                 loss: 0.3973
Episode: 4741/30000 (15.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5902s / 74.9154 s
agent0:                 episode reward: -0.4279,                 loss: nan
agent1:                 episode reward: 0.4279,                 loss: 0.4008
Episode: 4761/30000 (15.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5830s / 75.4984 s
agent0:                 episode reward: -0.2683,                 loss: nan
agent1:                 episode reward: 0.2683,                 loss: 0.4002
Episode: 4781/30000 (15.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5924s / 76.0908 s
agent0:                 episode reward: -0.8787,                 loss: nan
agent1:                 episode reward: 0.8787,                 loss: 0.4009
Episode: 4801/30000 (16.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5880s / 76.6788 s
agent0:                 episode reward: -0.3133,                 loss: nan
agent1:                 episode reward: 0.3133,                 loss: 0.4000
Episode: 4821/30000 (16.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5860s / 77.2648 s
agent0:                 episode reward: -0.4243,                 loss: nan
agent1:                 episode reward: 0.4243,                 loss: 0.3983
Episode: 4841/30000 (16.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5901s / 77.8549 s
agent0:                 episode reward: -0.0951,                 loss: nan
agent1:                 episode reward: 0.0951,                 loss: 0.4007
Episode: 4861/30000 (16.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5994s / 78.4543 s
agent0:                 episode reward: -0.4029,                 loss: nan
agent1:                 episode reward: 0.4029,                 loss: 0.3972
Episode: 4881/30000 (16.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6005s / 79.0548 s
agent0:                 episode reward: -0.6425,                 loss: nan
agent1:                 episode reward: 0.6425,                 loss: 0.4000
Episode: 4901/30000 (16.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6023s / 79.6572 s
agent0:                 episode reward: -0.5857,                 loss: nan
agent1:                 episode reward: 0.5857,                 loss: 0.4000
Episode: 4921/30000 (16.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6056s / 80.2627 s
agent0:                 episode reward: -0.2564,                 loss: nan
agent1:                 episode reward: 0.2564,                 loss: 0.4002
Episode: 4941/30000 (16.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5960s / 80.8587 s
agent0:                 episode reward: -0.4015,                 loss: nan
agent1:                 episode reward: 0.4015,                 loss: 0.4005
Episode: 4961/30000 (16.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5997s / 81.4585 s
agent0:                 episode reward: -0.4010,                 loss: nan
agent1:                 episode reward: 0.4010,                 loss: 0.3993
Episode: 4981/30000 (16.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6030s / 82.0615 s
agent0:                 episode reward: -0.6660,                 loss: nan
agent1:                 episode reward: 0.6660,                 loss: 0.3989
Episode: 5001/30000 (16.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6004s / 82.6619 s
agent0:                 episode reward: -0.5941,                 loss: nan
agent1:                 episode reward: 0.5941,                 loss: 0.3985
Episode: 5021/30000 (16.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5967s / 83.2586 s
agent0:                 episode reward: -0.4100,                 loss: nan
agent1:                 episode reward: 0.4100,                 loss: 0.3858
Episode: 5041/30000 (16.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5983s / 83.8569 s
agent0:                 episode reward: -0.5124,                 loss: nan
agent1:                 episode reward: 0.5124,                 loss: 0.3821
Episode: 5061/30000 (16.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5945s / 84.4514 s
agent0:                 episode reward: -0.7340,                 loss: nan
agent1:                 episode reward: 0.7340,                 loss: 0.3811
Episode: 5081/30000 (16.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5979s / 85.0493 s
agent0:                 episode reward: -0.3879,                 loss: nan
agent1:                 episode reward: 0.3879,                 loss: 0.3860
Episode: 5101/30000 (17.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6000s / 85.6493 s
agent0:                 episode reward: -0.2679,                 loss: nan
agent1:                 episode reward: 0.2679,                 loss: 0.3876
Episode: 5121/30000 (17.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5971s / 86.2465 s
agent0:                 episode reward: -0.3663,                 loss: nan
agent1:                 episode reward: 0.3663,                 loss: 0.3838
Episode: 5141/30000 (17.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6150s / 86.8615 s
agent0:                 episode reward: -0.6400,                 loss: nan
agent1:                 episode reward: 0.6400,                 loss: 0.3846
Episode: 5161/30000 (17.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5930s / 87.4545 s
agent0:                 episode reward: -0.5968,                 loss: nan
agent1:                 episode reward: 0.5968,                 loss: 0.3834
Episode: 5181/30000 (17.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5951s / 88.0496 s
agent0:                 episode reward: -0.4660,                 loss: nan
agent1:                 episode reward: 0.4660,                 loss: 0.3851
Episode: 5201/30000 (17.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6037s / 88.6533 s
agent0:                 episode reward: -0.7588,                 loss: nan
agent1:                 episode reward: 0.7588,                 loss: 0.3843
Episode: 5221/30000 (17.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6060s / 89.2594 s
agent0:                 episode reward: -0.6345,                 loss: nan
agent1:                 episode reward: 0.6345,                 loss: 0.3851
Episode: 5241/30000 (17.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5996s / 89.8590 s
agent0:                 episode reward: -0.6905,                 loss: nan
agent1:                 episode reward: 0.6905,                 loss: 0.3839
Episode: 5261/30000 (17.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6000s / 90.4589 s
agent0:                 episode reward: -0.6601,                 loss: nan
agent1:                 episode reward: 0.6601,                 loss: 0.3822
Episode: 5281/30000 (17.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6014s / 91.0603 s
agent0:                 episode reward: -0.4843,                 loss: nan
agent1:                 episode reward: 0.4843,                 loss: 0.3814
Episode: 5301/30000 (17.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5994s / 91.6598 s
agent0:                 episode reward: -0.6862,                 loss: nan
agent1:                 episode reward: 0.6862,                 loss: 0.3837
Episode: 5321/30000 (17.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5896s / 92.2494 s
agent0:                 episode reward: -0.6259,                 loss: nan
agent1:                 episode reward: 0.6259,                 loss: 0.3836
Episode: 5341/30000 (17.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5957s / 92.8450 s
agent0:                 episode reward: -0.3139,                 loss: nan
agent1:                 episode reward: 0.3139,                 loss: 0.3971
Episode: 5361/30000 (17.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5960s / 93.4410 s
agent0:                 episode reward: -0.5775,                 loss: nan
agent1:                 episode reward: 0.5775,                 loss: 0.4113
Episode: 5381/30000 (17.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5945s / 94.0356 s
agent0:                 episode reward: -0.3737,                 loss: nan
agent1:                 episode reward: 0.3737,                 loss: 0.4093
Episode: 5401/30000 (18.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6020s / 94.6375 s
agent0:                 episode reward: -1.0882,                 loss: nan
agent1:                 episode reward: 1.0882,                 loss: 0.4086
Episode: 5421/30000 (18.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5922s / 95.2297 s
agent0:                 episode reward: -0.7280,                 loss: nan
agent1:                 episode reward: 0.7280,                 loss: 0.4092
Episode: 5441/30000 (18.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5933s / 95.8230 s
agent0:                 episode reward: -0.5004,                 loss: nan
agent1:                 episode reward: 0.5004,                 loss: 0.4087
Episode: 5461/30000 (18.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5864s / 96.4094 s
agent0:                 episode reward: -0.5042,                 loss: nan
agent1:                 episode reward: 0.5042,                 loss: 0.4069
Episode: 5481/30000 (18.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5846s / 96.9941 s
agent0:                 episode reward: -0.3797,                 loss: nan
agent1:                 episode reward: 0.3797,                 loss: 0.4082
Episode: 5501/30000 (18.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6122s / 97.6062 s
agent0:                 episode reward: -0.6618,                 loss: nan
agent1:                 episode reward: 0.6618,                 loss: 0.4076
Episode: 5521/30000 (18.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5905s / 98.1967 s
agent0:                 episode reward: -0.6089,                 loss: nan
agent1:                 episode reward: 0.6089,                 loss: 0.4090
Episode: 5541/30000 (18.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5861s / 98.7828 s
agent0:                 episode reward: -0.3094,                 loss: nan
agent1:                 episode reward: 0.3094,                 loss: 0.4084
Episode: 5561/30000 (18.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5991s / 99.3819 s
agent0:                 episode reward: -0.5057,                 loss: nan
agent1:                 episode reward: 0.5057,                 loss: 0.4070
Episode: 5581/30000 (18.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5937s / 99.9755 s
agent0:                 episode reward: -0.2178,                 loss: nan
agent1:                 episode reward: 0.2178,                 loss: 0.4073
Episode: 5601/30000 (18.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5965s / 100.5720 s
agent0:                 episode reward: -0.3300,                 loss: nan
agent1:                 episode reward: 0.3300,                 loss: 0.4081
Episode: 5621/30000 (18.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5922s / 101.1642 s
agent0:                 episode reward: -0.6437,                 loss: nan
agent1:                 episode reward: 0.6437,                 loss: 0.4061
Episode: 5641/30000 (18.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5915s / 101.7556 s
agent0:                 episode reward: -0.4940,                 loss: nan
agent1:                 episode reward: 0.4940,                 loss: 0.4080
Episode: 5661/30000 (18.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5928s / 102.3485 s
agent0:                 episode reward: -0.5760,                 loss: nan
agent1:                 episode reward: 0.5760,                 loss: 0.4053
Episode: 5681/30000 (18.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5992s / 102.9477 s
agent0:                 episode reward: -0.4800,                 loss: nan
agent1:                 episode reward: 0.4800,                 loss: 0.3959
Episode: 5701/30000 (19.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5975s / 103.5451 s
agent0:                 episode reward: -0.3718,                 loss: nan
agent1:                 episode reward: 0.3718,                 loss: 0.3917
Episode: 5721/30000 (19.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5954s / 104.1405 s
agent0:                 episode reward: -0.8733,                 loss: nan
agent1:                 episode reward: 0.8733,                 loss: 0.3913
Episode: 5741/30000 (19.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5980s / 104.7385 s
agent0:                 episode reward: -0.5054,                 loss: nan
agent1:                 episode reward: 0.5054,                 loss: 0.3916
Episode: 5761/30000 (19.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6003s / 105.3389 s
agent0:                 episode reward: -0.8007,                 loss: nan
agent1:                 episode reward: 0.8007,                 loss: 0.3917
Episode: 5781/30000 (19.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5998s / 105.9387 s
agent0:                 episode reward: -0.4821,                 loss: nan
agent1:                 episode reward: 0.4821,                 loss: 0.3899
Episode: 5801/30000 (19.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5953s / 106.5340 s
agent0:                 episode reward: -0.4707,                 loss: nan
agent1:                 episode reward: 0.4707,                 loss: 0.3901
Episode: 5821/30000 (19.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5894s / 107.1234 s
agent0:                 episode reward: -0.6636,                 loss: nan
agent1:                 episode reward: 0.6636,                 loss: 0.3919
Episode: 5841/30000 (19.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5948s / 107.7182 s
agent0:                 episode reward: -0.5027,                 loss: nan
agent1:                 episode reward: 0.5027,                 loss: 0.3936
Episode: 5861/30000 (19.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5918s / 108.3100 s
agent0:                 episode reward: -0.2557,                 loss: nan
agent1:                 episode reward: 0.2557,                 loss: 0.3928
Episode: 5881/30000 (19.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5999s / 108.9099 s
agent0:                 episode reward: -0.5837,                 loss: nan
agent1:                 episode reward: 0.5837,                 loss: 0.3914
Episode: 5901/30000 (19.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5937s / 109.5036 s
agent0:                 episode reward: -0.6003,                 loss: nan
agent1:                 episode reward: 0.6003,                 loss: 0.3918
Episode: 5921/30000 (19.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5871s / 110.0907 s
agent0:                 episode reward: -0.1812,                 loss: nan
agent1:                 episode reward: 0.1812,                 loss: 0.3907
Episode: 5941/30000 (19.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5938s / 110.6845 s
agent0:                 episode reward: -0.3735,                 loss: nan
agent1:                 episode reward: 0.3735,                 loss: 0.3901
Episode: 5961/30000 (19.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5918s / 111.2763 s
agent0:                 episode reward: 0.2469,                 loss: nan
agent1:                 episode reward: -0.2469,                 loss: 0.3910
Episode: 5981/30000 (19.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5925s / 111.8688 s
agent0:                 episode reward: -1.0251,                 loss: nan
agent1:                 episode reward: 1.0251,                 loss: 0.3908
Episode: 6001/30000 (20.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5955s / 112.4643 s
agent0:                 episode reward: -0.2266,                 loss: nan
agent1:                 episode reward: 0.2266,                 loss: 0.3928
Episode: 6021/30000 (20.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5981s / 113.0624 s
agent0:                 episode reward: -0.4434,                 loss: nan
agent1:                 episode reward: 0.4434,                 loss: 0.3826
Episode: 6041/30000 (20.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6065s / 113.6689 s
agent0:                 episode reward: -0.3174,                 loss: nan
agent1:                 episode reward: 0.3174,                 loss: 0.3813
Episode: 6061/30000 (20.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5937s / 114.2626 s
agent0:                 episode reward: -0.3547,                 loss: nan
agent1:                 episode reward: 0.3547,                 loss: 0.3796
Episode: 6081/30000 (20.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6031s / 114.8656 s
agent0:                 episode reward: -0.3228,                 loss: nan
agent1:                 episode reward: 0.3228,                 loss: 0.3812
Episode: 6101/30000 (20.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5906s / 115.4562 s
agent0:                 episode reward: -0.4566,                 loss: nan
agent1:                 episode reward: 0.4566,                 loss: 0.3815
Episode: 6121/30000 (20.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5974s / 116.0537 s
agent0:                 episode reward: -0.8127,                 loss: nan
agent1:                 episode reward: 0.8127,                 loss: 0.3814
Episode: 6141/30000 (20.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6026s / 116.6563 s
agent0:                 episode reward: -0.3747,                 loss: nan
agent1:                 episode reward: 0.3747,                 loss: 0.3808
Episode: 6161/30000 (20.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6003s / 117.2566 s
agent0:                 episode reward: -0.6611,                 loss: nan
agent1:                 episode reward: 0.6611,                 loss: 0.3806
Episode: 6181/30000 (20.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5890s / 117.8456 s
agent0:                 episode reward: -0.8250,                 loss: nan
agent1:                 episode reward: 0.8250,                 loss: 0.3815
Episode: 6201/30000 (20.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5992s / 118.4448 s
agent0:                 episode reward: -0.3785,                 loss: nan
agent1:                 episode reward: 0.3785,                 loss: 0.3799
Episode: 6221/30000 (20.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5864s / 119.0312 s
agent0:                 episode reward: -0.4413,                 loss: nan
agent1:                 episode reward: 0.4413,                 loss: 0.3827
Episode: 6241/30000 (20.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5997s / 119.6309 s
agent0:                 episode reward: -0.7771,                 loss: nan
agent1:                 episode reward: 0.7771,                 loss: 0.3804
Episode: 6261/30000 (20.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5914s / 120.2222 s
agent0:                 episode reward: -0.3820,                 loss: nan
agent1:                 episode reward: 0.3820,                 loss: 0.3779
Episode: 6281/30000 (20.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6052s / 120.8274 s
agent0:                 episode reward: -0.6857,                 loss: nan
agent1:                 episode reward: 0.6857,                 loss: 0.3784
Episode: 6301/30000 (21.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6041s / 121.4315 s
agent0:                 episode reward: -0.0880,                 loss: nan
agent1:                 episode reward: 0.0880,                 loss: 0.3806
Episode: 6321/30000 (21.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5930s / 122.0244 s
agent0:                 episode reward: -0.3323,                 loss: nan
agent1:                 episode reward: 0.3323,                 loss: 0.3794
Episode: 6341/30000 (21.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5895s / 122.6139 s
agent0:                 episode reward: -0.5484,                 loss: nan
agent1:                 episode reward: 0.5484,                 loss: 0.3904
Episode: 6361/30000 (21.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6047s / 123.2186 s
agent0:                 episode reward: -0.3990,                 loss: nan
agent1:                 episode reward: 0.3990,                 loss: 0.4053
Episode: 6381/30000 (21.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6027s / 123.8213 s
agent0:                 episode reward: -0.5824,                 loss: nan
agent1:                 episode reward: 0.5824,                 loss: 0.4069
Episode: 6401/30000 (21.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5951s / 124.4164 s
agent0:                 episode reward: -0.5087,                 loss: nan
agent1:                 episode reward: 0.5087,                 loss: 0.4053
Episode: 6421/30000 (21.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5978s / 125.0142 s
agent0:                 episode reward: -0.6210,                 loss: nan
agent1:                 episode reward: 0.6210,                 loss: 0.4053
Episode: 6441/30000 (21.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6031s / 125.6173 s
agent0:                 episode reward: -0.3449,                 loss: nan
agent1:                 episode reward: 0.3449,                 loss: 0.4059
Episode: 6461/30000 (21.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6002s / 126.2175 s
agent0:                 episode reward: -0.5043,                 loss: nan
agent1:                 episode reward: 0.5043,                 loss: 0.4058
Episode: 6481/30000 (21.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6076s / 126.8251 s
agent0:                 episode reward: -0.3845,                 loss: nan
agent1:                 episode reward: 0.3845,                 loss: 0.4047
Episode: 6501/30000 (21.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6061s / 127.4312 s
agent0:                 episode reward: -0.6304,                 loss: nan
agent1:                 episode reward: 0.6304,                 loss: 0.4054
Episode: 6521/30000 (21.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6090s / 128.0402 s
agent0:                 episode reward: -0.1587,                 loss: nan
agent1:                 episode reward: 0.1587,                 loss: 0.4050
Episode: 6541/30000 (21.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5989s / 128.6392 s
agent0:                 episode reward: -0.4337,                 loss: nan
agent1:                 episode reward: 0.4337,                 loss: 0.4045
Episode: 6561/30000 (21.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6017s / 129.2409 s
agent0:                 episode reward: -0.3425,                 loss: nan
agent1:                 episode reward: 0.3425,                 loss: 0.4054
Episode: 6581/30000 (21.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5944s / 129.8353 s
agent0:                 episode reward: -0.6085,                 loss: nan
agent1:                 episode reward: 0.6085,                 loss: 0.4040
Episode: 6601/30000 (22.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5976s / 130.4329 s
agent0:                 episode reward: -0.3292,                 loss: nan
agent1:                 episode reward: 0.3292,                 loss: 0.4034
Episode: 6621/30000 (22.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5948s / 131.0277 s
agent0:                 episode reward: -0.7017,                 loss: nan
agent1:                 episode reward: 0.7017,                 loss: 0.4016
Episode: 6641/30000 (22.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6056s / 131.6334 s
agent0:                 episode reward: -0.3902,                 loss: nan
agent1:                 episode reward: 0.3902,                 loss: 0.4037
Episode: 6661/30000 (22.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6025s / 132.2358 s
agent0:                 episode reward: -0.6929,                 loss: nan
agent1:                 episode reward: 0.6929,                 loss: 0.4031
Episode: 6681/30000 (22.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6001s / 132.8359 s
agent0:                 episode reward: -0.4081,                 loss: nan
agent1:                 episode reward: 0.4081,                 loss: 0.4048
Episode: 6701/30000 (22.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6113s / 133.4471 s
agent0:                 episode reward: -0.1908,                 loss: nan
agent1:                 episode reward: 0.1908,                 loss: 0.4030
Episode: 6721/30000 (22.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5975s / 134.0447 s
agent0:                 episode reward: -0.1978,                 loss: nan
agent1:                 episode reward: 0.1978,                 loss: 0.4028
Episode: 6741/30000 (22.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6035s / 134.6482 s
agent0:                 episode reward: -0.3979,                 loss: nan
agent1:                 episode reward: 0.3979,                 loss: 0.4042
Episode: 6761/30000 (22.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6048s / 135.2530 s
agent0:                 episode reward: -0.5963,                 loss: nan
agent1:                 episode reward: 0.5963,                 loss: 0.4038
Episode: 6781/30000 (22.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5978s / 135.8508 s
agent0:                 episode reward: -0.3475,                 loss: nan
agent1:                 episode reward: 0.3475,                 loss: 0.4059
Episode: 6801/30000 (22.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6094s / 136.4602 s
agent0:                 episode reward: -0.4167,                 loss: nan
agent1:                 episode reward: 0.4167,                 loss: 0.4033
Episode: 6821/30000 (22.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5987s / 137.0588 s
agent0:                 episode reward: -0.6443,                 loss: nan
agent1:                 episode reward: 0.6443,                 loss: 0.4046
Episode: 6841/30000 (22.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5975s / 137.6563 s
agent0:                 episode reward: -0.5606,                 loss: nan
agent1:                 episode reward: 0.5606,                 loss: 0.4029
Episode: 6861/30000 (22.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6074s / 138.2637 s
agent0:                 episode reward: -0.4384,                 loss: nan
agent1:                 episode reward: 0.4384,                 loss: 0.4023
Episode: 6881/30000 (22.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6022s / 138.8659 s
agent0:                 episode reward: -0.5629,                 loss: nan
agent1:                 episode reward: 0.5629,                 loss: 0.4048
Episode: 6901/30000 (23.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5966s / 139.4625 s
agent0:                 episode reward: -0.5745,                 loss: nan
agent1:                 episode reward: 0.5745,                 loss: 0.4019
Episode: 6921/30000 (23.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5992s / 140.0617 s
agent0:                 episode reward: -0.5296,                 loss: nan
agent1:                 episode reward: 0.5296,                 loss: 0.4020
Episode: 6941/30000 (23.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5960s / 140.6578 s
agent0:                 episode reward: -0.6335,                 loss: nan
agent1:                 episode reward: 0.6335,                 loss: 0.4033
Episode: 6961/30000 (23.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6106s / 141.2683 s
agent0:                 episode reward: -0.3580,                 loss: nan
agent1:                 episode reward: 0.3580,                 loss: 0.4044
Episode: 6981/30000 (23.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5990s / 141.8673 s
agent0:                 episode reward: -0.7370,                 loss: nan
agent1:                 episode reward: 0.7370,                 loss: 0.4032
Episode: 7001/30000 (23.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6106s / 142.4779 s
agent0:                 episode reward: -0.8238,                 loss: nan
agent1:                 episode reward: 0.8238,                 loss: 0.4024
Episode: 7021/30000 (23.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6051s / 143.0830 s
agent0:                 episode reward: -0.5858,                 loss: nan
agent1:                 episode reward: 0.5858,                 loss: 0.3882
Episode: 7041/30000 (23.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6008s / 143.6838 s
agent0:                 episode reward: -0.2166,                 loss: nan
agent1:                 episode reward: 0.2166,                 loss: 0.3886
Episode: 7061/30000 (23.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6091s / 144.2929 s
agent0:                 episode reward: -0.4060,                 loss: nan
agent1:                 episode reward: 0.4060,                 loss: 0.3894
Episode: 7081/30000 (23.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6111s / 144.9040 s
agent0:                 episode reward: -0.5332,                 loss: nan
agent1:                 episode reward: 0.5332,                 loss: 0.3882
Episode: 7101/30000 (23.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6060s / 145.5100 s
agent0:                 episode reward: -0.2208,                 loss: nan
agent1:                 episode reward: 0.2208,                 loss: 0.3874
Episode: 7121/30000 (23.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6021s / 146.1121 s
agent0:                 episode reward: 0.0708,                 loss: nan
agent1:                 episode reward: -0.0708,                 loss: 0.3878
Episode: 7141/30000 (23.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5953s / 146.7075 s
agent0:                 episode reward: -0.5196,                 loss: nan
agent1:                 episode reward: 0.5196,                 loss: 0.3864
Episode: 7161/30000 (23.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6027s / 147.3102 s
agent0:                 episode reward: -0.3516,                 loss: nan
agent1:                 episode reward: 0.3516,                 loss: 0.3847
Episode: 7181/30000 (23.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6048s / 147.9150 s
agent0:                 episode reward: -0.4339,                 loss: nan
agent1:                 episode reward: 0.4339,                 loss: 0.3865
Episode: 7201/30000 (24.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5960s / 148.5110 s
agent0:                 episode reward: -0.3708,                 loss: nan
agent1:                 episode reward: 0.3708,                 loss: 0.3883
Episode: 7221/30000 (24.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5939s / 149.1049 s
agent0:                 episode reward: -0.5586,                 loss: nan
agent1:                 episode reward: 0.5586,                 loss: 0.3876
Episode: 7241/30000 (24.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5975s / 149.7024 s
agent0:                 episode reward: -0.8891,                 loss: nan
agent1:                 episode reward: 0.8891,                 loss: 0.3886
Episode: 7261/30000 (24.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6016s / 150.3040 s
agent0:                 episode reward: -0.5442,                 loss: nan
agent1:                 episode reward: 0.5442,                 loss: 0.3886
Episode: 7281/30000 (24.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6071s / 150.9111 s
agent0:                 episode reward: -0.5322,                 loss: nan
agent1:                 episode reward: 0.5322,                 loss: 0.3915
Episode: 7301/30000 (24.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6002s / 151.5113 s
agent0:                 episode reward: -0.9424,                 loss: nan
agent1:                 episode reward: 0.9424,                 loss: 0.3859
Episode: 7321/30000 (24.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6030s / 152.1144 s
agent0:                 episode reward: -0.7421,                 loss: nan
agent1:                 episode reward: 0.7421,                 loss: 0.3906
Episode: 7341/30000 (24.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6010s / 152.7153 s
agent0:                 episode reward: -0.5199,                 loss: nan
agent1:                 episode reward: 0.5199,                 loss: 0.3940
Episode: 7361/30000 (24.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6046s / 153.3199 s
agent0:                 episode reward: -0.7392,                 loss: nan
agent1:                 episode reward: 0.7392,                 loss: 0.4034
Episode: 7381/30000 (24.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6043s / 153.9241 s
agent0:                 episode reward: -0.7803,                 loss: nan
agent1:                 episode reward: 0.7803,                 loss: 0.4061
Episode: 7401/30000 (24.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6046s / 154.5288 s
agent0:                 episode reward: -0.5054,                 loss: nan
agent1:                 episode reward: 0.5054,                 loss: 0.4059
Episode: 7421/30000 (24.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6027s / 155.1315 s
agent0:                 episode reward: -0.6808,                 loss: nan
agent1:                 episode reward: 0.6808,                 loss: 0.4042
Episode: 7441/30000 (24.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6023s / 155.7338 s
agent0:                 episode reward: -0.3493,                 loss: nan
agent1:                 episode reward: 0.3493,                 loss: 0.4063
Episode: 7461/30000 (24.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5943s / 156.3281 s
agent0:                 episode reward: -0.4931,                 loss: nan
agent1:                 episode reward: 0.4931,                 loss: 0.4035
Episode: 7481/30000 (24.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5976s / 156.9257 s
agent0:                 episode reward: -0.1201,                 loss: nan
agent1:                 episode reward: 0.1201,                 loss: 0.4059
Episode: 7501/30000 (25.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5976s / 157.5233 s
agent0:                 episode reward: -0.4540,                 loss: nan
agent1:                 episode reward: 0.4540,                 loss: 0.4036
Episode: 7521/30000 (25.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5964s / 158.1197 s
agent0:                 episode reward: -0.7299,                 loss: nan
agent1:                 episode reward: 0.7299,                 loss: 0.4036
Episode: 7541/30000 (25.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6068s / 158.7265 s
agent0:                 episode reward: -0.6261,                 loss: nan
agent1:                 episode reward: 0.6261,                 loss: 0.4032
Episode: 7561/30000 (25.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6039s / 159.3304 s
agent0:                 episode reward: -0.6616,                 loss: nan
agent1:                 episode reward: 0.6616,                 loss: 0.4037
Episode: 7581/30000 (25.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5995s / 159.9299 s
agent0:                 episode reward: -0.5205,                 loss: nan
agent1:                 episode reward: 0.5205,                 loss: 0.4043
Episode: 7601/30000 (25.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6078s / 160.5377 s
agent0:                 episode reward: -0.4956,                 loss: nan
agent1:                 episode reward: 0.4956,                 loss: 0.4036
Episode: 7621/30000 (25.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6057s / 161.1434 s
agent0:                 episode reward: -0.3913,                 loss: nan
agent1:                 episode reward: 0.3913,                 loss: 0.4044
Episode: 7641/30000 (25.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6075s / 161.7509 s
agent0:                 episode reward: -0.6227,                 loss: nan
agent1:                 episode reward: 0.6227,                 loss: 0.4062
Episode: 7661/30000 (25.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6076s / 162.3585 s
agent0:                 episode reward: -0.8156,                 loss: nan
agent1:                 episode reward: 0.8156,                 loss: 0.4059
Episode: 7681/30000 (25.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5989s / 162.9575 s
agent0:                 episode reward: -0.5253,                 loss: nan
agent1:                 episode reward: 0.5253,                 loss: 0.3937
Episode: 7701/30000 (25.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6058s / 163.5632 s
agent0:                 episode reward: -0.1805,                 loss: nan
agent1:                 episode reward: 0.1805,                 loss: 0.3924
Episode: 7721/30000 (25.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6074s / 164.1706 s
agent0:                 episode reward: -0.9450,                 loss: nan
agent1:                 episode reward: 0.9450,                 loss: 0.3902
Episode: 7741/30000 (25.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6051s / 164.7757 s
agent0:                 episode reward: -0.1652,                 loss: nan
agent1:                 episode reward: 0.1652,                 loss: 0.3892
Episode: 7761/30000 (25.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6082s / 165.3839 s
agent0:                 episode reward: -0.5444,                 loss: nan
agent1:                 episode reward: 0.5444,                 loss: 0.3895
Episode: 7781/30000 (25.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6088s / 165.9927 s
agent0:                 episode reward: -0.7581,                 loss: nan
agent1:                 episode reward: 0.7581,                 loss: 0.3886
Episode: 7801/30000 (26.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6019s / 166.5946 s
agent0:                 episode reward: -0.5922,                 loss: nan
agent1:                 episode reward: 0.5922,                 loss: 0.3929
Episode: 7821/30000 (26.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6058s / 167.2005 s
agent0:                 episode reward: -0.1360,                 loss: nan
agent1:                 episode reward: 0.1360,                 loss: 0.3898
Episode: 7841/30000 (26.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6062s / 167.8067 s
agent0:                 episode reward: -0.3015,                 loss: nan
agent1:                 episode reward: 0.3015,                 loss: 0.3910
Episode: 7861/30000 (26.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6096s / 168.4162 s
agent0:                 episode reward: -0.2629,                 loss: nan
agent1:                 episode reward: 0.2629,                 loss: 0.3909
Episode: 7881/30000 (26.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6057s / 169.0219 s
agent0:                 episode reward: -0.0507,                 loss: nan
agent1:                 episode reward: 0.0507,                 loss: 0.3915
Episode: 7901/30000 (26.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6118s / 169.6337 s
agent0:                 episode reward: -0.2057,                 loss: nan
agent1:                 episode reward: 0.2057,                 loss: 0.3904
Episode: 7921/30000 (26.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6114s / 170.2451 s
agent0:                 episode reward: -0.4249,                 loss: nan
agent1:                 episode reward: 0.4249,                 loss: 0.3895
Episode: 7941/30000 (26.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6062s / 170.8513 s
agent0:                 episode reward: -0.6702,                 loss: nan
agent1:                 episode reward: 0.6702,                 loss: 0.3885
Episode: 7961/30000 (26.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6097s / 171.4611 s
agent0:                 episode reward: -0.8396,                 loss: nan
agent1:                 episode reward: 0.8396,                 loss: 0.3901
Episode: 7981/30000 (26.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5994s / 172.0604 s
agent0:                 episode reward: -0.4683,                 loss: nan
agent1:                 episode reward: 0.4683,                 loss: 0.3907
Episode: 8001/30000 (26.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6115s / 172.6719 s
agent0:                 episode reward: -0.4977,                 loss: nan
agent1:                 episode reward: 0.4977,                 loss: 0.3909
Episode: 8021/30000 (26.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6174s / 173.2893 s
agent0:                 episode reward: -0.5877,                 loss: nan
agent1:                 episode reward: 0.5877,                 loss: 0.3819
Episode: 8041/30000 (26.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6005s / 173.8898 s
agent0:                 episode reward: -0.3931,                 loss: nan
agent1:                 episode reward: 0.3931,                 loss: 0.3812
Episode: 8061/30000 (26.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6076s / 174.4974 s
agent0:                 episode reward: -0.4848,                 loss: nan
agent1:                 episode reward: 0.4848,                 loss: 0.3814
Episode: 8081/30000 (26.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6016s / 175.0991 s
agent0:                 episode reward: -0.1900,                 loss: nan
agent1:                 episode reward: 0.1900,                 loss: 0.3814
Episode: 8101/30000 (27.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6096s / 175.7087 s
agent0:                 episode reward: -0.5480,                 loss: nan
agent1:                 episode reward: 0.5480,                 loss: 0.3800
Episode: 8121/30000 (27.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6142s / 176.3229 s
agent0:                 episode reward: -0.4145,                 loss: nan
agent1:                 episode reward: 0.4145,                 loss: 0.3783
Episode: 8141/30000 (27.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6117s / 176.9345 s
agent0:                 episode reward: -0.6501,                 loss: nan
agent1:                 episode reward: 0.6501,                 loss: 0.3810
Episode: 8161/30000 (27.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6099s / 177.5445 s
agent0:                 episode reward: -0.6673,                 loss: nan
agent1:                 episode reward: 0.6673,                 loss: 0.3820
Episode: 8181/30000 (27.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6203s / 178.1647 s
