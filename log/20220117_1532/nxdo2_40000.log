pygame 2.0.0 (SDL 2.0.12, python 3.7.10)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 12.0, (1,), float32) action space: Discrete(3)
random seed: 91
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7f786ad541d0>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
Agents No. [0] (index starting from 0) are not learnable.
Load meta strategy:  [[0.483 0.092 0.2   ... 0.    0.121 0.   ]
 [0.    0.    0.    ... 0.    0.    0.   ]]
Load checkpoints (policy family):  [['83' '5753' '6419' ... '38431' '38946' '39041']
 ['121' '6342' '6627' ... '38452' '38973' '39078']]
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': 'random', 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000, 'update_itr': 1}, 'batch_size': 640, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'cpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220116204408/epi_40000/', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nxdo2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'selfplay_score_delta': 1.5, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'against_baseline': False}
Save models to : /home/zihan/research/MARS/data/model/20220116204408_exploit_40000/mdp_arbitrary_mdp_nxdo2. 
 Save logs to: /home/zihan/research/MARS/data/log/20220116204408_exploit_40000/mdp_arbitrary_mdp_nxdo2.
Episode: 1/30000 (0.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 1.2606s / 1.2606 s
agent0:                 episode reward: -0.4744,                 loss: nan
agent1:                 episode reward: 0.4744,                 loss: nan
Episode: 21/30000 (0.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4537s / 1.7143 s
agent0:                 episode reward: 0.4723,                 loss: nan
agent1:                 episode reward: -0.4723,                 loss: nan
Episode: 41/30000 (0.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1577s / 1.8720 s
agent0:                 episode reward: 0.3058,                 loss: nan
agent1:                 episode reward: -0.3058,                 loss: nan
Episode: 61/30000 (0.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3066s / 2.1786 s
agent0:                 episode reward: 0.2827,                 loss: nan
agent1:                 episode reward: -0.2827,                 loss: nan
Episode: 81/30000 (0.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3034s / 2.4820 s
agent0:                 episode reward: -0.0356,                 loss: nan
agent1:                 episode reward: 0.0356,                 loss: nan
Episode: 101/30000 (0.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3069s / 2.7889 s
agent0:                 episode reward: -0.1243,                 loss: nan
agent1:                 episode reward: 0.1243,                 loss: nan
Episode: 121/30000 (0.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4922s / 3.2811 s
agent0:                 episode reward: 0.0441,                 loss: nan
agent1:                 episode reward: -0.0441,                 loss: nan
Episode: 141/30000 (0.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6996s / 3.9806 s
agent0:                 episode reward: 0.3907,                 loss: nan
agent1:                 episode reward: -0.3907,                 loss: nan
Episode: 161/30000 (0.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7728s / 4.7535 s
agent0:                 episode reward: 0.0765,                 loss: nan
agent1:                 episode reward: -0.0765,                 loss: nan
Episode: 181/30000 (0.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6616s / 5.4151 s
agent0:                 episode reward: -0.1751,                 loss: nan
agent1:                 episode reward: 0.1751,                 loss: nan
Episode: 201/30000 (0.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 2.0432s / 7.4583 s
agent0:                 episode reward: -0.1439,                 loss: nan
agent1:                 episode reward: 0.1439,                 loss: nan
Episode: 221/30000 (0.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 32.7733s / 40.2315 s
agent0:                 episode reward: -0.1264,                 loss: nan
agent1:                 episode reward: 0.1264,                 loss: 0.2253
Episode: 241/30000 (0.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 100.3257s / 140.5572 s
agent0:                 episode reward: 0.2718,                 loss: nan
agent1:                 episode reward: -0.2718,                 loss: 0.2020
Episode: 261/30000 (0.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 100.3537s / 240.9109 s
agent0:                 episode reward: -0.1710,                 loss: nan
agent1:                 episode reward: 0.1710,                 loss: 0.1853
Episode: 281/30000 (0.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 98.4512s / 339.3621 s
agent0:                 episode reward: 0.1013,                 loss: nan
agent1:                 episode reward: -0.1013,                 loss: 0.1780
Episode: 301/30000 (1.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 98.2227s / 437.5847 s
agent0:                 episode reward: -0.0881,                 loss: nan
agent1:                 episode reward: 0.0881,                 loss: 0.1711
Episode: 321/30000 (1.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 101.1085s / 538.6933 s
agent0:                 episode reward: 0.0601,                 loss: nan
agent1:                 episode reward: -0.0601,                 loss: 0.1657
Episode: 341/30000 (1.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 96.5466s / 635.2399 s
agent0:                 episode reward: 0.0663,                 loss: nan
agent1:                 episode reward: -0.0663,                 loss: 0.1607
Episode: 361/30000 (1.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 102.0470s / 737.2869 s
agent0:                 episode reward: -0.1020,                 loss: nan
agent1:                 episode reward: 0.1020,                 loss: 0.1581
Episode: 381/30000 (1.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 102.4601s / 839.7470 s
agent0:                 episode reward: 0.0852,                 loss: nan
agent1:                 episode reward: -0.0852,                 loss: 0.1558
Episode: 401/30000 (1.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 101.3740s / 941.1210 s
agent0:                 episode reward: 0.1563,                 loss: nan
agent1:                 episode reward: -0.1563,                 loss: 0.1546
Episode: 421/30000 (1.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 97.6998s / 1038.8209 s
agent0:                 episode reward: 0.0233,                 loss: nan
agent1:                 episode reward: -0.0233,                 loss: 0.1530
Episode: 441/30000 (1.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 98.9604s / 1137.7813 s
agent0:                 episode reward: -0.2651,                 loss: nan
agent1:                 episode reward: 0.2651,                 loss: 0.1490
Episode: 461/30000 (1.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 100.6011s / 1238.3824 s
agent0:                 episode reward: 0.2732,                 loss: nan
agent1:                 episode reward: -0.2732,                 loss: 0.1504
Episode: 481/30000 (1.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 90.4735s / 1328.8559 s
agent0:                 episode reward: -0.0417,                 loss: nan
agent1:                 episode reward: 0.0417,                 loss: 0.1514
Episode: 501/30000 (1.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 98.8533s / 1427.7092 s
agent0:                 episode reward: -0.1633,                 loss: nan
agent1:                 episode reward: 0.1633,                 loss: 0.1503
Episode: 521/30000 (1.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 98.2024s / 1525.9116 s
agent0:                 episode reward: -0.0213,                 loss: nan
agent1:                 episode reward: 0.0213,                 loss: 0.1496
Episode: 541/30000 (1.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 102.6870s / 1628.5987 s
agent0:                 episode reward: -0.0520,                 loss: nan
agent1:                 episode reward: 0.0520,                 loss: 0.1504
Episode: 561/30000 (1.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 101.3885s / 1729.9872 s
agent0:                 episode reward: 0.1141,                 loss: nan
agent1:                 episode reward: -0.1141,                 loss: 0.1566
Episode: 581/30000 (1.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 100.6578s / 1830.6450 s
agent0:                 episode reward: -0.0704,                 loss: nan
agent1:                 episode reward: 0.0704,                 loss: 0.1496
Episode: 601/30000 (2.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 95.5175s / 1926.1626 s
agent0:                 episode reward: -0.6455,                 loss: nan
agent1:                 episode reward: 0.6455,                 loss: 0.1501
Episode: 621/30000 (2.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 95.8068s / 2021.9694 s
agent0:                 episode reward: -0.2227,                 loss: nan
agent1:                 episode reward: 0.2227,                 loss: 0.1510
Episode: 641/30000 (2.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 97.9008s / 2119.8702 s
agent0:                 episode reward: 0.3572,                 loss: nan
agent1:                 episode reward: -0.3572,                 loss: 0.1490
Episode: 661/30000 (2.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 99.6646s / 2219.5347 s
agent0:                 episode reward: -0.0591,                 loss: nan
agent1:                 episode reward: 0.0591,                 loss: 0.1492
Episode: 681/30000 (2.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 100.0831s / 2319.6178 s
agent0:                 episode reward: -0.4149,                 loss: nan
agent1:                 episode reward: 0.4149,                 loss: 0.1504
Episode: 701/30000 (2.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 97.4473s / 2417.0652 s
agent0:                 episode reward: -0.3580,                 loss: nan
agent1:                 episode reward: 0.3580,                 loss: 0.1485
Episode: 721/30000 (2.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 98.9558s / 2516.0210 s
agent0:                 episode reward: 0.3449,                 loss: nan
agent1:                 episode reward: -0.3449,                 loss: 0.1478
Episode: 741/30000 (2.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 101.9243s / 2617.9453 s
agent0:                 episode reward: 0.5168,                 loss: nan
agent1:                 episode reward: -0.5168,                 loss: 0.1487
Episode: 761/30000 (2.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 96.8572s / 2714.8025 s
agent0:                 episode reward: -0.0517,                 loss: nan
agent1:                 episode reward: 0.0517,                 loss: 0.1488
Episode: 781/30000 (2.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 127.0475s / 2841.8500 s
agent0:                 episode reward: -0.0404,                 loss: nan
agent1:                 episode reward: 0.0404,                 loss: 0.1493
Episode: 801/30000 (2.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.0840s / 2978.9340 s
agent0:                 episode reward: -0.0035,                 loss: nan
agent1:                 episode reward: 0.0035,                 loss: 0.1479
Episode: 821/30000 (2.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 140.0799s / 3119.0140 s
agent0:                 episode reward: -0.2973,                 loss: nan
agent1:                 episode reward: 0.2973,                 loss: 0.1476
Episode: 841/30000 (2.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.7535s / 3253.7674 s
agent0:                 episode reward: -0.1834,                 loss: nan
agent1:                 episode reward: 0.1834,                 loss: 0.1473
Episode: 861/30000 (2.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.7802s / 3391.5477 s
agent0:                 episode reward: 0.1340,                 loss: nan
agent1:                 episode reward: -0.1340,                 loss: 0.1457
Episode: 881/30000 (2.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.1960s / 3527.7437 s
agent0:                 episode reward: 0.3304,                 loss: nan
agent1:                 episode reward: -0.3304,                 loss: 0.1470
Episode: 901/30000 (3.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.3942s / 3665.1379 s
agent0:                 episode reward: -0.0160,                 loss: nan
agent1:                 episode reward: 0.0160,                 loss: 0.1435
Episode: 921/30000 (3.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.9382s / 3802.0761 s
agent0:                 episode reward: 0.1101,                 loss: nan
agent1:                 episode reward: -0.1101,                 loss: 0.1422
Episode: 941/30000 (3.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 138.4870s / 3940.5631 s
agent0:                 episode reward: -0.1944,                 loss: nan
agent1:                 episode reward: 0.1944,                 loss: 0.1437
Episode: 961/30000 (3.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2063s / 4076.7694 s
agent0:                 episode reward: 0.0844,                 loss: nan
agent1:                 episode reward: -0.0844,                 loss: 0.1426
Episode: 981/30000 (3.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.4777s / 4215.2471 s
agent0:                 episode reward: -0.1242,                 loss: nan
agent1:                 episode reward: 0.1242,                 loss: 0.1419
Episode: 1001/30000 (3.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1641s / 4349.4112 s
agent0:                 episode reward: -0.2368,                 loss: nan
agent1:                 episode reward: 0.2368,                 loss: 0.1411
Episode: 1021/30000 (3.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.5882s / 4485.9994 s
agent0:                 episode reward: 0.1322,                 loss: nan
agent1:                 episode reward: -0.1322,                 loss: 0.1397
Episode: 1041/30000 (3.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6358s / 4621.6352 s
agent0:                 episode reward: 0.2073,                 loss: nan
agent1:                 episode reward: -0.2073,                 loss: 0.1392
Episode: 1061/30000 (3.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 142.0687s / 4763.7039 s
agent0:                 episode reward: -0.2163,                 loss: nan
agent1:                 episode reward: 0.2163,                 loss: 0.1396
Episode: 1081/30000 (3.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.3771s / 4903.0810 s
agent0:                 episode reward: 0.1440,                 loss: nan
agent1:                 episode reward: -0.1440,                 loss: 0.1389
Episode: 1101/30000 (3.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 141.6831s / 5044.7641 s
agent0:                 episode reward: -0.1825,                 loss: nan
agent1:                 episode reward: 0.1825,                 loss: 0.1398
Episode: 1121/30000 (3.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.7750s / 5182.5391 s
agent0:                 episode reward: 0.2475,                 loss: nan
agent1:                 episode reward: -0.2475,                 loss: 0.1392
Episode: 1141/30000 (3.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0698s / 5318.6089 s
agent0:                 episode reward: 0.1094,                 loss: nan
agent1:                 episode reward: -0.1094,                 loss: 0.1397
Episode: 1161/30000 (3.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 139.0273s / 5457.6362 s
agent0:                 episode reward: 0.0210,                 loss: nan
agent1:                 episode reward: -0.0210,                 loss: 0.1385
Episode: 1181/30000 (3.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 141.5571s / 5599.1933 s
agent0:                 episode reward: 0.0945,                 loss: nan
agent1:                 episode reward: -0.0945,                 loss: 0.1378
Episode: 1201/30000 (4.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.9185s / 5736.1117 s
agent0:                 episode reward: 0.1307,                 loss: nan
agent1:                 episode reward: -0.1307,                 loss: 0.1395
Episode: 1221/30000 (4.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.7632s / 5873.8749 s
agent0:                 episode reward: 0.4958,                 loss: nan
agent1:                 episode reward: -0.4958,                 loss: 0.1410
Episode: 1241/30000 (4.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 139.5859s / 6013.4608 s
agent0:                 episode reward: 0.2157,                 loss: nan
agent1:                 episode reward: -0.2157,                 loss: 0.1438
Episode: 1261/30000 (4.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.6280s / 6153.0888 s
agent0:                 episode reward: -0.2363,                 loss: nan
agent1:                 episode reward: 0.2363,                 loss: 0.1442
Episode: 1281/30000 (4.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.4871s / 6290.5759 s
agent0:                 episode reward: -0.2053,                 loss: nan
agent1:                 episode reward: 0.2053,                 loss: 0.1435
Episode: 1301/30000 (4.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.7766s / 6427.3525 s
agent0:                 episode reward: 0.0129,                 loss: nan
agent1:                 episode reward: -0.0129,                 loss: 0.1423
Episode: 1321/30000 (4.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.8214s / 6564.1739 s
agent0:                 episode reward: 0.2820,                 loss: nan
agent1:                 episode reward: -0.2820,                 loss: 0.1429
Episode: 1341/30000 (4.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.9588s / 6700.1327 s
agent0:                 episode reward: -0.1430,                 loss: nan
agent1:                 episode reward: 0.1430,                 loss: 0.1442
Episode: 1361/30000 (4.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.3321s / 6836.4648 s
agent0:                 episode reward: -0.0504,                 loss: nan
agent1:                 episode reward: 0.0504,                 loss: 0.1446
Episode: 1381/30000 (4.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.3064s / 6975.7712 s
agent0:                 episode reward: 0.0889,                 loss: nan
agent1:                 episode reward: -0.0889,                 loss: 0.1437
Episode: 1401/30000 (4.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 142.7725s / 7118.5438 s
agent0:                 episode reward: 0.0239,                 loss: nan
agent1:                 episode reward: -0.0239,                 loss: 0.1421
Episode: 1421/30000 (4.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.4283s / 7254.9721 s
agent0:                 episode reward: 0.5522,                 loss: nan
agent1:                 episode reward: -0.5522,                 loss: 0.1420
Episode: 1441/30000 (4.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.5248s / 7394.4969 s
agent0:                 episode reward: 0.0471,                 loss: nan
agent1:                 episode reward: -0.0471,                 loss: 0.1424
Episode: 1461/30000 (4.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 140.2242s / 7534.7210 s
agent0:                 episode reward: 0.1819,                 loss: nan
agent1:                 episode reward: -0.1819,                 loss: 0.1427
Episode: 1481/30000 (4.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 138.8026s / 7673.5237 s
agent0:                 episode reward: 0.1441,                 loss: nan
agent1:                 episode reward: -0.1441,                 loss: 0.1426
Episode: 1501/30000 (5.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.8436s / 7810.3673 s
agent0:                 episode reward: 0.0101,                 loss: nan
agent1:                 episode reward: -0.0101,                 loss: 0.1427
Episode: 1521/30000 (5.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.4045s / 7948.7718 s
agent0:                 episode reward: -0.2297,                 loss: nan
agent1:                 episode reward: 0.2297,                 loss: 0.1431
Episode: 1541/30000 (5.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 138.8477s / 8087.6195 s
agent0:                 episode reward: 0.0708,                 loss: nan
agent1:                 episode reward: -0.0708,                 loss: 0.1426
Episode: 1561/30000 (5.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.3778s / 8224.9972 s
agent0:                 episode reward: -0.0194,                 loss: nan
agent1:                 episode reward: 0.0194,                 loss: 0.1421
Episode: 1581/30000 (5.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.1808s / 8363.1781 s
agent0:                 episode reward: 0.2516,                 loss: nan
agent1:                 episode reward: -0.2516,                 loss: 0.1422
Episode: 1601/30000 (5.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 140.8517s / 8504.0298 s
agent0:                 episode reward: 0.2493,                 loss: nan
agent1:                 episode reward: -0.2493,                 loss: 0.1424
Episode: 1621/30000 (5.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.8314s / 8643.8611 s
agent0:                 episode reward: 0.0271,                 loss: nan
agent1:                 episode reward: -0.0271,                 loss: 0.1422
Episode: 1641/30000 (5.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.8852s / 8782.7463 s
agent0:                 episode reward: 0.2161,                 loss: nan
agent1:                 episode reward: -0.2161,                 loss: 0.1417
Episode: 1661/30000 (5.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.8527s / 8918.5991 s
agent0:                 episode reward: -0.2808,                 loss: nan
agent1:                 episode reward: 0.2808,                 loss: 0.1415
Episode: 1681/30000 (5.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.8273s / 9058.4264 s
agent0:                 episode reward: 0.1190,                 loss: nan
agent1:                 episode reward: -0.1190,                 loss: 0.1407
Episode: 1701/30000 (5.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 139.8669s / 9198.2932 s
agent0:                 episode reward: -0.1030,                 loss: nan
agent1:                 episode reward: 0.1030,                 loss: 0.1427
Episode: 1721/30000 (5.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 138.3388s / 9336.6320 s
agent0:                 episode reward: 0.2109,                 loss: nan
agent1:                 episode reward: -0.2109,                 loss: 0.1428
Episode: 1741/30000 (5.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.4837s / 9476.1158 s
agent0:                 episode reward: -0.1460,                 loss: nan
agent1:                 episode reward: 0.1460,                 loss: 0.1406
Episode: 1761/30000 (5.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.7802s / 9612.8960 s
agent0:                 episode reward: -0.2177,                 loss: nan
agent1:                 episode reward: 0.2177,                 loss: 0.1422
Episode: 1781/30000 (5.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 138.3034s / 9751.1994 s
agent0:                 episode reward: -0.1702,                 loss: nan
agent1:                 episode reward: 0.1702,                 loss: 0.1426
Episode: 1801/30000 (6.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 141.3202s / 9892.5196 s
agent0:                 episode reward: 0.0480,                 loss: nan
agent1:                 episode reward: -0.0480,                 loss: 0.1421
Episode: 1821/30000 (6.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.8483s / 10028.3679 s
agent0:                 episode reward: -0.2842,                 loss: nan
agent1:                 episode reward: 0.2842,                 loss: 0.1421
Episode: 1841/30000 (6.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 141.8901s / 10170.2580 s
agent0:                 episode reward: -0.2154,                 loss: nan
agent1:                 episode reward: 0.2154,                 loss: 0.1406
Episode: 1861/30000 (6.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.8962s / 10309.1543 s
agent0:                 episode reward: 0.0199,                 loss: nan
agent1:                 episode reward: -0.0199,                 loss: 0.1399
Episode: 1881/30000 (6.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2652s / 10444.4195 s
agent0:                 episode reward: -0.3171,                 loss: nan
agent1:                 episode reward: 0.3171,                 loss: 0.1405
Episode: 1901/30000 (6.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 139.8254s / 10584.2449 s
agent0:                 episode reward: -0.1555,                 loss: nan
agent1:                 episode reward: 0.1555,                 loss: 0.1427
Episode: 1921/30000 (6.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 140.7472s / 10724.9921 s
agent0:                 episode reward: 0.0254,                 loss: nan
agent1:                 episode reward: -0.0254,                 loss: 0.1412
Episode: 1941/30000 (6.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.9298s / 10862.9220 s
agent0:                 episode reward: -0.1548,                 loss: nan
agent1:                 episode reward: 0.1548,                 loss: 0.1429
Episode: 1961/30000 (6.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.5980s / 10998.5199 s
agent0:                 episode reward: -0.3941,                 loss: nan
agent1:                 episode reward: 0.3941,                 loss: 0.1407
Episode: 1981/30000 (6.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.3557s / 11137.8757 s
agent0:                 episode reward: 0.0451,                 loss: nan
agent1:                 episode reward: -0.0451,                 loss: 0.1423
Episode: 2001/30000 (6.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.8717s / 11275.7474 s
agent0:                 episode reward: 0.0931,                 loss: nan
agent1:                 episode reward: -0.0931,                 loss: 0.1427
Episode: 2021/30000 (6.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 139.9976s / 11415.7450 s
agent0:                 episode reward: -0.0381,                 loss: nan
agent1:                 episode reward: 0.0381,                 loss: 0.1418
Episode: 2041/30000 (6.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.4842s / 11555.2292 s
agent0:                 episode reward: -0.1643,                 loss: nan
agent1:                 episode reward: 0.1643,                 loss: 0.1434
Episode: 2061/30000 (6.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.0588s / 11692.2879 s
agent0:                 episode reward: -0.1634,                 loss: nan
agent1:                 episode reward: 0.1634,                 loss: 0.1445
Episode: 2081/30000 (6.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 139.9520s / 11832.2399 s
agent0:                 episode reward: -0.1224,                 loss: nan
agent1:                 episode reward: 0.1224,                 loss: 0.1424
Episode: 2101/30000 (7.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.9255s / 11969.1654 s
agent0:                 episode reward: 0.0609,                 loss: nan
agent1:                 episode reward: -0.0609,                 loss: 0.1438
Episode: 2121/30000 (7.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.8430s / 12107.0084 s
agent0:                 episode reward: -0.1047,                 loss: nan
agent1:                 episode reward: 0.1047,                 loss: 0.1438
Episode: 2141/30000 (7.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 139.9461s / 12246.9545 s
agent0:                 episode reward: -0.1705,                 loss: nan
agent1:                 episode reward: 0.1705,                 loss: 0.1430
Episode: 2161/30000 (7.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 141.7838s / 12388.7383 s
agent0:                 episode reward: 0.1207,                 loss: nan
agent1:                 episode reward: -0.1207,                 loss: 0.1442
Episode: 2181/30000 (7.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 141.8095s / 12530.5478 s
agent0:                 episode reward: -0.1082,                 loss: nan
agent1:                 episode reward: 0.1082,                 loss: 0.1427
Episode: 2201/30000 (7.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 141.7123s / 12672.2601 s
agent0:                 episode reward: -0.0634,                 loss: nan
agent1:                 episode reward: 0.0634,                 loss: 0.1414
Episode: 2221/30000 (7.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 143.3919s / 12815.6521 s
agent0:                 episode reward: -0.0889,                 loss: nan
agent1:                 episode reward: 0.0889,                 loss: 0.1414
Episode: 2241/30000 (7.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 140.9657s / 12956.6178 s
agent0:                 episode reward: -0.8223,                 loss: nan
agent1:                 episode reward: 0.8223,                 loss: 0.1393
Episode: 2261/30000 (7.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 140.5196s / 13097.1373 s
agent0:                 episode reward: -0.3911,                 loss: nan
agent1:                 episode reward: 0.3911,                 loss: 0.1400
Episode: 2281/30000 (7.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 143.3227s / 13240.4600 s
agent0:                 episode reward: -0.2392,                 loss: nan
agent1:                 episode reward: 0.2392,                 loss: 0.1401
Episode: 2301/30000 (7.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 140.1607s / 13380.6208 s
agent0:                 episode reward: 0.1150,                 loss: nan
agent1:                 episode reward: -0.1150,                 loss: 0.1399
Episode: 2321/30000 (7.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 140.2474s / 13520.8682 s
agent0:                 episode reward: -0.2833,                 loss: nan
agent1:                 episode reward: 0.2833,                 loss: 0.1390
Episode: 2341/30000 (7.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 141.7463s / 13662.6145 s
agent0:                 episode reward: 0.0957,                 loss: nan
agent1:                 episode reward: -0.0957,                 loss: 0.1402
Episode: 2361/30000 (7.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 140.9104s / 13803.5250 s
agent0:                 episode reward: -0.3256,                 loss: nan
agent1:                 episode reward: 0.3256,                 loss: 0.1389
Episode: 2381/30000 (7.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 141.0541s / 13944.5790 s
agent0:                 episode reward: -0.1259,                 loss: nan
agent1:                 episode reward: 0.1259,                 loss: 0.1384
Episode: 2401/30000 (8.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 143.5130s / 14088.0920 s
agent0:                 episode reward: -0.5052,                 loss: nan
agent1:                 episode reward: 0.5052,                 loss: 0.1388
Episode: 2421/30000 (8.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 141.4218s / 14229.5138 s
agent0:                 episode reward: -0.1786,                 loss: nan
agent1:                 episode reward: 0.1786,                 loss: 0.1381
Episode: 2441/30000 (8.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 138.3255s / 14367.8392 s
agent0:                 episode reward: -0.1610,                 loss: nan
agent1:                 episode reward: 0.1610,                 loss: 0.1386
Episode: 2461/30000 (8.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 140.2667s / 14508.1059 s
agent0:                 episode reward: -0.0382,                 loss: nan
agent1:                 episode reward: 0.0382,                 loss: 0.1389
Episode: 2481/30000 (8.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 142.7257s / 14650.8316 s
agent0:                 episode reward: -0.2641,                 loss: nan
agent1:                 episode reward: 0.2641,                 loss: 0.1387
Episode: 2501/30000 (8.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 142.8305s / 14793.6622 s
agent0:                 episode reward: -0.3102,                 loss: nan
agent1:                 episode reward: 0.3102,                 loss: 0.1393
Episode: 2521/30000 (8.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 141.5932s / 14935.2553 s
agent0:                 episode reward: -0.4424,                 loss: nan
agent1:                 episode reward: 0.4424,                 loss: 0.1391
Episode: 2541/30000 (8.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 143.0372s / 15078.2925 s
agent0:                 episode reward: 0.1692,                 loss: nan
agent1:                 episode reward: -0.1692,                 loss: 0.1396
Episode: 2561/30000 (8.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 142.4964s / 15220.7890 s
agent0:                 episode reward: -0.2110,                 loss: nan
agent1:                 episode reward: 0.2110,                 loss: 0.1401
Episode: 2581/30000 (8.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 140.3340s / 15361.1230 s
agent0:                 episode reward: 0.0893,                 loss: nan
agent1:                 episode reward: -0.0893,                 loss: 0.1397
Episode: 2601/30000 (8.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 140.7437s / 15501.8667 s
agent0:                 episode reward: -0.1355,                 loss: nan
agent1:                 episode reward: 0.1355,                 loss: 0.1406
Episode: 2621/30000 (8.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 144.1844s / 15646.0511 s
agent0:                 episode reward: -0.1760,                 loss: nan
agent1:                 episode reward: 0.1760,                 loss: 0.1398
Episode: 2641/30000 (8.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 141.5094s / 15787.5604 s
agent0:                 episode reward: -0.2573,                 loss: nan
agent1:                 episode reward: 0.2573,                 loss: 0.1410
Episode: 2661/30000 (8.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 142.7714s / 15930.3319 s
agent0:                 episode reward: -0.2481,                 loss: nan
agent1:                 episode reward: 0.2481,                 loss: 0.1392
Episode: 2681/30000 (8.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 143.5899s / 16073.9218 s
agent0:                 episode reward: 0.0633,                 loss: nan
agent1:                 episode reward: -0.0633,                 loss: 0.1400
Episode: 2701/30000 (9.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 144.5057s / 16218.4274 s
agent0:                 episode reward: -0.1846,                 loss: nan
agent1:                 episode reward: 0.1846,                 loss: 0.1402
Episode: 2721/30000 (9.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 140.6743s / 16359.1017 s
agent0:                 episode reward: 0.3819,                 loss: nan
agent1:                 episode reward: -0.3819,                 loss: 0.1404
Episode: 2741/30000 (9.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 138.5554s / 16497.6572 s
agent0:                 episode reward: -0.3221,                 loss: nan
agent1:                 episode reward: 0.3221,                 loss: 0.1397
Episode: 2761/30000 (9.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 144.0902s / 16641.7474 s
agent0:                 episode reward: -0.0726,                 loss: nan
agent1:                 episode reward: 0.0726,                 loss: 0.1413
Episode: 2781/30000 (9.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.2789s / 16780.0263 s
agent0:                 episode reward: 0.0244,                 loss: nan
agent1:                 episode reward: -0.0244,                 loss: 0.1422
Episode: 2801/30000 (9.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 141.8074s / 16921.8337 s
agent0:                 episode reward: -0.1235,                 loss: nan
agent1:                 episode reward: 0.1235,                 loss: 0.1396
Episode: 2821/30000 (9.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.1738s / 17059.0075 s
agent0:                 episode reward: -0.0485,                 loss: nan
agent1:                 episode reward: 0.0485,                 loss: 0.1386
Episode: 2841/30000 (9.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 139.9356s / 17198.9432 s
agent0:                 episode reward: -0.0470,                 loss: nan
agent1:                 episode reward: 0.0470,                 loss: 0.1391
Episode: 2861/30000 (9.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 142.7899s / 17341.7331 s
agent0:                 episode reward: -0.0379,                 loss: nan
agent1:                 episode reward: 0.0379,                 loss: 0.1403
Episode: 2881/30000 (9.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.7824s / 17481.5155 s
agent0:                 episode reward: 0.0784,                 loss: nan
agent1:                 episode reward: -0.0784,                 loss: 0.1385
Episode: 2901/30000 (9.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 140.4866s / 17622.0021 s
agent0:                 episode reward: -0.0151,                 loss: nan
agent1:                 episode reward: 0.0151,                 loss: 0.1428
Episode: 2921/30000 (9.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 140.4742s / 17762.4762 s
agent0:                 episode reward: -0.1397,                 loss: nan
agent1:                 episode reward: 0.1397,                 loss: 0.1431
Episode: 2941/30000 (9.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.6792s / 17902.1554 s
agent0:                 episode reward: -0.0818,                 loss: nan
agent1:                 episode reward: 0.0818,                 loss: 0.1426
Episode: 2961/30000 (9.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 139.4318s / 18041.5873 s
agent0:                 episode reward: -0.1968,                 loss: nan
agent1:                 episode reward: 0.1968,                 loss: 0.1431
Episode: 2981/30000 (9.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 140.1863s / 18181.7736 s
agent0:                 episode reward: -0.2119,                 loss: nan
agent1:                 episode reward: 0.2119,                 loss: 0.1425
Episode: 3001/30000 (10.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 140.7687s / 18322.5423 s
agent0:                 episode reward: 0.0727,                 loss: nan
agent1:                 episode reward: -0.0727,                 loss: 0.1432
Episode: 3021/30000 (10.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 143.2092s / 18465.7515 s
agent0:                 episode reward: -0.1617,                 loss: nan
agent1:                 episode reward: 0.1617,                 loss: 0.1423
Episode: 3041/30000 (10.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.3450s / 18603.0965 s
agent0:                 episode reward: -0.1736,                 loss: nan
agent1:                 episode reward: 0.1736,                 loss: 0.1412
Episode: 3061/30000 (10.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 140.7102s / 18743.8067 s
agent0:                 episode reward: -0.0628,                 loss: nan
agent1:                 episode reward: 0.0628,                 loss: 0.1420
Episode: 3081/30000 (10.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 145.0335s / 18888.8402 s
agent0:                 episode reward: 0.1986,                 loss: nan
agent1:                 episode reward: -0.1986,                 loss: 0.1431
Episode: 3101/30000 (10.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.9759s / 19026.8161 s
agent0:                 episode reward: -0.1860,                 loss: nan
agent1:                 episode reward: 0.1860,                 loss: 0.1405
Episode: 3121/30000 (10.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 142.0098s / 19168.8260 s
agent0:                 episode reward: 0.2223,                 loss: nan
agent1:                 episode reward: -0.2223,                 loss: 0.1410
Episode: 3141/30000 (10.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 142.5176s / 19311.3436 s
agent0:                 episode reward: 0.1261,                 loss: nan
agent1:                 episode reward: -0.1261,                 loss: 0.1409
Episode: 3161/30000 (10.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 143.1534s / 19454.4970 s
agent0:                 episode reward: -0.2386,                 loss: nan
agent1:                 episode reward: 0.2386,                 loss: 0.1403
Episode: 3181/30000 (10.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 143.5987s / 19598.0957 s
agent0:                 episode reward: -0.4136,                 loss: nan
agent1:                 episode reward: 0.4136,                 loss: 0.1417
Episode: 3201/30000 (10.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 141.3849s / 19739.4806 s
agent0:                 episode reward: 0.0586,                 loss: nan
agent1:                 episode reward: -0.0586,                 loss: 0.1427
Episode: 3221/30000 (10.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 143.5324s / 19883.0129 s
agent0:                 episode reward: -0.4405,                 loss: nan
agent1:                 episode reward: 0.4405,                 loss: 0.1387
Episode: 3241/30000 (10.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 140.5734s / 20023.5863 s
agent0:                 episode reward: -0.6236,                 loss: nan
agent1:                 episode reward: 0.6236,                 loss: 0.1364
Episode: 3261/30000 (10.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 139.4842s / 20163.0705 s
agent0:                 episode reward: 0.1147,                 loss: nan
agent1:                 episode reward: -0.1147,                 loss: 0.1371
Episode: 3281/30000 (10.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 140.6189s / 20303.6894 s
agent0:                 episode reward: -0.2161,                 loss: nan
agent1:                 episode reward: 0.2161,                 loss: 0.1367
Episode: 3301/30000 (11.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 143.8743s / 20447.5637 s
agent0:                 episode reward: -0.4693,                 loss: nan
agent1:                 episode reward: 0.4693,                 loss: 0.1379
Episode: 3321/30000 (11.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 141.2843s / 20588.8480 s
agent0:                 episode reward: -0.1901,                 loss: nan
agent1:                 episode reward: 0.1901,                 loss: 0.1362
Episode: 3341/30000 (11.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 139.0681s / 20727.9161 s
agent0:                 episode reward: -0.1645,                 loss: nan
agent1:                 episode reward: 0.1645,                 loss: 0.1352
Episode: 3361/30000 (11.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4401s / 20863.3562 s
agent0:                 episode reward: -0.7947,                 loss: nan
agent1:                 episode reward: 0.7947,                 loss: 0.1355
Episode: 3381/30000 (11.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.3219s / 20996.6781 s
agent0:                 episode reward: -0.1101,                 loss: nan
agent1:                 episode reward: 0.1101,                 loss: 0.1364
Episode: 3401/30000 (11.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.7173s / 21130.3954 s
agent0:                 episode reward: 0.1545,                 loss: nan
agent1:                 episode reward: -0.1545,                 loss: 0.1355
Episode: 3421/30000 (11.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.4497s / 21267.8451 s
agent0:                 episode reward: -0.2077,                 loss: nan
agent1:                 episode reward: 0.2077,                 loss: 0.1357
Episode: 3441/30000 (11.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 144.9626s / 21412.8077 s
agent0:                 episode reward: 0.0857,                 loss: nan
agent1:                 episode reward: -0.0857,                 loss: 0.1385
Episode: 3461/30000 (11.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 144.9105s / 21557.7182 s
agent0:                 episode reward: -0.3142,                 loss: nan
agent1:                 episode reward: 0.3142,                 loss: 0.1378
Episode: 3481/30000 (11.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 144.1175s / 21701.8357 s
agent0:                 episode reward: -0.0893,                 loss: nan
agent1:                 episode reward: 0.0893,                 loss: 0.1367
Episode: 3501/30000 (11.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 140.3772s / 21842.2129 s
agent0:                 episode reward: 0.0785,                 loss: nan
agent1:                 episode reward: -0.0785,                 loss: 0.1377
Episode: 3521/30000 (11.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 142.3749s / 21984.5878 s
agent0:                 episode reward: -0.0440,                 loss: nan
agent1:                 episode reward: 0.0440,                 loss: 0.1354
Episode: 3541/30000 (11.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 141.5742s / 22126.1620 s
agent0:                 episode reward: -0.5740,                 loss: nan
agent1:                 episode reward: 0.5740,                 loss: 0.1374
Episode: 3561/30000 (11.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 141.2713s / 22267.4333 s
agent0:                 episode reward: -0.5697,                 loss: nan
agent1:                 episode reward: 0.5697,                 loss: 0.1424
Episode: 3581/30000 (11.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 143.7035s / 22411.1368 s
agent0:                 episode reward: -0.3299,                 loss: nan
agent1:                 episode reward: 0.3299,                 loss: 0.1440
Episode: 3601/30000 (12.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 142.4356s / 22553.5723 s
agent0:                 episode reward: -0.0212,                 loss: nan
agent1:                 episode reward: 0.0212,                 loss: 0.1444
Episode: 3621/30000 (12.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 144.6013s / 22698.1736 s
agent0:                 episode reward: -0.3743,                 loss: nan
agent1:                 episode reward: 0.3743,                 loss: 0.1425
Episode: 3641/30000 (12.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 143.3551s / 22841.5287 s
agent0:                 episode reward: -0.4277,                 loss: nan
agent1:                 episode reward: 0.4277,                 loss: 0.1446
Episode: 3661/30000 (12.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 143.4102s / 22984.9388 s
agent0:                 episode reward: -0.4842,                 loss: nan
agent1:                 episode reward: 0.4842,                 loss: 0.1456
Episode: 3681/30000 (12.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 142.8270s / 23127.7658 s
agent0:                 episode reward: 0.0040,                 loss: nan
agent1:                 episode reward: -0.0040,                 loss: 0.1437
Episode: 3701/30000 (12.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 141.9799s / 23269.7457 s
agent0:                 episode reward: 0.2326,                 loss: nan
agent1:                 episode reward: -0.2326,                 loss: 0.1429
Episode: 3721/30000 (12.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 140.9128s / 23410.6585 s
agent0:                 episode reward: -0.0086,                 loss: nan
agent1:                 episode reward: 0.0086,                 loss: 0.1448
Episode: 3741/30000 (12.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 140.4245s / 23551.0830 s
agent0:                 episode reward: -0.0573,                 loss: nan
agent1:                 episode reward: 0.0573,                 loss: 0.1442
Episode: 3761/30000 (12.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 144.1285s / 23695.2115 s
agent0:                 episode reward: -0.1276,                 loss: nan
agent1:                 episode reward: 0.1276,                 loss: 0.1433
Episode: 3781/30000 (12.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 142.4125s / 23837.6240 s
agent0:                 episode reward: -0.3686,                 loss: nan
agent1:                 episode reward: 0.3686,                 loss: 0.1437
Episode: 3801/30000 (12.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 141.5051s / 23979.1291 s
agent0:                 episode reward: -0.2521,                 loss: nan
agent1:                 episode reward: 0.2521,                 loss: 0.1448
Episode: 3821/30000 (12.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 144.3670s / 24123.4961 s
agent0:                 episode reward: -0.2731,                 loss: nan
agent1:                 episode reward: 0.2731,                 loss: 0.1448
Episode: 3841/30000 (12.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 143.9425s / 24267.4385 s
agent0:                 episode reward: -0.6287,                 loss: nan
agent1:                 episode reward: 0.6287,                 loss: 0.1448
Episode: 3861/30000 (12.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 142.6338s / 24410.0723 s
agent0:                 episode reward: -0.3269,                 loss: nan
agent1:                 episode reward: 0.3269,                 loss: 0.1426
Episode: 3881/30000 (12.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 144.1894s / 24554.2617 s
agent0:                 episode reward: 0.1100,                 loss: nan
agent1:                 episode reward: -0.1100,                 loss: 0.1448
Episode: 3901/30000 (13.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 142.6738s / 24696.9355 s
agent0:                 episode reward: -0.5010,                 loss: nan
agent1:                 episode reward: 0.5010,                 loss: 0.1390
Episode: 3921/30000 (13.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 143.3212s / 24840.2567 s
agent0:                 episode reward: -0.6013,                 loss: nan
agent1:                 episode reward: 0.6013,                 loss: 0.1399
Episode: 3941/30000 (13.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 146.3144s / 24986.5711 s
agent0:                 episode reward: -0.1057,                 loss: nan
agent1:                 episode reward: 0.1057,                 loss: 0.1384
Episode: 3961/30000 (13.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 142.6421s / 25129.2132 s
agent0:                 episode reward: -0.1593,                 loss: nan
agent1:                 episode reward: 0.1593,                 loss: 0.1380
Episode: 3981/30000 (13.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 143.6445s / 25272.8577 s
agent0:                 episode reward: -0.1736,                 loss: nan
agent1:                 episode reward: 0.1736,                 loss: 0.1388
Episode: 4001/30000 (13.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 143.0435s / 25415.9012 s
agent0:                 episode reward: -0.0402,                 loss: nan
agent1:                 episode reward: 0.0402,                 loss: 0.1382
Episode: 4021/30000 (13.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 143.1734s / 25559.0745 s
agent0:                 episode reward: 0.0551,                 loss: nan
agent1:                 episode reward: -0.0551,                 loss: 0.1400
Episode: 4041/30000 (13.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 145.7167s / 25704.7912 s
agent0:                 episode reward: -0.2037,                 loss: nan
agent1:                 episode reward: 0.2037,                 loss: 0.1377
Episode: 4061/30000 (13.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 145.4719s / 25850.2631 s
agent0:                 episode reward: -0.1003,                 loss: nan
agent1:                 episode reward: 0.1003,                 loss: 0.1386
Episode: 4081/30000 (13.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 143.9336s / 25994.1967 s
agent0:                 episode reward: 0.0165,                 loss: nan
agent1:                 episode reward: -0.0165,                 loss: 0.1406
Episode: 4101/30000 (13.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 144.4604s / 26138.6570 s
agent0:                 episode reward: -0.3035,                 loss: nan
agent1:                 episode reward: 0.3035,                 loss: 0.1387
Episode: 4121/30000 (13.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 140.6002s / 26279.2572 s
agent0:                 episode reward: -0.0042,                 loss: nan
agent1:                 episode reward: 0.0042,                 loss: 0.1396
Episode: 4141/30000 (13.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 144.3630s / 26423.6202 s
agent0:                 episode reward: -0.1532,                 loss: nan
agent1:                 episode reward: 0.1532,                 loss: 0.1394
Episode: 4161/30000 (13.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 147.5220s / 26571.1423 s
agent0:                 episode reward: -0.0763,                 loss: nan
agent1:                 episode reward: 0.0763,                 loss: 0.1412
Episode: 4181/30000 (13.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 144.4148s / 26715.5571 s
agent0:                 episode reward: -0.3372,                 loss: nan
agent1:                 episode reward: 0.3372,                 loss: 0.1395
Episode: 4201/30000 (14.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 145.4314s / 26860.9885 s
agent0:                 episode reward: -0.2785,                 loss: nan
agent1:                 episode reward: 0.2785,                 loss: 0.1407
Episode: 4221/30000 (14.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 143.3013s / 27004.2898 s
agent0:                 episode reward: -0.0242,                 loss: nan
agent1:                 episode reward: 0.0242,                 loss: 0.1407
Episode: 4241/30000 (14.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 143.8644s / 27148.1541 s
agent0:                 episode reward: -0.1076,                 loss: nan
agent1:                 episode reward: 0.1076,                 loss: 0.1391
Episode: 4261/30000 (14.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 146.5967s / 27294.7508 s
agent0:                 episode reward: -0.2260,                 loss: nan
agent1:                 episode reward: 0.2260,                 loss: 0.1385
Episode: 4281/30000 (14.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8658s / 27429.6166 s
agent0:                 episode reward: -0.3232,                 loss: nan
agent1:                 episode reward: 0.3232,                 loss: 0.1398
Episode: 4301/30000 (14.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1949s / 27563.8115 s
agent0:                 episode reward: -0.3535,                 loss: nan
agent1:                 episode reward: 0.3535,                 loss: 0.1391
Episode: 4321/30000 (14.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9896s / 27698.8011 s
agent0:                 episode reward: -0.0366,                 loss: nan
agent1:                 episode reward: 0.0366,                 loss: 0.1383
Episode: 4341/30000 (14.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.5140s / 27834.3151 s
agent0:                 episode reward: -0.3424,                 loss: nan
agent1:                 episode reward: 0.3424,                 loss: 0.1410
Episode: 4361/30000 (14.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.8484s / 27970.1635 s
agent0:                 episode reward: -0.3706,                 loss: nan
agent1:                 episode reward: 0.3706,                 loss: 0.1401
Episode: 4381/30000 (14.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.3729s / 28104.5364 s
agent0:                 episode reward: -0.3900,                 loss: nan
agent1:                 episode reward: 0.3900,                 loss: 0.1399
Episode: 4401/30000 (14.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8387s / 28239.3751 s
agent0:                 episode reward: 0.3034,                 loss: nan
agent1:                 episode reward: -0.3034,                 loss: 0.1400
Episode: 4421/30000 (14.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.8505s / 28373.2256 s
agent0:                 episode reward: -0.8145,                 loss: nan
agent1:                 episode reward: 0.8145,                 loss: 0.1384
Episode: 4441/30000 (14.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.1838s / 28509.4094 s
agent0:                 episode reward: -0.4795,                 loss: nan
agent1:                 episode reward: 0.4795,                 loss: 0.1403
Episode: 4461/30000 (14.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.0412s / 28644.4506 s
agent0:                 episode reward: -0.2384,                 loss: nan
agent1:                 episode reward: 0.2384,                 loss: 0.1404
Episode: 4481/30000 (14.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2443s / 28780.6949 s
agent0:                 episode reward: -0.2001,                 loss: nan
agent1:                 episode reward: 0.2001,                 loss: 0.1384
Episode: 4501/30000 (15.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.3737s / 28917.0686 s
agent0:                 episode reward: -0.1583,                 loss: nan
agent1:                 episode reward: 0.1583,                 loss: 0.1395
Episode: 4521/30000 (15.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7819s / 29052.8505 s
agent0:                 episode reward: -0.3358,                 loss: nan
agent1:                 episode reward: 0.3358,                 loss: 0.1406
Episode: 4541/30000 (15.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.9925s / 29186.8431 s
agent0:                 episode reward: -0.3854,                 loss: nan
agent1:                 episode reward: 0.3854,                 loss: 0.1403
Episode: 4561/30000 (15.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3653s / 29322.2083 s
agent0:                 episode reward: -0.3818,                 loss: nan
agent1:                 episode reward: 0.3818,                 loss: 0.1371
Episode: 4581/30000 (15.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6695s / 29457.8778 s
agent0:                 episode reward: -0.1688,                 loss: nan
agent1:                 episode reward: 0.1688,                 loss: 0.1363
Episode: 4601/30000 (15.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.3814s / 29590.2592 s
agent0:                 episode reward: 0.1442,                 loss: nan
agent1:                 episode reward: -0.1442,                 loss: 0.1376
Episode: 4621/30000 (15.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.9700s / 29723.2292 s
agent0:                 episode reward: -0.1281,                 loss: nan
agent1:                 episode reward: 0.1281,                 loss: 0.1356
Episode: 4641/30000 (15.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.7210s / 29857.9502 s
agent0:                 episode reward: -0.0660,                 loss: nan
agent1:                 episode reward: 0.0660,                 loss: 0.1375
Episode: 4661/30000 (15.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 131.5162s / 29989.4664 s
agent0:                 episode reward: -0.3887,                 loss: nan
agent1:                 episode reward: 0.3887,                 loss: 0.1380
Episode: 4681/30000 (15.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.7091s / 30126.1755 s
agent0:                 episode reward: -0.4234,                 loss: nan
agent1:                 episode reward: 0.4234,                 loss: 0.1372
Episode: 4701/30000 (15.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0253s / 30260.2008 s
agent0:                 episode reward: 0.0984,                 loss: nan
agent1:                 episode reward: -0.0984,                 loss: 0.1364
Episode: 4721/30000 (15.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.8454s / 30394.0462 s
agent0:                 episode reward: -0.2966,                 loss: nan
agent1:                 episode reward: 0.2966,                 loss: 0.1373
Episode: 4741/30000 (15.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.4058s / 30528.4520 s
agent0:                 episode reward: -0.2262,                 loss: nan
agent1:                 episode reward: 0.2262,                 loss: 0.1369
Episode: 4761/30000 (15.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.8280s / 30661.2800 s
agent0:                 episode reward: -0.4818,                 loss: nan
agent1:                 episode reward: 0.4818,                 loss: 0.1373
Episode: 4781/30000 (15.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.3462s / 30798.6262 s
agent0:                 episode reward: -0.2876,                 loss: nan
agent1:                 episode reward: 0.2876,                 loss: 0.1373
Episode: 4801/30000 (16.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.4646s / 30931.0908 s
agent0:                 episode reward: -0.0230,                 loss: nan
agent1:                 episode reward: 0.0230,                 loss: 0.1388
Episode: 4821/30000 (16.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.5467s / 31063.6375 s
agent0:                 episode reward: -0.2933,                 loss: nan
agent1:                 episode reward: 0.2933,                 loss: 0.1373
Episode: 4841/30000 (16.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6844s / 31198.3219 s
agent0:                 episode reward: -0.1759,                 loss: nan
agent1:                 episode reward: 0.1759,                 loss: 0.1379
Episode: 4861/30000 (16.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.9733s / 31338.2952 s
agent0:                 episode reward: -0.3050,                 loss: nan
agent1:                 episode reward: 0.3050,                 loss: 0.1363
Episode: 4881/30000 (16.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.9361s / 31474.2313 s
agent0:                 episode reward: 0.2893,                 loss: nan
agent1:                 episode reward: -0.2893,                 loss: 0.1358
Episode: 4901/30000 (16.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.2842s / 31611.5155 s
agent0:                 episode reward: -0.0112,                 loss: nan
agent1:                 episode reward: 0.0112,                 loss: 0.1381
Episode: 4921/30000 (16.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6380s / 31746.1535 s
agent0:                 episode reward: -0.4036,                 loss: nan
agent1:                 episode reward: 0.4036,                 loss: 0.1393
Episode: 4941/30000 (16.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1280s / 31880.2815 s
agent0:                 episode reward: -0.6698,                 loss: nan
agent1:                 episode reward: 0.6698,                 loss: 0.1388
Episode: 4961/30000 (16.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 131.4628s / 32011.7443 s
agent0:                 episode reward: 0.0022,                 loss: nan
agent1:                 episode reward: -0.0022,                 loss: 0.1395
Episode: 4981/30000 (16.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.0699s / 32144.8142 s
agent0:                 episode reward: -0.4208,                 loss: nan
agent1:                 episode reward: 0.4208,                 loss: 0.1387
Episode: 5001/30000 (16.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3056s / 32280.1198 s
agent0:                 episode reward: -0.1793,                 loss: nan
agent1:                 episode reward: 0.1793,                 loss: 0.1386
Episode: 5021/30000 (16.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.5798s / 32415.6996 s
agent0:                 episode reward: -0.4482,                 loss: nan
agent1:                 episode reward: 0.4482,                 loss: 0.1387
Episode: 5041/30000 (16.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.7742s / 32552.4738 s
agent0:                 episode reward: -0.1991,                 loss: nan
agent1:                 episode reward: 0.1991,                 loss: 0.1381
Episode: 5061/30000 (16.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.9995s / 32689.4733 s
agent0:                 episode reward: -0.4651,                 loss: nan
agent1:                 episode reward: 0.4651,                 loss: 0.1392
Episode: 5081/30000 (16.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.2817s / 32821.7550 s
agent0:                 episode reward: -0.4375,                 loss: nan
agent1:                 episode reward: 0.4375,                 loss: 0.1389
Episode: 5101/30000 (17.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.1123s / 32957.8673 s
agent0:                 episode reward: -0.1502,                 loss: nan
agent1:                 episode reward: 0.1502,                 loss: 0.1381
Episode: 5121/30000 (17.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.0158s / 33089.8831 s
agent0:                 episode reward: -0.0427,                 loss: nan
agent1:                 episode reward: 0.0427,                 loss: 0.1382
Episode: 5141/30000 (17.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.3591s / 33224.2422 s
agent0:                 episode reward: -0.3642,                 loss: nan
agent1:                 episode reward: 0.3642,                 loss: 0.1382
Episode: 5161/30000 (17.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.5293s / 33357.7715 s
agent0:                 episode reward: -0.4118,                 loss: nan
agent1:                 episode reward: 0.4118,                 loss: 0.1386
Episode: 5181/30000 (17.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 131.7398s / 33489.5113 s
agent0:                 episode reward: 0.0695,                 loss: nan
agent1:                 episode reward: -0.0695,                 loss: 0.1389
Episode: 5201/30000 (17.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7767s / 33625.2880 s
agent0:                 episode reward: -0.3624,                 loss: nan
agent1:                 episode reward: 0.3624,                 loss: 0.1377
Episode: 5221/30000 (17.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2573s / 33760.5452 s
agent0:                 episode reward: -0.9885,                 loss: nan
agent1:                 episode reward: 0.9885,                 loss: 0.1393
Episode: 5241/30000 (17.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1261s / 33894.6714 s
agent0:                 episode reward: 0.0343,                 loss: nan
agent1:                 episode reward: -0.0343,                 loss: 0.1390
Episode: 5261/30000 (17.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.7812s / 34031.4526 s
agent0:                 episode reward: -0.0318,                 loss: nan
agent1:                 episode reward: 0.0318,                 loss: 0.1379
Episode: 5281/30000 (17.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.8570s / 34170.3096 s
agent0:                 episode reward: 0.1254,                 loss: nan
agent1:                 episode reward: -0.1254,                 loss: 0.1410
Episode: 5301/30000 (17.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.7660s / 34304.0756 s
agent0:                 episode reward: -0.2920,                 loss: nan
agent1:                 episode reward: 0.2920,                 loss: 0.1383
Episode: 5321/30000 (17.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.9633s / 34438.0389 s
agent0:                 episode reward: -0.0028,                 loss: nan
agent1:                 episode reward: 0.0028,                 loss: 0.1385
Episode: 5341/30000 (17.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.8610s / 34573.8998 s
agent0:                 episode reward: -0.0677,                 loss: nan
agent1:                 episode reward: 0.0677,                 loss: 0.1381
Episode: 5361/30000 (17.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.5113s / 34706.4111 s
agent0:                 episode reward: -0.3538,                 loss: nan
agent1:                 episode reward: 0.3538,                 loss: 0.1398
Episode: 5381/30000 (17.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.4567s / 34839.8678 s
agent0:                 episode reward: 0.0084,                 loss: nan
agent1:                 episode reward: -0.0084,                 loss: 0.1404
Episode: 5401/30000 (18.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7436s / 34975.6114 s
agent0:                 episode reward: -0.4849,                 loss: nan
agent1:                 episode reward: 0.4849,                 loss: 0.1390
Episode: 5421/30000 (18.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.3136s / 35109.9250 s
agent0:                 episode reward: -0.4669,                 loss: nan
agent1:                 episode reward: 0.4669,                 loss: 0.1399
Episode: 5441/30000 (18.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 138.7508s / 35248.6758 s
agent0:                 episode reward: 0.0981,                 loss: nan
agent1:                 episode reward: -0.0981,                 loss: 0.1400
Episode: 5461/30000 (18.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.1538s / 35384.8296 s
agent0:                 episode reward: -0.4065,                 loss: nan
agent1:                 episode reward: 0.4065,                 loss: 0.1398
Episode: 5481/30000 (18.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5402s / 35519.3698 s
agent0:                 episode reward: 0.0381,                 loss: nan
agent1:                 episode reward: -0.0381,                 loss: 0.1395
Episode: 5501/30000 (18.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1708s / 35654.5406 s
agent0:                 episode reward: -0.2198,                 loss: nan
agent1:                 episode reward: 0.2198,                 loss: 0.1372
Episode: 5521/30000 (18.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0270s / 35790.5676 s
agent0:                 episode reward: 0.2202,                 loss: nan
agent1:                 episode reward: -0.2202,                 loss: 0.1399
Episode: 5541/30000 (18.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.7354s / 35925.3030 s
agent0:                 episode reward: -0.2710,                 loss: nan
agent1:                 episode reward: 0.2710,                 loss: 0.1399
Episode: 5561/30000 (18.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.2536s / 36058.5566 s
agent0:                 episode reward: 0.0133,                 loss: nan
agent1:                 episode reward: -0.0133,                 loss: 0.1387
Episode: 5581/30000 (18.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.5589s / 36191.1155 s
agent0:                 episode reward: -0.3385,                 loss: nan
agent1:                 episode reward: 0.3385,                 loss: 0.1385
Episode: 5601/30000 (18.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.6284s / 36324.7439 s
agent0:                 episode reward: 0.0021,                 loss: nan
agent1:                 episode reward: -0.0021,                 loss: 0.1390
Episode: 5621/30000 (18.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.9230s / 36458.6669 s
agent0:                 episode reward: 0.0804,                 loss: nan
agent1:                 episode reward: -0.0804,                 loss: 0.1378
Episode: 5641/30000 (18.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.5394s / 36594.2062 s
agent0:                 episode reward: -0.5854,                 loss: nan
agent1:                 episode reward: 0.5854,                 loss: 0.1374
Episode: 5661/30000 (18.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4099s / 36729.6162 s
agent0:                 episode reward: -0.2505,                 loss: nan
agent1:                 episode reward: 0.2505,                 loss: 0.1390
Episode: 5681/30000 (18.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.6820s / 36866.2982 s
agent0:                 episode reward: 0.2029,                 loss: nan
agent1:                 episode reward: -0.2029,                 loss: 0.1376
Episode: 5701/30000 (19.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2715s / 37001.5697 s
agent0:                 episode reward: -0.1534,                 loss: nan
agent1:                 episode reward: 0.1534,                 loss: 0.1366
Episode: 5721/30000 (19.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2554s / 37136.8251 s
agent0:                 episode reward: -0.4320,                 loss: nan
agent1:                 episode reward: 0.4320,                 loss: 0.1380
Episode: 5741/30000 (19.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.1990s / 37269.0241 s
agent0:                 episode reward: -0.0326,                 loss: nan
agent1:                 episode reward: 0.0326,                 loss: 0.1385
Episode: 5761/30000 (19.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2336s / 37405.2577 s
agent0:                 episode reward: -0.1087,                 loss: nan
agent1:                 episode reward: 0.1087,                 loss: 0.1371
Episode: 5781/30000 (19.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.3396s / 37541.5973 s
agent0:                 episode reward: -0.2466,                 loss: nan
agent1:                 episode reward: 0.2466,                 loss: 0.1401
Episode: 5801/30000 (19.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2348s / 37677.8321 s
agent0:                 episode reward: -0.1246,                 loss: nan
agent1:                 episode reward: 0.1246,                 loss: 0.1379
Episode: 5821/30000 (19.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0007s / 37811.8328 s
agent0:                 episode reward: -0.3932,                 loss: nan
agent1:                 episode reward: 0.3932,                 loss: 0.1372
Episode: 5841/30000 (19.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.3538s / 37945.1866 s
agent0:                 episode reward: -0.3665,                 loss: nan
agent1:                 episode reward: 0.3665,                 loss: 0.1387
Episode: 5861/30000 (19.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1818s / 38080.3684 s
agent0:                 episode reward: -0.0165,                 loss: nan
agent1:                 episode reward: 0.0165,                 loss: 0.1393
Episode: 5881/30000 (19.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.8739s / 38217.2423 s
agent0:                 episode reward: 0.0420,                 loss: nan
agent1:                 episode reward: -0.0420,                 loss: 0.1387
Episode: 5901/30000 (19.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.1613s / 38353.4036 s
agent0:                 episode reward: -0.0752,                 loss: nan
agent1:                 episode reward: 0.0752,                 loss: 0.1410
Episode: 5921/30000 (19.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9747s / 38488.3783 s
agent0:                 episode reward: -0.2309,                 loss: nan
agent1:                 episode reward: 0.2309,                 loss: 0.1404
Episode: 5941/30000 (19.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0823s / 38622.4606 s
agent0:                 episode reward: -0.4220,                 loss: nan
agent1:                 episode reward: 0.4220,                 loss: 0.1422
Episode: 5961/30000 (19.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.2413s / 38759.7018 s
agent0:                 episode reward: -0.1633,                 loss: nan
agent1:                 episode reward: 0.1633,                 loss: 0.1400
Episode: 5981/30000 (19.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0783s / 38893.7801 s
agent0:                 episode reward: -0.4592,                 loss: nan
agent1:                 episode reward: 0.4592,                 loss: 0.1399
Episode: 6001/30000 (20.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.1254s / 39030.9055 s
agent0:                 episode reward: -0.3652,                 loss: nan
agent1:                 episode reward: 0.3652,                 loss: 0.1402
Episode: 6021/30000 (20.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.2686s / 39169.1741 s
agent0:                 episode reward: -0.4530,                 loss: nan
agent1:                 episode reward: 0.4530,                 loss: 0.1408
Episode: 6041/30000 (20.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.2223s / 39303.3964 s
agent0:                 episode reward: -0.2629,                 loss: nan
agent1:                 episode reward: 0.2629,                 loss: 0.1416
Episode: 6061/30000 (20.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.4999s / 39435.8963 s
agent0:                 episode reward: -0.1353,                 loss: nan
agent1:                 episode reward: 0.1353,                 loss: 0.1419
Episode: 6081/30000 (20.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.7880s / 39570.6843 s
agent0:                 episode reward: -0.5956,                 loss: nan
agent1:                 episode reward: 0.5956,                 loss: 0.1404
Episode: 6101/30000 (20.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9065s / 39705.5908 s
agent0:                 episode reward: -0.0293,                 loss: nan
agent1:                 episode reward: 0.0293,                 loss: 0.1420
Episode: 6121/30000 (20.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.3169s / 39842.9077 s
agent0:                 episode reward: -0.3379,                 loss: nan
agent1:                 episode reward: 0.3379,                 loss: 0.1399
Episode: 6141/30000 (20.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6550s / 39978.5627 s
agent0:                 episode reward: -0.3719,                 loss: nan
agent1:                 episode reward: 0.3719,                 loss: 0.1412
Episode: 6161/30000 (20.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.5613s / 40114.1241 s
agent0:                 episode reward: -0.3546,                 loss: nan
agent1:                 episode reward: 0.3546,                 loss: 0.1407
Episode: 6181/30000 (20.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.2681s / 40248.3922 s
agent0:                 episode reward: -0.0313,                 loss: nan
agent1:                 episode reward: 0.0313,                 loss: 0.1414
Episode: 6201/30000 (20.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.4505s / 40382.8427 s
agent0:                 episode reward: -0.1996,                 loss: nan
agent1:                 episode reward: 0.1996,                 loss: 0.1405
Episode: 6221/30000 (20.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1531s / 40516.9957 s
agent0:                 episode reward: -0.5073,                 loss: nan
agent1:                 episode reward: 0.5073,                 loss: 0.1397
Episode: 6241/30000 (20.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5793s / 40651.5750 s
agent0:                 episode reward: -0.1111,                 loss: nan
agent1:                 episode reward: 0.1111,                 loss: 0.1357
Episode: 6261/30000 (20.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.5150s / 40785.0901 s
agent0:                 episode reward: -0.1198,                 loss: nan
agent1:                 episode reward: 0.1198,                 loss: 0.1387
Episode: 6281/30000 (20.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 140.5535s / 40925.6436 s
agent0:                 episode reward: -0.1714,                 loss: nan
agent1:                 episode reward: 0.1714,                 loss: 0.1386
Episode: 6301/30000 (21.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.4107s / 41058.0542 s
agent0:                 episode reward: -0.4338,                 loss: nan
agent1:                 episode reward: 0.4338,                 loss: 0.1384
Episode: 6321/30000 (21.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.1113s / 41191.1655 s
agent0:                 episode reward: -0.2463,                 loss: nan
agent1:                 episode reward: 0.2463,                 loss: 0.1381
Episode: 6341/30000 (21.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.7039s / 41325.8694 s
agent0:                 episode reward: -0.1390,                 loss: nan
agent1:                 episode reward: 0.1390,                 loss: 0.1388
Episode: 6361/30000 (21.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7293s / 41461.5987 s
agent0:                 episode reward: -0.4687,                 loss: nan
agent1:                 episode reward: 0.4687,                 loss: 0.1387
Episode: 6381/30000 (21.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7035s / 41597.3022 s
agent0:                 episode reward: -0.3623,                 loss: nan
agent1:                 episode reward: 0.3623,                 loss: 0.1389
Episode: 6401/30000 (21.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9573s / 41732.2595 s
agent0:                 episode reward: -0.1056,                 loss: nan
agent1:                 episode reward: 0.1056,                 loss: 0.1386
Episode: 6421/30000 (21.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1016s / 41867.3611 s
agent0:                 episode reward: 0.1686,                 loss: nan
agent1:                 episode reward: -0.1686,                 loss: 0.1368
Episode: 6441/30000 (21.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4491s / 42002.8101 s
agent0:                 episode reward: -0.3652,                 loss: nan
agent1:                 episode reward: 0.3652,                 loss: 0.1384
Episode: 6461/30000 (21.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.5287s / 42135.3388 s
agent0:                 episode reward: -0.4163,                 loss: nan
agent1:                 episode reward: 0.4163,                 loss: 0.1374
Episode: 6481/30000 (21.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2707s / 42270.6095 s
agent0:                 episode reward: 0.1185,                 loss: nan
agent1:                 episode reward: -0.1185,                 loss: 0.1390
Episode: 6501/30000 (21.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0667s / 42406.6763 s
agent0:                 episode reward: -0.2852,                 loss: nan
agent1:                 episode reward: 0.2852,                 loss: 0.1373
Episode: 6521/30000 (21.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.4784s / 42543.1546 s
agent0:                 episode reward: -0.3376,                 loss: nan
agent1:                 episode reward: 0.3376,                 loss: 0.1384
Episode: 6541/30000 (21.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.3698s / 42676.5244 s
agent0:                 episode reward: -0.4079,                 loss: nan
agent1:                 episode reward: 0.4079,                 loss: 0.1370
Episode: 6561/30000 (21.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3422s / 42811.8666 s
agent0:                 episode reward: -0.4477,                 loss: nan
agent1:                 episode reward: 0.4477,                 loss: 0.1377
Episode: 6581/30000 (21.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.0218s / 42946.8884 s
agent0:                 episode reward: -0.2574,                 loss: nan
agent1:                 episode reward: 0.2574,                 loss: 0.1368
Episode: 6601/30000 (22.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0549s / 43080.9433 s
agent0:                 episode reward: -0.2179,                 loss: nan
agent1:                 episode reward: 0.2179,                 loss: 0.1371
Episode: 6621/30000 (22.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.7415s / 43213.6849 s
agent0:                 episode reward: -0.0822,                 loss: nan
agent1:                 episode reward: 0.0822,                 loss: 0.1373
Episode: 6641/30000 (22.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.9081s / 43347.5929 s
agent0:                 episode reward: -0.0878,                 loss: nan
agent1:                 episode reward: 0.0878,                 loss: 0.1372
Episode: 6661/30000 (22.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.2156s / 43479.8085 s
agent0:                 episode reward: -0.2982,                 loss: nan
agent1:                 episode reward: 0.2982,                 loss: 0.1373
Episode: 6681/30000 (22.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.0498s / 43617.8583 s
agent0:                 episode reward: -0.6163,                 loss: nan
agent1:                 episode reward: 0.6163,                 loss: 0.1359
Episode: 6701/30000 (22.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0593s / 43751.9176 s
agent0:                 episode reward: -0.5628,                 loss: nan
agent1:                 episode reward: 0.5628,                 loss: 0.1357
Episode: 6721/30000 (22.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9019s / 43886.8196 s
agent0:                 episode reward: -0.1051,                 loss: nan
agent1:                 episode reward: 0.1051,                 loss: 0.1371
Episode: 6741/30000 (22.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.3770s / 44024.1966 s
agent0:                 episode reward: -0.1575,                 loss: nan
agent1:                 episode reward: 0.1575,                 loss: 0.1376
Episode: 6761/30000 (22.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2612s / 44159.4578 s
agent0:                 episode reward: -0.3352,                 loss: nan
agent1:                 episode reward: 0.3352,                 loss: 0.1384
Episode: 6781/30000 (22.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.9236s / 44295.3814 s
agent0:                 episode reward: -0.1161,                 loss: nan
agent1:                 episode reward: 0.1161,                 loss: 0.1370
Episode: 6801/30000 (22.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.9093s / 44429.2906 s
agent0:                 episode reward: -0.4226,                 loss: nan
agent1:                 episode reward: 0.4226,                 loss: 0.1358
Episode: 6821/30000 (22.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6167s / 44564.9073 s
agent0:                 episode reward: -0.5958,                 loss: nan
agent1:                 episode reward: 0.5958,                 loss: 0.1367
Episode: 6841/30000 (22.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.0212s / 44696.9285 s
agent0:                 episode reward: -0.5389,                 loss: nan
agent1:                 episode reward: 0.5389,                 loss: 0.1365
Episode: 6861/30000 (22.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.0515s / 44829.9800 s
agent0:                 episode reward: -0.0704,                 loss: nan
agent1:                 episode reward: 0.0704,                 loss: 0.1365
Episode: 6881/30000 (22.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 143.3220s / 44973.3020 s
agent0:                 episode reward: -0.5653,                 loss: nan
agent1:                 episode reward: 0.5653,                 loss: 0.1383
Episode: 6901/30000 (23.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.1124s / 45109.4145 s
agent0:                 episode reward: -0.1331,                 loss: nan
agent1:                 episode reward: 0.1331,                 loss: 0.1395
Episode: 6921/30000 (23.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8215s / 45244.2359 s
agent0:                 episode reward: -0.1388,                 loss: nan
agent1:                 episode reward: 0.1388,                 loss: 0.1393
Episode: 6941/30000 (23.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.0170s / 45379.2529 s
agent0:                 episode reward: -0.1316,                 loss: nan
agent1:                 episode reward: 0.1316,                 loss: 0.1400
Episode: 6961/30000 (23.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3879s / 45514.6409 s
agent0:                 episode reward: -0.0766,                 loss: nan
agent1:                 episode reward: 0.0766,                 loss: 0.1417
Episode: 6981/30000 (23.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.9119s / 45650.5528 s
agent0:                 episode reward: -0.4598,                 loss: nan
agent1:                 episode reward: 0.4598,                 loss: 0.1405
Episode: 7001/30000 (23.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9850s / 45785.5378 s
agent0:                 episode reward: -0.2339,                 loss: nan
agent1:                 episode reward: 0.2339,                 loss: 0.1402
Episode: 7021/30000 (23.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.7506s / 45923.2884 s
agent0:                 episode reward: -0.4006,                 loss: nan
agent1:                 episode reward: 0.4006,                 loss: 0.1409
Episode: 7041/30000 (23.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.3243s / 46056.6126 s
agent0:                 episode reward: -0.0654,                 loss: nan
agent1:                 episode reward: 0.0654,                 loss: 0.1399
Episode: 7061/30000 (23.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0712s / 46190.6838 s
agent0:                 episode reward: -0.1235,                 loss: nan
agent1:                 episode reward: 0.1235,                 loss: 0.1386
Episode: 7081/30000 (23.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.0982s / 46325.7820 s
agent0:                 episode reward: -0.3751,                 loss: nan
agent1:                 episode reward: 0.3751,                 loss: 0.1392
Episode: 7101/30000 (23.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.5860s / 46462.3681 s
agent0:                 episode reward: -0.3776,                 loss: nan
agent1:                 episode reward: 0.3776,                 loss: 0.1404
Episode: 7121/30000 (23.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.5091s / 46597.8772 s
agent0:                 episode reward: -0.2055,                 loss: nan
agent1:                 episode reward: 0.2055,                 loss: 0.1406
Episode: 7141/30000 (23.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.1589s / 46736.0361 s
agent0:                 episode reward: -0.2548,                 loss: nan
agent1:                 episode reward: 0.2548,                 loss: 0.1389
Episode: 7161/30000 (23.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5340s / 46870.5701 s
agent0:                 episode reward: -0.6780,                 loss: nan
agent1:                 episode reward: 0.6780,                 loss: 0.1401
Episode: 7181/30000 (23.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.2814s / 47004.8515 s
agent0:                 episode reward: -0.1365,                 loss: nan
agent1:                 episode reward: 0.1365,                 loss: 0.1406
Episode: 7201/30000 (24.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.9748s / 47138.8263 s
agent0:                 episode reward: -0.4550,                 loss: nan
agent1:                 episode reward: 0.4550,                 loss: 0.1388
Episode: 7221/30000 (24.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.8104s / 47275.6367 s
agent0:                 episode reward: -0.6823,                 loss: nan
agent1:                 episode reward: 0.6823,                 loss: 0.1404
Episode: 7241/30000 (24.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3201s / 47410.9568 s
agent0:                 episode reward: -0.4610,                 loss: nan
agent1:                 episode reward: 0.4610,                 loss: 0.1402
Episode: 7261/30000 (24.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.7940s / 47547.7508 s
agent0:                 episode reward: -0.1533,                 loss: nan
agent1:                 episode reward: 0.1533,                 loss: 0.1380
Episode: 7281/30000 (24.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2683s / 47684.0192 s
agent0:                 episode reward: -0.1782,                 loss: nan
agent1:                 episode reward: 0.1782,                 loss: 0.1407
Episode: 7301/30000 (24.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.3021s / 47820.3213 s
agent0:                 episode reward: -0.6174,                 loss: nan
agent1:                 episode reward: 0.6174,                 loss: 0.1406
Episode: 7321/30000 (24.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9991s / 47955.3203 s
agent0:                 episode reward: -0.9197,                 loss: nan
agent1:                 episode reward: 0.9197,                 loss: 0.1394
Episode: 7341/30000 (24.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.9407s / 48091.2611 s
agent0:                 episode reward: -0.5535,                 loss: nan
agent1:                 episode reward: 0.5535,                 loss: 0.1397
Episode: 7361/30000 (24.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 138.6345s / 48229.8956 s
agent0:                 episode reward: -0.4444,                 loss: nan
agent1:                 episode reward: 0.4444,                 loss: 0.1392
Episode: 7381/30000 (24.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.5497s / 48365.4453 s
agent0:                 episode reward: -0.6056,                 loss: nan
agent1:                 episode reward: 0.6056,                 loss: 0.1398
Episode: 7401/30000 (24.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.3218s / 48499.7671 s
agent0:                 episode reward: -0.6676,                 loss: nan
agent1:                 episode reward: 0.6676,                 loss: 0.1404
Episode: 7421/30000 (24.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.3272s / 48637.0942 s
agent0:                 episode reward: -0.4884,                 loss: nan
agent1:                 episode reward: 0.4884,                 loss: 0.1392
Episode: 7441/30000 (24.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 130.7224s / 48767.8166 s
agent0:                 episode reward: -0.5598,                 loss: nan
agent1:                 episode reward: 0.5598,                 loss: 0.1399
Episode: 7461/30000 (24.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3045s / 48903.1211 s
agent0:                 episode reward: -0.5163,                 loss: nan
agent1:                 episode reward: 0.5163,                 loss: 0.1386
Episode: 7481/30000 (24.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.4049s / 49039.5261 s
agent0:                 episode reward: -0.2793,                 loss: nan
agent1:                 episode reward: 0.2793,                 loss: 0.1393
Episode: 7501/30000 (25.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.3834s / 49175.9095 s
agent0:                 episode reward: -0.2949,                 loss: nan
agent1:                 episode reward: 0.2949,                 loss: 0.1394
Episode: 7521/30000 (25.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.5370s / 49311.4465 s
agent0:                 episode reward: -0.1155,                 loss: nan
agent1:                 episode reward: 0.1155,                 loss: 0.1404
Episode: 7541/30000 (25.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.4343s / 49444.8808 s
agent0:                 episode reward: -0.0481,                 loss: nan
agent1:                 episode reward: 0.0481,                 loss: 0.1404
Episode: 7561/30000 (25.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.3704s / 49581.2512 s
agent0:                 episode reward: -0.5189,                 loss: nan
agent1:                 episode reward: 0.5189,                 loss: 0.1410
Episode: 7581/30000 (25.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.2844s / 49714.5356 s
agent0:                 episode reward: -0.3625,                 loss: nan
agent1:                 episode reward: 0.3625,                 loss: 0.1411
Episode: 7601/30000 (25.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7576s / 49850.2933 s
agent0:                 episode reward: -0.7459,                 loss: nan
agent1:                 episode reward: 0.7459,                 loss: 0.1398
Episode: 7621/30000 (25.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.7595s / 49987.0528 s
agent0:                 episode reward: -0.2879,                 loss: nan
agent1:                 episode reward: 0.2879,                 loss: 0.1406
Episode: 7641/30000 (25.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.9507s / 50123.0035 s
agent0:                 episode reward: -0.3847,                 loss: nan
agent1:                 episode reward: 0.3847,                 loss: 0.1396
Episode: 7661/30000 (25.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.5896s / 50258.5931 s
agent0:                 episode reward: -0.6465,                 loss: nan
agent1:                 episode reward: 0.6465,                 loss: 0.1407
Episode: 7681/30000 (25.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5081s / 50393.1012 s
agent0:                 episode reward: -0.0396,                 loss: nan
agent1:                 episode reward: 0.0396,                 loss: 0.1403
Episode: 7701/30000 (25.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0669s / 50527.1681 s
agent0:                 episode reward: -0.1075,                 loss: nan
agent1:                 episode reward: 0.1075,                 loss: 0.1385
Episode: 7721/30000 (25.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.1157s / 50664.2838 s
agent0:                 episode reward: -0.3009,                 loss: nan
agent1:                 episode reward: 0.3009,                 loss: 0.1401
Episode: 7741/30000 (25.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6309s / 50799.9147 s
agent0:                 episode reward: -0.2095,                 loss: nan
agent1:                 episode reward: 0.2095,                 loss: 0.1398
Episode: 7761/30000 (25.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0045s / 50933.9192 s
agent0:                 episode reward: -0.2559,                 loss: nan
agent1:                 episode reward: 0.2559,                 loss: 0.1406
Episode: 7781/30000 (25.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0178s / 51067.9370 s
agent0:                 episode reward: -0.2228,                 loss: nan
agent1:                 episode reward: 0.2228,                 loss: 0.1404
Episode: 7801/30000 (26.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.6778s / 51201.6148 s
agent0:                 episode reward: -0.4668,                 loss: nan
agent1:                 episode reward: 0.4668,                 loss: 0.1398
Episode: 7821/30000 (26.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.7390s / 51336.3538 s
agent0:                 episode reward: -0.1878,                 loss: nan
agent1:                 episode reward: 0.1878,                 loss: 0.1401
Episode: 7841/30000 (26.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.8226s / 51470.1763 s
agent0:                 episode reward: -0.5011,                 loss: nan
agent1:                 episode reward: 0.5011,                 loss: 0.1391
Episode: 7861/30000 (26.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2951s / 51605.4715 s
agent0:                 episode reward: -0.2038,                 loss: nan
agent1:                 episode reward: 0.2038,                 loss: 0.1385
Episode: 7881/30000 (26.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.5984s / 51738.0699 s
agent0:                 episode reward: -0.1168,                 loss: nan
agent1:                 episode reward: 0.1168,                 loss: 0.1409
Episode: 7901/30000 (26.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5107s / 51872.5806 s
agent0:                 episode reward: -0.7738,                 loss: nan
agent1:                 episode reward: 0.7738,                 loss: 0.1391
Episode: 7921/30000 (26.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.9964s / 52006.5770 s
agent0:                 episode reward: -0.1872,                 loss: nan
agent1:                 episode reward: 0.1872,                 loss: 0.1390
Episode: 7941/30000 (26.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.6645s / 52144.2415 s
agent0:                 episode reward: -0.0987,                 loss: nan
agent1:                 episode reward: 0.0987,                 loss: 0.1383
Episode: 7961/30000 (26.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5605s / 52278.8019 s
agent0:                 episode reward: -0.6832,                 loss: nan
agent1:                 episode reward: 0.6832,                 loss: 0.1376
Episode: 7981/30000 (26.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.9665s / 52411.7684 s
agent0:                 episode reward: -0.2103,                 loss: nan
agent1:                 episode reward: 0.2103,                 loss: 0.1392
Episode: 8001/30000 (26.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.4784s / 52545.2468 s
agent0:                 episode reward: -0.5153,                 loss: nan
agent1:                 episode reward: 0.5153,                 loss: 0.1375
Episode: 8021/30000 (26.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.9496s / 52678.1964 s
agent0:                 episode reward: -0.4429,                 loss: nan
agent1:                 episode reward: 0.4429,                 loss: 0.1386
Episode: 8041/30000 (26.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.4509s / 52812.6473 s
agent0:                 episode reward: -0.3618,                 loss: nan
agent1:                 episode reward: 0.3618,                 loss: 0.1385
Episode: 8061/30000 (26.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1474s / 52947.7947 s
agent0:                 episode reward: -0.0221,                 loss: nan
agent1:                 episode reward: 0.0221,                 loss: 0.1367
Episode: 8081/30000 (26.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1734s / 53082.9682 s
agent0:                 episode reward: -0.3215,                 loss: nan
agent1:                 episode reward: 0.3215,                 loss: 0.1407
Episode: 8101/30000 (27.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.4157s / 53219.3838 s
agent0:                 episode reward: -0.4230,                 loss: nan
agent1:                 episode reward: 0.4230,                 loss: 0.1378
Episode: 8121/30000 (27.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.6560s / 53353.0398 s
agent0:                 episode reward: -0.0338,                 loss: nan
agent1:                 episode reward: 0.0338,                 loss: 0.1383
Episode: 8141/30000 (27.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.9799s / 53489.0197 s
agent0:                 episode reward: -0.3027,                 loss: nan
agent1:                 episode reward: 0.3027,                 loss: 0.1381
Episode: 8161/30000 (27.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8286s / 53623.8483 s
agent0:                 episode reward: -0.6190,                 loss: nan
agent1:                 episode reward: 0.6190,                 loss: 0.1386
Episode: 8181/30000 (27.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.5104s / 53761.3587 s
agent0:                 episode reward: -0.4235,                 loss: nan
agent1:                 episode reward: 0.4235,                 loss: 0.1377
Episode: 8201/30000 (27.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.3886s / 53898.7473 s
agent0:                 episode reward: -0.0781,                 loss: nan
agent1:                 episode reward: 0.0781,                 loss: 0.1379
Episode: 8221/30000 (27.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6421s / 54034.3894 s
agent0:                 episode reward: -0.3910,                 loss: nan
agent1:                 episode reward: 0.3910,                 loss: 0.1395
Episode: 8241/30000 (27.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9026s / 54169.2920 s
agent0:                 episode reward: -0.6450,                 loss: nan
agent1:                 episode reward: 0.6450,                 loss: 0.1398
Episode: 8261/30000 (27.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7854s / 54305.0774 s
agent0:                 episode reward: -0.3342,                 loss: nan
agent1:                 episode reward: 0.3342,                 loss: 0.1410
Episode: 8281/30000 (27.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.3159s / 54437.3933 s
agent0:                 episode reward: -0.3780,                 loss: nan
agent1:                 episode reward: 0.3780,                 loss: 0.1410
Episode: 8301/30000 (27.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1828s / 54572.5761 s
agent0:                 episode reward: -0.4550,                 loss: nan
agent1:                 episode reward: 0.4550,                 loss: 0.1406
Episode: 8321/30000 (27.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.4228s / 54705.9989 s
agent0:                 episode reward: -0.7393,                 loss: nan
agent1:                 episode reward: 0.7393,                 loss: 0.1399
Episode: 8341/30000 (27.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.1194s / 54842.1183 s
agent0:                 episode reward: 0.0110,                 loss: nan
agent1:                 episode reward: -0.0110,                 loss: 0.1399
Episode: 8361/30000 (27.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.2011s / 54976.3194 s
agent0:                 episode reward: -0.7037,                 loss: nan
agent1:                 episode reward: 0.7037,                 loss: 0.1401
Episode: 8381/30000 (27.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7480s / 55112.0675 s
agent0:                 episode reward: -0.4924,                 loss: nan
agent1:                 episode reward: 0.4924,                 loss: 0.1383
Episode: 8401/30000 (28.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.7719s / 55246.8394 s
agent0:                 episode reward: -0.7047,                 loss: nan
agent1:                 episode reward: 0.7047,                 loss: 0.1393
Episode: 8421/30000 (28.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0269s / 55380.8663 s
agent0:                 episode reward: -0.0462,                 loss: nan
agent1:                 episode reward: 0.0462,                 loss: 0.1405
Episode: 8441/30000 (28.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.3543s / 55517.2206 s
agent0:                 episode reward: -0.1293,                 loss: nan
agent1:                 episode reward: 0.1293,                 loss: 0.1412
Episode: 8461/30000 (28.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6808s / 55652.9014 s
agent0:                 episode reward: -0.3917,                 loss: nan
agent1:                 episode reward: 0.3917,                 loss: 0.1400
Episode: 8481/30000 (28.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3722s / 55788.2737 s
agent0:                 episode reward: -0.7601,                 loss: nan
agent1:                 episode reward: 0.7601,                 loss: 0.1381
Episode: 8501/30000 (28.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0783s / 55924.3520 s
agent0:                 episode reward: -0.5018,                 loss: nan
agent1:                 episode reward: 0.5018,                 loss: 0.1397
Episode: 8521/30000 (28.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9923s / 56059.3443 s
agent0:                 episode reward: -0.6402,                 loss: nan
agent1:                 episode reward: 0.6402,                 loss: 0.1392
Episode: 8541/30000 (28.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 139.5623s / 56198.9066 s
agent0:                 episode reward: -0.3699,                 loss: nan
agent1:                 episode reward: 0.3699,                 loss: 0.1389
Episode: 8561/30000 (28.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4394s / 56334.3460 s
agent0:                 episode reward: -0.2257,                 loss: nan
agent1:                 episode reward: 0.2257,                 loss: 0.1400
Episode: 8581/30000 (28.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.7500s / 56472.0960 s
agent0:                 episode reward: -0.2288,                 loss: nan
agent1:                 episode reward: 0.2288,                 loss: 0.1400
Episode: 8601/30000 (28.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1919s / 56607.2879 s
agent0:                 episode reward: -0.4278,                 loss: nan
agent1:                 episode reward: 0.4278,                 loss: 0.1372
Episode: 8621/30000 (28.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6839s / 56742.9718 s
agent0:                 episode reward: -0.4604,                 loss: nan
agent1:                 episode reward: 0.4604,                 loss: 0.1385
Episode: 8641/30000 (28.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 129.9615s / 56872.9333 s
agent0:                 episode reward: -0.1418,                 loss: nan
agent1:                 episode reward: 0.1418,                 loss: 0.1378
Episode: 8661/30000 (28.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.4980s / 57009.4313 s
agent0:                 episode reward: -0.5905,                 loss: nan
agent1:                 episode reward: 0.5905,                 loss: 0.1396
Episode: 8681/30000 (28.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.3678s / 57142.7991 s
agent0:                 episode reward: -0.3807,                 loss: nan
agent1:                 episode reward: 0.3807,                 loss: 0.1393
Episode: 8701/30000 (29.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.4903s / 57280.2895 s
agent0:                 episode reward: -0.5627,                 loss: nan
agent1:                 episode reward: 0.5627,                 loss: 0.1394
Episode: 8721/30000 (29.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8747s / 57415.1642 s
agent0:                 episode reward: -0.6089,                 loss: nan
agent1:                 episode reward: 0.6089,                 loss: 0.1395
Episode: 8741/30000 (29.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0083s / 57551.1724 s
agent0:                 episode reward: -0.5432,                 loss: nan
agent1:                 episode reward: 0.5432,                 loss: 0.1372
Episode: 8761/30000 (29.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5490s / 57685.7215 s
agent0:                 episode reward: -0.2376,                 loss: nan
agent1:                 episode reward: 0.2376,                 loss: 0.1383
Episode: 8781/30000 (29.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2183s / 57820.9398 s
agent0:                 episode reward: -0.9822,                 loss: nan
agent1:                 episode reward: 0.9822,                 loss: 0.1379
Episode: 8801/30000 (29.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.4998s / 57958.4396 s
agent0:                 episode reward: -0.3180,                 loss: nan
agent1:                 episode reward: 0.3180,                 loss: 0.1375
Episode: 8821/30000 (29.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.0854s / 58096.5250 s
agent0:                 episode reward: -0.0954,                 loss: nan
agent1:                 episode reward: 0.0954,                 loss: 0.1393
Episode: 8841/30000 (29.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1339s / 58231.6589 s
agent0:                 episode reward: -0.4533,                 loss: nan
agent1:                 episode reward: 0.4533,                 loss: 0.1386
Episode: 8861/30000 (29.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.2937s / 58364.9526 s
agent0:                 episode reward: -0.7157,                 loss: nan
agent1:                 episode reward: 0.7157,                 loss: 0.1391
Episode: 8881/30000 (29.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.4561s / 58501.4087 s
agent0:                 episode reward: -0.4588,                 loss: nan
agent1:                 episode reward: 0.4588,                 loss: 0.1402
Episode: 8901/30000 (29.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1858s / 58636.5944 s
agent0:                 episode reward: -0.4259,                 loss: nan
agent1:                 episode reward: 0.4259,                 loss: 0.1381
Episode: 8921/30000 (29.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.4307s / 58771.0251 s
agent0:                 episode reward: -0.2445,                 loss: nan
agent1:                 episode reward: 0.2445,                 loss: 0.1393
Episode: 8941/30000 (29.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.6770s / 58907.7021 s
agent0:                 episode reward: -0.5966,                 loss: nan
agent1:                 episode reward: 0.5966,                 loss: 0.1373
Episode: 8961/30000 (29.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.0786s / 59045.7806 s
agent0:                 episode reward: -0.3527,                 loss: nan
agent1:                 episode reward: 0.3527,                 loss: 0.1392
Episode: 8981/30000 (29.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.3628s / 59180.1434 s
agent0:                 episode reward: -0.7353,                 loss: nan
agent1:                 episode reward: 0.7353,                 loss: 0.1369
Episode: 9001/30000 (30.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6634s / 59314.8069 s
agent0:                 episode reward: -0.3109,                 loss: nan
agent1:                 episode reward: 0.3109,                 loss: 0.1398
Episode: 9021/30000 (30.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.4504s / 59453.2572 s
agent0:                 episode reward: 0.2464,                 loss: nan
agent1:                 episode reward: -0.2464,                 loss: 0.1387
Episode: 9041/30000 (30.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4091s / 59588.6663 s
agent0:                 episode reward: -0.0001,                 loss: nan
agent1:                 episode reward: 0.0001,                 loss: 0.1383
Episode: 9061/30000 (30.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4794s / 59724.1457 s
agent0:                 episode reward: -0.4216,                 loss: nan
agent1:                 episode reward: 0.4216,                 loss: 0.1392
Episode: 9081/30000 (30.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.6528s / 59856.7985 s
agent0:                 episode reward: -0.2865,                 loss: nan
agent1:                 episode reward: 0.2865,                 loss: 0.1395
Episode: 9101/30000 (30.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.3950s / 59989.1935 s
agent0:                 episode reward: -0.3865,                 loss: nan
agent1:                 episode reward: 0.3865,                 loss: 0.1403
Episode: 9121/30000 (30.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9560s / 60124.1495 s
agent0:                 episode reward: -0.3446,                 loss: nan
agent1:                 episode reward: 0.3446,                 loss: 0.1387
Episode: 9141/30000 (30.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.4978s / 60260.6472 s
agent0:                 episode reward: -0.2523,                 loss: nan
agent1:                 episode reward: 0.2523,                 loss: 0.1397
Episode: 9161/30000 (30.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6343s / 60395.2815 s
agent0:                 episode reward: -0.4797,                 loss: nan
agent1:                 episode reward: 0.4797,                 loss: 0.1389
Episode: 9181/30000 (30.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.0333s / 60528.3148 s
agent0:                 episode reward: -0.2480,                 loss: nan
agent1:                 episode reward: 0.2480,                 loss: 0.1396
Episode: 9201/30000 (30.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 131.9354s / 60660.2502 s
agent0:                 episode reward: 0.1585,                 loss: nan
agent1:                 episode reward: -0.1585,                 loss: 0.1380
Episode: 9221/30000 (30.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.1419s / 60793.3921 s
agent0:                 episode reward: -0.9192,                 loss: nan
agent1:                 episode reward: 0.9192,                 loss: 0.1400
Episode: 9241/30000 (30.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.0909s / 60930.4830 s
agent0:                 episode reward: -0.7673,                 loss: nan
agent1:                 episode reward: 0.7673,                 loss: 0.1416
Episode: 9261/30000 (30.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.0202s / 61065.5032 s
agent0:                 episode reward: -0.6225,                 loss: nan
agent1:                 episode reward: 0.6225,                 loss: 0.1396
Episode: 9281/30000 (30.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.8364s / 61203.3396 s
agent0:                 episode reward: -0.3139,                 loss: nan
agent1:                 episode reward: 0.3139,                 loss: 0.1389
Episode: 9301/30000 (31.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.1812s / 61340.5208 s
agent0:                 episode reward: -0.4934,                 loss: nan
agent1:                 episode reward: 0.4934,                 loss: 0.1410
Episode: 9321/30000 (31.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4592s / 61475.9800 s
agent0:                 episode reward: -0.5482,                 loss: nan
agent1:                 episode reward: 0.5482,                 loss: 0.1395
Episode: 9341/30000 (31.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 138.7055s / 61614.6855 s
agent0:                 episode reward: -0.1812,                 loss: nan
agent1:                 episode reward: 0.1812,                 loss: 0.1412
Episode: 9361/30000 (31.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.9669s / 61753.6524 s
agent0:                 episode reward: 0.0496,                 loss: nan
agent1:                 episode reward: -0.0496,                 loss: 0.1391
Episode: 9381/30000 (31.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6916s / 61889.3440 s
agent0:                 episode reward: -0.2915,                 loss: nan
agent1:                 episode reward: 0.2915,                 loss: 0.1413
Episode: 9401/30000 (31.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4050s / 62024.7490 s
agent0:                 episode reward: -0.6209,                 loss: nan
agent1:                 episode reward: 0.6209,                 loss: 0.1402
Episode: 9421/30000 (31.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3592s / 62160.1082 s
agent0:                 episode reward: -0.0507,                 loss: nan
agent1:                 episode reward: 0.0507,                 loss: 0.1387
Episode: 9441/30000 (31.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 141.5915s / 62301.6998 s
agent0:                 episode reward: -0.6483,                 loss: nan
agent1:                 episode reward: 0.6483,                 loss: 0.1405
Episode: 9461/30000 (31.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.5542s / 62435.2540 s
agent0:                 episode reward: -0.5654,                 loss: nan
agent1:                 episode reward: 0.5654,                 loss: 0.1402
Episode: 9481/30000 (31.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.5004s / 62568.7544 s
agent0:                 episode reward: -0.6147,                 loss: nan
agent1:                 episode reward: 0.6147,                 loss: 0.1395
Episode: 9501/30000 (31.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3908s / 62704.1452 s
agent0:                 episode reward: -0.2152,                 loss: nan
agent1:                 episode reward: 0.2152,                 loss: 0.1409
Episode: 9521/30000 (31.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1697s / 62839.3149 s
agent0:                 episode reward: -0.1703,                 loss: nan
agent1:                 episode reward: 0.1703,                 loss: 0.1394
Episode: 9541/30000 (31.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0667s / 62973.3817 s
agent0:                 episode reward: -0.4428,                 loss: nan
agent1:                 episode reward: 0.4428,                 loss: 0.1419
Episode: 9561/30000 (31.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8374s / 63108.2191 s
agent0:                 episode reward: -0.3250,                 loss: nan
agent1:                 episode reward: 0.3250,                 loss: 0.1410
Episode: 9581/30000 (31.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.4492s / 63245.6683 s
agent0:                 episode reward: -0.5184,                 loss: nan
agent1:                 episode reward: 0.5184,                 loss: 0.1403
Episode: 9601/30000 (32.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2059s / 63380.8742 s
agent0:                 episode reward: -0.5709,                 loss: nan
agent1:                 episode reward: 0.5709,                 loss: 0.1406
Episode: 9621/30000 (32.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.5947s / 63514.4690 s
agent0:                 episode reward: -0.6395,                 loss: nan
agent1:                 episode reward: 0.6395,                 loss: 0.1398
Episode: 9641/30000 (32.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 138.0968s / 63652.5658 s
agent0:                 episode reward: -0.8760,                 loss: nan
agent1:                 episode reward: 0.8760,                 loss: 0.1398
Episode: 9661/30000 (32.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.3819s / 63789.9477 s
agent0:                 episode reward: -0.4101,                 loss: nan
agent1:                 episode reward: 0.4101,                 loss: 0.1391
Episode: 9681/30000 (32.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 139.1323s / 63929.0800 s
agent0:                 episode reward: -0.5713,                 loss: nan
agent1:                 episode reward: 0.5713,                 loss: 0.1422
Episode: 9701/30000 (32.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0351s / 64065.1150 s
agent0:                 episode reward: -0.4150,                 loss: nan
agent1:                 episode reward: 0.4150,                 loss: 0.1404
Episode: 9721/30000 (32.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6466s / 64199.7616 s
agent0:                 episode reward: -0.5418,                 loss: nan
agent1:                 episode reward: 0.5418,                 loss: 0.1401
Episode: 9741/30000 (32.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.9054s / 64335.6670 s
agent0:                 episode reward: -0.5109,                 loss: nan
agent1:                 episode reward: 0.5109,                 loss: 0.1399
Episode: 9761/30000 (32.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 141.4103s / 64477.0774 s
agent0:                 episode reward: -0.4595,                 loss: nan
agent1:                 episode reward: 0.4595,                 loss: 0.1403
Episode: 9781/30000 (32.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.4588s / 64611.5362 s
agent0:                 episode reward: -0.6585,                 loss: nan
agent1:                 episode reward: 0.6585,                 loss: 0.1413
Episode: 9801/30000 (32.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1185s / 64745.6547 s
agent0:                 episode reward: -0.3060,                 loss: nan
agent1:                 episode reward: 0.3060,                 loss: 0.1399
Episode: 9821/30000 (32.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.3645s / 64882.0192 s
agent0:                 episode reward: -0.7574,                 loss: nan
agent1:                 episode reward: 0.7574,                 loss: 0.1405
Episode: 9841/30000 (32.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.8757s / 65014.8949 s
agent0:                 episode reward: -0.7067,                 loss: nan
agent1:                 episode reward: 0.7067,                 loss: 0.1404
Episode: 9861/30000 (32.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2940s / 65151.1889 s
agent0:                 episode reward: -0.2636,                 loss: nan
agent1:                 episode reward: 0.2636,                 loss: 0.1407
Episode: 9881/30000 (32.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0430s / 65285.2319 s
agent0:                 episode reward: -0.1405,                 loss: nan
agent1:                 episode reward: 0.1405,                 loss: 0.1394
Episode: 9901/30000 (33.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.0236s / 65422.2555 s
agent0:                 episode reward: -0.5799,                 loss: nan
agent1:                 episode reward: 0.5799,                 loss: 0.1440
Episode: 9921/30000 (33.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.8837s / 65555.1392 s
agent0:                 episode reward: -0.4824,                 loss: nan
agent1:                 episode reward: 0.4824,                 loss: 0.1429
Episode: 9941/30000 (33.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.5366s / 65691.6758 s
agent0:                 episode reward: 0.0428,                 loss: nan
agent1:                 episode reward: -0.0428,                 loss: 0.1428
Episode: 9961/30000 (33.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.7518s / 65825.4276 s
agent0:                 episode reward: -0.4921,                 loss: nan
agent1:                 episode reward: 0.4921,                 loss: 0.1432
Episode: 9981/30000 (33.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0488s / 65961.4764 s
agent0:                 episode reward: -0.0785,                 loss: nan
agent1:                 episode reward: 0.0785,                 loss: 0.1431
Episode: 10001/30000 (33.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5097s / 66095.9861 s
agent0:                 episode reward: -0.7123,                 loss: nan
agent1:                 episode reward: 0.7123,                 loss: 0.1445
Episode: 10021/30000 (33.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.4321s / 66230.4183 s
agent0:                 episode reward: -0.2854,                 loss: nan
agent1:                 episode reward: 0.2854,                 loss: 0.1436
Episode: 10041/30000 (33.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7379s / 66366.1562 s
agent0:                 episode reward: 0.2282,                 loss: nan
agent1:                 episode reward: -0.2282,                 loss: 0.1422
Episode: 10061/30000 (33.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 131.9741s / 66498.1303 s
agent0:                 episode reward: -0.4726,                 loss: nan
agent1:                 episode reward: 0.4726,                 loss: 0.1445
Episode: 10081/30000 (33.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.3817s / 66631.5120 s
agent0:                 episode reward: -0.3922,                 loss: nan
agent1:                 episode reward: 0.3922,                 loss: 0.1442
Episode: 10101/30000 (33.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0804s / 66765.5924 s
agent0:                 episode reward: -0.3488,                 loss: nan
agent1:                 episode reward: 0.3488,                 loss: 0.1440
Episode: 10121/30000 (33.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.3174s / 66901.9098 s
agent0:                 episode reward: -0.4186,                 loss: nan
agent1:                 episode reward: 0.4186,                 loss: 0.1429
Episode: 10141/30000 (33.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1578s / 67036.0676 s
agent0:                 episode reward: -0.0327,                 loss: nan
agent1:                 episode reward: 0.0327,                 loss: 0.1429
Episode: 10161/30000 (33.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.7618s / 67168.8294 s
agent0:                 episode reward: -0.3257,                 loss: nan
agent1:                 episode reward: 0.3257,                 loss: 0.1444
Episode: 10181/30000 (33.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2556s / 67304.0849 s
agent0:                 episode reward: -0.0707,                 loss: nan
agent1:                 episode reward: 0.0707,                 loss: 0.1438
Episode: 10201/30000 (34.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.9326s / 67438.0176 s
agent0:                 episode reward: -0.7272,                 loss: nan
agent1:                 episode reward: 0.7272,                 loss: 0.1432
Episode: 10221/30000 (34.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.4935s / 67571.5111 s
agent0:                 episode reward: -0.7517,                 loss: nan
agent1:                 episode reward: 0.7517,                 loss: 0.1435
Episode: 10241/30000 (34.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 131.8758s / 67703.3870 s
agent0:                 episode reward: -0.6070,                 loss: nan
agent1:                 episode reward: 0.6070,                 loss: 0.1419
Episode: 10261/30000 (34.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.0977s / 67841.4847 s
agent0:                 episode reward: -0.0396,                 loss: nan
agent1:                 episode reward: 0.0396,                 loss: 0.1410
Episode: 10281/30000 (34.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8427s / 67976.3273 s
agent0:                 episode reward: -0.5435,                 loss: nan
agent1:                 episode reward: 0.5435,                 loss: 0.1412
Episode: 10301/30000 (34.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.9010s / 68112.2283 s
agent0:                 episode reward: 0.0072,                 loss: nan
agent1:                 episode reward: -0.0072,                 loss: 0.1403
Episode: 10321/30000 (34.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.3738s / 68244.6022 s
agent0:                 episode reward: -0.3200,                 loss: nan
agent1:                 episode reward: 0.3200,                 loss: 0.1421
Episode: 10341/30000 (34.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.2962s / 68377.8983 s
agent0:                 episode reward: -0.6657,                 loss: nan
agent1:                 episode reward: 0.6657,                 loss: 0.1409
Episode: 10361/30000 (34.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.4322s / 68512.3305 s
agent0:                 episode reward: -0.7878,                 loss: nan
agent1:                 episode reward: 0.7878,                 loss: 0.1401
Episode: 10381/30000 (34.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7080s / 68648.0385 s
agent0:                 episode reward: -0.3227,                 loss: nan
agent1:                 episode reward: 0.3227,                 loss: 0.1403
Episode: 10401/30000 (34.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.4403s / 68782.4788 s
agent0:                 episode reward: -0.0692,                 loss: nan
agent1:                 episode reward: 0.0692,                 loss: 0.1418
Episode: 10421/30000 (34.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8186s / 68917.2975 s
agent0:                 episode reward: -0.5886,                 loss: nan
agent1:                 episode reward: 0.5886,                 loss: 0.1395
Episode: 10441/30000 (34.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.7256s / 69055.0230 s
agent0:                 episode reward: -0.5234,                 loss: nan
agent1:                 episode reward: 0.5234,                 loss: 0.1414
Episode: 10461/30000 (34.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.3157s / 69187.3387 s
agent0:                 episode reward: -0.2902,                 loss: nan
agent1:                 episode reward: 0.2902,                 loss: 0.1404
Episode: 10481/30000 (34.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.1366s / 69319.4753 s
agent0:                 episode reward: -0.3913,                 loss: nan
agent1:                 episode reward: 0.3913,                 loss: 0.1422
Episode: 10501/30000 (35.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.3151s / 69451.7903 s
agent0:                 episode reward: -0.0642,                 loss: nan
agent1:                 episode reward: 0.0642,                 loss: 0.1418
Episode: 10521/30000 (35.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6881s / 69586.4784 s
agent0:                 episode reward: -0.6969,                 loss: nan
agent1:                 episode reward: 0.6969,                 loss: 0.1407
Episode: 10541/30000 (35.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3389s / 69721.8173 s
agent0:                 episode reward: -0.6463,                 loss: nan
agent1:                 episode reward: 0.6463,                 loss: 0.1403
Episode: 10561/30000 (35.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0556s / 69857.8729 s
agent0:                 episode reward: -0.9592,                 loss: nan
agent1:                 episode reward: 0.9592,                 loss: 0.1406
Episode: 10581/30000 (35.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.2243s / 69995.0972 s
agent0:                 episode reward: -0.1432,                 loss: nan
agent1:                 episode reward: 0.1432,                 loss: 0.1413
Episode: 10601/30000 (35.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8048s / 70129.9020 s
agent0:                 episode reward: -0.3779,                 loss: nan
agent1:                 episode reward: 0.3779,                 loss: 0.1397
Episode: 10621/30000 (35.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.8272s / 70263.7292 s
agent0:                 episode reward: -0.8214,                 loss: nan
agent1:                 episode reward: 0.8214,                 loss: 0.1404
Episode: 10641/30000 (35.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2522s / 70399.9814 s
agent0:                 episode reward: -0.2766,                 loss: nan
agent1:                 episode reward: 0.2766,                 loss: 0.1368
Episode: 10661/30000 (35.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.6884s / 70532.6698 s
agent0:                 episode reward: -0.0240,                 loss: nan
agent1:                 episode reward: 0.0240,                 loss: 0.1391
Episode: 10681/30000 (35.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2296s / 70667.8993 s
agent0:                 episode reward: -0.4467,                 loss: nan
agent1:                 episode reward: 0.4467,                 loss: 0.1408
Episode: 10701/30000 (35.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8129s / 70802.7123 s
agent0:                 episode reward: -0.1678,                 loss: nan
agent1:                 episode reward: 0.1678,                 loss: 0.1402
Episode: 10721/30000 (35.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1498s / 70937.8621 s
agent0:                 episode reward: -0.7081,                 loss: nan
agent1:                 episode reward: 0.7081,                 loss: 0.1392
Episode: 10741/30000 (35.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4316s / 71073.2938 s
agent0:                 episode reward: -0.6539,                 loss: nan
agent1:                 episode reward: 0.6539,                 loss: 0.1400
Episode: 10761/30000 (35.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.4981s / 71207.7919 s
agent0:                 episode reward: -0.7079,                 loss: nan
agent1:                 episode reward: 0.7079,                 loss: 0.1395
Episode: 10781/30000 (35.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.7535s / 71344.5454 s
agent0:                 episode reward: -0.3889,                 loss: nan
agent1:                 episode reward: 0.3889,                 loss: 0.1411
Episode: 10801/30000 (36.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.5216s / 71478.0670 s
agent0:                 episode reward: -0.6224,                 loss: nan
agent1:                 episode reward: 0.6224,                 loss: 0.1406
Episode: 10821/30000 (36.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1364s / 71613.2034 s
agent0:                 episode reward: 0.0976,                 loss: nan
agent1:                 episode reward: -0.0976,                 loss: 0.1405
Episode: 10841/30000 (36.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.1175s / 71749.3208 s
agent0:                 episode reward: -0.6296,                 loss: nan
agent1:                 episode reward: 0.6296,                 loss: 0.1389
Episode: 10861/30000 (36.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.3349s / 71883.6557 s
agent0:                 episode reward: -0.6836,                 loss: nan
agent1:                 episode reward: 0.6836,                 loss: 0.1384
Episode: 10881/30000 (36.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.1620s / 72019.8177 s
agent0:                 episode reward: -0.5116,                 loss: nan
agent1:                 episode reward: 0.5116,                 loss: 0.1395
Episode: 10901/30000 (36.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0296s / 72155.8473 s
agent0:                 episode reward: -0.5205,                 loss: nan
agent1:                 episode reward: 0.5205,                 loss: 0.1414
Episode: 10921/30000 (36.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 131.6309s / 72287.4783 s
agent0:                 episode reward: -0.5107,                 loss: nan
agent1:                 episode reward: 0.5107,                 loss: 0.1416
Episode: 10941/30000 (36.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.0192s / 72422.4974 s
agent0:                 episode reward: -0.5818,                 loss: nan
agent1:                 episode reward: 0.5818,                 loss: 0.1421
Episode: 10961/30000 (36.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.9289s / 72555.4264 s
agent0:                 episode reward: -0.0724,                 loss: nan
agent1:                 episode reward: 0.0724,                 loss: 0.1430
Episode: 10981/30000 (36.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.5628s / 72690.9892 s
agent0:                 episode reward: -0.0554,                 loss: nan
agent1:                 episode reward: 0.0554,                 loss: 0.1416
Episode: 11001/30000 (36.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.7683s / 72825.7575 s
agent0:                 episode reward: -0.4679,                 loss: nan
agent1:                 episode reward: 0.4679,                 loss: 0.1413
Episode: 11021/30000 (36.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0113s / 72959.7688 s
agent0:                 episode reward: -0.6236,                 loss: nan
agent1:                 episode reward: 0.6236,                 loss: 0.1415
Episode: 11041/30000 (36.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6418s / 73095.4106 s
agent0:                 episode reward: -0.2813,                 loss: nan
agent1:                 episode reward: 0.2813,                 loss: 0.1421
Episode: 11061/30000 (36.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9278s / 73230.3384 s
agent0:                 episode reward: -0.2780,                 loss: nan
agent1:                 episode reward: 0.2780,                 loss: 0.1416
Episode: 11081/30000 (36.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.8196s / 73366.1580 s
agent0:                 episode reward: -0.3619,                 loss: nan
agent1:                 episode reward: 0.3619,                 loss: 0.1415
Episode: 11101/30000 (37.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.2750s / 73499.4329 s
agent0:                 episode reward: -0.1959,                 loss: nan
agent1:                 episode reward: 0.1959,                 loss: 0.1413
Episode: 11121/30000 (37.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0954s / 73635.5284 s
agent0:                 episode reward: -0.9228,                 loss: nan
agent1:                 episode reward: 0.9228,                 loss: 0.1405
Episode: 11141/30000 (37.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3362s / 73770.8645 s
agent0:                 episode reward: -0.5872,                 loss: nan
agent1:                 episode reward: 0.5872,                 loss: 0.1433
Episode: 11161/30000 (37.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0104s / 73904.8750 s
agent0:                 episode reward: -0.7154,                 loss: nan
agent1:                 episode reward: 0.7154,                 loss: 0.1425
Episode: 11181/30000 (37.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.9511s / 74038.8260 s
agent0:                 episode reward: -0.5494,                 loss: nan
agent1:                 episode reward: 0.5494,                 loss: 0.1412
Episode: 11201/30000 (37.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.8931s / 74171.7191 s
agent0:                 episode reward: -0.1043,                 loss: nan
agent1:                 episode reward: 0.1043,                 loss: 0.1401
Episode: 11221/30000 (37.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.8436s / 74307.5627 s
agent0:                 episode reward: -0.1727,                 loss: nan
agent1:                 episode reward: 0.1727,                 loss: 0.1420
Episode: 11241/30000 (37.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3367s / 74442.8995 s
agent0:                 episode reward: -0.6015,                 loss: nan
agent1:                 episode reward: 0.6015,                 loss: 0.1417
Episode: 11261/30000 (37.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.7107s / 74576.6102 s
agent0:                 episode reward: 0.2362,                 loss: nan
agent1:                 episode reward: -0.2362,                 loss: 0.1412
Episode: 11281/30000 (37.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.5845s / 74712.1947 s
agent0:                 episode reward: -0.3054,                 loss: nan
agent1:                 episode reward: 0.3054,                 loss: 0.1406
Episode: 11301/30000 (37.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.6658s / 74848.8605 s
agent0:                 episode reward: -0.5707,                 loss: nan
agent1:                 episode reward: 0.5707,                 loss: 0.1393
Episode: 11321/30000 (37.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 131.0307s / 74979.8912 s
agent0:                 episode reward: -0.4780,                 loss: nan
agent1:                 episode reward: 0.4780,                 loss: 0.1417
Episode: 11341/30000 (37.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.2090s / 75117.1002 s
agent0:                 episode reward: -0.4075,                 loss: nan
agent1:                 episode reward: 0.4075,                 loss: 0.1416
Episode: 11361/30000 (37.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.4126s / 75250.5129 s
agent0:                 episode reward: -0.6155,                 loss: nan
agent1:                 episode reward: 0.6155,                 loss: 0.1406
Episode: 11381/30000 (37.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.3170s / 75383.8299 s
agent0:                 episode reward: -0.6293,                 loss: nan
agent1:                 episode reward: 0.6293,                 loss: 0.1416
Episode: 11401/30000 (38.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9884s / 75518.8182 s
agent0:                 episode reward: -0.6487,                 loss: nan
agent1:                 episode reward: 0.6487,                 loss: 0.1397
Episode: 11421/30000 (38.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 130.2403s / 75649.0586 s
agent0:                 episode reward: -0.7596,                 loss: nan
agent1:                 episode reward: 0.7596,                 loss: 0.1422
Episode: 11441/30000 (38.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8202s / 75783.8788 s
agent0:                 episode reward: -0.6836,                 loss: nan
agent1:                 episode reward: 0.6836,                 loss: 0.1407
Episode: 11461/30000 (38.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5864s / 75918.4652 s
agent0:                 episode reward: -0.5720,                 loss: nan
agent1:                 episode reward: 0.5720,                 loss: 0.1401
Episode: 11481/30000 (38.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6105s / 76053.0757 s
agent0:                 episode reward: -0.1200,                 loss: nan
agent1:                 episode reward: 0.1200,                 loss: 0.1394
Episode: 11501/30000 (38.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9824s / 76188.0581 s
agent0:                 episode reward: -0.4252,                 loss: nan
agent1:                 episode reward: 0.4252,                 loss: 0.1420
Episode: 11521/30000 (38.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.2610s / 76325.3191 s
agent0:                 episode reward: -0.4956,                 loss: nan
agent1:                 episode reward: 0.4956,                 loss: 0.1424
Episode: 11541/30000 (38.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.5770s / 76460.8961 s
agent0:                 episode reward: -0.5341,                 loss: nan
agent1:                 episode reward: 0.5341,                 loss: 0.1397
Episode: 11561/30000 (38.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.9435s / 76594.8396 s
agent0:                 episode reward: -0.4312,                 loss: nan
agent1:                 episode reward: 0.4312,                 loss: 0.1384
Episode: 11581/30000 (38.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.3444s / 76732.1840 s
agent0:                 episode reward: 0.0022,                 loss: nan
agent1:                 episode reward: -0.0022,                 loss: 0.1405
Episode: 11601/30000 (38.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9275s / 76867.1115 s
agent0:                 episode reward: -0.3944,                 loss: nan
agent1:                 episode reward: 0.3944,                 loss: 0.1399
Episode: 11621/30000 (38.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8851s / 77001.9966 s
agent0:                 episode reward: -0.3882,                 loss: nan
agent1:                 episode reward: 0.3882,                 loss: 0.1391
Episode: 11641/30000 (38.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7169s / 77137.7135 s
agent0:                 episode reward: -0.2108,                 loss: nan
agent1:                 episode reward: 0.2108,                 loss: 0.1395
Episode: 11661/30000 (38.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.4697s / 77271.1832 s
agent0:                 episode reward: -0.2485,                 loss: nan
agent1:                 episode reward: 0.2485,                 loss: 0.1386
Episode: 11681/30000 (38.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.4028s / 77405.5860 s
agent0:                 episode reward: -0.6903,                 loss: nan
agent1:                 episode reward: 0.6903,                 loss: 0.1382
Episode: 11701/30000 (39.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2895s / 77541.8755 s
agent0:                 episode reward: -0.2117,                 loss: nan
agent1:                 episode reward: 0.2117,                 loss: 0.1392
Episode: 11721/30000 (39.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1947s / 77677.0702 s
agent0:                 episode reward: -0.4022,                 loss: nan
agent1:                 episode reward: 0.4022,                 loss: 0.1399
Episode: 11741/30000 (39.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.4434s / 77813.5136 s
agent0:                 episode reward: -0.3706,                 loss: nan
agent1:                 episode reward: 0.3706,                 loss: 0.1394
Episode: 11761/30000 (39.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.8610s / 77950.3746 s
agent0:                 episode reward: -0.3080,                 loss: nan
agent1:                 episode reward: 0.3080,                 loss: 0.1387
Episode: 11781/30000 (39.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.1372s / 78087.5118 s
agent0:                 episode reward: -0.5775,                 loss: nan
agent1:                 episode reward: 0.5775,                 loss: 0.1391
Episode: 11801/30000 (39.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.3386s / 78219.8504 s
agent0:                 episode reward: -0.6804,                 loss: nan
agent1:                 episode reward: 0.6804,                 loss: 0.1403
Episode: 11821/30000 (39.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.1427s / 78356.9930 s
agent0:                 episode reward: -0.5734,                 loss: nan
agent1:                 episode reward: 0.5734,                 loss: 0.1391
Episode: 11841/30000 (39.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.7685s / 78490.7615 s
agent0:                 episode reward: -0.6004,                 loss: nan
agent1:                 episode reward: 0.6004,                 loss: 0.1394
Episode: 11861/30000 (39.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.6559s / 78628.4174 s
agent0:                 episode reward: -0.2569,                 loss: nan
agent1:                 episode reward: 0.2569,                 loss: 0.1410
Episode: 11881/30000 (39.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.1547s / 78764.5721 s
agent0:                 episode reward: -0.3672,                 loss: nan
agent1:                 episode reward: 0.3672,                 loss: 0.1390
Episode: 11901/30000 (39.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.8720s / 78897.4441 s
agent0:                 episode reward: -0.4543,                 loss: nan
agent1:                 episode reward: 0.4543,                 loss: 0.1394
Episode: 11921/30000 (39.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7128s / 79033.1569 s
agent0:                 episode reward: -0.2653,                 loss: nan
agent1:                 episode reward: 0.2653,                 loss: 0.1405
Episode: 11941/30000 (39.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.2647s / 79167.4216 s
agent0:                 episode reward: -0.5170,                 loss: nan
agent1:                 episode reward: 0.5170,                 loss: 0.1386
Episode: 11961/30000 (39.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.5462s / 79300.9678 s
agent0:                 episode reward: -0.5982,                 loss: nan
agent1:                 episode reward: 0.5982,                 loss: 0.1400
Episode: 11981/30000 (39.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.4986s / 79435.4664 s
agent0:                 episode reward: -0.1222,                 loss: nan
agent1:                 episode reward: 0.1222,                 loss: 0.1385
Episode: 12001/30000 (40.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.6971s / 79572.1634 s
agent0:                 episode reward: -0.3669,                 loss: nan
agent1:                 episode reward: 0.3669,                 loss: 0.1388
Episode: 12021/30000 (40.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.4578s / 79706.6213 s
agent0:                 episode reward: -0.2011,                 loss: nan
agent1:                 episode reward: 0.2011,                 loss: 0.1397
Episode: 12041/30000 (40.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.3788s / 79844.0000 s
agent0:                 episode reward: -0.6836,                 loss: nan
agent1:                 episode reward: 0.6836,                 loss: 0.1396
Episode: 12061/30000 (40.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 131.8273s / 79975.8274 s
agent0:                 episode reward: -0.0530,                 loss: nan
agent1:                 episode reward: 0.0530,                 loss: 0.1391
Episode: 12081/30000 (40.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.8024s / 80109.6298 s
agent0:                 episode reward: -0.4645,                 loss: nan
agent1:                 episode reward: 0.4645,                 loss: 0.1399
Episode: 12101/30000 (40.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.6767s / 80246.3065 s
agent0:                 episode reward: -0.0270,                 loss: nan
agent1:                 episode reward: 0.0270,                 loss: 0.1405
Episode: 12121/30000 (40.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.5946s / 80381.9011 s
agent0:                 episode reward: -0.3672,                 loss: nan
agent1:                 episode reward: 0.3672,                 loss: 0.1392
Episode: 12141/30000 (40.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.5155s / 80520.4167 s
agent0:                 episode reward: -0.4662,                 loss: nan
agent1:                 episode reward: 0.4662,                 loss: 0.1405
Episode: 12161/30000 (40.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9772s / 80655.3938 s
agent0:                 episode reward: -0.5906,                 loss: nan
agent1:                 episode reward: 0.5906,                 loss: 0.1406
Episode: 12181/30000 (40.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.5553s / 80787.9491 s
agent0:                 episode reward: -0.7701,                 loss: nan
agent1:                 episode reward: 0.7701,                 loss: 0.1378
Episode: 12201/30000 (40.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.8527s / 80924.8018 s
agent0:                 episode reward: -0.3867,                 loss: nan
agent1:                 episode reward: 0.3867,                 loss: 0.1412
Episode: 12221/30000 (40.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.2093s / 81059.0111 s
agent0:                 episode reward: -0.0755,                 loss: nan
agent1:                 episode reward: 0.0755,                 loss: 0.1393
Episode: 12241/30000 (40.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.5591s / 81192.5702 s
agent0:                 episode reward: -0.3235,                 loss: nan
agent1:                 episode reward: 0.3235,                 loss: 0.1428
Episode: 12261/30000 (40.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2415s / 81328.8117 s
agent0:                 episode reward: -0.2049,                 loss: nan
agent1:                 episode reward: 0.2049,                 loss: 0.1424
Episode: 12281/30000 (40.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 138.3362s / 81467.1478 s
agent0:                 episode reward: -0.8404,                 loss: nan
agent1:                 episode reward: 0.8404,                 loss: 0.1413
Episode: 12301/30000 (41.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.5750s / 81602.7228 s
agent0:                 episode reward: -0.3542,                 loss: nan
agent1:                 episode reward: 0.3542,                 loss: 0.1418
Episode: 12321/30000 (41.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8753s / 81737.5981 s
agent0:                 episode reward: -0.6388,                 loss: nan
agent1:                 episode reward: 0.6388,                 loss: 0.1413
Episode: 12341/30000 (41.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.3123s / 81869.9104 s
agent0:                 episode reward: -0.2143,                 loss: nan
agent1:                 episode reward: 0.2143,                 loss: 0.1419
Episode: 12361/30000 (41.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.1458s / 82006.0562 s
agent0:                 episode reward: -0.3123,                 loss: nan
agent1:                 episode reward: 0.3123,                 loss: 0.1414
Episode: 12381/30000 (41.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4175s / 82141.4738 s
agent0:                 episode reward: -0.4561,                 loss: nan
agent1:                 episode reward: 0.4561,                 loss: 0.1416
Episode: 12401/30000 (41.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5583s / 82276.0321 s
agent0:                 episode reward: -0.9433,                 loss: nan
agent1:                 episode reward: 0.9433,                 loss: 0.1413
Episode: 12421/30000 (41.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1198s / 82410.1519 s
agent0:                 episode reward: -0.4158,                 loss: nan
agent1:                 episode reward: 0.4158,                 loss: 0.1420
Episode: 12441/30000 (41.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.5118s / 82546.6637 s
agent0:                 episode reward: -0.5203,                 loss: nan
agent1:                 episode reward: 0.5203,                 loss: 0.1422
Episode: 12461/30000 (41.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6978s / 82682.3615 s
agent0:                 episode reward: -0.4505,                 loss: nan
agent1:                 episode reward: 0.4505,                 loss: 0.1416
Episode: 12481/30000 (41.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0245s / 82816.3859 s
agent0:                 episode reward: -0.6082,                 loss: nan
agent1:                 episode reward: 0.6082,                 loss: 0.1415
Episode: 12501/30000 (41.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.5583s / 82951.9442 s
agent0:                 episode reward: -0.6453,                 loss: nan
agent1:                 episode reward: 0.6453,                 loss: 0.1415
Episode: 12521/30000 (41.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.3720s / 83085.3162 s
agent0:                 episode reward: -0.1788,                 loss: nan
agent1:                 episode reward: 0.1788,                 loss: 0.1414
Episode: 12541/30000 (41.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.9433s / 83222.2595 s
agent0:                 episode reward: -0.3664,                 loss: nan
agent1:                 episode reward: 0.3664,                 loss: 0.1409
Episode: 12561/30000 (41.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.8898s / 83361.1492 s
agent0:                 episode reward: -0.2562,                 loss: nan
agent1:                 episode reward: 0.2562,                 loss: 0.1411
Episode: 12581/30000 (41.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4157s / 83496.5650 s
agent0:                 episode reward: -0.8710,                 loss: nan
agent1:                 episode reward: 0.8710,                 loss: 0.1397
Episode: 12601/30000 (42.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.3105s / 83630.8755 s
agent0:                 episode reward: -0.4199,                 loss: nan
agent1:                 episode reward: 0.4199,                 loss: 0.1400
Episode: 12621/30000 (42.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6898s / 83765.5652 s
agent0:                 episode reward: -0.2243,                 loss: nan
agent1:                 episode reward: 0.2243,                 loss: 0.1408
Episode: 12641/30000 (42.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.8163s / 83902.3815 s
agent0:                 episode reward: -0.4643,                 loss: nan
agent1:                 episode reward: 0.4643,                 loss: 0.1396
Episode: 12661/30000 (42.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.3280s / 84036.7095 s
agent0:                 episode reward: -0.8444,                 loss: nan
agent1:                 episode reward: 0.8444,                 loss: 0.1398
Episode: 12681/30000 (42.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.3676s / 84170.0771 s
agent0:                 episode reward: -0.8863,                 loss: nan
agent1:                 episode reward: 0.8863,                 loss: 0.1407
Episode: 12701/30000 (42.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.5404s / 84305.6175 s
agent0:                 episode reward: -0.5210,                 loss: nan
agent1:                 episode reward: 0.5210,                 loss: 0.1410
Episode: 12721/30000 (42.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 141.3073s / 84446.9248 s
agent0:                 episode reward: -0.2552,                 loss: nan
agent1:                 episode reward: 0.2552,                 loss: 0.1403
Episode: 12741/30000 (42.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.7471s / 84581.6719 s
agent0:                 episode reward: -0.5264,                 loss: nan
agent1:                 episode reward: 0.5264,                 loss: 0.1420
Episode: 12761/30000 (42.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.0473s / 84713.7192 s
agent0:                 episode reward: -0.4005,                 loss: nan
agent1:                 episode reward: 0.4005,                 loss: 0.1402
Episode: 12781/30000 (42.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 131.8104s / 84845.5296 s
agent0:                 episode reward: -0.1972,                 loss: nan
agent1:                 episode reward: 0.1972,                 loss: 0.1407
Episode: 12801/30000 (42.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2829s / 84981.8125 s
agent0:                 episode reward: -0.7335,                 loss: nan
agent1:                 episode reward: 0.7335,                 loss: 0.1398
Episode: 12821/30000 (42.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6289s / 85117.4414 s
agent0:                 episode reward: -0.4114,                 loss: nan
agent1:                 episode reward: 0.4114,                 loss: 0.1401
Episode: 12841/30000 (42.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3785s / 85252.8199 s
agent0:                 episode reward: -0.1727,                 loss: nan
agent1:                 episode reward: 0.1727,                 loss: 0.1412
Episode: 12861/30000 (42.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.7591s / 85386.5791 s
agent0:                 episode reward: -0.3409,                 loss: nan
agent1:                 episode reward: 0.3409,                 loss: 0.1412
Episode: 12881/30000 (42.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.8546s / 85520.4337 s
agent0:                 episode reward: -0.4960,                 loss: nan
agent1:                 episode reward: 0.4960,                 loss: 0.1415
Episode: 12901/30000 (43.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6925s / 85656.1262 s
agent0:                 episode reward: -0.5193,                 loss: nan
agent1:                 episode reward: 0.5193,                 loss: 0.1421
Episode: 12921/30000 (43.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.4150s / 85792.5412 s
agent0:                 episode reward: -0.2521,                 loss: nan
agent1:                 episode reward: 0.2521,                 loss: 0.1420
Episode: 12941/30000 (43.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.5212s / 85929.0624 s
agent0:                 episode reward: -0.7670,                 loss: nan
agent1:                 episode reward: 0.7670,                 loss: 0.1417
Episode: 12961/30000 (43.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1934s / 86063.2558 s
agent0:                 episode reward: -0.1765,                 loss: nan
agent1:                 episode reward: 0.1765,                 loss: 0.1423
Episode: 12981/30000 (43.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.5700s / 86198.8258 s
agent0:                 episode reward: -0.4029,                 loss: nan
agent1:                 episode reward: 0.4029,                 loss: 0.1429
Episode: 13001/30000 (43.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6414s / 86334.4672 s
agent0:                 episode reward: -0.3741,                 loss: nan
agent1:                 episode reward: 0.3741,                 loss: 0.1412
Episode: 13021/30000 (43.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.8473s / 86468.3144 s
agent0:                 episode reward: -0.6792,                 loss: nan
agent1:                 episode reward: 0.6792,                 loss: 0.1406
Episode: 13041/30000 (43.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8412s / 86603.1556 s
agent0:                 episode reward: -0.6159,                 loss: nan
agent1:                 episode reward: 0.6159,                 loss: 0.1406
Episode: 13061/30000 (43.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7372s / 86738.8928 s
agent0:                 episode reward: -0.8021,                 loss: nan
agent1:                 episode reward: 0.8021,                 loss: 0.1405
Episode: 13081/30000 (43.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.8773s / 86871.7701 s
agent0:                 episode reward: -0.7521,                 loss: nan
agent1:                 episode reward: 0.7521,                 loss: 0.1417
Episode: 13101/30000 (43.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.6629s / 87008.4330 s
agent0:                 episode reward: -0.6298,                 loss: nan
agent1:                 episode reward: 0.6298,                 loss: 0.1409
Episode: 13121/30000 (43.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.6542s / 87146.0872 s
agent0:                 episode reward: -0.2574,                 loss: nan
agent1:                 episode reward: 0.2574,                 loss: 0.1413
Episode: 13141/30000 (43.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2272s / 87282.3144 s
agent0:                 episode reward: -0.2984,                 loss: nan
agent1:                 episode reward: 0.2984,                 loss: 0.1428
Episode: 13161/30000 (43.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.6919s / 87415.0062 s
agent0:                 episode reward: -0.3476,                 loss: nan
agent1:                 episode reward: 0.3476,                 loss: 0.1434
Episode: 13181/30000 (43.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.3951s / 87549.4014 s
agent0:                 episode reward: 0.0017,                 loss: nan
agent1:                 episode reward: -0.0017,                 loss: 0.1426
Episode: 13201/30000 (44.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3720s / 87684.7733 s
agent0:                 episode reward: -0.8662,                 loss: nan
agent1:                 episode reward: 0.8662,                 loss: 0.1413
Episode: 13221/30000 (44.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.2339s / 87818.0072 s
agent0:                 episode reward: -0.3331,                 loss: nan
agent1:                 episode reward: 0.3331,                 loss: 0.1410
Episode: 13241/30000 (44.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9454s / 87952.9526 s
agent0:                 episode reward: -0.8501,                 loss: nan
agent1:                 episode reward: 0.8501,                 loss: 0.1404
Episode: 13261/30000 (44.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 140.5561s / 88093.5087 s
agent0:                 episode reward: -0.6005,                 loss: nan
agent1:                 episode reward: 0.6005,                 loss: 0.1407
Episode: 13281/30000 (44.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.6640s / 88231.1727 s
agent0:                 episode reward: -0.5429,                 loss: nan
agent1:                 episode reward: 0.5429,                 loss: 0.1413
Episode: 13301/30000 (44.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.9761s / 88368.1488 s
agent0:                 episode reward: -0.5106,                 loss: nan
agent1:                 episode reward: 0.5106,                 loss: 0.1398
Episode: 13321/30000 (44.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1701s / 88503.3189 s
agent0:                 episode reward: -0.1813,                 loss: nan
agent1:                 episode reward: 0.1813,                 loss: 0.1405
Episode: 13341/30000 (44.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9728s / 88638.2917 s
agent0:                 episode reward: -0.6952,                 loss: nan
agent1:                 episode reward: 0.6952,                 loss: 0.1397
Episode: 13361/30000 (44.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.3584s / 88772.6501 s
agent0:                 episode reward: -0.1055,                 loss: nan
agent1:                 episode reward: 0.1055,                 loss: 0.1414
Episode: 13381/30000 (44.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.0517s / 88905.7017 s
agent0:                 episode reward: -0.7511,                 loss: nan
agent1:                 episode reward: 0.7511,                 loss: 0.1405
Episode: 13401/30000 (44.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0787s / 89039.7804 s
agent0:                 episode reward: -0.6020,                 loss: nan
agent1:                 episode reward: 0.6020,                 loss: 0.1408
Episode: 13421/30000 (44.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6889s / 89175.4693 s
agent0:                 episode reward: -0.4670,                 loss: nan
agent1:                 episode reward: 0.4670,                 loss: 0.1404
Episode: 13441/30000 (44.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.4254s / 89312.8947 s
agent0:                 episode reward: -0.5382,                 loss: nan
agent1:                 episode reward: 0.5382,                 loss: 0.1424
Episode: 13461/30000 (44.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.7875s / 89446.6821 s
agent0:                 episode reward: -0.6326,                 loss: nan
agent1:                 episode reward: 0.6326,                 loss: 0.1427
Episode: 13481/30000 (44.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.5726s / 89580.2547 s
agent0:                 episode reward: -0.2231,                 loss: nan
agent1:                 episode reward: 0.2231,                 loss: 0.1424
Episode: 13501/30000 (45.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.0879s / 89719.3426 s
agent0:                 episode reward: -0.5411,                 loss: nan
agent1:                 episode reward: 0.5411,                 loss: 0.1426
Episode: 13521/30000 (45.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.9241s / 89856.2667 s
agent0:                 episode reward: -0.4667,                 loss: nan
agent1:                 episode reward: 0.4667,                 loss: 0.1417
Episode: 13541/30000 (45.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.4220s / 89989.6887 s
agent0:                 episode reward: -0.7193,                 loss: nan
agent1:                 episode reward: 0.7193,                 loss: 0.1402
Episode: 13561/30000 (45.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6379s / 90125.3266 s
agent0:                 episode reward: -0.3001,                 loss: nan
agent1:                 episode reward: 0.3001,                 loss: 0.1390
Episode: 13581/30000 (45.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.3814s / 90261.7080 s
agent0:                 episode reward: -0.4354,                 loss: nan
agent1:                 episode reward: 0.4354,                 loss: 0.1405
Episode: 13601/30000 (45.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6313s / 90396.3393 s
agent0:                 episode reward: -0.9530,                 loss: nan
agent1:                 episode reward: 0.9530,                 loss: 0.1408
Episode: 13621/30000 (45.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.4878s / 90533.8271 s
agent0:                 episode reward: -0.3951,                 loss: nan
agent1:                 episode reward: 0.3951,                 loss: 0.1379
Episode: 13641/30000 (45.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.4775s / 90670.3046 s
agent0:                 episode reward: -0.6922,                 loss: nan
agent1:                 episode reward: 0.6922,                 loss: 0.1399
Episode: 13661/30000 (45.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.0069s / 90805.3114 s
agent0:                 episode reward: -0.6023,                 loss: nan
agent1:                 episode reward: 0.6023,                 loss: 0.1400
Episode: 13681/30000 (45.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4085s / 90940.7200 s
agent0:                 episode reward: -0.8493,                 loss: nan
agent1:                 episode reward: 0.8493,                 loss: 0.1399
Episode: 13701/30000 (45.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.0471s / 91078.7671 s
agent0:                 episode reward: -0.5680,                 loss: nan
agent1:                 episode reward: 0.5680,                 loss: 0.1387
Episode: 13721/30000 (45.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.4542s / 91212.2213 s
agent0:                 episode reward: -0.1966,                 loss: nan
agent1:                 episode reward: 0.1966,                 loss: 0.1393
Episode: 13741/30000 (45.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.6903s / 91345.9116 s
agent0:                 episode reward: -0.3018,                 loss: nan
agent1:                 episode reward: 0.3018,                 loss: 0.1400
Episode: 13761/30000 (45.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.7247s / 91479.6363 s
agent0:                 episode reward: -0.3595,                 loss: nan
agent1:                 episode reward: 0.3595,                 loss: 0.1391
Episode: 13781/30000 (45.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.4575s / 91614.0938 s
agent0:                 episode reward: -0.4509,                 loss: nan
agent1:                 episode reward: 0.4509,                 loss: 0.1392
Episode: 13801/30000 (46.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.8008s / 91749.8946 s
agent0:                 episode reward: -0.4173,                 loss: nan
agent1:                 episode reward: 0.4173,                 loss: 0.1387
Episode: 13821/30000 (46.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.7856s / 91882.6802 s
agent0:                 episode reward: -0.1841,                 loss: nan
agent1:                 episode reward: 0.1841,                 loss: 0.1409
Episode: 13841/30000 (46.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0379s / 92016.7181 s
agent0:                 episode reward: -0.7256,                 loss: nan
agent1:                 episode reward: 0.7256,                 loss: 0.1376
Episode: 13861/30000 (46.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.8238s / 92153.5419 s
agent0:                 episode reward: -0.0858,                 loss: nan
agent1:                 episode reward: 0.0858,                 loss: 0.1391
Episode: 13881/30000 (46.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.5309s / 92290.0727 s
agent0:                 episode reward: -0.5845,                 loss: nan
agent1:                 episode reward: 0.5845,                 loss: 0.1393
Episode: 13901/30000 (46.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.4686s / 92426.5413 s
agent0:                 episode reward: -0.5437,                 loss: nan
agent1:                 episode reward: 0.5437,                 loss: 0.1405
Episode: 13921/30000 (46.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6929s / 92562.2342 s
agent0:                 episode reward: -0.6698,                 loss: nan
agent1:                 episode reward: 0.6698,                 loss: 0.1399
Episode: 13941/30000 (46.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.8072s / 92698.0414 s
agent0:                 episode reward: -0.5265,                 loss: nan
agent1:                 episode reward: 0.5265,                 loss: 0.1397
Episode: 13961/30000 (46.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3839s / 92833.4253 s
agent0:                 episode reward: -0.4748,                 loss: nan
agent1:                 episode reward: 0.4748,                 loss: 0.1404
Episode: 13981/30000 (46.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0066s / 92969.4319 s
agent0:                 episode reward: -0.1977,                 loss: nan
agent1:                 episode reward: 0.1977,                 loss: 0.1394
Episode: 14001/30000 (46.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.2254s / 93103.6572 s
agent0:                 episode reward: -0.2692,                 loss: nan
agent1:                 episode reward: 0.2692,                 loss: 0.1409
Episode: 14021/30000 (46.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.6378s / 93240.2951 s
agent0:                 episode reward: -0.4657,                 loss: nan
agent1:                 episode reward: 0.4657,                 loss: 0.1394
Episode: 14041/30000 (46.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.3171s / 93378.6122 s
agent0:                 episode reward: -0.5260,                 loss: nan