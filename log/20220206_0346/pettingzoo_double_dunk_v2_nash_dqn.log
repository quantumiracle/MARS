pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
double_dunk_v2 pettingzoo
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
random seed: [91, 69]
<SubprocVectorEnv instance>
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
No agent are not learnable.
Arguments:  {'env_name': 'double_dunk_v2', 'env_type': 'pettingzoo', 'num_envs': 2, 'ram': True, 'seed': 'random', 'algorithm': 'NashDQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 5, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 0.1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}}
Save models to : /home/zihan/research/MARS/data/model/20220206_0346/pettingzoo_double_dunk_v2_nash_dqn. 
 Save logs to: /home/zihan/research/MARS/data/log/20220206_0346/pettingzoo_double_dunk_v2_nash_dqn.
Episode: 1/10000 (0.0100%),                 avg. length: 2857.0,                last time consumption/overall running time: 23.0762s / 23.0762 s
env0_first_0:                 episode reward: -24.0000,                 loss: 0.0945
env0_second_0:                 episode reward: 24.0000,                 loss: 0.0921
env1_first_0:                 episode reward: -20.0000,                 loss: nan
env1_second_0:                 episode reward: 20.0000,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 3966.7,                last time consumption/overall running time: 892.8870s / 915.9632 s
env0_first_0:                 episode reward: -29.4500,                 loss: 0.0851
env0_second_0:                 episode reward: 29.4500,                 loss: 0.0803
env1_first_0:                 episode reward: -26.4500,                 loss: nan
env1_second_0:                 episode reward: 26.4500,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 3991.0,                last time consumption/overall running time: 1091.1500s / 2007.1132 s
env0_first_0:                 episode reward: -26.9000,                 loss: 0.0984
env0_second_0:                 episode reward: 26.9000,                 loss: 0.0810
env1_first_0:                 episode reward: -25.9000,                 loss: nan
env1_second_0:                 episode reward: 25.9000,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 3881.7,                last time consumption/overall running time: 1061.3535s / 3068.4667 s
env0_first_0:                 episode reward: -23.8500,                 loss: 0.0891
env0_second_0:                 episode reward: 23.8500,                 loss: 0.0982
env1_first_0:                 episode reward: -24.5500,                 loss: nan
env1_second_0:                 episode reward: 24.5500,                 loss: nan
Episode: 81/10000 (0.8100%),                 avg. length: 3562.95,                last time consumption/overall running time: 965.6277s / 4034.0945 s
env0_first_0:                 episode reward: -21.4500,                 loss: 0.0938
env0_second_0:                 episode reward: 21.4500,                 loss: 0.0958
env1_first_0:                 episode reward: -22.4500,                 loss: nan
env1_second_0:                 episode reward: 22.4500,                 loss: nan
Episode: 101/10000 (1.0100%),                 avg. length: 3921.95,                last time consumption/overall running time: 1058.3972s / 5092.4917 s
env0_first_0:                 episode reward: -22.7500,                 loss: 0.0886
env0_second_0:                 episode reward: 22.7500,                 loss: 0.0901
env1_first_0:                 episode reward: -23.3500,                 loss: nan
env1_second_0:                 episode reward: 23.3500,                 loss: nan
Episode: 121/10000 (1.2100%),                 avg. length: 3850.15,                last time consumption/overall running time: 1041.1825s / 6133.6742 s
env0_first_0:                 episode reward: -23.1000,                 loss: 0.0926
env0_second_0:                 episode reward: 23.1000,                 loss: 0.0927
env1_first_0:                 episode reward: -26.9500,                 loss: nan
env1_second_0:                 episode reward: 26.9500,                 loss: nan
Episode: 141/10000 (1.4100%),                 avg. length: 3748.9,                last time consumption/overall running time: 1013.5122s / 7147.1863 s
env0_first_0:                 episode reward: -26.4000,                 loss: 0.0880
env0_second_0:                 episode reward: 26.4000,                 loss: 0.0877
env1_first_0:                 episode reward: -23.1000,                 loss: nan
env1_second_0:                 episode reward: 23.1000,                 loss: nan
Episode: 161/10000 (1.6100%),                 avg. length: 4031.6,                last time consumption/overall running time: 1107.7002s / 8254.8866 s
env0_first_0:                 episode reward: -25.9000,                 loss: 0.0861
env0_second_0:                 episode reward: 25.9000,                 loss: 0.0888
env1_first_0:                 episode reward: -25.2500,                 loss: nan
env1_second_0:                 episode reward: 25.2500,                 loss: nan
Episode: 181/10000 (1.8100%),                 avg. length: 3934.7,                last time consumption/overall running time: 1081.0052s / 9335.8918 s
env0_first_0:                 episode reward: -22.9000,                 loss: 0.0903
env0_second_0:                 episode reward: 22.9000,                 loss: 0.0869
env1_first_0:                 episode reward: -25.9000,                 loss: nan
env1_second_0:                 episode reward: 25.9000,                 loss: nan
Episode: 201/10000 (2.0100%),                 avg. length: 3746.85,                last time consumption/overall running time: 1020.9827s / 10356.8745 s
env0_first_0:                 episode reward: -22.9000,                 loss: 0.0840
env0_second_0:                 episode reward: 22.9000,                 loss: 0.0885
env1_first_0:                 episode reward: -26.4000,                 loss: nan
env1_second_0:                 episode reward: 26.4000,                 loss: nan
Episode: 221/10000 (2.2100%),                 avg. length: 3727.05,                last time consumption/overall running time: 1013.7144s / 11370.5889 s
env0_first_0:                 episode reward: -25.2500,                 loss: 0.0844
env0_second_0:                 episode reward: 25.2500,                 loss: 0.0846
env1_first_0:                 episode reward: -25.4000,                 loss: nan
env1_second_0:                 episode reward: 25.4000,                 loss: nan
Episode: 241/10000 (2.4100%),                 avg. length: 3785.4,                last time consumption/overall running time: 1023.2941s / 12393.8829 s
env0_first_0:                 episode reward: -24.0000,                 loss: 0.0814
env0_second_0:                 episode reward: 24.0000,                 loss: 0.0845
env1_first_0:                 episode reward: -24.5500,                 loss: nan
env1_second_0:                 episode reward: 24.5500,                 loss: nan
Episode: 261/10000 (2.6100%),                 avg. length: 3795.3,                last time consumption/overall running time: 1048.7874s / 13442.6704 s
env0_first_0:                 episode reward: -26.0000,                 loss: 0.0866
env0_second_0:                 episode reward: 26.0000,                 loss: 0.0820
env1_first_0:                 episode reward: -24.1500,                 loss: nan
env1_second_0:                 episode reward: 24.1500,                 loss: nan
Episode: 281/10000 (2.8100%),                 avg. length: 4033.5,                last time consumption/overall running time: 1100.4984s / 14543.1688 s
env0_first_0:                 episode reward: -28.0000,                 loss: 0.0812
env0_second_0:                 episode reward: 28.0000,                 loss: 0.0851
env1_first_0:                 episode reward: -30.2000,                 loss: nan
env1_second_0:                 episode reward: 30.2000,                 loss: nan
Episode: 301/10000 (3.0100%),                 avg. length: 3883.0,                last time consumption/overall running time: 1066.6415s / 15609.8102 s
env0_first_0:                 episode reward: -25.0500,                 loss: 0.0862
env0_second_0:                 episode reward: 25.0500,                 loss: 0.0848
env1_first_0:                 episode reward: -27.2000,                 loss: nan
env1_second_0:                 episode reward: 27.2000,                 loss: nan
Episode: 321/10000 (3.2100%),                 avg. length: 3886.9,                last time consumption/overall running time: 1063.8125s / 16673.6227 s
env0_first_0:                 episode reward: -27.2000,                 loss: 0.0818
env0_second_0:                 episode reward: 27.2000,                 loss: 0.0878
env1_first_0:                 episode reward: -25.1500,                 loss: nan
env1_second_0:                 episode reward: 25.1500,                 loss: nan
Episode: 341/10000 (3.4100%),                 avg. length: 4112.75,                last time consumption/overall running time: 1127.7462s / 17801.3689 s
env0_first_0:                 episode reward: -25.4000,                 loss: 0.0826
env0_second_0:                 episode reward: 25.4000,                 loss: 0.0805
env1_first_0:                 episode reward: -27.1500,                 loss: nan
env1_second_0:                 episode reward: 27.1500,                 loss: nan
Episode: 361/10000 (3.6100%),                 avg. length: 3988.8,                last time consumption/overall running time: 1095.8284s / 18897.1973 s
env0_first_0:                 episode reward: -26.6500,                 loss: 0.0793
env0_second_0:                 episode reward: 26.6500,                 loss: 0.0770
env1_first_0:                 episode reward: -28.5500,                 loss: nan
env1_second_0:                 episode reward: 28.5500,                 loss: nan
Episode: 381/10000 (3.8100%),                 avg. length: 4181.7,                last time consumption/overall running time: 1157.1868s / 20054.3841 s
env0_first_0:                 episode reward: -28.5000,                 loss: 0.0856
env0_second_0:                 episode reward: 28.5000,                 loss: 0.0800
env1_first_0:                 episode reward: -29.4000,                 loss: nan
env1_second_0:                 episode reward: 29.4000,                 loss: nan
Episode: 401/10000 (4.0100%),                 avg. length: 3900.25,                last time consumption/overall running time: 1062.8101s / 21117.1941 s
env0_first_0:                 episode reward: -25.0000,                 loss: 0.0800
env0_second_0:                 episode reward: 25.0000,                 loss: 0.0780
env1_first_0:                 episode reward: -27.8500,                 loss: nan
env1_second_0:                 episode reward: 27.8500,                 loss: nan
Episode: 421/10000 (4.2100%),                 avg. length: 3692.75,                last time consumption/overall running time: 1017.9895s / 22135.1836 s
env0_first_0:                 episode reward: -24.0000,                 loss: 0.0834
env0_second_0:                 episode reward: 24.0000,                 loss: 0.0826
env1_first_0:                 episode reward: -23.6000,                 loss: nan
env1_second_0:                 episode reward: 23.6000,                 loss: nan
Episode: 441/10000 (4.4100%),                 avg. length: 3982.7,                last time consumption/overall running time: 1092.8282s / 23228.0119 s
env0_first_0:                 episode reward: -29.9500,                 loss: 0.0826
env0_second_0:                 episode reward: 29.9500,                 loss: 0.0797
env1_first_0:                 episode reward: -26.7500,                 loss: nan
env1_second_0:                 episode reward: 26.7500,                 loss: nan
Episode: 461/10000 (4.6100%),                 avg. length: 4056.7,                last time consumption/overall running time: 1115.5974s / 24343.6093 s
env0_first_0:                 episode reward: -29.0500,                 loss: 0.0808
env0_second_0:                 episode reward: 29.0500,                 loss: 0.0811
env1_first_0:                 episode reward: -29.2500,                 loss: nan
env1_second_0:                 episode reward: 29.2500,                 loss: nan
Episode: 481/10000 (4.8100%),                 avg. length: 4077.45,                last time consumption/overall running time: 1120.9396s / 25464.5490 s
env0_first_0:                 episode reward: -25.9000,                 loss: 0.0795
env0_second_0:                 episode reward: 25.9000,                 loss: 0.0793
env1_first_0:                 episode reward: -26.0000,                 loss: nan
env1_second_0:                 episode reward: 26.0000,                 loss: nan
Episode: 501/10000 (5.0100%),                 avg. length: 3873.3,                last time consumption/overall running time: 1051.4065s / 26515.9555 s
env0_first_0:                 episode reward: -26.7500,                 loss: 0.0810
env0_second_0:                 episode reward: 26.7500,                 loss: 0.0798
env1_first_0:                 episode reward: -26.3500,                 loss: nan
env1_second_0:                 episode reward: 26.3500,                 loss: nan
Episode: 521/10000 (5.2100%),                 avg. length: 3948.15,                last time consumption/overall running time: 1088.2440s / 27604.1995 s
env0_first_0:                 episode reward: -24.8000,                 loss: 0.0811
env0_second_0:                 episode reward: 24.8000,                 loss: 0.0812
env1_first_0:                 episode reward: -25.7000,                 loss: nan
env1_second_0:                 episode reward: 25.7000,                 loss: nan
Episode: 541/10000 (5.4100%),                 avg. length: 3889.8,                last time consumption/overall running time: 1067.2508s / 28671.4503 s
env0_first_0:                 episode reward: -24.8500,                 loss: 0.0778
env0_second_0:                 episode reward: 24.8500,                 loss: 0.0790
env1_first_0:                 episode reward: -26.0500,                 loss: nan
env1_second_0:                 episode reward: 26.0500,                 loss: nan
Episode: 561/10000 (5.6100%),                 avg. length: 4093.8,                last time consumption/overall running time: 1125.4699s / 29796.9202 s
env0_first_0:                 episode reward: -30.7500,                 loss: 0.0832
env0_second_0:                 episode reward: 30.7500,                 loss: 0.0782
env1_first_0:                 episode reward: -27.1500,                 loss: nan
env1_second_0:                 episode reward: 27.1500,                 loss: nan
Episode: 581/10000 (5.8100%),                 avg. length: 4256.75,                last time consumption/overall running time: 1186.8321s / 30983.7523 s
env0_first_0:                 episode reward: -29.5500,                 loss: 0.0828
env0_second_0:                 episode reward: 29.5500,                 loss: 0.0765
env1_first_0:                 episode reward: -29.7500,                 loss: nan
env1_second_0:                 episode reward: 29.7500,                 loss: nan
Episode: 601/10000 (6.0100%),                 avg. length: 3894.65,                last time consumption/overall running time: 1067.3633s / 32051.1156 s
env0_first_0:                 episode reward: -27.4500,                 loss: 0.0760
env0_second_0:                 episode reward: 27.4500,                 loss: 0.0745
env1_first_0:                 episode reward: -26.0500,                 loss: nan
env1_second_0:                 episode reward: 26.0500,                 loss: nan
Episode: 621/10000 (6.2100%),                 avg. length: 3702.4,                last time consumption/overall running time: 1020.1478s / 33071.2634 s
env0_first_0:                 episode reward: -26.9000,                 loss: 0.0753
env0_second_0:                 episode reward: 26.9000,                 loss: 0.0748
env1_first_0:                 episode reward: -22.2500,                 loss: nan
env1_second_0:                 episode reward: 22.2500,                 loss: nan
Episode: 641/10000 (6.4100%),                 avg. length: 4049.95,                last time consumption/overall running time: 1110.6170s / 34181.8804 s
env0_first_0:                 episode reward: -26.8500,                 loss: 0.0770
env0_second_0:                 episode reward: 26.8500,                 loss: 0.0737
env1_first_0:                 episode reward: -27.1000,                 loss: nan
env1_second_0:                 episode reward: 27.1000,                 loss: nan
Episode: 661/10000 (6.6100%),                 avg. length: 3882.75,                last time consumption/overall running time: 1075.7431s / 35257.6235 s
env0_first_0:                 episode reward: -27.8000,                 loss: 0.0760
env0_second_0:                 episode reward: 27.8000,                 loss: 0.0689
env1_first_0:                 episode reward: -28.7000,                 loss: nan
env1_second_0:                 episode reward: 28.7000,                 loss: nan
Episode: 681/10000 (6.8100%),                 avg. length: 3824.05,                last time consumption/overall running time: 1055.1942s / 36312.8177 s
env0_first_0:                 episode reward: -29.7000,                 loss: 0.0772
env0_second_0:                 episode reward: 29.7000,                 loss: 0.0645
env1_first_0:                 episode reward: -28.1000,                 loss: nan
env1_second_0:                 episode reward: 28.1000,                 loss: nan
Episode: 701/10000 (7.0100%),                 avg. length: 3908.15,                last time consumption/overall running time: 1074.4069s / 37387.2246 s
env0_first_0:                 episode reward: -26.4000,                 loss: 0.0761
env0_second_0:                 episode reward: 26.4000,                 loss: 0.0627
env1_first_0:                 episode reward: -25.7000,                 loss: nan
env1_second_0:                 episode reward: 25.7000,                 loss: nan
Episode: 721/10000 (7.2100%),                 avg. length: 3896.7,                last time consumption/overall running time: 1076.6326s / 38463.8572 s
env0_first_0:                 episode reward: -24.9500,                 loss: 0.0711
env0_second_0:                 episode reward: 24.9500,                 loss: 0.0610
env1_first_0:                 episode reward: -27.8000,                 loss: nan
env1_second_0:                 episode reward: 27.8000,                 loss: nan
Episode: 741/10000 (7.4100%),                 avg. length: 4147.95,                last time consumption/overall running time: 1139.7826s / 39603.6398 s
env0_first_0:                 episode reward: -31.7500,                 loss: 0.0730
env0_second_0:                 episode reward: 31.7500,                 loss: 0.0585
env1_first_0:                 episode reward: -30.3000,                 loss: nan
env1_second_0:                 episode reward: 30.3000,                 loss: nan
Episode: 761/10000 (7.6100%),                 avg. length: 4010.9,                last time consumption/overall running time: 1118.1745s / 40721.8143 s
env0_first_0:                 episode reward: -26.2000,                 loss: 0.0684
env0_second_0:                 episode reward: 26.2000,                 loss: 0.0546
env1_first_0:                 episode reward: -27.5500,                 loss: nan
env1_second_0:                 episode reward: 27.5500,                 loss: nan
Episode: 781/10000 (7.8100%),                 avg. length: 3554.8,                last time consumption/overall running time: 991.0713s / 41712.8856 s
env0_first_0:                 episode reward: -23.5000,                 loss: 0.0638
env0_second_0:                 episode reward: 23.5000,                 loss: 0.0526
env1_first_0:                 episode reward: -26.1000,                 loss: nan
env1_second_0:                 episode reward: 26.1000,                 loss: nan
Episode: 801/10000 (8.0100%),                 avg. length: 3728.35,                last time consumption/overall running time: 1037.7463s / 42750.6320 s
env0_first_0:                 episode reward: -27.6000,                 loss: 0.0648
env0_second_0:                 episode reward: 27.6000,                 loss: 0.0511
env1_first_0:                 episode reward: -27.1500,                 loss: nan
env1_second_0:                 episode reward: 27.1500,                 loss: nan
Episode: 821/10000 (8.2100%),                 avg. length: 3715.15,                last time consumption/overall running time: 1025.5940s / 43776.2260 s
env0_first_0:                 episode reward: -24.3500,                 loss: 0.0607
env0_second_0:                 episode reward: 24.3500,                 loss: 0.0516
env1_first_0:                 episode reward: -26.8500,                 loss: nan
env1_second_0:                 episode reward: 26.8500,                 loss: nan
Episode: 841/10000 (8.4100%),                 avg. length: 3701.8,                last time consumption/overall running time: 1022.9986s / 44799.2246 s
env0_first_0:                 episode reward: -25.4500,                 loss: 0.0568
env0_second_0:                 episode reward: 25.4500,                 loss: 0.0518
env1_first_0:                 episode reward: -24.3500,                 loss: nan
env1_second_0:                 episode reward: 24.3500,                 loss: nan
Episode: 861/10000 (8.6100%),                 avg. length: 3678.15,                last time consumption/overall running time: 1007.1590s / 45806.3836 s
env0_first_0:                 episode reward: -24.0500,                 loss: 0.0568
env0_second_0:                 episode reward: 24.0500,                 loss: 0.0501
env1_first_0:                 episode reward: -22.6000,                 loss: nan
env1_second_0:                 episode reward: 22.6000,                 loss: nan
Episode: 881/10000 (8.8100%),                 avg. length: 4058.7,                last time consumption/overall running time: 1122.6413s / 46929.0248 s
env0_first_0:                 episode reward: -28.7000,                 loss: 0.0548
env0_second_0:                 episode reward: 28.7000,                 loss: 0.0497
env1_first_0:                 episode reward: -27.3500,                 loss: nan
env1_second_0:                 episode reward: 27.3500,                 loss: nan
Episode: 901/10000 (9.0100%),                 avg. length: 3931.35,                last time consumption/overall running time: 1088.3772s / 48017.4020 s
env0_first_0:                 episode reward: -26.6500,                 loss: 0.0490
env0_second_0:                 episode reward: 26.6500,                 loss: 0.0448
env1_first_0:                 episode reward: -26.3000,                 loss: nan
env1_second_0:                 episode reward: 26.3000,                 loss: nan
Episode: 921/10000 (9.2100%),                 avg. length: 3743.9,                last time consumption/overall running time: 1034.4793s / 49051.8814 s
env0_first_0:                 episode reward: -27.8000,                 loss: 0.0478
env0_second_0:                 episode reward: 27.8000,                 loss: 0.0437
env1_first_0:                 episode reward: -28.2500,                 loss: nan
env1_second_0:                 episode reward: 28.2500,                 loss: nan
Episode: 941/10000 (9.4100%),                 avg. length: 3657.5,                last time consumption/overall running time: 1005.7151s / 50057.5965 s
env0_first_0:                 episode reward: -28.6500,                 loss: 0.0465
env0_second_0:                 episode reward: 28.6500,                 loss: 0.0451
env1_first_0:                 episode reward: -25.9000,                 loss: nan
env1_second_0:                 episode reward: 25.9000,                 loss: nan
Episode: 961/10000 (9.6100%),                 avg. length: 3964.45,                last time consumption/overall running time: 1087.3001s / 51144.8966 s
env0_first_0:                 episode reward: -28.4500,                 loss: 0.0436
env0_second_0:                 episode reward: 28.4500,                 loss: 0.0425
env1_first_0:                 episode reward: -26.8500,                 loss: nan
env1_second_0:                 episode reward: 26.8500,                 loss: nan
Episode: 981/10000 (9.8100%),                 avg. length: 3824.15,                last time consumption/overall running time: 1058.6173s / 52203.5139 s
env0_first_0:                 episode reward: -27.6000,                 loss: 0.0447
env0_second_0:                 episode reward: 27.6000,                 loss: 0.0429
env1_first_0:                 episode reward: -25.1500,                 loss: nan
env1_second_0:                 episode reward: 25.1500,                 loss: nan
Episode: 1001/10000 (10.0100%),                 avg. length: 3880.45,                last time consumption/overall running time: 1070.5723s / 53274.0862 s
env0_first_0:                 episode reward: -27.4000,                 loss: 0.0417
env0_second_0:                 episode reward: 27.4000,                 loss: 0.0410
env1_first_0:                 episode reward: -24.2500,                 loss: nan
env1_second_0:                 episode reward: 24.2500,                 loss: nan
Episode: 1021/10000 (10.2100%),                 avg. length: 3907.2,                last time consumption/overall running time: 1087.2710s / 54361.3573 s
env0_first_0:                 episode reward: -26.0000,                 loss: 0.0432
env0_second_0:                 episode reward: 26.0000,                 loss: 0.0445
env1_first_0:                 episode reward: -27.9000,                 loss: nan
env1_second_0:                 episode reward: 27.9000,                 loss: nan
Episode: 1041/10000 (10.4100%),                 avg. length: 3890.5,                last time consumption/overall running time: 1094.0380s / 55455.3953 s
env0_first_0:                 episode reward: -26.1000,                 loss: 0.0453
env0_second_0:                 episode reward: 26.1000,                 loss: 0.0463
env1_first_0:                 episode reward: -27.1500,                 loss: nan
env1_second_0:                 episode reward: 27.1500,                 loss: nan
Episode: 1061/10000 (10.6100%),                 avg. length: 3747.4,                last time consumption/overall running time: 1029.1370s / 56484.5324 s
env0_first_0:                 episode reward: -25.9500,                 loss: 0.0462
env0_second_0:                 episode reward: 25.9500,                 loss: 0.0446
env1_first_0:                 episode reward: -25.9000,                 loss: nan
env1_second_0:                 episode reward: 25.9000,                 loss: nan
Episode: 1081/10000 (10.8100%),                 avg. length: 3749.3,                last time consumption/overall running time: 1042.9886s / 57527.5210 s
env0_first_0:                 episode reward: -28.6500,                 loss: 0.0446
env0_second_0:                 episode reward: 28.6500,                 loss: 0.0445
env1_first_0:                 episode reward: -24.9500,                 loss: nan
env1_second_0:                 episode reward: 24.9500,                 loss: nan
Episode: 1101/10000 (11.0100%),                 avg. length: 3619.65,                last time consumption/overall running time: 1012.5552s / 58540.0761 s
env0_first_0:                 episode reward: -25.0000,                 loss: 0.0458
env0_second_0:                 episode reward: 25.0000,                 loss: 0.0448
env1_first_0:                 episode reward: -21.7000,                 loss: nan
env1_second_0:                 episode reward: 21.7000,                 loss: nan
Episode: 1121/10000 (11.2100%),                 avg. length: 3783.3,                last time consumption/overall running time: 1046.9393s / 59587.0155 s
env0_first_0:                 episode reward: -23.1500,                 loss: 0.0457
env0_second_0:                 episode reward: 23.1500,                 loss: 0.0433
env1_first_0:                 episode reward: -24.1000,                 loss: nan
env1_second_0:                 episode reward: 24.1000,                 loss: nan
Episode: 1141/10000 (11.4100%),                 avg. length: 4057.05,                last time consumption/overall running time: 1120.3590s / 60707.3745 s
env0_first_0:                 episode reward: -27.3500,                 loss: 0.0439
env0_second_0:                 episode reward: 27.3500,                 loss: 0.0431
env1_first_0:                 episode reward: -27.5500,                 loss: nan
env1_second_0:                 episode reward: 27.5500,                 loss: nan
Episode: 1161/10000 (11.6100%),                 avg. length: 3693.05,                last time consumption/overall running time: 1025.8628s / 61733.2373 s
env0_first_0:                 episode reward: -24.0000,                 loss: 0.0416
env0_second_0:                 episode reward: 24.0000,                 loss: 0.0410
env1_first_0:                 episode reward: -27.0500,                 loss: nan
env1_second_0:                 episode reward: 27.0500,                 loss: nan
Episode: 1181/10000 (11.8100%),                 avg. length: 3874.6,                last time consumption/overall running time: 1084.9317s / 62818.1691 s
env0_first_0:                 episode reward: -26.3500,                 loss: 0.0410
env0_second_0:                 episode reward: 26.3500,                 loss: 0.0401
env1_first_0:                 episode reward: -26.2000,                 loss: nan
env1_second_0:                 episode reward: 26.2000,                 loss: nan
Episode: 1201/10000 (12.0100%),                 avg. length: 3627.4,                last time consumption/overall running time: 998.8263s / 63816.9953 s
env0_first_0:                 episode reward: -26.3500,                 loss: 0.0428
env0_second_0:                 episode reward: 26.3500,                 loss: 0.0428
env1_first_0:                 episode reward: -22.3500,                 loss: nan
env1_second_0:                 episode reward: 22.3500,                 loss: nan
Episode: 1221/10000 (12.2100%),                 avg. length: 3900.05,                last time consumption/overall running time: 1069.3775s / 64886.3728 s
env0_first_0:                 episode reward: -26.8500,                 loss: 0.0452
env0_second_0:                 episode reward: 26.8500,                 loss: 0.0416
env1_first_0:                 episode reward: -29.3000,                 loss: nan
env1_second_0:                 episode reward: 29.3000,                 loss: nan
Episode: 1241/10000 (12.4100%),                 avg. length: 3876.25,                last time consumption/overall running time: 1061.9065s / 65948.2793 s
env0_first_0:                 episode reward: -25.6000,                 loss: 0.0410
env0_second_0:                 episode reward: 25.6000,                 loss: 0.0413
env1_first_0:                 episode reward: -24.2000,                 loss: nan
env1_second_0:                 episode reward: 24.2000,                 loss: nan
Episode: 1261/10000 (12.6100%),                 avg. length: 3545.8,                last time consumption/overall running time: 977.0362s / 66925.3155 s
env0_first_0:                 episode reward: -23.3500,                 loss: 0.0424
env0_second_0:                 episode reward: 23.3500,                 loss: 0.0420
env1_first_0:                 episode reward: -20.7500,                 loss: nan
env1_second_0:                 episode reward: 20.7500,                 loss: nan
Episode: 1281/10000 (12.8100%),                 avg. length: 3872.0,                last time consumption/overall running time: 1075.0908s / 68000.4063 s
env0_first_0:                 episode reward: -27.4000,                 loss: 0.0429
env0_second_0:                 episode reward: 27.4000,                 loss: 0.0415
env1_first_0:                 episode reward: -26.1500,                 loss: nan
env1_second_0:                 episode reward: 26.1500,                 loss: nan
Episode: 1301/10000 (13.0100%),                 avg. length: 4085.05,                last time consumption/overall running time: 1133.5239s / 69133.9302 s
env0_first_0:                 episode reward: -26.7000,                 loss: 0.0407
env0_second_0:                 episode reward: 26.7000,                 loss: 0.0403
env1_first_0:                 episode reward: -27.1500,                 loss: nan
env1_second_0:                 episode reward: 27.1500,                 loss: nan
Episode: 1321/10000 (13.2100%),                 avg. length: 3944.5,                last time consumption/overall running time: 1089.9758s / 70223.9060 s
env0_first_0:                 episode reward: -26.3500,                 loss: 0.0416
env0_second_0:                 episode reward: 26.3500,                 loss: 0.0420
env1_first_0:                 episode reward: -26.6000,                 loss: nan
env1_second_0:                 episode reward: 26.6000,                 loss: nan
Episode: 1341/10000 (13.4100%),                 avg. length: 3585.95,                last time consumption/overall running time: 979.1784s / 71203.0844 s
env0_first_0:                 episode reward: -23.9000,                 loss: 0.0437
env0_second_0:                 episode reward: 23.9000,                 loss: 0.0430
env1_first_0:                 episode reward: -24.1500,                 loss: nan
env1_second_0:                 episode reward: 24.1500,                 loss: nan
Episode: 1361/10000 (13.6100%),                 avg. length: 3718.95,                last time consumption/overall running time: 1031.0440s / 72234.1284 s
env0_first_0:                 episode reward: -25.6000,                 loss: 0.0436
env0_second_0:                 episode reward: 25.6000,                 loss: 0.0421
env1_first_0:                 episode reward: -25.6500,                 loss: nan
env1_second_0:                 episode reward: 25.6500,                 loss: nan
Episode: 1381/10000 (13.8100%),                 avg. length: 3962.15,                last time consumption/overall running time: 1097.3173s / 73331.4457 s
env0_first_0:                 episode reward: -24.9500,                 loss: 0.0424
env0_second_0:                 episode reward: 24.9500,                 loss: 0.0432
env1_first_0:                 episode reward: -25.7000,                 loss: nan
env1_second_0:                 episode reward: 25.7000,                 loss: nan
Episode: 1401/10000 (14.0100%),                 avg. length: 3685.5,                last time consumption/overall running time: 1024.6400s / 74356.0856 s
env0_first_0:                 episode reward: -26.2000,                 loss: 0.0426
env0_second_0:                 episode reward: 26.2000,                 loss: 0.0418
env1_first_0:                 episode reward: -25.6500,                 loss: nan
env1_second_0:                 episode reward: 25.6500,                 loss: nan
Episode: 1421/10000 (14.2100%),                 avg. length: 3630.85,                last time consumption/overall running time: 992.6670s / 75348.7526 s
env0_first_0:                 episode reward: -21.0000,                 loss: 0.0402
env0_second_0:                 episode reward: 21.0000,                 loss: 0.0385
env1_first_0:                 episode reward: -22.5000,                 loss: nan
env1_second_0:                 episode reward: 22.5000,                 loss: nan
Episode: 1441/10000 (14.4100%),                 avg. length: 3605.35,                last time consumption/overall running time: 996.5815s / 76345.3341 s
env0_first_0:                 episode reward: -24.1000,                 loss: 0.0396
env0_second_0:                 episode reward: 24.1000,                 loss: 0.0409
env1_first_0:                 episode reward: -22.7500,                 loss: nan
env1_second_0:                 episode reward: 22.7500,                 loss: nan
Episode: 1461/10000 (14.6100%),                 avg. length: 3956.35,                last time consumption/overall running time: 1086.6814s / 77432.0155 s
env0_first_0:                 episode reward: -27.0500,                 loss: 0.0410
env0_second_0:                 episode reward: 27.0500,                 loss: 0.0407
env1_first_0:                 episode reward: -25.5500,                 loss: nan
env1_second_0:                 episode reward: 25.5500,                 loss: nan
Episode: 1481/10000 (14.8100%),                 avg. length: 3827.4,                last time consumption/overall running time: 1050.0812s / 78482.0967 s
env0_first_0:                 episode reward: -23.8500,                 loss: 0.0437
env0_second_0:                 episode reward: 23.8500,                 loss: 0.0400
env1_first_0:                 episode reward: -24.0000,                 loss: nan
env1_second_0:                 episode reward: 24.0000,                 loss: nan
Episode: 1501/10000 (15.0100%),                 avg. length: 3708.55,                last time consumption/overall running time: 1010.3768s / 79492.4735 s
env0_first_0:                 episode reward: -25.8500,                 loss: 0.0415
env0_second_0:                 episode reward: 25.8500,                 loss: 0.0408
env1_first_0:                 episode reward: -24.6000,                 loss: nan
env1_second_0:                 episode reward: 24.6000,                 loss: nan
Episode: 1521/10000 (15.2100%),                 avg. length: 3631.35,                last time consumption/overall running time: 1014.2510s / 80506.7244 s
env0_first_0:                 episode reward: -23.2000,                 loss: 0.0407
env0_second_0:                 episode reward: 23.2000,                 loss: 0.0426
env1_first_0:                 episode reward: -24.7000,                 loss: nan
env1_second_0:                 episode reward: 24.7000,                 loss: nan
Episode: 1541/10000 (15.4100%),                 avg. length: 3906.35,                last time consumption/overall running time: 1098.5640s / 81605.2885 s
env0_first_0:                 episode reward: -25.3000,                 loss: 0.0388
env0_second_0:                 episode reward: 25.3000,                 loss: 0.0397
env1_first_0:                 episode reward: -27.4000,                 loss: nan
env1_second_0:                 episode reward: 27.4000,                 loss: nan
Episode: 1561/10000 (15.6100%),                 avg. length: 3496.65,                last time consumption/overall running time: 984.4591s / 82589.7476 s
env0_first_0:                 episode reward: -22.4000,                 loss: 0.0398
env0_second_0:                 episode reward: 22.4000,                 loss: 0.0367
env1_first_0:                 episode reward: -22.1500,                 loss: nan
env1_second_0:                 episode reward: 22.1500,                 loss: nan
Episode: 1581/10000 (15.8100%),                 avg. length: 3603.85,                last time consumption/overall running time: 978.9098s / 83568.6574 s
env0_first_0:                 episode reward: -25.2000,                 loss: 0.0395
env0_second_0:                 episode reward: 25.2000,                 loss: 0.0386
env1_first_0:                 episode reward: -26.7000,                 loss: nan
env1_second_0:                 episode reward: 26.7000,                 loss: nan
Episode: 1601/10000 (16.0100%),                 avg. length: 3815.1,                last time consumption/overall running time: 1037.0648s / 84605.7222 s
env0_first_0:                 episode reward: -25.7000,                 loss: 0.0410
env0_second_0:                 episode reward: 25.7000,                 loss: 0.0400
env1_first_0:                 episode reward: -25.6500,                 loss: nan
env1_second_0:                 episode reward: 25.6500,                 loss: nan
Episode: 1621/10000 (16.2100%),                 avg. length: 3595.35,                last time consumption/overall running time: 994.2339s / 85599.9561 s
env0_first_0:                 episode reward: -22.3000,                 loss: 0.0369
env0_second_0:                 episode reward: 22.3000,                 loss: 0.0377
env1_first_0:                 episode reward: -23.3000,                 loss: nan
env1_second_0:                 episode reward: 23.3000,                 loss: nan
Episode: 1641/10000 (16.4100%),                 avg. length: 3820.1,                last time consumption/overall running time: 1063.0939s / 86663.0499 s
env0_first_0:                 episode reward: -25.7500,                 loss: 0.0389
env0_second_0:                 episode reward: 25.7500,                 loss: 0.0367
env1_first_0:                 episode reward: -25.5000,                 loss: nan
env1_second_0:                 episode reward: 25.5000,                 loss: nan
Episode: 1661/10000 (16.6100%),                 avg. length: 3708.6,                last time consumption/overall running time: 1039.3484s / 87702.3983 s
env0_first_0:                 episode reward: -22.6000,                 loss: 0.0388
env0_second_0:                 episode reward: 22.6000,                 loss: 0.0409
env1_first_0:                 episode reward: -22.9000,                 loss: nan
env1_second_0:                 episode reward: 22.9000,                 loss: nan
Episode: 1681/10000 (16.8100%),                 avg. length: 3764.15,                last time consumption/overall running time: 1034.6242s / 88737.0225 s
env0_first_0:                 episode reward: -24.3500,                 loss: 0.0401
env0_second_0:                 episode reward: 24.3500,                 loss: 0.0391
env1_first_0:                 episode reward: -24.7500,                 loss: nan
env1_second_0:                 episode reward: 24.7500,                 loss: nan
Episode: 1701/10000 (17.0100%),                 avg. length: 3485.9,                last time consumption/overall running time: 947.4839s / 89684.5064 s
env0_first_0:                 episode reward: -24.2500,                 loss: 0.0373
env0_second_0:                 episode reward: 24.2500,                 loss: 0.0402
env1_first_0:                 episode reward: -22.5500,                 loss: nan
env1_second_0:                 episode reward: 22.5500,                 loss: nan
Episode: 1721/10000 (17.2100%),                 avg. length: 3512.6,                last time consumption/overall running time: 975.2635s / 90659.7699 s
env0_first_0:                 episode reward: -19.8500,                 loss: 0.0398
env0_second_0:                 episode reward: 19.8500,                 loss: 0.0403
env1_first_0:                 episode reward: -22.3500,                 loss: nan
env1_second_0:                 episode reward: 22.3500,                 loss: nan
Episode: 1741/10000 (17.4100%),                 avg. length: 3187.95,                last time consumption/overall running time: 887.7068s / 91547.4767 s
env0_first_0:                 episode reward: -17.8500,                 loss: 0.0408
env0_second_0:                 episode reward: 17.8500,                 loss: 0.0402
env1_first_0:                 episode reward: -20.7500,                 loss: nan
env1_second_0:                 episode reward: 20.7500,                 loss: nan
Episode: 1761/10000 (17.6100%),                 avg. length: 3654.95,                last time consumption/overall running time: 1004.3921s / 92551.8689 s
env0_first_0:                 episode reward: -22.4000,                 loss: 0.0406
env0_second_0:                 episode reward: 22.4000,                 loss: 0.0390
env1_first_0:                 episode reward: -21.4500,                 loss: nan
env1_second_0:                 episode reward: 21.4500,                 loss: nan
Episode: 1781/10000 (17.8100%),                 avg. length: 3638.5,                last time consumption/overall running time: 1002.4105s / 93554.2794 s
env0_first_0:                 episode reward: -20.8000,                 loss: 0.0394
env0_second_0:                 episode reward: 20.8000,                 loss: 0.0387
env1_first_0:                 episode reward: -21.6500,                 loss: nan
env1_second_0:                 episode reward: 21.6500,                 loss: nan
Episode: 1801/10000 (18.0100%),                 avg. length: 3479.2,                last time consumption/overall running time: 944.9946s / 94499.2740 s
env0_first_0:                 episode reward: -21.4500,                 loss: 0.0388
env0_second_0:                 episode reward: 21.4500,                 loss: 0.0384
env1_first_0:                 episode reward: -21.6000,                 loss: nan
env1_second_0:                 episode reward: 21.6000,                 loss: nan
Episode: 1821/10000 (18.2100%),                 avg. length: 3715.8,                last time consumption/overall running time: 1038.8166s / 95538.0905 s
env0_first_0:                 episode reward: -20.3000,                 loss: 0.0381
env0_second_0:                 episode reward: 20.3000,                 loss: 0.0384
env1_first_0:                 episode reward: -23.2000,                 loss: nan
env1_second_0:                 episode reward: 23.2000,                 loss: nan
Episode: 1841/10000 (18.4100%),                 avg. length: 3409.4,                last time consumption/overall running time: 939.4372s / 96477.5278 s
env0_first_0:                 episode reward: -19.3000,                 loss: 0.0389
env0_second_0:                 episode reward: 19.3000,                 loss: 0.0370
env1_first_0:                 episode reward: -19.0000,                 loss: nan
env1_second_0:                 episode reward: 19.0000,                 loss: nan
Episode: 1861/10000 (18.6100%),                 avg. length: 3332.0,                last time consumption/overall running time: 936.5823s / 97414.1101 s
env0_first_0:                 episode reward: -21.1500,                 loss: 0.0383
env0_second_0:                 episode reward: 21.1500,                 loss: 0.0394
env1_first_0:                 episode reward: -23.5500,                 loss: nan
env1_second_0:                 episode reward: 23.5500,                 loss: nan
Episode: 1881/10000 (18.8100%),                 avg. length: 3666.6,                last time consumption/overall running time: 1034.4272s / 98448.5373 s
env0_first_0:                 episode reward: -21.5000,                 loss: 0.0380
env0_second_0:                 episode reward: 21.5000,                 loss: 0.0370
env1_first_0:                 episode reward: -24.9500,                 loss: nan
env1_second_0:                 episode reward: 24.9500,                 loss: nan
Episode: 1901/10000 (19.0100%),                 avg. length: 3469.1,                last time consumption/overall running time: 950.7148s / 99399.2521 s
env0_first_0:                 episode reward: -19.2500,                 loss: 0.0373
env0_second_0:                 episode reward: 19.2500,                 loss: 0.0375
env1_first_0:                 episode reward: -19.9000,                 loss: nan
env1_second_0:                 episode reward: 19.9000,                 loss: nan
Episode: 1921/10000 (19.2100%),                 avg. length: 3595.9,                last time consumption/overall running time: 992.3284s / 100391.5804 s
env0_first_0:                 episode reward: -23.5500,                 loss: 0.0378
env0_second_0:                 episode reward: 23.5500,                 loss: 0.0406
env1_first_0:                 episode reward: -20.5500,                 loss: nan
env1_second_0:                 episode reward: 20.5500,                 loss: nan
Episode: 1941/10000 (19.4100%),                 avg. length: 3150.35,                last time consumption/overall running time: 875.7107s / 101267.2912 s
env0_first_0:                 episode reward: -15.2000,                 loss: 0.0389
env0_second_0:                 episode reward: 15.2000,                 loss: 0.0390
env1_first_0:                 episode reward: -18.3500,                 loss: nan
env1_second_0:                 episode reward: 18.3500,                 loss: nan
Episode: 1961/10000 (19.6100%),                 avg. length: 3207.8,                last time consumption/overall running time: 883.2397s / 102150.5309 s
env0_first_0:                 episode reward: -18.4000,                 loss: 0.0396
env0_second_0:                 episode reward: 18.4000,                 loss: 0.0401
env1_first_0:                 episode reward: -18.1500,                 loss: nan
env1_second_0:                 episode reward: 18.1500,                 loss: nan
Episode: 1981/10000 (19.8100%),                 avg. length: 3474.7,                last time consumption/overall running time: 954.3448s / 103104.8757 s
env0_first_0:                 episode reward: -20.5500,                 loss: 0.0396
env0_second_0:                 episode reward: 20.5500,                 loss: 0.0379
env1_first_0:                 episode reward: -24.6000,                 loss: nan
env1_second_0:                 episode reward: 24.6000,                 loss: nan
Episode: 2001/10000 (20.0100%),                 avg. length: 3711.75,                last time consumption/overall running time: 1016.0731s / 104120.9488 s
env0_first_0:                 episode reward: -22.6500,                 loss: 0.0388
env0_second_0:                 episode reward: 22.6500,                 loss: 0.0372
env1_first_0:                 episode reward: -20.8000,                 loss: nan
env1_second_0:                 episode reward: 20.8000,                 loss: nan
Episode: 2021/10000 (20.2100%),                 avg. length: 3378.95,                last time consumption/overall running time: 906.5090s / 105027.4578 s
env0_first_0:                 episode reward: -21.7000,                 loss: 0.0382
env0_second_0:                 episode reward: 21.7000,                 loss: 0.0370
env1_first_0:                 episode reward: -20.3500,                 loss: nan
env1_second_0:                 episode reward: 20.3500,                 loss: nan
Episode: 2041/10000 (20.4100%),                 avg. length: 3747.05,                last time consumption/overall running time: 1038.1345s / 106065.5923 s
env0_first_0:                 episode reward: -23.6500,                 loss: 0.0368
env0_second_0:                 episode reward: 23.6500,                 loss: 0.0371
env1_first_0:                 episode reward: -22.0500,                 loss: nan
env1_second_0:                 episode reward: 22.0500,                 loss: nan
Episode: 2061/10000 (20.6100%),                 avg. length: 3457.95,                last time consumption/overall running time: 958.3165s / 107023.9087 s
env0_first_0:                 episode reward: -20.2000,                 loss: 0.0386
env0_second_0:                 episode reward: 20.2000,                 loss: 0.0369
env1_first_0:                 episode reward: -20.8000,                 loss: nan
env1_second_0:                 episode reward: 20.8000,                 loss: nan
Episode: 2081/10000 (20.8100%),                 avg. length: 3614.2,                last time consumption/overall running time: 1000.2858s / 108024.1945 s
env0_first_0:                 episode reward: -22.9500,                 loss: 0.0393
env0_second_0:                 episode reward: 22.9500,                 loss: 0.0400
env1_first_0:                 episode reward: -22.5000,                 loss: nan
env1_second_0:                 episode reward: 22.5000,                 loss: nan
Episode: 2101/10000 (21.0100%),                 avg. length: 3323.45,                last time consumption/overall running time: 905.8843s / 108930.0788 s
env0_first_0:                 episode reward: -18.8000,                 loss: 0.0374
env0_second_0:                 episode reward: 18.8000,                 loss: 0.0375
env1_first_0:                 episode reward: -20.3500,                 loss: nan
env1_second_0:                 episode reward: 20.3500,                 loss: nan
Episode: 2121/10000 (21.2100%),                 avg. length: 3455.75,                last time consumption/overall running time: 945.2760s / 109875.3549 s
env0_first_0:                 episode reward: -21.8500,                 loss: 0.0384
env0_second_0:                 episode reward: 21.8500,                 loss: 0.0368
env1_first_0:                 episode reward: -21.1000,                 loss: nan
env1_second_0:                 episode reward: 21.1000,                 loss: nan
Episode: 2141/10000 (21.4100%),                 avg. length: 3290.3,                last time consumption/overall running time: 887.4318s / 110762.7867 s
env0_first_0:                 episode reward: -20.7000,                 loss: 0.0386
env0_second_0:                 episode reward: 20.7000,                 loss: 0.0397
env1_first_0:                 episode reward: -19.4500,                 loss: nan
env1_second_0:                 episode reward: 19.4500,                 loss: nan
Episode: 2161/10000 (21.6100%),                 avg. length: 3509.9,                last time consumption/overall running time: 940.6430s / 111703.4296 s
env0_first_0:                 episode reward: -20.4500,                 loss: 0.0376
env0_second_0:                 episode reward: 20.4500,                 loss: 0.0377
env1_first_0:                 episode reward: -22.4000,                 loss: nan
env1_second_0:                 episode reward: 22.4000,                 loss: nan
Episode: 2181/10000 (21.8100%),                 avg. length: 3446.9,                last time consumption/overall running time: 950.4542s / 112653.8839 s
env0_first_0:                 episode reward: -19.2000,                 loss: 0.0362
env0_second_0:                 episode reward: 19.2000,                 loss: 0.0368
env1_first_0:                 episode reward: -19.3500,                 loss: nan
env1_second_0:                 episode reward: 19.3500,                 loss: nan
Episode: 2201/10000 (22.0100%),                 avg. length: 3560.6,                last time consumption/overall running time: 983.8358s / 113637.7197 s
env0_first_0:                 episode reward: -22.7000,                 loss: 0.0377
env0_second_0:                 episode reward: 22.7000,                 loss: 0.0379
env1_first_0:                 episode reward: -21.4500,                 loss: nan
env1_second_0:                 episode reward: 21.4500,                 loss: nan
Episode: 2221/10000 (22.2100%),                 avg. length: 3280.1,                last time consumption/overall running time: 885.3042s / 114523.0239 s
env0_first_0:                 episode reward: -20.7000,                 loss: 0.0375
env0_second_0:                 episode reward: 20.7000,                 loss: 0.0384
env1_first_0:                 episode reward: -19.4500,                 loss: nan
env1_second_0:                 episode reward: 19.4500,                 loss: nan
Episode: 2241/10000 (22.4100%),                 avg. length: 3376.0,                last time consumption/overall running time: 912.4450s / 115435.4689 s
env0_first_0:                 episode reward: -19.5000,                 loss: 0.0377
env0_second_0:                 episode reward: 19.5000,                 loss: 0.0370
env1_first_0:                 episode reward: -19.8500,                 loss: nan
env1_second_0:                 episode reward: 19.8500,                 loss: nan
Episode: 2261/10000 (22.6100%),                 avg. length: 3660.35,                last time consumption/overall running time: 982.9067s / 116418.3756 s
env0_first_0:                 episode reward: -23.1500,                 loss: 0.0381
env0_second_0:                 episode reward: 23.1500,                 loss: 0.0368
env1_first_0:                 episode reward: -22.0000,                 loss: nan
env1_second_0:                 episode reward: 22.0000,                 loss: nan
Episode: 2281/10000 (22.8100%),                 avg. length: 3118.55,                last time consumption/overall running time: 848.0621s / 117266.4377 s
env0_first_0:                 episode reward: -16.2000,                 loss: 0.0361
env0_second_0:                 episode reward: 16.2000,                 loss: 0.0361
env1_first_0:                 episode reward: -17.1500,                 loss: nan
env1_second_0:                 episode reward: 17.1500,                 loss: nan
Episode: 2301/10000 (23.0100%),                 avg. length: 3578.8,                last time consumption/overall running time: 981.0830s / 118247.5207 s
env0_first_0:                 episode reward: -19.9000,                 loss: 0.0355
env0_second_0:                 episode reward: 19.9000,                 loss: 0.0353
env1_first_0:                 episode reward: -19.5500,                 loss: nan
env1_second_0:                 episode reward: 19.5500,                 loss: nan
Episode: 2321/10000 (23.2100%),                 avg. length: 3548.4,                last time consumption/overall running time: 969.8167s / 119217.3374 s
env0_first_0:                 episode reward: -19.8500,                 loss: 0.0343
env0_second_0:                 episode reward: 19.8500,                 loss: 0.0341
env1_first_0:                 episode reward: -21.0000,                 loss: nan
env1_second_0:                 episode reward: 21.0000,                 loss: nan
Episode: 2341/10000 (23.4100%),                 avg. length: 3308.8,                last time consumption/overall running time: 895.8921s / 120113.2295 s
env0_first_0:                 episode reward: -18.5000,                 loss: 0.0349
env0_second_0:                 episode reward: 18.5000,                 loss: 0.0346
env1_first_0:                 episode reward: -20.9000,                 loss: nan
env1_second_0:                 episode reward: 20.9000,                 loss: nan
Episode: 2361/10000 (23.6100%),                 avg. length: 3564.95,                last time consumption/overall running time: 955.0890s / 121068.3185 s
env0_first_0:                 episode reward: -19.0500,                 loss: 0.0345
env0_second_0:                 episode reward: 19.0500,                 loss: 0.0352
env1_first_0:                 episode reward: -23.7000,                 loss: nan
env1_second_0:                 episode reward: 23.7000,                 loss: nan
Episode: 2381/10000 (23.8100%),                 avg. length: 3509.05,                last time consumption/overall running time: 946.1331s / 122014.4516 s
env0_first_0:                 episode reward: -23.1500,                 loss: 0.0359
env0_second_0:                 episode reward: 23.1500,                 loss: 0.0356
env1_first_0:                 episode reward: -23.1000,                 loss: nan
env1_second_0:                 episode reward: 23.1000,                 loss: nan
Episode: 2401/10000 (24.0100%),                 avg. length: 3591.05,                last time consumption/overall running time: 967.1785s / 122981.6300 s
env0_first_0:                 episode reward: -22.6000,                 loss: 0.0376
env0_second_0:                 episode reward: 22.6000,                 loss: 0.0358
env1_first_0:                 episode reward: -22.7000,                 loss: nan
env1_second_0:                 episode reward: 22.7000,                 loss: nan
Episode: 2421/10000 (24.2100%),                 avg. length: 3260.1,                last time consumption/overall running time: 880.7383s / 123862.3683 s
env0_first_0:                 episode reward: -17.9000,                 loss: 0.0362
env0_second_0:                 episode reward: 17.9000,                 loss: 0.0342
env1_first_0:                 episode reward: -17.8500,                 loss: nan
env1_second_0:                 episode reward: 17.8500,                 loss: nan
Episode: 2441/10000 (24.4100%),                 avg. length: 3312.75,                last time consumption/overall running time: 910.3467s / 124772.7150 s
env0_first_0:                 episode reward: -19.6000,                 loss: 0.0361
env0_second_0:                 episode reward: 19.6000,                 loss: 0.0367
env1_first_0:                 episode reward: -16.7000,                 loss: nan
env1_second_0:                 episode reward: 16.7000,                 loss: nan
Episode: 2461/10000 (24.6100%),                 avg. length: 3398.8,                last time consumption/overall running time: 921.9645s / 125694.6795 s
env0_first_0:                 episode reward: -19.5500,                 loss: 0.0378
env0_second_0:                 episode reward: 19.5500,                 loss: 0.0384
env1_first_0:                 episode reward: -20.6500,                 loss: nan
env1_second_0:                 episode reward: 20.6500,                 loss: nan
Episode: 2481/10000 (24.8100%),                 avg. length: 3441.65,                last time consumption/overall running time: 924.7388s / 126619.4183 s
env0_first_0:                 episode reward: -21.3000,                 loss: 0.0397
env0_second_0:                 episode reward: 21.3000,                 loss: 0.0372
env1_first_0:                 episode reward: -18.8000,                 loss: nan
env1_second_0:                 episode reward: 18.8000,                 loss: nan
Episode: 2501/10000 (25.0100%),                 avg. length: 3324.6,                last time consumption/overall running time: 901.5322s / 127520.9505 s
env0_first_0:                 episode reward: -21.1500,                 loss: 0.0369
env0_second_0:                 episode reward: 21.1500,                 loss: 0.0379
env1_first_0:                 episode reward: -20.1000,                 loss: nan
env1_second_0:                 episode reward: 20.1000,                 loss: nan
Episode: 2521/10000 (25.2100%),                 avg. length: 3539.7,                last time consumption/overall running time: 968.3260s / 128489.2765 s
env0_first_0:                 episode reward: -18.2000,                 loss: 0.0379
env0_second_0:                 episode reward: 18.2000,                 loss: 0.0384
env1_first_0:                 episode reward: -19.2500,                 loss: nan
env1_second_0:                 episode reward: 19.2500,                 loss: nan
Episode: 2541/10000 (25.4100%),                 avg. length: 3220.35,                last time consumption/overall running time: 869.4892s / 129358.7657 s
env0_first_0:                 episode reward: -18.4000,                 loss: 0.0385
env0_second_0:                 episode reward: 18.4000,                 loss: 0.0377
env1_first_0:                 episode reward: -17.1500,                 loss: nan
env1_second_0:                 episode reward: 17.1500,                 loss: nan
Episode: 2561/10000 (25.6100%),                 avg. length: 3530.65,                last time consumption/overall running time: 939.7738s / 130298.5395 s
env0_first_0:                 episode reward: -20.6000,                 loss: 0.0375
env0_second_0:                 episode reward: 20.6000,                 loss: 0.0377
env1_first_0:                 episode reward: -24.5500,                 loss: nan
env1_second_0:                 episode reward: 24.5500,                 loss: nan
Episode: 2581/10000 (25.8100%),                 avg. length: 3546.05,                last time consumption/overall running time: 952.6246s / 131251.1641 s
env0_first_0:                 episode reward: -21.6000,                 loss: 0.0368
env0_second_0:                 episode reward: 21.6000,                 loss: 0.0371
env1_first_0:                 episode reward: -20.7500,                 loss: nan
env1_second_0:                 episode reward: 20.7500,                 loss: nan
Episode: 2601/10000 (26.0100%),                 avg. length: 3466.15,                last time consumption/overall running time: 944.5087s / 132195.6729 s
env0_first_0:                 episode reward: -19.0500,                 loss: 0.0369
env0_second_0:                 episode reward: 19.0500,                 loss: 0.0362
env1_first_0:                 episode reward: -18.4000,                 loss: nan
env1_second_0:                 episode reward: 18.4000,                 loss: nan
Episode: 2621/10000 (26.2100%),                 avg. length: 3253.75,                last time consumption/overall running time: 880.2384s / 133075.9113 s
env0_first_0:                 episode reward: -18.5500,                 loss: 0.0381
env0_second_0:                 episode reward: 18.5500,                 loss: 0.0385
env1_first_0:                 episode reward: -17.3000,                 loss: nan
env1_second_0:                 episode reward: 17.3000,                 loss: nan
Episode: 2641/10000 (26.4100%),                 avg. length: 3333.95,                last time consumption/overall running time: 905.8509s / 133981.7622 s
env0_first_0:                 episode reward: -16.0000,                 loss: 0.0377
env0_second_0:                 episode reward: 16.0000,                 loss: 0.0379
env1_first_0:                 episode reward: -19.4500,                 loss: nan
env1_second_0:                 episode reward: 19.4500,                 loss: nan
Episode: 2661/10000 (26.6100%),                 avg. length: 3392.9,                last time consumption/overall running time: 913.4230s / 134895.1852 s
env0_first_0:                 episode reward: -14.2000,                 loss: 0.0368
env0_second_0:                 episode reward: 14.2000,                 loss: 0.0368
env1_first_0:                 episode reward: -17.5500,                 loss: nan
env1_second_0:                 episode reward: 17.5500,                 loss: nan
Episode: 2681/10000 (26.8100%),                 avg. length: 3375.0,                last time consumption/overall running time: 914.9506s / 135810.1358 s
env0_first_0:                 episode reward: -20.7500,                 loss: 0.0364
env0_second_0:                 episode reward: 20.7500,                 loss: 0.0358
env1_first_0:                 episode reward: -20.3000,                 loss: nan
env1_second_0:                 episode reward: 20.3000,                 loss: nan
Episode: 2701/10000 (27.0100%),                 avg. length: 3376.35,                last time consumption/overall running time: 906.8420s / 136716.9778 s
env0_first_0:                 episode reward: -16.7000,                 loss: 0.0358
env0_second_0:                 episode reward: 16.7000,                 loss: 0.0359
env1_first_0:                 episode reward: -18.8000,                 loss: nan
env1_second_0:                 episode reward: 18.8000,                 loss: nan
Episode: 2721/10000 (27.2100%),                 avg. length: 3346.6,                last time consumption/overall running time: 914.4089s / 137631.3867 s
env0_first_0:                 episode reward: -16.1000,                 loss: 0.0374
env0_second_0:                 episode reward: 16.1000,                 loss: 0.0353
env1_first_0:                 episode reward: -16.8500,                 loss: nan
env1_second_0:                 episode reward: 16.8500,                 loss: nan
Episode: 2741/10000 (27.4100%),                 avg. length: 3238.65,                last time consumption/overall running time: 895.2717s / 138526.6584 s
env0_first_0:                 episode reward: -15.4500,                 loss: 0.0358
env0_second_0:                 episode reward: 15.4500,                 loss: 0.0354
env1_first_0:                 episode reward: -17.1000,                 loss: nan
env1_second_0:                 episode reward: 17.1000,                 loss: nan
Episode: 2761/10000 (27.6100%),                 avg. length: 3297.95,                last time consumption/overall running time: 883.5833s / 139410.2416 s
env0_first_0:                 episode reward: -17.4000,                 loss: 0.0377
env0_second_0:                 episode reward: 17.4000,                 loss: 0.0372
env1_first_0:                 episode reward: -15.5500,                 loss: nan
env1_second_0:                 episode reward: 15.5500,                 loss: nan
Episode: 2781/10000 (27.8100%),                 avg. length: 3023.9,                last time consumption/overall running time: 814.6138s / 140224.8555 s
env0_first_0:                 episode reward: -16.2500,                 loss: 0.0373
env0_second_0:                 episode reward: 16.2500,                 loss: 0.0384
env1_first_0:                 episode reward: -14.6500,                 loss: nan
env1_second_0:                 episode reward: 14.6500,                 loss: nan
Episode: 2801/10000 (28.0100%),                 avg. length: 3248.7,                last time consumption/overall running time: 883.9035s / 141108.7590 s
env0_first_0:                 episode reward: -16.5500,                 loss: 0.0393
env0_second_0:                 episode reward: 16.5500,                 loss: 0.0381
env1_first_0:                 episode reward: -16.7000,                 loss: nan
env1_second_0:                 episode reward: 16.7000,                 loss: nan
Episode: 2821/10000 (28.2100%),                 avg. length: 3183.25,                last time consumption/overall running time: 864.4814s / 141973.2404 s
env0_first_0:                 episode reward: -15.1000,                 loss: 0.0382
env0_second_0:                 episode reward: 15.1000,                 loss: 0.0383
env1_first_0:                 episode reward: -15.1000,                 loss: nan
env1_second_0:                 episode reward: 15.1000,                 loss: nan
Episode: 2841/10000 (28.4100%),                 avg. length: 3230.5,                last time consumption/overall running time: 866.2586s / 142839.4991 s
env0_first_0:                 episode reward: -17.8500,                 loss: 0.0376
env0_second_0:                 episode reward: 17.8500,                 loss: 0.0376
env1_first_0:                 episode reward: -14.9000,                 loss: nan
env1_second_0:                 episode reward: 14.9000,                 loss: nan
Episode: 2861/10000 (28.6100%),                 avg. length: 3247.6,                last time consumption/overall running time: 869.3722s / 143708.8713 s
env0_first_0:                 episode reward: -16.5500,                 loss: 0.0385
env0_second_0:                 episode reward: 16.5500,                 loss: 0.0379
env1_first_0:                 episode reward: -18.5500,                 loss: nan
env1_second_0:                 episode reward: 18.5500,                 loss: nan
Episode: 2881/10000 (28.8100%),                 avg. length: 3456.3,                last time consumption/overall running time: 923.2106s / 144632.0818 s
env0_first_0:                 episode reward: -17.5500,                 loss: 0.0382
env0_second_0:                 episode reward: 17.5500,                 loss: 0.0375
env1_first_0:                 episode reward: -17.3000,                 loss: nan
env1_second_0:                 episode reward: 17.3000,                 loss: nan
Episode: 2901/10000 (29.0100%),                 avg. length: 3188.15,                last time consumption/overall running time: 849.1740s / 145481.2558 s
env0_first_0:                 episode reward: -16.8000,                 loss: 0.0384
env0_second_0:                 episode reward: 16.8000,                 loss: 0.0370
env1_first_0:                 episode reward: -15.5500,                 loss: nan
env1_second_0:                 episode reward: 15.5500,                 loss: nan
Episode: 2921/10000 (29.2100%),                 avg. length: 3216.4,                last time consumption/overall running time: 862.2479s / 146343.5037 s
env0_first_0:                 episode reward: -16.6500,                 loss: 0.0363
env0_second_0:                 episode reward: 16.6500,                 loss: 0.0365
env1_first_0:                 episode reward: -14.5000,                 loss: nan
env1_second_0:                 episode reward: 14.5000,                 loss: nan
Episode: 2941/10000 (29.4100%),                 avg. length: 3294.35,                last time consumption/overall running time: 910.5945s / 147254.0982 s
env0_first_0:                 episode reward: -12.0500,                 loss: 0.0366
env0_second_0:                 episode reward: 12.0500,                 loss: 0.0364
env1_first_0:                 episode reward: -17.6500,                 loss: nan
env1_second_0:                 episode reward: 17.6500,                 loss: nan
Episode: 2961/10000 (29.6100%),                 avg. length: 3301.6,                last time consumption/overall running time: 891.5900s / 148145.6882 s
env0_first_0:                 episode reward: -18.2000,                 loss: 0.0391
env0_second_0:                 episode reward: 18.2000,                 loss: 0.0380
env1_first_0:                 episode reward: -17.4500,                 loss: nan
env1_second_0:                 episode reward: 17.4500,                 loss: nan
Episode: 2981/10000 (29.8100%),                 avg. length: 3177.0,                last time consumption/overall running time: 883.2975s / 149028.9857 s
env0_first_0:                 episode reward: -14.4500,                 loss: 0.0384
env0_second_0:                 episode reward: 14.4500,                 loss: 0.0365
env1_first_0:                 episode reward: -14.3000,                 loss: nan
env1_second_0:                 episode reward: 14.3000,                 loss: nan
Episode: 3001/10000 (30.0100%),                 avg. length: 3285.4,                last time consumption/overall running time: 906.1362s / 149935.1219 s
env0_first_0:                 episode reward: -15.0000,                 loss: 0.0371
env0_second_0:                 episode reward: 15.0000,                 loss: 0.0361
env1_first_0:                 episode reward: -16.6500,                 loss: nan
env1_second_0:                 episode reward: 16.6500,                 loss: nan
Episode: 3021/10000 (30.2100%),                 avg. length: 3273.0,                last time consumption/overall running time: 875.9418s / 150811.0637 s
env0_first_0:                 episode reward: -15.8500,                 loss: 0.0358
env0_second_0:                 episode reward: 15.8500,                 loss: 0.0374
env1_first_0:                 episode reward: -15.8000,                 loss: nan
env1_second_0:                 episode reward: 15.8000,                 loss: nan
Episode: 3041/10000 (30.4100%),                 avg. length: 3295.05,                last time consumption/overall running time: 904.3014s / 151715.3651 s
env0_first_0:                 episode reward: -16.2000,                 loss: 0.0377
env0_second_0:                 episode reward: 16.2000,                 loss: 0.0380
env1_first_0:                 episode reward: -15.6500,                 loss: nan
env1_second_0:                 episode reward: 15.6500,                 loss: nan
Episode: 3061/10000 (30.6100%),                 avg. length: 3295.5,                last time consumption/overall running time: 896.1229s / 152611.4880 s
env0_first_0:                 episode reward: -16.9000,                 loss: 0.0364
env0_second_0:                 episode reward: 16.9000,                 loss: 0.0380
env1_first_0:                 episode reward: -19.5000,                 loss: nan
env1_second_0:                 episode reward: 19.5000,                 loss: nan
Episode: 3081/10000 (30.8100%),                 avg. length: 3400.05,                last time consumption/overall running time: 911.6020s / 153523.0901 s
env0_first_0:                 episode reward: -18.8000,                 loss: 0.0385
env0_second_0:                 episode reward: 18.8000,                 loss: 0.0376
env1_first_0:                 episode reward: -15.9500,                 loss: nan
env1_second_0:                 episode reward: 15.9500,                 loss: nan
Episode: 3101/10000 (31.0100%),                 avg. length: 3383.2,                last time consumption/overall running time: 918.1816s / 154441.2716 s
env0_first_0:                 episode reward: -17.0500,                 loss: 0.0398
env0_second_0:                 episode reward: 17.0500,                 loss: 0.0384
env1_first_0:                 episode reward: -14.6500,                 loss: nan
env1_second_0:                 episode reward: 14.6500,                 loss: nan
Episode: 3121/10000 (31.2100%),                 avg. length: 3459.25,                last time consumption/overall running time: 964.6739s / 155405.9456 s
env0_first_0:                 episode reward: -16.5000,                 loss: 0.0388
env0_second_0:                 episode reward: 16.5000,                 loss: 0.0385
env1_first_0:                 episode reward: -17.9500,                 loss: nan
env1_second_0:                 episode reward: 17.9500,                 loss: nan
Episode: 3141/10000 (31.4100%),                 avg. length: 3214.5,                last time consumption/overall running time: 891.0354s / 156296.9809 s
env0_first_0:                 episode reward: -15.8500,                 loss: 0.0401
env0_second_0:                 episode reward: 15.8500,                 loss: 0.0395
env1_first_0:                 episode reward: -14.8000,                 loss: nan
env1_second_0:                 episode reward: 14.8000,                 loss: nan
Episode: 3161/10000 (31.6100%),                 avg. length: 3108.65,                last time consumption/overall running time: 843.1834s / 157140.1643 s
env0_first_0:                 episode reward: -14.4500,                 loss: 0.0413
env0_second_0:                 episode reward: 14.4500,                 loss: 0.0389
env1_first_0:                 episode reward: -13.8000,                 loss: nan
env1_second_0:                 episode reward: 13.8000,                 loss: nan
Episode: 3181/10000 (31.8100%),                 avg. length: 3110.2,                last time consumption/overall running time: 859.8084s / 157999.9726 s
env0_first_0:                 episode reward: -13.0500,                 loss: 0.0378
env0_second_0:                 episode reward: 13.0500,                 loss: 0.0372
env1_first_0:                 episode reward: -14.6500,                 loss: nan
env1_second_0:                 episode reward: 14.6500,                 loss: nan
Episode: 3201/10000 (32.0100%),                 avg. length: 3414.25,                last time consumption/overall running time: 939.7891s / 158939.7618 s
env0_first_0:                 episode reward: -17.3500,                 loss: 0.0380
env0_second_0:                 episode reward: 17.3500,                 loss: 0.0371
env1_first_0:                 episode reward: -16.6500,                 loss: nan
env1_second_0:                 episode reward: 16.6500,                 loss: nan
Episode: 3221/10000 (32.2100%),                 avg. length: 3130.75,                last time consumption/overall running time: 857.3872s / 159797.1489 s
env0_first_0:                 episode reward: -15.6500,                 loss: 0.0370
env0_second_0:                 episode reward: 15.6500,                 loss: 0.0368
env1_first_0:                 episode reward: -15.2500,                 loss: nan
env1_second_0:                 episode reward: 15.2500,                 loss: nan
Episode: 3241/10000 (32.4100%),                 avg. length: 3057.65,                last time consumption/overall running time: 841.4377s / 160638.5867 s
env0_first_0:                 episode reward: -13.3000,                 loss: 0.0380
env0_second_0:                 episode reward: 13.3000,                 loss: 0.0369
env1_first_0:                 episode reward: -16.1000,                 loss: nan
env1_second_0:                 episode reward: 16.1000,                 loss: nan
Episode: 3261/10000 (32.6100%),                 avg. length: 3174.75,                last time consumption/overall running time: 861.9147s / 161500.5014 s
env0_first_0:                 episode reward: -14.9500,                 loss: 0.0373
env0_second_0:                 episode reward: 14.9500,                 loss: 0.0372
env1_first_0:                 episode reward: -14.2500,                 loss: nan
env1_second_0:                 episode reward: 14.2500,                 loss: nan
Episode: 3281/10000 (32.8100%),                 avg. length: 3291.75,                last time consumption/overall running time: 888.6055s / 162389.1069 s
env0_first_0:                 episode reward: -15.1500,                 loss: 0.0367
env0_second_0:                 episode reward: 15.1500,                 loss: 0.0369
env1_first_0:                 episode reward: -16.2500,                 loss: nan
env1_second_0:                 episode reward: 16.2500,                 loss: nan
Episode: 3301/10000 (33.0100%),                 avg. length: 3200.25,                last time consumption/overall running time: 873.2551s / 163262.3619 s
env0_first_0:                 episode reward: -12.9000,                 loss: 0.0358
env0_second_0:                 episode reward: 12.9000,                 loss: 0.0367
env1_first_0:                 episode reward: -13.8500,                 loss: nan
env1_second_0:                 episode reward: 13.8500,                 loss: nan
Episode: 3321/10000 (33.2100%),                 avg. length: 3118.65,                last time consumption/overall running time: 860.2419s / 164122.6038 s
env0_first_0:                 episode reward: -17.0500,                 loss: 0.0376
env0_second_0:                 episode reward: 17.0500,                 loss: 0.0374
env1_first_0:                 episode reward: -15.0000,                 loss: nan
env1_second_0:                 episode reward: 15.0000,                 loss: nan
Episode: 3341/10000 (33.4100%),                 avg. length: 3039.15,                last time consumption/overall running time: 815.0130s / 164937.6168 s
env0_first_0:                 episode reward: -13.3500,                 loss: 0.0386
env0_second_0:                 episode reward: 13.3500,                 loss: 0.0378
env1_first_0:                 episode reward: -14.6000,                 loss: nan
env1_second_0:                 episode reward: 14.6000,                 loss: nan
Episode: 3361/10000 (33.6100%),                 avg. length: 3083.7,                last time consumption/overall running time: 835.5028s / 165773.1196 s
env0_first_0:                 episode reward: -14.6000,                 loss: 0.0383
env0_second_0:                 episode reward: 14.6000,                 loss: 0.0368
env1_first_0:                 episode reward: -15.6000,                 loss: nan
env1_second_0:                 episode reward: 15.6000,                 loss: nan
Episode: 3381/10000 (33.8100%),                 avg. length: 3127.45,                last time consumption/overall running time: 866.0642s / 166639.1838 s
env0_first_0:                 episode reward: -14.1000,                 loss: 0.0394
env0_second_0:                 episode reward: 14.1000,                 loss: 0.0355
env1_first_0:                 episode reward: -13.2500,                 loss: nan
env1_second_0:                 episode reward: 13.2500,                 loss: nan
Episode: 3401/10000 (34.0100%),                 avg. length: 3139.7,                last time consumption/overall running time: 889.3681s / 167528.5519 s
env0_first_0:                 episode reward: -16.3000,                 loss: 0.0361
env0_second_0:                 episode reward: 16.3000,                 loss: 0.0359
env1_first_0:                 episode reward: -16.1500,                 loss: nan
env1_second_0:                 episode reward: 16.1500,                 loss: nan
Episode: 3421/10000 (34.2100%),                 avg. length: 3115.05,                last time consumption/overall running time: 838.8787s / 168367.4307 s
env0_first_0:                 episode reward: -13.2500,                 loss: 0.0365
env0_second_0:                 episode reward: 13.2500,                 loss: 0.0361
env1_first_0:                 episode reward: -14.7500,                 loss: nan
env1_second_0:                 episode reward: 14.7500,                 loss: nan
Episode: 3441/10000 (34.4100%),                 avg. length: 3164.1,                last time consumption/overall running time: 906.8647s / 169274.2953 s
env0_first_0:                 episode reward: -15.5000,                 loss: 0.0366
env0_second_0:                 episode reward: 15.5000,                 loss: 0.0355
env1_first_0:                 episode reward: -14.6500,                 loss: nan
env1_second_0:                 episode reward: 14.6500,                 loss: nan
Episode: 3461/10000 (34.6100%),                 avg. length: 3316.75,                last time consumption/overall running time: 923.4772s / 170197.7725 s
env0_first_0:                 episode reward: -16.7000,                 loss: 0.0365
env0_second_0:                 episode reward: 16.7000,                 loss: 0.0363
env1_first_0:                 episode reward: -17.1000,                 loss: nan
env1_second_0:                 episode reward: 17.1000,                 loss: nan
Episode: 3481/10000 (34.8100%),                 avg. length: 3222.5,                last time consumption/overall running time: 890.7181s / 171088.4906 s
env0_first_0:                 episode reward: -15.3500,                 loss: 0.0364
env0_second_0:                 episode reward: 15.3500,                 loss: 0.0381
env1_first_0:                 episode reward: -16.7500,                 loss: nan
env1_second_0:                 episode reward: 16.7500,                 loss: nan
Episode: 3501/10000 (35.0100%),                 avg. length: 3268.7,                last time consumption/overall running time: 883.6356s / 171972.1262 s
env0_first_0:                 episode reward: -17.2500,                 loss: 0.0401
env0_second_0:                 episode reward: 17.2500,                 loss: 0.0405
env1_first_0:                 episode reward: -14.4500,                 loss: nan
env1_second_0:                 episode reward: 14.4500,                 loss: nan
Episode: 3521/10000 (35.2100%),                 avg. length: 3358.55,                last time consumption/overall running time: 892.2780s / 172864.4042 s
env0_first_0:                 episode reward: -18.3500,                 loss: 0.0395
env0_second_0:                 episode reward: 18.3500,                 loss: 0.0382
env1_first_0:                 episode reward: -16.7500,                 loss: nan
env1_second_0:                 episode reward: 16.7500,                 loss: nan
Episode: 3541/10000 (35.4100%),                 avg. length: 3117.2,                last time consumption/overall running time: 836.9947s / 173701.3989 s
env0_first_0:                 episode reward: -14.3000,                 loss: 0.0380
env0_second_0:                 episode reward: 14.3000,                 loss: 0.0376
env1_first_0:                 episode reward: -15.4500,                 loss: nan
env1_second_0:                 episode reward: 15.4500,                 loss: nan
Episode: 3561/10000 (35.6100%),                 avg. length: 3308.05,                last time consumption/overall running time: 912.5923s / 174613.9912 s
env0_first_0:                 episode reward: -16.2500,                 loss: 0.0381
env0_second_0:                 episode reward: 16.2500,                 loss: 0.0379
env1_first_0:                 episode reward: -16.1000,                 loss: nan
env1_second_0:                 episode reward: 16.1000,                 loss: nan
Episode: 3581/10000 (35.8100%),                 avg. length: 3402.0,                last time consumption/overall running time: 924.3113s / 175538.3024 s
env0_first_0:                 episode reward: -16.5000,                 loss: 0.0384
env0_second_0:                 episode reward: 16.5000,                 loss: 0.0363
env1_first_0:                 episode reward: -18.6000,                 loss: nan
env1_second_0:                 episode reward: 18.6000,                 loss: nan
Episode: 3601/10000 (36.0100%),                 avg. length: 3051.05,                last time consumption/overall running time: 835.6534s / 176373.9558 s
env0_first_0:                 episode reward: -14.5500,                 loss: 0.0394
env0_second_0:                 episode reward: 14.5500,                 loss: 0.0376
env1_first_0:                 episode reward: -15.6000,                 loss: nan
env1_second_0:                 episode reward: 15.6000,                 loss: nan
Episode: 3621/10000 (36.2100%),                 avg. length: 3173.25,                last time consumption/overall running time: 867.1248s / 177241.0806 s
env0_first_0:                 episode reward: -14.4000,                 loss: 0.0371
env0_second_0:                 episode reward: 14.4000,                 loss: 0.0367
env1_first_0:                 episode reward: -14.0500,                 loss: nan
env1_second_0:                 episode reward: 14.0500,                 loss: nan
Episode: 3641/10000 (36.4100%),                 avg. length: 3181.8,                last time consumption/overall running time: 859.1513s / 178100.2320 s
env0_first_0:                 episode reward: -14.9000,                 loss: 0.0391
env0_second_0:                 episode reward: 14.9000,                 loss: 0.0356
env1_first_0:                 episode reward: -13.4000,                 loss: nan
env1_second_0:                 episode reward: 13.4000,                 loss: nan
Episode: 3661/10000 (36.6100%),                 avg. length: 3164.85,                last time consumption/overall running time: 855.9277s / 178956.1597 s
env0_first_0:                 episode reward: -16.4500,                 loss: 0.0374
env0_second_0:                 episode reward: 16.4500,                 loss: 0.0380
env1_first_0:                 episode reward: -13.2000,                 loss: nan
env1_second_0:                 episode reward: 13.2000,                 loss: nan
Episode: 3681/10000 (36.8100%),                 avg. length: 3315.95,                last time consumption/overall running time: 888.8599s / 179845.0196 s
env0_first_0:                 episode reward: -15.7000,                 loss: 0.0380
env0_second_0:                 episode reward: 15.7000,                 loss: 0.0392
env1_first_0:                 episode reward: -16.6000,                 loss: nan
env1_second_0:                 episode reward: 16.6000,                 loss: nan
Episode: 3701/10000 (37.0100%),                 avg. length: 3144.3,                last time consumption/overall running time: 845.4393s / 180690.4589 s
env0_first_0:                 episode reward: -13.2500,                 loss: 0.0356
env0_second_0:                 episode reward: 13.2500,                 loss: 0.0377
env1_first_0:                 episode reward: -13.0500,                 loss: nan
env1_second_0:                 episode reward: 13.0500,                 loss: nan
Episode: 3721/10000 (37.2100%),                 avg. length: 3143.85,                last time consumption/overall running time: 840.0475s / 181530.5063 s
env0_first_0:                 episode reward: -16.3000,                 loss: 0.0376
env0_second_0:                 episode reward: 16.3000,                 loss: 0.0359
env1_first_0:                 episode reward: -12.9500,                 loss: nan
env1_second_0:                 episode reward: 12.9500,                 loss: nan
Episode: 3741/10000 (37.4100%),                 avg. length: 2922.95,                last time consumption/overall running time: 782.6741s / 182313.1804 s
env0_first_0:                 episode reward: -13.6500,                 loss: 0.0382
env0_second_0:                 episode reward: 13.6500,                 loss: 0.0371
env1_first_0:                 episode reward: -13.3500,                 loss: nan
env1_second_0:                 episode reward: 13.3500,                 loss: nan
Episode: 3761/10000 (37.6100%),                 avg. length: 3167.0,                last time consumption/overall running time: 864.4438s / 183177.6243 s
env0_first_0:                 episode reward: -15.9500,                 loss: 0.0380
env0_second_0:                 episode reward: 15.9500,                 loss: 0.0381
env1_first_0:                 episode reward: -13.5500,                 loss: nan
env1_second_0:                 episode reward: 13.5500,                 loss: nan
Episode: 3781/10000 (37.8100%),                 avg. length: 3134.3,                last time consumption/overall running time: 850.7122s / 184028.3365 s
env0_first_0:                 episode reward: -14.6000,                 loss: 0.0380
env0_second_0:                 episode reward: 14.6000,                 loss: 0.0381
env1_first_0:                 episode reward: -14.6000,                 loss: nan
env1_second_0:                 episode reward: 14.6000,                 loss: nan
Episode: 3801/10000 (38.0100%),                 avg. length: 2885.6,                last time consumption/overall running time: 797.9384s / 184826.2749 s
env0_first_0:                 episode reward: -13.5500,                 loss: 0.0375
env0_second_0:                 episode reward: 13.5500,                 loss: 0.0371
env1_first_0:                 episode reward: -11.2000,                 loss: nan
env1_second_0:                 episode reward: 11.2000,                 loss: nan
Episode: 3821/10000 (38.2100%),                 avg. length: 3095.95,                last time consumption/overall running time: 834.7426s / 185661.0175 s
env0_first_0:                 episode reward: -14.2000,                 loss: 0.0387
env0_second_0:                 episode reward: 14.2000,                 loss: 0.0358
env1_first_0:                 episode reward: -14.7000,                 loss: nan
env1_second_0:                 episode reward: 14.7000,                 loss: nan
Episode: 3841/10000 (38.4100%),                 avg. length: 3099.9,                last time consumption/overall running time: 834.1150s / 186495.1325 s
env0_first_0:                 episode reward: -12.1000,                 loss: 0.0390
env0_second_0:                 episode reward: 12.1000,                 loss: 0.0380
env1_first_0:                 episode reward: -12.4000,                 loss: nan
env1_second_0:                 episode reward: 12.4000,                 loss: nan
Episode: 3861/10000 (38.6100%),                 avg. length: 3116.1,                last time consumption/overall running time: 874.5548s / 187369.6873 s
env0_first_0:                 episode reward: -13.7000,                 loss: 0.0402
env0_second_0:                 episode reward: 13.7000,                 loss: 0.0401
env1_first_0:                 episode reward: -12.3500,                 loss: nan
env1_second_0:                 episode reward: 12.3500,                 loss: nan
Episode: 3881/10000 (38.8100%),                 avg. length: 3200.35,                last time consumption/overall running time: 882.5379s / 188252.2252 s
env0_first_0:                 episode reward: -12.9500,                 loss: 0.0389
env0_second_0:                 episode reward: 12.9500,                 loss: 0.0381
env1_first_0:                 episode reward: -13.7500,                 loss: nan
env1_second_0:                 episode reward: 13.7500,                 loss: nan
Episode: 3901/10000 (39.0100%),                 avg. length: 3363.35,                last time consumption/overall running time: 906.7678s / 189158.9930 s
env0_first_0:                 episode reward: -17.1500,                 loss: 0.0357
env0_second_0:                 episode reward: 17.1500,                 loss: 0.0344
env1_first_0:                 episode reward: -16.1500,                 loss: nan
env1_second_0:                 episode reward: 16.1500,                 loss: nan
Episode: 3921/10000 (39.2100%),                 avg. length: 3054.1,                last time consumption/overall running time: 839.5527s / 189998.5457 s
env0_first_0:                 episode reward: -11.4500,                 loss: 0.0375
env0_second_0:                 episode reward: 11.4500,                 loss: 0.0372
env1_first_0:                 episode reward: -10.9000,                 loss: nan
env1_second_0:                 episode reward: 10.9000,                 loss: nan
Episode: 3941/10000 (39.4100%),                 avg. length: 3105.75,                last time consumption/overall running time: 840.2617s / 190838.8074 s
env0_first_0:                 episode reward: -12.8000,                 loss: 0.0378
env0_second_0:                 episode reward: 12.8000,                 loss: 0.0376
env1_first_0:                 episode reward: -14.7500,                 loss: nan
env1_second_0:                 episode reward: 14.7500,                 loss: nan
Episode: 3961/10000 (39.6100%),                 avg. length: 3258.2,                last time consumption/overall running time: 892.5013s / 191731.3087 s
env0_first_0:                 episode reward: -15.1500,                 loss: 0.0376
env0_second_0:                 episode reward: 15.1500,                 loss: 0.0370
env1_first_0:                 episode reward: -13.2500,                 loss: nan
env1_second_0:                 episode reward: 13.2500,                 loss: nan
Episode: 3981/10000 (39.8100%),                 avg. length: 2986.2,                last time consumption/overall running time: 795.4790s / 192526.7877 s
env0_first_0:                 episode reward: -12.8000,                 loss: 0.0377
env0_second_0:                 episode reward: 12.8000,                 loss: 0.0392
env1_first_0:                 episode reward: -10.6500,                 loss: nan
env1_second_0:                 episode reward: 10.6500,                 loss: nan
Episode: 4001/10000 (40.0100%),                 avg. length: 3150.5,                last time consumption/overall running time: 863.6712s / 193390.4589 s
env0_first_0:                 episode reward: -12.4500,                 loss: 0.0362
env0_second_0:                 episode reward: 12.4500,                 loss: 0.0392
env1_first_0:                 episode reward: -14.4000,                 loss: nan
env1_second_0:                 episode reward: 14.4000,                 loss: nan
Episode: 4021/10000 (40.2100%),                 avg. length: 3102.75,                last time consumption/overall running time: 847.2100s / 194237.6688 s
env0_first_0:                 episode reward: -14.1000,                 loss: 0.0371
env0_second_0:                 episode reward: 14.1000,                 loss: 0.0370
env1_first_0:                 episode reward: -13.1500,                 loss: nan
env1_second_0:                 episode reward: 13.1500,                 loss: nan
Episode: 4041/10000 (40.4100%),                 avg. length: 2937.2,                last time consumption/overall running time: 818.5130s / 195056.1818 s
env0_first_0:                 episode reward: -10.7000,                 loss: 0.0394
env0_second_0:                 episode reward: 10.7000,                 loss: 0.0394
env1_first_0:                 episode reward: -10.3500,                 loss: nan
env1_second_0:                 episode reward: 10.3500,                 loss: nan
Episode: 4061/10000 (40.6100%),                 avg. length: 3216.65,                last time consumption/overall running time: 878.1145s / 195934.2963 s
env0_first_0:                 episode reward: -17.2000,                 loss: 0.0388
env0_second_0:                 episode reward: 17.2000,                 loss: 0.0418
env1_first_0:                 episode reward: -14.5500,                 loss: nan
env1_second_0:                 episode reward: 14.5500,                 loss: nan
Episode: 4081/10000 (40.8100%),                 avg. length: 3107.9,                last time consumption/overall running time: 844.1982s / 196778.4945 s
env0_first_0:                 episode reward: -13.7000,                 loss: 0.0377
env0_second_0:                 episode reward: 13.7000,                 loss: 0.0364
env1_first_0:                 episode reward: -13.6500,                 loss: nan
env1_second_0:                 episode reward: 13.6500,                 loss: nan
Episode: 4101/10000 (41.0100%),                 avg. length: 3152.95,                last time consumption/overall running time: 840.5927s / 197619.0872 s
env0_first_0:                 episode reward: -15.3500,                 loss: 0.0358
env0_second_0:                 episode reward: 15.3500,                 loss: 0.0350
env1_first_0:                 episode reward: -11.3500,                 loss: nan
env1_second_0:                 episode reward: 11.3500,                 loss: nan
Episode: 4121/10000 (41.2100%),                 avg. length: 3022.9,                last time consumption/overall running time: 817.5433s / 198436.6305 s
env0_first_0:                 episode reward: -14.1500,                 loss: 0.0363
env0_second_0:                 episode reward: 14.1500,                 loss: 0.0354
env1_first_0:                 episode reward: -10.3500,                 loss: nan
env1_second_0:                 episode reward: 10.3500,                 loss: nan
Episode: 4141/10000 (41.4100%),                 avg. length: 3019.35,                last time consumption/overall running time: 816.2852s / 199252.9158 s
env0_first_0:                 episode reward: -12.2000,                 loss: 0.0371
env0_second_0:                 episode reward: 12.2000,                 loss: 0.0376
env1_first_0:                 episode reward: -11.5500,                 loss: nan
env1_second_0:                 episode reward: 11.5500,                 loss: nan
Episode: 4161/10000 (41.6100%),                 avg. length: 3091.4,                last time consumption/overall running time: 833.3671s / 200086.2828 s
env0_first_0:                 episode reward: -15.1000,                 loss: 0.0382
env0_second_0:                 episode reward: 15.1000,                 loss: 0.0383
env1_first_0:                 episode reward: -12.9000,                 loss: nan
env1_second_0:                 episode reward: 12.9000,                 loss: nan
Episode: 4181/10000 (41.8100%),                 avg. length: 3040.5,                last time consumption/overall running time: 813.1021s / 200899.3849 s
env0_first_0:                 episode reward: -13.3000,                 loss: 0.0387
env0_second_0:                 episode reward: 13.3000,                 loss: 0.0375
env1_first_0:                 episode reward: -11.8500,                 loss: nan
env1_second_0:                 episode reward: 11.8500,                 loss: nan
Episode: 4201/10000 (42.0100%),                 avg. length: 3047.75,                last time consumption/overall running time: 815.5423s / 201714.9272 s
env0_first_0:                 episode reward: -13.5500,                 loss: 0.0370
env0_second_0:                 episode reward: 13.5500,                 loss: 0.0376
env1_first_0:                 episode reward: -10.6000,                 loss: nan
env1_second_0:                 episode reward: 10.6000,                 loss: nan
Episode: 4221/10000 (42.2100%),                 avg. length: 3046.95,                last time consumption/overall running time: 822.5018s / 202537.4290 s
env0_first_0:                 episode reward: -13.6500,                 loss: 0.0367
env0_second_0:                 episode reward: 13.6500,                 loss: 0.0368
env1_first_0:                 episode reward: -10.4000,                 loss: nan
env1_second_0:                 episode reward: 10.4000,                 loss: nan
Episode: 4241/10000 (42.4100%),                 avg. length: 3049.05,                last time consumption/overall running time: 800.0632s / 203337.4922 s
env0_first_0:                 episode reward: -14.0000,                 loss: 0.0381
env0_second_0:                 episode reward: 14.0000,                 loss: 0.0383
env1_first_0:                 episode reward: -13.6000,                 loss: nan
env1_second_0:                 episode reward: 13.6000,                 loss: nan
Episode: 4261/10000 (42.6100%),                 avg. length: 2872.85,                last time consumption/overall running time: 758.2932s / 204095.7854 s
env0_first_0:                 episode reward: -11.5000,                 loss: 0.0384
env0_second_0:                 episode reward: 11.5000,                 loss: 0.0378
env1_first_0:                 episode reward: -12.7000,                 loss: nan
env1_second_0:                 episode reward: 12.7000,                 loss: nan
Episode: 4281/10000 (42.8100%),                 avg. length: 2995.7,                last time consumption/overall running time: 795.6626s / 204891.4480 s
env0_first_0:                 episode reward: -13.8500,                 loss: 0.0365
env0_second_0:                 episode reward: 13.8500,                 loss: 0.0361
env1_first_0:                 episode reward: -14.4000,                 loss: nan
env1_second_0:                 episode reward: 14.4000,                 loss: nan
Episode: 4301/10000 (43.0100%),                 avg. length: 2986.35,                last time consumption/overall running time: 792.4323s / 205683.8803 s
env0_first_0:                 episode reward: -17.2500,                 loss: 0.0379
env0_second_0:                 episode reward: 17.2500,                 loss: 0.0381
env1_first_0:                 episode reward: -10.8500,                 loss: nan
env1_second_0:                 episode reward: 10.8500,                 loss: nan
Episode: 4321/10000 (43.2100%),                 avg. length: 3194.6,                last time consumption/overall running time: 850.7647s / 206534.6450 s
env0_first_0:                 episode reward: -10.9000,                 loss: 0.0401
env0_second_0:                 episode reward: 10.9000,                 loss: 0.0402
env1_first_0:                 episode reward: -16.6500,                 loss: nan
env1_second_0:                 episode reward: 16.6500,                 loss: nan
Episode: 4341/10000 (43.4100%),                 avg. length: 3140.05,                last time consumption/overall running time: 834.4779s / 207369.1229 s
env0_first_0:                 episode reward: -13.1000,                 loss: 0.0390
env0_second_0:                 episode reward: 13.1000,                 loss: 0.0389
env1_first_0:                 episode reward: -14.3000,                 loss: nan
env1_second_0:                 episode reward: 14.3000,                 loss: nan
Episode: 4361/10000 (43.6100%),                 avg. length: 3090.7,                last time consumption/overall running time: 811.8964s / 208181.0193 s
env0_first_0:                 episode reward: -16.0500,                 loss: 0.0364
env0_second_0:                 episode reward: 16.0500,                 loss: 0.0369
env1_first_0:                 episode reward: -13.0500,                 loss: nan
env1_second_0:                 episode reward: 13.0500,                 loss: nan
Episode: 4381/10000 (43.8100%),                 avg. length: 2915.95,                last time consumption/overall running time: 759.9069s / 208940.9262 s
env0_first_0:                 episode reward: -11.7500,                 loss: 0.0351
env0_second_0:                 episode reward: 11.7500,                 loss: 0.0375
env1_first_0:                 episode reward: -11.8500,                 loss: nan
env1_second_0:                 episode reward: 11.8500,                 loss: nan
Episode: 4401/10000 (44.0100%),                 avg. length: 2992.05,                last time consumption/overall running time: 797.6981s / 209738.6242 s
env0_first_0:                 episode reward: -15.5500,                 loss: 0.0385
env0_second_0:                 episode reward: 15.5500,                 loss: 0.0390
env1_first_0:                 episode reward: -14.8000,                 loss: nan
env1_second_0:                 episode reward: 14.8000,                 loss: nan
Episode: 4421/10000 (44.2100%),                 avg. length: 3128.0,                last time consumption/overall running time: 843.5235s / 210582.1477 s
env0_first_0:                 episode reward: -13.3000,                 loss: 0.0381
env0_second_0:                 episode reward: 13.3000,                 loss: 0.0374
env1_first_0:                 episode reward: -13.2500,                 loss: nan
env1_second_0:                 episode reward: 13.2500,                 loss: nan
Episode: 4441/10000 (44.4100%),                 avg. length: 3129.7,                last time consumption/overall running time: 812.5168s / 211394.6646 s
env0_first_0:                 episode reward: -10.7500,                 loss: 0.0363
env0_second_0:                 episode reward: 10.7500,                 loss: 0.0351
env1_first_0:                 episode reward: -13.2500,                 loss: nan
env1_second_0:                 episode reward: 13.2500,                 loss: nan
Episode: 4461/10000 (44.6100%),                 avg. length: 3216.2,                last time consumption/overall running time: 841.4415s / 212236.1061 s
env0_first_0:                 episode reward: -16.1500,                 loss: 0.0365
env0_second_0:                 episode reward: 16.1500,                 loss: 0.0369
env1_first_0:                 episode reward: -14.4000,                 loss: nan
env1_second_0:                 episode reward: 14.4000,                 loss: nan
Episode: 4481/10000 (44.8100%),                 avg. length: 2987.6,                last time consumption/overall running time: 790.2322s / 213026.3383 s
env0_first_0:                 episode reward: -14.0000,                 loss: 0.0380
env0_second_0:                 episode reward: 14.0000,                 loss: 0.0377
env1_first_0:                 episode reward: -13.5500,                 loss: nan
env1_second_0:                 episode reward: 13.5500,                 loss: nan
Episode: 4501/10000 (45.0100%),                 avg. length: 3056.85,                last time consumption/overall running time: 798.0079s / 213824.3461 s
env0_first_0:                 episode reward: -13.0500,                 loss: 0.0372
env0_second_0:                 episode reward: 13.0500,                 loss: 0.0385
env1_first_0:                 episode reward: -13.2500,                 loss: nan
env1_second_0:                 episode reward: 13.2500,                 loss: nan
Episode: 4521/10000 (45.2100%),                 avg. length: 2968.0,                last time consumption/overall running time: 793.3804s / 214617.7265 s
env0_first_0:                 episode reward: -13.2500,                 loss: 0.0375
env0_second_0:                 episode reward: 13.2500,                 loss: 0.0356
env1_first_0:                 episode reward: -11.7000,                 loss: nan
env1_second_0:                 episode reward: 11.7000,                 loss: nan
Episode: 4541/10000 (45.4100%),                 avg. length: 3071.9,                last time consumption/overall running time: 811.8406s / 215429.5671 s
env0_first_0:                 episode reward: -12.3000,                 loss: 0.0379
env0_second_0:                 episode reward: 12.3000,                 loss: 0.0351
env1_first_0:                 episode reward: -12.5000,                 loss: nan
env1_second_0:                 episode reward: 12.5000,                 loss: nan
Episode: 4561/10000 (45.6100%),                 avg. length: 3023.2,                last time consumption/overall running time: 800.3896s / 216229.9567 s
env0_first_0:                 episode reward: -11.2500,                 loss: 0.0394
env0_second_0:                 episode reward: 11.2500,                 loss: 0.0389
env1_first_0:                 episode reward: -14.1000,                 loss: nan
env1_second_0:                 episode reward: 14.1000,                 loss: nan
Episode: 4581/10000 (45.8100%),                 avg. length: 3182.2,                last time consumption/overall running time: 843.6485s / 217073.6052 s
env0_first_0:                 episode reward: -13.5000,                 loss: 0.0375
env0_second_0:                 episode reward: 13.5000,                 loss: 0.0373
env1_first_0:                 episode reward: -13.8000,                 loss: nan
env1_second_0:                 episode reward: 13.8000,                 loss: nan
Episode: 4601/10000 (46.0100%),                 avg. length: 3153.45,                last time consumption/overall running time: 830.9026s / 217904.5078 s
env0_first_0:                 episode reward: -14.0000,                 loss: 0.0372
env0_second_0:                 episode reward: 14.0000,                 loss: 0.0365
env1_first_0:                 episode reward: -11.9500,                 loss: nan
env1_second_0:                 episode reward: 11.9500,                 loss: nan
Episode: 4621/10000 (46.2100%),                 avg. length: 3161.35,                last time consumption/overall running time: 837.5717s / 218742.0795 s
env0_first_0:                 episode reward: -13.2500,                 loss: 0.0365
env0_second_0:                 episode reward: 13.2500,                 loss: 0.0361
env1_first_0:                 episode reward: -13.1500,                 loss: nan
env1_second_0:                 episode reward: 13.1500,                 loss: nan
Episode: 4641/10000 (46.4100%),                 avg. length: 3135.05,                last time consumption/overall running time: 830.0764s / 219572.1559 s
env0_first_0:                 episode reward: -14.3000,                 loss: 0.0374
env0_second_0:                 episode reward: 14.3000,                 loss: 0.0352
env1_first_0:                 episode reward: -14.1000,                 loss: nan
env1_second_0:                 episode reward: 14.1000,                 loss: nan
Episode: 4661/10000 (46.6100%),                 avg. length: 3166.2,                last time consumption/overall running time: 832.1414s / 220404.2972 s
env0_first_0:                 episode reward: -14.7000,                 loss: 0.0380
env0_second_0:                 episode reward: 14.7000,                 loss: 0.0372
env1_first_0:                 episode reward: -13.6000,                 loss: nan
env1_second_0:                 episode reward: 13.6000,                 loss: nan
Episode: 4681/10000 (46.8100%),                 avg. length: 3099.0,                last time consumption/overall running time: 833.8167s / 221238.1139 s
env0_first_0:                 episode reward: -15.2500,                 loss: 0.0378
env0_second_0:                 episode reward: 15.2500,                 loss: 0.0388
env1_first_0:                 episode reward: -13.9500,                 loss: nan
env1_second_0:                 episode reward: 13.9500,                 loss: nan
Episode: 4701/10000 (47.0100%),                 avg. length: 3137.95,                last time consumption/overall running time: 833.1710s / 222071.2849 s
env0_first_0:                 episode reward: -13.4500,                 loss: 0.0357
env0_second_0:                 episode reward: 13.4500,                 loss: 0.0341
env1_first_0:                 episode reward: -14.2500,                 loss: nan
env1_second_0:                 episode reward: 14.2500,                 loss: nan
Episode: 4721/10000 (47.2100%),                 avg. length: 3108.6,                last time consumption/overall running time: 828.2873s / 222899.5722 s
env0_first_0:                 episode reward: -12.9000,                 loss: 0.0359
env0_second_0:                 episode reward: 12.9000,                 loss: 0.0348
env1_first_0:                 episode reward: -12.6000,                 loss: nan
env1_second_0:                 episode reward: 12.6000,                 loss: nan
Episode: 4741/10000 (47.4100%),                 avg. length: 3163.8,                last time consumption/overall running time: 830.5894s / 223730.1616 s
env0_first_0:                 episode reward: -15.9500,                 loss: 0.0353
env0_second_0:                 episode reward: 15.9500,                 loss: 0.0356
env1_first_0:                 episode reward: -13.2500,                 loss: nan
env1_second_0:                 episode reward: 13.2500,                 loss: nan
Episode: 4761/10000 (47.6100%),                 avg. length: 3074.75,                last time consumption/overall running time: 815.5042s / 224545.6659 s
env0_first_0:                 episode reward: -11.5000,                 loss: 0.0345
env0_second_0:                 episode reward: 11.5000,                 loss: 0.0350
env1_first_0:                 episode reward: -13.7000,                 loss: nan
env1_second_0:                 episode reward: 13.7000,                 loss: nan
Episode: 4781/10000 (47.8100%),                 avg. length: 3036.85,                last time consumption/overall running time: 811.1229s / 225356.7888 s
env0_first_0:                 episode reward: -11.1000,                 loss: 0.0368
env0_second_0:                 episode reward: 11.1000,                 loss: 0.0359
env1_first_0:                 episode reward: -12.2500,                 loss: nan
env1_second_0:                 episode reward: 12.2500,                 loss: nan
Episode: 4801/10000 (48.0100%),                 avg. length: 3158.15,                last time consumption/overall running time: 829.4762s / 226186.2650 s
env0_first_0:                 episode reward: -14.1000,                 loss: 0.0357
env0_second_0:                 episode reward: 14.1000,                 loss: 0.0385
env1_first_0:                 episode reward: -15.2500,                 loss: nan
env1_second_0:                 episode reward: 15.2500,                 loss: nan
Episode: 4821/10000 (48.2100%),                 avg. length: 2972.9,                last time consumption/overall running time: 792.2815s / 226978.5465 s
env0_first_0:                 episode reward: -13.1500,                 loss: 0.0376
env0_second_0:                 episode reward: 13.1500,                 loss: 0.0371
env1_first_0:                 episode reward: -10.4500,                 loss: nan
env1_second_0:                 episode reward: 10.4500,                 loss: nan
Episode: 4841/10000 (48.4100%),                 avg. length: 3033.95,                last time consumption/overall running time: 805.3223s / 227783.8688 s
env0_first_0:                 episode reward: -12.8500,                 loss: 0.0371
env0_second_0:                 episode reward: 12.8500,                 loss: 0.0361
env1_first_0:                 episode reward: -14.1500,                 loss: nan
env1_second_0:                 episode reward: 14.1500,                 loss: nan
Episode: 4861/10000 (48.6100%),                 avg. length: 3078.9,                last time consumption/overall running time: 805.6661s / 228589.5349 s
env0_first_0:                 episode reward: -13.0000,                 loss: 0.0368
env0_second_0:                 episode reward: 13.0000,                 loss: 0.0355
env1_first_0:                 episode reward: -12.1000,                 loss: nan
env1_second_0:                 episode reward: 12.1000,                 loss: nan
Episode: 4881/10000 (48.8100%),                 avg. length: 3080.55,                last time consumption/overall running time: 812.0708s / 229401.6057 s
env0_first_0:                 episode reward: -13.1500,                 loss: 0.0362
env0_second_0:                 episode reward: 13.1500,                 loss: 0.0371
env1_first_0:                 episode reward: -12.0500,                 loss: nan
env1_second_0:                 episode reward: 12.0500,                 loss: nan
Episode: 4901/10000 (49.0100%),                 avg. length: 3231.55,                last time consumption/overall running time: 869.9323s / 230271.5381 s
env0_first_0:                 episode reward: -14.5500,                 loss: 0.0367
env0_second_0:                 episode reward: 14.5500,                 loss: 0.0360
env1_first_0:                 episode reward: -12.0000,                 loss: nan
env1_second_0:                 episode reward: 12.0000,                 loss: nan
Episode: 4921/10000 (49.2100%),                 avg. length: 3190.3,                last time consumption/overall running time: 835.0624s / 231106.6004 s
env0_first_0:                 episode reward: -13.0000,                 loss: 0.0357
env0_second_0:                 episode reward: 13.0000,                 loss: 0.0374
env1_first_0:                 episode reward: -14.3000,                 loss: nan
env1_second_0:                 episode reward: 14.3000,                 loss: nan
Episode: 4941/10000 (49.4100%),                 avg. length: 2935.75,                last time consumption/overall running time: 776.9100s / 231883.5105 s
env0_first_0:                 episode reward: -14.2000,                 loss: 0.0353
env0_second_0:                 episode reward: 14.2000,                 loss: 0.0352
env1_first_0:                 episode reward: -13.1500,                 loss: nan
env1_second_0:                 episode reward: 13.1500,                 loss: nan
Episode: 4961/10000 (49.6100%),                 avg. length: 2962.85,                last time consumption/overall running time: 774.6740s / 232658.1845 s
env0_first_0:                 episode reward: -12.2000,                 loss: 0.0366
env0_second_0:                 episode reward: 12.2000,                 loss: 0.0377
env1_first_0:                 episode reward: -10.8000,                 loss: nan
env1_second_0:                 episode reward: 10.8000,                 loss: nan
Episode: 4981/10000 (49.8100%),                 avg. length: 3071.0,                last time consumption/overall running time: 799.1580s / 233457.3426 s
env0_first_0:                 episode reward: -13.6500,                 loss: 0.0363
env0_second_0:                 episode reward: 13.6500,                 loss: 0.0359
env1_first_0:                 episode reward: -13.8000,                 loss: nan
env1_second_0:                 episode reward: 13.8000,                 loss: nan
Episode: 5001/10000 (50.0100%),                 avg. length: 2994.5,                last time consumption/overall running time: 791.4731s / 234248.8156 s
env0_first_0:                 episode reward: -12.9500,                 loss: 0.0366
env0_second_0:                 episode reward: 12.9500,                 loss: 0.0360
env1_first_0:                 episode reward: -11.5000,                 loss: nan
env1_second_0:                 episode reward: 11.5000,                 loss: nan
Episode: 5021/10000 (50.2100%),                 avg. length: 3195.2,                last time consumption/overall running time: 851.5467s / 235100.3624 s
env0_first_0:                 episode reward: -16.0500,                 loss: 0.0390
env0_second_0:                 episode reward: 16.0500,                 loss: 0.0390
env1_first_0:                 episode reward: -14.5000,                 loss: nan
env1_second_0:                 episode reward: 14.5000,                 loss: nan
Episode: 5041/10000 (50.4100%),                 avg. length: 3319.2,                last time consumption/overall running time: 867.3111s / 235967.6735 s
env0_first_0:                 episode reward: -17.5500,                 loss: 0.0366
env0_second_0:                 episode reward: 17.5500,                 loss: 0.0359
env1_first_0:                 episode reward: -12.2500,                 loss: nan
env1_second_0:                 episode reward: 12.2500,                 loss: nan
Episode: 5061/10000 (50.6100%),                 avg. length: 2909.0,                last time consumption/overall running time: 774.1402s / 236741.8137 s
env0_first_0:                 episode reward: -14.0500,                 loss: 0.0345
env0_second_0:                 episode reward: 14.0500,                 loss: 0.0348
env1_first_0:                 episode reward: -11.9500,                 loss: nan
env1_second_0:                 episode reward: 11.9500,                 loss: nan
Episode: 5081/10000 (50.8100%),                 avg. length: 3204.55,                last time consumption/overall running time: 841.9588s / 237583.7725 s
env0_first_0:                 episode reward: -15.1500,                 loss: 0.0356
env0_second_0:                 episode reward: 15.1500,                 loss: 0.0369
env1_first_0:                 episode reward: -13.9000,                 loss: nan
env1_second_0:                 episode reward: 13.9000,                 loss: nan
Episode: 5101/10000 (51.0100%),                 avg. length: 3209.6,                last time consumption/overall running time: 849.0258s / 238432.7983 s
env0_first_0:                 episode reward: -13.2500,                 loss: 0.0383
env0_second_0:                 episode reward: 13.2500,                 loss: 0.0367
env1_first_0:                 episode reward: -14.0000,                 loss: nan
env1_second_0:                 episode reward: 14.0000,                 loss: nan
Episode: 5121/10000 (51.2100%),                 avg. length: 3041.2,                last time consumption/overall running time: 802.3861s / 239235.1844 s
env0_first_0:                 episode reward: -11.3000,                 loss: 0.0363
env0_second_0:                 episode reward: 11.3000,                 loss: 0.0366
env1_first_0:                 episode reward: -12.2500,                 loss: nan
env1_second_0:                 episode reward: 12.2500,                 loss: nan
Episode: 5141/10000 (51.4100%),                 avg. length: 3292.4,                last time consumption/overall running time: 866.8482s / 240102.0326 s
env0_first_0:                 episode reward: -12.9500,                 loss: 0.0348
env0_second_0:                 episode reward: 12.9500,                 loss: 0.0367
env1_first_0:                 episode reward: -11.8500,                 loss: nan
env1_second_0:                 episode reward: 11.8500,                 loss: nan
Episode: 5161/10000 (51.6100%),                 avg. length: 2940.05,                last time consumption/overall running time: 773.2964s / 240875.3290 s
env0_first_0:                 episode reward: -10.8000,                 loss: 0.0358
env0_second_0:                 episode reward: 10.8000,                 loss: 0.0347
env1_first_0:                 episode reward: -14.3500,                 loss: nan
env1_second_0:                 episode reward: 14.3500,                 loss: nan
Episode: 5181/10000 (51.8100%),                 avg. length: 2932.55,                last time consumption/overall running time: 783.4268s / 241658.7557 s
env0_first_0:                 episode reward: -12.4000,                 loss: 0.0378
env0_second_0:                 episode reward: 12.4000,                 loss: 0.0362
env1_first_0:                 episode reward: -11.3000,                 loss: nan
env1_second_0:                 episode reward: 11.3000,                 loss: nan
Episode: 5201/10000 (52.0100%),                 avg. length: 3170.55,                last time consumption/overall running time: 848.8885s / 242507.6443 s
env0_first_0:                 episode reward: -13.8000,                 loss: 0.0377
env0_second_0:                 episode reward: 13.8000,                 loss: 0.0386
env1_first_0:                 episode reward: -12.5500,                 loss: nan
env1_second_0:                 episode reward: 12.5500,                 loss: nan
Episode: 5221/10000 (52.2100%),                 avg. length: 3120.05,                last time consumption/overall running time: 839.4041s / 243347.0484 s
env0_first_0:                 episode reward: -16.2000,                 loss: 0.0370
env0_second_0:                 episode reward: 16.2000,                 loss: 0.0375
env1_first_0:                 episode reward: -14.1000,                 loss: nan
env1_second_0:                 episode reward: 14.1000,                 loss: nan
Episode: 5241/10000 (52.4100%),                 avg. length: 3169.4,                last time consumption/overall running time: 845.1864s / 244192.2348 s
env0_first_0:                 episode reward: -12.8000,                 loss: 0.0386
env0_second_0:                 episode reward: 12.8000,                 loss: 0.0381
env1_first_0:                 episode reward: -13.8500,                 loss: nan
env1_second_0:                 episode reward: 13.8500,                 loss: nan
Episode: 5261/10000 (52.6100%),                 avg. length: 3230.25,                last time consumption/overall running time: 843.2322s / 245035.4670 s
env0_first_0:                 episode reward: -13.2500,                 loss: 0.0372
env0_second_0:                 episode reward: 13.2500,                 loss: 0.0361
env1_first_0:                 episode reward: -12.7000,                 loss: nan
env1_second_0:                 episode reward: 12.7000,                 loss: nan
Episode: 5281/10000 (52.8100%),                 avg. length: 3199.95,                last time consumption/overall running time: 839.8692s / 245875.3362 s
env0_first_0:                 episode reward: -15.4500,                 loss: 0.0364
env0_second_0:                 episode reward: 15.4500,                 loss: 0.0361
env1_first_0:                 episode reward: -16.1000,                 loss: nan
env1_second_0:                 episode reward: 16.1000,                 loss: nan
Episode: 5301/10000 (53.0100%),                 avg. length: 3086.45,                last time consumption/overall running time: 826.6941s / 246702.0304 s
env0_first_0:                 episode reward: -13.1500,                 loss: 0.0354
env0_second_0:                 episode reward: 13.1500,                 loss: 0.0357
env1_first_0:                 episode reward: -13.2500,                 loss: nan
env1_second_0:                 episode reward: 13.2500,                 loss: nan
Episode: 5321/10000 (53.2100%),                 avg. length: 3063.15,                last time consumption/overall running time: 828.6339s / 247530.6643 s
env0_first_0:                 episode reward: -13.3000,                 loss: 0.0378
env0_second_0:                 episode reward: 13.3000,                 loss: 0.0361
env1_first_0:                 episode reward: -14.4000,                 loss: nan
env1_second_0:                 episode reward: 14.4000,                 loss: nan
Episode: 5341/10000 (53.4100%),                 avg. length: 3069.3,                last time consumption/overall running time: 793.5304s / 248324.1947 s
env0_first_0:                 episode reward: -12.9000,                 loss: 0.0377
env0_second_0:                 episode reward: 12.9000,                 loss: 0.0339
env1_first_0:                 episode reward: -13.6000,                 loss: nan
env1_second_0:                 episode reward: 13.6000,                 loss: nan
Episode: 5361/10000 (53.6100%),                 avg. length: 2886.55,                last time consumption/overall running time: 757.0655s / 249081.2602 s
env0_first_0:                 episode reward: -11.5000,                 loss: 0.0338
env0_second_0:                 episode reward: 11.5000,                 loss: 0.0357
env1_first_0:                 episode reward: -12.0000,                 loss: nan
env1_second_0:                 episode reward: 12.0000,                 loss: nan
Episode: 5381/10000 (53.8100%),                 avg. length: 2763.2,                last time consumption/overall running time: 761.8590s / 249843.1192 s
env0_first_0:                 episode reward: -11.0000,                 loss: 0.0369
env0_second_0:                 episode reward: 11.0000,                 loss: 0.0365
env1_first_0:                 episode reward: -10.8000,                 loss: nan
env1_second_0:                 episode reward: 10.8000,                 loss: nan
Episode: 5401/10000 (54.0100%),                 avg. length: 3064.65,                last time consumption/overall running time: 815.8432s / 250658.9624 s
env0_first_0:                 episode reward: -12.3000,                 loss: 0.0378
env0_second_0:                 episode reward: 12.3000,                 loss: 0.0386
env1_first_0:                 episode reward: -11.2500,                 loss: nan
env1_second_0:                 episode reward: 11.2500,                 loss: nan
Episode: 5421/10000 (54.2100%),                 avg. length: 3155.5,                last time consumption/overall running time: 820.2254s / 251479.1878 s
env0_first_0:                 episode reward: -13.6500,                 loss: 0.0385
env0_second_0:                 episode reward: 13.6500,                 loss: 0.0385
env1_first_0:                 episode reward: -14.3000,                 loss: nan
env1_second_0:                 episode reward: 14.3000,                 loss: nan
Episode: 5441/10000 (54.4100%),                 avg. length: 3076.4,                last time consumption/overall running time: 812.1836s / 252291.3714 s
env0_first_0:                 episode reward: -15.2500,                 loss: 0.0379
env0_second_0:                 episode reward: 15.2500,                 loss: 0.0374
env1_first_0:                 episode reward: -13.8500,                 loss: nan
env1_second_0:                 episode reward: 13.8500,                 loss: nan
Episode: 5461/10000 (54.6100%),                 avg. length: 2824.2,                last time consumption/overall running time: 750.1928s / 253041.5642 s
env0_first_0:                 episode reward: -10.4500,                 loss: 0.0365
env0_second_0:                 episode reward: 10.4500,                 loss: 0.0351
env1_first_0:                 episode reward: -11.5000,                 loss: nan
env1_second_0:                 episode reward: 11.5000,                 loss: nan
Episode: 5481/10000 (54.8100%),                 avg. length: 3093.25,                last time consumption/overall running time: 810.6452s / 253852.2094 s
env0_first_0:                 episode reward: -12.7000,                 loss: 0.0367
env0_second_0:                 episode reward: 12.7000,                 loss: 0.0364
env1_first_0:                 episode reward: -12.7500,                 loss: nan
env1_second_0:                 episode reward: 12.7500,                 loss: nan
Episode: 5501/10000 (55.0100%),                 avg. length: 3418.65,                last time consumption/overall running time: 939.3295s / 254791.5389 s
env0_first_0:                 episode reward: -16.4000,                 loss: 0.0350
env0_second_0:                 episode reward: 16.4000,                 loss: 0.0351
env1_first_0:                 episode reward: -17.4500,                 loss: nan
env1_second_0:                 episode reward: 17.4500,                 loss: nan
Episode: 5521/10000 (55.2100%),                 avg. length: 2980.55,                last time consumption/overall running time: 814.3085s / 255605.8475 s
env0_first_0:                 episode reward: -15.2000,                 loss: 0.0345
env0_second_0:                 episode reward: 15.2000,                 loss: 0.0362
env1_first_0:                 episode reward: -9.8000,                 loss: nan
env1_second_0:                 episode reward: 9.8000,                 loss: nan
Episode: 5541/10000 (55.4100%),                 avg. length: 3016.85,                last time consumption/overall running time: 834.3493s / 256440.1967 s
env0_first_0:                 episode reward: -13.7000,                 loss: 0.0364
env0_second_0:                 episode reward: 13.7000,                 loss: 0.0370
env1_first_0:                 episode reward: -15.4000,                 loss: nan
env1_second_0:                 episode reward: 15.4000,                 loss: nan
Episode: 5561/10000 (55.6100%),                 avg. length: 3051.0,                last time consumption/overall running time: 802.9820s / 257243.1787 s
env0_first_0:                 episode reward: -13.2500,                 loss: 0.0385
env0_second_0:                 episode reward: 13.2500,                 loss: 0.0372
env1_first_0:                 episode reward: -15.1000,                 loss: nan
env1_second_0:                 episode reward: 15.1000,                 loss: nan
Episode: 5581/10000 (55.8100%),                 avg. length: 3096.25,                last time consumption/overall running time: 832.9382s / 258076.1170 s
env0_first_0:                 episode reward: -13.5500,                 loss: 0.0367
env0_second_0:                 episode reward: 13.5500,                 loss: 0.0372
env1_first_0:                 episode reward: -11.4000,                 loss: nan
env1_second_0:                 episode reward: 11.4000,                 loss: nan
Episode: 5601/10000 (56.0100%),                 avg. length: 3008.35,                last time consumption/overall running time: 798.7441s / 258874.8610 s
env0_first_0:                 episode reward: -11.9000,                 loss: 0.0358
env0_second_0:                 episode reward: 11.9000,                 loss: 0.0350
env1_first_0:                 episode reward: -12.3500,                 loss: nan
env1_second_0:                 episode reward: 12.3500,                 loss: nan
Episode: 5621/10000 (56.2100%),                 avg. length: 3069.15,                last time consumption/overall running time: 808.0825s / 259682.9435 s
env0_first_0:                 episode reward: -14.1000,                 loss: 0.0344
env0_second_0:                 episode reward: 14.1000,                 loss: 0.0361
env1_first_0:                 episode reward: -13.2500,                 loss: nan
env1_second_0:                 episode reward: 13.2500,                 loss: nan
Episode: 5641/10000 (56.4100%),                 avg. length: 3203.15,                last time consumption/overall running time: 841.8056s / 260524.7491 s
env0_first_0:                 episode reward: -14.3500,                 loss: 0.0378
env0_second_0:                 episode reward: 14.3500,                 loss: 0.0369
env1_first_0:                 episode reward: -13.1500,                 loss: nan
env1_second_0:                 episode reward: 13.1500,                 loss: nan
Episode: 5661/10000 (56.6100%),                 avg. length: 3227.45,                last time consumption/overall running time: 865.2765s / 261390.0256 s
env0_first_0:                 episode reward: -11.5500,                 loss: 0.0374
env0_second_0:                 episode reward: 11.5500,                 loss: 0.0363
env1_first_0:                 episode reward: -16.0000,                 loss: nan
env1_second_0:                 episode reward: 16.0000,                 loss: nan
Episode: 5681/10000 (56.8100%),                 avg. length: 3027.35,                last time consumption/overall running time: 815.6665s / 262205.6921 s
env0_first_0:                 episode reward: -11.7000,                 loss: 0.0371
env0_second_0:                 episode reward: 11.7000,                 loss: 0.0351
env1_first_0:                 episode reward: -11.7000,                 loss: nan
env1_second_0:                 episode reward: 11.7000,                 loss: nan
Episode: 5701/10000 (57.0100%),                 avg. length: 3227.35,                last time consumption/overall running time: 886.3348s / 263092.0270 s
env0_first_0:                 episode reward: -15.9000,                 loss: 0.0365
env0_second_0:                 episode reward: 15.9000,                 loss: 0.0371
env1_first_0:                 episode reward: -13.0500,                 loss: nan
env1_second_0:                 episode reward: 13.0500,                 loss: nan
Episode: 5721/10000 (57.2100%),                 avg. length: 3146.75,                last time consumption/overall running time: 857.6802s / 263949.7072 s
env0_first_0:                 episode reward: -11.0500,                 loss: 0.0360
env0_second_0:                 episode reward: 11.0500,                 loss: 0.0362
env1_first_0:                 episode reward: -14.0000,                 loss: nan
env1_second_0:                 episode reward: 14.0000,                 loss: nan
Episode: 5741/10000 (57.4100%),                 avg. length: 3276.6,                last time consumption/overall running time: 901.0213s / 264850.7285 s
env0_first_0:                 episode reward: -15.6500,                 loss: 0.0341
env0_second_0:                 episode reward: 15.6500,                 loss: 0.0359
env1_first_0:                 episode reward: -15.6500,                 loss: nan
env1_second_0:                 episode reward: 15.6500,                 loss: nan
Episode: 5761/10000 (57.6100%),                 avg. length: 2977.6,                last time consumption/overall running time: 824.9590s / 265675.6875 s
env0_first_0:                 episode reward: -11.0500,                 loss: 0.0359
env0_second_0:                 episode reward: 11.0500,                 loss: 0.0361
env1_first_0:                 episode reward: -11.0000,                 loss: nan
env1_second_0:                 episode reward: 11.0000,                 loss: nan
Episode: 5781/10000 (57.8100%),                 avg. length: 3195.25,                last time consumption/overall running time: 856.4894s / 266532.1769 s
env0_first_0:                 episode reward: -12.9500,                 loss: 0.0363
env0_second_0:                 episode reward: 12.9500,                 loss: 0.0359
env1_first_0:                 episode reward: -13.7000,                 loss: nan
env1_second_0:                 episode reward: 13.7000,                 loss: nan
Episode: 5801/10000 (58.0100%),                 avg. length: 2919.7,                last time consumption/overall running time: 761.1704s / 267293.3473 s
env0_first_0:                 episode reward: -11.1500,                 loss: 0.0362
env0_second_0:                 episode reward: 11.1500,                 loss: 0.0358
env1_first_0:                 episode reward: -13.4000,                 loss: nan
env1_second_0:                 episode reward: 13.4000,                 loss: nan
Episode: 5821/10000 (58.2100%),                 avg. length: 3056.05,                last time consumption/overall running time: 841.6250s / 268134.9723 s
env0_first_0:                 episode reward: -13.8500,                 loss: 0.0357
env0_second_0:                 episode reward: 13.8500,                 loss: 0.0361
env1_first_0:                 episode reward: -13.2000,                 loss: nan
env1_second_0:                 episode reward: 13.2000,                 loss: nan
Episode: 5841/10000 (58.4100%),                 avg. length: 3053.0,                last time consumption/overall running time: 842.8981s / 268977.8704 s
env0_first_0:                 episode reward: -14.4000,                 loss: 0.0361
env0_second_0:                 episode reward: 14.4000,                 loss: 0.0362
env1_first_0:                 episode reward: -13.8000,                 loss: nan
env1_second_0:                 episode reward: 13.8000,                 loss: nan
Episode: 5861/10000 (58.6100%),                 avg. length: 3078.25,                last time consumption/overall running time: 794.3982s / 269772.2686 s
env0_first_0:                 episode reward: -14.4500,                 loss: 0.0362
env0_second_0:                 episode reward: 14.4500,                 loss: 0.0388
env1_first_0:                 episode reward: -14.9000,                 loss: nan
env1_second_0:                 episode reward: 14.9000,                 loss: nan
Episode: 5881/10000 (58.8100%),                 avg. length: 3062.3,                last time consumption/overall running time: 835.6883s / 270607.9569 s
env0_first_0:                 episode reward: -13.7000,                 loss: 0.0362
env0_second_0:                 episode reward: 13.7000,                 loss: 0.0380
env1_first_0:                 episode reward: -13.0500,                 loss: nan
env1_second_0:                 episode reward: 13.0500,                 loss: nan
Episode: 5901/10000 (59.0100%),                 avg. length: 2991.9,                last time consumption/overall running time: 819.5854s / 271427.5423 s
env0_first_0:                 episode reward: -12.7000,                 loss: 0.0364
env0_second_0:                 episode reward: 12.7000,                 loss: 0.0374
env1_first_0:                 episode reward: -13.3000,                 loss: nan
env1_second_0:                 episode reward: 13.3000,                 loss: nan
Episode: 5921/10000 (59.2100%),                 avg. length: 3237.55,                last time consumption/overall running time: 900.2747s / 272327.8170 s
env0_first_0:                 episode reward: -15.4000,                 loss: 0.0355
env0_second_0:                 episode reward: 15.4000,                 loss: 0.0383
env1_first_0:                 episode reward: -14.9500,                 loss: nan
env1_second_0:                 episode reward: 14.9500,                 loss: nan
Episode: 5941/10000 (59.4100%),                 avg. length: 2947.5,                last time consumption/overall running time: 765.9997s / 273093.8166 s
env0_first_0:                 episode reward: -12.6000,                 loss: 0.0367
env0_second_0:                 episode reward: 12.6000,                 loss: 0.0360
env1_first_0:                 episode reward: -11.1000,                 loss: nan
env1_second_0:                 episode reward: 11.1000,                 loss: nan
Episode: 5961/10000 (59.6100%),                 avg. length: 2968.5,                last time consumption/overall running time: 763.5553s / 273857.3719 s
env0_first_0:                 episode reward: -12.2500,                 loss: 0.0379
env0_second_0:                 episode reward: 12.2500,                 loss: 0.0362
env1_first_0:                 episode reward: -11.6500,                 loss: nan
env1_second_0:                 episode reward: 11.6500,                 loss: nan
Episode: 5981/10000 (59.8100%),                 avg. length: 3057.7,                last time consumption/overall running time: 814.0037s / 274671.3756 s
env0_first_0:                 episode reward: -12.8500,                 loss: 0.0387
env0_second_0:                 episode reward: 12.8500,                 loss: 0.0387
env1_first_0:                 episode reward: -12.5000,                 loss: nan
env1_second_0:                 episode reward: 12.5000,                 loss: nan
Episode: 6001/10000 (60.0100%),                 avg. length: 3038.65,                last time consumption/overall running time: 815.5777s / 275486.9533 s
env0_first_0:                 episode reward: -13.8000,                 loss: 0.0371
env0_second_0:                 episode reward: 13.8000,                 loss: 0.0380
env1_first_0:                 episode reward: -11.3500,                 loss: nan
env1_second_0:                 episode reward: 11.3500,                 loss: nan
Episode: 6021/10000 (60.2100%),                 avg. length: 2920.7,                last time consumption/overall running time: 776.6952s / 276263.6484 s
env0_first_0:                 episode reward: -12.1500,                 loss: 0.0365
env0_second_0:                 episode reward: 12.1500,                 loss: 0.0368
env1_first_0:                 episode reward: -13.5500,                 loss: nan
env1_second_0:                 episode reward: 13.5500,                 loss: nan
Episode: 6041/10000 (60.4100%),                 avg. length: 2997.65,                last time consumption/overall running time: 767.8020s / 277031.4504 s
env0_first_0:                 episode reward: -14.7500,                 loss: 0.0382
env0_second_0:                 episode reward: 14.7500,                 loss: 0.0368
env1_first_0:                 episode reward: -11.3000,                 loss: nan
env1_second_0:                 episode reward: 11.3000,                 loss: nan
Episode: 6061/10000 (60.6100%),                 avg. length: 3116.8,                last time consumption/overall running time: 826.8256s / 277858.2760 s
env0_first_0:                 episode reward: -12.7000,                 loss: 0.0357
env0_second_0:                 episode reward: 12.7000,                 loss: 0.0360
env1_first_0:                 episode reward: -10.8000,                 loss: nan
env1_second_0:                 episode reward: 10.8000,                 loss: nan
Episode: 6081/10000 (60.8100%),                 avg. length: 2891.25,                last time consumption/overall running time: 767.3605s / 278625.6365 s
env0_first_0:                 episode reward: -11.5000,                 loss: 0.0370
env0_second_0:                 episode reward: 11.5000,                 loss: 0.0367
env1_first_0:                 episode reward: -12.2000,                 loss: nan
env1_second_0:                 episode reward: 12.2000,                 loss: nan
Episode: 6101/10000 (61.0100%),                 avg. length: 3056.3,                last time consumption/overall running time: 815.6289s / 279441.2654 s
env0_first_0:                 episode reward: -13.5000,                 loss: 0.0367
env0_second_0:                 episode reward: 13.5000,                 loss: 0.0365
env1_first_0:                 episode reward: -12.8000,                 loss: nan
env1_second_0:                 episode reward: 12.8000,                 loss: nan
Episode: 6121/10000 (61.2100%),                 avg. length: 2983.25,                last time consumption/overall running time: 760.3869s / 280201.6523 s
env0_first_0:                 episode reward: -14.0000,                 loss: 0.0370
env0_second_0:                 episode reward: 14.0000,                 loss: 0.0352
env1_first_0:                 episode reward: -11.6000,                 loss: nan
env1_second_0:                 episode reward: 11.6000,                 loss: nan
Episode: 6141/10000 (61.4100%),                 avg. length: 3105.7,                last time consumption/overall running time: 809.0697s / 281010.7220 s
env0_first_0:                 episode reward: -12.8500,                 loss: 0.0374
env0_second_0:                 episode reward: 12.8500,                 loss: 0.0376
env1_first_0:                 episode reward: -12.7000,                 loss: nan
env1_second_0:                 episode reward: 12.7000,                 loss: nan
Episode: 6161/10000 (61.6100%),                 avg. length: 3047.9,                last time consumption/overall running time: 821.9185s / 281832.6405 s
env0_first_0:                 episode reward: -9.7000,                 loss: 0.0371
env0_second_0:                 episode reward: 9.7000,                 loss: 0.0370
env1_first_0:                 episode reward: -11.4000,                 loss: nan
env1_second_0:                 episode reward: 11.4000,                 loss: nan
Episode: 6181/10000 (61.8100%),                 avg. length: 2978.2,                last time consumption/overall running time: 788.1445s / 282620.7850 s
env0_first_0:                 episode reward: -11.2000,                 loss: 0.0354
env0_second_0:                 episode reward: 11.2000,                 loss: 0.0362
env1_first_0:                 episode reward: -13.5000,                 loss: nan
env1_second_0:                 episode reward: 13.5000,                 loss: nan
Episode: 6201/10000 (62.0100%),                 avg. length: 2883.65,                last time consumption/overall running time: 774.2019s / 283394.9869 s
env0_first_0:                 episode reward: -10.4000,                 loss: 0.0352
env0_second_0:                 episode reward: 10.4000,                 loss: 0.0350
env1_first_0:                 episode reward: -11.4000,                 loss: nan
env1_second_0:                 episode reward: 11.4000,                 loss: nan
Episode: 6221/10000 (62.2100%),                 avg. length: 3328.45,                last time consumption/overall running time: 878.9169s / 284273.9038 s
env0_first_0:                 episode reward: -15.2500,                 loss: 0.0352
env0_second_0:                 episode reward: 15.2500,                 loss: 0.0361
env1_first_0:                 episode reward: -14.9500,                 loss: nan
env1_second_0:                 episode reward: 14.9500,                 loss: nan
Episode: 6241/10000 (62.4100%),                 avg. length: 3044.25,                last time consumption/overall running time: 800.2595s / 285074.1633 s
env0_first_0:                 episode reward: -14.9000,                 loss: 0.0364
env0_second_0:                 episode reward: 14.9000,                 loss: 0.0376
env1_first_0:                 episode reward: -15.9500,                 loss: nan
env1_second_0:                 episode reward: 15.9500,                 loss: nan
Episode: 6261/10000 (62.6100%),                 avg. length: 2997.75,                last time consumption/overall running time: 807.1602s / 285881.3235 s
env0_first_0:                 episode reward: -12.9000,                 loss: 0.0379
env0_second_0:                 episode reward: 12.9000,                 loss: 0.0377
env1_first_0:                 episode reward: -12.1500,                 loss: nan
env1_second_0:                 episode reward: 12.1500,                 loss: nan
Episode: 6281/10000 (62.8100%),                 avg. length: 2945.1,                last time consumption/overall running time: 772.8837s / 286654.2072 s
env0_first_0:                 episode reward: -12.1000,                 loss: 0.0386
env0_second_0:                 episode reward: 12.1000,                 loss: 0.0378
env1_first_0:                 episode reward: -11.5000,                 loss: nan
env1_second_0:                 episode reward: 11.5000,                 loss: nan
Episode: 6301/10000 (63.0100%),                 avg. length: 3081.05,                last time consumption/overall running time: 838.0359s / 287492.2431 s
env0_first_0:                 episode reward: -12.7000,                 loss: 0.0361
env0_second_0:                 episode reward: 12.7000,                 loss: 0.0359
env1_first_0:                 episode reward: -13.9500,                 loss: nan
env1_second_0:                 episode reward: 13.9500,                 loss: nan
Episode: 6321/10000 (63.2100%),                 avg. length: 3250.4,                last time consumption/overall running time: 872.0076s / 288364.2507 s
env0_first_0:                 episode reward: -13.4000,                 loss: 0.0347
env0_second_0:                 episode reward: 13.4000,                 loss: 0.0363
env1_first_0:                 episode reward: -12.5000,                 loss: nan
env1_second_0:                 episode reward: 12.5000,                 loss: nan
Episode: 6341/10000 (63.4100%),                 avg. length: 2873.15,                last time consumption/overall running time: 785.3679s / 289149.6186 s
env0_first_0:                 episode reward: -10.5000,                 loss: 0.0353
env0_second_0:                 episode reward: 10.5000,                 loss: 0.0339
env1_first_0:                 episode reward: -12.6000,                 loss: nan
env1_second_0:                 episode reward: 12.6000,                 loss: nan
Episode: 6361/10000 (63.6100%),                 avg. length: 3186.05,                last time consumption/overall running time: 867.2972s / 290016.9158 s
env0_first_0:                 episode reward: -11.8500,                 loss: 0.0359
env0_second_0:                 episode reward: 11.8500,                 loss: 0.0346
env1_first_0:                 episode reward: -14.9500,                 loss: nan
env1_second_0:                 episode reward: 14.9500,                 loss: nan
Episode: 6381/10000 (63.8100%),                 avg. length: 3093.9,                last time consumption/overall running time: 841.4455s / 290858.3613 s
env0_first_0:                 episode reward: -14.2500,                 loss: 0.0360
env0_second_0:                 episode reward: 14.2500,                 loss: 0.0343
env1_first_0:                 episode reward: -11.3000,                 loss: nan
env1_second_0:                 episode reward: 11.3000,                 loss: nan
Episode: 6401/10000 (64.0100%),                 avg. length: 3033.9,                last time consumption/overall running time: 825.0316s / 291683.3929 s
env0_first_0:                 episode reward: -14.9500,                 loss: 0.0358
env0_second_0:                 episode reward: 14.9500,                 loss: 0.0359
env1_first_0:                 episode reward: -13.4000,                 loss: nan
env1_second_0:                 episode reward: 13.4000,                 loss: nan
Episode: 6421/10000 (64.2100%),                 avg. length: 3096.7,                last time consumption/overall running time: 807.8555s / 292491.2484 s
env0_first_0:                 episode reward: -13.5000,                 loss: 0.0363
env0_second_0:                 episode reward: 13.5000,                 loss: 0.0356
env1_first_0:                 episode reward: -15.5500,                 loss: nan
env1_second_0:                 episode reward: 15.5500,                 loss: nan
Episode: 6441/10000 (64.4100%),                 avg. length: 3136.45,                last time consumption/overall running time: 852.0057s / 293343.2541 s
env0_first_0:                 episode reward: -15.7000,                 loss: 0.0384
env0_second_0:                 episode reward: 15.7000,                 loss: 0.0364
env1_first_0:                 episode reward: -14.2500,                 loss: nan
env1_second_0:                 episode reward: 14.2500,                 loss: nan
Episode: 6461/10000 (64.6100%),                 avg. length: 3147.85,                last time consumption/overall running time: 840.6892s / 294183.9433 s
env0_first_0:                 episode reward: -18.0500,                 loss: 0.0377
env0_second_0:                 episode reward: 18.0500,                 loss: 0.0378
env1_first_0:                 episode reward: -14.5500,                 loss: nan
env1_second_0:                 episode reward: 14.5500,                 loss: nan
Episode: 6481/10000 (64.8100%),                 avg. length: 3087.15,                last time consumption/overall running time: 823.2427s / 295007.1860 s
env0_first_0:                 episode reward: -15.2000,                 loss: 0.0339
env0_second_0:                 episode reward: 15.2000,                 loss: 0.0349
env1_first_0:                 episode reward: -11.3500,                 loss: nan
env1_second_0:                 episode reward: 11.3500,                 loss: nan
Episode: 6501/10000 (65.0100%),                 avg. length: 2967.65,                last time consumption/overall running time: 761.2118s / 295768.3978 s
env0_first_0:                 episode reward: -12.5000,                 loss: 0.0361
env0_second_0:                 episode reward: 12.5000,                 loss: 0.0362
env1_first_0:                 episode reward: -10.5500,                 loss: nan
env1_second_0:                 episode reward: 10.5500,                 loss: nan
Episode: 6521/10000 (65.2100%),                 avg. length: 2999.75,                last time consumption/overall running time: 790.3600s / 296558.7578 s
env0_first_0:                 episode reward: -10.9000,                 loss: 0.0368
env0_second_0:                 episode reward: 10.9000,                 loss: 0.0376
env1_first_0:                 episode reward: -11.7000,                 loss: nan
env1_second_0:                 episode reward: 11.7000,                 loss: nan
Episode: 6541/10000 (65.4100%),                 avg. length: 3029.85,                last time consumption/overall running time: 804.0518s / 297362.8096 s
env0_first_0:                 episode reward: -14.8500,                 loss: 0.0350
env0_second_0:                 episode reward: 14.8500,                 loss: 0.0357
env1_first_0:                 episode reward: -15.2000,                 loss: nan
env1_second_0:                 episode reward: 15.2000,                 loss: nan
Episode: 6561/10000 (65.6100%),                 avg. length: 3116.3,                last time consumption/overall running time: 817.8576s / 298180.6672 s
env0_first_0:                 episode reward: -11.7500,                 loss: 0.0343
env0_second_0:                 episode reward: 11.7500,                 loss: 0.0350
env1_first_0:                 episode reward: -16.1000,                 loss: nan
env1_second_0:                 episode reward: 16.1000,                 loss: nan
Episode: 6581/10000 (65.8100%),                 avg. length: 3145.6,                last time consumption/overall running time: 832.7652s / 299013.4324 s
env0_first_0:                 episode reward: -13.4000,                 loss: 0.0347
env0_second_0:                 episode reward: 13.4000,                 loss: 0.0336
env1_first_0:                 episode reward: -15.4500,                 loss: nan
env1_second_0:                 episode reward: 15.4500,                 loss: nan
Episode: 6601/10000 (66.0100%),                 avg. length: 3078.65,                last time consumption/overall running time: 819.4627s / 299832.8951 s
env0_first_0:                 episode reward: -12.7500,                 loss: 0.0357
env0_second_0:                 episode reward: 12.7500,                 loss: 0.0341
env1_first_0:                 episode reward: -12.3500,                 loss: nan
env1_second_0:                 episode reward: 12.3500,                 loss: nan
Episode: 6621/10000 (66.2100%),                 avg. length: 3170.1,                last time consumption/overall running time: 858.5196s / 300691.4147 s
env0_first_0:                 episode reward: -15.1500,                 loss: 0.0357
env0_second_0:                 episode reward: 15.1500,                 loss: 0.0355
env1_first_0:                 episode reward: -14.7500,                 loss: nan
env1_second_0:                 episode reward: 14.7500,                 loss: nan
Episode: 6641/10000 (66.4100%),                 avg. length: 3108.3,                last time consumption/overall running time: 805.1122s / 301496.5268 s
env0_first_0:                 episode reward: -12.1500,                 loss: 0.0362
env0_second_0:                 episode reward: 12.1500,                 loss: 0.0363
env1_first_0:                 episode reward: -16.1500,                 loss: nan
env1_second_0:                 episode reward: 16.1500,                 loss: nan
Episode: 6661/10000 (66.6100%),                 avg. length: 3022.0,                last time consumption/overall running time: 814.5430s / 302311.0698 s
env0_first_0:                 episode reward: -13.7000,                 loss: 0.0369
env0_second_0:                 episode reward: 13.7000,                 loss: 0.0365
env1_first_0:                 episode reward: -12.4500,                 loss: nan
env1_second_0:                 episode reward: 12.4500,                 loss: nan
Episode: 6681/10000 (66.8100%),                 avg. length: 2940.15,                last time consumption/overall running time: 789.8418s / 303100.9116 s
env0_first_0:                 episode reward: -12.5000,                 loss: 0.0378
env0_second_0:                 episode reward: 12.5000,                 loss: 0.0374
env1_first_0:                 episode reward: -11.0500,                 loss: nan
env1_second_0:                 episode reward: 11.0500,                 loss: nan
Episode: 6701/10000 (67.0100%),                 avg. length: 2966.4,                last time consumption/overall running time: 770.8026s / 303871.7142 s
env0_first_0:                 episode reward: -12.2500,                 loss: 0.0378
env0_second_0:                 episode reward: 12.2500,                 loss: 0.0360
env1_first_0:                 episode reward: -12.8000,                 loss: nan
env1_second_0:                 episode reward: 12.8000,                 loss: nan
Episode: 6721/10000 (67.2100%),                 avg. length: 3068.4,                last time consumption/overall running time: 812.0792s / 304683.7934 s
env0_first_0:                 episode reward: -13.8500,                 loss: 0.0346
env0_second_0:                 episode reward: 13.8500,                 loss: 0.0364
env1_first_0:                 episode reward: -13.2500,                 loss: nan
env1_second_0:                 episode reward: 13.2500,                 loss: nan
Episode: 6741/10000 (67.4100%),                 avg. length: 2980.9,                last time consumption/overall running time: 790.8716s / 305474.6650 s
env0_first_0:                 episode reward: -13.3500,                 loss: 0.0345
env0_second_0:                 episode reward: 13.3500,                 loss: 0.0373
env1_first_0:                 episode reward: -15.5000,                 loss: nan
env1_second_0:                 episode reward: 15.5000,                 loss: nan
Episode: 6761/10000 (67.6100%),                 avg. length: 2910.2,                last time consumption/overall running time: 751.4992s / 306226.1642 s
env0_first_0:                 episode reward: -10.8000,                 loss: 0.0374
env0_second_0:                 episode reward: 10.8000,                 loss: 0.0366
env1_first_0:                 episode reward: -12.3500,                 loss: nan
env1_second_0:                 episode reward: 12.3500,                 loss: nan
Episode: 6781/10000 (67.8100%),                 avg. length: 2999.55,                last time consumption/overall running time: 800.1482s / 307026.3124 s
env0_first_0:                 episode reward: -13.8500,                 loss: 0.0400
env0_second_0:                 episode reward: 13.8500,                 loss: 0.0395
env1_first_0:                 episode reward: -14.4000,                 loss: nan
env1_second_0:                 episode reward: 14.4000,                 loss: nan
Episode: 6801/10000 (68.0100%),                 avg. length: 2959.35,                last time consumption/overall running time: 775.1020s / 307801.4144 s
env0_first_0:                 episode reward: -11.5500,                 loss: 0.0372
env0_second_0:                 episode reward: 11.5500,                 loss: 0.0354
env1_first_0:                 episode reward: -11.3000,                 loss: nan
env1_second_0:                 episode reward: 11.3000,                 loss: nan
Episode: 6821/10000 (68.2100%),                 avg. length: 2888.15,                last time consumption/overall running time: 771.6314s / 308573.0458 s
env0_first_0:                 episode reward: -12.0500,                 loss: 0.0360
env0_second_0:                 episode reward: 12.0500,                 loss: 0.0345
env1_first_0:                 episode reward: -13.8000,                 loss: nan
env1_second_0:                 episode reward: 13.8000,                 loss: nan
Episode: 6841/10000 (68.4100%),                 avg. length: 2963.55,                last time consumption/overall running time: 806.6063s / 309379.6522 s
env0_first_0:                 episode reward: -12.4500,                 loss: 0.0364
env0_second_0:                 episode reward: 12.4500,                 loss: 0.0356
env1_first_0:                 episode reward: -12.4000,                 loss: nan
env1_second_0:                 episode reward: 12.4000,                 loss: nan
Episode: 6861/10000 (68.6100%),                 avg. length: 2996.6,                last time consumption/overall running time: 816.9179s / 310196.5701 s
env0_first_0:                 episode reward: -13.8500,                 loss: 0.0363
env0_second_0:                 episode reward: 13.8500,                 loss: 0.0360
env1_first_0:                 episode reward: -13.5000,                 loss: nan
env1_second_0:                 episode reward: 13.5000,                 loss: nan
Episode: 6881/10000 (68.8100%),                 avg. length: 3076.4,                last time consumption/overall running time: 839.6182s / 311036.1884 s
env0_first_0:                 episode reward: -12.3000,                 loss: 0.0354
env0_second_0:                 episode reward: 12.3000,                 loss: 0.0364
env1_first_0:                 episode reward: -12.8000,                 loss: nan
env1_second_0:                 episode reward: 12.8000,                 loss: nan
Episode: 6901/10000 (69.0100%),                 avg. length: 2959.9,                last time consumption/overall running time: 805.9472s / 311842.1356 s
env0_first_0:                 episode reward: -13.3500,                 loss: 0.0348
env0_second_0:                 episode reward: 13.3500,                 loss: 0.0354
env1_first_0:                 episode reward: -11.6500,                 loss: nan
env1_second_0:                 episode reward: 11.6500,                 loss: nan
Episode: 6921/10000 (69.2100%),                 avg. length: 3059.05,                last time consumption/overall running time: 809.3395s / 312651.4751 s
env0_first_0:                 episode reward: -11.6500,                 loss: 0.0358
env0_second_0:                 episode reward: 11.6500,                 loss: 0.0379
env1_first_0:                 episode reward: -12.4000,                 loss: nan
env1_second_0:                 episode reward: 12.4000,                 loss: nan
Episode: 6941/10000 (69.4100%),                 avg. length: 3041.55,                last time consumption/overall running time: 818.6398s / 313470.1149 s
env0_first_0:                 episode reward: -13.4000,                 loss: 0.0358
env0_second_0:                 episode reward: 13.4000,                 loss: 0.0362
env1_first_0:                 episode reward: -12.7000,                 loss: nan
env1_second_0:                 episode reward: 12.7000,                 loss: nan
Episode: 6961/10000 (69.6100%),                 avg. length: 3056.05,                last time consumption/overall running time: 825.1199s / 314295.2348 s
env0_first_0:                 episode reward: -11.6500,                 loss: 0.0351
env0_second_0:                 episode reward: 11.6500,                 loss: 0.0352
env1_first_0:                 episode reward: -14.6000,                 loss: nan
env1_second_0:                 episode reward: 14.6000,                 loss: nan
Episode: 6981/10000 (69.8100%),                 avg. length: 3067.45,                last time consumption/overall running time: 832.5201s / 315127.7549 s
env0_first_0:                 episode reward: -13.2000,                 loss: 0.0367
env0_second_0:                 episode reward: 13.2000,                 loss: 0.0363
env1_first_0:                 episode reward: -13.1000,                 loss: nan
env1_second_0:                 episode reward: 13.1000,                 loss: nan
Episode: 7001/10000 (70.0100%),                 avg. length: 2902.6,                last time consumption/overall running time: 758.8386s / 315886.5935 s
env0_first_0:                 episode reward: -10.9500,                 loss: 0.0373
env0_second_0:                 episode reward: 10.9500,                 loss: 0.0380
env1_first_0:                 episode reward: -12.6000,                 loss: nan
env1_second_0:                 episode reward: 12.6000,                 loss: nan
Episode: 7021/10000 (70.2100%),                 avg. length: 2914.55,                last time consumption/overall running time: 787.4258s / 316674.0194 s
env0_first_0:                 episode reward: -10.5000,                 loss: 0.0366
env0_second_0:                 episode reward: 10.5000,                 loss: 0.0375
env1_first_0:                 episode reward: -11.6500,                 loss: nan
env1_second_0:                 episode reward: 11.6500,                 loss: nan
Episode: 7041/10000 (70.4100%),                 avg. length: 2933.0,                last time consumption/overall running time: 790.8297s / 317464.8491 s
env0_first_0:                 episode reward: -13.6500,                 loss: 0.0374
env0_second_0:                 episode reward: 13.6500,                 loss: 0.0396
env1_first_0:                 episode reward: -13.1500,                 loss: nan
env1_second_0:                 episode reward: 13.1500,                 loss: nan
Episode: 7061/10000 (70.6100%),                 avg. length: 2940.55,                last time consumption/overall running time: 780.7866s / 318245.6356 s
env0_first_0:                 episode reward: -15.0000,                 loss: 0.0397
env0_second_0:                 episode reward: 15.0000,                 loss: 0.0398
env1_first_0:                 episode reward: -11.2000,                 loss: nan
env1_second_0:                 episode reward: 11.2000,                 loss: nan
Episode: 7081/10000 (70.8100%),                 avg. length: 3079.6,                last time consumption/overall running time: 811.5842s / 319057.2198 s
env0_first_0:                 episode reward: -13.0500,                 loss: 0.0370
env0_second_0:                 episode reward: 13.0500,                 loss: 0.0369
env1_first_0:                 episode reward: -15.0000,                 loss: nan
env1_second_0:                 episode reward: 15.0000,                 loss: nan
Episode: 7101/10000 (71.0100%),                 avg. length: 3041.45,                last time consumption/overall running time: 820.0156s / 319877.2354 s
env0_first_0:                 episode reward: -13.0000,                 loss: 0.0358
env0_second_0:                 episode reward: 13.0000,                 loss: 0.0345
env1_first_0:                 episode reward: -12.4500,                 loss: nan
env1_second_0:                 episode reward: 12.4500,                 loss: nan
Episode: 7121/10000 (71.2100%),                 avg. length: 3025.25,                last time consumption/overall running time: 780.9348s / 320658.1703 s
env0_first_0:                 episode reward: -13.6000,                 loss: 0.0351
env0_second_0:                 episode reward: 13.6000,                 loss: 0.0345
env1_first_0:                 episode reward: -13.8500,                 loss: nan
env1_second_0:                 episode reward: 13.8500,                 loss: nan
Episode: 7141/10000 (71.4100%),                 avg. length: 3073.4,                last time consumption/overall running time: 834.4266s / 321492.5969 s
env0_first_0:                 episode reward: -14.3500,                 loss: 0.0353
env0_second_0:                 episode reward: 14.3500,                 loss: 0.0349
env1_first_0:                 episode reward: -12.4000,                 loss: nan
env1_second_0:                 episode reward: 12.4000,                 loss: nan
Episode: 7161/10000 (71.6100%),                 avg. length: 3050.9,                last time consumption/overall running time: 800.2535s / 322292.8503 s
env0_first_0:                 episode reward: -15.0500,                 loss: 0.0374
env0_second_0:                 episode reward: 15.0500,                 loss: 0.0364
env1_first_0:                 episode reward: -11.2500,                 loss: nan
env1_second_0:                 episode reward: 11.2500,                 loss: nan
Episode: 7181/10000 (71.8100%),                 avg. length: 3117.65,                last time consumption/overall running time: 830.8256s / 323123.6759 s
env0_first_0:                 episode reward: -13.0500,                 loss: 0.0367
env0_second_0:                 episode reward: 13.0500,                 loss: 0.0384
env1_first_0:                 episode reward: -13.6000,                 loss: nan
env1_second_0:                 episode reward: 13.6000,                 loss: nan
Episode: 7201/10000 (72.0100%),                 avg. length: 3020.1,                last time consumption/overall running time: 817.0316s / 323940.7076 s
env0_first_0:                 episode reward: -15.5500,                 loss: 0.0378
env0_second_0:                 episode reward: 15.5500,                 loss: 0.0369
env1_first_0:                 episode reward: -13.8000,                 loss: nan
env1_second_0:                 episode reward: 13.8000,                 loss: nan
Episode: 7221/10000 (72.2100%),                 avg. length: 2949.7,                last time consumption/overall running time: 783.7325s / 324724.4400 s
env0_first_0:                 episode reward: -12.6000,                 loss: 0.0377
env0_second_0:                 episode reward: 12.6000,                 loss: 0.0360
env1_first_0:                 episode reward: -10.8500,                 loss: nan
env1_second_0:                 episode reward: 10.8500,                 loss: nan
Episode: 7241/10000 (72.4100%),                 avg. length: 3181.05,                last time consumption/overall running time: 864.5976s / 325589.0376 s
env0_first_0:                 episode reward: -14.2500,                 loss: 0.0353
env0_second_0:                 episode reward: 14.2500,                 loss: 0.0351
env1_first_0:                 episode reward: -15.1500,                 loss: nan
env1_second_0:                 episode reward: 15.1500,                 loss: nan
Episode: 7261/10000 (72.6100%),                 avg. length: 3183.75,                last time consumption/overall running time: 848.7291s / 326437.7667 s
env0_first_0:                 episode reward: -14.5000,                 loss: 0.0360
env0_second_0:                 episode reward: 14.5000,                 loss: 0.0348
env1_first_0:                 episode reward: -14.3000,                 loss: nan
env1_second_0:                 episode reward: 14.3000,                 loss: nan
Episode: 7281/10000 (72.8100%),                 avg. length: 3127.5,                last time consumption/overall running time: 841.6780s / 327279.4446 s
env0_first_0:                 episode reward: -15.3000,                 loss: 0.0357
env0_second_0:                 episode reward: 15.3000,                 loss: 0.0358
env1_first_0:                 episode reward: -14.8000,                 loss: nan
env1_second_0:                 episode reward: 14.8000,                 loss: nan
Episode: 7301/10000 (73.0100%),                 avg. length: 3058.35,                last time consumption/overall running time: 822.2340s / 328101.6786 s
env0_first_0:                 episode reward: -13.0500,                 loss: 0.0387
env0_second_0:                 episode reward: 13.0500,                 loss: 0.0373
env1_first_0:                 episode reward: -10.6000,                 loss: nan
env1_second_0:                 episode reward: 10.6000,                 loss: nan
Episode: 7321/10000 (73.2100%),                 avg. length: 3207.95,                last time consumption/overall running time: 869.8552s / 328971.5338 s
env0_first_0:                 episode reward: -13.5000,                 loss: 0.0344
env0_second_0:                 episode reward: 13.5000,                 loss: 0.0352
env1_first_0:                 episode reward: -14.2500,                 loss: nan
env1_second_0:                 episode reward: 14.2500,                 loss: nan
Episode: 7341/10000 (73.4100%),                 avg. length: 3001.6,                last time consumption/overall running time: 791.2897s / 329762.8235 s
env0_first_0:                 episode reward: -15.6000,                 loss: 0.0356
env0_second_0:                 episode reward: 15.6000,                 loss: 0.0360
env1_first_0:                 episode reward: -14.9000,                 loss: nan
env1_second_0:                 episode reward: 14.9000,                 loss: nan
Episode: 7361/10000 (73.6100%),                 avg. length: 3013.75,                last time consumption/overall running time: 816.9988s / 330579.8223 s
env0_first_0:                 episode reward: -16.2000,                 loss: 0.0378
env0_second_0:                 episode reward: 16.2000,                 loss: 0.0382
env1_first_0:                 episode reward: -14.8000,                 loss: nan
env1_second_0:                 episode reward: 14.8000,                 loss: nan
Episode: 7381/10000 (73.8100%),                 avg. length: 3193.8,                last time consumption/overall running time: 847.5899s / 331427.4122 s
env0_first_0:                 episode reward: -13.8500,                 loss: 0.0359
env0_second_0:                 episode reward: 13.8500,                 loss: 0.0365
env1_first_0:                 episode reward: -13.3500,                 loss: nan
env1_second_0:                 episode reward: 13.3500,                 loss: nan
Episode: 7401/10000 (74.0100%),                 avg. length: 3122.25,                last time consumption/overall running time: 841.3368s / 332268.7490 s
env0_first_0:                 episode reward: -12.9500,                 loss: 0.0385
env0_second_0:                 episode reward: 12.9500,                 loss: 0.0381
env1_first_0:                 episode reward: -12.9500,                 loss: nan
env1_second_0:                 episode reward: 12.9500,                 loss: nan
Episode: 7421/10000 (74.2100%),                 avg. length: 3284.2,                last time consumption/overall running time: 867.7674s / 333136.5165 s
env0_first_0:                 episode reward: -14.4500,                 loss: 0.0361
env0_second_0:                 episode reward: 14.4500,                 loss: 0.0375
env1_first_0:                 episode reward: -14.5000,                 loss: nan
env1_second_0:                 episode reward: 14.5000,                 loss: nan
Episode: 7441/10000 (74.4100%),                 avg. length: 3020.25,                last time consumption/overall running time: 772.4382s / 333908.9546 s
env0_first_0:                 episode reward: -12.6500,                 loss: 0.0373
env0_second_0:                 episode reward: 12.6500,                 loss: 0.0365
env1_first_0:                 episode reward: -13.0000,                 loss: nan
env1_second_0:                 episode reward: 13.0000,                 loss: nan
Episode: 7461/10000 (74.6100%),                 avg. length: 3142.8,                last time consumption/overall running time: 845.4999s / 334754.4546 s
env0_first_0:                 episode reward: -14.8000,                 loss: 0.0356
env0_second_0:                 episode reward: 14.8000,                 loss: 0.0367
env1_first_0:                 episode reward: -15.5000,                 loss: nan
env1_second_0:                 episode reward: 15.5000,                 loss: nan
Episode: 7481/10000 (74.8100%),                 avg. length: 3222.0,                last time consumption/overall running time: 868.2839s / 335622.7384 s
env0_first_0:                 episode reward: -12.1500,                 loss: 0.0375
env0_second_0:                 episode reward: 12.1500,                 loss: 0.0364
env1_first_0:                 episode reward: -13.8500,                 loss: nan
env1_second_0:                 episode reward: 13.8500,                 loss: nan
Episode: 7501/10000 (75.0100%),                 avg. length: 2920.95,                last time consumption/overall running time: 754.0640s / 336376.8024 s
env0_first_0:                 episode reward: -13.7500,                 loss: 0.0359
env0_second_0:                 episode reward: 13.7500,                 loss: 0.0380
env1_first_0:                 episode reward: -13.4000,                 loss: nan
env1_second_0:                 episode reward: 13.4000,                 loss: nan
Episode: 7521/10000 (75.2100%),                 avg. length: 2844.25,                last time consumption/overall running time: 753.4857s / 337130.2881 s
env0_first_0:                 episode reward: -9.6500,                 loss: 0.0379
env0_second_0:                 episode reward: 9.6500,                 loss: 0.0388
env1_first_0:                 episode reward: -11.2000,                 loss: nan
env1_second_0:                 episode reward: 11.2000,                 loss: nan
Episode: 7541/10000 (75.4100%),                 avg. length: 2941.65,                last time consumption/overall running time: 794.8117s / 337925.0998 s
env0_first_0:                 episode reward: -13.4500,                 loss: 0.0376
env0_second_0:                 episode reward: 13.4500,                 loss: 0.0386
env1_first_0:                 episode reward: -12.2000,                 loss: nan
env1_second_0:                 episode reward: 12.2000,                 loss: nan
Episode: 7561/10000 (75.6100%),                 avg. length: 3070.2,                last time consumption/overall running time: 816.9295s / 338742.0293 s
env0_first_0:                 episode reward: -14.9000,                 loss: 0.0356
env0_second_0:                 episode reward: 14.9000,                 loss: 0.0350
env1_first_0:                 episode reward: -13.5500,                 loss: nan
env1_second_0:                 episode reward: 13.5500,                 loss: nan
Episode: 7581/10000 (75.8100%),                 avg. length: 2970.0,                last time consumption/overall running time: 771.8411s / 339513.8705 s
env0_first_0:                 episode reward: -13.2000,                 loss: 0.0369
env0_second_0:                 episode reward: 13.2000,                 loss: 0.0344
env1_first_0:                 episode reward: -10.9000,                 loss: nan
env1_second_0:                 episode reward: 10.9000,                 loss: nan
Episode: 7601/10000 (76.0100%),                 avg. length: 2983.75,                last time consumption/overall running time: 789.1661s / 340303.0366 s
env0_first_0:                 episode reward: -11.1500,                 loss: 0.0357
env0_second_0:                 episode reward: 11.1500,                 loss: 0.0344
env1_first_0:                 episode reward: -12.7000,                 loss: nan
env1_second_0:                 episode reward: 12.7000,                 loss: nan
Episode: 7621/10000 (76.2100%),                 avg. length: 2953.4,                last time consumption/overall running time: 793.8104s / 341096.8470 s
env0_first_0:                 episode reward: -11.8000,                 loss: 0.0343
env0_second_0:                 episode reward: 11.8000,                 loss: 0.0366
env1_first_0:                 episode reward: -11.8000,                 loss: nan
env1_second_0:                 episode reward: 11.8000,                 loss: nan
Episode: 7641/10000 (76.4100%),                 avg. length: 3089.05,                last time consumption/overall running time: 811.6303s / 341908.4773 s
env0_first_0:                 episode reward: -14.5500,                 loss: 0.0366
env0_second_0:                 episode reward: 14.5500,                 loss: 0.0373
env1_first_0:                 episode reward: -13.4500,                 loss: nan
env1_second_0:                 episode reward: 13.4500,                 loss: nan
Episode: 7661/10000 (76.6100%),                 avg. length: 3005.85,                last time consumption/overall running time: 784.9389s / 342693.4162 s
env0_first_0:                 episode reward: -12.2000,                 loss: 0.0377
env0_second_0:                 episode reward: 12.2000,                 loss: 0.0376
env1_first_0:                 episode reward: -12.1500,                 loss: nan
env1_second_0:                 episode reward: 12.1500,                 loss: nan
Episode: 7681/10000 (76.8100%),                 avg. length: 2987.05,                last time consumption/overall running time: 778.1959s / 343471.6121 s
env0_first_0:                 episode reward: -12.6000,                 loss: 0.0364
env0_second_0:                 episode reward: 12.6000,                 loss: 0.0351
env1_first_0:                 episode reward: -13.0500,                 loss: nan
env1_second_0:                 episode reward: 13.0500,                 loss: nan
Episode: 7701/10000 (77.0100%),                 avg. length: 2928.55,                last time consumption/overall running time: 777.2690s / 344248.8811 s
env0_first_0:                 episode reward: -11.1000,                 loss: 0.0354
env0_second_0:                 episode reward: 11.1000,                 loss: 0.0358
env1_first_0:                 episode reward: -14.0000,                 loss: nan
env1_second_0:                 episode reward: 14.0000,                 loss: nan
Episode: 7721/10000 (77.2100%),                 avg. length: 3095.9,                last time consumption/overall running time: 803.1338s / 345052.0149 s
env0_first_0:                 episode reward: -12.8500,                 loss: 0.0366
env0_second_0:                 episode reward: 12.8500,                 loss: 0.0363
env1_first_0:                 episode reward: -13.0500,                 loss: nan
env1_second_0:                 episode reward: 13.0500,                 loss: nan
Episode: 7741/10000 (77.4100%),                 avg. length: 3025.95,                last time consumption/overall running time: 799.5720s / 345851.5868 s
env0_first_0:                 episode reward: -13.9500,                 loss: 0.0378
env0_second_0:                 episode reward: 13.9500,                 loss: 0.0377
env1_first_0:                 episode reward: -13.1500,                 loss: nan
env1_second_0:                 episode reward: 13.1500,                 loss: nan
Episode: 7761/10000 (77.6100%),                 avg. length: 3066.65,                last time consumption/overall running time: 807.1278s / 346658.7147 s
env0_first_0:                 episode reward: -14.5000,                 loss: 0.0361
env0_second_0:                 episode reward: 14.5000,                 loss: 0.0343
env1_first_0:                 episode reward: -13.8500,                 loss: nan
env1_second_0:                 episode reward: 13.8500,                 loss: nan
Episode: 7781/10000 (77.8100%),                 avg. length: 3014.5,                last time consumption/overall running time: 783.3255s / 347442.0401 s
env0_first_0:                 episode reward: -11.9500,                 loss: 0.0350
env0_second_0:                 episode reward: 11.9500,                 loss: 0.0330
env1_first_0:                 episode reward: -13.6000,                 loss: nan
env1_second_0:                 episode reward: 13.6000,                 loss: nan
Episode: 7801/10000 (78.0100%),                 avg. length: 3093.4,                last time consumption/overall running time: 805.4758s / 348247.5159 s
env0_first_0:                 episode reward: -12.3000,                 loss: 0.0359
env0_second_0:                 episode reward: 12.3000,                 loss: 0.0346
env1_first_0:                 episode reward: -10.7500,                 loss: nan
env1_second_0:                 episode reward: 10.7500,                 loss: nan
Episode: 7821/10000 (78.2100%),                 avg. length: 3238.5,                last time consumption/overall running time: 851.2284s / 349098.7443 s
env0_first_0:                 episode reward: -15.3500,                 loss: 0.0357
env0_second_0:                 episode reward: 15.3500,                 loss: 0.0364
env1_first_0:                 episode reward: -12.8500,                 loss: nan
env1_second_0:                 episode reward: 12.8500,                 loss: nan
Episode: 7841/10000 (78.4100%),                 avg. length: 3091.35,                last time consumption/overall running time: 833.1461s / 349931.8904 s
env0_first_0:                 episode reward: -12.7500,                 loss: 0.0338
env0_second_0:                 episode reward: 12.7500,                 loss: 0.0348
env1_first_0:                 episode reward: -12.7000,                 loss: nan
env1_second_0:                 episode reward: 12.7000,                 loss: nan
Episode: 7861/10000 (78.6100%),                 avg. length: 3078.35,                last time consumption/overall running time: 823.0578s / 350754.9481 s
env0_first_0:                 episode reward: -14.3000,                 loss: 0.0355
env0_second_0:                 episode reward: 14.3000,                 loss: 0.0363
env1_first_0:                 episode reward: -11.9000,                 loss: nan
env1_second_0:                 episode reward: 11.9000,                 loss: nan
Episode: 7881/10000 (78.8100%),                 avg. length: 3092.5,                last time consumption/overall running time: 825.9941s / 351580.9422 s
env0_first_0:                 episode reward: -15.7500,                 loss: 0.0356
env0_second_0:                 episode reward: 15.7500,                 loss: 0.0344
env1_first_0:                 episode reward: -11.4000,                 loss: nan
env1_second_0:                 episode reward: 11.4000,                 loss: nan
Episode: 7901/10000 (79.0100%),                 avg. length: 2962.3,                last time consumption/overall running time: 779.7798s / 352360.7220 s
env0_first_0:                 episode reward: -14.3500,                 loss: 0.0349
env0_second_0:                 episode reward: 14.3500,                 loss: 0.0342
env1_first_0:                 episode reward: -11.7500,                 loss: nan
env1_second_0:                 episode reward: 11.7500,                 loss: nan
Episode: 7921/10000 (79.2100%),                 avg. length: 3061.1,                last time consumption/overall running time: 797.3082s / 353158.0303 s
env0_first_0:                 episode reward: -10.8500,                 loss: 0.0360
env0_second_0:                 episode reward: 10.8500,                 loss: 0.0353
env1_first_0:                 episode reward: -14.0500,                 loss: nan
env1_second_0:                 episode reward: 14.0500,                 loss: nan
Episode: 7941/10000 (79.4100%),                 avg. length: 2904.75,                last time consumption/overall running time: 768.0328s / 353926.0631 s
env0_first_0:                 episode reward: -12.0000,                 loss: 0.0379
env0_second_0:                 episode reward: 12.0000,                 loss: 0.0380
env1_first_0:                 episode reward: -14.2500,                 loss: nan
env1_second_0:                 episode reward: 14.2500,                 loss: nan
Episode: 7961/10000 (79.6100%),                 avg. length: 3053.1,                last time consumption/overall running time: 824.8244s / 354750.8875 s
env0_first_0:                 episode reward: -13.3500,                 loss: 0.0383
env0_second_0:                 episode reward: 13.3500,                 loss: 0.0371
env1_first_0:                 episode reward: -13.1000,                 loss: nan
env1_second_0:                 episode reward: 13.1000,                 loss: nan
Episode: 7981/10000 (79.8100%),                 avg. length: 3127.4,                last time consumption/overall running time: 822.4072s / 355573.2947 s
env0_first_0:                 episode reward: -11.6000,                 loss: 0.0354
env0_second_0:                 episode reward: 11.6000,                 loss: 0.0351
env1_first_0:                 episode reward: -13.4000,                 loss: nan
env1_second_0:                 episode reward: 13.4000,                 loss: nan
Episode: 8001/10000 (80.0100%),                 avg. length: 3059.85,                last time consumption/overall running time: 821.4110s / 356394.7057 s
env0_first_0:                 episode reward: -13.3000,                 loss: 0.0332
env0_second_0:                 episode reward: 13.3000,                 loss: 0.0344
env1_first_0:                 episode reward: -11.8000,                 loss: nan
env1_second_0:                 episode reward: 11.8000,                 loss: nan
Episode: 8021/10000 (80.2100%),                 avg. length: 3092.0,                last time consumption/overall running time: 784.1122s / 357178.8179 s
env0_first_0:                 episode reward: -13.4000,                 loss: 0.0359
env0_second_0:                 episode reward: 13.4000,                 loss: 0.0356
env1_first_0:                 episode reward: -11.5500,                 loss: nan
env1_second_0:                 episode reward: 11.5500,                 loss: nan
Episode: 8041/10000 (80.4100%),                 avg. length: 2997.35,                last time consumption/overall running time: 769.0703s / 357947.8882 s
env0_first_0:                 episode reward: -13.6000,                 loss: 0.0364
env0_second_0:                 episode reward: 13.6000,                 loss: 0.0375
env1_first_0:                 episode reward: -12.9000,                 loss: nan
env1_second_0:                 episode reward: 12.9000,                 loss: nan
Episode: 8061/10000 (80.6100%),                 avg. length: 3173.1,                last time consumption/overall running time: 829.2523s / 358777.1405 s
env0_first_0:                 episode reward: -12.8000,                 loss: 0.0375
env0_second_0:                 episode reward: 12.8000,                 loss: 0.0366
env1_first_0:                 episode reward: -13.5500,                 loss: nan
env1_second_0:                 episode reward: 13.5500,                 loss: nan
Episode: 8081/10000 (80.8100%),                 avg. length: 3134.75,                last time consumption/overall running time: 844.0451s / 359621.1857 s
env0_first_0:                 episode reward: -15.4500,                 loss: 0.0373
env0_second_0:                 episode reward: 15.4500,                 loss: 0.0359
env1_first_0:                 episode reward: -13.0000,                 loss: nan
env1_second_0:                 episode reward: 13.0000,                 loss: nan
Episode: 8101/10000 (81.0100%),                 avg. length: 2979.8,                last time consumption/overall running time: 777.4256s / 360398.6113 s
env0_first_0:                 episode reward: -13.1000,                 loss: 0.0360
env0_second_0:                 episode reward: 13.1000,                 loss: 0.0362
env1_first_0:                 episode reward: -13.5500,                 loss: nan
env1_second_0:                 episode reward: 13.5500,                 loss: nan
Episode: 8121/10000 (81.2100%),                 avg. length: 3085.45,                last time consumption/overall running time: 798.6050s / 361197.2163 s
env0_first_0:                 episode reward: -12.7000,                 loss: 0.0373
env0_second_0:                 episode reward: 12.7000,                 loss: 0.0375
env1_first_0:                 episode reward: -11.6500,                 loss: nan
env1_second_0:                 episode reward: 11.6500,                 loss: nan
Episode: 8141/10000 (81.4100%),                 avg. length: 3046.1,                last time consumption/overall running time: 792.8236s / 361990.0398 s
env0_first_0:                 episode reward: -9.7000,                 loss: 0.0358
env0_second_0:                 episode reward: 9.7000,                 loss: 0.0378
env1_first_0:                 episode reward: -13.3000,                 loss: nan
env1_second_0:                 episode reward: 13.3000,                 loss: nan
Episode: 8161/10000 (81.6100%),                 avg. length: 2732.05,                last time consumption/overall running time: 714.9227s / 362704.9626 s
env0_first_0:                 episode reward: -10.4500,                 loss: 0.0356
env0_second_0:                 episode reward: 10.4500,                 loss: 0.0367
env1_first_0:                 episode reward: -13.7000,                 loss: nan
env1_second_0:                 episode reward: 13.7000,                 loss: nan
Episode: 8181/10000 (81.8100%),                 avg. length: 2863.5,                last time consumption/overall running time: 776.1948s / 363481.1573 s
env0_first_0:                 episode reward: -10.9500,                 loss: 0.0363
env0_second_0:                 episode reward: 10.9500,                 loss: 0.0356
env1_first_0:                 episode reward: -11.3500,                 loss: nan
env1_second_0:                 episode reward: 11.3500,                 loss: nan
Episode: 8201/10000 (82.0100%),                 avg. length: 3054.9,                last time consumption/overall running time: 827.0159s / 364308.1733 s
env0_first_0:                 episode reward: -13.7500,                 loss: 0.0383
env0_second_0:                 episode reward: 13.7500,                 loss: 0.0366
env1_first_0:                 episode reward: -11.9500,                 loss: nan
env1_second_0:                 episode reward: 11.9500,                 loss: nan
Episode: 8221/10000 (82.2100%),                 avg. length: 2971.65,                last time consumption/overall running time: 774.3434s / 365082.5167 s
env0_first_0:                 episode reward: -10.8500,                 loss: 0.0381
env0_second_0:                 episode reward: 10.8500,                 loss: 0.0360
env1_first_0:                 episode reward: -13.8500,                 loss: nan
env1_second_0:                 episode reward: 13.8500,                 loss: nan
Episode: 8241/10000 (82.4100%),                 avg. length: 3076.45,                last time consumption/overall running time: 794.0131s / 365876.5297 s
env0_first_0:                 episode reward: -13.1500,                 loss: 0.0364
env0_second_0:                 episode reward: 13.1500,                 loss: 0.0347
env1_first_0:                 episode reward: -13.1500,                 loss: nan
env1_second_0:                 episode reward: 13.1500,                 loss: nan
Episode: 8261/10000 (82.6100%),                 avg. length: 2933.5,                last time consumption/overall running time: 783.4938s / 366660.0235 s
env0_first_0:                 episode reward: -10.2000,                 loss: 0.0356
env0_second_0:                 episode reward: 10.2000,                 loss: 0.0343
env1_first_0:                 episode reward: -9.9000,                 loss: nan
env1_second_0:                 episode reward: 9.9000,                 loss: nan
Episode: 8281/10000 (82.8100%),                 avg. length: 3029.4,                last time consumption/overall running time: 812.9234s / 367472.9469 s
env0_first_0:                 episode reward: -13.2500,                 loss: 0.0371
env0_second_0:                 episode reward: 13.2500,                 loss: 0.0370
env1_first_0:                 episode reward: -15.8000,                 loss: nan
env1_second_0:                 episode reward: 15.8000,                 loss: nan
Episode: 8301/10000 (83.0100%),                 avg. length: 2859.65,                last time consumption/overall running time: 760.0901s / 368233.0370 s
env0_first_0:                 episode reward: -12.0500,                 loss: 0.0356
env0_second_0:                 episode reward: 12.0500,                 loss: 0.0367
env1_first_0:                 episode reward: -13.4000,                 loss: nan
env1_second_0:                 episode reward: 13.4000,                 loss: nan
Episode: 8321/10000 (83.2100%),                 avg. length: 3183.8,                last time consumption/overall running time: 831.4816s / 369064.5186 s
env0_first_0:                 episode reward: -16.2500,                 loss: 0.0351
env0_second_0:                 episode reward: 16.2500,                 loss: 0.0366
env1_first_0:                 episode reward: -14.3000,                 loss: nan
env1_second_0:                 episode reward: 14.3000,                 loss: nan
Episode: 8341/10000 (83.4100%),                 avg. length: 3200.3,                last time consumption/overall running time: 830.8115s / 369895.3300 s
env0_first_0:                 episode reward: -16.4500,                 loss: 0.0365
env0_second_0:                 episode reward: 16.4500,                 loss: 0.0359
env1_first_0:                 episode reward: -14.7500,                 loss: nan
env1_second_0:                 episode reward: 14.7500,                 loss: nan
Episode: 8361/10000 (83.6100%),                 avg. length: 3019.05,                last time consumption/overall running time: 768.7706s / 370664.1007 s
env0_first_0:                 episode reward: -11.7000,                 loss: 0.0360
env0_second_0:                 episode reward: 11.7000,                 loss: 0.0347
env1_first_0:                 episode reward: -13.5500,                 loss: nan
env1_second_0:                 episode reward: 13.5500,                 loss: nan
Episode: 8381/10000 (83.8100%),                 avg. length: 3009.9,                last time consumption/overall running time: 804.4524s / 371468.5530 s
env0_first_0:                 episode reward: -13.5000,                 loss: 0.0367
env0_second_0:                 episode reward: 13.5000,                 loss: 0.0372
env1_first_0:                 episode reward: -12.0000,                 loss: nan
env1_second_0:                 episode reward: 12.0000,                 loss: nan
Episode: 8401/10000 (84.0100%),                 avg. length: 3149.2,                last time consumption/overall running time: 838.6556s / 372307.2086 s
env0_first_0:                 episode reward: -13.3000,                 loss: 0.0373
env0_second_0:                 episode reward: 13.3000,                 loss: 0.0376
env1_first_0:                 episode reward: -13.9500,                 loss: nan
env1_second_0:                 episode reward: 13.9500,                 loss: nan
Episode: 8421/10000 (84.2100%),                 avg. length: 2933.9,                last time consumption/overall running time: 768.9024s / 373076.1110 s
env0_first_0:                 episode reward: -12.7500,                 loss: 0.0371
env0_second_0:                 episode reward: 12.7500,                 loss: 0.0369
env1_first_0:                 episode reward: -13.0000,                 loss: nan
env1_second_0:                 episode reward: 13.0000,                 loss: nan
Episode: 8441/10000 (84.4100%),                 avg. length: 3080.15,                last time consumption/overall running time: 822.5317s / 373898.6427 s
env0_first_0:                 episode reward: -16.4500,                 loss: 0.0373
env0_second_0:                 episode reward: 16.4500,                 loss: 0.0365
env1_first_0:                 episode reward: -13.9500,                 loss: nan
env1_second_0:                 episode reward: 13.9500,                 loss: nan
Episode: 8461/10000 (84.6100%),                 avg. length: 2922.85,                last time consumption/overall running time: 781.0907s / 374679.7334 s
env0_first_0:                 episode reward: -10.2000,                 loss: 0.0369
env0_second_0:                 episode reward: 10.2000,                 loss: 0.0374
env1_first_0:                 episode reward: -11.5000,                 loss: nan
env1_second_0:                 episode reward: 11.5000,                 loss: nan
Episode: 8481/10000 (84.8100%),                 avg. length: 2835.65,                last time consumption/overall running time: 758.2099s / 375437.9433 s
env0_first_0:                 episode reward: -13.4500,                 loss: 0.0388
env0_second_0:                 episode reward: 13.4500,                 loss: 0.0383
env1_first_0:                 episode reward: -13.2500,                 loss: nan
env1_second_0:                 episode reward: 13.2500,                 loss: nan
Episode: 8501/10000 (85.0100%),                 avg. length: 2986.9,                last time consumption/overall running time: 794.7953s / 376232.7386 s
env0_first_0:                 episode reward: -13.6000,                 loss: 0.0386
env0_second_0:                 episode reward: 13.6000,                 loss: 0.0396
env1_first_0:                 episode reward: -11.5500,                 loss: nan
env1_second_0:                 episode reward: 11.5500,                 loss: nan
Episode: 8521/10000 (85.2100%),                 avg. length: 3001.2,                last time consumption/overall running time: 797.2359s / 377029.9745 s
env0_first_0:                 episode reward: -14.1000,                 loss: 0.0379
env0_second_0:                 episode reward: 14.1000,                 loss: 0.0377
env1_first_0:                 episode reward: -10.3000,                 loss: nan
env1_second_0:                 episode reward: 10.3000,                 loss: nan
Episode: 8541/10000 (85.4100%),                 avg. length: 3092.2,                last time consumption/overall running time: 815.4990s / 377845.4735 s
env0_first_0:                 episode reward: -14.1000,                 loss: 0.0390
env0_second_0:                 episode reward: 14.1000,                 loss: 0.0376
env1_first_0:                 episode reward: -12.2000,                 loss: nan
env1_second_0:                 episode reward: 12.2000,                 loss: nan
Episode: 8561/10000 (85.6100%),                 avg. length: 3274.8,                last time consumption/overall running time: 847.8174s / 378693.2909 s
env0_first_0:                 episode reward: -14.7000,                 loss: 0.0365
env0_second_0:                 episode reward: 14.7000,                 loss: 0.0364
env1_first_0:                 episode reward: -14.0000,                 loss: nan
env1_second_0:                 episode reward: 14.0000,                 loss: nan
Episode: 8581/10000 (85.8100%),                 avg. length: 2931.25,                last time consumption/overall running time: 773.5849s / 379466.8758 s
env0_first_0:                 episode reward: -13.1500,                 loss: 0.0363
env0_second_0:                 episode reward: 13.1500,                 loss: 0.0366
env1_first_0:                 episode reward: -12.7500,                 loss: nan
env1_second_0:                 episode reward: 12.7500,                 loss: nan
Episode: 8601/10000 (86.0100%),                 avg. length: 3058.2,                last time consumption/overall running time: 799.8627s / 380266.7385 s
env0_first_0:                 episode reward: -11.4500,                 loss: 0.0359
env0_second_0:                 episode reward: 11.4500,                 loss: 0.0364
env1_first_0:                 episode reward: -12.6000,                 loss: nan
env1_second_0:                 episode reward: 12.6000,                 loss: nan
Episode: 8621/10000 (86.2100%),                 avg. length: 2792.7,                last time consumption/overall running time: 736.0085s / 381002.7470 s
env0_first_0:                 episode reward: -13.8000,                 loss: 0.0353
env0_second_0:                 episode reward: 13.8000,                 loss: 0.0374
env1_first_0:                 episode reward: -11.0500,                 loss: nan
env1_second_0:                 episode reward: 11.0500,                 loss: nan
Episode: 8641/10000 (86.4100%),                 avg. length: 3081.8,                last time consumption/overall running time: 828.5268s / 381831.2737 s
env0_first_0:                 episode reward: -12.4500,                 loss: 0.0366
env0_second_0:                 episode reward: 12.4500,                 loss: 0.0380
env1_first_0:                 episode reward: -12.4500,                 loss: nan
env1_second_0:                 episode reward: 12.4500,                 loss: nan
Episode: 8661/10000 (86.6100%),                 avg. length: 2964.35,                last time consumption/overall running time: 789.9716s / 382621.2453 s
env0_first_0:                 episode reward: -12.7000,                 loss: 0.0363
env0_second_0:                 episode reward: 12.7000,                 loss: 0.0377
env1_first_0:                 episode reward: -11.1500,                 loss: nan
env1_second_0:                 episode reward: 11.1500,                 loss: nan
Episode: 8681/10000 (86.8100%),                 avg. length: 2921.9,                last time consumption/overall running time: 769.3816s / 383390.6269 s
env0_first_0:                 episode reward: -13.6500,                 loss: 0.0353
env0_second_0:                 episode reward: 13.6500,                 loss: 0.0355
env1_first_0:                 episode reward: -12.0500,                 loss: nan
env1_second_0:                 episode reward: 12.0500,                 loss: nan
Episode: 8701/10000 (87.0100%),                 avg. length: 3020.2,                last time consumption/overall running time: 806.6283s / 384197.2552 s
env0_first_0:                 episode reward: -12.7500,                 loss: 0.0357
env0_second_0:                 episode reward: 12.7500,                 loss: 0.0344
env1_first_0:                 episode reward: -12.2500,                 loss: nan
env1_second_0:                 episode reward: 12.2500,                 loss: nan
Episode: 8721/10000 (87.2100%),                 avg. length: 3043.9,                last time consumption/overall running time: 816.5897s / 385013.8449 s
env0_first_0:                 episode reward: -13.2000,                 loss: 0.0369
env0_second_0:                 episode reward: 13.2000,                 loss: 0.0353
env1_first_0:                 episode reward: -14.8000,                 loss: nan
env1_second_0:                 episode reward: 14.8000,                 loss: nan
Episode: 8741/10000 (87.4100%),                 avg. length: 3044.4,                last time consumption/overall running time: 818.6511s / 385832.4960 s
env0_first_0:                 episode reward: -12.6500,                 loss: 0.0370
env0_second_0:                 episode reward: 12.6500,                 loss: 0.0353
env1_first_0:                 episode reward: -12.8000,                 loss: nan
env1_second_0:                 episode reward: 12.8000,                 loss: nan
Episode: 8761/10000 (87.6100%),                 avg. length: 3153.55,                last time consumption/overall running time: 848.3709s / 386680.8669 s
env0_first_0:                 episode reward: -13.0500,                 loss: 0.0366
env0_second_0:                 episode reward: 13.0500,                 loss: 0.0369
env1_first_0:                 episode reward: -14.4500,                 loss: nan
env1_second_0:                 episode reward: 14.4500,                 loss: nan
Episode: 8781/10000 (87.8100%),                 avg. length: 3221.6,                last time consumption/overall running time: 841.9110s / 387522.7780 s
env0_first_0:                 episode reward: -16.3500,                 loss: 0.0354
env0_second_0:                 episode reward: 16.3500,                 loss: 0.0366
env1_first_0:                 episode reward: -14.8000,                 loss: nan
env1_second_0:                 episode reward: 14.8000,                 loss: nan
Episode: 8801/10000 (88.0100%),                 avg. length: 3147.9,                last time consumption/overall running time: 797.3670s / 388320.1450 s
env0_first_0:                 episode reward: -12.8000,                 loss: 0.0354
env0_second_0:                 episode reward: 12.8000,                 loss: 0.0356
env1_first_0:                 episode reward: -14.7000,                 loss: nan
env1_second_0:                 episode reward: 14.7000,                 loss: nan
Episode: 8821/10000 (88.2100%),                 avg. length: 2931.05,                last time consumption/overall running time: 765.9243s / 389086.0693 s
env0_first_0:                 episode reward: -13.5000,                 loss: 0.0351
env0_second_0:                 episode reward: 13.5000,                 loss: 0.0346
env1_first_0:                 episode reward: -11.4500,                 loss: nan
env1_second_0:                 episode reward: 11.4500,                 loss: nan
Episode: 8841/10000 (88.4100%),                 avg. length: 3173.35,                last time consumption/overall running time: 832.0047s / 389918.0740 s
env0_first_0:                 episode reward: -14.0500,                 loss: 0.0347
env0_second_0:                 episode reward: 14.0500,                 loss: 0.0370
env1_first_0:                 episode reward: -13.4500,                 loss: nan
env1_second_0:                 episode reward: 13.4500,                 loss: nan
Episode: 8861/10000 (88.6100%),                 avg. length: 3257.6,                last time consumption/overall running time: 873.1694s / 390791.2434 s
env0_first_0:                 episode reward: -14.0500,                 loss: 0.0361
env0_second_0:                 episode reward: 14.0500,                 loss: 0.0360
env1_first_0:                 episode reward: -15.4500,                 loss: nan
env1_second_0:                 episode reward: 15.4500,                 loss: nan
Episode: 8881/10000 (88.8100%),                 avg. length: 3026.65,                last time consumption/overall running time: 807.5019s / 391598.7453 s
env0_first_0:                 episode reward: -14.6000,                 loss: 0.0368
env0_second_0:                 episode reward: 14.6000,                 loss: 0.0367
env1_first_0:                 episode reward: -14.4500,                 loss: nan
env1_second_0:                 episode reward: 14.4500,                 loss: nan
Episode: 8901/10000 (89.0100%),                 avg. length: 2998.95,                last time consumption/overall running time: 811.3012s / 392410.0465 s
env0_first_0:                 episode reward: -13.8500,                 loss: 0.0367
env0_second_0:                 episode reward: 13.8500,                 loss: 0.0354
env1_first_0:                 episode reward: -11.6500,                 loss: nan
env1_second_0:                 episode reward: 11.6500,                 loss: nan
Episode: 8921/10000 (89.2100%),                 avg. length: 2979.1,                last time consumption/overall running time: 796.3568s / 393206.4033 s
env0_first_0:                 episode reward: -10.6500,                 loss: 0.0346
env0_second_0:                 episode reward: 10.6500,                 loss: 0.0357
env1_first_0:                 episode reward: -15.1000,                 loss: nan
env1_second_0:                 episode reward: 15.1000,                 loss: nan
Episode: 8941/10000 (89.4100%),                 avg. length: 3113.7,                last time consumption/overall running time: 837.6788s / 394044.0821 s
env0_first_0:                 episode reward: -15.4000,                 loss: 0.0353
env0_second_0:                 episode reward: 15.4000,                 loss: 0.0371
env1_first_0:                 episode reward: -13.2000,                 loss: nan
env1_second_0:                 episode reward: 13.2000,                 loss: nan
Episode: 8961/10000 (89.6100%),                 avg. length: 3154.85,                last time consumption/overall running time: 835.8100s / 394879.8921 s
env0_first_0:                 episode reward: -15.4000,                 loss: 0.0363
env0_second_0:                 episode reward: 15.4000,                 loss: 0.0357
env1_first_0:                 episode reward: -13.9000,                 loss: nan
env1_second_0:                 episode reward: 13.9000,                 loss: nan
Episode: 8981/10000 (89.8100%),                 avg. length: 2958.8,                last time consumption/overall running time: 772.8029s / 395652.6950 s
env0_first_0:                 episode reward: -15.2500,                 loss: 0.0355
env0_second_0:                 episode reward: 15.2500,                 loss: 0.0354
env1_first_0:                 episode reward: -12.1000,                 loss: nan
env1_second_0:                 episode reward: 12.1000,                 loss: nan
Episode: 9001/10000 (90.0100%),                 avg. length: 2985.0,                last time consumption/overall running time: 795.4975s / 396448.1925 s
env0_first_0:                 episode reward: -12.3000,                 loss: 0.0377
env0_second_0:                 episode reward: 12.3000,                 loss: 0.0363
env1_first_0:                 episode reward: -12.3500,                 loss: nan
env1_second_0:                 episode reward: 12.3500,                 loss: nan
Episode: 9021/10000 (90.2100%),                 avg. length: 2969.35,                last time consumption/overall running time: 791.6267s / 397239.8191 s
env0_first_0:                 episode reward: -14.0500,                 loss: 0.0372
env0_second_0:                 episode reward: 14.0500,                 loss: 0.0363
env1_first_0:                 episode reward: -13.0500,                 loss: nan
env1_second_0:                 episode reward: 13.0500,                 loss: nan
Episode: 9041/10000 (90.4100%),                 avg. length: 3035.75,                last time consumption/overall running time: 807.4274s / 398047.2465 s
env0_first_0:                 episode reward: -13.5500,                 loss: 0.0370
env0_second_0:                 episode reward: 13.5500,                 loss: 0.0382
env1_first_0:                 episode reward: -11.9500,                 loss: nan
env1_second_0:                 episode reward: 11.9500,                 loss: nan
Episode: 9061/10000 (90.6100%),                 avg. length: 3038.2,                last time consumption/overall running time: 812.1734s / 398859.4199 s
env0_first_0:                 episode reward: -13.8000,                 loss: 0.0376
env0_second_0:                 episode reward: 13.8000,                 loss: 0.0367
env1_first_0:                 episode reward: -14.4000,                 loss: nan
env1_second_0:                 episode reward: 14.4000,                 loss: nan
Episode: 9081/10000 (90.8100%),                 avg. length: 3021.75,                last time consumption/overall running time: 816.4820s / 399675.9019 s
env0_first_0:                 episode reward: -13.7000,                 loss: 0.0374
env0_second_0:                 episode reward: 13.7000,                 loss: 0.0368
env1_first_0:                 episode reward: -12.5500,                 loss: nan
env1_second_0:                 episode reward: 12.5500,                 loss: nan
Episode: 9101/10000 (91.0100%),                 avg. length: 3088.8,                last time consumption/overall running time: 822.9152s / 400498.8171 s
env0_first_0:                 episode reward: -12.6500,                 loss: 0.0347
env0_second_0:                 episode reward: 12.6500,                 loss: 0.0350
env1_first_0:                 episode reward: -14.6000,                 loss: nan
env1_second_0:                 episode reward: 14.6000,                 loss: nan
Episode: 9121/10000 (91.2100%),                 avg. length: 2836.2,                last time consumption/overall running time: 753.5908s / 401252.4079 s
env0_first_0:                 episode reward: -14.8500,                 loss: 0.0342
env0_second_0:                 episode reward: 14.8500,                 loss: 0.0350
env1_first_0:                 episode reward: -14.6500,                 loss: nan
env1_second_0:                 episode reward: 14.6500,                 loss: nan
Episode: 9141/10000 (91.4100%),                 avg. length: 3080.65,                last time consumption/overall running time: 826.8311s / 402079.2390 s
env0_first_0:                 episode reward: -13.8000,                 loss: 0.0355
env0_second_0:                 episode reward: 13.8000,                 loss: 0.0361
env1_first_0:                 episode reward: -15.4500,                 loss: nan
env1_second_0:                 episode reward: 15.4500,                 loss: nan
Episode: 9161/10000 (91.6100%),                 avg. length: 2935.95,                last time consumption/overall running time: 773.2909s / 402852.5299 s
env0_first_0:                 episode reward: -14.3500,                 loss: 0.0357
env0_second_0:                 episode reward: 14.3500,                 loss: 0.0356
env1_first_0:                 episode reward: -12.3000,                 loss: nan
env1_second_0:                 episode reward: 12.3000,                 loss: nan
Episode: 9181/10000 (91.8100%),                 avg. length: 3054.9,                last time consumption/overall running time: 801.7805s / 403654.3103 s
env0_first_0:                 episode reward: -15.0000,                 loss: 0.0350
env0_second_0:                 episode reward: 15.0000,                 loss: 0.0351
env1_first_0:                 episode reward: -15.4500,                 loss: nan
env1_second_0:                 episode reward: 15.4500,                 loss: nan
Episode: 9201/10000 (92.0100%),                 avg. length: 3172.55,                last time consumption/overall running time: 838.7089s / 404493.0192 s
env0_first_0:                 episode reward: -15.2500,                 loss: 0.0351
env0_second_0:                 episode reward: 15.2500,                 loss: 0.0362
env1_first_0:                 episode reward: -15.8000,                 loss: nan
env1_second_0:                 episode reward: 15.8000,                 loss: nan
Episode: 9221/10000 (92.2100%),                 avg. length: 3155.35,                last time consumption/overall running time: 814.3171s / 405307.3363 s
env0_first_0:                 episode reward: -13.5000,                 loss: 0.0362
env0_second_0:                 episode reward: 13.5000,                 loss: 0.0351
env1_first_0:                 episode reward: -12.4000,                 loss: nan
env1_second_0:                 episode reward: 12.4000,                 loss: nan
Episode: 9241/10000 (92.4100%),                 avg. length: 3123.9,                last time consumption/overall running time: 823.1652s / 406130.5015 s
env0_first_0:                 episode reward: -16.6500,                 loss: 0.0353
env0_second_0:                 episode reward: 16.6500,                 loss: 0.0352
env1_first_0:                 episode reward: -13.5500,                 loss: nan
env1_second_0:                 episode reward: 13.5500,                 loss: nan
Episode: 9261/10000 (92.6100%),                 avg. length: 3046.45,                last time consumption/overall running time: 816.7328s / 406947.2343 s
env0_first_0:                 episode reward: -14.4000,                 loss: 0.0374
env0_second_0:                 episode reward: 14.4000,                 loss: 0.0357
env1_first_0:                 episode reward: -11.0000,                 loss: nan
env1_second_0:                 episode reward: 11.0000,                 loss: nan
Episode: 9281/10000 (92.8100%),                 avg. length: 3069.3,                last time consumption/overall running time: 817.5409s / 407764.7752 s
env0_first_0:                 episode reward: -14.5500,                 loss: 0.0372
env0_second_0:                 episode reward: 14.5500,                 loss: 0.0358
env1_first_0:                 episode reward: -12.0500,                 loss: nan
env1_second_0:                 episode reward: 12.0500,                 loss: nan
Episode: 9301/10000 (93.0100%),                 avg. length: 3229.3,                last time consumption/overall running time: 843.4672s / 408608.2424 s
env0_first_0:                 episode reward: -14.6500,                 loss: 0.0358
env0_second_0:                 episode reward: 14.6500,                 loss: 0.0381
env1_first_0:                 episode reward: -13.2000,                 loss: nan
env1_second_0:                 episode reward: 13.2000,                 loss: nan
Episode: 9321/10000 (93.2100%),                 avg. length: 3078.75,                last time consumption/overall running time: 831.4603s / 409439.7028 s
env0_first_0:                 episode reward: -12.8000,                 loss: 0.0362
env0_second_0:                 episode reward: 12.8000,                 loss: 0.0368
env1_first_0:                 episode reward: -12.1500,                 loss: nan
env1_second_0:                 episode reward: 12.1500,                 loss: nan
Episode: 9341/10000 (93.4100%),                 avg. length: 2794.6,                last time consumption/overall running time: 747.4130s / 410187.1158 s
env0_first_0:                 episode reward: -10.6500,                 loss: 0.0352
env0_second_0:                 episode reward: 10.6500,                 loss: 0.0353
env1_first_0:                 episode reward: -11.5500,                 loss: nan
env1_second_0:                 episode reward: 11.5500,                 loss: nan
Episode: 9361/10000 (93.6100%),                 avg. length: 3240.0,                last time consumption/overall running time: 836.0489s / 411023.1647 s
env0_first_0:                 episode reward: -17.3000,                 loss: 0.0364
env0_second_0:                 episode reward: 17.3000,                 loss: 0.0371
env1_first_0:                 episode reward: -14.6500,                 loss: nan
env1_second_0:                 episode reward: 14.6500,                 loss: nan
Episode: 9381/10000 (93.8100%),                 avg. length: 2995.25,                last time consumption/overall running time: 789.3756s / 411812.5403 s
env0_first_0:                 episode reward: -12.7000,                 loss: 0.0368
env0_second_0:                 episode reward: 12.7000,                 loss: 0.0372
env1_first_0:                 episode reward: -15.5500,                 loss: nan
env1_second_0:                 episode reward: 15.5500,                 loss: nan
Episode: 9401/10000 (94.0100%),                 avg. length: 2961.5,                last time consumption/overall running time: 797.6528s / 412610.1930 s
env0_first_0:                 episode reward: -11.2000,                 loss: 0.0371
env0_second_0:                 episode reward: 11.2000,                 loss: 0.0360
env1_first_0:                 episode reward: -13.2000,                 loss: nan
env1_second_0:                 episode reward: 13.2000,                 loss: nan
Episode: 9421/10000 (94.2100%),                 avg. length: 3108.65,                last time consumption/overall running time: 835.1883s / 413445.3814 s
env0_first_0:                 episode reward: -14.5500,                 loss: 0.0363
env0_second_0:                 episode reward: 14.5500,                 loss: 0.0355
env1_first_0:                 episode reward: -13.2000,                 loss: nan
env1_second_0:                 episode reward: 13.2000,                 loss: nan
Episode: 9441/10000 (94.4100%),                 avg. length: 3109.2,                last time consumption/overall running time: 822.3871s / 414267.7684 s
env0_first_0:                 episode reward: -12.4500,                 loss: 0.0356
env0_second_0:                 episode reward: 12.4500,                 loss: 0.0354
env1_first_0:                 episode reward: -13.5500,                 loss: nan
env1_second_0:                 episode reward: 13.5500,                 loss: nan
Episode: 9461/10000 (94.6100%),                 avg. length: 2957.35,                last time consumption/overall running time: 768.3726s / 415036.1410 s
env0_first_0:                 episode reward: -14.0000,                 loss: 0.0356
env0_second_0:                 episode reward: 14.0000,                 loss: 0.0370
env1_first_0:                 episode reward: -12.3000,                 loss: nan
env1_second_0:                 episode reward: 12.3000,                 loss: nan
Episode: 9481/10000 (94.8100%),                 avg. length: 2893.95,                last time consumption/overall running time: 763.8124s / 415799.9534 s
env0_first_0:                 episode reward: -12.3000,                 loss: 0.0355
env0_second_0:                 episode reward: 12.3000,                 loss: 0.0354
env1_first_0:                 episode reward: -12.5500,                 loss: nan
env1_second_0:                 episode reward: 12.5500,                 loss: nan
Episode: 9501/10000 (95.0100%),                 avg. length: 2941.65,                last time consumption/overall running time: 782.4883s / 416582.4417 s
env0_first_0:                 episode reward: -13.0500,                 loss: 0.0357
env0_second_0:                 episode reward: 13.0500,                 loss: 0.0348
env1_first_0:                 episode reward: -13.4500,                 loss: nan
env1_second_0:                 episode reward: 13.4500,                 loss: nan
Episode: 9521/10000 (95.2100%),                 avg. length: 3007.15,                last time consumption/overall running time: 775.2934s / 417357.7351 s
env0_first_0:                 episode reward: -11.5000,                 loss: 0.0377
env0_second_0:                 episode reward: 11.5000,                 loss: 0.0363
env1_first_0:                 episode reward: -12.7500,                 loss: nan
env1_second_0:                 episode reward: 12.7500,                 loss: nan
Episode: 9541/10000 (95.4100%),                 avg. length: 3101.25,                last time consumption/overall running time: 815.4357s / 418173.1709 s
env0_first_0:                 episode reward: -12.4000,                 loss: 0.0361
env0_second_0:                 episode reward: 12.4000,                 loss: 0.0362
env1_first_0:                 episode reward: -13.6000,                 loss: nan
env1_second_0:                 episode reward: 13.6000,                 loss: nan
Episode: 9561/10000 (95.6100%),                 avg. length: 3267.75,                last time consumption/overall running time: 872.8716s / 419046.0425 s
env0_first_0:                 episode reward: -13.8000,                 loss: 0.0340
env0_second_0:                 episode reward: 13.8000,                 loss: 0.0359
env1_first_0:                 episode reward: -13.1000,                 loss: nan
env1_second_0:                 episode reward: 13.1000,                 loss: nan
Episode: 9581/10000 (95.8100%),                 avg. length: 3064.6,                last time consumption/overall running time: 803.4823s / 419849.5248 s
env0_first_0:                 episode reward: -14.0500,                 loss: 0.0353
env0_second_0:                 episode reward: 14.0500,                 loss: 0.0336
env1_first_0:                 episode reward: -13.5500,                 loss: nan
env1_second_0:                 episode reward: 13.5500,                 loss: nan
Episode: 9601/10000 (96.0100%),                 avg. length: 2983.9,                last time consumption/overall running time: 806.6632s / 420656.1880 s
env0_first_0:                 episode reward: -15.0500,                 loss: 0.0349
env0_second_0:                 episode reward: 15.0500,                 loss: 0.0352
env1_first_0:                 episode reward: -14.3000,                 loss: nan
env1_second_0:                 episode reward: 14.3000,                 loss: nan
Episode: 9621/10000 (96.2100%),                 avg. length: 3145.55,                last time consumption/overall running time: 844.8744s / 421501.0624 s
env0_first_0:                 episode reward: -14.3500,                 loss: 0.0371
env0_second_0:                 episode reward: 14.3500,                 loss: 0.0355
env1_first_0:                 episode reward: -14.1000,                 loss: nan
env1_second_0:                 episode reward: 14.1000,                 loss: nan
Episode: 9641/10000 (96.4100%),                 avg. length: 2880.9,                last time consumption/overall running time: 740.8091s / 422241.8714 s
env0_first_0:                 episode reward: -12.4500,                 loss: 0.0366
env0_second_0:                 episode reward: 12.4500,                 loss: 0.0353
env1_first_0:                 episode reward: -8.8000,                 loss: nan
env1_second_0:                 episode reward: 8.8000,                 loss: nan
Episode: 9661/10000 (96.6100%),                 avg. length: 2978.05,                last time consumption/overall running time: 774.5159s / 423016.3873 s
env0_first_0:                 episode reward: -14.5000,                 loss: 0.0360
env0_second_0:                 episode reward: 14.5000,                 loss: 0.0368
env1_first_0:                 episode reward: -13.0000,                 loss: nan
env1_second_0:                 episode reward: 13.0000,                 loss: nan
Episode: 9681/10000 (96.8100%),                 avg. length: 3033.7,                last time consumption/overall running time: 767.6694s / 423784.0567 s
env0_first_0:                 episode reward: -12.2000,                 loss: 0.0364
env0_second_0:                 episode reward: 12.2000,                 loss: 0.0368
env1_first_0:                 episode reward: -13.9500,                 loss: nan
env1_second_0:                 episode reward: 13.9500,                 loss: nan
Episode: 9701/10000 (97.0100%),                 avg. length: 3178.05,                last time consumption/overall running time: 852.0683s / 424636.1251 s
env0_first_0:                 episode reward: -13.5500,                 loss: 0.0385
env0_second_0:                 episode reward: 13.5500,                 loss: 0.0361
env1_first_0:                 episode reward: -14.2500,                 loss: nan
env1_second_0:                 episode reward: 14.2500,                 loss: nan
Episode: 9721/10000 (97.2100%),                 avg. length: 3111.65,                last time consumption/overall running time: 807.0845s / 425443.2096 s
env0_first_0:                 episode reward: -12.4500,                 loss: 0.0373
env0_second_0:                 episode reward: 12.4500,                 loss: 0.0357
env1_first_0:                 episode reward: -12.2500,                 loss: nan
env1_second_0:                 episode reward: 12.2500,                 loss: nan
Episode: 9741/10000 (97.4100%),                 avg. length: 2941.25,                last time consumption/overall running time: 762.4623s / 426205.6719 s
env0_first_0:                 episode reward: -12.2000,                 loss: 0.0359
env0_second_0:                 episode reward: 12.2000,                 loss: 0.0368
env1_first_0:                 episode reward: -12.3500,                 loss: nan
env1_second_0:                 episode reward: 12.3500,                 loss: nan
Episode: 9761/10000 (97.6100%),                 avg. length: 3102.8,                last time consumption/overall running time: 823.1779s / 427028.8497 sLoad double_dunk_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
Load double_dunk_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

env0_first_0:                 episode reward: -15.8500,                 loss: 0.0355
env0_second_0:                 episode reward: 15.8500,                 loss: 0.0370
env1_first_0:                 episode reward: -13.3000,                 loss: nan
env1_second_0:                 episode reward: 13.3000,                 loss: nan
Episode: 9781/10000 (97.8100%),                 avg. length: 3118.5,                last time consumption/overall running time: 816.4932s / 427845.3429 s
env0_first_0:                 episode reward: -14.7000,                 loss: 0.0344
env0_second_0:                 episode reward: 14.7000,                 loss: 0.0350
env1_first_0:                 episode reward: -13.0500,                 loss: nan
env1_second_0:                 episode reward: 13.0500,                 loss: nan
Episode: 9801/10000 (98.0100%),                 avg. length: 3028.3,                last time consumption/overall running time: 816.7467s / 428662.0896 s
env0_first_0:                 episode reward: -11.0000,                 loss: 0.0350
env0_second_0:                 episode reward: 11.0000,                 loss: 0.0347
env1_first_0:                 episode reward: -14.1000,                 loss: nan
env1_second_0:                 episode reward: 14.1000,                 loss: nan
Episode: 9821/10000 (98.2100%),                 avg. length: 3084.35,                last time consumption/overall running time: 828.1688s / 429490.2584 s
env0_first_0:                 episode reward: -13.5000,                 loss: 0.0358
env0_second_0:                 episode reward: 13.5000,                 loss: 0.0367
env1_first_0:                 episode reward: -13.7000,                 loss: nan
env1_second_0:                 episode reward: 13.7000,                 loss: nan
Episode: 9841/10000 (98.4100%),                 avg. length: 3163.7,                last time consumption/overall running time: 841.1911s / 430331.4495 s
env0_first_0:                 episode reward: -15.2500,                 loss: 0.0374
env0_second_0:                 episode reward: 15.2500,                 loss: 0.0355
env1_first_0:                 episode reward: -12.1000,                 loss: nan
env1_second_0:                 episode reward: 12.1000,                 loss: nan
Episode: 9861/10000 (98.6100%),                 avg. length: 2994.3,                last time consumption/overall running time: 798.3604s / 431129.8099 s
env0_first_0:                 episode reward: -11.3000,                 loss: 0.0369
env0_second_0:                 episode reward: 11.3000,                 loss: 0.0359
env1_first_0:                 episode reward: -11.7500,                 loss: nan
env1_second_0:                 episode reward: 11.7500,                 loss: nan
Episode: 9881/10000 (98.8100%),                 avg. length: 2999.65,                last time consumption/overall running time: 804.9829s / 431934.7928 s
env0_first_0:                 episode reward: -12.7000,                 loss: 0.0362
env0_second_0:                 episode reward: 12.7000,                 loss: 0.0361
env1_first_0:                 episode reward: -12.6500,                 loss: nan
env1_second_0:                 episode reward: 12.6500,                 loss: nan
Episode: 9901/10000 (99.0100%),                 avg. length: 3013.6,                last time consumption/overall running time: 809.2392s / 432744.0321 s
env0_first_0:                 episode reward: -12.6500,                 loss: 0.0366
env0_second_0:                 episode reward: 12.6500,                 loss: 0.0368
env1_first_0:                 episode reward: -13.6500,                 loss: nan
env1_second_0:                 episode reward: 13.6500,                 loss: nan
Episode: 9921/10000 (99.2100%),                 avg. length: 3015.9,                last time consumption/overall running time: 808.8623s / 433552.8943 s
env0_first_0:                 episode reward: -13.0500,                 loss: 0.0361
env0_second_0:                 episode reward: 13.0500,                 loss: 0.0359
env1_first_0:                 episode reward: -13.0000,                 loss: nan
env1_second_0:                 episode reward: 13.0000,                 loss: nan
Episode: 9941/10000 (99.4100%),                 avg. length: 3102.1,                last time consumption/overall running time: 827.4834s / 434380.3777 s
env0_first_0:                 episode reward: -12.9500,                 loss: 0.0349
env0_second_0:                 episode reward: 12.9500,                 loss: 0.0342
env1_first_0:                 episode reward: -14.7500,                 loss: nan
env1_second_0:                 episode reward: 14.7500,                 loss: nan
Episode: 9961/10000 (99.6100%),                 avg. length: 2957.75,                last time consumption/overall running time: 769.0761s / 435149.4539 s
env0_first_0:                 episode reward: -12.4500,                 loss: 0.0365
env0_second_0:                 episode reward: 12.4500,                 loss: 0.0347
env1_first_0:                 episode reward: -14.5500,                 loss: nan
env1_second_0:                 episode reward: 14.5500,                 loss: nan
Episode: 9981/10000 (99.8100%),                 avg. length: 3044.2,                last time consumption/overall running time: 815.2162s / 435964.6700 s
env0_first_0:                 episode reward: -10.6500,                 loss: 0.0375
env0_second_0:                 episode reward: 10.6500,                 loss: 0.0368
env1_first_0:                 episode reward: -13.5500,                 loss: nan
env1_second_0:                 episode reward: 13.5500,                 loss: nan
