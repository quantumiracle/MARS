pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
boxing_v1 pettingzoo
Load boxing_v1 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
random seed: 23
<mars.env.wrappers.mars_wrappers.Dict2TupleWrapper object at 0x7f3f2482e2b0>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  ./data/model/20220409_1833/pettingzoo_boxing_v1_nash_dqn_exploiter/50000_0
Arguments:  {'env_name': 'boxing_v1', 'env_type': 'pettingzoo', 'num_envs': 1, 'ram': True, 'seed': 'random', 'algorithm': 'NashDQNExploiter', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 100000, 'exploiter_update_itr': 3}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': './data/model/20220409_1833/pettingzoo_boxing_v1_nash_dqn_exploiter/50000_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn_exploiter', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}, 'against_baseline': False}
Save models to : /home/zihan/research/MARS/data/model/20220409_1833_exploit/pettingzoo_boxing_v1_nash_dqn_exploiter. 
 Save logs to: /home/zihan/research/MARS/data/log/20220409_1833_exploit/pettingzoo_boxing_v1_nash_dqn_exploiter.
Episode: 1/10000 (0.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 6.6236s / 6.6236 s
first_0:                 episode reward: 3.0000,                 loss: nan
second_0:                 episode reward: -3.0000,                 loss: 0.0255
Episode: 21/10000 (0.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 138.6782s / 145.3018 s
first_0:                 episode reward: 2.5000,                 loss: nan
second_0:                 episode reward: -2.5000,                 loss: 0.0187
Episode: 41/10000 (0.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 139.2239s / 284.5257 s
first_0:                 episode reward: 4.6500,                 loss: nan
second_0:                 episode reward: -4.6500,                 loss: 0.0261
Episode: 61/10000 (0.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 139.1013s / 423.6271 s
first_0:                 episode reward: 3.9000,                 loss: nan
second_0:                 episode reward: -3.9000,                 loss: 0.0300
Episode: 81/10000 (0.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 138.7211s / 562.3482 s
first_0:                 episode reward: 4.7500,                 loss: nan
second_0:                 episode reward: -4.7500,                 loss: 0.0299
Episode: 101/10000 (1.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 139.9376s / 702.2857 s
first_0:                 episode reward: 2.4000,                 loss: nan
second_0:                 episode reward: -2.4000,                 loss: 0.0238
Episode: 121/10000 (1.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 139.9135s / 842.1993 s
first_0:                 episode reward: 5.8000,                 loss: nan
second_0:                 episode reward: -5.8000,                 loss: 0.0168
Episode: 141/10000 (1.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 140.2407s / 982.4399 s
first_0:                 episode reward: 3.5500,                 loss: nan
second_0:                 episode reward: -3.5500,                 loss: 0.0173
Episode: 161/10000 (1.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 141.8222s / 1124.2621 s
first_0:                 episode reward: 2.4500,                 loss: nan
second_0:                 episode reward: -2.4500,                 loss: 0.0160
Episode: 181/10000 (1.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 141.3843s / 1265.6464 s
first_0:                 episode reward: 1.0000,                 loss: nan
second_0:                 episode reward: -1.0000,                 loss: 0.0137
Episode: 201/10000 (2.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 143.6841s / 1409.3305 s
first_0:                 episode reward: 1.6500,                 loss: nan
second_0:                 episode reward: -1.6500,                 loss: 0.0192
Episode: 221/10000 (2.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 141.6309s / 1550.9614 s
first_0:                 episode reward: 0.7500,                 loss: nan
second_0:                 episode reward: -0.7500,                 loss: 0.0148
Episode: 241/10000 (2.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 144.0237s / 1694.9851 s
first_0:                 episode reward: 0.8500,                 loss: nan
second_0:                 episode reward: -0.8500,                 loss: 0.0107
Episode: 261/10000 (2.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 144.4907s / 1839.4758 s
first_0:                 episode reward: 0.5000,                 loss: nan
second_0:                 episode reward: -0.5000,                 loss: 0.0091
Episode: 281/10000 (2.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 145.4404s / 1984.9162 s
first_0:                 episode reward: 0.6000,                 loss: nan
second_0:                 episode reward: -0.6000,                 loss: 0.0076
Episode: 301/10000 (3.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 145.6135s / 2130.5297 s
first_0:                 episode reward: -0.2000,                 loss: nan
second_0:                 episode reward: 0.2000,                 loss: 0.0076
Episode: 321/10000 (3.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 146.6627s / 2277.1924 s
first_0:                 episode reward: -0.3000,                 loss: nan
second_0:                 episode reward: 0.3000,                 loss: 0.0071
Episode: 341/10000 (3.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 147.8477s / 2425.0401 s
first_0:                 episode reward: -0.3500,                 loss: nan
second_0:                 episode reward: 0.3500,                 loss: 0.0069
Episode: 361/10000 (3.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 148.4880s / 2573.5281 s
first_0:                 episode reward: 0.3500,                 loss: nan
second_0:                 episode reward: -0.3500,                 loss: 0.0061
Episode: 381/10000 (3.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 148.7124s / 2722.2405 s
first_0:                 episode reward: -0.9000,                 loss: nan
second_0:                 episode reward: 0.9000,                 loss: 0.0058
Episode: 401/10000 (4.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 148.1700s / 2870.4105 s
first_0:                 episode reward: -0.1500,                 loss: nan
second_0:                 episode reward: 0.1500,                 loss: 0.0056
Episode: 421/10000 (4.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 148.8063s / 3019.2168 s
first_0:                 episode reward: 0.0500,                 loss: nan
second_0:                 episode reward: -0.0500,                 loss: 0.0055
Episode: 441/10000 (4.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.9853s / 3170.2021 s
first_0:                 episode reward: -1.1500,                 loss: nan
second_0:                 episode reward: 1.1500,                 loss: 0.0056
Episode: 461/10000 (4.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 148.1582s / 3318.3603 s
first_0:                 episode reward: 0.0500,                 loss: nan
second_0:                 episode reward: -0.0500,                 loss: 0.0063
Episode: 481/10000 (4.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.0356s / 3468.3960 s
first_0:                 episode reward: -1.3500,                 loss: nan
second_0:                 episode reward: 1.3500,                 loss: 0.0067
Episode: 501/10000 (5.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.0083s / 3618.4042 s
first_0:                 episode reward: -0.0500,                 loss: nan
second_0:                 episode reward: 0.0500,                 loss: 0.0071
Episode: 521/10000 (5.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 148.7776s / 3767.1818 s
first_0:                 episode reward: -0.4500,                 loss: nan
second_0:                 episode reward: 0.4500,                 loss: 0.0083
Episode: 541/10000 (5.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.3084s / 3917.4902 s
first_0:                 episode reward: -1.2500,                 loss: nan
second_0:                 episode reward: 1.2500,                 loss: 0.0087
Episode: 561/10000 (5.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 149.7780s / 4067.2682 s
first_0:                 episode reward: -4.1000,                 loss: nan
second_0:                 episode reward: 4.1000,                 loss: 0.0096
Episode: 581/10000 (5.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 153.1260s / 4220.3942 s
first_0:                 episode reward: -3.8000,                 loss: nan
second_0:                 episode reward: 3.8000,                 loss: 0.0105
Episode: 601/10000 (6.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.4073s / 4370.8015 s
first_0:                 episode reward: -1.9000,                 loss: nan
second_0:                 episode reward: 1.9000,                 loss: 0.0121
Episode: 621/10000 (6.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.7109s / 4521.5124 s
first_0:                 episode reward: -3.1000,                 loss: nan
second_0:                 episode reward: 3.1000,                 loss: 0.0131
Episode: 641/10000 (6.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 152.2830s / 4673.7954 s
first_0:                 episode reward: -1.5500,                 loss: nan
second_0:                 episode reward: 1.5500,                 loss: 0.0155
Episode: 661/10000 (6.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.9440s / 4824.7394 s
first_0:                 episode reward: -5.3500,                 loss: nan
second_0:                 episode reward: 5.3500,                 loss: 0.0170
Episode: 681/10000 (6.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.6103s / 4975.3497 s
first_0:                 episode reward: -10.2000,                 loss: nan
second_0:                 episode reward: 10.2000,                 loss: 0.0207
Episode: 701/10000 (7.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 149.9622s / 5125.3119 s
first_0:                 episode reward: -6.1500,                 loss: nan
second_0:                 episode reward: 6.1500,                 loss: 0.0218
Episode: 721/10000 (7.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 152.3764s / 5277.6883 s
first_0:                 episode reward: -15.0500,                 loss: nan
second_0:                 episode reward: 15.0500,                 loss: 0.0245
Episode: 741/10000 (7.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.0702s / 5427.7585 s
first_0:                 episode reward: -22.8000,                 loss: nan
second_0:                 episode reward: 22.8000,                 loss: 0.0309
Episode: 761/10000 (7.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 151.2066s / 5578.9651 s
first_0:                 episode reward: -25.2000,                 loss: nan
second_0:                 episode reward: 25.2000,                 loss: 0.0319
Episode: 781/10000 (7.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 151.0045s / 5729.9697 s
first_0:                 episode reward: -18.4000,                 loss: nan
second_0:                 episode reward: 18.4000,                 loss: 0.0396
Episode: 801/10000 (8.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 151.6544s / 5881.6241 s
first_0:                 episode reward: -27.5000,                 loss: nan
second_0:                 episode reward: 27.5000,                 loss: 0.0446
Episode: 821/10000 (8.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 152.3163s / 6033.9404 s
first_0:                 episode reward: -40.8500,                 loss: nan
second_0:                 episode reward: 40.8500,                 loss: 0.0515
Episode: 841/10000 (8.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 151.1892s / 6185.1296 s
first_0:                 episode reward: -42.6000,                 loss: nan
second_0:                 episode reward: 42.6000,                 loss: 0.0593
Episode: 861/10000 (8.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 151.0819s / 6336.2114 s
first_0:                 episode reward: -45.6000,                 loss: nan
second_0:                 episode reward: 45.6000,                 loss: 0.0582
Episode: 881/10000 (8.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.5762s / 6486.7876 s
first_0:                 episode reward: -51.4000,                 loss: nan
second_0:                 episode reward: 51.4000,                 loss: 0.0646
Episode: 901/10000 (9.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 149.2833s / 6636.0710 s
first_0:                 episode reward: -52.6500,                 loss: nan
second_0:                 episode reward: 52.6500,                 loss: 0.0699
Episode: 921/10000 (9.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 152.2193s / 6788.2902 s
first_0:                 episode reward: -62.6500,                 loss: nan
second_0:                 episode reward: 62.6500,                 loss: 0.0777
Episode: 941/10000 (9.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 149.7073s / 6937.9975 s
first_0:                 episode reward: -80.8500,                 loss: nan
second_0:                 episode reward: 80.8500,                 loss: 0.0894
Episode: 961/10000 (9.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 152.5764s / 7090.5739 s
first_0:                 episode reward: -83.9500,                 loss: nan
second_0:                 episode reward: 83.9500,                 loss: 0.0987
Episode: 981/10000 (9.8100%),                 avg. length: 297.75,                last time consumption/overall running time: 152.1845s / 7242.7584 s
first_0:                 episode reward: -81.9500,                 loss: nan
second_0:                 episode reward: 81.9500,                 loss: 0.1075
Episode: 1001/10000 (10.0100%),                 avg. length: 297.3,                last time consumption/overall running time: 150.0134s / 7392.7718 s
first_0:                 episode reward: -89.7500,                 loss: nan
second_0:                 episode reward: 89.7500,                 loss: 0.1204
Episode: 1021/10000 (10.2100%),                 avg. length: 285.45,                last time consumption/overall running time: 143.9609s / 7536.7327 s
first_0:                 episode reward: -95.8500,                 loss: nan
second_0:                 episode reward: 95.8500,                 loss: 0.1263
Episode: 1041/10000 (10.4100%),                 avg. length: 288.3,                last time consumption/overall running time: 146.4430s / 7683.1757 s
first_0:                 episode reward: -93.1500,                 loss: nan
second_0:                 episode reward: 93.1500,                 loss: 0.1266
Episode: 1061/10000 (10.6100%),                 avg. length: 280.35,                last time consumption/overall running time: 142.7058s / 7825.8815 s
first_0:                 episode reward: -92.5000,                 loss: nan
second_0:                 episode reward: 92.5000,                 loss: 0.1382
Episode: 1081/10000 (10.8100%),                 avg. length: 274.25,                last time consumption/overall running time: 138.9454s / 7964.8269 s
first_0:                 episode reward: -90.5500,                 loss: nan
second_0:                 episode reward: 90.5500,                 loss: 0.1454
Episode: 1101/10000 (11.0100%),                 avg. length: 282.65,                last time consumption/overall running time: 143.3638s / 8108.1907 s
first_0:                 episode reward: -96.3500,                 loss: nan
second_0:                 episode reward: 96.3500,                 loss: 0.1505
Episode: 1121/10000 (11.2100%),                 avg. length: 265.15,                last time consumption/overall running time: 134.6369s / 8242.8276 s
first_0:                 episode reward: -98.0000,                 loss: nan
second_0:                 episode reward: 98.0000,                 loss: 0.1482
Episode: 1141/10000 (11.4100%),                 avg. length: 267.0,                last time consumption/overall running time: 135.4537s / 8378.2813 s
first_0:                 episode reward: -98.7500,                 loss: nan
second_0:                 episode reward: 98.7500,                 loss: 0.1503
Episode: 1161/10000 (11.6100%),                 avg. length: 259.9,                last time consumption/overall running time: 133.1973s / 8511.4786 s
first_0:                 episode reward: -92.5500,                 loss: nan
second_0:                 episode reward: 92.5500,                 loss: 0.1544
Episode: 1181/10000 (11.8100%),                 avg. length: 248.2,                last time consumption/overall running time: 126.5686s / 8638.0472 s
first_0:                 episode reward: -99.1000,                 loss: nan
second_0:                 episode reward: 99.1000,                 loss: 0.1484
Episode: 1201/10000 (12.0100%),                 avg. length: 258.5,                last time consumption/overall running time: 130.4810s / 8768.5283 s
first_0:                 episode reward: -97.7000,                 loss: nan
second_0:                 episode reward: 97.7000,                 loss: 0.1401
Episode: 1221/10000 (12.2100%),                 avg. length: 257.85,                last time consumption/overall running time: 130.7260s / 8899.2542 s
first_0:                 episode reward: -98.5500,                 loss: nan
second_0:                 episode reward: 98.5500,                 loss: 0.1476
Episode: 1241/10000 (12.4100%),                 avg. length: 247.7,                last time consumption/overall running time: 124.5558s / 9023.8101 s
first_0:                 episode reward: -98.8500,                 loss: nan
second_0:                 episode reward: 98.8500,                 loss: 0.1503
Episode: 1261/10000 (12.6100%),                 avg. length: 253.2,                last time consumption/overall running time: 127.0777s / 9150.8877 s
first_0:                 episode reward: -98.8500,                 loss: nan
second_0:                 episode reward: 98.8500,                 loss: 0.1487
Episode: 1281/10000 (12.8100%),                 avg. length: 252.5,                last time consumption/overall running time: 130.8372s / 9281.7249 s
first_0:                 episode reward: -98.0000,                 loss: nan
second_0:                 episode reward: 98.0000,                 loss: 0.1513
Episode: 1301/10000 (13.0100%),                 avg. length: 256.7,                last time consumption/overall running time: 130.6978s / 9412.4227 s
first_0:                 episode reward: -98.8500,                 loss: nan
second_0:                 episode reward: 98.8500,                 loss: 0.1596
Episode: 1321/10000 (13.2100%),                 avg. length: 247.95,                last time consumption/overall running time: 126.6177s / 9539.0404 s
first_0:                 episode reward: -99.6500,                 loss: nan
second_0:                 episode reward: 99.6500,                 loss: 0.1642
Episode: 1341/10000 (13.4100%),                 avg. length: 236.8,                last time consumption/overall running time: 119.4984s / 9658.5388 s
first_0:                 episode reward: -99.7000,                 loss: nan
second_0:                 episode reward: 99.7000,                 loss: 0.1655
Episode: 1361/10000 (13.6100%),                 avg. length: 242.55,                last time consumption/overall running time: 124.9888s / 9783.5277 s
first_0:                 episode reward: -99.5000,                 loss: nan
second_0:                 episode reward: 99.5000,                 loss: 0.1735
Episode: 1381/10000 (13.8100%),                 avg. length: 239.95,                last time consumption/overall running time: 121.4447s / 9904.9723 s
first_0:                 episode reward: -99.5000,                 loss: nan
second_0:                 episode reward: 99.5000,                 loss: 0.1794
Episode: 1401/10000 (14.0100%),                 avg. length: 239.15,                last time consumption/overall running time: 121.3722s / 10026.3445 s
first_0:                 episode reward: -99.3000,                 loss: nan
second_0:                 episode reward: 99.3000,                 loss: 0.1757
Episode: 1421/10000 (14.2100%),                 avg. length: 237.3,                last time consumption/overall running time: 118.9831s / 10145.3276 s
first_0:                 episode reward: -94.4000,                 loss: nan
second_0:                 episode reward: 94.4000,                 loss: 0.1691
Episode: 1441/10000 (14.4100%),                 avg. length: 240.25,                last time consumption/overall running time: 122.3084s / 10267.6359 s
first_0:                 episode reward: -99.3500,                 loss: nan
second_0:                 episode reward: 99.3500,                 loss: 0.1786
Episode: 1461/10000 (14.6100%),                 avg. length: 247.4,                last time consumption/overall running time: 125.8794s / 10393.5154 s
first_0:                 episode reward: -93.8500,                 loss: nan
second_0:                 episode reward: 93.8500,                 loss: 0.1726
Episode: 1481/10000 (14.8100%),                 avg. length: 250.9,                last time consumption/overall running time: 126.5691s / 10520.0844 s
first_0:                 episode reward: -88.7000,                 loss: nan
second_0:                 episode reward: 88.7000,                 loss: 0.1730
Episode: 1501/10000 (15.0100%),                 avg. length: 235.9,                last time consumption/overall running time: 119.9291s / 10640.0135 s
first_0:                 episode reward: -99.6500,                 loss: nan
second_0:                 episode reward: 99.6500,                 loss: 0.1694
Episode: 1521/10000 (15.2100%),                 avg. length: 235.9,                last time consumption/overall running time: 118.8606s / 10758.8741 s
first_0:                 episode reward: -99.2500,                 loss: nan
second_0:                 episode reward: 99.2500,                 loss: 0.1752
Episode: 1541/10000 (15.4100%),                 avg. length: 242.25,                last time consumption/overall running time: 123.9013s / 10882.7754 s
first_0:                 episode reward: -94.4000,                 loss: nan
second_0:                 episode reward: 94.4000,                 loss: 0.1762
Episode: 1561/10000 (15.6100%),                 avg. length: 232.0,                last time consumption/overall running time: 118.7603s / 11001.5357 s
first_0:                 episode reward: -94.8000,                 loss: nan
second_0:                 episode reward: 94.8000,                 loss: 0.1760
Episode: 1581/10000 (15.8100%),                 avg. length: 233.25,                last time consumption/overall running time: 119.1547s / 11120.6904 s
first_0:                 episode reward: -99.7500,                 loss: nan
second_0:                 episode reward: 99.7500,                 loss: 0.1785
Episode: 1601/10000 (16.0100%),                 avg. length: 242.25,                last time consumption/overall running time: 124.1933s / 11244.8837 s
first_0:                 episode reward: -99.4000,                 loss: nan
second_0:                 episode reward: 99.4000,                 loss: 0.1807
Episode: 1621/10000 (16.2100%),                 avg. length: 231.2,                last time consumption/overall running time: 116.1265s / 11361.0102 s
first_0:                 episode reward: -99.9500,                 loss: nan
second_0:                 episode reward: 99.9500,                 loss: 0.1822
Episode: 1641/10000 (16.4100%),                 avg. length: 246.3,                last time consumption/overall running time: 126.0550s / 11487.0652 s
first_0:                 episode reward: -99.0500,                 loss: nan
second_0:                 episode reward: 99.0500,                 loss: 0.1770
Episode: 1661/10000 (16.6100%),                 avg. length: 227.4,                last time consumption/overall running time: 114.9637s / 11602.0289 s
first_0:                 episode reward: -99.7500,                 loss: nan
second_0:                 episode reward: 99.7500,                 loss: 0.1776
Episode: 1681/10000 (16.8100%),                 avg. length: 230.85,                last time consumption/overall running time: 117.8485s / 11719.8774 s
first_0:                 episode reward: -99.7500,                 loss: nan
second_0:                 episode reward: 99.7500,                 loss: 0.1671
Episode: 1701/10000 (17.0100%),                 avg. length: 236.9,                last time consumption/overall running time: 119.2487s / 11839.1262 s
first_0:                 episode reward: -99.3000,                 loss: nan
second_0:                 episode reward: 99.3000,                 loss: 0.1707
Episode: 1721/10000 (17.2100%),                 avg. length: 228.15,                last time consumption/overall running time: 115.2579s / 11954.3841 s
first_0:                 episode reward: -99.7500,                 loss: nan
second_0:                 episode reward: 99.7500,                 loss: 0.1681
Episode: 1741/10000 (17.4100%),                 avg. length: 240.5,                last time consumption/overall running time: 122.2847s / 12076.6688 s
first_0:                 episode reward: -94.6000,                 loss: nan
second_0:                 episode reward: 94.6000,                 loss: 0.1697
Episode: 1761/10000 (17.6100%),                 avg. length: 233.8,                last time consumption/overall running time: 117.7924s / 12194.4612 s
first_0:                 episode reward: -99.4500,                 loss: nan
second_0:                 episode reward: 99.4500,                 loss: 0.1691
Episode: 1781/10000 (17.8100%),                 avg. length: 238.95,                last time consumption/overall running time: 121.8173s / 12316.2785 s
first_0:                 episode reward: -89.0000,                 loss: nan
second_0:                 episode reward: 89.0000,                 loss: 0.1683
Episode: 1801/10000 (18.0100%),                 avg. length: 241.05,                last time consumption/overall running time: 123.7089s / 12439.9874 s
first_0:                 episode reward: -94.1500,                 loss: nan
second_0:                 episode reward: 94.1500,                 loss: 0.1634
Episode: 1821/10000 (18.2100%),                 avg. length: 239.65,                last time consumption/overall running time: 123.3055s / 12563.2929 s
first_0:                 episode reward: -94.2000,                 loss: nan
second_0:                 episode reward: 94.2000,                 loss: 0.1624
Episode: 1841/10000 (18.4100%),                 avg. length: 243.1,                last time consumption/overall running time: 124.3660s / 12687.6589 s
first_0:                 episode reward: -99.3500,                 loss: nan
second_0:                 episode reward: 99.3500,                 loss: 0.1590
Episode: 1861/10000 (18.6100%),                 avg. length: 229.95,                last time consumption/overall running time: 113.6881s / 12801.3471 s
first_0:                 episode reward: -99.7000,                 loss: nan
second_0:                 episode reward: 99.7000,                 loss: 0.1634
Episode: 1881/10000 (18.8100%),                 avg. length: 237.8,                last time consumption/overall running time: 120.8840s / 12922.2310 s
first_0:                 episode reward: -99.4000,                 loss: nan
second_0:                 episode reward: 99.4000,                 loss: 0.1648
Episode: 1901/10000 (19.0100%),                 avg. length: 240.05,                last time consumption/overall running time: 121.8226s / 13044.0537 s
first_0:                 episode reward: -99.4500,                 loss: nan
second_0:                 episode reward: 99.4500,                 loss: 0.1591
Episode: 1921/10000 (19.2100%),                 avg. length: 242.95,                last time consumption/overall running time: 125.1462s / 13169.1999 s
first_0:                 episode reward: -98.9000,                 loss: nan
second_0:                 episode reward: 98.9000,                 loss: 0.1530
Episode: 1941/10000 (19.4100%),                 avg. length: 255.6,                last time consumption/overall running time: 130.5781s / 13299.7780 s
first_0:                 episode reward: -92.5500,                 loss: nan
second_0:                 episode reward: 92.5500,                 loss: 0.1543
Episode: 1961/10000 (19.6100%),                 avg. length: 245.4,                last time consumption/overall running time: 125.6498s / 13425.4278 s