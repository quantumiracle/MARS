pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
pong_v2 pettingzoo
Load pong_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(6)
random seed: 796
<mars.env.wrappers.mars_wrappers.Dict2TupleWrapper object at 0x7f9db143b3c8>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  ./data/model/20220429_0152/pettingzoo_pong_v2_nash_dqn_exploiter/1_0
Arguments:  {'env_name': 'pong_v2', 'env_type': 'pettingzoo', 'num_envs': 1, 'ram': True, 'seed': 'random', 'algorithm': 'NashDQNExploiter', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 100000, 'exploiter_update_itr': 3}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 50000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': './data/model/20220429_0152/pettingzoo_pong_v2_nash_dqn_exploiter/1_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn_exploiter', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}, 'against_baseline': False, 'idx_exploited_model': 0}
Save models to : /home/zihan/research/MARS/data/model/20220429_0152_exploit_first_4/pettingzoo_pong_v2_nash_dqn_exploiter. 
 Save logs to: /home/zihan/research/MARS/data/log/20220429_0152_exploit_first_4/pettingzoo_pong_v2_nash_dqn_exploiter.
Episode: 1/50000 (0.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 8.6906s / 8.6906 s
first_0:                 episode reward: 5.0000,                 loss: nan
second_0:                 episode reward: -5.0000,                 loss: 0.1429
Episode: 21/50000 (0.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 50.9679s / 59.6585 s
first_0:                 episode reward: 5.5000,                 loss: nan
second_0:                 episode reward: -5.5000,                 loss: 0.0779
Episode: 41/50000 (0.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 51.7771s / 111.4356 s
first_0:                 episode reward: 4.9000,                 loss: nan
second_0:                 episode reward: -4.9000,                 loss: 0.0323
Episode: 61/50000 (0.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 49.8912s / 161.3268 s
first_0:                 episode reward: 4.6500,                 loss: nan
second_0:                 episode reward: -4.6500,                 loss: 0.0268
Episode: 81/50000 (0.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 52.1623s / 213.4891 s
first_0:                 episode reward: 5.0500,                 loss: nan
second_0:                 episode reward: -5.0500,                 loss: 0.0213
Episode: 101/50000 (0.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 53.7120s / 267.2011 s
first_0:                 episode reward: 4.0500,                 loss: nan
second_0:                 episode reward: -4.0500,                 loss: 0.0230
Episode: 121/50000 (0.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 53.2622s / 320.4633 s
first_0:                 episode reward: 5.1500,                 loss: nan
second_0:                 episode reward: -5.1500,                 loss: 0.0232
Episode: 141/50000 (0.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 55.5716s / 376.0349 s
first_0:                 episode reward: 6.4500,                 loss: nan
second_0:                 episode reward: -6.4500,                 loss: 0.0180
Episode: 161/50000 (0.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 56.5709s / 432.6059 s
first_0:                 episode reward: 6.6500,                 loss: nan
second_0:                 episode reward: -6.6500,                 loss: 0.0172
Episode: 181/50000 (0.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 58.3252s / 490.9311 s
first_0:                 episode reward: 3.6500,                 loss: nan
second_0:                 episode reward: -3.6500,                 loss: 0.0185
Episode: 201/50000 (0.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 57.9441s / 548.8752 s
first_0:                 episode reward: 4.2500,                 loss: nan
second_0:                 episode reward: -4.2500,                 loss: 0.0188
Episode: 221/50000 (0.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 60.2819s / 609.1570 s
first_0:                 episode reward: 5.3500,                 loss: nan
second_0:                 episode reward: -5.3500,                 loss: 0.0164
Episode: 241/50000 (0.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 61.3131s / 670.4701 s
first_0:                 episode reward: 5.2500,                 loss: nan
second_0:                 episode reward: -5.2500,                 loss: 0.0164
Episode: 261/50000 (0.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 62.8694s / 733.3396 s
first_0:                 episode reward: 4.7000,                 loss: nan
second_0:                 episode reward: -4.7000,                 loss: 0.0179
Episode: 281/50000 (0.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 64.8954s / 798.2350 s
first_0:                 episode reward: 3.8000,                 loss: nan
second_0:                 episode reward: -3.8000,                 loss: 0.0170
Episode: 301/50000 (0.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 65.3325s / 863.5675 s
first_0:                 episode reward: 3.4500,                 loss: nan
second_0:                 episode reward: -3.4500,                 loss: 0.0178
Episode: 321/50000 (0.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 67.3411s / 930.9086 s
first_0:                 episode reward: 2.9500,                 loss: nan
second_0:                 episode reward: -2.9500,                 loss: 0.0174
Episode: 341/50000 (0.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 68.1821s / 999.0907 s
first_0:                 episode reward: 3.1000,                 loss: nan
second_0:                 episode reward: -3.1000,                 loss: 0.0169
Episode: 361/50000 (0.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 68.9894s / 1068.0801 s
first_0:                 episode reward: 3.2000,                 loss: nan
second_0:                 episode reward: -3.2000,                 loss: 0.0176
Episode: 381/50000 (0.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 68.5784s / 1136.6585 s
first_0:                 episode reward: 2.3000,                 loss: nan
second_0:                 episode reward: -2.3000,                 loss: 0.0206
Episode: 401/50000 (0.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 68.8175s / 1205.4759 s
first_0:                 episode reward: 3.7000,                 loss: nan
second_0:                 episode reward: -3.7000,                 loss: 0.0237
Episode: 421/50000 (0.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 69.1918s / 1274.6677 s
first_0:                 episode reward: 3.1000,                 loss: nan
second_0:                 episode reward: -3.1000,                 loss: 0.0268
Episode: 441/50000 (0.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 69.1602s / 1343.8279 s
first_0:                 episode reward: 3.6500,                 loss: nan
second_0:                 episode reward: -3.6500,                 loss: 0.0283
Episode: 461/50000 (0.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 68.5985s / 1412.4264 s
first_0:                 episode reward: 3.1000,                 loss: nan
second_0:                 episode reward: -3.1000,                 loss: 0.0264
Episode: 481/50000 (0.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 68.3671s / 1480.7935 s
first_0:                 episode reward: 2.1500,                 loss: nan
second_0:                 episode reward: -2.1500,                 loss: 0.0257
Episode: 501/50000 (1.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 68.4937s / 1549.2872 s
first_0:                 episode reward: 2.4500,                 loss: nan
second_0:                 episode reward: -2.4500,                 loss: 0.0238
Episode: 521/50000 (1.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 68.9001s / 1618.1873 s
first_0:                 episode reward: 2.7000,                 loss: nan
second_0:                 episode reward: -2.7000,                 loss: 0.0191
Episode: 541/50000 (1.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 68.7376s / 1686.9249 s
first_0:                 episode reward: 2.7000,                 loss: nan
second_0:                 episode reward: -2.7000,                 loss: 0.0152
Episode: 561/50000 (1.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 68.9586s / 1755.8835 s
first_0:                 episode reward: 5.3000,                 loss: nan
second_0:                 episode reward: -5.3000,                 loss: 0.0160
Episode: 581/50000 (1.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 68.7414s / 1824.6249 s
first_0:                 episode reward: 7.7000,                 loss: nan
second_0:                 episode reward: -7.7000,                 loss: 0.0157
Episode: 601/50000 (1.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 69.7284s / 1894.3533 s
first_0:                 episode reward: 7.1500,                 loss: nan
second_0:                 episode reward: -7.1500,                 loss: 0.0157
Episode: 621/50000 (1.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 69.1413s / 1963.4947 s
first_0:                 episode reward: 7.9500,                 loss: nan
second_0:                 episode reward: -7.9500,                 loss: 0.0153
Episode: 641/50000 (1.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 69.3007s / 2032.7953 s
first_0:                 episode reward: 7.7500,                 loss: nan
second_0:                 episode reward: -7.7500,                 loss: 0.0146
Episode: 661/50000 (1.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 68.7225s / 2101.5178 s
first_0:                 episode reward: 6.0500,                 loss: nan
second_0:                 episode reward: -6.0500,                 loss: 0.0158
Episode: 681/50000 (1.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 68.9475s / 2170.4653 s
first_0:                 episode reward: 3.4000,                 loss: nan
second_0:                 episode reward: -3.4000,                 loss: 0.0158
Episode: 701/50000 (1.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 69.7635s / 2240.2287 s
first_0:                 episode reward: 3.6000,                 loss: nan
second_0:                 episode reward: -3.6000,                 loss: 0.0166
Episode: 721/50000 (1.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 69.3726s / 2309.6013 s
first_0:                 episode reward: 2.5500,                 loss: nan
second_0:                 episode reward: -2.5500,                 loss: 0.0162
Episode: 741/50000 (1.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 69.8378s / 2379.4391 s
first_0:                 episode reward: 2.9000,                 loss: nan
second_0:                 episode reward: -2.9000,                 loss: 0.0171
Episode: 761/50000 (1.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 69.1261s / 2448.5652 s
first_0:                 episode reward: 2.6000,                 loss: nan
second_0:                 episode reward: -2.6000,                 loss: 0.0165
Episode: 781/50000 (1.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 69.7974s / 2518.3626 s
first_0:                 episode reward: 3.4500,                 loss: nan
second_0:                 episode reward: -3.4500,                 loss: 0.0158
Episode: 801/50000 (1.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 69.6190s / 2587.9816 s
first_0:                 episode reward: 2.6000,                 loss: nan
second_0:                 episode reward: -2.6000,                 loss: 0.0159
Episode: 821/50000 (1.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 69.3923s / 2657.3739 s
first_0:                 episode reward: 2.3000,                 loss: nan
second_0:                 episode reward: -2.3000,                 loss: 0.0177
Episode: 841/50000 (1.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 69.1679s / 2726.5418 s
first_0:                 episode reward: 2.1500,                 loss: nan
second_0:                 episode reward: -2.1500,                 loss: 0.0190
Episode: 861/50000 (1.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 69.5258s / 2796.0676 s
first_0:                 episode reward: 2.0000,                 loss: nan
second_0:                 episode reward: -2.0000,                 loss: 0.0179
Episode: 881/50000 (1.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 69.0486s / 2865.1162 s
first_0:                 episode reward: 2.8000,                 loss: nan
second_0:                 episode reward: -2.8000,                 loss: 0.0187
Episode: 901/50000 (1.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 69.6996s / 2934.8158 s
first_0:                 episode reward: 3.5000,                 loss: nan
second_0:                 episode reward: -3.5000,                 loss: 0.0204
Episode: 921/50000 (1.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 69.3032s / 3004.1190 s
first_0:                 episode reward: 3.8000,                 loss: nan
second_0:                 episode reward: -3.8000,                 loss: 0.0212
Episode: 941/50000 (1.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 69.1832s / 3073.3022 s
first_0:                 episode reward: 2.8500,                 loss: nan
second_0:                 episode reward: -2.8500,                 loss: 0.0242
Episode: 961/50000 (1.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 68.8692s / 3142.1714 s
first_0:                 episode reward: 3.2500,                 loss: nan
second_0:                 episode reward: -3.2500,                 loss: 0.0290
Episode: 981/50000 (1.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 69.6353s / 3211.8068 s
first_0:                 episode reward: 3.8000,                 loss: nan
second_0:                 episode reward: -3.8000,                 loss: 0.0299
Episode: 1001/50000 (2.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 69.9772s / 3281.7840 s
first_0:                 episode reward: 3.3000,                 loss: nan
second_0:                 episode reward: -3.3000,                 loss: 0.0353
Episode: 1021/50000 (2.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 70.3133s / 3352.0973 s
first_0:                 episode reward: 2.9500,                 loss: nan
second_0:                 episode reward: -2.9500,                 loss: 0.0286
Episode: 1041/50000 (2.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 69.9668s / 3422.0640 s
first_0:                 episode reward: 3.0500,                 loss: nan
second_0:                 episode reward: -3.0500,                 loss: 0.0201
Episode: 1061/50000 (2.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 69.6306s / 3491.6947 s
first_0:                 episode reward: 5.6000,                 loss: nan
second_0:                 episode reward: -5.6000,                 loss: 0.0194
Episode: 1081/50000 (2.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 70.0966s / 3561.7912 s
first_0:                 episode reward: 6.0500,                 loss: nan
second_0:                 episode reward: -6.0500,                 loss: 0.0198
Episode: 1101/50000 (2.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 69.4717s / 3631.2630 s
first_0:                 episode reward: 5.5500,                 loss: nan
second_0:                 episode reward: -5.5500,                 loss: 0.0235
Episode: 1121/50000 (2.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 68.3534s / 3699.6164 s
first_0:                 episode reward: 3.5000,                 loss: nan
second_0:                 episode reward: -3.5000,                 loss: 0.0277
Episode: 1141/50000 (2.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 69.6901s / 3769.3065 s
first_0:                 episode reward: 3.0000,                 loss: nan
second_0:                 episode reward: -3.0000,                 loss: 0.0311
Episode: 1161/50000 (2.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 69.3701s / 3838.6766 s
first_0:                 episode reward: 2.3000,                 loss: nan
second_0:                 episode reward: -2.3000,                 loss: 0.0307
Episode: 1181/50000 (2.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 69.3025s / 3907.9791 s
first_0:                 episode reward: 2.4000,                 loss: nan
second_0:                 episode reward: -2.4000,                 loss: 0.0290
Episode: 1201/50000 (2.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 69.3822s / 3977.3613 s
first_0:                 episode reward: 2.5000,                 loss: nan
second_0:                 episode reward: -2.5000,                 loss: 0.0255
Episode: 1221/50000 (2.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 69.5727s / 4046.9340 s
first_0:                 episode reward: 2.8500,                 loss: nan
second_0:                 episode reward: -2.8500,                 loss: 0.0229
Episode: 1241/50000 (2.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 69.3858s / 4116.3198 s
first_0:                 episode reward: 3.2500,                 loss: nan
second_0:                 episode reward: -3.2500,                 loss: 0.0231
Episode: 1261/50000 (2.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 69.7024s / 4186.0222 s
first_0:                 episode reward: 4.5000,                 loss: nan
second_0:                 episode reward: -4.5000,                 loss: 0.0260
Episode: 1281/50000 (2.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 69.6076s / 4255.6299 s
first_0:                 episode reward: 4.3500,                 loss: nan
second_0:                 episode reward: -4.3500,                 loss: 0.0350
Episode: 1301/50000 (2.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 69.6366s / 4325.2665 s
first_0:                 episode reward: 3.7000,                 loss: nan
second_0:                 episode reward: -3.7000,                 loss: 0.0386
Episode: 1321/50000 (2.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 69.7598s / 4395.0262 s
first_0:                 episode reward: 3.2000,                 loss: nan
second_0:                 episode reward: -3.2000,                 loss: 0.0333
Episode: 1341/50000 (2.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 69.7390s / 4464.7653 s
first_0:                 episode reward: 3.0000,                 loss: nan
second_0:                 episode reward: -3.0000,                 loss: 0.0281
Episode: 1361/50000 (2.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 69.7713s / 4534.5366 s
first_0:                 episode reward: 3.3500,                 loss: nan
second_0:                 episode reward: -3.3500,                 loss: 0.0253
Episode: 1381/50000 (2.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 69.8143s / 4604.3508 s
first_0:                 episode reward: 3.2500,                 loss: nan
second_0:                 episode reward: -3.2500,                 loss: 0.0241
Episode: 1401/50000 (2.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 69.6318s / 4673.9826 s
first_0:                 episode reward: 2.2000,                 loss: nan
second_0:                 episode reward: -2.2000,                 loss: 0.0228
Episode: 1421/50000 (2.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 69.1027s / 4743.0853 s
first_0:                 episode reward: 2.1000,                 loss: nan
second_0:                 episode reward: -2.1000,                 loss: 0.0258
Episode: 1441/50000 (2.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 69.1456s / 4812.2309 s
first_0:                 episode reward: 2.5000,                 loss: nan
second_0:                 episode reward: -2.5000,                 loss: 0.0309
Episode: 1461/50000 (2.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 69.4660s / 4881.6969 s
first_0:                 episode reward: 3.3500,                 loss: nan
second_0:                 episode reward: -3.3500,                 loss: 0.0344
Episode: 1481/50000 (2.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 69.5494s / 4951.2463 s
first_0:                 episode reward: 3.0000,                 loss: nan
second_0:                 episode reward: -3.0000,                 loss: 0.0295
Episode: 1501/50000 (3.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 69.2009s / 5020.4472 s
first_0:                 episode reward: 3.9500,                 loss: nan
second_0:                 episode reward: -3.9500,                 loss: 0.0236
Episode: 1521/50000 (3.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 69.2872s / 5089.7343 s
first_0:                 episode reward: 3.5000,                 loss: nan
second_0:                 episode reward: -3.5000,                 loss: 0.0220
Episode: 1541/50000 (3.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 70.7694s / 5160.5037 s
first_0:                 episode reward: 3.4000,                 loss: nan
second_0:                 episode reward: -3.4000,                 loss: 0.0258
Episode: 1561/50000 (3.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 71.8983s / 5232.4020 s
first_0:                 episode reward: 3.0500,                 loss: nan
second_0:                 episode reward: -3.0500,                 loss: 0.0302
Episode: 1581/50000 (3.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 71.8884s / 5304.2904 s
first_0:                 episode reward: 3.2000,                 loss: nan
second_0:                 episode reward: -3.2000,                 loss: 0.0307
Episode: 1601/50000 (3.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 71.1708s / 5375.4612 s
first_0:                 episode reward: 3.2000,                 loss: nan
second_0:                 episode reward: -3.2000,                 loss: 0.0285
Episode: 1621/50000 (3.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 71.5794s / 5447.0406 s
first_0:                 episode reward: 3.5000,                 loss: nan
second_0:                 episode reward: -3.5000,                 loss: 0.0250
Episode: 1641/50000 (3.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 71.3582s / 5518.3988 s
first_0:                 episode reward: 2.4500,                 loss: nan
second_0:                 episode reward: -2.4500,                 loss: 0.0271
Episode: 1661/50000 (3.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 69.7634s / 5588.1622 s
first_0:                 episode reward: 2.5500,                 loss: nan
second_0:                 episode reward: -2.5500,                 loss: 0.0284
Episode: 1681/50000 (3.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 69.6031s / 5657.7653 s
first_0:                 episode reward: 3.0500,                 loss: nan
second_0:                 episode reward: -3.0500,                 loss: 0.0305
Episode: 1701/50000 (3.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 69.1930s / 5726.9583 s
first_0:                 episode reward: 2.7000,                 loss: nan
second_0:                 episode reward: -2.7000,                 loss: 0.0266
Episode: 1721/50000 (3.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 69.1415s / 5796.0997 s
first_0:                 episode reward: 3.4500,                 loss: nan
second_0:                 episode reward: -3.4500,                 loss: 0.0247
Episode: 1741/50000 (3.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 69.2202s / 5865.3200 s
first_0:                 episode reward: 3.7000,                 loss: nan
second_0:                 episode reward: -3.7000,                 loss: 0.0270
Episode: 1761/50000 (3.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 69.3999s / 5934.7199 s
first_0:                 episode reward: 3.9000,                 loss: nan
second_0:                 episode reward: -3.9000,                 loss: 0.0283
Episode: 1781/50000 (3.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 69.6375s / 6004.3574 s
first_0:                 episode reward: 3.9500,                 loss: nan
second_0:                 episode reward: -3.9500,                 loss: 0.0302
Episode: 1801/50000 (3.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 69.7062s / 6074.0636 s
first_0:                 episode reward: 4.3500,                 loss: nan
second_0:                 episode reward: -4.3500,                 loss: 0.0361
Episode: 1821/50000 (3.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 69.3939s / 6143.4575 s
first_0:                 episode reward: 4.2000,                 loss: nan
second_0:                 episode reward: -4.2000,                 loss: 0.0412
Episode: 1841/50000 (3.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 69.8478s / 6213.3054 s
first_0:                 episode reward: 3.7500,                 loss: nan
second_0:                 episode reward: -3.7500,                 loss: 0.0354
Episode: 1861/50000 (3.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 69.3529s / 6282.6583 s
first_0:                 episode reward: 2.9500,                 loss: nan
second_0:                 episode reward: -2.9500,                 loss: 0.0279
Episode: 1881/50000 (3.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 69.4879s / 6352.1462 s
first_0:                 episode reward: 2.6500,                 loss: nan
second_0:                 episode reward: -2.6500,                 loss: 0.0227
Episode: 1901/50000 (3.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 69.5329s / 6421.6791 s
first_0:                 episode reward: 2.8000,                 loss: nan
second_0:                 episode reward: -2.8000,                 loss: 0.0234
Episode: 1921/50000 (3.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 69.6830s / 6491.3621 s
first_0:                 episode reward: 3.8500,                 loss: nan
second_0:                 episode reward: -3.8500,                 loss: 0.0273
Episode: 1941/50000 (3.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 69.6596s / 6561.0217 s
first_0:                 episode reward: 3.1000,                 loss: nan
second_0:                 episode reward: -3.1000,                 loss: 0.0295
Episode: 1961/50000 (3.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 69.6449s / 6630.6666 s
first_0:                 episode reward: 3.0000,                 loss: nan
second_0:                 episode reward: -3.0000,                 loss: 0.0277
Episode: 1981/50000 (3.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 69.5894s / 6700.2560 s
first_0:                 episode reward: 3.2500,                 loss: nan
second_0:                 episode reward: -3.2500,                 loss: 0.0254
Episode: 2001/50000 (4.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 69.3817s / 6769.6377 s
first_0:                 episode reward: 3.3000,                 loss: nan
second_0:                 episode reward: -3.3000,                 loss: 0.0234
Episode: 2021/50000 (4.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 70.1209s / 6839.7586 s
first_0:                 episode reward: 4.1000,                 loss: nan
second_0:                 episode reward: -4.1000,                 loss: 0.0291
Episode: 2041/50000 (4.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 69.7252s / 6909.4837 s
first_0:                 episode reward: 3.1000,                 loss: nan
second_0:                 episode reward: -3.1000,                 loss: 0.0309
Episode: 2061/50000 (4.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 69.7729s / 6979.2567 s
first_0:                 episode reward: 3.6000,                 loss: nan
second_0:                 episode reward: -3.6000,                 loss: 0.0308
Episode: 2081/50000 (4.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 70.2133s / 7049.4700 s
first_0:                 episode reward: 2.8000,                 loss: nan
second_0:                 episode reward: -2.8000,                 loss: 0.0298
Episode: 2101/50000 (4.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 69.7527s / 7119.2227 s
first_0:                 episode reward: 3.0500,                 loss: nan
second_0:                 episode reward: -3.0500,                 loss: 0.0262
Episode: 2121/50000 (4.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 70.2983s / 7189.5209 s
first_0:                 episode reward: 3.2500,                 loss: nan
second_0:                 episode reward: -3.2500,                 loss: 0.0276
Episode: 2141/50000 (4.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 69.6129s / 7259.1338 s
first_0:                 episode reward: 3.9000,                 loss: nan
second_0:                 episode reward: -3.9000,                 loss: 0.0241
Episode: 2161/50000 (4.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 69.6431s / 7328.7769 s
first_0:                 episode reward: 2.7500,                 loss: nan
second_0:                 episode reward: -2.7500,                 loss: 0.0238
Episode: 2181/50000 (4.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 69.8063s / 7398.5832 s
first_0:                 episode reward: 2.1500,                 loss: nan
second_0:                 episode reward: -2.1500,                 loss: 0.0263
Episode: 2201/50000 (4.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 70.0157s / 7468.5989 s
first_0:                 episode reward: 2.8500,                 loss: nan
second_0:                 episode reward: -2.8500,                 loss: 0.0270
Episode: 2221/50000 (4.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 69.7433s / 7538.3423 s
first_0:                 episode reward: 3.6500,                 loss: nan
second_0:                 episode reward: -3.6500,                 loss: 0.0236
Episode: 2241/50000 (4.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 70.0861s / 7608.4284 s
first_0:                 episode reward: 2.9500,                 loss: nan
second_0:                 episode reward: -2.9500,                 loss: 0.0206
Episode: 2261/50000 (4.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 70.1161s / 7678.5445 s
first_0:                 episode reward: 3.1000,                 loss: nan
second_0:                 episode reward: -3.1000,                 loss: 0.0198
Episode: 2281/50000 (4.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 70.3929s / 7748.9374 s
first_0:                 episode reward: 4.5000,                 loss: nan
second_0:                 episode reward: -4.5000,                 loss: 0.0221
Episode: 2301/50000 (4.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 69.8000s / 7818.7374 s
first_0:                 episode reward: 3.5500,                 loss: nan
second_0:                 episode reward: -3.5500,                 loss: 0.0254
Episode: 2321/50000 (4.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 70.0280s / 7888.7654 s
first_0:                 episode reward: 3.2000,                 loss: nan
second_0:                 episode reward: -3.2000,                 loss: 0.0279
Episode: 2341/50000 (4.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 69.5267s / 7958.2921 s
first_0:                 episode reward: 3.9500,                 loss: nan
second_0:                 episode reward: -3.9500,                 loss: 0.0296
Episode: 2361/50000 (4.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 70.8384s / 8029.1305 s
first_0:                 episode reward: 4.0000,                 loss: nan
second_0:                 episode reward: -4.0000,                 loss: 0.0300
Episode: 2381/50000 (4.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 72.4761s / 8101.6066 s
first_0:                 episode reward: 3.8000,                 loss: nan
second_0:                 episode reward: -3.8000,                 loss: 0.0318
Episode: 2401/50000 (4.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 72.1143s / 8173.7209 s
first_0:                 episode reward: 3.8000,                 loss: nan
second_0:                 episode reward: -3.8000,                 loss: 0.0329
Episode: 2421/50000 (4.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 71.8540s / 8245.5748 s
first_0:                 episode reward: 4.1000,                 loss: nan
second_0:                 episode reward: -4.1000,                 loss: 0.0335
Episode: 2441/50000 (4.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 71.9503s / 8317.5251 s
first_0:                 episode reward: 3.3000,                 loss: nan
second_0:                 episode reward: -3.3000,                 loss: 0.0356
Episode: 2461/50000 (4.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 71.5439s / 8389.0690 s
first_0:                 episode reward: 2.4500,                 loss: nan
second_0:                 episode reward: -2.4500,                 loss: 0.0338
Episode: 2481/50000 (4.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 70.7346s / 8459.8036 s
first_0:                 episode reward: 2.7500,                 loss: nan
second_0:                 episode reward: -2.7500,                 loss: 0.0292
Episode: 2501/50000 (5.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 70.2995s / 8530.1031 s
first_0:                 episode reward: 2.9500,                 loss: nan
second_0:                 episode reward: -2.9500,                 loss: 0.0263
Episode: 2521/50000 (5.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 71.2025s / 8601.3056 s
first_0:                 episode reward: 3.5500,                 loss: nan
second_0:                 episode reward: -3.5500,                 loss: 0.0256
Episode: 2541/50000 (5.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 71.9586s / 8673.2642 s
first_0:                 episode reward: 4.0500,                 loss: nan
second_0:                 episode reward: -4.0500,                 loss: 0.0275
Episode: 2561/50000 (5.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 70.9137s / 8744.1779 s
first_0:                 episode reward: 4.3000,                 loss: nan
second_0:                 episode reward: -4.3000,                 loss: 0.0252
Episode: 2581/50000 (5.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 69.5396s / 8813.7175 s
first_0:                 episode reward: 4.6500,                 loss: nan
second_0:                 episode reward: -4.6500,                 loss: 0.0238
Episode: 2601/50000 (5.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 70.0060s / 8883.7235 s
first_0:                 episode reward: 4.3500,                 loss: nan
second_0:                 episode reward: -4.3500,                 loss: 0.0252
Episode: 2621/50000 (5.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 69.7671s / 8953.4906 s
first_0:                 episode reward: 4.0000,                 loss: nan
second_0:                 episode reward: -4.0000,                 loss: 0.0242
Episode: 2641/50000 (5.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 69.4909s / 9022.9815 s
first_0:                 episode reward: 3.2500,                 loss: nan
second_0:                 episode reward: -3.2500,                 loss: 0.0229
Episode: 2661/50000 (5.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 69.5095s / 9092.4909 s
first_0:                 episode reward: 4.3500,                 loss: nan
second_0:                 episode reward: -4.3500,                 loss: 0.0222
Episode: 2681/50000 (5.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 69.8340s / 9162.3249 s
first_0:                 episode reward: 3.2000,                 loss: nan
second_0:                 episode reward: -3.2000,                 loss: 0.0205
Episode: 2701/50000 (5.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 69.6619s / 9231.9868 s
first_0:                 episode reward: 4.8000,                 loss: nan
second_0:                 episode reward: -4.8000,                 loss: 0.0198
Episode: 2721/50000 (5.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 69.6271s / 9301.6139 s
first_0:                 episode reward: 4.4500,                 loss: nan
second_0:                 episode reward: -4.4500,                 loss: 0.0220
Episode: 2741/50000 (5.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 69.4202s / 9371.0341 s
first_0:                 episode reward: 5.3000,                 loss: nan
second_0:                 episode reward: -5.3000,                 loss: 0.0233
Episode: 2761/50000 (5.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 68.4913s / 9439.5253 s
first_0:                 episode reward: 4.7000,                 loss: nan
second_0:                 episode reward: -4.7000,                 loss: 0.0221
Episode: 2781/50000 (5.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 69.5817s / 9509.1070 s
first_0:                 episode reward: 3.8500,                 loss: nan
second_0:                 episode reward: -3.8500,                 loss: 0.0241
Episode: 2801/50000 (5.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 69.7035s / 9578.8106 s
first_0:                 episode reward: 3.9500,                 loss: nan
second_0:                 episode reward: -3.9500,                 loss: 0.0278
Episode: 2821/50000 (5.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 69.5704s / 9648.3809 s
first_0:                 episode reward: 4.2000,                 loss: nan
second_0:                 episode reward: -4.2000,                 loss: 0.0290
Episode: 2841/50000 (5.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 69.8305s / 9718.2114 s
first_0:                 episode reward: 4.6500,                 loss: nan
second_0:                 episode reward: -4.6500,                 loss: 0.0274
Episode: 2861/50000 (5.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 69.5472s / 9787.7586 s
first_0:                 episode reward: 4.2500,                 loss: nan
second_0:                 episode reward: -4.2500,                 loss: 0.0271
Episode: 2881/50000 (5.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 69.8670s / 9857.6256 s
first_0:                 episode reward: 2.7000,                 loss: nan
second_0:                 episode reward: -2.7000,                 loss: 0.0266
Episode: 2901/50000 (5.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 70.1173s / 9927.7429 s
first_0:                 episode reward: 1.0500,                 loss: nan
second_0:                 episode reward: -1.0500,                 loss: 0.0249
Episode: 2921/50000 (5.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 69.9210s / 9997.6639 s
first_0:                 episode reward: 2.1000,                 loss: nan
second_0:                 episode reward: -2.1000,                 loss: 0.0232
Episode: 2941/50000 (5.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 69.7030s / 10067.3669 s
first_0:                 episode reward: 2.6500,                 loss: nan
second_0:                 episode reward: -2.6500,                 loss: 0.0227
Episode: 2961/50000 (5.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 69.4626s / 10136.8295 s
first_0:                 episode reward: 1.9500,                 loss: nan
second_0:                 episode reward: -1.9500,                 loss: 0.0222
Episode: 2981/50000 (5.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 69.7241s / 10206.5536 s
first_0:                 episode reward: 2.0500,                 loss: nan
second_0:                 episode reward: -2.0500,                 loss: 0.0245
Episode: 3001/50000 (6.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 69.4842s / 10276.0378 s
first_0:                 episode reward: 2.5000,                 loss: nan
second_0:                 episode reward: -2.5000,                 loss: 0.0261
Episode: 3021/50000 (6.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 69.9498s / 10345.9876 s
first_0:                 episode reward: 3.5500,                 loss: nan
second_0:                 episode reward: -3.5500,                 loss: 0.0269
Episode: 3041/50000 (6.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 70.2728s / 10416.2605 s
first_0:                 episode reward: 3.4500,                 loss: nan
second_0:                 episode reward: -3.4500,                 loss: 0.0249
Episode: 3061/50000 (6.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 69.7077s / 10485.9681 s
first_0:                 episode reward: 2.8500,                 loss: nan
second_0:                 episode reward: -2.8500,                 loss: 0.0233
Episode: 3081/50000 (6.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 69.5399s / 10555.5080 s
first_0:                 episode reward: 3.4000,                 loss: nan
second_0:                 episode reward: -3.4000,                 loss: 0.0239
Episode: 3101/50000 (6.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 70.5286s / 10626.0366 s
first_0:                 episode reward: 2.7500,                 loss: nan
second_0:                 episode reward: -2.7500,                 loss: 0.0246
Episode: 3121/50000 (6.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 69.9067s / 10695.9433 s
first_0:                 episode reward: 3.3000,                 loss: nan
second_0:                 episode reward: -3.3000,                 loss: 0.0261
Episode: 3141/50000 (6.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 69.9402s / 10765.8835 s
first_0:                 episode reward: 1.8500,                 loss: nan
second_0:                 episode reward: -1.8500,                 loss: 0.0279
Episode: 3161/50000 (6.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 69.3967s / 10835.2802 s
first_0:                 episode reward: 2.4000,                 loss: nan
second_0:                 episode reward: -2.4000,                 loss: 0.0316
Episode: 3181/50000 (6.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 69.6355s / 10904.9158 s
first_0:                 episode reward: 1.5000,                 loss: nan
second_0:                 episode reward: -1.5000,                 loss: 0.0331
Episode: 3201/50000 (6.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 70.0352s / 10974.9510 s
first_0:                 episode reward: 3.0500,                 loss: nan
second_0:                 episode reward: -3.0500,                 loss: 0.0276
Episode: 3221/50000 (6.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 69.2614s / 11044.2123 s
first_0:                 episode reward: 3.6500,                 loss: nan
second_0:                 episode reward: -3.6500,                 loss: 0.0262
Episode: 3241/50000 (6.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 70.1230s / 11114.3354 s
first_0:                 episode reward: 1.3000,                 loss: nan
second_0:                 episode reward: -1.3000,                 loss: 0.0261
Episode: 3261/50000 (6.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 69.5971s / 11183.9325 s
first_0:                 episode reward: 2.0000,                 loss: nan
second_0:                 episode reward: -2.0000,                 loss: 0.0221
Episode: 3281/50000 (6.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 69.7870s / 11253.7195 s
first_0:                 episode reward: 2.1000,                 loss: nan
second_0:                 episode reward: -2.1000,                 loss: 0.0219
Episode: 3301/50000 (6.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 73.1107s / 11326.8302 s
first_0:                 episode reward: 1.7000,                 loss: nan
second_0:                 episode reward: -1.7000,                 loss: 0.0243
Episode: 3321/50000 (6.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 74.1450s / 11400.9751 s
first_0:                 episode reward: 1.6000,                 loss: nan
second_0:                 episode reward: -1.6000,                 loss: 0.0243
Episode: 3341/50000 (6.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 75.1714s / 11476.1466 s
first_0:                 episode reward: 2.6500,                 loss: nan
second_0:                 episode reward: -2.6500,                 loss: 0.0249
Episode: 3361/50000 (6.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 75.4492s / 11551.5958 s
first_0:                 episode reward: 2.9000,                 loss: nan
second_0:                 episode reward: -2.9000,                 loss: 0.0270
Episode: 3381/50000 (6.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 75.0358s / 11626.6316 s
first_0:                 episode reward: 2.8500,                 loss: nan
second_0:                 episode reward: -2.8500,                 loss: 0.0328
Episode: 3401/50000 (6.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 75.0906s / 11701.7222 s
first_0:                 episode reward: 3.1500,                 loss: nan
second_0:                 episode reward: -3.1500,                 loss: 0.0294
Episode: 3421/50000 (6.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 74.6678s / 11776.3900 s
first_0:                 episode reward: 3.5000,                 loss: nan
second_0:                 episode reward: -3.5000,                 loss: 0.0282
Episode: 3441/50000 (6.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 72.6634s / 11849.0534 s
first_0:                 episode reward: 2.6000,                 loss: nan
second_0:                 episode reward: -2.6000,                 loss: 0.0279
Episode: 3461/50000 (6.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 72.3688s / 11921.4222 s
first_0:                 episode reward: 1.7000,                 loss: nan
second_0:                 episode reward: -1.7000,                 loss: 0.0313
Episode: 3481/50000 (6.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 73.7123s / 11995.1345 s
first_0:                 episode reward: 3.8000,                 loss: nan
second_0:                 episode reward: -3.8000,                 loss: 0.0328
Episode: 3501/50000 (7.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 73.0376s / 12068.1721 s
first_0:                 episode reward: 5.0000,                 loss: nan
second_0:                 episode reward: -5.0000,                 loss: 0.0299
Episode: 3521/50000 (7.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 73.4971s / 12141.6691 s
first_0:                 episode reward: 4.2500,                 loss: nan
second_0:                 episode reward: -4.2500,                 loss: 0.0345
Episode: 3541/50000 (7.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 72.1178s / 12213.7869 s
first_0:                 episode reward: 4.0500,                 loss: nan
second_0:                 episode reward: -4.0500,                 loss: 0.0383
Episode: 3561/50000 (7.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 72.3218s / 12286.1087 s
first_0:                 episode reward: 4.2000,                 loss: nan
second_0:                 episode reward: -4.2000,                 loss: 0.0353
Episode: 3581/50000 (7.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 72.7882s / 12358.8969 s
first_0:                 episode reward: 2.9500,                 loss: nan
second_0:                 episode reward: -2.9500,                 loss: 0.0306
Episode: 3601/50000 (7.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 72.7521s / 12431.6490 s