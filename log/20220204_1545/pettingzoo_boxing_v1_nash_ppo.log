pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
boxing_v1 pettingzoo
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
random seed: [91, 69]
<SubprocVectorEnv instance>
No agent are not learnable.
Arguments:  {'env_name': 'boxing_v1', 'env_type': 'pettingzoo', 'num_envs': 2, 'ram': True, 'seed': 'random', 'algorithm': 'NashPPO', 'algorithm_spec': {'episodic_update': True, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000, 'lambda': 0.95, 'eps_clip': 0.2, 'K_epoch': 4, 'GAE': True}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False, 'policy': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': 'Softmax'}, 'value': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}}, 'marl_method': 'nash_ppo', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True}}
Save models to : /home/zihan/research/MARS/data/model/20220204_1545/pettingzoo_boxing_v1_nash_ppo. 
 Save logs to: /home/zihan/research/MARS/data/log/20220204_1545/pettingzoo_boxing_v1_nash_ppo.
Episode: 1/30000 (0.0033%),                 avg. length: 1784.0,                last time consumption/overall running time: 16.2184s / 16.2184 s
env0_first_0:                 episode reward: 4.0000,                 loss: -0.1267
env0_second_0:                 episode reward: -4.0000,                 loss: -0.1173
env1_first_0:                 episode reward: -3.0000,                 loss: nan
env1_second_0:                 episode reward: 3.0000,                 loss: nan
Episode: 21/30000 (0.0700%),                 avg. length: 1784.0,                last time consumption/overall running time: 287.8856s / 304.1041 s
env0_first_0:                 episode reward: -1.8000,                 loss: -0.0723
env0_second_0:                 episode reward: 1.8000,                 loss: -0.0631
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 41/30000 (0.1367%),                 avg. length: 1784.0,                last time consumption/overall running time: 283.6829s / 587.7870 s
env0_first_0:                 episode reward: -0.4500,                 loss: -0.1026
env0_second_0:                 episode reward: 0.4500,                 loss: -0.0948
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 61/30000 (0.2033%),                 avg. length: 1784.0,                last time consumption/overall running time: 303.8776s / 891.6646 s
env0_first_0:                 episode reward: -0.7000,                 loss: -0.0268
env0_second_0:                 episode reward: 0.7000,                 loss: -0.0243
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 81/30000 (0.2700%),                 avg. length: 1784.0,                last time consumption/overall running time: 302.2509s / 1193.9155 s
env0_first_0:                 episode reward: -1.7500,                 loss: 0.0322
env0_second_0:                 episode reward: 1.7500,                 loss: 0.0312
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 101/30000 (0.3367%),                 avg. length: 1784.0,                last time consumption/overall running time: 292.0589s / 1485.9744 s
env0_first_0:                 episode reward: -1.2000,                 loss: -0.1751
env0_second_0:                 episode reward: 1.2000,                 loss: -0.1731
env1_first_0:                 episode reward: -1.9000,                 loss: nan
env1_second_0:                 episode reward: 1.9000,                 loss: nan
Episode: 121/30000 (0.4033%),                 avg. length: 1784.0,                last time consumption/overall running time: 283.7656s / 1769.7400 s
env0_first_0:                 episode reward: -5.1000,                 loss: 0.3402
env0_second_0:                 episode reward: 5.1000,                 loss: 0.3358
env1_first_0:                 episode reward: -4.6500,                 loss: nan
env1_second_0:                 episode reward: 4.6500,                 loss: nan
Episode: 141/30000 (0.4700%),                 avg. length: 1784.0,                last time consumption/overall running time: 293.7961s / 2063.5361 s
env0_first_0:                 episode reward: -2.8000,                 loss: 0.3632
env0_second_0:                 episode reward: 2.8000,                 loss: 0.3737
env1_first_0:                 episode reward: -2.7500,                 loss: nan
env1_second_0:                 episode reward: 2.7500,                 loss: nan
Episode: 161/30000 (0.5367%),                 avg. length: 1784.0,                last time consumption/overall running time: 286.5049s / 2350.0410 s
env0_first_0:                 episode reward: -7.3000,                 loss: 0.4069
env0_second_0:                 episode reward: 7.3000,                 loss: 0.4095
env1_first_0:                 episode reward: -2.7000,                 loss: nan
env1_second_0:                 episode reward: 2.7000,                 loss: nan
Episode: 181/30000 (0.6033%),                 avg. length: 1784.0,                last time consumption/overall running time: 293.4455s / 2643.4864 s
env0_first_0:                 episode reward: 0.3000,                 loss: -0.0358
env0_second_0:                 episode reward: -0.3000,                 loss: -0.0345
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 201/30000 (0.6700%),                 avg. length: 1784.0,                last time consumption/overall running time: 297.2463s / 2940.7327 s
env0_first_0:                 episode reward: 1.0000,                 loss: -0.0451
env0_second_0:                 episode reward: -1.0000,                 loss: -0.0467
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 221/30000 (0.7367%),                 avg. length: 1784.0,                last time consumption/overall running time: 294.5052s / 3235.2379 s
env0_first_0:                 episode reward: -4.1000,                 loss: -0.1249
env0_second_0:                 episode reward: 4.1000,                 loss: -0.1210
env1_first_0:                 episode reward: 3.4000,                 loss: nan
env1_second_0:                 episode reward: -3.4000,                 loss: nan
Episode: 241/30000 (0.8033%),                 avg. length: 1784.0,                last time consumption/overall running time: 300.5671s / 3535.8051 s
env0_first_0:                 episode reward: -1.2000,                 loss: -0.2398
env0_second_0:                 episode reward: 1.2000,                 loss: -0.2407
env1_first_0:                 episode reward: -2.7000,                 loss: nan
env1_second_0:                 episode reward: 2.7000,                 loss: nan
Episode: 261/30000 (0.8700%),                 avg. length: 1784.0,                last time consumption/overall running time: 298.9069s / 3834.7120 s
env0_first_0:                 episode reward: -2.0500,                 loss: -0.2038
env0_second_0:                 episode reward: 2.0500,                 loss: -0.2034
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 281/30000 (0.9367%),                 avg. length: 1784.0,                last time consumption/overall running time: 302.5136s / 4137.2256 s
env0_first_0:                 episode reward: -1.5500,                 loss: -0.1257
env0_second_0:                 episode reward: 1.5500,                 loss: -0.1268
env1_first_0:                 episode reward: -2.5000,                 loss: nan
env1_second_0:                 episode reward: 2.5000,                 loss: nan
Episode: 301/30000 (1.0033%),                 avg. length: 1784.0,                last time consumption/overall running time: 300.0232s / 4437.2488 s
env0_first_0:                 episode reward: -1.0000,                 loss: -0.2313
env0_second_0:                 episode reward: 1.0000,                 loss: -0.2368
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 321/30000 (1.0700%),                 avg. length: 1784.0,                last time consumption/overall running time: 283.7413s / 4720.9901 s
env0_first_0:                 episode reward: -0.2500,                 loss: -0.2140
env0_second_0:                 episode reward: 0.2500,                 loss: -0.2193
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 341/30000 (1.1367%),                 avg. length: 1784.0,                last time consumption/overall running time: 296.4427s / 5017.4328 s
env0_first_0:                 episode reward: -1.5500,                 loss: 0.1559
env0_second_0:                 episode reward: 1.5500,                 loss: 0.1563
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 361/30000 (1.2033%),                 avg. length: 1784.0,                last time consumption/overall running time: 303.9954s / 5321.4282 s
env0_first_0:                 episode reward: -7.0000,                 loss: 0.2677
env0_second_0:                 episode reward: 7.0000,                 loss: 0.2753
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 381/30000 (1.2700%),                 avg. length: 1784.0,                last time consumption/overall running time: 298.3690s / 5619.7972 s
env0_first_0:                 episode reward: -5.7500,                 loss: 0.1245
env0_second_0:                 episode reward: 5.7500,                 loss: 0.1302
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 401/30000 (1.3367%),                 avg. length: 1784.0,                last time consumption/overall running time: 287.1791s / 5906.9762 s
env0_first_0:                 episode reward: -0.5000,                 loss: -0.0314
env0_second_0:                 episode reward: 0.5000,                 loss: -0.0254
env1_first_0:                 episode reward: -1.6500,                 loss: nan
env1_second_0:                 episode reward: 1.6500,                 loss: nan
Episode: 421/30000 (1.4033%),                 avg. length: 1784.0,                last time consumption/overall running time: 296.3885s / 6203.3647 s
env0_first_0:                 episode reward: -1.1000,                 loss: -0.0457
env0_second_0:                 episode reward: 1.1000,                 loss: -0.0427
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 441/30000 (1.4700%),                 avg. length: 1784.0,                last time consumption/overall running time: 286.4696s / 6489.8344 s
env0_first_0:                 episode reward: -1.6000,                 loss: 0.0506
env0_second_0:                 episode reward: 1.6000,                 loss: 0.0597
env1_first_0:                 episode reward: -3.1500,                 loss: nan
env1_second_0:                 episode reward: 3.1500,                 loss: nan
Episode: 461/30000 (1.5367%),                 avg. length: 1784.0,                last time consumption/overall running time: 278.2987s / 6768.1331 s
env0_first_0:                 episode reward: -2.0500,                 loss: -0.0433
env0_second_0:                 episode reward: 2.0500,                 loss: -0.0415
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 481/30000 (1.6033%),                 avg. length: 1784.0,                last time consumption/overall running time: 304.3894s / 7072.5224 s
env0_first_0:                 episode reward: -1.7500,                 loss: 0.1559
env0_second_0:                 episode reward: 1.7500,                 loss: 0.1655
env1_first_0:                 episode reward: -2.8000,                 loss: nan
env1_second_0:                 episode reward: 2.8000,                 loss: nan
Episode: 501/30000 (1.6700%),                 avg. length: 1784.0,                last time consumption/overall running time: 302.3490s / 7374.8714 s
env0_first_0:                 episode reward: -0.3000,                 loss: -0.4162
env0_second_0:                 episode reward: 0.3000,                 loss: -0.4248
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 521/30000 (1.7367%),                 avg. length: 1784.0,                last time consumption/overall running time: 308.1527s / 7683.0242 s
env0_first_0:                 episode reward: -2.8500,                 loss: 0.0545
env0_second_0:                 episode reward: 2.8500,                 loss: 0.0651
env1_first_0:                 episode reward: -4.3500,                 loss: nan
env1_second_0:                 episode reward: 4.3500,                 loss: nan
Episode: 541/30000 (1.8033%),                 avg. length: 1784.0,                last time consumption/overall running time: 307.5055s / 7990.5297 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.5735
env0_second_0:                 episode reward: 3.9500,                 loss: 0.5934
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 561/30000 (1.8700%),                 avg. length: 1784.0,                last time consumption/overall running time: 317.4573s / 8307.9869 s
env0_first_0:                 episode reward: -1.9500,                 loss: 0.1786
env0_second_0:                 episode reward: 1.9500,                 loss: 0.1895
env1_first_0:                 episode reward: -2.7000,                 loss: nan
env1_second_0:                 episode reward: 2.7000,                 loss: nan
Episode: 581/30000 (1.9367%),                 avg. length: 1784.0,                last time consumption/overall running time: 311.5022s / 8619.4891 s
env0_first_0:                 episode reward: -4.3500,                 loss: 0.1814
env0_second_0:                 episode reward: 4.3500,                 loss: 0.1823
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 601/30000 (2.0033%),                 avg. length: 1784.0,                last time consumption/overall running time: 321.7253s / 8941.2144 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0487
env0_second_0:                 episode reward: 0.9000,                 loss: 0.0528
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 621/30000 (2.0700%),                 avg. length: 1784.0,                last time consumption/overall running time: 316.8943s / 9258.1087 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.3329
env0_second_0:                 episode reward: 0.0000,                 loss: 0.3505
env1_first_0:                 episode reward: -2.4000,                 loss: nan
env1_second_0:                 episode reward: 2.4000,                 loss: nan
Episode: 641/30000 (2.1367%),                 avg. length: 1784.0,                last time consumption/overall running time: 326.7043s / 9584.8130 s
env0_first_0:                 episode reward: -1.8500,                 loss: 0.2031
env0_second_0:                 episode reward: 1.8500,                 loss: 0.2150
env1_first_0:                 episode reward: -2.8500,                 loss: nan
env1_second_0:                 episode reward: 2.8500,                 loss: nan
Episode: 661/30000 (2.2033%),                 avg. length: 1784.0,                last time consumption/overall running time: 315.0926s / 9899.9056 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.0017
env0_second_0:                 episode reward: 1.0500,                 loss: 0.0151
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 681/30000 (2.2700%),                 avg. length: 1784.0,                last time consumption/overall running time: 309.6636s / 10209.5692 s
env0_first_0:                 episode reward: -2.7000,                 loss: -0.1686
env0_second_0:                 episode reward: 2.7000,                 loss: -0.1658
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 701/30000 (2.3367%),                 avg. length: 1784.0,                last time consumption/overall running time: 325.9010s / 10535.4703 s
env0_first_0:                 episode reward: -3.1000,                 loss: 0.0697
env0_second_0:                 episode reward: 3.1000,                 loss: 0.0983
env1_first_0:                 episode reward: -3.2500,                 loss: nan
env1_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 721/30000 (2.4033%),                 avg. length: 1784.0,                last time consumption/overall running time: 321.9221s / 10857.3924 s
env0_first_0:                 episode reward: -8.3500,                 loss: 1.0069
env0_second_0:                 episode reward: 8.3500,                 loss: 1.0545
env1_first_0:                 episode reward: -9.3000,                 loss: nan
env1_second_0:                 episode reward: 9.3000,                 loss: nan
Episode: 741/30000 (2.4700%),                 avg. length: 1748.55,                last time consumption/overall running time: 305.6938s / 11163.0862 s
env0_first_0:                 episode reward: -12.7500,                 loss: 2.1841
env0_second_0:                 episode reward: 12.7500,                 loss: 2.2459
env1_first_0:                 episode reward: -15.4000,                 loss: nan
env1_second_0:                 episode reward: 15.4000,                 loss: nan
Episode: 761/30000 (2.5367%),                 avg. length: 1534.55,                last time consumption/overall running time: 257.3603s / 11420.4465 s
env0_first_0:                 episode reward: -22.6500,                 loss: 3.4770
env0_second_0:                 episode reward: 22.6500,                 loss: 3.5425
env1_first_0:                 episode reward: -30.0000,                 loss: nan
env1_second_0:                 episode reward: 30.0000,                 loss: nan
Episode: 781/30000 (2.6033%),                 avg. length: 1503.45,                last time consumption/overall running time: 246.2564s / 11666.7029 s
env0_first_0:                 episode reward: -37.0000,                 loss: 4.3000
env0_second_0:                 episode reward: 37.0000,                 loss: 4.2727
env1_first_0:                 episode reward: -27.6000,                 loss: nan
env1_second_0:                 episode reward: 27.6000,                 loss: nan
Episode: 801/30000 (2.6700%),                 avg. length: 1554.4,                last time consumption/overall running time: 267.3810s / 11934.0838 s
env0_first_0:                 episode reward: -21.0500,                 loss: 3.2604
env0_second_0:                 episode reward: 21.0500,                 loss: 3.1725
env1_first_0:                 episode reward: -24.4500,                 loss: nan
env1_second_0:                 episode reward: 24.4500,                 loss: nan
Episode: 821/30000 (2.7367%),                 avg. length: 1726.45,                last time consumption/overall running time: 295.5897s / 12229.6735 s
env0_first_0:                 episode reward: -14.1000,                 loss: 1.4330
env0_second_0:                 episode reward: 14.1000,                 loss: 1.4273
env1_first_0:                 episode reward: -12.3500,                 loss: nan
env1_second_0:                 episode reward: 12.3500,                 loss: nan
Episode: 841/30000 (2.8033%),                 avg. length: 1705.45,                last time consumption/overall running time: 293.0379s / 12522.7114 s
env0_first_0:                 episode reward: -13.9500,                 loss: 0.9238
env0_second_0:                 episode reward: 13.9500,                 loss: 1.0103
env1_first_0:                 episode reward: -5.9000,                 loss: nan
env1_second_0:                 episode reward: 5.9000,                 loss: nan
Episode: 861/30000 (2.8700%),                 avg. length: 1609.3,                last time consumption/overall running time: 284.8379s / 12807.5493 s
env0_first_0:                 episode reward: -17.4500,                 loss: 2.1791
env0_second_0:                 episode reward: 17.4500,                 loss: 2.2814
env1_first_0:                 episode reward: -18.7500,                 loss: nan
env1_second_0:                 episode reward: 18.7500,                 loss: nan
Episode: 881/30000 (2.9367%),                 avg. length: 1506.0,                last time consumption/overall running time: 266.5609s / 13074.1102 s
env0_first_0:                 episode reward: -21.6500,                 loss: 3.3473
env0_second_0:                 episode reward: 21.6500,                 loss: 3.4054
env1_first_0:                 episode reward: -30.1000,                 loss: nan
env1_second_0:                 episode reward: 30.1000,                 loss: nan
Episode: 901/30000 (3.0033%),                 avg. length: 1203.4,                last time consumption/overall running time: 206.8633s / 13280.9735 s
env0_first_0:                 episode reward: -39.1500,                 loss: 5.8841
env0_second_0:                 episode reward: 39.1500,                 loss: 5.9396
env1_first_0:                 episode reward: -39.5000,                 loss: nan
env1_second_0:                 episode reward: 39.5000,                 loss: nan
Episode: 921/30000 (3.0700%),                 avg. length: 1404.15,                last time consumption/overall running time: 239.8516s / 13520.8251 s
env0_first_0:                 episode reward: -24.6000,                 loss: 4.5703
env0_second_0:                 episode reward: 24.6000,                 loss: 4.4794
env1_first_0:                 episode reward: -27.5000,                 loss: nan
env1_second_0:                 episode reward: 27.5000,                 loss: nan
Episode: 941/30000 (3.1367%),                 avg. length: 1514.95,                last time consumption/overall running time: 249.6245s / 13770.4496 s
env0_first_0:                 episode reward: -28.9500,                 loss: 3.6565
env0_second_0:                 episode reward: 28.9500,                 loss: 3.6778
env1_first_0:                 episode reward: -26.2500,                 loss: nan
env1_second_0:                 episode reward: 26.2500,                 loss: nan
Episode: 961/30000 (3.2033%),                 avg. length: 1411.7,                last time consumption/overall running time: 244.3044s / 14014.7540 s
env0_first_0:                 episode reward: -32.6000,                 loss: 4.5136
env0_second_0:                 episode reward: 32.6000,                 loss: 4.4770
env1_first_0:                 episode reward: -31.2000,                 loss: nan
env1_second_0:                 episode reward: 31.2000,                 loss: nan
Episode: 981/30000 (3.2700%),                 avg. length: 1233.45,                last time consumption/overall running time: 207.4907s / 14222.2447 s
env0_first_0:                 episode reward: -32.6000,                 loss: 5.5064
env0_second_0:                 episode reward: 32.6000,                 loss: 5.5072
env1_first_0:                 episode reward: -33.4500,                 loss: nan
env1_second_0:                 episode reward: 33.4500,                 loss: nan
Episode: 1001/30000 (3.3367%),                 avg. length: 1369.75,                last time consumption/overall running time: 227.7055s / 14449.9502 s
env0_first_0:                 episode reward: -29.7500,                 loss: 4.1760
env0_second_0:                 episode reward: 29.7500,                 loss: 4.1354
env1_first_0:                 episode reward: -16.0500,                 loss: nan
env1_second_0:                 episode reward: 16.0500,                 loss: nan
Episode: 1021/30000 (3.4033%),                 avg. length: 1506.05,                last time consumption/overall running time: 247.1788s / 14697.1290 s
env0_first_0:                 episode reward: -28.3500,                 loss: 4.5022
env0_second_0:                 episode reward: 28.3500,                 loss: 4.4531
env1_first_0:                 episode reward: -27.0500,                 loss: nan
env1_second_0:                 episode reward: 27.0500,                 loss: nan
Episode: 1041/30000 (3.4700%),                 avg. length: 1183.65,                last time consumption/overall running time: 185.7200s / 14882.8490 s
env0_first_0:                 episode reward: -36.1500,                 loss: 6.1521
env0_second_0:                 episode reward: 36.1500,                 loss: 6.1491
env1_first_0:                 episode reward: -36.8500,                 loss: nan
env1_second_0:                 episode reward: 36.8500,                 loss: nan
Episode: 1061/30000 (3.5367%),                 avg. length: 1272.75,                last time consumption/overall running time: 219.3163s / 15102.1653 s
env0_first_0:                 episode reward: -31.7000,                 loss: 5.6634
env0_second_0:                 episode reward: 31.7000,                 loss: 5.6307
env1_first_0:                 episode reward: -37.2000,                 loss: nan
env1_second_0:                 episode reward: 37.2000,                 loss: nan
Episode: 1081/30000 (3.6033%),                 avg. length: 1303.75,                last time consumption/overall running time: 223.6067s / 15325.7720 s
env0_first_0:                 episode reward: -32.3000,                 loss: 5.4089
env0_second_0:                 episode reward: 32.3000,                 loss: 5.4864
env1_first_0:                 episode reward: -32.1500,                 loss: nan
env1_second_0:                 episode reward: 32.1500,                 loss: nan
Episode: 1101/30000 (3.6700%),                 avg. length: 1412.05,                last time consumption/overall running time: 235.0794s / 15560.8514 s
env0_first_0:                 episode reward: -22.2500,                 loss: 5.0739
env0_second_0:                 episode reward: 22.2500,                 loss: 4.9801
env1_first_0:                 episode reward: -35.9000,                 loss: nan
env1_second_0:                 episode reward: 35.9000,                 loss: nan
Episode: 1121/30000 (3.7367%),                 avg. length: 1588.25,                last time consumption/overall running time: 265.7545s / 15826.6059 s
env0_first_0:                 episode reward: -22.7000,                 loss: 4.5700
env0_second_0:                 episode reward: 22.7000,                 loss: 4.5172
env1_first_0:                 episode reward: -24.5000,                 loss: nan
env1_second_0:                 episode reward: 24.5000,                 loss: nan
Episode: 1141/30000 (3.8033%),                 avg. length: 1560.25,                last time consumption/overall running time: 269.3800s / 16095.9860 s
env0_first_0:                 episode reward: -17.2500,                 loss: 4.9995
env0_second_0:                 episode reward: 17.2500,                 loss: 4.9334
env1_first_0:                 episode reward: -29.6500,                 loss: nan
env1_second_0:                 episode reward: 29.6500,                 loss: nan
Episode: 1161/30000 (3.8700%),                 avg. length: 1710.35,                last time consumption/overall running time: 282.6836s / 16378.6696 s
env0_first_0:                 episode reward: -24.8000,                 loss: 4.2180
env0_second_0:                 episode reward: 24.8000,                 loss: 4.1222
env1_first_0:                 episode reward: -24.5000,                 loss: nan
env1_second_0:                 episode reward: 24.5000,                 loss: nan
Episode: 1181/30000 (3.9367%),                 avg. length: 1630.95,                last time consumption/overall running time: 257.1589s / 16635.8285 s
env0_first_0:                 episode reward: -25.2500,                 loss: 4.8780
env0_second_0:                 episode reward: 25.2500,                 loss: 4.8314
env1_first_0:                 episode reward: -27.3000,                 loss: nan
env1_second_0:                 episode reward: 27.3000,                 loss: nan
Episode: 1201/30000 (4.0033%),                 avg. length: 1451.15,                last time consumption/overall running time: 250.1869s / 16886.0154 s
env0_first_0:                 episode reward: -35.2000,                 loss: 5.8901
env0_second_0:                 episode reward: 35.2000,                 loss: 5.8507
env1_first_0:                 episode reward: -30.3000,                 loss: nan
env1_second_0:                 episode reward: 30.3000,                 loss: nan
Episode: 1221/30000 (4.0700%),                 avg. length: 1325.35,                last time consumption/overall running time: 217.3987s / 17103.4141 s
env0_first_0:                 episode reward: -35.8000,                 loss: 6.1019
env0_second_0:                 episode reward: 35.8000,                 loss: 6.1013
env1_first_0:                 episode reward: -27.5500,                 loss: nan
env1_second_0:                 episode reward: 27.5500,                 loss: nan
Episode: 1241/30000 (4.1367%),                 avg. length: 1346.1,                last time consumption/overall running time: 226.0154s / 17329.4295 s
env0_first_0:                 episode reward: -33.6500,                 loss: 6.1227
env0_second_0:                 episode reward: 33.6500,                 loss: 6.1802
env1_first_0:                 episode reward: -32.4000,                 loss: nan
env1_second_0:                 episode reward: 32.4000,                 loss: nan
Episode: 1261/30000 (4.2033%),                 avg. length: 1324.0,                last time consumption/overall running time: 224.9102s / 17554.3397 s
env0_first_0:                 episode reward: -35.8500,                 loss: 6.3780
env0_second_0:                 episode reward: 35.8500,                 loss: 6.3497
env1_first_0:                 episode reward: -34.0500,                 loss: nan
env1_second_0:                 episode reward: 34.0500,                 loss: nan
Episode: 1281/30000 (4.2700%),                 avg. length: 1439.55,                last time consumption/overall running time: 228.9556s / 17783.2952 s
env0_first_0:                 episode reward: -29.9500,                 loss: 5.8859
env0_second_0:                 episode reward: 29.9500,                 loss: 5.8390
env1_first_0:                 episode reward: -32.2500,                 loss: nan
env1_second_0:                 episode reward: 32.2500,                 loss: nan
Episode: 1301/30000 (4.3367%),                 avg. length: 1350.4,                last time consumption/overall running time: 230.5177s / 18013.8129 s
env0_first_0:                 episode reward: -37.4500,                 loss: 6.4198
env0_second_0:                 episode reward: 37.4500,                 loss: 6.3601
env1_first_0:                 episode reward: -30.0500,                 loss: nan
env1_second_0:                 episode reward: 30.0500,                 loss: nan
Episode: 1321/30000 (4.4033%),                 avg. length: 1395.65,                last time consumption/overall running time: 239.4455s / 18253.2584 s
env0_first_0:                 episode reward: -36.1500,                 loss: 6.9183
env0_second_0:                 episode reward: 36.1500,                 loss: 6.8458
env1_first_0:                 episode reward: -44.2500,                 loss: nan
env1_second_0:                 episode reward: 44.2500,                 loss: nan
Episode: 1341/30000 (4.4700%),                 avg. length: 1186.65,                last time consumption/overall running time: 212.4553s / 18465.7137 s
env0_first_0:                 episode reward: -45.5500,                 loss: 8.0041
env0_second_0:                 episode reward: 45.5500,                 loss: 8.1287
env1_first_0:                 episode reward: -41.8500,                 loss: nan
env1_second_0:                 episode reward: 41.8500,                 loss: nan
Episode: 1361/30000 (4.5367%),                 avg. length: 1177.05,                last time consumption/overall running time: 205.6071s / 18671.3208 s
env0_first_0:                 episode reward: -51.1500,                 loss: 9.1763
env0_second_0:                 episode reward: 51.1500,                 loss: 9.1172
env1_first_0:                 episode reward: -37.4500,                 loss: nan
env1_second_0:                 episode reward: 37.4500,                 loss: nan
Episode: 1381/30000 (4.6033%),                 avg. length: 1453.15,                last time consumption/overall running time: 255.6801s / 18927.0009 s
env0_first_0:                 episode reward: -33.4000,                 loss: 6.0243
env0_second_0:                 episode reward: 33.4000,                 loss: 6.1541
env1_first_0:                 episode reward: -32.1500,                 loss: nan
env1_second_0:                 episode reward: 32.1500,                 loss: nan
Episode: 1401/30000 (4.6700%),                 avg. length: 1385.25,                last time consumption/overall running time: 240.6621s / 19167.6629 s
env0_first_0:                 episode reward: -32.3000,                 loss: 6.0999
env0_second_0:                 episode reward: 32.3000,                 loss: 6.3602
env1_first_0:                 episode reward: -35.6000,                 loss: nan
env1_second_0:                 episode reward: 35.6000,                 loss: nan
Episode: 1421/30000 (4.7367%),                 avg. length: 904.5,                last time consumption/overall running time: 160.5292s / 19328.1921 s
env0_first_0:                 episode reward: -50.9500,                 loss: 11.1378
env0_second_0:                 episode reward: 50.9500,                 loss: 11.7418
env1_first_0:                 episode reward: -49.6500,                 loss: nan
env1_second_0:                 episode reward: 49.6500,                 loss: nan
Episode: 1441/30000 (4.8033%),                 avg. length: 859.8,                last time consumption/overall running time: 156.0032s / 19484.1953 s
env0_first_0:                 episode reward: -53.0500,                 loss: 14.8581
env0_second_0:                 episode reward: 53.0500,                 loss: 14.7217
env1_first_0:                 episode reward: -50.6500,                 loss: nan
env1_second_0:                 episode reward: 50.6500,                 loss: nan
Episode: 1461/30000 (4.8700%),                 avg. length: 877.4,                last time consumption/overall running time: 158.6138s / 19642.8091 s
env0_first_0:                 episode reward: -51.9500,                 loss: 12.4697
env0_second_0:                 episode reward: 51.9500,                 loss: 12.5420
env1_first_0:                 episode reward: -53.2000,                 loss: nan
env1_second_0:                 episode reward: 53.2000,                 loss: nan
Episode: 1481/30000 (4.9367%),                 avg. length: 1066.05,                last time consumption/overall running time: 186.3186s / 19829.1276 s
env0_first_0:                 episode reward: -58.4000,                 loss: 11.4966
env0_second_0:                 episode reward: 58.4000,                 loss: 11.4690
env1_first_0:                 episode reward: -53.0000,                 loss: nan
env1_second_0:                 episode reward: 53.0000,                 loss: nan
Episode: 1501/30000 (5.0033%),                 avg. length: 946.95,                last time consumption/overall running time: 161.0817s / 19990.2093 s
env0_first_0:                 episode reward: -47.9500,                 loss: 13.5445
env0_second_0:                 episode reward: 47.9500,                 loss: 13.4101
env1_first_0:                 episode reward: -55.8500,                 loss: nan
env1_second_0:                 episode reward: 55.8500,                 loss: nan
Episode: 1521/30000 (5.0700%),                 avg. length: 977.15,                last time consumption/overall running time: 163.9456s / 20154.1549 s
env0_first_0:                 episode reward: -52.8000,                 loss: 12.1145
env0_second_0:                 episode reward: 52.8000,                 loss: 12.1215
env1_first_0:                 episode reward: -41.0000,                 loss: nan
env1_second_0:                 episode reward: 41.0000,                 loss: nan
Episode: 1541/30000 (5.1367%),                 avg. length: 922.85,                last time consumption/overall running time: 169.1344s / 20323.2893 s
env0_first_0:                 episode reward: -49.4000,                 loss: 11.9766
env0_second_0:                 episode reward: 49.4000,                 loss: 12.0483
env1_first_0:                 episode reward: -55.9500,                 loss: nan
env1_second_0:                 episode reward: 55.9500,                 loss: nan
Episode: 1561/30000 (5.2033%),                 avg. length: 964.75,                last time consumption/overall running time: 172.7104s / 20495.9997 s
env0_first_0:                 episode reward: -46.2000,                 loss: 11.2381
env0_second_0:                 episode reward: 46.2000,                 loss: 10.9930
env1_first_0:                 episode reward: -37.6000,                 loss: nan
env1_second_0:                 episode reward: 37.6000,                 loss: nan
Episode: 1581/30000 (5.2700%),                 avg. length: 1210.25,                last time consumption/overall running time: 214.2722s / 20710.2719 s
env0_first_0:                 episode reward: -37.7500,                 loss: 7.6671
env0_second_0:                 episode reward: 37.7500,                 loss: 7.6184
env1_first_0:                 episode reward: -29.5500,                 loss: nan
env1_second_0:                 episode reward: 29.5500,                 loss: nan
Episode: 1601/30000 (5.3367%),                 avg. length: 833.2,                last time consumption/overall running time: 146.4856s / 20856.7575 s
env0_first_0:                 episode reward: -48.3500,                 loss: 14.7767
env0_second_0:                 episode reward: 48.3500,                 loss: 14.9323
env1_first_0:                 episode reward: -49.1000,                 loss: nan
env1_second_0:                 episode reward: 49.1000,                 loss: nan
Episode: 1621/30000 (5.4033%),                 avg. length: 772.4,                last time consumption/overall running time: 139.8912s / 20996.6487 s
env0_first_0:                 episode reward: -54.2000,                 loss: 14.8581
env0_second_0:                 episode reward: 54.2000,                 loss: 14.7914
env1_first_0:                 episode reward: -53.8000,                 loss: nan
env1_second_0:                 episode reward: 53.8000,                 loss: nan
Episode: 1641/30000 (5.4700%),                 avg. length: 673.8,                last time consumption/overall running time: 121.2126s / 21117.8613 s
env0_first_0:                 episode reward: -65.5500,                 loss: 19.3205
env0_second_0:                 episode reward: 65.5500,                 loss: 19.2174
env1_first_0:                 episode reward: -52.6000,                 loss: nan
env1_second_0:                 episode reward: 52.6000,                 loss: nan
Episode: 1661/30000 (5.5367%),                 avg. length: 710.35,                last time consumption/overall running time: 131.4452s / 21249.3065 s
env0_first_0:                 episode reward: -57.1000,                 loss: 17.2248
env0_second_0:                 episode reward: 57.1000,                 loss: 16.9276
env1_first_0:                 episode reward: -48.9000,                 loss: nan
env1_second_0:                 episode reward: 48.9000,                 loss: nan
Episode: 1681/30000 (5.6033%),                 avg. length: 715.35,                last time consumption/overall running time: 129.0421s / 21378.3486 s
env0_first_0:                 episode reward: -61.8500,                 loss: 16.8548
env0_second_0:                 episode reward: 61.8500,                 loss: 17.2093
env1_first_0:                 episode reward: -52.0000,                 loss: nan
env1_second_0:                 episode reward: 52.0000,                 loss: nan
Episode: 1701/30000 (5.6700%),                 avg. length: 648.35,                last time consumption/overall running time: 118.7807s / 21497.1293 s
env0_first_0:                 episode reward: -54.1000,                 loss: 21.0055
env0_second_0:                 episode reward: 54.1000,                 loss: 20.7666
env1_first_0:                 episode reward: -63.9000,                 loss: nan
env1_second_0:                 episode reward: 63.9000,                 loss: nan
Episode: 1721/30000 (5.7367%),                 avg. length: 771.2,                last time consumption/overall running time: 140.4746s / 21637.6039 s
env0_first_0:                 episode reward: -58.5500,                 loss: 18.0738
env0_second_0:                 episode reward: 58.5500,                 loss: 17.9769
env1_first_0:                 episode reward: -54.5500,                 loss: nan
env1_second_0:                 episode reward: 54.5500,                 loss: nan
Episode: 1741/30000 (5.8033%),                 avg. length: 672.55,                last time consumption/overall running time: 122.4297s / 21760.0336 s
env0_first_0:                 episode reward: -61.8000,                 loss: 19.1638
env0_second_0:                 episode reward: 61.8000,                 loss: 19.3783
env1_first_0:                 episode reward: -51.2000,                 loss: nan
env1_second_0:                 episode reward: 51.2000,                 loss: nan
Episode: 1761/30000 (5.8700%),                 avg. length: 606.0,                last time consumption/overall running time: 105.8720s / 21865.9056 s
env0_first_0:                 episode reward: -57.3500,                 loss: 22.9906
env0_second_0:                 episode reward: 57.3500,                 loss: 23.3753
env1_first_0:                 episode reward: -67.5000,                 loss: nan
env1_second_0:                 episode reward: 67.5000,                 loss: nan
Episode: 1781/30000 (5.9367%),                 avg. length: 579.3,                last time consumption/overall running time: 109.0853s / 21974.9908 s
env0_first_0:                 episode reward: -53.4000,                 loss: 25.6796
env0_second_0:                 episode reward: 53.4000,                 loss: 25.2358
env1_first_0:                 episode reward: -66.8000,                 loss: nan
env1_second_0:                 episode reward: 66.8000,                 loss: nan
Episode: 1801/30000 (6.0033%),                 avg. length: 641.2,                last time consumption/overall running time: 117.0851s / 22092.0759 s
env0_first_0:                 episode reward: -53.3000,                 loss: 19.7428
env0_second_0:                 episode reward: 53.3000,                 loss: 19.8099
env1_first_0:                 episode reward: -63.2000,                 loss: nan
env1_second_0:                 episode reward: 63.2000,                 loss: nan
Episode: 1821/30000 (6.0700%),                 avg. length: 536.35,                last time consumption/overall running time: 95.1357s / 22187.2116 s
env0_first_0:                 episode reward: -59.8000,                 loss: 24.1093
env0_second_0:                 episode reward: 59.8000,                 loss: 24.6661
env1_first_0:                 episode reward: -71.4500,                 loss: nan
env1_second_0:                 episode reward: 71.4500,                 loss: nan
Episode: 1841/30000 (6.1367%),                 avg. length: 437.4,                last time consumption/overall running time: 80.6113s / 22267.8229 s
env0_first_0:                 episode reward: -79.3000,                 loss: 32.7953
env0_second_0:                 episode reward: 79.3000,                 loss: 33.0875
env1_first_0:                 episode reward: -59.0500,                 loss: nan
env1_second_0:                 episode reward: 59.0500,                 loss: nan
Episode: 1861/30000 (6.2033%),                 avg. length: 557.55,                last time consumption/overall running time: 98.8812s / 22366.7042 s
env0_first_0:                 episode reward: -62.4000,                 loss: 31.3110
env0_second_0:                 episode reward: 62.4000,                 loss: 30.8531
env1_first_0:                 episode reward: -53.9500,                 loss: nan
env1_second_0:                 episode reward: 53.9500,                 loss: nan
Episode: 1881/30000 (6.2700%),                 avg. length: 453.45,                last time consumption/overall running time: 85.5621s / 22452.2662 s
env0_first_0:                 episode reward: -68.7500,                 loss: 31.2954
env0_second_0:                 episode reward: 68.7500,                 loss: 31.0789
env1_first_0:                 episode reward: -69.6000,                 loss: nan
env1_second_0:                 episode reward: 69.6000,                 loss: nan
Episode: 1901/30000 (6.3367%),                 avg. length: 469.95,                last time consumption/overall running time: 85.9823s / 22538.2486 s
env0_first_0:                 episode reward: -84.4000,                 loss: 33.4545
env0_second_0:                 episode reward: 84.4000,                 loss: 33.1119
env1_first_0:                 episode reward: -67.5000,                 loss: nan
env1_second_0:                 episode reward: 67.5000,                 loss: nan
Episode: 1921/30000 (6.4033%),                 avg. length: 594.9,                last time consumption/overall running time: 106.7493s / 22644.9979 s
env0_first_0:                 episode reward: -63.2500,                 loss: 25.1048
env0_second_0:                 episode reward: 63.2500,                 loss: 25.4533
env1_first_0:                 episode reward: -66.3000,                 loss: nan
env1_second_0:                 episode reward: 66.3000,                 loss: nan
Episode: 1941/30000 (6.4700%),                 avg. length: 536.5,                last time consumption/overall running time: 94.8779s / 22739.8758 s
env0_first_0:                 episode reward: -73.0500,                 loss: 26.9511
env0_second_0:                 episode reward: 73.0500,                 loss: 26.8081
env1_first_0:                 episode reward: -71.4000,                 loss: nan
env1_second_0:                 episode reward: 71.4000,                 loss: nan
Episode: 1961/30000 (6.5367%),                 avg. length: 607.3,                last time consumption/overall running time: 111.2226s / 22851.0984 s
env0_first_0:                 episode reward: -69.3000,                 loss: 22.6410
env0_second_0:                 episode reward: 69.3000,                 loss: 21.6249
env1_first_0:                 episode reward: -64.7000,                 loss: nan
env1_second_0:                 episode reward: 64.7000,                 loss: nan
Episode: 1981/30000 (6.6033%),                 avg. length: 447.5,                last time consumption/overall running time: 86.0892s / 22937.1876 s
env0_first_0:                 episode reward: -68.5000,                 loss: 32.7388
env0_second_0:                 episode reward: 68.5000,                 loss: 32.6640
env1_first_0:                 episode reward: -71.0000,                 loss: nan
env1_second_0:                 episode reward: 71.0000,                 loss: nan
Episode: 2001/30000 (6.6700%),                 avg. length: 542.6,                last time consumption/overall running time: 100.0631s / 23037.2507 s
env0_first_0:                 episode reward: -69.1500,                 loss: 26.3629
env0_second_0:                 episode reward: 69.1500,                 loss: 25.9430
env1_first_0:                 episode reward: -71.5500,                 loss: nan
env1_second_0:                 episode reward: 71.5500,                 loss: nan
Episode: 2021/30000 (6.7367%),                 avg. length: 504.55,                last time consumption/overall running time: 96.9035s / 23134.1542 s
env0_first_0:                 episode reward: -76.5500,                 loss: 28.7546
env0_second_0:                 episode reward: 76.5500,                 loss: 28.5275
env1_first_0:                 episode reward: -62.2500,                 loss: nan
env1_second_0:                 episode reward: 62.2500,                 loss: nan
Episode: 2041/30000 (6.8033%),                 avg. length: 415.3,                last time consumption/overall running time: 80.6998s / 23214.8541 s
env0_first_0:                 episode reward: -74.7000,                 loss: 36.0846
env0_second_0:                 episode reward: 74.7000,                 loss: 35.9255
env1_first_0:                 episode reward: -76.6500,                 loss: nan
env1_second_0:                 episode reward: 76.6500,                 loss: nan
Episode: 2061/30000 (6.8700%),                 avg. length: 913.3,                last time consumption/overall running time: 163.3229s / 23378.1769 s
env0_first_0:                 episode reward: -36.5500,                 loss: 21.2943
env0_second_0:                 episode reward: 36.5500,                 loss: 20.5513
env1_first_0:                 episode reward: -56.0500,                 loss: nan
env1_second_0:                 episode reward: 56.0500,                 loss: nan
Episode: 2081/30000 (6.9367%),                 avg. length: 688.15,                last time consumption/overall running time: 128.0136s / 23506.1906 s
env0_first_0:                 episode reward: -57.4500,                 loss: 20.8647
env0_second_0:                 episode reward: 57.4500,                 loss: 20.9636
env1_first_0:                 episode reward: -59.4500,                 loss: nan
env1_second_0:                 episode reward: 59.4500,                 loss: nan
Episode: 2101/30000 (7.0033%),                 avg. length: 528.1,                last time consumption/overall running time: 95.0924s / 23601.2830 s
env0_first_0:                 episode reward: -74.1000,                 loss: 29.7095
env0_second_0:                 episode reward: 74.1000,                 loss: 29.2819
env1_first_0:                 episode reward: -72.1000,                 loss: nan
env1_second_0:                 episode reward: 72.1000,                 loss: nan
Episode: 2121/30000 (7.0700%),                 avg. length: 450.45,                last time consumption/overall running time: 87.7953s / 23689.0783 s
env0_first_0:                 episode reward: -73.0000,                 loss: 36.1598
env0_second_0:                 episode reward: 73.0000,                 loss: 38.6751
env1_first_0:                 episode reward: -74.0000,                 loss: nan
env1_second_0:                 episode reward: 74.0000,                 loss: nan
Episode: 2141/30000 (7.1367%),                 avg. length: 488.1,                last time consumption/overall running time: 93.5693s / 23782.6476 s
env0_first_0:                 episode reward: -72.5000,                 loss: 32.2171
env0_second_0:                 episode reward: 72.5000,                 loss: 34.9907
env1_first_0:                 episode reward: -67.1500,                 loss: nan
env1_second_0:                 episode reward: 67.1500,                 loss: nan
Episode: 2161/30000 (7.2033%),                 avg. length: 1357.5,                last time consumption/overall running time: 224.4003s / 24007.0478 s
env0_first_0:                 episode reward: -23.7000,                 loss: 8.3458
env0_second_0:                 episode reward: 23.7000,                 loss: 10.3646
env1_first_0:                 episode reward: -24.3500,                 loss: nan
env1_second_0:                 episode reward: 24.3500,                 loss: nan
Episode: 2181/30000 (7.2700%),                 avg. length: 589.25,                last time consumption/overall running time: 99.7166s / 24106.7644 s
env0_first_0:                 episode reward: -54.8500,                 loss: 18.7794
env0_second_0:                 episode reward: 54.8500,                 loss: 21.3077
env1_first_0:                 episode reward: -70.4000,                 loss: nan
env1_second_0:                 episode reward: 70.4000,                 loss: nan
Episode: 2201/30000 (7.3367%),                 avg. length: 400.35,                last time consumption/overall running time: 79.3895s / 24186.1538 s
env0_first_0:                 episode reward: -75.0500,                 loss: 35.8723
env0_second_0:                 episode reward: 75.0500,                 loss: 38.4097
env1_first_0:                 episode reward: -76.0000,                 loss: nan
env1_second_0:                 episode reward: 76.0000,                 loss: nan
Episode: 2221/30000 (7.4033%),                 avg. length: 372.9,                last time consumption/overall running time: 75.9839s / 24262.1378 s
env0_first_0:                 episode reward: -81.6000,                 loss: 37.2627
env0_second_0:                 episode reward: 81.6000,                 loss: 38.9362
env1_first_0:                 episode reward: -74.1000,                 loss: nan
env1_second_0:                 episode reward: 74.1000,                 loss: nan
Episode: 2241/30000 (7.4700%),                 avg. length: 528.8,                last time consumption/overall running time: 99.8585s / 24361.9962 s
env0_first_0:                 episode reward: -72.7000,                 loss: 29.3174
env0_second_0:                 episode reward: 72.7000,                 loss: 29.6264
env1_first_0:                 episode reward: -74.3000,                 loss: nan
env1_second_0:                 episode reward: 74.3000,                 loss: nan
Episode: 2261/30000 (7.5367%),                 avg. length: 487.25,                last time consumption/overall running time: 91.8340s / 24453.8302 s
env0_first_0:                 episode reward: -73.0500,                 loss: 33.2278
env0_second_0:                 episode reward: 73.0500,                 loss: 34.2119
env1_first_0:                 episode reward: -65.0000,                 loss: nan
env1_second_0:                 episode reward: 65.0000,                 loss: nan
Episode: 2281/30000 (7.6033%),                 avg. length: 620.15,                last time consumption/overall running time: 115.6679s / 24569.4982 s
env0_first_0:                 episode reward: -54.3500,                 loss: 26.1388
env0_second_0:                 episode reward: 54.3500,                 loss: 26.2435
env1_first_0:                 episode reward: -66.8000,                 loss: nan
env1_second_0:                 episode reward: 66.8000,                 loss: nan
Episode: 2301/30000 (7.6700%),                 avg. length: 687.8,                last time consumption/overall running time: 119.0897s / 24688.5878 s
env0_first_0:                 episode reward: -60.7000,                 loss: 20.5032
env0_second_0:                 episode reward: 60.7000,                 loss: 20.9129
env1_first_0:                 episode reward: -34.5500,                 loss: nan
env1_second_0:                 episode reward: 34.5500,                 loss: nan
Episode: 2321/30000 (7.7367%),                 avg. length: 1133.65,                last time consumption/overall running time: 197.1501s / 24885.7380 s
env0_first_0:                 episode reward: -39.6500,                 loss: 17.8317
env0_second_0:                 episode reward: 39.6500,                 loss: 17.4071
env1_first_0:                 episode reward: -63.8500,                 loss: nan
env1_second_0:                 episode reward: 63.8500,                 loss: nan
Episode: 2341/30000 (7.8033%),                 avg. length: 1727.0,                last time consumption/overall running time: 279.0526s / 25164.7905 s
env0_first_0:                 episode reward: -20.3500,                 loss: 2.4925
env0_second_0:                 episode reward: 20.3500,                 loss: 2.5564
env1_first_0:                 episode reward: -10.1000,                 loss: nan
env1_second_0:                 episode reward: 10.1000,                 loss: nan
Episode: 2361/30000 (7.8700%),                 avg. length: 1711.05,                last time consumption/overall running time: 278.5589s / 25443.3495 s
env0_first_0:                 episode reward: -20.5000,                 loss: 7.3015
env0_second_0:                 episode reward: 20.5000,                 loss: 6.9023
env1_first_0:                 episode reward: -29.3000,                 loss: nan
env1_second_0:                 episode reward: 29.3000,                 loss: nan
Episode: 2381/30000 (7.9367%),                 avg. length: 1784.0,                last time consumption/overall running time: 301.3310s / 25744.6805 s
env0_first_0:                 episode reward: -21.8500,                 loss: 2.1049
env0_second_0:                 episode reward: 21.8500,                 loss: 2.5528
env1_first_0:                 episode reward: -10.5500,                 loss: nan
env1_second_0:                 episode reward: 10.5500,                 loss: nan
Episode: 2401/30000 (8.0033%),                 avg. length: 1628.5,                last time consumption/overall running time: 265.7961s / 26010.4765 s
env0_first_0:                 episode reward: -39.0000,                 loss: 11.3455
env0_second_0:                 episode reward: 39.0000,                 loss: 12.6557
env1_first_0:                 episode reward: -20.5000,                 loss: nan
env1_second_0:                 episode reward: 20.5000,                 loss: nan
Episode: 2421/30000 (8.0700%),                 avg. length: 1574.3,                last time consumption/overall running time: 266.7795s / 26277.2561 s
env0_first_0:                 episode reward: -20.7500,                 loss: 7.6375
env0_second_0:                 episode reward: 20.7500,                 loss: 8.6362
env1_first_0:                 episode reward: -34.1500,                 loss: nan
env1_second_0:                 episode reward: 34.1500,                 loss: nan
Episode: 2441/30000 (8.1367%),                 avg. length: 1784.0,                last time consumption/overall running time: 307.6032s / 26584.8592 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0157
env0_second_0:                 episode reward: 0.0000,                 loss: 0.8826
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2461/30000 (8.2033%),                 avg. length: 1784.0,                last time consumption/overall running time: 296.9451s / 26881.8044 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0701
env0_second_0:                 episode reward: 0.0000,                 loss: 0.9380
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2481/30000 (8.2700%),                 avg. length: 1784.0,                last time consumption/overall running time: 304.7684s / 27186.5728 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0662
env0_second_0:                 episode reward: 0.0000,                 loss: 2.4267
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2501/30000 (8.3367%),                 avg. length: 1784.0,                last time consumption/overall running time: 305.7443s / 27492.3170 s
env0_first_0:                 episode reward: 0.2000,                 loss: -0.0218
env0_second_0:                 episode reward: -0.2000,                 loss: 2.9552
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 2521/30000 (8.4033%),                 avg. length: 1784.0,                last time consumption/overall running time: 309.2644s / 27801.5814 s
env0_first_0:                 episode reward: 4.9500,                 loss: 1.5435
env0_second_0:                 episode reward: -4.9500,                 loss: 16.7721
env1_first_0:                 episode reward: 8.8500,                 loss: nan
env1_second_0:                 episode reward: -8.8500,                 loss: nan
Episode: 2541/30000 (8.4700%),                 avg. length: 1784.0,                last time consumption/overall running time: 308.7934s / 28110.3748 s
env0_first_0:                 episode reward: -7.2500,                 loss: 0.4753
env0_second_0:                 episode reward: 7.2500,                 loss: 5.4717
env1_first_0:                 episode reward: -6.4000,                 loss: nan
env1_second_0:                 episode reward: 6.4000,                 loss: nan
Episode: 2561/30000 (8.5367%),                 avg. length: 1336.6,                last time consumption/overall running time: 233.8988s / 28344.2735 s
env0_first_0:                 episode reward: -49.0500,                 loss: 3.3487
env0_second_0:                 episode reward: 49.0500,                 loss: 8.5225
env1_first_0:                 episode reward: -49.2500,                 loss: nan
env1_second_0:                 episode reward: 49.2500,                 loss: nan
Episode: 2581/30000 (8.6033%),                 avg. length: 924.85,                last time consumption/overall running time: 163.6704s / 28507.9439 s
env0_first_0:                 episode reward: -64.2500,                 loss: 5.3387
env0_second_0:                 episode reward: 64.2500,                 loss: 10.7303
env1_first_0:                 episode reward: -63.3500,                 loss: nan
env1_second_0:                 episode reward: 63.3500,                 loss: nan
Episode: 2601/30000 (8.6700%),                 avg. length: 823.75,                last time consumption/overall running time: 152.2293s / 28660.1732 s
env0_first_0:                 episode reward: -54.6000,                 loss: 6.5202
env0_second_0:                 episode reward: 54.6000,                 loss: 12.3895
env1_first_0:                 episode reward: -62.6500,                 loss: nan
env1_second_0:                 episode reward: 62.6500,                 loss: nan
Episode: 2621/30000 (8.7367%),                 avg. length: 622.8,                last time consumption/overall running time: 119.5988s / 28779.7720 s
env0_first_0:                 episode reward: -75.6000,                 loss: 12.5848
env0_second_0:                 episode reward: 75.6000,                 loss: 17.8414
env1_first_0:                 episode reward: -63.0000,                 loss: nan
env1_second_0:                 episode reward: 63.0000,                 loss: nan
Episode: 2641/30000 (8.8033%),                 avg. length: 510.1,                last time consumption/overall running time: 90.3975s / 28870.1694 s
env0_first_0:                 episode reward: -72.7500,                 loss: 21.9815
env0_second_0:                 episode reward: 72.7500,                 loss: 25.2085
env1_first_0:                 episode reward: -75.9500,                 loss: nan
env1_second_0:                 episode reward: 75.9500,                 loss: nan
Episode: 2661/30000 (8.8700%),                 avg. length: 599.15,                last time consumption/overall running time: 111.8798s / 28982.0492 s
env0_first_0:                 episode reward: -70.2000,                 loss: 21.0554
env0_second_0:                 episode reward: 70.2000,                 loss: 25.0628
env1_first_0:                 episode reward: -71.1500,                 loss: nan
env1_second_0:                 episode reward: 71.1500,                 loss: nan
Episode: 2681/30000 (8.9367%),                 avg. length: 483.05,                last time consumption/overall running time: 93.5796s / 29075.6288 s
env0_first_0:                 episode reward: -71.8000,                 loss: 26.3799
env0_second_0:                 episode reward: 71.8000,                 loss: 30.5546
env1_first_0:                 episode reward: -72.9000,                 loss: nan
env1_second_0:                 episode reward: 72.9000,                 loss: nan
Episode: 2701/30000 (9.0033%),                 avg. length: 626.4,                last time consumption/overall running time: 112.6400s / 29188.2688 s
env0_first_0:                 episode reward: -62.7500,                 loss: 24.5494
env0_second_0:                 episode reward: 62.7500,                 loss: 28.0103
env1_first_0:                 episode reward: -74.6000,                 loss: nan
env1_second_0:                 episode reward: 74.6000,                 loss: nan
Episode: 2721/30000 (9.0700%),                 avg. length: 860.6,                last time consumption/overall running time: 153.9784s / 29342.2472 s
env0_first_0:                 episode reward: -66.7500,                 loss: 15.2514
env0_second_0:                 episode reward: 66.7500,                 loss: 19.3639
env1_first_0:                 episode reward: -52.9000,                 loss: nan
env1_second_0:                 episode reward: 52.9000,                 loss: nan
Episode: 2741/30000 (9.1367%),                 avg. length: 497.2,                last time consumption/overall running time: 92.4248s / 29434.6720 s
env0_first_0:                 episode reward: -58.5500,                 loss: 30.9382
env0_second_0:                 episode reward: 58.5500,                 loss: 33.2524
env1_first_0:                 episode reward: -77.5000,                 loss: nan
env1_second_0:                 episode reward: 77.5000,                 loss: nan
Episode: 2761/30000 (9.2033%),                 avg. length: 494.6,                last time consumption/overall running time: 92.9362s / 29527.6082 s
env0_first_0:                 episode reward: -63.9500,                 loss: 29.1419
env0_second_0:                 episode reward: 63.9500,                 loss: 33.3081
env1_first_0:                 episode reward: -71.4000,                 loss: nan
env1_second_0:                 episode reward: 71.4000,                 loss: nan
Episode: 2781/30000 (9.2700%),                 avg. length: 500.75,                last time consumption/overall running time: 90.2544s / 29617.8626 s
env0_first_0:                 episode reward: -73.7000,                 loss: 31.2796
env0_second_0:                 episode reward: 73.7000,                 loss: 36.4768
env1_first_0:                 episode reward: -63.7000,                 loss: nan
env1_second_0:                 episode reward: 63.7000,                 loss: nan
Episode: 2801/30000 (9.3367%),                 avg. length: 459.0,                last time consumption/overall running time: 86.1666s / 29704.0292 s
env0_first_0:                 episode reward: -71.0500,                 loss: 36.0518
env0_second_0:                 episode reward: 71.0500,                 loss: 39.2979
env1_first_0:                 episode reward: -67.9000,                 loss: nan
env1_second_0:                 episode reward: 67.9000,                 loss: nan
Episode: 2821/30000 (9.4033%),                 avg. length: 523.5,                last time consumption/overall running time: 98.3117s / 29802.3409 s
env0_first_0:                 episode reward: -69.3500,                 loss: 31.4369
env0_second_0:                 episode reward: 69.3500,                 loss: 35.2583
env1_first_0:                 episode reward: -59.9000,                 loss: nan
env1_second_0:                 episode reward: 59.9000,                 loss: nan
Episode: 2841/30000 (9.4700%),                 avg. length: 454.85,                last time consumption/overall running time: 86.8631s / 29889.2040 s
env0_first_0:                 episode reward: -73.7000,                 loss: 33.5943
env0_second_0:                 episode reward: 73.7000,                 loss: 37.4438
env1_first_0:                 episode reward: -77.8000,                 loss: nan
env1_second_0:                 episode reward: 77.8000,                 loss: nan
Episode: 2861/30000 (9.5367%),                 avg. length: 445.7,                last time consumption/overall running time: 87.1503s / 29976.3543 s
env0_first_0:                 episode reward: -72.8000,                 loss: 33.4032
env0_second_0:                 episode reward: 72.8000,                 loss: 36.3647
env1_first_0:                 episode reward: -75.6000,                 loss: nan
env1_second_0:                 episode reward: 75.6000,                 loss: nan
Episode: 2881/30000 (9.6033%),                 avg. length: 342.9,                last time consumption/overall running time: 65.6597s / 30042.0140 s
env0_first_0:                 episode reward: -73.8500,                 loss: 42.5684
env0_second_0:                 episode reward: 73.8500,                 loss: 46.7772
env1_first_0:                 episode reward: -71.3000,                 loss: nan
env1_second_0:                 episode reward: 71.3000,                 loss: nan
Episode: 2901/30000 (9.6700%),                 avg. length: 417.1,                last time consumption/overall running time: 73.9795s / 30115.9935 s
env0_first_0:                 episode reward: -60.1000,                 loss: 37.0321
env0_second_0:                 episode reward: 60.1000,                 loss: 40.4809
env1_first_0:                 episode reward: -77.6000,                 loss: nan
env1_second_0:                 episode reward: 77.6000,                 loss: nan
Episode: 2921/30000 (9.7367%),                 avg. length: 777.6,                last time consumption/overall running time: 132.9571s / 30248.9506 s
env0_first_0:                 episode reward: -54.5000,                 loss: 28.9633
env0_second_0:                 episode reward: 54.5000,                 loss: 33.2792
env1_first_0:                 episode reward: -51.3500,                 loss: nan
env1_second_0:                 episode reward: 51.3500,                 loss: nan
Episode: 2941/30000 (9.8033%),                 avg. length: 1531.25,                last time consumption/overall running time: 263.3901s / 30512.3407 s
env0_first_0:                 episode reward: -15.7500,                 loss: 5.9527
env0_second_0:                 episode reward: 15.7500,                 loss: 10.5366
env1_first_0:                 episode reward: -13.8500,                 loss: nan
env1_second_0:                 episode reward: 13.8500,                 loss: nan
Episode: 2961/30000 (9.8700%),                 avg. length: 464.85,                last time consumption/overall running time: 80.1327s / 30592.4734 s
env0_first_0:                 episode reward: -72.1000,                 loss: 24.7952
env0_second_0:                 episode reward: 72.1000,                 loss: 28.6859
env1_first_0:                 episode reward: -67.1000,                 loss: nan
env1_second_0:                 episode reward: 67.1000,                 loss: nan
Episode: 2981/30000 (9.9367%),                 avg. length: 485.9,                last time consumption/overall running time: 84.9510s / 30677.4244 s
env0_first_0:                 episode reward: -71.1500,                 loss: 47.6250
env0_second_0:                 episode reward: 71.1500,                 loss: 50.8731
env1_first_0:                 episode reward: -59.5000,                 loss: nan
env1_second_0:                 episode reward: 59.5000,                 loss: nan
Episode: 3001/30000 (10.0033%),                 avg. length: 1541.1,                last time consumption/overall running time: 253.8893s / 30931.3137 s
env0_first_0:                 episode reward: -10.7500,                 loss: 4.8962
env0_second_0:                 episode reward: 10.7500,                 loss: 10.1228
env1_first_0:                 episode reward: -10.6000,                 loss: nan
env1_second_0:                 episode reward: 10.6000,                 loss: nan
Episode: 3021/30000 (10.0700%),                 avg. length: 1320.25,                last time consumption/overall running time: 218.1599s / 31149.4736 s
env0_first_0:                 episode reward: -48.0000,                 loss: 5.5579
env0_second_0:                 episode reward: 48.0000,                 loss: 8.2155
env1_first_0:                 episode reward: -34.8000,                 loss: nan
env1_second_0:                 episode reward: 34.8000,                 loss: nan
Episode: 3041/30000 (10.1367%),                 avg. length: 1041.55,                last time consumption/overall running time: 180.2056s / 31329.6793 s
env0_first_0:                 episode reward: -50.6500,                 loss: 9.1273
env0_second_0:                 episode reward: 50.6500,                 loss: 16.7831
env1_first_0:                 episode reward: -45.9500,                 loss: nan
env1_second_0:                 episode reward: 45.9500,                 loss: nan
Episode: 3061/30000 (10.2033%),                 avg. length: 489.05,                last time consumption/overall running time: 92.8002s / 31422.4794 s
env0_first_0:                 episode reward: -70.1000,                 loss: 32.0130
env0_second_0:                 episode reward: 70.1000,                 loss: 34.7638
env1_first_0:                 episode reward: -79.2500,                 loss: nan
env1_second_0:                 episode reward: 79.2500,                 loss: nan
Episode: 3081/30000 (10.2700%),                 avg. length: 392.95,                last time consumption/overall running time: 71.6480s / 31494.1274 s
env0_first_0:                 episode reward: -68.6000,                 loss: 38.3205
env0_second_0:                 episode reward: 68.6000,                 loss: 42.7553
env1_first_0:                 episode reward: -71.7000,                 loss: nan
env1_second_0:                 episode reward: 71.7000,                 loss: nan
Episode: 3101/30000 (10.3367%),                 avg. length: 636.25,                last time consumption/overall running time: 111.1227s / 31605.2501 s
env0_first_0:                 episode reward: -62.8000,                 loss: 24.6898
env0_second_0:                 episode reward: 62.8000,                 loss: 27.9024
env1_first_0:                 episode reward: -61.2000,                 loss: nan
env1_second_0:                 episode reward: 61.2000,                 loss: nan
Episode: 3121/30000 (10.4033%),                 avg. length: 356.65,                last time consumption/overall running time: 67.6428s / 31672.8929 s
env0_first_0:                 episode reward: -77.6000,                 loss: 42.0429
env0_second_0:                 episode reward: 77.6000,                 loss: 51.1178
env1_first_0:                 episode reward: -67.7500,                 loss: nan
env1_second_0:                 episode reward: 67.7500,                 loss: nan
Episode: 3141/30000 (10.4700%),                 avg. length: 406.1,                last time consumption/overall running time: 78.7902s / 31751.6830 s
env0_first_0:                 episode reward: -68.7000,                 loss: 30.8563
env0_second_0:                 episode reward: 68.7000,                 loss: 35.0147
env1_first_0:                 episode reward: -77.5500,                 loss: nan
env1_second_0:                 episode reward: 77.5500,                 loss: nan
Episode: 3161/30000 (10.5367%),                 avg. length: 355.5,                last time consumption/overall running time: 67.3256s / 31819.0086 s
env0_first_0:                 episode reward: -73.3000,                 loss: 34.7383
env0_second_0:                 episode reward: 73.3000,                 loss: 39.4317
env1_first_0:                 episode reward: -72.3500,                 loss: nan
env1_second_0:                 episode reward: 72.3500,                 loss: nan
Episode: 3181/30000 (10.6033%),                 avg. length: 323.95,                last time consumption/overall running time: 60.6202s / 31879.6287 s
env0_first_0:                 episode reward: -90.3000,                 loss: 40.2300
env0_second_0:                 episode reward: 90.3000,                 loss: 43.8160
env1_first_0:                 episode reward: -71.6000,                 loss: nan
env1_second_0:                 episode reward: 71.6000,                 loss: nan
Episode: 3201/30000 (10.6700%),                 avg. length: 992.2,                last time consumption/overall running time: 167.3543s / 32046.9831 s
env0_first_0:                 episode reward: -59.8500,                 loss: 21.3068
env0_second_0:                 episode reward: 59.8500,                 loss: 24.9367
env1_first_0:                 episode reward: -48.1500,                 loss: nan
env1_second_0:                 episode reward: 48.1500,                 loss: nan
Episode: 3221/30000 (10.7367%),                 avg. length: 1396.15,                last time consumption/overall running time: 222.2022s / 32269.1853 s
env0_first_0:                 episode reward: -50.9000,                 loss: 7.4867
env0_second_0:                 episode reward: 50.9000,                 loss: 10.8452
env1_first_0:                 episode reward: -54.8000,                 loss: nan
env1_second_0:                 episode reward: 54.8000,                 loss: nan
Episode: 3241/30000 (10.8033%),                 avg. length: 315.1,                last time consumption/overall running time: 58.7125s / 32327.8978 s
env0_first_0:                 episode reward: -66.7000,                 loss: 47.7212
env0_second_0:                 episode reward: 66.7000,                 loss: 48.3534
env1_first_0:                 episode reward: -76.0000,                 loss: nan
env1_second_0:                 episode reward: 76.0000,                 loss: nan
Episode: 3261/30000 (10.8700%),                 avg. length: 348.8,                last time consumption/overall running time: 68.0118s / 32395.9097 s
env0_first_0:                 episode reward: -61.8500,                 loss: 36.5348
env0_second_0:                 episode reward: 61.8500,                 loss: 42.1171
env1_first_0:                 episode reward: -70.3000,                 loss: nan
env1_second_0:                 episode reward: 70.3000,                 loss: nan
Episode: 3281/30000 (10.9367%),                 avg. length: 304.5,                last time consumption/overall running time: 61.1669s / 32457.0765 s
env0_first_0:                 episode reward: -66.8500,                 loss: 43.2096
env0_second_0:                 episode reward: 66.8500,                 loss: 45.0835
env1_first_0:                 episode reward: -84.2000,                 loss: nan
env1_second_0:                 episode reward: 84.2000,                 loss: nan
Episode: 3301/30000 (11.0033%),                 avg. length: 342.8,                last time consumption/overall running time: 69.4277s / 32526.5042 s
env0_first_0:                 episode reward: -79.1500,                 loss: 41.7796
env0_second_0:                 episode reward: 79.1500,                 loss: 44.8479
env1_first_0:                 episode reward: -78.4000,                 loss: nan
env1_second_0:                 episode reward: 78.4000,                 loss: nan
Episode: 3321/30000 (11.0700%),                 avg. length: 1482.55,                last time consumption/overall running time: 258.5380s / 32785.0422 s
env0_first_0:                 episode reward: -12.4000,                 loss: 7.7835
env0_second_0:                 episode reward: 12.4000,                 loss: 12.9855
env1_first_0:                 episode reward: -15.7000,                 loss: nan
env1_second_0:                 episode reward: 15.7000,                 loss: nan
Episode: 3341/30000 (11.1367%),                 avg. length: 518.75,                last time consumption/overall running time: 98.3841s / 32883.4263 s
env0_first_0:                 episode reward: -71.4500,                 loss: 23.6915
env0_second_0:                 episode reward: 71.4500,                 loss: 26.6363
env1_first_0:                 episode reward: -61.6500,                 loss: nan
env1_second_0:                 episode reward: 61.6500,                 loss: nan
Episode: 3361/30000 (11.2033%),                 avg. length: 292.15,                last time consumption/overall running time: 54.5450s / 32937.9713 s
env0_first_0:                 episode reward: -93.4000,                 loss: 36.7976
env0_second_0:                 episode reward: 93.4000,                 loss: 43.0246
env1_first_0:                 episode reward: -59.9000,                 loss: nan
env1_second_0:                 episode reward: 59.9000,                 loss: nan
Episode: 3381/30000 (11.2700%),                 avg. length: 366.1,                last time consumption/overall running time: 72.1531s / 33010.1243 s
env0_first_0:                 episode reward: -77.2000,                 loss: 34.8122
env0_second_0:                 episode reward: 77.2000,                 loss: 37.6069
env1_first_0:                 episode reward: -73.2500,                 loss: nan
env1_second_0:                 episode reward: 73.2500,                 loss: nan
Episode: 3401/30000 (11.3367%),                 avg. length: 491.45,                last time consumption/overall running time: 90.1309s / 33100.2552 s
env0_first_0:                 episode reward: -58.5000,                 loss: 34.7527
env0_second_0:                 episode reward: 58.5000,                 loss: 37.6852
env1_first_0:                 episode reward: -68.1000,                 loss: nan
env1_second_0:                 episode reward: 68.1000,                 loss: nan
Episode: 3421/30000 (11.4033%),                 avg. length: 793.2,                last time consumption/overall running time: 134.5666s / 33234.8218 s
env0_first_0:                 episode reward: -47.5000,                 loss: 19.9936
env0_second_0:                 episode reward: 47.5000,                 loss: 23.3512
env1_first_0:                 episode reward: -50.8000,                 loss: nan
env1_second_0:                 episode reward: 50.8000,                 loss: nan
Episode: 3441/30000 (11.4700%),                 avg. length: 318.3,                last time consumption/overall running time: 65.6554s / 33300.4772 s
env0_first_0:                 episode reward: -74.6500,                 loss: 41.7903
env0_second_0:                 episode reward: 74.6500,                 loss: 135.8975
env1_first_0:                 episode reward: -74.8000,                 loss: nan
env1_second_0:                 episode reward: 74.8000,                 loss: nan
Episode: 3461/30000 (11.5367%),                 avg. length: 351.85,                last time consumption/overall running time: 70.4557s / 33370.9329 s
env0_first_0:                 episode reward: -64.0000,                 loss: 39.6315
env0_second_0:                 episode reward: 64.0000,                 loss: 44.9697
env1_first_0:                 episode reward: -79.4000,                 loss: nan
env1_second_0:                 episode reward: 79.4000,                 loss: nan
Episode: 3481/30000 (11.6033%),                 avg. length: 341.5,                last time consumption/overall running time: 62.3487s / 33433.2816 s
env0_first_0:                 episode reward: -72.0500,                 loss: 42.3573
env0_second_0:                 episode reward: 72.0500,                 loss: 45.6516
env1_first_0:                 episode reward: -71.2500,                 loss: nan
env1_second_0:                 episode reward: 71.2500,                 loss: nan
Episode: 3501/30000 (11.6700%),                 avg. length: 1570.5,                last time consumption/overall running time: 275.4963s / 33708.7779 s
env0_first_0:                 episode reward: -7.0500,                 loss: 7.8309
env0_second_0:                 episode reward: 7.0500,                 loss: 10.3950
env1_first_0:                 episode reward: -13.6000,                 loss: nan
env1_second_0:                 episode reward: 13.6000,                 loss: nan
Episode: 3521/30000 (11.7367%),                 avg. length: 1784.0,                last time consumption/overall running time: 309.4528s / 34018.2307 s
env0_first_0:                 episode reward: -0.2000,                 loss: 1.3706
env0_second_0:                 episode reward: 0.2000,                 loss: 3.7710
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 3541/30000 (11.8033%),                 avg. length: 612.75,                last time consumption/overall running time: 109.9493s / 34128.1800 s
env0_first_0:                 episode reward: -65.3000,                 loss: 28.2141
env0_second_0:                 episode reward: 65.3000,                 loss: 34.0427
env1_first_0:                 episode reward: -46.3000,                 loss: nan
env1_second_0:                 episode reward: 46.3000,                 loss: nan
Episode: 3561/30000 (11.8700%),                 avg. length: 633.75,                last time consumption/overall running time: 113.9403s / 34242.1204 s
env0_first_0:                 episode reward: -57.6500,                 loss: 27.7062
env0_second_0:                 episode reward: 57.6500,                 loss: 31.4224
env1_first_0:                 episode reward: -66.6500,                 loss: nan
env1_second_0:                 episode reward: 66.6500,                 loss: nan
Episode: 3581/30000 (11.9367%),                 avg. length: 1145.5,                last time consumption/overall running time: 201.7134s / 34443.8337 s
env0_first_0:                 episode reward: -35.1500,                 loss: 9.1474
env0_second_0:                 episode reward: 35.1500,                 loss: 14.1978
env1_first_0:                 episode reward: -40.6000,                 loss: nan
env1_second_0:                 episode reward: 40.6000,                 loss: nan
Episode: 3601/30000 (12.0033%),                 avg. length: 669.85,                last time consumption/overall running time: 118.3474s / 34562.1811 s
env0_first_0:                 episode reward: -52.7500,                 loss: 23.4521
env0_second_0:                 episode reward: 52.7500,                 loss: 28.0411
env1_first_0:                 episode reward: -53.7000,                 loss: nan
env1_second_0:                 episode reward: 53.7000,                 loss: nan
Episode: 3621/30000 (12.0700%),                 avg. length: 453.1,                last time consumption/overall running time: 81.7920s / 34643.9731 s
env0_first_0:                 episode reward: -65.0500,                 loss: 35.7189
env0_second_0:                 episode reward: 65.0500,                 loss: 41.2725
env1_first_0:                 episode reward: -64.4500,                 loss: nan
env1_second_0:                 episode reward: 64.4500,                 loss: nan
Episode: 3641/30000 (12.1367%),                 avg. length: 567.2,                last time consumption/overall running time: 100.3417s / 34744.3148 s
env0_first_0:                 episode reward: -60.7000,                 loss: 38.2676
env0_second_0:                 episode reward: 60.7000,                 loss: 44.1962
env1_first_0:                 episode reward: -56.6500,                 loss: nan
env1_second_0:                 episode reward: 56.6500,                 loss: nan
Episode: 3661/30000 (12.2033%),                 avg. length: 451.45,                last time consumption/overall running time: 84.9845s / 34829.2993 s
env0_first_0:                 episode reward: -71.8500,                 loss: 35.8169
env0_second_0:                 episode reward: 71.8500,                 loss: 44.1896
env1_first_0:                 episode reward: -64.9500,                 loss: nan
env1_second_0:                 episode reward: 64.9500,                 loss: nan
Episode: 3681/30000 (12.2700%),                 avg. length: 378.75,                last time consumption/overall running time: 75.6389s / 34904.9382 s
env0_first_0:                 episode reward: -64.2500,                 loss: 45.8367
env0_second_0:                 episode reward: 64.2500,                 loss: 50.4534
env1_first_0:                 episode reward: -75.4000,                 loss: nan
env1_second_0:                 episode reward: 75.4000,                 loss: nan
Episode: 3701/30000 (12.3367%),                 avg. length: 412.7,                last time consumption/overall running time: 80.8290s / 34985.7672 s
env0_first_0:                 episode reward: -59.8000,                 loss: 37.0311
env0_second_0:                 episode reward: 59.8000,                 loss: 41.4172
env1_first_0:                 episode reward: -71.0000,                 loss: nan
env1_second_0:                 episode reward: 71.0000,                 loss: nan
Episode: 3721/30000 (12.4033%),                 avg. length: 421.7,                last time consumption/overall running time: 79.7808s / 35065.5480 s
env0_first_0:                 episode reward: -57.8000,                 loss: 34.9851
env0_second_0:                 episode reward: 57.8000,                 loss: 40.8881
env1_first_0:                 episode reward: -71.0500,                 loss: nan
env1_second_0:                 episode reward: 71.0500,                 loss: nan
Episode: 3741/30000 (12.4700%),                 avg. length: 374.25,                last time consumption/overall running time: 69.2943s / 35134.8423 s
env0_first_0:                 episode reward: -63.0000,                 loss: 40.6375
env0_second_0:                 episode reward: 63.0000,                 loss: 46.1216
env1_first_0:                 episode reward: -72.7500,                 loss: nan
env1_second_0:                 episode reward: 72.7500,                 loss: nan
Episode: 3761/30000 (12.5367%),                 avg. length: 458.8,                last time consumption/overall running time: 82.9682s / 35217.8105 s
env0_first_0:                 episode reward: -73.3500,                 loss: 34.6123
env0_second_0:                 episode reward: 73.3500,                 loss: 38.2896
env1_first_0:                 episode reward: -66.8000,                 loss: nan
env1_second_0:                 episode reward: 66.8000,                 loss: nan
Episode: 3781/30000 (12.6033%),                 avg. length: 429.9,                last time consumption/overall running time: 79.9692s / 35297.7797 s
env0_first_0:                 episode reward: -59.5000,                 loss: 37.9178
env0_second_0:                 episode reward: 59.5000,                 loss: 42.0629
env1_first_0:                 episode reward: -63.4000,                 loss: nan
env1_second_0:                 episode reward: 63.4000,                 loss: nan
Episode: 3801/30000 (12.6700%),                 avg. length: 806.0,                last time consumption/overall running time: 144.9142s / 35442.6939 s
env0_first_0:                 episode reward: -52.1000,                 loss: 29.3953
env0_second_0:                 episode reward: 52.1000,                 loss: 32.2902
env1_first_0:                 episode reward: -51.0000,                 loss: nan
env1_second_0:                 episode reward: 51.0000,                 loss: nan
Episode: 3821/30000 (12.7367%),                 avg. length: 350.1,                last time consumption/overall running time: 68.8775s / 35511.5714 s
env0_first_0:                 episode reward: -71.7000,                 loss: 43.8909
env0_second_0:                 episode reward: 71.7000,                 loss: 46.2968
env1_first_0:                 episode reward: -72.5500,                 loss: nan
env1_second_0:                 episode reward: 72.5500,                 loss: nan
Episode: 3841/30000 (12.8033%),                 avg. length: 1072.2,                last time consumption/overall running time: 184.3727s / 35695.9441 s
env0_first_0:                 episode reward: -43.0000,                 loss: 22.8083
env0_second_0:                 episode reward: 43.0000,                 loss: 26.3590
env1_first_0:                 episode reward: -48.5500,                 loss: nan
env1_second_0:                 episode reward: 48.5500,                 loss: nan
Episode: 3861/30000 (12.8700%),                 avg. length: 1211.75,                last time consumption/overall running time: 199.8367s / 35895.7808 s
env0_first_0:                 episode reward: -7.6000,                 loss: 9.5681
env0_second_0:                 episode reward: 7.6000,                 loss: 13.6527
env1_first_0:                 episode reward: -17.1500,                 loss: nan
env1_second_0:                 episode reward: 17.1500,                 loss: nan
Episode: 3881/30000 (12.9367%),                 avg. length: 942.0,                last time consumption/overall running time: 162.4801s / 36058.2610 s
env0_first_0:                 episode reward: -27.2000,                 loss: 15.0904
env0_second_0:                 episode reward: 27.2000,                 loss: 18.0052
env1_first_0:                 episode reward: -21.6000,                 loss: nan
env1_second_0:                 episode reward: 21.6000,                 loss: nan
Episode: 3901/30000 (13.0033%),                 avg. length: 576.6,                last time consumption/overall running time: 97.4555s / 36155.7164 s
env0_first_0:                 episode reward: -41.0000,                 loss: 24.2099
env0_second_0:                 episode reward: 41.0000,                 loss: 24.2289
env1_first_0:                 episode reward: -70.9000,                 loss: nan
env1_second_0:                 episode reward: 70.9000,                 loss: nan
Episode: 3921/30000 (13.0700%),                 avg. length: 795.55,                last time consumption/overall running time: 136.6462s / 36292.3626 s
env0_first_0:                 episode reward: -38.5500,                 loss: 25.7538
env0_second_0:                 episode reward: 38.5500,                 loss: 25.9435
env1_first_0:                 episode reward: -44.0000,                 loss: nan
env1_second_0:                 episode reward: 44.0000,                 loss: nan
Episode: 3941/30000 (13.1367%),                 avg. length: 565.75,                last time consumption/overall running time: 97.5815s / 36389.9441 s
env0_first_0:                 episode reward: -66.4500,                 loss: 29.3060
env0_second_0:                 episode reward: 66.4500,                 loss: 28.7804
env1_first_0:                 episode reward: -53.8000,                 loss: nan
env1_second_0:                 episode reward: 53.8000,                 loss: nan
Episode: 3961/30000 (13.2033%),                 avg. length: 580.65,                last time consumption/overall running time: 102.7259s / 36492.6700 s
env0_first_0:                 episode reward: -67.2500,                 loss: 27.0782
env0_second_0:                 episode reward: 67.2500,                 loss: 25.9702
env1_first_0:                 episode reward: -71.6500,                 loss: nan
env1_second_0:                 episode reward: 71.6500,                 loss: nan
Episode: 3981/30000 (13.2700%),                 avg. length: 890.4,                last time consumption/overall running time: 150.0195s / 36642.6895 s
env0_first_0:                 episode reward: -48.9500,                 loss: 17.3539
env0_second_0:                 episode reward: 48.9500,                 loss: 18.6505
env1_first_0:                 episode reward: -55.4000,                 loss: nan
env1_second_0:                 episode reward: 55.4000,                 loss: nan
Episode: 4001/30000 (13.3367%),                 avg. length: 1468.75,                last time consumption/overall running time: 249.2979s / 36891.9874 s
env0_first_0:                 episode reward: -19.3500,                 loss: 8.8796
env0_second_0:                 episode reward: 19.3500,                 loss: 11.3620
env1_first_0:                 episode reward: -29.1500,                 loss: nan
env1_second_0:                 episode reward: 29.1500,                 loss: nan
Episode: 4021/30000 (13.4033%),                 avg. length: 1784.0,                last time consumption/overall running time: 301.5885s / 37193.5759 s
env0_first_0:                 episode reward: -5.6000,                 loss: 1.7117
env0_second_0:                 episode reward: 5.6000,                 loss: 12.6161
env1_first_0:                 episode reward: -5.1000,                 loss: nan
env1_second_0:                 episode reward: 5.1000,                 loss: nan
Episode: 4041/30000 (13.4700%),                 avg. length: 1784.0,                last time consumption/overall running time: 298.5858s / 37492.1617 s
env0_first_0:                 episode reward: -12.0000,                 loss: 1.6422
env0_second_0:                 episode reward: 12.0000,                 loss: 5.2006
env1_first_0:                 episode reward: -14.7500,                 loss: nan
env1_second_0:                 episode reward: 14.7500,                 loss: nan
Episode: 4061/30000 (13.5367%),                 avg. length: 1784.0,                last time consumption/overall running time: 298.1395s / 37790.3012 s
env0_first_0:                 episode reward: -2.0500,                 loss: 0.2071
env0_second_0:                 episode reward: 2.0500,                 loss: 3.3315
env1_first_0:                 episode reward: -2.7500,                 loss: nan
env1_second_0:                 episode reward: 2.7500,                 loss: nan
Episode: 4081/30000 (13.6033%),                 avg. length: 1784.0,                last time consumption/overall running time: 291.4506s / 38081.7517 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0295
env0_second_0:                 episode reward: 0.0000,                 loss: 2.8419
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 4101/30000 (13.6700%),                 avg. length: 1784.0,                last time consumption/overall running time: 295.6486s / 38377.4003 s
env0_first_0:                 episode reward: -0.3000,                 loss: -0.0403
env0_second_0:                 episode reward: 0.3000,                 loss: 44.9574
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 4121/30000 (13.7367%),                 avg. length: 1784.0,                last time consumption/overall running time: 293.2953s / 38670.6956 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0792
env0_second_0:                 episode reward: 0.0000,                 loss: 2.6004
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4141/30000 (13.8033%),                 avg. length: 1784.0,                last time consumption/overall running time: 281.9440s / 38952.6396 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.1005
env0_second_0:                 episode reward: 0.0000,                 loss: 2.0551
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 4161/30000 (13.8700%),                 avg. length: 1784.0,                last time consumption/overall running time: 276.8543s / 39229.4939 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.0805
env0_second_0:                 episode reward: 0.2000,                 loss: 1.4960
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 4181/30000 (13.9367%),                 avg. length: 1784.0,                last time consumption/overall running time: 284.4302s / 39513.9241 s
env0_first_0:                 episode reward: -0.4000,                 loss: -0.0657
env0_second_0:                 episode reward: 0.4000,                 loss: 0.9692
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 4201/30000 (14.0033%),                 avg. length: 1784.0,                last time consumption/overall running time: 291.3520s / 39805.2761 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0739
env0_second_0:                 episode reward: 0.0000,                 loss: 1.3128
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4221/30000 (14.0700%),                 avg. length: 1784.0,                last time consumption/overall running time: 295.7707s / 40101.0468 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0673
env0_second_0:                 episode reward: 0.0000,                 loss: 4.9072
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4241/30000 (14.1367%),                 avg. length: 1784.0,                last time consumption/overall running time: 294.5932s / 40395.6400 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0573
env0_second_0:                 episode reward: 0.0000,                 loss: 3.2357
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4261/30000 (14.2033%),                 avg. length: 1784.0,                last time consumption/overall running time: 286.2450s / 40681.8850 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0654
env0_second_0:                 episode reward: 0.0000,                 loss: 2.1567
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4281/30000 (14.2700%),                 avg. length: 1784.0,                last time consumption/overall running time: 299.5663s / 40981.4513 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0738
env0_second_0:                 episode reward: 0.0000,                 loss: 1.7368
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4301/30000 (14.3367%),                 avg. length: 1784.0,                last time consumption/overall running time: 299.2175s / 41280.6688 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0529
env0_second_0:                 episode reward: 0.0000,                 loss: 1.3488
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4321/30000 (14.4033%),                 avg. length: 1784.0,                last time consumption/overall running time: 300.3237s / 41580.9926 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0326
env0_second_0:                 episode reward: 0.0000,                 loss: 0.8984
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4341/30000 (14.4700%),                 avg. length: 1784.0,                last time consumption/overall running time: 296.4810s / 41877.4736 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0156
env0_second_0:                 episode reward: 0.0000,                 loss: 1.1218
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4361/30000 (14.5367%),                 avg. length: 1784.0,                last time consumption/overall running time: 300.0825s / 42177.5561 s
env0_first_0:                 episode reward: 0.2000,                 loss: -0.0497
env0_second_0:                 episode reward: -0.2000,                 loss: 0.6173
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 4381/30000 (14.6033%),                 avg. length: 1784.0,                last time consumption/overall running time: 298.9254s / 42476.4815 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.0388
env0_second_0:                 episode reward: -0.1000,                 loss: 0.9490
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 4401/30000 (14.6700%),                 avg. length: 1784.0,                last time consumption/overall running time: 297.0813s / 42773.5628 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0606
env0_second_0:                 episode reward: 0.0000,                 loss: 0.8686
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4421/30000 (14.7367%),                 avg. length: 1784.0,                last time consumption/overall running time: 299.0352s / 43072.5980 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0579
env0_second_0:                 episode reward: 0.0000,                 loss: 2.5458
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4441/30000 (14.8033%),                 avg. length: 1784.0,                last time consumption/overall running time: 299.2616s / 43371.8596 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0272
env0_second_0:                 episode reward: 0.0000,                 loss: 0.3112
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 4461/30000 (14.8700%),                 avg. length: 1784.0,                last time consumption/overall running time: 297.0677s / 43668.9274 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.0326
env0_second_0:                 episode reward: -0.0500,                 loss: 0.1153
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 4481/30000 (14.9367%),                 avg. length: 1784.0,                last time consumption/overall running time: 299.0300s / 43967.9574 s
env0_first_0:                 episode reward: 0.2000,                 loss: -0.0195
env0_second_0:                 episode reward: -0.2000,                 loss: 0.1777
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 4501/30000 (15.0033%),                 avg. length: 1784.0,                last time consumption/overall running time: 296.7248s / 44264.6822 s
env0_first_0:                 episode reward: 1.1000,                 loss: -0.0399
env0_second_0:                 episode reward: -1.1000,                 loss: 0.4663
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 4521/30000 (15.0700%),                 avg. length: 1784.0,                last time consumption/overall running time: 300.4079s / 44565.0901 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0655
env0_second_0:                 episode reward: 0.9500,                 loss: 0.3841
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 4541/30000 (15.1367%),                 avg. length: 1784.0,                last time consumption/overall running time: 300.1849s / 44865.2750 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0593
env0_second_0:                 episode reward: 0.0000,                 loss: 0.1668
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4561/30000 (15.2033%),                 avg. length: 1784.0,                last time consumption/overall running time: 299.8455s / 45165.1205 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0586
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0355
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4581/30000 (15.2700%),                 avg. length: 1784.0,                last time consumption/overall running time: 296.6911s / 45461.8117 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.0552
env0_second_0:                 episode reward: -0.1000,                 loss: -0.0134
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4601/30000 (15.3367%),                 avg. length: 1784.0,                last time consumption/overall running time: 298.9243s / 45760.7360 s
env0_first_0:                 episode reward: -1.2500,                 loss: -0.0094
env0_second_0:                 episode reward: 1.2500,                 loss: 0.2764
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 4621/30000 (15.4033%),                 avg. length: 940.85,                last time consumption/overall running time: 164.5650s / 45925.3010 s
env0_first_0:                 episode reward: -54.0000,                 loss: 9.9083
env0_second_0:                 episode reward: 54.0000,                 loss: 10.4617
env1_first_0:                 episode reward: -51.1000,                 loss: nan
env1_second_0:                 episode reward: 51.1000,                 loss: nan
Episode: 4641/30000 (15.4700%),                 avg. length: 940.4,                last time consumption/overall running time: 164.7863s / 46090.0873 s
env0_first_0:                 episode reward: -46.8500,                 loss: 20.9634
env0_second_0:                 episode reward: 46.8500,                 loss: 23.8697
env1_first_0:                 episode reward: -55.8000,                 loss: nan
env1_second_0:                 episode reward: 55.8000,                 loss: nan
Episode: 4661/30000 (15.5367%),                 avg. length: 378.15,                last time consumption/overall running time: 72.8744s / 46162.9617 s
env0_first_0:                 episode reward: -68.6500,                 loss: 38.6999
env0_second_0:                 episode reward: 68.6500,                 loss: 48.0440
env1_first_0:                 episode reward: -72.8000,                 loss: nan
env1_second_0:                 episode reward: 72.8000,                 loss: nan
Episode: 4681/30000 (15.6033%),                 avg. length: 555.25,                last time consumption/overall running time: 104.6124s / 46267.5740 s
env0_first_0:                 episode reward: -65.9500,                 loss: 38.2055
env0_second_0:                 episode reward: 65.9500,                 loss: 42.3704
env1_first_0:                 episode reward: -62.9500,                 loss: nan
env1_second_0:                 episode reward: 62.9500,                 loss: nan
Episode: 4701/30000 (15.6700%),                 avg. length: 360.25,                last time consumption/overall running time: 71.7488s / 46339.3228 s
env0_first_0:                 episode reward: -79.9500,                 loss: 41.8293
env0_second_0:                 episode reward: 79.9500,                 loss: 48.0887
env1_first_0:                 episode reward: -61.5000,                 loss: nan
env1_second_0:                 episode reward: 61.5000,                 loss: nan
Episode: 4721/30000 (15.7367%),                 avg. length: 301.95,                last time consumption/overall running time: 62.5036s / 46401.8265 s
env0_first_0:                 episode reward: -84.7500,                 loss: 44.9820
env0_second_0:                 episode reward: 84.7500,                 loss: 48.3250
env1_first_0:                 episode reward: -63.0500,                 loss: nan
env1_second_0:                 episode reward: 63.0500,                 loss: nan
Episode: 4741/30000 (15.8033%),                 avg. length: 268.8,                last time consumption/overall running time: 57.6409s / 46459.4674 s
env0_first_0:                 episode reward: -80.0000,                 loss: 52.3549
env0_second_0:                 episode reward: 80.0000,                 loss: 54.6238
env1_first_0:                 episode reward: -75.7500,                 loss: nan
env1_second_0:                 episode reward: 75.7500,                 loss: nan
Episode: 4761/30000 (15.8700%),                 avg. length: 305.0,                last time consumption/overall running time: 63.2857s / 46522.7531 s
env0_first_0:                 episode reward: -78.1000,                 loss: 51.6033
env0_second_0:                 episode reward: 78.1000,                 loss: 51.7594
env1_first_0:                 episode reward: -85.9000,                 loss: nan
env1_second_0:                 episode reward: 85.9000,                 loss: nan
Episode: 4781/30000 (15.9367%),                 avg. length: 336.6,                last time consumption/overall running time: 68.0873s / 46590.8404 s
env0_first_0:                 episode reward: -90.9500,                 loss: 42.1896
env0_second_0:                 episode reward: 90.9500,                 loss: 45.8975
env1_first_0:                 episode reward: -81.0000,                 loss: nan
env1_second_0:                 episode reward: 81.0000,                 loss: nan
Episode: 4801/30000 (16.0033%),                 avg. length: 462.65,                last time consumption/overall running time: 88.0018s / 46678.8423 s
env0_first_0:                 episode reward: -68.7000,                 loss: 32.6114
env0_second_0:                 episode reward: 68.7000,                 loss: 37.5639
env1_first_0:                 episode reward: -77.9000,                 loss: nan
env1_second_0:                 episode reward: 77.9000,                 loss: nan
Episode: 4821/30000 (16.0700%),                 avg. length: 1784.0,                last time consumption/overall running time: 310.4724s / 46989.3146 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.4661
env0_second_0:                 episode reward: -0.1000,                 loss: 3.6288
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4841/30000 (16.1367%),                 avg. length: 1784.0,                last time consumption/overall running time: 295.0884s / 47284.4030 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0250
env0_second_0:                 episode reward: 0.0000,                 loss: 2.2635
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4861/30000 (16.2033%),                 avg. length: 1784.0,                last time consumption/overall running time: 295.2284s / 47579.6314 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0056
env0_second_0:                 episode reward: 0.0000,                 loss: 1.9378
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4881/30000 (16.2700%),                 avg. length: 1784.0,                last time consumption/overall running time: 301.6023s / 47881.2337 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.0371
env0_second_0:                 episode reward: -0.1000,                 loss: 1.9143
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 4901/30000 (16.3367%),                 avg. length: 1784.0,                last time consumption/overall running time: 303.6895s / 48184.9233 s
env0_first_0:                 episode reward: 0.4500,                 loss: -0.0711
env0_second_0:                 episode reward: -0.4500,                 loss: 2.0193
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 4921/30000 (16.4033%),                 avg. length: 1784.0,                last time consumption/overall running time: 290.1283s / 48475.0515 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.0555
env0_second_0:                 episode reward: -0.1000,                 loss: 8.3052
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 4941/30000 (16.4700%),                 avg. length: 1784.0,                last time consumption/overall running time: 299.1497s / 48774.2012 s
env0_first_0:                 episode reward: 0.4000,                 loss: -0.0468
env0_second_0:                 episode reward: -0.4000,                 loss: 3.0834
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 4961/30000 (16.5367%),                 avg. length: 1784.0,                last time consumption/overall running time: 304.3411s / 49078.5424 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0335
env0_second_0:                 episode reward: 0.0000,                 loss: 1.7105
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 4981/30000 (16.6033%),                 avg. length: 1784.0,                last time consumption/overall running time: 301.0381s / 49379.5805 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0460
env0_second_0:                 episode reward: 0.0000,                 loss: 2.9370
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5001/30000 (16.6700%),                 avg. length: 1784.0,                last time consumption/overall running time: 301.9654s / 49681.5459 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0477
env0_second_0:                 episode reward: 0.0000,                 loss: 2.4979
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5021/30000 (16.7367%),                 avg. length: 1784.0,                last time consumption/overall running time: 301.6683s / 49983.2142 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0740
env0_second_0:                 episode reward: -0.1000,                 loss: 4.1713
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5041/30000 (16.8033%),                 avg. length: 1784.0,                last time consumption/overall running time: 289.4355s / 50272.6497 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0438
env0_second_0:                 episode reward: 0.0000,                 loss: 1.5245
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5061/30000 (16.8700%),                 avg. length: 1784.0,                last time consumption/overall running time: 292.4586s / 50565.1083 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0305
env0_second_0:                 episode reward: 0.0000,                 loss: 1.1810
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 5081/30000 (16.9367%),                 avg. length: 1784.0,                last time consumption/overall running time: 291.4872s / 50856.5955 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.0250
env0_second_0:                 episode reward: 0.2000,                 loss: 0.7511
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5101/30000 (17.0033%),                 avg. length: 1784.0,                last time consumption/overall running time: 286.5259s / 51143.1214 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0644
env0_second_0:                 episode reward: 0.0000,                 loss: 1.1494
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5121/30000 (17.0700%),                 avg. length: 1784.0,                last time consumption/overall running time: 289.4691s / 51432.5905 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.1234
env0_second_0:                 episode reward: 0.0000,                 loss: 1.2704
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5141/30000 (17.1367%),                 avg. length: 1784.0,                last time consumption/overall running time: 293.2240s / 51725.8146 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.1263
env0_second_0:                 episode reward: 0.0000,                 loss: 1.2659
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5161/30000 (17.2033%),                 avg. length: 1784.0,                last time consumption/overall running time: 291.7911s / 52017.6057 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.1320
env0_second_0:                 episode reward: 0.0000,                 loss: 1.2595
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5181/30000 (17.2700%),                 avg. length: 1784.0,                last time consumption/overall running time: 298.1020s / 52315.7077 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.1227
env0_second_0:                 episode reward: 0.0000,                 loss: 1.0989
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5201/30000 (17.3367%),                 avg. length: 1784.0,                last time consumption/overall running time: 290.8028s / 52606.5105 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.1151
env0_second_0:                 episode reward: 0.0000,                 loss: 0.8296
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5221/30000 (17.4033%),                 avg. length: 1784.0,                last time consumption/overall running time: 300.0837s / 52906.5942 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.1083
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2750
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5241/30000 (17.4700%),                 avg. length: 1784.0,                last time consumption/overall running time: 298.7804s / 53205.3746 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0712
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2261
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5261/30000 (17.5367%),                 avg. length: 1784.0,                last time consumption/overall running time: 299.0257s / 53504.4002 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0702
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2463
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5281/30000 (17.6033%),                 avg. length: 1784.0,                last time consumption/overall running time: 295.9586s / 53800.3588 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.0674
env0_second_0:                 episode reward: 0.2000,                 loss: 0.4700
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 5301/30000 (17.6700%),                 avg. length: 1784.0,                last time consumption/overall running time: 297.0930s / 54097.4518 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.1061
env0_second_0:                 episode reward: 0.0000,                 loss: 0.6980
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 5321/30000 (17.7367%),                 avg. length: 1784.0,                last time consumption/overall running time: 305.5021s / 54402.9539 s
env0_first_0:                 episode reward: -6.0000,                 loss: 0.2783
env0_second_0:                 episode reward: 6.0000,                 loss: 1.5680
env1_first_0:                 episode reward: -6.8000,                 loss: nan
env1_second_0:                 episode reward: 6.8000,                 loss: nan
Episode: 5341/30000 (17.8033%),                 avg. length: 1315.35,                last time consumption/overall running time: 231.4835s / 54634.4374 s
env0_first_0:                 episode reward: -29.5000,                 loss: 9.6962
env0_second_0:                 episode reward: 29.5000,                 loss: 12.1668
env1_first_0:                 episode reward: -34.6500,                 loss: nan
env1_second_0:                 episode reward: 34.6500,                 loss: nan
Episode: 5361/30000 (17.8700%),                 avg. length: 376.0,                last time consumption/overall running time: 71.1696s / 54705.6070 s
env0_first_0:                 episode reward: -69.9000,                 loss: 32.2650
env0_second_0:                 episode reward: 69.9000,                 loss: 36.5415
env1_first_0:                 episode reward: -79.6500,                 loss: nan
env1_second_0:                 episode reward: 79.6500,                 loss: nan
Episode: 5381/30000 (17.9367%),                 avg. length: 877.25,                last time consumption/overall running time: 151.5177s / 54857.1247 s
env0_first_0:                 episode reward: -61.0500,                 loss: 29.8980
env0_second_0:                 episode reward: 61.0500,                 loss: 33.7803
env1_first_0:                 episode reward: -61.1000,                 loss: nan
env1_second_0:                 episode reward: 61.1000,                 loss: nan
Episode: 5401/30000 (18.0033%),                 avg. length: 542.45,                last time consumption/overall running time: 102.1192s / 54959.2439 s
env0_first_0:                 episode reward: -68.1000,                 loss: 40.1198
env0_second_0:                 episode reward: 68.1000,                 loss: 43.5100
env1_first_0:                 episode reward: -64.2000,                 loss: nan
env1_second_0:                 episode reward: 64.2000,                 loss: nan
Episode: 5421/30000 (18.0700%),                 avg. length: 349.7,                last time consumption/overall running time: 68.5322s / 55027.7761 s
env0_first_0:                 episode reward: -79.8000,                 loss: 44.4771
env0_second_0:                 episode reward: 79.8000,                 loss: 51.1843
env1_first_0:                 episode reward: -71.6000,                 loss: nan
env1_second_0:                 episode reward: 71.6000,                 loss: nan
Episode: 5441/30000 (18.1367%),                 avg. length: 865.7,                last time consumption/overall running time: 149.4122s / 55177.1883 s
env0_first_0:                 episode reward: -55.1500,                 loss: 23.3343
env0_second_0:                 episode reward: 55.1500,                 loss: 25.9555
env1_first_0:                 episode reward: -60.3500,                 loss: nan
env1_second_0:                 episode reward: 60.3500,                 loss: nan
Episode: 5461/30000 (18.2033%),                 avg. length: 711.2,                last time consumption/overall running time: 131.0909s / 55308.2792 s
env0_first_0:                 episode reward: -72.6500,                 loss: 31.5533
env0_second_0:                 episode reward: 72.6500,                 loss: 35.0579
env1_first_0:                 episode reward: -70.8500,                 loss: nan
env1_second_0:                 episode reward: 70.8500,                 loss: nan
Episode: 5481/30000 (18.2700%),                 avg. length: 376.95,                last time consumption/overall running time: 71.6824s / 55379.9617 s
env0_first_0:                 episode reward: -88.3000,                 loss: 31.3435
env0_second_0:                 episode reward: 88.3000,                 loss: 33.7130
env1_first_0:                 episode reward: -83.6500,                 loss: nan
env1_second_0:                 episode reward: 83.6500,                 loss: nan
Episode: 5501/30000 (18.3367%),                 avg. length: 1784.0,                last time consumption/overall running time: 306.6046s / 55686.5663 s
env0_first_0:                 episode reward: -0.8000,                 loss: 1.0729
env0_second_0:                 episode reward: 0.8000,                 loss: 12.1913
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 5521/30000 (18.4033%),                 avg. length: 1784.0,                last time consumption/overall running time: 310.7457s / 55997.3120 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0681
env0_second_0:                 episode reward: 0.3500,                 loss: 2.8910
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 5541/30000 (18.4700%),                 avg. length: 1784.0,                last time consumption/overall running time: 301.1819s / 56298.4939 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0649
env0_second_0:                 episode reward: 0.6000,                 loss: 1.9852
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 5561/30000 (18.5367%),                 avg. length: 1784.0,                last time consumption/overall running time: 304.0027s / 56602.4967 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0303
env0_second_0:                 episode reward: 0.4000,                 loss: 2.0280
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 5581/30000 (18.6033%),                 avg. length: 1784.0,                last time consumption/overall running time: 302.4938s / 56904.9904 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0225
env0_second_0:                 episode reward: 0.9000,                 loss: 1.8691
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 5601/30000 (18.6700%),                 avg. length: 1784.0,                last time consumption/overall running time: 297.0165s / 57202.0069 s
env0_first_0:                 episode reward: -0.4000,                 loss: -0.0129
env0_second_0:                 episode reward: 0.4000,                 loss: 3.6145
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 5621/30000 (18.7367%),                 avg. length: 1784.0,                last time consumption/overall running time: 298.6041s / 57500.6110 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0526
env0_second_0:                 episode reward: 0.0000,                 loss: 4.0707
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5641/30000 (18.8033%),                 avg. length: 1784.0,                last time consumption/overall running time: 301.9932s / 57802.6042 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0573
env0_second_0:                 episode reward: 0.0000,                 loss: 2.2559
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5661/30000 (18.8700%),                 avg. length: 1784.0,                last time consumption/overall running time: 291.8481s / 58094.4523 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0476
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2831
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5681/30000 (18.9367%),                 avg. length: 1784.0,                last time consumption/overall running time: 289.8092s / 58384.2616 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0608
env0_second_0:                 episode reward: 0.0000,                 loss: 0.8390
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5701/30000 (19.0033%),                 avg. length: 1784.0,                last time consumption/overall running time: 286.1490s / 58670.4106 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0791
env0_second_0:                 episode reward: 0.0000,                 loss: 0.7702
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5721/30000 (19.0700%),                 avg. length: 1784.0,                last time consumption/overall running time: 300.8301s / 58971.2407 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0985
env0_second_0:                 episode reward: 0.0000,                 loss: 0.8823
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5741/30000 (19.1367%),                 avg. length: 1784.0,                last time consumption/overall running time: 300.1219s / 59271.3626 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.1547
env0_second_0:                 episode reward: 0.0000,                 loss: 0.4234
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5761/30000 (19.2033%),                 avg. length: 1490.2,                last time consumption/overall running time: 254.3696s / 59525.7322 s
env0_first_0:                 episode reward: -38.5500,                 loss: 2.1713
env0_second_0:                 episode reward: 38.5500,                 loss: 4.2105
env1_first_0:                 episode reward: -40.1500,                 loss: nan
env1_second_0:                 episode reward: 40.1500,                 loss: nan
Episode: 5781/30000 (19.2700%),                 avg. length: 1408.05,                last time consumption/overall running time: 246.5786s / 59772.3109 s
env0_first_0:                 episode reward: -63.4000,                 loss: 2.8339
env0_second_0:                 episode reward: 63.4000,                 loss: 5.9467
env1_first_0:                 episode reward: -67.2000,                 loss: nan
env1_second_0:                 episode reward: 67.2000,                 loss: nan
Episode: 5801/30000 (19.3367%),                 avg. length: 1769.6,                last time consumption/overall running time: 307.8461s / 60080.1569 s
env0_first_0:                 episode reward: -9.7500,                 loss: 0.2493
env0_second_0:                 episode reward: 9.7500,                 loss: 2.0175
env1_first_0:                 episode reward: -8.7000,                 loss: nan
env1_second_0:                 episode reward: 8.7000,                 loss: nan
Episode: 5821/30000 (19.4033%),                 avg. length: 1784.0,                last time consumption/overall running time: 302.9968s / 60383.1537 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2132
env0_second_0:                 episode reward: 0.0000,                 loss: 0.5190
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5841/30000 (19.4700%),                 avg. length: 1784.0,                last time consumption/overall running time: 302.8565s / 60686.0102 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2243
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2418
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5861/30000 (19.5367%),                 avg. length: 1784.0,                last time consumption/overall running time: 312.7177s / 60998.7280 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2206
env0_second_0:                 episode reward: 0.0000,                 loss: 0.1725
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5881/30000 (19.6033%),                 avg. length: 1784.0,                last time consumption/overall running time: 296.2238s / 61294.9518 s
env0_first_0:                 episode reward: -0.2500,                 loss: -0.1922
env0_second_0:                 episode reward: 0.2500,                 loss: 0.3216
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 5901/30000 (19.6700%),                 avg. length: 1784.0,                last time consumption/overall running time: 298.9359s / 61593.8876 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.1718
env0_second_0:                 episode reward: 0.1500,                 loss: 0.6762
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 5921/30000 (19.7367%),                 avg. length: 1784.0,                last time consumption/overall running time: 310.9836s / 61904.8712 s
env0_first_0:                 episode reward: -0.3000,                 loss: -0.1535
env0_second_0:                 episode reward: 0.3000,                 loss: 1.2759
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 5941/30000 (19.8033%),                 avg. length: 1784.0,                last time consumption/overall running time: 298.6146s / 62203.4858 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.1990
env0_second_0:                 episode reward: 0.0000,                 loss: 1.0317
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 5961/30000 (19.8700%),                 avg. length: 1784.0,                last time consumption/overall running time: 298.0206s / 62501.5064 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.2442
env0_second_0:                 episode reward: 0.2000,                 loss: 0.4453
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 5981/30000 (19.9367%),                 avg. length: 1784.0,                last time consumption/overall running time: 302.2835s / 62803.7898 s
env0_first_0:                 episode reward: -1.2500,                 loss: -0.2578
env0_second_0:                 episode reward: 1.2500,                 loss: 1.2731
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 6001/30000 (20.0033%),                 avg. length: 1784.0,                last time consumption/overall running time: 301.4267s / 63105.2165 s
env0_first_0:                 episode reward: -2.8000,                 loss: -0.1523
env0_second_0:                 episode reward: 2.8000,                 loss: 0.9329
env1_first_0:                 episode reward: -4.8000,                 loss: nan
env1_second_0:                 episode reward: 4.8000,                 loss: nan
Episode: 6021/30000 (20.0700%),                 avg. length: 1784.0,                last time consumption/overall running time: 309.7259s / 63414.9424 s
env0_first_0:                 episode reward: -2.0000,                 loss: -0.2295
env0_second_0:                 episode reward: 2.0000,                 loss: 1.0622
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 6041/30000 (20.1367%),                 avg. length: 1784.0,                last time consumption/overall running time: 303.7155s / 63718.6580 s
env0_first_0:                 episode reward: -1.0000,                 loss: -0.3584
env0_second_0:                 episode reward: 1.0000,                 loss: 1.4562
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 6061/30000 (20.2033%),                 avg. length: 1784.0,                last time consumption/overall running time: 312.0891s / 64030.7471 s
env0_first_0:                 episode reward: 0.5000,                 loss: -0.3676
env0_second_0:                 episode reward: -0.5000,                 loss: 0.8635
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 6081/30000 (20.2700%),                 avg. length: 1784.0,                last time consumption/overall running time: 308.0766s / 64338.8237 s
env0_first_0:                 episode reward: -0.6000,                 loss: -0.3587
env0_second_0:                 episode reward: 0.6000,                 loss: 1.0247
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 6101/30000 (20.3367%),                 avg. length: 1784.0,                last time consumption/overall running time: 302.0266s / 64640.8504 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.4037
env0_second_0:                 episode reward: 0.1500,                 loss: 1.1663
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 6121/30000 (20.4033%),                 avg. length: 1784.0,                last time consumption/overall running time: 299.9567s / 64940.8070 s
env0_first_0:                 episode reward: -0.4000,                 loss: -0.3825
env0_second_0:                 episode reward: 0.4000,                 loss: 0.5101
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 6141/30000 (20.4700%),                 avg. length: 1784.0,                last time consumption/overall running time: 301.5089s / 65242.3159 s
env0_first_0:                 episode reward: -0.5500,                 loss: -0.3423
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2016
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 6161/30000 (20.5367%),                 avg. length: 1378.15,                last time consumption/overall running time: 235.9725s / 65478.2884 s
env0_first_0:                 episode reward: -28.0000,                 loss: 3.2645
env0_second_0:                 episode reward: 28.0000,                 loss: 4.0707
env1_first_0:                 episode reward: -34.7500,                 loss: nan
env1_second_0:                 episode reward: 34.7500,                 loss: nan
Episode: 6181/30000 (20.6033%),                 avg. length: 459.4,                last time consumption/overall running time: 88.3723s / 65566.6608 s
env0_first_0:                 episode reward: -68.5500,                 loss: 18.8846
env0_second_0:                 episode reward: 68.5500,                 loss: 19.1500
env1_first_0:                 episode reward: -77.7500,                 loss: nan
env1_second_0:                 episode reward: 77.7500,                 loss: nan
Episode: 6201/30000 (20.6700%),                 avg. length: 395.85,                last time consumption/overall running time: 76.7174s / 65643.3782 s
env0_first_0:                 episode reward: -67.3500,                 loss: 31.5977
env0_second_0:                 episode reward: 67.3500,                 loss: 31.8602
env1_first_0:                 episode reward: -78.2500,                 loss: nan
env1_second_0:                 episode reward: 78.2500,                 loss: nan
Episode: 6221/30000 (20.7367%),                 avg. length: 317.4,                last time consumption/overall running time: 58.1175s / 65701.4957 s
env0_first_0:                 episode reward: -81.4500,                 loss: 34.9087
env0_second_0:                 episode reward: 81.4500,                 loss: 36.7973
env1_first_0:                 episode reward: -76.4000,                 loss: nan
env1_second_0:                 episode reward: 76.4000,                 loss: nan
Episode: 6241/30000 (20.8033%),                 avg. length: 314.2,                last time consumption/overall running time: 58.7253s / 65760.2210 s
env0_first_0:                 episode reward: -70.1000,                 loss: 33.4817
env0_second_0:                 episode reward: 70.1000,                 loss: 34.7701
env1_first_0:                 episode reward: -84.2000,                 loss: nan
env1_second_0:                 episode reward: 84.2000,                 loss: nan
Episode: 6261/30000 (20.8700%),                 avg. length: 827.85,                last time consumption/overall running time: 142.9332s / 65903.1543 s
env0_first_0:                 episode reward: -43.7000,                 loss: 23.7002
env0_second_0:                 episode reward: 43.7000,                 loss: 25.7501
env1_first_0:                 episode reward: -52.8000,                 loss: nan
env1_second_0:                 episode reward: 52.8000,                 loss: nan
Episode: 6281/30000 (20.9367%),                 avg. length: 1784.0,                last time consumption/overall running time: 306.7755s / 66209.9297 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0624
env0_second_0:                 episode reward: 0.0000,                 loss: 0.7771
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 6301/30000 (21.0033%),                 avg. length: 1784.0,                last time consumption/overall running time: 308.9473s / 66518.8770 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0729
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0455
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 6321/30000 (21.0700%),                 avg. length: 1784.0,                last time consumption/overall running time: 307.9874s / 66826.8644 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.1361
env0_second_0:                 episode reward: 0.0000,                 loss: -0.0937
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 6341/30000 (21.1367%),                 avg. length: 1743.15,                last time consumption/overall running time: 305.0402s / 67131.9046 s
env0_first_0:                 episode reward: -4.8000,                 loss: 1.1058
env0_second_0:                 episode reward: 4.8000,                 loss: 1.3172
env1_first_0:                 episode reward: -8.3500,                 loss: nan
env1_second_0:                 episode reward: 8.3500,                 loss: nan
Episode: 6361/30000 (21.2033%),                 avg. length: 1012.6,                last time consumption/overall running time: 179.0897s / 67310.9943 s
env0_first_0:                 episode reward: -35.6000,                 loss: 8.4560
env0_second_0:                 episode reward: 35.6000,                 loss: 9.9702
env1_first_0:                 episode reward: -45.5500,                 loss: nan
env1_second_0:                 episode reward: 45.5500,                 loss: nan
Episode: 6381/30000 (21.2700%),                 avg. length: 459.4,                last time consumption/overall running time: 80.4711s / 67391.4654 s
env0_first_0:                 episode reward: -51.5500,                 loss: 21.8340
env0_second_0:                 episode reward: 51.5500,                 loss: 24.1327
env1_first_0:                 episode reward: -86.6000,                 loss: nan
env1_second_0:                 episode reward: 86.6000,                 loss: nan
Episode: 6401/30000 (21.3367%),                 avg. length: 483.8,                last time consumption/overall running time: 93.5593s / 67485.0247 s
env0_first_0:                 episode reward: -64.2000,                 loss: 36.3913
env0_second_0:                 episode reward: 64.2000,                 loss: 38.7229
env1_first_0:                 episode reward: -59.5500,                 loss: nan
env1_second_0:                 episode reward: 59.5500,                 loss: nan
Episode: 6421/30000 (21.4033%),                 avg. length: 270.2,                last time consumption/overall running time: 51.4166s / 67536.4413 s
env0_first_0:                 episode reward: -79.6500,                 loss: 44.5528
env0_second_0:                 episode reward: 79.6500,                 loss: 45.9782
env1_first_0:                 episode reward: -83.7000,                 loss: nan
env1_second_0:                 episode reward: 83.7000,                 loss: nan
Episode: 6441/30000 (21.4700%),                 avg. length: 407.35,                last time consumption/overall running time: 77.2247s / 67613.6660 s
env0_first_0:                 episode reward: -78.1500,                 loss: 35.1038
env0_second_0:                 episode reward: 78.1500,                 loss: 35.8763
env1_first_0:                 episode reward: -77.2500,                 loss: nan
env1_second_0:                 episode reward: 77.2500,                 loss: nan
Episode: 6461/30000 (21.5367%),                 avg. length: 372.5,                last time consumption/overall running time: 70.9061s / 67684.5721 s
env0_first_0:                 episode reward: -89.0500,                 loss: 36.9265
env0_second_0:                 episode reward: 89.0500,                 loss: 42.6041
env1_first_0:                 episode reward: -70.2000,                 loss: nan
env1_second_0:                 episode reward: 70.2000,                 loss: nan
Episode: 6481/30000 (21.6033%),                 avg. length: 395.95,                last time consumption/overall running time: 74.4676s / 67759.0397 s
env0_first_0:                 episode reward: -75.8500,                 loss: 37.4536
env0_second_0:                 episode reward: 75.8500,                 loss: 41.7767
env1_first_0:                 episode reward: -75.0500,                 loss: nan
env1_second_0:                 episode reward: 75.0500,                 loss: nan
Episode: 6501/30000 (21.6700%),                 avg. length: 424.0,                last time consumption/overall running time: 74.7124s / 67833.7521 s
env0_first_0:                 episode reward: -68.5000,                 loss: 31.7521
env0_second_0:                 episode reward: 68.5000,                 loss: 35.0103
env1_first_0:                 episode reward: -74.1500,                 loss: nan
env1_second_0:                 episode reward: 74.1500,                 loss: nan
Episode: 6521/30000 (21.7367%),                 avg. length: 486.2,                last time consumption/overall running time: 84.1139s / 67917.8661 s
env0_first_0:                 episode reward: -77.9000,                 loss: 20.3137
env0_second_0:                 episode reward: 77.9000,                 loss: 24.2598
env1_first_0:                 episode reward: -71.7500,                 loss: nan
env1_second_0:                 episode reward: 71.7500,                 loss: nan
Episode: 6541/30000 (21.8033%),                 avg. length: 529.4,                last time consumption/overall running time: 89.1036s / 68006.9697 s
env0_first_0:                 episode reward: -73.2500,                 loss: 21.8618
env0_second_0:                 episode reward: 73.2500,                 loss: 23.4038
env1_first_0:                 episode reward: -74.3000,                 loss: nan
env1_second_0:                 episode reward: 74.3000,                 loss: nan
Episode: 6561/30000 (21.8700%),                 avg. length: 832.7,                last time consumption/overall running time: 141.1350s / 68148.1047 s
env0_first_0:                 episode reward: -59.3500,                 loss: 18.2521
env0_second_0:                 episode reward: 59.3500,                 loss: 18.6113
env1_first_0:                 episode reward: -60.6500,                 loss: nan
env1_second_0:                 episode reward: 60.6500,                 loss: nan
Episode: 6581/30000 (21.9367%),                 avg. length: 466.35,                last time consumption/overall running time: 86.3356s / 68234.4403 s
env0_first_0:                 episode reward: -70.8500,                 loss: 25.7167
env0_second_0:                 episode reward: 70.8500,                 loss: 25.5719
env1_first_0:                 episode reward: -75.0500,                 loss: nan
env1_second_0:                 episode reward: 75.0500,                 loss: nan
Episode: 6601/30000 (22.0033%),                 avg. length: 327.5,                last time consumption/overall running time: 63.8251s / 68298.2654 s
env0_first_0:                 episode reward: -82.8000,                 loss: 38.0770
env0_second_0:                 episode reward: 82.8000,                 loss: 39.2701
env1_first_0:                 episode reward: -84.0000,                 loss: nan
env1_second_0:                 episode reward: 84.0000,                 loss: nan
Episode: 6621/30000 (22.0700%),                 avg. length: 457.55,                last time consumption/overall running time: 79.3220s / 68377.5874 s
env0_first_0:                 episode reward: -69.2500,                 loss: 28.9140
env0_second_0:                 episode reward: 69.2500,                 loss: 29.5910
env1_first_0:                 episode reward: -73.1000,                 loss: nan
env1_second_0:                 episode reward: 73.1000,                 loss: nan
Episode: 6641/30000 (22.1367%),                 avg. length: 658.15,                last time consumption/overall running time: 113.8314s / 68491.4188 s
env0_first_0:                 episode reward: -43.9500,                 loss: 17.0333
env0_second_0:                 episode reward: 43.9500,                 loss: 15.5733
env1_first_0:                 episode reward: -44.6000,                 loss: nan
env1_second_0:                 episode reward: 44.6000,                 loss: nan
Episode: 6661/30000 (22.2033%),                 avg. length: 275.3,                last time consumption/overall running time: 56.7316s / 68548.1504 s
env0_first_0:                 episode reward: -93.7000,                 loss: 37.2271
env0_second_0:                 episode reward: 93.7000,                 loss: 38.2528
env1_first_0:                 episode reward: -80.2000,                 loss: nan
env1_second_0:                 episode reward: 80.2000,                 loss: nan
Episode: 6681/30000 (22.2700%),                 avg. length: 281.3,                last time consumption/overall running time: 54.8187s / 68602.9691 s
env0_first_0:                 episode reward: -83.7500,                 loss: 35.0521
env0_second_0:                 episode reward: 83.7500,                 loss: 36.9599
env1_first_0:                 episode reward: -82.5500,                 loss: nan
env1_second_0:                 episode reward: 82.5500,                 loss: nan
Episode: 6701/30000 (22.3367%),                 avg. length: 365.55,                last time consumption/overall running time: 67.8875s / 68670.8566 s
env0_first_0:                 episode reward: -82.0000,                 loss: 34.4324
env0_second_0:                 episode reward: 82.0000,                 loss: 34.8221
env1_first_0:                 episode reward: -75.1500,                 loss: nan
env1_second_0:                 episode reward: 75.1500,                 loss: nan
Episode: 6721/30000 (22.4033%),                 avg. length: 321.95,                last time consumption/overall running time: 61.5902s / 68732.4468 s
env0_first_0:                 episode reward: -84.0500,                 loss: 30.5682
env0_second_0:                 episode reward: 84.0500,                 loss: 29.6322
env1_first_0:                 episode reward: -76.6500,                 loss: nan
env1_second_0:                 episode reward: 76.6500,                 loss: nan
Episode: 6741/30000 (22.4700%),                 avg. length: 342.3,                last time consumption/overall running time: 61.9870s / 68794.4339 s
env0_first_0:                 episode reward: -71.3500,                 loss: 35.3957
env0_second_0:                 episode reward: 71.3500,                 loss: 34.9897
env1_first_0:                 episode reward: -79.2500,                 loss: nan
env1_second_0:                 episode reward: 79.2500,                 loss: nan
Episode: 6761/30000 (22.5367%),                 avg. length: 586.1,                last time consumption/overall running time: 106.4797s / 68900.9136 s
env0_first_0:                 episode reward: -70.5000,                 loss: 23.5055
env0_second_0:                 episode reward: 70.5000,                 loss: 25.2706
env1_first_0:                 episode reward: -59.8000,                 loss: nan
env1_second_0:                 episode reward: 59.8000,                 loss: nan
Episode: 6781/30000 (22.6033%),                 avg. length: 407.95,                last time consumption/overall running time: 78.4594s / 68979.3729 s
env0_first_0:                 episode reward: -73.9000,                 loss: 28.4483
env0_second_0:                 episode reward: 73.9000,                 loss: 28.6892
env1_first_0:                 episode reward: -81.5000,                 loss: nan
env1_second_0:                 episode reward: 81.5000,                 loss: nan
Episode: 6801/30000 (22.6700%),                 avg. length: 435.05,                last time consumption/overall running time: 82.5610s / 69061.9339 s
env0_first_0:                 episode reward: -71.3500,                 loss: 24.4461
env0_second_0:                 episode reward: 71.3500,                 loss: 27.5682
env1_first_0:                 episode reward: -84.4000,                 loss: nan
env1_second_0:                 episode reward: 84.4000,                 loss: nan
Episode: 6821/30000 (22.7367%),                 avg. length: 436.95,                last time consumption/overall running time: 82.5127s / 69144.4466 s
env0_first_0:                 episode reward: -78.4000,                 loss: 30.2253
env0_second_0:                 episode reward: 78.4000,                 loss: 53.0166
env1_first_0:                 episode reward: -75.5500,                 loss: nan
env1_second_0:                 episode reward: 75.5500,                 loss: nan
Episode: 6841/30000 (22.8033%),                 avg. length: 408.75,                last time consumption/overall running time: 76.5470s / 69220.9937 s
env0_first_0:                 episode reward: -71.7000,                 loss: 33.1837
env0_second_0:                 episode reward: 71.7000,                 loss: 35.5121
env1_first_0:                 episode reward: -69.2500,                 loss: nan
env1_second_0:                 episode reward: 69.2500,                 loss: nan
Episode: 6861/30000 (22.8700%),                 avg. length: 477.25,                last time consumption/overall running time: 90.4358s / 69311.4294 s
env0_first_0:                 episode reward: -67.7000,                 loss: 28.3569
env0_second_0:                 episode reward: 67.7000,                 loss: 28.5432
env1_first_0:                 episode reward: -73.6000,                 loss: nan
env1_second_0:                 episode reward: 73.6000,                 loss: nan
Episode: 6881/30000 (22.9367%),                 avg. length: 564.55,                last time consumption/overall running time: 102.6462s / 69414.0757 s
env0_first_0:                 episode reward: -63.8000,                 loss: 25.5216
env0_second_0:                 episode reward: 63.8000,                 loss: 26.0413
env1_first_0:                 episode reward: -63.3500,                 loss: nan
env1_second_0:                 episode reward: 63.3500,                 loss: nan
Episode: 6901/30000 (23.0033%),                 avg. length: 511.7,                last time consumption/overall running time: 94.3171s / 69508.3928 s
env0_first_0:                 episode reward: -74.7500,                 loss: 27.4155
env0_second_0:                 episode reward: 74.7500,                 loss: 27.4047
env1_first_0:                 episode reward: -74.4500,                 loss: nan
env1_second_0:                 episode reward: 74.4500,                 loss: nan
Episode: 6921/30000 (23.0700%),                 avg. length: 444.55,                last time consumption/overall running time: 82.4086s / 69590.8014 s
env0_first_0:                 episode reward: -70.7500,                 loss: 26.9331
env0_second_0:                 episode reward: 70.7500,                 loss: 27.2106
env1_first_0:                 episode reward: -72.7000,                 loss: nan
env1_second_0:                 episode reward: 72.7000,                 loss: nan
Episode: 6941/30000 (23.1367%),                 avg. length: 685.9,                last time consumption/overall running time: 122.6609s / 69713.4623 s
env0_first_0:                 episode reward: -68.6000,                 loss: 21.3110
env0_second_0:                 episode reward: 68.6000,                 loss: 21.9862
env1_first_0:                 episode reward: -60.3000,                 loss: nan
env1_second_0:                 episode reward: 60.3000,                 loss: nan
Episode: 6961/30000 (23.2033%),                 avg. length: 386.1,                last time consumption/overall running time: 77.2072s / 69790.6695 s
env0_first_0:                 episode reward: -75.8500,                 loss: 34.7517
env0_second_0:                 episode reward: 75.8500,                 loss: 35.6866
env1_first_0:                 episode reward: -72.6000,                 loss: nan
env1_second_0:                 episode reward: 72.6000,                 loss: nan
Episode: 6981/30000 (23.2700%),                 avg. length: 429.4,                last time consumption/overall running time: 76.5257s / 69867.1952 s
env0_first_0:                 episode reward: -67.4500,                 loss: 29.5648
env0_second_0:                 episode reward: 67.4500,                 loss: 32.1794
env1_first_0:                 episode reward: -73.3500,                 loss: nan
env1_second_0:                 episode reward: 73.3500,                 loss: nan
Episode: 7001/30000 (23.3367%),                 avg. length: 389.35,                last time consumption/overall running time: 75.9900s / 69943.1852 s
env0_first_0:                 episode reward: -82.0500,                 loss: 30.2663
env0_second_0:                 episode reward: 82.0500,                 loss: 32.2534
env1_first_0:                 episode reward: -78.8000,                 loss: nan
env1_second_0:                 episode reward: 78.8000,                 loss: nan
Episode: 7021/30000 (23.4033%),                 avg. length: 250.4,                last time consumption/overall running time: 49.3654s / 69992.5506 s
env0_first_0:                 episode reward: -91.6000,                 loss: 37.6880
env0_second_0:                 episode reward: 91.6000,                 loss: 34.3171
env1_first_0:                 episode reward: -81.9500,                 loss: nan
env1_second_0:                 episode reward: 81.9500,                 loss: nan
Episode: 7041/30000 (23.4700%),                 avg. length: 290.05,                last time consumption/overall running time: 57.8771s / 70050.4277 s
env0_first_0:                 episode reward: -86.2500,                 loss: 36.5388
env0_second_0:                 episode reward: 86.2500,                 loss: 37.3201
env1_first_0:                 episode reward: -72.5000,                 loss: nan
env1_second_0:                 episode reward: 72.5000,                 loss: nan
Episode: 7061/30000 (23.5367%),                 avg. length: 529.9,                last time consumption/overall running time: 94.1714s / 70144.5991 s
env0_first_0:                 episode reward: -71.9000,                 loss: 23.7934
env0_second_0:                 episode reward: 71.9000,                 loss: 25.5672
env1_first_0:                 episode reward: -70.9500,                 loss: nan
env1_second_0:                 episode reward: 70.9500,                 loss: nan
Episode: 7081/30000 (23.6033%),                 avg. length: 465.9,                last time consumption/overall running time: 87.6892s / 70232.2883 s
env0_first_0:                 episode reward: -78.7000,                 loss: 28.6309
env0_second_0:                 episode reward: 78.7000,                 loss: 31.0302
env1_first_0:                 episode reward: -69.0000,                 loss: nan
env1_second_0:                 episode reward: 69.0000,                 loss: nan
Episode: 7101/30000 (23.6700%),                 avg. length: 358.85,                last time consumption/overall running time: 69.9443s / 70302.2326 s
env0_first_0:                 episode reward: -85.7000,                 loss: 34.0940
env0_second_0:                 episode reward: 85.7000,                 loss: 43.0561
env1_first_0:                 episode reward: -79.3000,                 loss: nan
env1_second_0:                 episode reward: 79.3000,                 loss: nan
Episode: 7121/30000 (23.7367%),                 avg. length: 374.25,                last time consumption/overall running time: 72.9523s / 70375.1849 s
env0_first_0:                 episode reward: -77.7500,                 loss: 27.1725
env0_second_0:                 episode reward: 77.7500,                 loss: 30.1927
env1_first_0:                 episode reward: -89.2000,                 loss: nan
env1_second_0:                 episode reward: 89.2000,                 loss: nan
Episode: 7141/30000 (23.8033%),                 avg. length: 566.2,                last time consumption/overall running time: 104.8939s / 70480.0788 s
env0_first_0:                 episode reward: -68.6500,                 loss: 19.2434
env0_second_0:                 episode reward: 68.6500,                 loss: 23.4638
env1_first_0:                 episode reward: -74.0500,                 loss: nan
env1_second_0:                 episode reward: 74.0500,                 loss: nan
Episode: 7161/30000 (23.8700%),                 avg. length: 705.2,                last time consumption/overall running time: 129.4897s / 70609.5686 s
env0_first_0:                 episode reward: -59.3500,                 loss: 28.1971
env0_second_0:                 episode reward: 59.3500,                 loss: 31.9099
env1_first_0:                 episode reward: -47.4000,                 loss: nan
env1_second_0:                 episode reward: 47.4000,                 loss: nan
Episode: 7181/30000 (23.9367%),                 avg. length: 423.3,                last time consumption/overall running time: 81.0782s / 70690.6468 s
env0_first_0:                 episode reward: -63.2500,                 loss: 26.8737
env0_second_0:                 episode reward: 63.2500,                 loss: 30.2483
env1_first_0:                 episode reward: -78.4500,                 loss: nan
env1_second_0:                 episode reward: 78.4500,                 loss: nan
Episode: 7201/30000 (24.0033%),                 avg. length: 368.65,                last time consumption/overall running time: 71.4913s / 70762.1381 s
env0_first_0:                 episode reward: -75.5000,                 loss: 28.5033
env0_second_0:                 episode reward: 75.5000,                 loss: 32.2092
env1_first_0:                 episode reward: -69.8000,                 loss: nan
env1_second_0:                 episode reward: 69.8000,                 loss: nan
Episode: 7221/30000 (24.0700%),                 avg. length: 343.9,                last time consumption/overall running time: 67.0075s / 70829.1456 s
env0_first_0:                 episode reward: -83.7500,                 loss: 39.1264
env0_second_0:                 episode reward: 83.7500,                 loss: 41.6431
env1_first_0:                 episode reward: -64.3000,                 loss: nan
env1_second_0:                 episode reward: 64.3000,                 loss: nan
Episode: 7241/30000 (24.1367%),                 avg. length: 382.05,                last time consumption/overall running time: 69.0046s / 70898.1502 s
env0_first_0:                 episode reward: -72.5500,                 loss: 33.8304
env0_second_0:                 episode reward: 72.5500,                 loss: 35.2524
env1_first_0:                 episode reward: -71.1500,                 loss: nan
env1_second_0:                 episode reward: 71.1500,                 loss: nan
Episode: 7261/30000 (24.2033%),                 avg. length: 408.5,                last time consumption/overall running time: 77.5214s / 70975.6716 s
env0_first_0:                 episode reward: -76.9500,                 loss: 35.0252
env0_second_0:                 episode reward: 76.9500,                 loss: 36.8103
env1_first_0:                 episode reward: -56.1000,                 loss: nan
env1_second_0:                 episode reward: 56.1000,                 loss: nan
Episode: 7281/30000 (24.2700%),                 avg. length: 393.65,                last time consumption/overall running time: 76.7395s / 71052.4111 s
env0_first_0:                 episode reward: -70.9000,                 loss: 33.1380
env0_second_0:                 episode reward: 70.9000,                 loss: 35.1608
env1_first_0:                 episode reward: -83.7500,                 loss: nan
env1_second_0:                 episode reward: 83.7500,                 loss: nan
Episode: 7301/30000 (24.3367%),                 avg. length: 337.65,                last time consumption/overall running time: 66.7938s / 71119.2049 s
env0_first_0:                 episode reward: -69.4000,                 loss: 33.3278
env0_second_0:                 episode reward: 69.4000,                 loss: 35.2914
env1_first_0:                 episode reward: -85.0000,                 loss: nan
env1_second_0:                 episode reward: 85.0000,                 loss: nan
Episode: 7321/30000 (24.4033%),                 avg. length: 653.4,                last time consumption/overall running time: 116.9440s / 71236.1490 s
env0_first_0:                 episode reward: -68.7000,                 loss: 23.3357
env0_second_0:                 episode reward: 68.7000,                 loss: 24.1773
env1_first_0:                 episode reward: -65.3500,                 loss: nan
env1_second_0:                 episode reward: 65.3500,                 loss: nan
Episode: 7341/30000 (24.4700%),                 avg. length: 381.25,                last time consumption/overall running time: 72.2494s / 71308.3983 s
env0_first_0:                 episode reward: -58.0000,                 loss: 30.7854
env0_second_0:                 episode reward: 58.0000,                 loss: 30.4410
env1_first_0:                 episode reward: -81.1000,                 loss: nan
env1_second_0:                 episode reward: 81.1000,                 loss: nan
Episode: 7361/30000 (24.5367%),                 avg. length: 389.1,                last time consumption/overall running time: 74.6439s / 71383.0423 s
env0_first_0:                 episode reward: -65.6000,                 loss: 36.5124
env0_second_0:                 episode reward: 65.6000,                 loss: 36.1228
env1_first_0:                 episode reward: -73.1000,                 loss: nan
env1_second_0:                 episode reward: 73.1000,                 loss: nan
Episode: 7381/30000 (24.6033%),                 avg. length: 707.05,                last time consumption/overall running time: 121.5955s / 71504.6378 s
env0_first_0:                 episode reward: -65.0500,                 loss: 26.0643
env0_second_0:                 episode reward: 65.0500,                 loss: 30.7119
env1_first_0:                 episode reward: -62.8000,                 loss: nan
env1_second_0:                 episode reward: 62.8000,                 loss: nan
Episode: 7401/30000 (24.6700%),                 avg. length: 406.35,                last time consumption/overall running time: 79.4157s / 71584.0534 s
env0_first_0:                 episode reward: -82.9500,                 loss: 36.6565
env0_second_0:                 episode reward: 82.9500,                 loss: 39.1956
env1_first_0:                 episode reward: -64.5000,                 loss: nan
env1_second_0:                 episode reward: 64.5000,                 loss: nan
Episode: 7421/30000 (24.7367%),                 avg. length: 375.0,                last time consumption/overall running time: 74.5356s / 71658.5891 s
env0_first_0:                 episode reward: -67.1000,                 loss: 42.6574
env0_second_0:                 episode reward: 67.1000,                 loss: 45.8775
env1_first_0:                 episode reward: -66.5500,                 loss: nan
env1_second_0:                 episode reward: 66.5500,                 loss: nan
Episode: 7441/30000 (24.8033%),                 avg. length: 359.7,                last time consumption/overall running time: 77.3465s / 71735.9356 s
env0_first_0:                 episode reward: -74.6500,                 loss: 38.9999
env0_second_0:                 episode reward: 74.6500,                 loss: 41.8634
env1_first_0:                 episode reward: -79.9500,                 loss: nan
env1_second_0:                 episode reward: 79.9500,                 loss: nan
Episode: 7461/30000 (24.8700%),                 avg. length: 640.25,                last time consumption/overall running time: 119.2477s / 71855.1833 s
env0_first_0:                 episode reward: -71.7500,                 loss: 27.0092
env0_second_0:                 episode reward: 71.7500,                 loss: 29.4244
env1_first_0:                 episode reward: -72.8000,                 loss: nan
env1_second_0:                 episode reward: 72.8000,                 loss: nan
Episode: 7481/30000 (24.9367%),                 avg. length: 1384.25,                last time consumption/overall running time: 243.2976s / 72098.4809 s
env0_first_0:                 episode reward: -23.2500,                 loss: 11.8820
env0_second_0:                 episode reward: 23.2500,                 loss: 16.2660
env1_first_0:                 episode reward: -21.8000,                 loss: nan
env1_second_0:                 episode reward: 21.8000,                 loss: nan
Episode: 7501/30000 (25.0033%),                 avg. length: 1784.0,                last time consumption/overall running time: 312.8387s / 72411.3196 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.3232
env0_second_0:                 episode reward: 0.0000,                 loss: 4.3129
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 7521/30000 (25.0700%),                 avg. length: 1784.0,                last time consumption/overall running time: 300.2372s / 72711.5568 s
env0_first_0:                 episode reward: -6.1500,                 loss: 1.1576
env0_second_0:                 episode reward: 6.1500,                 loss: 6.0891
env1_first_0:                 episode reward: -10.6000,                 loss: nan
env1_second_0:                 episode reward: 10.6000,                 loss: nan
Episode: 7541/30000 (25.1367%),                 avg. length: 1115.55,                last time consumption/overall running time: 186.5959s / 72898.1527 s
env0_first_0:                 episode reward: -63.5500,                 loss: 12.7532
env0_second_0:                 episode reward: 63.5500,                 loss: 17.6564
env1_first_0:                 episode reward: -70.3000,                 loss: nan
env1_second_0:                 episode reward: 70.3000,                 loss: nan
Episode: 7561/30000 (25.2033%),                 avg. length: 500.85,                last time consumption/overall running time: 86.4705s / 72984.6233 s
env0_first_0:                 episode reward: -68.9500,                 loss: 29.1230
env0_second_0:                 episode reward: 68.9500,                 loss: 33.4834
env1_first_0:                 episode reward: -83.6500,                 loss: nan
env1_second_0:                 episode reward: 83.6500,                 loss: nan
Episode: 7581/30000 (25.2700%),                 avg. length: 503.1,                last time consumption/overall running time: 89.7970s / 73074.4202 s
env0_first_0:                 episode reward: -65.2000,                 loss: 22.1691
env0_second_0:                 episode reward: 65.2000,                 loss: 27.0386
env1_first_0:                 episode reward: -65.2500,                 loss: nan
env1_second_0:                 episode reward: 65.2500,                 loss: nan
Episode: 7601/30000 (25.3367%),                 avg. length: 353.15,                last time consumption/overall running time: 70.5159s / 73144.9361 s
env0_first_0:                 episode reward: -73.2000,                 loss: 37.5227
env0_second_0:                 episode reward: 73.2000,                 loss: 40.8198
env1_first_0:                 episode reward: -84.9500,                 loss: nan
env1_second_0:                 episode reward: 84.9500,                 loss: nan
Episode: 7621/30000 (25.4033%),                 avg. length: 296.7,                last time consumption/overall running time: 53.9345s / 73198.8706 s
env0_first_0:                 episode reward: -84.7500,                 loss: 39.3472
env0_second_0:                 episode reward: 84.7500,                 loss: 41.5080
env1_first_0:                 episode reward: -77.4500,                 loss: nan
env1_second_0:                 episode reward: 77.4500,                 loss: nan
Episode: 7641/30000 (25.4700%),                 avg. length: 325.0,                last time consumption/overall running time: 67.8218s / 73266.6925 s
env0_first_0:                 episode reward: -79.1500,                 loss: 38.5272
env0_second_0:                 episode reward: 79.1500,                 loss: 41.0549
env1_first_0:                 episode reward: -74.2000,                 loss: nan
env1_second_0:                 episode reward: 74.2000,                 loss: nan
Episode: 7661/30000 (25.5367%),                 avg. length: 316.2,                last time consumption/overall running time: 59.4265s / 73326.1189 s
env0_first_0:                 episode reward: -61.9500,                 loss: 32.9114
env0_second_0:                 episode reward: 61.9500,                 loss: 33.4267
env1_first_0:                 episode reward: -84.2500,                 loss: nan
env1_second_0:                 episode reward: 84.2500,                 loss: nan
Episode: 7681/30000 (25.6033%),                 avg. length: 324.05,                last time consumption/overall running time: 63.7091s / 73389.8280 s
env0_first_0:                 episode reward: -81.0500,                 loss: 38.8420
env0_second_0:                 episode reward: 81.0500,                 loss: 41.7743
env1_first_0:                 episode reward: -74.7000,                 loss: nan
env1_second_0:                 episode reward: 74.7000,                 loss: nan
Episode: 7701/30000 (25.6700%),                 avg. length: 298.2,                last time consumption/overall running time: 63.2173s / 73453.0453 s
env0_first_0:                 episode reward: -73.7500,                 loss: 43.8345
env0_second_0:                 episode reward: 73.7500,                 loss: 47.2030
env1_first_0:                 episode reward: -68.4000,                 loss: nan
env1_second_0:                 episode reward: 68.4000,                 loss: nan
Episode: 7721/30000 (25.7367%),                 avg. length: 245.75,                last time consumption/overall running time: 51.2543s / 73504.2996 s
env0_first_0:                 episode reward: -78.9500,                 loss: 42.9801
env0_second_0:                 episode reward: 78.9500,                 loss: 41.6134
env1_first_0:                 episode reward: -85.2000,                 loss: nan
env1_second_0:                 episode reward: 85.2000,                 loss: nan
Episode: 7741/30000 (25.8033%),                 avg. length: 820.7,                last time consumption/overall running time: 146.4661s / 73650.7657 s
env0_first_0:                 episode reward: -54.3000,                 loss: 23.7690
env0_second_0:                 episode reward: 54.3000,                 loss: 25.1026
env1_first_0:                 episode reward: -43.5000,                 loss: nan
env1_second_0:                 episode reward: 43.5000,                 loss: nan
Episode: 7761/30000 (25.8700%),                 avg. length: 1423.8,                last time consumption/overall running time: 233.0839s / 73883.8496 s
env0_first_0:                 episode reward: -19.3500,                 loss: 8.0230
env0_second_0:                 episode reward: 19.3500,                 loss: 11.4946
env1_first_0:                 episode reward: -23.5000,                 loss: nan
env1_second_0:                 episode reward: 23.5000,                 loss: nan
Episode: 7781/30000 (25.9367%),                 avg. length: 1784.0,                last time consumption/overall running time: 280.0752s / 74163.9247 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2347
env0_second_0:                 episode reward: 0.4000,                 loss: 0.7448
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 7801/30000 (26.0033%),                 avg. length: 1784.0,                last time consumption/overall running time: 296.0683s / 74459.9930 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0872
env0_second_0:                 episode reward: 0.1000,                 loss: 0.4222
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 7821/30000 (26.0700%),                 avg. length: 1784.0,                last time consumption/overall running time: 290.6774s / 74750.6704 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0158
env0_second_0:                 episode reward: 0.1000,                 loss: 0.3837
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 7841/30000 (26.1367%),                 avg. length: 1784.0,                last time consumption/overall running time: 299.4132s / 75050.0836 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0092
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2549
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 7861/30000 (26.2033%),                 avg. length: 1784.0,                last time consumption/overall running time: 288.7622s / 75338.8458 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0237
env0_second_0:                 episode reward: 0.0000,                 loss: 0.3683
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 7881/30000 (26.2700%),                 avg. length: 1784.0,                last time consumption/overall running time: 297.0558s / 75635.9016 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0119
env0_second_0:                 episode reward: 0.0000,                 loss: 0.6510
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 7901/30000 (26.3367%),                 avg. length: 1784.0,                last time consumption/overall running time: 292.4671s / 75928.3687 s
env0_first_0:                 episode reward: 0.9000,                 loss: -0.0009
env0_second_0:                 episode reward: -0.9000,                 loss: 0.8071
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 7921/30000 (26.4033%),                 avg. length: 1784.0,                last time consumption/overall running time: 289.3946s / 76217.7633 s
env0_first_0:                 episode reward: 0.9000,                 loss: -0.0020
env0_second_0:                 episode reward: -0.9000,                 loss: 1.3944
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 7941/30000 (26.4700%),                 avg. length: 1784.0,                last time consumption/overall running time: 297.7475s / 76515.5108 s
env0_first_0:                 episode reward: 0.1500,                 loss: -0.0312
env0_second_0:                 episode reward: -0.1500,                 loss: 0.3557
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 7961/30000 (26.5367%),                 avg. length: 1784.0,                last time consumption/overall running time: 295.4072s / 76810.9180 s
env0_first_0:                 episode reward: 1.5000,                 loss: -0.0291
env0_second_0:                 episode reward: -1.5000,                 loss: 0.7810
env1_first_0:                 episode reward: 1.8000,                 loss: nan
env1_second_0:                 episode reward: -1.8000,                 loss: nan
Episode: 7981/30000 (26.6033%),                 avg. length: 1784.0,                last time consumption/overall running time: 303.8488s / 77114.7668 s
env0_first_0:                 episode reward: 0.6000,                 loss: -0.0176
env0_second_0:                 episode reward: -0.6000,                 loss: 0.7315
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 8001/30000 (26.6700%),                 avg. length: 1784.0,                last time consumption/overall running time: 296.1719s / 77410.9387 s
env0_first_0:                 episode reward: 1.3500,                 loss: 0.0282
env0_second_0:                 episode reward: -1.3500,                 loss: 2.2353
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 8021/30000 (26.7367%),                 avg. length: 886.45,                last time consumption/overall running time: 152.1220s / 77563.0607 s
env0_first_0:                 episode reward: -51.7000,                 loss: 24.7559
env0_second_0:                 episode reward: 51.7000,                 loss: 28.6264
env1_first_0:                 episode reward: -57.2500,                 loss: nan
env1_second_0:                 episode reward: 57.2500,                 loss: nan
Episode: 8041/30000 (26.8033%),                 avg. length: 495.85,                last time consumption/overall running time: 86.7130s / 77649.7737 s
env0_first_0:                 episode reward: -50.2000,                 loss: 36.8023
env0_second_0:                 episode reward: 50.2000,                 loss: 36.7974
env1_first_0:                 episode reward: -76.2000,                 loss: nan
env1_second_0:                 episode reward: 76.2000,                 loss: nan
Episode: 8061/30000 (26.8700%),                 avg. length: 374.5,                last time consumption/overall running time: 65.7800s / 77715.5537 s
env0_first_0:                 episode reward: -62.5500,                 loss: 41.0140
env0_second_0:                 episode reward: 62.5500,                 loss: 41.9338
env1_first_0:                 episode reward: -55.6000,                 loss: nan
env1_second_0:                 episode reward: 55.6000,                 loss: nan
Episode: 8081/30000 (26.9367%),                 avg. length: 595.2,                last time consumption/overall running time: 99.2293s / 77814.7831 s
env0_first_0:                 episode reward: -46.8500,                 loss: 43.5873
env0_second_0:                 episode reward: 46.8500,                 loss: 48.1698
env1_first_0:                 episode reward: -71.6500,                 loss: nan
env1_second_0:                 episode reward: 71.6500,                 loss: nan
Episode: 8101/30000 (27.0033%),                 avg. length: 749.8,                last time consumption/overall running time: 127.9154s / 77942.6984 s
env0_first_0:                 episode reward: -56.4500,                 loss: 26.0477
env0_second_0:                 episode reward: 56.4500,                 loss: 29.1602
env1_first_0:                 episode reward: -53.0500,                 loss: nan
env1_second_0:                 episode reward: 53.0500,                 loss: nan
Episode: 8121/30000 (27.0700%),                 avg. length: 735.7,                last time consumption/overall running time: 135.0716s / 78077.7701 s
env0_first_0:                 episode reward: -67.7000,                 loss: 23.2678
env0_second_0:                 episode reward: 67.7000,                 loss: 26.1991
env1_first_0:                 episode reward: -62.7500,                 loss: nan
env1_second_0:                 episode reward: 62.7500,                 loss: nan
Episode: 8141/30000 (27.1367%),                 avg. length: 610.3,                last time consumption/overall running time: 108.5401s / 78186.3102 s
env0_first_0:                 episode reward: -70.3000,                 loss: 27.3304
env0_second_0:                 episode reward: 70.3000,                 loss: 27.4404
env1_first_0:                 episode reward: -62.8500,                 loss: nan
env1_second_0:                 episode reward: 62.8500,                 loss: nan
Episode: 8161/30000 (27.2033%),                 avg. length: 412.8,                last time consumption/overall running time: 79.3713s / 78265.6816 s
env0_first_0:                 episode reward: -72.6500,                 loss: 35.2700
env0_second_0:                 episode reward: 72.6500,                 loss: 36.4091
env1_first_0:                 episode reward: -56.4000,                 loss: nan
env1_second_0:                 episode reward: 56.4000,                 loss: nan
Episode: 8181/30000 (27.2700%),                 avg. length: 1350.0,                last time consumption/overall running time: 236.9468s / 78502.6284 s
env0_first_0:                 episode reward: -29.8500,                 loss: 13.4137
env0_second_0:                 episode reward: 29.8500,                 loss: 15.7882
env1_first_0:                 episode reward: -36.2000,                 loss: nan
env1_second_0:                 episode reward: 36.2000,                 loss: nan
Episode: 8201/30000 (27.3367%),                 avg. length: 354.75,                last time consumption/overall running time: 66.6282s / 78569.2566 s
env0_first_0:                 episode reward: -74.2000,                 loss: 28.5169
env0_second_0:                 episode reward: 74.2000,                 loss: 29.5770
env1_first_0:                 episode reward: -71.1000,                 loss: nan
env1_second_0:                 episode reward: 71.1000,                 loss: nan
Episode: 8221/30000 (27.4033%),                 avg. length: 475.5,                last time consumption/overall running time: 90.1884s / 78659.4450 s
env0_first_0:                 episode reward: -67.9000,                 loss: 25.6218
env0_second_0:                 episode reward: 67.9000,                 loss: 29.0563
env1_first_0:                 episode reward: -66.3500,                 loss: nan
env1_second_0:                 episode reward: 66.3500,                 loss: nan
Episode: 8241/30000 (27.4700%),                 avg. length: 844.15,                last time consumption/overall running time: 151.0394s / 78810.4843 s
env0_first_0:                 episode reward: -51.5000,                 loss: 28.0817
env0_second_0:                 episode reward: 51.5000,                 loss: 32.9007
env1_first_0:                 episode reward: -57.0000,                 loss: nan
env1_second_0:                 episode reward: 57.0000,                 loss: nan
Episode: 8261/30000 (27.5367%),                 avg. length: 1170.65,                last time consumption/overall running time: 200.9403s / 79011.4246 s
env0_first_0:                 episode reward: -49.4000,                 loss: 8.2013
env0_second_0:                 episode reward: 49.4000,                 loss: 12.8509
env1_first_0:                 episode reward: -54.7500,                 loss: nan
env1_second_0:                 episode reward: 54.7500,                 loss: nan
Episode: 8281/30000 (27.6033%),                 avg. length: 1243.95,                last time consumption/overall running time: 205.8882s / 79217.3128 s
env0_first_0:                 episode reward: -52.3000,                 loss: 6.9652
env0_second_0:                 episode reward: 52.3000,                 loss: 9.5463
env1_first_0:                 episode reward: -60.2500,                 loss: nan
env1_second_0:                 episode reward: 60.2500,                 loss: nan
Episode: 8301/30000 (27.6700%),                 avg. length: 1722.25,                last time consumption/overall running time: 284.1913s / 79501.5041 s
env0_first_0:                 episode reward: -48.0500,                 loss: 4.5434
env0_second_0:                 episode reward: 48.0500,                 loss: 8.6853
env1_first_0:                 episode reward: -47.9500,                 loss: nan
env1_second_0:                 episode reward: 47.9500,                 loss: nan
Episode: 8321/30000 (27.7367%),                 avg. length: 1770.55,                last time consumption/overall running time: 297.6687s / 79799.1728 s
env0_first_0:                 episode reward: -44.2500,                 loss: 3.5590
env0_second_0:                 episode reward: 44.2500,                 loss: 6.8407
env1_first_0:                 episode reward: -40.3000,                 loss: nan
env1_second_0:                 episode reward: 40.3000,                 loss: nan
Episode: 8341/30000 (27.8033%),                 avg. length: 966.1,                last time consumption/overall running time: 162.1759s / 79961.3487 s
env0_first_0:                 episode reward: -53.1500,                 loss: 20.7612
env0_second_0:                 episode reward: 53.1500,                 loss: 21.5451
env1_first_0:                 episode reward: -66.8000,                 loss: nan
env1_second_0:                 episode reward: 66.8000,                 loss: nan
Episode: 8361/30000 (27.8700%),                 avg. length: 1623.85,                last time consumption/overall running time: 262.6421s / 80223.9908 s
env0_first_0:                 episode reward: -17.4000,                 loss: 4.5949
env0_second_0:                 episode reward: 17.4000,                 loss: 6.5921
env1_first_0:                 episode reward: -16.3500,                 loss: nan
env1_second_0:                 episode reward: 16.3500,                 loss: nan
Episode: 8381/30000 (27.9367%),                 avg. length: 578.75,                last time consumption/overall running time: 104.9076s / 80328.8984 s
env0_first_0:                 episode reward: -62.3000,                 loss: 32.0183
env0_second_0:                 episode reward: 62.3000,                 loss: 34.0201
env1_first_0:                 episode reward: -72.5500,                 loss: nan
env1_second_0:                 episode reward: 72.5500,                 loss: nan
Episode: 8401/30000 (28.0033%),                 avg. length: 1784.0,                last time consumption/overall running time: 299.1294s / 80628.0278 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.5816
env0_second_0:                 episode reward: -0.5500,                 loss: 2.8298
env1_first_0:                 episode reward: -2.2000,                 loss: nan
env1_second_0:                 episode reward: 2.2000,                 loss: nan
Episode: 8421/30000 (28.0700%),                 avg. length: 1635.05,                last time consumption/overall running time: 271.0060s / 80899.0338 s
env0_first_0:                 episode reward: -4.3000,                 loss: 3.7232
env0_second_0:                 episode reward: 4.3000,                 loss: 4.3496
env1_first_0:                 episode reward: -4.1000,                 loss: nan
env1_second_0:                 episode reward: 4.1000,                 loss: nan
Episode: 8441/30000 (28.1367%),                 avg. length: 1784.0,                last time consumption/overall running time: 286.0598s / 81185.0936 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.2996
env0_second_0:                 episode reward: 1.0500,                 loss: 0.7090
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 8461/30000 (28.2033%),                 avg. length: 1784.0,                last time consumption/overall running time: 281.0149s / 81466.1085 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0057
env0_second_0:                 episode reward: -0.6000,                 loss: 0.5400
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 8481/30000 (28.2700%),                 avg. length: 1628.3,                last time consumption/overall running time: 265.2243s / 81731.3328 s
env0_first_0:                 episode reward: -3.6000,                 loss: 7.0845
env0_second_0:                 episode reward: 3.6000,                 loss: 7.0378
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 8501/30000 (28.3367%),                 avg. length: 1478.45,                last time consumption/overall running time: 249.5383s / 81980.8710 s
env0_first_0:                 episode reward: -6.6500,                 loss: 13.1201
env0_second_0:                 episode reward: 6.6500,                 loss: 12.6161
env1_first_0:                 episode reward: -11.5000,                 loss: nan
env1_second_0:                 episode reward: 11.5000,                 loss: nan
Episode: 8521/30000 (28.4033%),                 avg. length: 588.15,                last time consumption/overall running time: 107.0349s / 82087.9059 s
env0_first_0:                 episode reward: -63.4500,                 loss: 21.2267
env0_second_0:                 episode reward: 63.4500,                 loss: 21.0285
env1_first_0:                 episode reward: -52.7500,                 loss: nan
env1_second_0:                 episode reward: 52.7500,                 loss: nan
Episode: 8541/30000 (28.4700%),                 avg. length: 298.35,                last time consumption/overall running time: 58.5994s / 82146.5053 s
env0_first_0:                 episode reward: -76.6500,                 loss: 41.4418
env0_second_0:                 episode reward: 76.6500,                 loss: 37.0579
env1_first_0:                 episode reward: -75.4500,                 loss: nan
env1_second_0:                 episode reward: 75.4500,                 loss: nan
Episode: 8561/30000 (28.5367%),                 avg. length: 277.3,                last time consumption/overall running time: 57.0993s / 82203.6046 s
env0_first_0:                 episode reward: -83.7500,                 loss: 35.8649
env0_second_0:                 episode reward: 83.7500,                 loss: 34.0016
env1_first_0:                 episode reward: -82.7500,                 loss: nan
env1_second_0:                 episode reward: 82.7500,                 loss: nan
Episode: 8581/30000 (28.6033%),                 avg. length: 388.35,                last time consumption/overall running time: 75.1076s / 82278.7122 s
env0_first_0:                 episode reward: -78.9500,                 loss: 32.2076
env0_second_0:                 episode reward: 78.9500,                 loss: 33.5399
env1_first_0:                 episode reward: -76.3000,                 loss: nan
env1_second_0:                 episode reward: 76.3000,                 loss: nan
Episode: 8601/30000 (28.6700%),                 avg. length: 1025.5,                last time consumption/overall running time: 177.0342s / 82455.7464 s
env0_first_0:                 episode reward: -68.5000,                 loss: 19.1774
env0_second_0:                 episode reward: 68.5000,                 loss: 21.7583
env1_first_0:                 episode reward: -63.0000,                 loss: nan
env1_second_0:                 episode reward: 63.0000,                 loss: nan
Episode: 8621/30000 (28.7367%),                 avg. length: 1508.4,                last time consumption/overall running time: 259.5728s / 82715.3193 s
env0_first_0:                 episode reward: -49.3500,                 loss: 14.0232
env0_second_0:                 episode reward: 49.3500,                 loss: 16.4699
env1_first_0:                 episode reward: -51.3000,                 loss: nan
env1_second_0:                 episode reward: 51.3000,                 loss: nan
Episode: 8641/30000 (28.8033%),                 avg. length: 1067.45,                last time consumption/overall running time: 185.7410s / 82901.0603 s
env0_first_0:                 episode reward: -50.0000,                 loss: 11.6894
env0_second_0:                 episode reward: 50.0000,                 loss: 15.7280
env1_first_0:                 episode reward: -50.6000,                 loss: nan
env1_second_0:                 episode reward: 50.6000,                 loss: nan
Episode: 8661/30000 (28.8700%),                 avg. length: 398.1,                last time consumption/overall running time: 78.1145s / 82979.1748 s
env0_first_0:                 episode reward: -70.9000,                 loss: 32.2092
env0_second_0:                 episode reward: 70.9000,                 loss: 33.0992
env1_first_0:                 episode reward: -82.1000,                 loss: nan
env1_second_0:                 episode reward: 82.1000,                 loss: nan
Episode: 8681/30000 (28.9367%),                 avg. length: 322.85,                last time consumption/overall running time: 60.6372s / 83039.8120 s
env0_first_0:                 episode reward: -90.9500,                 loss: 39.6440
env0_second_0:                 episode reward: 90.9500,                 loss: 40.7338
env1_first_0:                 episode reward: -82.6500,                 loss: nan
env1_second_0:                 episode reward: 82.6500,                 loss: nan
Episode: 8701/30000 (29.0033%),                 avg. length: 527.55,                last time consumption/overall running time: 98.5498s / 83138.3618 s
env0_first_0:                 episode reward: -76.6500,                 loss: 25.4968
env0_second_0:                 episode reward: 76.6500,                 loss: 25.5545
env1_first_0:                 episode reward: -72.4500,                 loss: nan
env1_second_0:                 episode reward: 72.4500,                 loss: nan
Episode: 8721/30000 (29.0700%),                 avg. length: 719.15,                last time consumption/overall running time: 128.7624s / 83267.1242 s
env0_first_0:                 episode reward: -67.0500,                 loss: 22.6112
env0_second_0:                 episode reward: 67.0500,                 loss: 24.5073
env1_first_0:                 episode reward: -70.2500,                 loss: nan
env1_second_0:                 episode reward: 70.2500,                 loss: nan
Episode: 8741/30000 (29.1367%),                 avg. length: 401.55,                last time consumption/overall running time: 76.0822s / 83343.2064 s
env0_first_0:                 episode reward: -71.0000,                 loss: 39.2601
env0_second_0:                 episode reward: 71.0000,                 loss: 44.4573
env1_first_0:                 episode reward: -84.1000,                 loss: nan
env1_second_0:                 episode reward: 84.1000,                 loss: nan
Episode: 8761/30000 (29.2033%),                 avg. length: 495.1,                last time consumption/overall running time: 91.7609s / 83434.9673 s
env0_first_0:                 episode reward: -62.7000,                 loss: 33.7427
env0_second_0:                 episode reward: 62.7000,                 loss: 36.4469
env1_first_0:                 episode reward: -56.3500,                 loss: nan
env1_second_0:                 episode reward: 56.3500,                 loss: nan
Episode: 8781/30000 (29.2700%),                 avg. length: 570.05,                last time consumption/overall running time: 103.8484s / 83538.8157 s
env0_first_0:                 episode reward: -29.4500,                 loss: 33.4889
env0_second_0:                 episode reward: 29.4500,                 loss: 35.6703
env1_first_0:                 episode reward: -37.1000,                 loss: nan
env1_second_0:                 episode reward: 37.1000,                 loss: nan
Episode: 8801/30000 (29.3367%),                 avg. length: 648.05,                last time consumption/overall running time: 117.0590s / 83655.8747 s
env0_first_0:                 episode reward: -18.4500,                 loss: 32.6213
env0_second_0:                 episode reward: 18.4500,                 loss: 35.2987
env1_first_0:                 episode reward: -36.2500,                 loss: nan
env1_second_0:                 episode reward: 36.2500,                 loss: nan
Episode: 8821/30000 (29.4033%),                 avg. length: 1297.05,                last time consumption/overall running time: 223.5812s / 83879.4558 s
env0_first_0:                 episode reward: -14.7500,                 loss: 14.5258
env0_second_0:                 episode reward: 14.7500,                 loss: 16.6253
env1_first_0:                 episode reward: -17.9000,                 loss: nan
env1_second_0:                 episode reward: 17.9000,                 loss: nan
Episode: 8841/30000 (29.4700%),                 avg. length: 493.1,                last time consumption/overall running time: 93.7587s / 83973.2146 s
env0_first_0:                 episode reward: -64.5000,                 loss: 42.7729
env0_second_0:                 episode reward: 64.5000,                 loss: 45.2855
env1_first_0:                 episode reward: -42.1000,                 loss: nan
env1_second_0:                 episode reward: 42.1000,                 loss: nan
Episode: 8861/30000 (29.5367%),                 avg. length: 372.9,                last time consumption/overall running time: 71.5269s / 84044.7414 s
env0_first_0:                 episode reward: -66.1000,                 loss: 43.9384
env0_second_0:                 episode reward: 66.1000,                 loss: 45.8381
env1_first_0:                 episode reward: -71.7000,                 loss: nan
env1_second_0:                 episode reward: 71.7000,                 loss: nan
Episode: 8881/30000 (29.6033%),                 avg. length: 760.8,                last time consumption/overall running time: 138.7241s / 84183.4655 s
env0_first_0:                 episode reward: -71.6500,                 loss: 26.5868
env0_second_0:                 episode reward: 71.6500,                 loss: 36.7516
env1_first_0:                 episode reward: -53.4500,                 loss: nan
env1_second_0:                 episode reward: 53.4500,                 loss: nan
Episode: 8901/30000 (29.6700%),                 avg. length: 544.1,                last time consumption/overall running time: 103.2153s / 84286.6808 s
env0_first_0:                 episode reward: -71.3500,                 loss: 28.3266
env0_second_0:                 episode reward: 71.3500,                 loss: 32.7910
env1_first_0:                 episode reward: -73.7000,                 loss: nan
env1_second_0:                 episode reward: 73.7000,                 loss: nan
Episode: 8921/30000 (29.7367%),                 avg. length: 1068.55,                last time consumption/overall running time: 188.1721s / 84474.8529 s
env0_first_0:                 episode reward: -52.4500,                 loss: 13.1320
env0_second_0:                 episode reward: 52.4500,                 loss: 17.4177
env1_first_0:                 episode reward: -37.5000,                 loss: nan
env1_second_0:                 episode reward: 37.5000,                 loss: nan
Episode: 8941/30000 (29.8033%),                 avg. length: 757.35,                last time consumption/overall running time: 135.9749s / 84610.8278 s
env0_first_0:                 episode reward: -70.9500,                 loss: 24.9168
env0_second_0:                 episode reward: 70.9500,                 loss: 27.8557
env1_first_0:                 episode reward: -55.3000,                 loss: nan
env1_second_0:                 episode reward: 55.3000,                 loss: nan
Episode: 8961/30000 (29.8700%),                 avg. length: 524.35,                last time consumption/overall running time: 97.7990s / 84708.6268 s
env0_first_0:                 episode reward: -61.3500,                 loss: 45.1796
env0_second_0:                 episode reward: 61.3500,                 loss: 49.9037
env1_first_0:                 episode reward: -63.9500,                 loss: nan
env1_second_0:                 episode reward: 63.9500,                 loss: nan
Episode: 8981/30000 (29.9367%),                 avg. length: 391.25,                last time consumption/overall running time: 71.8236s / 84780.4505 s
env0_first_0:                 episode reward: -70.2500,                 loss: 47.3823
env0_second_0:                 episode reward: 70.2500,                 loss: 51.1884
env1_first_0:                 episode reward: -69.9500,                 loss: nan
env1_second_0:                 episode reward: 69.9500,                 loss: nan
Episode: 9001/30000 (30.0033%),                 avg. length: 414.2,                last time consumption/overall running time: 81.0721s / 84861.5225 s
env0_first_0:                 episode reward: -66.5000,                 loss: 38.5286
env0_second_0:                 episode reward: 66.5000,                 loss: 38.5783
env1_first_0:                 episode reward: -69.7000,                 loss: nan
env1_second_0:                 episode reward: 69.7000,                 loss: nan
Episode: 9021/30000 (30.0700%),                 avg. length: 372.75,                last time consumption/overall running time: 73.3162s / 84934.8387 s
env0_first_0:                 episode reward: -74.6000,                 loss: 35.9935
env0_second_0:                 episode reward: 74.6000,                 loss: 34.5921
env1_first_0:                 episode reward: -81.8500,                 loss: nan
env1_second_0:                 episode reward: 81.8500,                 loss: nan
Episode: 9041/30000 (30.1367%),                 avg. length: 551.05,                last time consumption/overall running time: 103.4113s / 85038.2500 s
env0_first_0:                 episode reward: -74.2500,                 loss: 35.5042
env0_second_0:                 episode reward: 74.2500,                 loss: 37.3389
env1_first_0:                 episode reward: -60.8500,                 loss: nan
env1_second_0:                 episode reward: 60.8500,                 loss: nan
Episode: 9061/30000 (30.2033%),                 avg. length: 682.2,                last time consumption/overall running time: 125.5708s / 85163.8208 s
env0_first_0:                 episode reward: -16.5500,                 loss: 32.1915
env0_second_0:                 episode reward: 16.5500,                 loss: 32.6873
env1_first_0:                 episode reward: -36.4500,                 loss: nan
env1_second_0:                 episode reward: 36.4500,                 loss: nan
Episode: 9081/30000 (30.2700%),                 avg. length: 724.2,                last time consumption/overall running time: 133.0796s / 85296.9005 s
env0_first_0:                 episode reward: -18.8500,                 loss: 33.7939
env0_second_0:                 episode reward: 18.8500,                 loss: 35.1520
env1_first_0:                 episode reward: -22.3000,                 loss: nan
env1_second_0:                 episode reward: 22.3000,                 loss: nan
Episode: 9101/30000 (30.3367%),                 avg. length: 1015.1,                last time consumption/overall running time: 179.2574s / 85476.1579 s
env0_first_0:                 episode reward: -32.9000,                 loss: 27.6077
env0_second_0:                 episode reward: 32.9000,                 loss: 28.1541
env1_first_0:                 episode reward: -18.4000,                 loss: nan
env1_second_0:                 episode reward: 18.4000,                 loss: nan
Episode: 9121/30000 (30.4033%),                 avg. length: 1699.25,                last time consumption/overall running time: 280.6050s / 85756.7630 s
env0_first_0:                 episode reward: -24.0500,                 loss: 6.9749
env0_second_0:                 episode reward: 24.0500,                 loss: 9.4254
env1_first_0:                 episode reward: -23.1500,                 loss: nan
env1_second_0:                 episode reward: 23.1500,                 loss: nan
Episode: 9141/30000 (30.4700%),                 avg. length: 1673.45,                last time consumption/overall running time: 279.5795s / 86036.3425 s
env0_first_0:                 episode reward: -27.5000,                 loss: 5.3048
env0_second_0:                 episode reward: 27.5000,                 loss: 7.4584
env1_first_0:                 episode reward: -37.1000,                 loss: nan
env1_second_0:                 episode reward: 37.1000,                 loss: nan
Episode: 9161/30000 (30.5367%),                 avg. length: 1045.2,                last time consumption/overall running time: 176.8211s / 86213.1635 s
env0_first_0:                 episode reward: -36.0000,                 loss: 10.1608
env0_second_0:                 episode reward: 36.0000,                 loss: 13.1827
env1_first_0:                 episode reward: -47.9000,                 loss: nan
env1_second_0:                 episode reward: 47.9000,                 loss: nan
Episode: 9181/30000 (30.6033%),                 avg. length: 521.45,                last time consumption/overall running time: 94.2724s / 86307.4360 s
env0_first_0:                 episode reward: -67.7000,                 loss: 29.5062
env0_second_0:                 episode reward: 67.7000,                 loss: 29.1518
env1_first_0:                 episode reward: -67.0500,                 loss: nan
env1_second_0:                 episode reward: 67.0500,                 loss: nan
Episode: 9201/30000 (30.6700%),                 avg. length: 309.65,                last time consumption/overall running time: 62.5081s / 86369.9441 s
env0_first_0:                 episode reward: -78.5000,                 loss: 41.9540
env0_second_0:                 episode reward: 78.5000,                 loss: 42.4592
env1_first_0:                 episode reward: -74.6000,                 loss: nan
env1_second_0:                 episode reward: 74.6000,                 loss: nan
Episode: 9221/30000 (30.7367%),                 avg. length: 278.4,                last time consumption/overall running time: 55.3923s / 86425.3364 s
env0_first_0:                 episode reward: -78.7000,                 loss: 37.7938
env0_second_0:                 episode reward: 78.7000,                 loss: 36.6485
env1_first_0:                 episode reward: -86.9000,                 loss: nan
env1_second_0:                 episode reward: 86.9000,                 loss: nan
Episode: 9241/30000 (30.8033%),                 avg. length: 300.3,                last time consumption/overall running time: 59.4496s / 86484.7860 s
env0_first_0:                 episode reward: -76.6000,                 loss: 31.0219
env0_second_0:                 episode reward: 76.6000,                 loss: 32.5435
env1_first_0:                 episode reward: -83.7000,                 loss: nan
env1_second_0:                 episode reward: 83.7000,                 loss: nan
Episode: 9261/30000 (30.8700%),                 avg. length: 387.1,                last time consumption/overall running time: 75.8196s / 86560.6056 s
env0_first_0:                 episode reward: -64.8000,                 loss: 36.2780
env0_second_0:                 episode reward: 64.8000,                 loss: 36.8159
env1_first_0:                 episode reward: -69.8500,                 loss: nan
env1_second_0:                 episode reward: 69.8500,                 loss: nan
Episode: 9281/30000 (30.9367%),                 avg. length: 597.9,                last time consumption/overall running time: 111.3923s / 86671.9979 s
env0_first_0:                 episode reward: -69.0000,                 loss: 31.7255
env0_second_0:                 episode reward: 69.0000,                 loss: 33.3604
env1_first_0:                 episode reward: -51.0500,                 loss: nan
env1_second_0:                 episode reward: 51.0500,                 loss: nan
Episode: 9301/30000 (31.0033%),                 avg. length: 422.65,                last time consumption/overall running time: 79.7766s / 86751.7744 s
env0_first_0:                 episode reward: -61.8500,                 loss: 36.9130
env0_second_0:                 episode reward: 61.8500,                 loss: 37.2820
env1_first_0:                 episode reward: -72.9500,                 loss: nan
env1_second_0:                 episode reward: 72.9500,                 loss: nan
Episode: 9321/30000 (31.0700%),                 avg. length: 1070.45,                last time consumption/overall running time: 183.2754s / 86935.0499 s
env0_first_0:                 episode reward: -32.3500,                 loss: 20.9662
env0_second_0:                 episode reward: 32.3500,                 loss: 20.6347
env1_first_0:                 episode reward: -36.7000,                 loss: nan
env1_second_0:                 episode reward: 36.7000,                 loss: nan
Episode: 9341/30000 (31.1367%),                 avg. length: 289.65,                last time consumption/overall running time: 60.7353s / 86995.7852 s
env0_first_0:                 episode reward: -77.6500,                 loss: 49.5421
env0_second_0:                 episode reward: 77.6500,                 loss: 46.9692
env1_first_0:                 episode reward: -67.4500,                 loss: nan
env1_second_0:                 episode reward: 67.4500,                 loss: nan
Episode: 9361/30000 (31.2033%),                 avg. length: 553.35,                last time consumption/overall running time: 97.8229s / 87093.6081 s
env0_first_0:                 episode reward: -45.4000,                 loss: 31.1498
env0_second_0:                 episode reward: 45.4000,                 loss: 29.5869
env1_first_0:                 episode reward: -74.9500,                 loss: nan
env1_second_0:                 episode reward: 74.9500,                 loss: nan
Episode: 9381/30000 (31.2700%),                 avg. length: 1120.15,                last time consumption/overall running time: 194.8962s / 87288.5043 s
env0_first_0:                 episode reward: -40.4000,                 loss: 20.4623
env0_second_0:                 episode reward: 40.4000,                 loss: 20.8535
env1_first_0:                 episode reward: -39.0000,                 loss: nan
env1_second_0:                 episode reward: 39.0000,                 loss: nan
Episode: 9401/30000 (31.3367%),                 avg. length: 1736.1,                last time consumption/overall running time: 298.3057s / 87586.8100 s
env0_first_0:                 episode reward: -9.7500,                 loss: 2.7635
env0_second_0:                 episode reward: 9.7500,                 loss: 4.0661
env1_first_0:                 episode reward: -6.8000,                 loss: nan
env1_second_0:                 episode reward: 6.8000,                 loss: nan
Episode: 9421/30000 (31.4033%),                 avg. length: 1562.4,                last time consumption/overall running time: 262.9705s / 87849.7804 s
env0_first_0:                 episode reward: -22.1000,                 loss: 3.7951
env0_second_0:                 episode reward: 22.1000,                 loss: 5.7134
env1_first_0:                 episode reward: -24.9000,                 loss: nan
env1_second_0:                 episode reward: 24.9000,                 loss: nan
Episode: 9441/30000 (31.4700%),                 avg. length: 1474.7,                last time consumption/overall running time: 245.1231s / 88094.9036 s
env0_first_0:                 episode reward: -14.3000,                 loss: 6.3000
env0_second_0:                 episode reward: 14.3000,                 loss: 9.2918
env1_first_0:                 episode reward: -12.3000,                 loss: nan
env1_second_0:                 episode reward: 12.3000,                 loss: nan
Episode: 9461/30000 (31.5367%),                 avg. length: 1247.45,                last time consumption/overall running time: 206.2046s / 88301.1082 s
env0_first_0:                 episode reward: -30.0000,                 loss: 12.6820
env0_second_0:                 episode reward: 30.0000,                 loss: 14.4128
env1_first_0:                 episode reward: -32.6000,                 loss: nan
env1_second_0:                 episode reward: 32.6000,                 loss: nan
Episode: 9481/30000 (31.6033%),                 avg. length: 778.55,                last time consumption/overall running time: 138.2196s / 88439.3278 s
env0_first_0:                 episode reward: -35.8000,                 loss: 29.3158
env0_second_0:                 episode reward: 35.8000,                 loss: 31.1319
env1_first_0:                 episode reward: -55.0500,                 loss: nan
env1_second_0:                 episode reward: 55.0500,                 loss: nan
Episode: 9501/30000 (31.6700%),                 avg. length: 441.7,                last time consumption/overall running time: 85.6584s / 88524.9862 s
env0_first_0:                 episode reward: -65.5500,                 loss: 43.0886
env0_second_0:                 episode reward: 65.5500,                 loss: 42.1076
env1_first_0:                 episode reward: -69.7000,                 loss: nan
env1_second_0:                 episode reward: 69.7000,                 loss: nan
Episode: 9521/30000 (31.7367%),                 avg. length: 462.4,                last time consumption/overall running time: 79.9083s / 88604.8945 s
env0_first_0:                 episode reward: -72.3500,                 loss: 38.9232
env0_second_0:                 episode reward: 72.3500,                 loss: 46.0620
env1_first_0:                 episode reward: -61.9500,                 loss: nan
env1_second_0:                 episode reward: 61.9500,                 loss: nan
Episode: 9541/30000 (31.8033%),                 avg. length: 918.1,                last time consumption/overall running time: 156.2128s / 88761.1073 s
env0_first_0:                 episode reward: -48.9500,                 loss: 21.1112
env0_second_0:                 episode reward: 48.9500,                 loss: 24.8255
env1_first_0:                 episode reward: -47.4000,                 loss: nan
env1_second_0:                 episode reward: 47.4000,                 loss: nan
Episode: 9561/30000 (31.8700%),                 avg. length: 1121.45,                last time consumption/overall running time: 196.8444s / 88957.9517 s
env0_first_0:                 episode reward: -32.7000,                 loss: 13.3241
env0_second_0:                 episode reward: 32.7000,                 loss: 15.0144
env1_first_0:                 episode reward: -43.6000,                 loss: nan
env1_second_0:                 episode reward: 43.6000,                 loss: nan
Episode: 9581/30000 (31.9367%),                 avg. length: 438.4,                last time consumption/overall running time: 81.5975s / 89039.5492 s
env0_first_0:                 episode reward: -62.3500,                 loss: 37.7231
env0_second_0:                 episode reward: 62.3500,                 loss: 36.6808
env1_first_0:                 episode reward: -71.6500,                 loss: nan
env1_second_0:                 episode reward: 71.6500,                 loss: nan
Episode: 9601/30000 (32.0033%),                 avg. length: 487.15,                last time consumption/overall running time: 91.0805s / 89130.6297 s
env0_first_0:                 episode reward: -66.1500,                 loss: 34.1652
env0_second_0:                 episode reward: 66.1500,                 loss: 33.9977
env1_first_0:                 episode reward: -71.7500,                 loss: nan
env1_second_0:                 episode reward: 71.7500,                 loss: nan
Episode: 9621/30000 (32.0700%),                 avg. length: 344.8,                last time consumption/overall running time: 69.7915s / 89200.4212 s
env0_first_0:                 episode reward: -74.5000,                 loss: 36.6328
env0_second_0:                 episode reward: 74.5000,                 loss: 37.2675
env1_first_0:                 episode reward: -77.2000,                 loss: nan
env1_second_0:                 episode reward: 77.2000,                 loss: nan
Episode: 9641/30000 (32.1367%),                 avg. length: 341.6,                last time consumption/overall running time: 65.3304s / 89265.7517 s
env0_first_0:                 episode reward: -80.8500,                 loss: 35.7013
env0_second_0:                 episode reward: 80.8500,                 loss: 35.2540
env1_first_0:                 episode reward: -78.3500,                 loss: nan
env1_second_0:                 episode reward: 78.3500,                 loss: nan
Episode: 9661/30000 (32.2033%),                 avg. length: 335.55,                last time consumption/overall running time: 67.7361s / 89333.4878 s
env0_first_0:                 episode reward: -77.0500,                 loss: 35.7192
env0_second_0:                 episode reward: 77.0500,                 loss: 38.4482
env1_first_0:                 episode reward: -73.8000,                 loss: nan
env1_second_0:                 episode reward: 73.8000,                 loss: nan
Episode: 9681/30000 (32.2700%),                 avg. length: 472.35,                last time consumption/overall running time: 90.9517s / 89424.4395 s
env0_first_0:                 episode reward: -66.4000,                 loss: 31.5158
env0_second_0:                 episode reward: 66.4000,                 loss: 34.0893
env1_first_0:                 episode reward: -66.6500,                 loss: nan
env1_second_0:                 episode reward: 66.6500,                 loss: nan
Episode: 9701/30000 (32.3367%),                 avg. length: 386.6,                last time consumption/overall running time: 76.3053s / 89500.7448 s
env0_first_0:                 episode reward: -66.9500,                 loss: 40.0796
env0_second_0:                 episode reward: 66.9500,                 loss: 42.5162
env1_first_0:                 episode reward: -72.8500,                 loss: nan
env1_second_0:                 episode reward: 72.8500,                 loss: nan
Episode: 9721/30000 (32.4033%),                 avg. length: 343.7,                last time consumption/overall running time: 63.6716s / 89564.4164 s
env0_first_0:                 episode reward: -72.5500,                 loss: 32.6051
env0_second_0:                 episode reward: 72.5500,                 loss: 36.4979
env1_first_0:                 episode reward: -63.5500,                 loss: nan
env1_second_0:                 episode reward: 63.5500,                 loss: nan
Episode: 9741/30000 (32.4700%),                 avg. length: 372.25,                last time consumption/overall running time: 66.4863s / 89630.9027 s
env0_first_0:                 episode reward: -69.3000,                 loss: 38.1709
env0_second_0:                 episode reward: 69.3000,                 loss: 43.9865
env1_first_0:                 episode reward: -64.7500,                 loss: nan
env1_second_0:                 episode reward: 64.7500,                 loss: nan
Episode: 9761/30000 (32.5367%),                 avg. length: 312.35,                last time consumption/overall running time: 61.4916s / 89692.3943 s
env0_first_0:                 episode reward: -59.8000,                 loss: 33.6017
env0_second_0:                 episode reward: 59.8000,                 loss: 36.5365
env1_first_0:                 episode reward: -81.1000,                 loss: nan
env1_second_0:                 episode reward: 81.1000,                 loss: nan
Episode: 9781/30000 (32.6033%),                 avg. length: 281.35,                last time consumption/overall running time: 56.8179s / 89749.2122 s
env0_first_0:                 episode reward: -73.0000,                 loss: 34.8956
env0_second_0:                 episode reward: 73.0000,                 loss: 37.1453
env1_first_0:                 episode reward: -84.4000,                 loss: nan
env1_second_0:                 episode reward: 84.4000,                 loss: nan
Episode: 9801/30000 (32.6700%),                 avg. length: 341.55,                last time consumption/overall running time: 67.0637s / 89816.2758 s
env0_first_0:                 episode reward: -71.6500,                 loss: 33.6043
env0_second_0:                 episode reward: 71.6500,                 loss: 36.3677
env1_first_0:                 episode reward: -82.8500,                 loss: nan
env1_second_0:                 episode reward: 82.8500,                 loss: nan
Episode: 9821/30000 (32.7367%),                 avg. length: 336.85,                last time consumption/overall running time: 66.7266s / 89883.0024 s
env0_first_0:                 episode reward: -67.7000,                 loss: 36.2351
env0_second_0:                 episode reward: 67.7000,                 loss: 39.3994
env1_first_0:                 episode reward: -80.1000,                 loss: nan
env1_second_0:                 episode reward: 80.1000,                 loss: nan
Episode: 9841/30000 (32.8033%),                 avg. length: 335.2,                last time consumption/overall running time: 66.1626s / 89949.1650 s
env0_first_0:                 episode reward: -69.1500,                 loss: 35.6801
env0_second_0:                 episode reward: 69.1500,                 loss: 37.2162
env1_first_0:                 episode reward: -75.4500,                 loss: nan
env1_second_0:                 episode reward: 75.4500,                 loss: nan
Episode: 9861/30000 (32.8700%),                 avg. length: 689.4,                last time consumption/overall running time: 124.1612s / 90073.3263 s
env0_first_0:                 episode reward: -36.4500,                 loss: 20.9296
env0_second_0:                 episode reward: 36.4500,                 loss: 21.3945
env1_first_0:                 episode reward: -43.8000,                 loss: nan
env1_second_0:                 episode reward: 43.8000,                 loss: nan
Episode: 9881/30000 (32.9367%),                 avg. length: 508.1,                last time consumption/overall running time: 94.9319s / 90168.2582 s
env0_first_0:                 episode reward: -62.5000,                 loss: 31.2607
env0_second_0:                 episode reward: 62.5000,                 loss: 32.4505
env1_first_0:                 episode reward: -55.1500,                 loss: nan
env1_second_0:                 episode reward: 55.1500,                 loss: nan
Episode: 9901/30000 (33.0033%),                 avg. length: 358.95,                last time consumption/overall running time: 71.0103s / 90239.2685 s
env0_first_0:                 episode reward: -56.8000,                 loss: 37.2686
env0_second_0:                 episode reward: 56.8000,                 loss: 39.0906
env1_first_0:                 episode reward: -73.0500,                 loss: nan
env1_second_0:                 episode reward: 73.0500,                 loss: nan
Episode: 9921/30000 (33.0700%),                 avg. length: 392.95,                last time consumption/overall running time: 73.9824s / 90313.2509 s
env0_first_0:                 episode reward: -75.5500,                 loss: 38.4725
env0_second_0:                 episode reward: 75.5500,                 loss: 38.6301
env1_first_0:                 episode reward: -64.0500,                 loss: nan
env1_second_0:                 episode reward: 64.0500,                 loss: nan
Episode: 9941/30000 (33.1367%),                 avg. length: 494.85,                last time consumption/overall running time: 92.1528s / 90405.4037 s
env0_first_0:                 episode reward: -51.4500,                 loss: 32.2955
env0_second_0:                 episode reward: 51.4500,                 loss: 35.1606
env1_first_0:                 episode reward: -75.6000,                 loss: nan
env1_second_0:                 episode reward: 75.6000,                 loss: nan
Episode: 9961/30000 (33.2033%),                 avg. length: 411.6,                last time consumption/overall running time: 73.7998s / 90479.2035 s
env0_first_0:                 episode reward: -63.6500,                 loss: 35.2192
env0_second_0:                 episode reward: 63.6500,                 loss: 36.8490
env1_first_0:                 episode reward: -85.3000,                 loss: nan
env1_second_0:                 episode reward: 85.3000,                 loss: nan
Episode: 9981/30000 (33.2700%),                 avg. length: 478.6,                last time consumption/overall running time: 87.6588s / 90566.8622 s
env0_first_0:                 episode reward: -66.8000,                 loss: 30.6187
env0_second_0:                 episode reward: 66.8000,                 loss: 31.4395
env1_first_0:                 episode reward: -55.8500,                 loss: nan
env1_second_0:                 episode reward: 55.8500,                 loss: nan
Episode: 10001/30000 (33.3367%),                 avg. length: 692.45,                last time consumption/overall running time: 126.8613s / 90693.7235 s
env0_first_0:                 episode reward: -56.0000,                 loss: 26.3363
env0_second_0:                 episode reward: 56.0000,                 loss: 27.1419
env1_first_0:                 episode reward: -48.0000,                 loss: nan
env1_second_0:                 episode reward: 48.0000,                 loss: nan
Episode: 10021/30000 (33.4033%),                 avg. length: 647.2,                last time consumption/overall running time: 119.3529s / 90813.0765 s
env0_first_0:                 episode reward: -59.8500,                 loss: 32.4922
env0_second_0:                 episode reward: 59.8500,                 loss: 33.8390
env1_first_0:                 episode reward: -55.7000,                 loss: nan
env1_second_0:                 episode reward: 55.7000,                 loss: nan
Episode: 10041/30000 (33.4700%),                 avg. length: 580.05,                last time consumption/overall running time: 106.2455s / 90919.3220 s
env0_first_0:                 episode reward: -62.0000,                 loss: 32.8598
env0_second_0:                 episode reward: 62.0000,                 loss: 33.6283
env1_first_0:                 episode reward: -66.0500,                 loss: nan
env1_second_0:                 episode reward: 66.0500,                 loss: nan
Episode: 10061/30000 (33.5367%),                 avg. length: 932.35,                last time consumption/overall running time: 164.7891s / 91084.1111 s
env0_first_0:                 episode reward: -48.5500,                 loss: 34.7342
env0_second_0:                 episode reward: 48.5500,                 loss: 38.7767
env1_first_0:                 episode reward: -52.3500,                 loss: nan
env1_second_0:                 episode reward: 52.3500,                 loss: nan
Episode: 10081/30000 (33.6033%),                 avg. length: 1607.55,                last time consumption/overall running time: 279.2646s / 91363.3757 s
env0_first_0:                 episode reward: -12.8500,                 loss: 10.1966
env0_second_0:                 episode reward: 12.8500,                 loss: 12.3449
env1_first_0:                 episode reward: -20.1500,                 loss: nan
env1_second_0:                 episode reward: 20.1500,                 loss: nan
Episode: 10101/30000 (33.6700%),                 avg. length: 1784.0,                last time consumption/overall running time: 305.0874s / 91668.4631 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0721
env0_second_0:                 episode reward: 0.0000,                 loss: 2.8276
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 10121/30000 (33.7367%),                 avg. length: 1784.0,                last time consumption/overall running time: 307.1910s / 91975.6541 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2076
env0_second_0:                 episode reward: 0.1000,                 loss: 3.1252
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 10141/30000 (33.8033%),                 avg. length: 1610.3,                last time consumption/overall running time: 267.7097s / 92243.3638 s
env0_first_0:                 episode reward: -29.7500,                 loss: 5.9376
env0_second_0:                 episode reward: 29.7500,                 loss: 8.5702
env1_first_0:                 episode reward: -25.0500,                 loss: nan
env1_second_0:                 episode reward: 25.0500,                 loss: nan
Episode: 10161/30000 (33.8700%),                 avg. length: 713.95,                last time consumption/overall running time: 125.9342s / 92369.2980 s
env0_first_0:                 episode reward: -61.8000,                 loss: 33.7228
env0_second_0:                 episode reward: 61.8000,                 loss: 36.1464
env1_first_0:                 episode reward: -59.9500,                 loss: nan
env1_second_0:                 episode reward: 59.9500,                 loss: nan
Episode: 10181/30000 (33.9367%),                 avg. length: 732.15,                last time consumption/overall running time: 130.9217s / 92500.2196 s
env0_first_0:                 episode reward: -69.3500,                 loss: 38.0074
env0_second_0:                 episode reward: 69.3500,                 loss: 41.5123
env1_first_0:                 episode reward: -68.4500,                 loss: nan
env1_second_0:                 episode reward: 68.4500,                 loss: nan
Episode: 10201/30000 (34.0033%),                 avg. length: 1690.05,                last time consumption/overall running time: 277.9220s / 92778.1416 s
env0_first_0:                 episode reward: -23.3000,                 loss: 9.7506
env0_second_0:                 episode reward: 23.3000,                 loss: 11.1988
env1_first_0:                 episode reward: -22.5000,                 loss: nan
env1_second_0:                 episode reward: 22.5000,                 loss: nan
Episode: 10221/30000 (34.0700%),                 avg. length: 890.6,                last time consumption/overall running time: 155.1085s / 92933.2501 s
env0_first_0:                 episode reward: -59.2500,                 loss: 29.9605
env0_second_0:                 episode reward: 59.2500,                 loss: 35.1947
env1_first_0:                 episode reward: -52.6500,                 loss: nan
env1_second_0:                 episode reward: 52.6500,                 loss: nan
Episode: 10241/30000 (34.1367%),                 avg. length: 853.8,                last time consumption/overall running time: 151.1846s / 93084.4347 s
env0_first_0:                 episode reward: -60.7000,                 loss: 28.4737
env0_second_0:                 episode reward: 60.7000,                 loss: 32.3626
env1_first_0:                 episode reward: -65.4500,                 loss: nan
env1_second_0:                 episode reward: 65.4500,                 loss: nan
Episode: 10261/30000 (34.2033%),                 avg. length: 1451.85,                last time consumption/overall running time: 247.0036s / 93331.4384 s
env0_first_0:                 episode reward: -38.8500,                 loss: 11.4994
env0_second_0:                 episode reward: 38.8500,                 loss: 12.8024
env1_first_0:                 episode reward: -29.1000,                 loss: nan
env1_second_0:                 episode reward: 29.1000,                 loss: nan
Episode: 10281/30000 (34.2700%),                 avg. length: 1784.0,                last time consumption/overall running time: 310.7968s / 93642.2352 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2469
env0_second_0:                 episode reward: -0.3000,                 loss: 2.1942
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 10301/30000 (34.3367%),                 avg. length: 1784.0,                last time consumption/overall running time: 298.3180s / 93940.5532 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.8365
env0_second_0:                 episode reward: -0.3000,                 loss: 2.6267
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 10321/30000 (34.4033%),                 avg. length: 1784.0,                last time consumption/overall running time: 306.1335s / 94246.6866 s
env0_first_0:                 episode reward: -4.8000,                 loss: 2.5627
env0_second_0:                 episode reward: 4.8000,                 loss: 5.6121
env1_first_0:                 episode reward: -6.0500,                 loss: nan
env1_second_0:                 episode reward: 6.0500,                 loss: nan
Episode: 10341/30000 (34.4700%),                 avg. length: 1045.3,                last time consumption/overall running time: 174.8828s / 94421.5695 s
env0_first_0:                 episode reward: -55.2500,                 loss: 25.8952
env0_second_0:                 episode reward: 55.2500,                 loss: 29.3744
env1_first_0:                 episode reward: -71.0500,                 loss: nan
env1_second_0:                 episode reward: 71.0500,                 loss: nan
Episode: 10361/30000 (34.5367%),                 avg. length: 847.5,                last time consumption/overall running time: 144.8146s / 94566.3841 s
env0_first_0:                 episode reward: -70.7000,                 loss: 31.6249
env0_second_0:                 episode reward: 70.7000,                 loss: 31.8765
env1_first_0:                 episode reward: -67.6500,                 loss: nan
env1_second_0:                 episode reward: 67.6500,                 loss: nan
Episode: 10381/30000 (34.6033%),                 avg. length: 1275.8,                last time consumption/overall running time: 223.2002s / 94789.5843 s
env0_first_0:                 episode reward: -49.1000,                 loss: 17.7701
env0_second_0:                 episode reward: 49.1000,                 loss: 20.5459
env1_first_0:                 episode reward: -22.5500,                 loss: nan
env1_second_0:                 episode reward: 22.5500,                 loss: nan
Episode: 10401/30000 (34.6700%),                 avg. length: 1784.0,                last time consumption/overall running time: 295.1819s / 95084.7661 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.0076
env0_second_0:                 episode reward: -0.1000,                 loss: 1.3183
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 10421/30000 (34.7367%),                 avg. length: 1784.0,                last time consumption/overall running time: 306.8260s / 95391.5922 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.0398
env0_second_0:                 episode reward: -0.1000,                 loss: 1.9618
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 10441/30000 (34.8033%),                 avg. length: 1784.0,                last time consumption/overall running time: 307.0121s / 95698.6043 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.0415
env0_second_0:                 episode reward: -0.1000,                 loss: 0.6994
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 10461/30000 (34.8700%),                 avg. length: 1784.0,                last time consumption/overall running time: 312.5277s / 96011.1319 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0993
env0_second_0:                 episode reward: -0.7000,                 loss: 0.8552
env1_first_0:                 episode reward: 2.1000,                 loss: nan
env1_second_0:                 episode reward: -2.1000,                 loss: nan
Episode: 10481/30000 (34.9367%),                 avg. length: 1784.0,                last time consumption/overall running time: 307.2237s / 96318.3556 s
env0_first_0:                 episode reward: -3.0000,                 loss: 1.1681
env0_second_0:                 episode reward: 3.0000,                 loss: 3.0891
env1_first_0:                 episode reward: -1.6500,                 loss: nan
env1_second_0:                 episode reward: 1.6500,                 loss: nan
Episode: 10501/30000 (35.0033%),                 avg. length: 1004.65,                last time consumption/overall running time: 173.5554s / 96491.9111 s
env0_first_0:                 episode reward: -51.6000,                 loss: 28.2722
env0_second_0:                 episode reward: 51.6000,                 loss: 29.0220
env1_first_0:                 episode reward: -50.8500,                 loss: nan
env1_second_0:                 episode reward: 50.8500,                 loss: nan
Episode: 10521/30000 (35.0700%),                 avg. length: 338.7,                last time consumption/overall running time: 66.4032s / 96558.3142 s
env0_first_0:                 episode reward: -84.9500,                 loss: 47.8354
env0_second_0:                 episode reward: 84.9500,                 loss: 47.4177
env1_first_0:                 episode reward: -60.8000,                 loss: nan
env1_second_0:                 episode reward: 60.8000,                 loss: nan
Episode: 10541/30000 (35.1367%),                 avg. length: 333.4,                last time consumption/overall running time: 65.9247s / 96624.2389 s
env0_first_0:                 episode reward: -74.1500,                 loss: 45.8363
env0_second_0:                 episode reward: 74.1500,                 loss: 44.5051
env1_first_0:                 episode reward: -83.2000,                 loss: nan
env1_second_0:                 episode reward: 83.2000,                 loss: nan
Episode: 10561/30000 (35.2033%),                 avg. length: 721.55,                last time consumption/overall running time: 128.7319s / 96752.9709 s
env0_first_0:                 episode reward: -59.1000,                 loss: 31.9849
env0_second_0:                 episode reward: 59.1000,                 loss: 32.8452
env1_first_0:                 episode reward: -70.0500,                 loss: nan
env1_second_0:                 episode reward: 70.0500,                 loss: nan
Episode: 10581/30000 (35.2700%),                 avg. length: 653.2,                last time consumption/overall running time: 120.7852s / 96873.7561 s
env0_first_0:                 episode reward: -46.1500,                 loss: 29.9306
env0_second_0:                 episode reward: 46.1500,                 loss: 31.6335
env1_first_0:                 episode reward: -58.5500,                 loss: nan
env1_second_0:                 episode reward: 58.5500,                 loss: nan
Episode: 10601/30000 (35.3367%),                 avg. length: 316.5,                last time consumption/overall running time: 65.8698s / 96939.6258 s
env0_first_0:                 episode reward: -74.4000,                 loss: 43.7170
env0_second_0:                 episode reward: 74.4000,                 loss: 42.8095
env1_first_0:                 episode reward: -58.9000,                 loss: nan
env1_second_0:                 episode reward: 58.9000,                 loss: nan
Episode: 10621/30000 (35.4033%),                 avg. length: 350.65,                last time consumption/overall running time: 72.3692s / 97011.9950 s
env0_first_0:                 episode reward: -76.0000,                 loss: 34.7341
env0_second_0:                 episode reward: 76.0000,                 loss: 32.6027
env1_first_0:                 episode reward: -74.5500,                 loss: nan
env1_second_0:                 episode reward: 74.5500,                 loss: nan
Episode: 10641/30000 (35.4700%),                 avg. length: 1784.0,                last time consumption/overall running time: 310.5891s / 97322.5841 s
env0_first_0:                 episode reward: -4.3500,                 loss: 3.0388
env0_second_0:                 episode reward: 4.3500,                 loss: 3.5354
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 10661/30000 (35.5367%),                 avg. length: 534.7,                last time consumption/overall running time: 102.2070s / 97424.7911 s
env0_first_0:                 episode reward: -70.2000,                 loss: 31.4787
env0_second_0:                 episode reward: 70.2000,                 loss: 30.0860
env1_first_0:                 episode reward: -70.6500,                 loss: nan
env1_second_0:                 episode reward: 70.6500,                 loss: nan
Episode: 10681/30000 (35.6033%),                 avg. length: 1173.3,                last time consumption/overall running time: 207.9595s / 97632.7506 s
env0_first_0:                 episode reward: -35.1500,                 loss: 16.2044
env0_second_0:                 episode reward: 35.1500,                 loss: 14.6704
env1_first_0:                 episode reward: -30.4500,                 loss: nan
env1_second_0:                 episode reward: 30.4500,                 loss: nan
Episode: 10701/30000 (35.6700%),                 avg. length: 1784.0,                last time consumption/overall running time: 311.1602s / 97943.9108 s
env0_first_0:                 episode reward: -6.7000,                 loss: 1.2292
env0_second_0:                 episode reward: 6.7000,                 loss: 1.6578
env1_first_0:                 episode reward: -5.0000,                 loss: nan
env1_second_0:                 episode reward: 5.0000,                 loss: nan
Episode: 10721/30000 (35.7367%),                 avg. length: 1566.0,                last time consumption/overall running time: 269.7573s / 98213.6682 s
env0_first_0:                 episode reward: -9.8500,                 loss: 7.7284
env0_second_0:                 episode reward: 9.8500,                 loss: 8.4889
env1_first_0:                 episode reward: -17.7500,                 loss: nan
env1_second_0:                 episode reward: 17.7500,                 loss: nan
Episode: 10741/30000 (35.8033%),                 avg. length: 356.75,                last time consumption/overall running time: 70.9479s / 98284.6160 s
env0_first_0:                 episode reward: -76.3500,                 loss: 34.5621
env0_second_0:                 episode reward: 76.3500,                 loss: 33.4972
env1_first_0:                 episode reward: -86.4500,                 loss: nan
env1_second_0:                 episode reward: 86.4500,                 loss: nan
Episode: 10761/30000 (35.8700%),                 avg. length: 282.15,                last time consumption/overall running time: 58.0977s / 98342.7137 s
env0_first_0:                 episode reward: -83.1500,                 loss: 37.0223
env0_second_0:                 episode reward: 83.1500,                 loss: 36.1598
env1_first_0:                 episode reward: -87.4500,                 loss: nan
env1_second_0:                 episode reward: 87.4500,                 loss: nan
Episode: 10781/30000 (35.9367%),                 avg. length: 949.25,                last time consumption/overall running time: 166.1198s / 98508.8335 s
env0_first_0:                 episode reward: -43.3000,                 loss: 28.5627
env0_second_0:                 episode reward: 43.3000,                 loss: 23.6828
env1_first_0:                 episode reward: -57.2000,                 loss: nan
env1_second_0:                 episode reward: 57.2000,                 loss: nan
Episode: 10801/30000 (36.0033%),                 avg. length: 1784.0,                last time consumption/overall running time: 308.4940s / 98817.3275 s
env0_first_0:                 episode reward: -7.7000,                 loss: 2.7672
env0_second_0:                 episode reward: 7.7000,                 loss: 6.1934
env1_first_0:                 episode reward: -9.5000,                 loss: nan
env1_second_0:                 episode reward: 9.5000,                 loss: nan
Episode: 10821/30000 (36.0700%),                 avg. length: 1784.0,                last time consumption/overall running time: 320.1340s / 99137.4615 s
env0_first_0:                 episode reward: -7.2000,                 loss: 2.7766
env0_second_0:                 episode reward: 7.2000,                 loss: 5.3663
env1_first_0:                 episode reward: -6.2000,                 loss: nan
env1_second_0:                 episode reward: 6.2000,                 loss: nan
Episode: 10841/30000 (36.1367%),                 avg. length: 855.5,                last time consumption/overall running time: 167.7612s / 99305.2227 s
env0_first_0:                 episode reward: -40.5000,                 loss: 21.6569
env0_second_0:                 episode reward: 40.5000,                 loss: 20.8398
env1_first_0:                 episode reward: -39.4500,                 loss: nan
env1_second_0:                 episode reward: 39.4500,                 loss: nan
Episode: 10861/30000 (36.2033%),                 avg. length: 320.55,                last time consumption/overall running time: 65.2419s / 99370.4646 s
env0_first_0:                 episode reward: -77.7500,                 loss: 44.8053
env0_second_0:                 episode reward: 77.7500,                 loss: 44.3760
env1_first_0:                 episode reward: -68.2000,                 loss: nan
env1_second_0:                 episode reward: 68.2000,                 loss: nan
Episode: 10881/30000 (36.2700%),                 avg. length: 1492.1,                last time consumption/overall running time: 279.1881s / 99649.6527 s
env0_first_0:                 episode reward: -16.6000,                 loss: 11.3990
env0_second_0:                 episode reward: 16.6000,                 loss: 14.5155
env1_first_0:                 episode reward: -14.8000,                 loss: nan
env1_second_0:                 episode reward: 14.8000,                 loss: nan
Episode: 10901/30000 (36.3367%),                 avg. length: 1784.0,                last time consumption/overall running time: 322.1347s / 99971.7874 s
env0_first_0:                 episode reward: -4.6000,                 loss: 2.1750
env0_second_0:                 episode reward: 4.6000,                 loss: 4.5426
env1_first_0:                 episode reward: -5.5500,                 loss: nan
env1_second_0:                 episode reward: 5.5500,                 loss: nan
Episode: 10921/30000 (36.4033%),                 avg. length: 1784.0,                last time consumption/overall running time: 315.5732s / 100287.3606 s
env0_first_0:                 episode reward: -3.9000,                 loss: 2.0316
env0_second_0:                 episode reward: 3.9000,                 loss: 4.2909
env1_first_0:                 episode reward: -6.9000,                 loss: nan
env1_second_0:                 episode reward: 6.9000,                 loss: nan
Episode: 10941/30000 (36.4700%),                 avg. length: 1655.35,                last time consumption/overall running time: 290.8518s / 100578.2124 s
env0_first_0:                 episode reward: -6.1500,                 loss: 3.1633
env0_second_0:                 episode reward: 6.1500,                 loss: 6.4551
env1_first_0:                 episode reward: -11.6000,                 loss: nan
env1_second_0:                 episode reward: 11.6000,                 loss: nan
Episode: 10961/30000 (36.5367%),                 avg. length: 900.15,                last time consumption/overall running time: 171.9454s / 100750.1578 s
env0_first_0:                 episode reward: -44.0000,                 loss: 21.2188
env0_second_0:                 episode reward: 44.0000,                 loss: 22.8818
env1_first_0:                 episode reward: -68.7000,                 loss: nan
env1_second_0:                 episode reward: 68.7000,                 loss: nan
Episode: 10981/30000 (36.6033%),                 avg. length: 1010.25,                last time consumption/overall running time: 181.2120s / 100931.3697 s
env0_first_0:                 episode reward: -52.9000,                 loss: 29.6316
env0_second_0:                 episode reward: 52.9000,                 loss: 28.9263
env1_first_0:                 episode reward: -53.1500,                 loss: nan
env1_second_0:                 episode reward: 53.1500,                 loss: nan
Episode: 11001/30000 (36.6700%),                 avg. length: 1322.1,                last time consumption/overall running time: 231.3912s / 101162.7609 s
env0_first_0:                 episode reward: -50.8500,                 loss: 20.3267
env0_second_0:                 episode reward: 50.8500,                 loss: 23.3269
env1_first_0:                 episode reward: -50.2500,                 loss: nan
env1_second_0:                 episode reward: 50.2500,                 loss: nan
Episode: 11021/30000 (36.7367%),                 avg. length: 807.3,                last time consumption/overall running time: 152.8572s / 101315.6181 s
env0_first_0:                 episode reward: -54.9000,                 loss: 40.1562
env0_second_0:                 episode reward: 54.9000,                 loss: 42.9234
env1_first_0:                 episode reward: -55.2000,                 loss: nan
env1_second_0:                 episode reward: 55.2000,                 loss: nan
Episode: 11041/30000 (36.8033%),                 avg. length: 727.75,                last time consumption/overall running time: 138.7910s / 101454.4091 s
env0_first_0:                 episode reward: -64.3000,                 loss: 31.1828
env0_second_0:                 episode reward: 64.3000,                 loss: 33.8161
env1_first_0:                 episode reward: -53.6000,                 loss: nan
env1_second_0:                 episode reward: 53.6000,                 loss: nan
Episode: 11061/30000 (36.8700%),                 avg. length: 1353.0,                last time consumption/overall running time: 246.9619s / 101701.3710 s
env0_first_0:                 episode reward: -13.1500,                 loss: 9.9150
env0_second_0:                 episode reward: 13.1500,                 loss: 12.4459
env1_first_0:                 episode reward: -20.7500,                 loss: nan
env1_second_0:                 episode reward: 20.7500,                 loss: nan
Episode: 11081/30000 (36.9367%),                 avg. length: 357.4,                last time consumption/overall running time: 68.7032s / 101770.0742 s
env0_first_0:                 episode reward: -62.6500,                 loss: 46.4199
env0_second_0:                 episode reward: 62.6500,                 loss: 46.9455
env1_first_0:                 episode reward: -66.5000,                 loss: nan
env1_second_0:                 episode reward: 66.5000,                 loss: nan
Episode: 11101/30000 (37.0033%),                 avg. length: 291.15,                last time consumption/overall running time: 61.0113s / 101831.0855 s
env0_first_0:                 episode reward: -66.1500,                 loss: 50.5884
env0_second_0:                 episode reward: 66.1500,                 loss: 50.4747
env1_first_0:                 episode reward: -69.1500,                 loss: nan
env1_second_0:                 episode reward: 69.1500,                 loss: nan
Episode: 11121/30000 (37.0700%),                 avg. length: 375.85,                last time consumption/overall running time: 75.5439s / 101906.6294 s
env0_first_0:                 episode reward: -78.5500,                 loss: 43.1555
env0_second_0:                 episode reward: 78.5500,                 loss: 42.2295
env1_first_0:                 episode reward: -76.1000,                 loss: nan
env1_second_0:                 episode reward: 76.1000,                 loss: nan
Episode: 11141/30000 (37.1367%),                 avg. length: 1640.0,                last time consumption/overall running time: 273.7118s / 102180.3412 s
env0_first_0:                 episode reward: -7.7500,                 loss: 6.6993
env0_second_0:                 episode reward: 7.7500,                 loss: 7.7110
env1_first_0:                 episode reward: -10.0500,                 loss: nan
env1_second_0:                 episode reward: 10.0500,                 loss: nan
Episode: 11161/30000 (37.2033%),                 avg. length: 1784.0,                last time consumption/overall running time: 299.9068s / 102480.2479 s
env0_first_0:                 episode reward: -1.6500,                 loss: 0.1893
env0_second_0:                 episode reward: 1.6500,                 loss: 2.1055
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 11181/30000 (37.2700%),                 avg. length: 1784.0,                last time consumption/overall running time: 297.8673s / 102778.1152 s
env0_first_0:                 episode reward: -2.9500,                 loss: 0.1556
env0_second_0:                 episode reward: 2.9500,                 loss: 2.8716
env1_first_0:                 episode reward: -2.0000,                 loss: nan
env1_second_0:                 episode reward: 2.0000,                 loss: nan
Episode: 11201/30000 (37.3367%),                 avg. length: 1784.0,                last time consumption/overall running time: 298.6905s / 103076.8057 s
env0_first_0:                 episode reward: -4.6500,                 loss: 0.3571
env0_second_0:                 episode reward: 4.6500,                 loss: 2.2837
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 11221/30000 (37.4033%),                 avg. length: 1784.0,                last time consumption/overall running time: 293.6204s / 103370.4261 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0434
env0_second_0:                 episode reward: 0.3000,                 loss: 1.4753
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 11241/30000 (37.4700%),                 avg. length: 1510.7,                last time consumption/overall running time: 253.9133s / 103624.3394 s
env0_first_0:                 episode reward: -18.8500,                 loss: 13.8419
env0_second_0:                 episode reward: 18.8500,                 loss: 15.1383
env1_first_0:                 episode reward: -11.8000,                 loss: nan
env1_second_0:                 episode reward: 11.8000,                 loss: nan
Episode: 11261/30000 (37.5367%),                 avg. length: 547.6,                last time consumption/overall running time: 92.2593s / 103716.5987 s
env0_first_0:                 episode reward: -69.9500,                 loss: 26.1988
env0_second_0:                 episode reward: 69.9500,                 loss: 27.4312
env1_first_0:                 episode reward: -74.1500,                 loss: nan
env1_second_0:                 episode reward: 74.1500,                 loss: nan
Episode: 11281/30000 (37.6033%),                 avg. length: 349.5,                last time consumption/overall running time: 67.1762s / 103783.7749 s
env0_first_0:                 episode reward: -77.9500,                 loss: 31.5382
env0_second_0:                 episode reward: 77.9500,                 loss: 31.9883
env1_first_0:                 episode reward: -76.6000,                 loss: nan
env1_second_0:                 episode reward: 76.6000,                 loss: nan
Episode: 11301/30000 (37.6700%),                 avg. length: 306.75,                last time consumption/overall running time: 60.9762s / 103844.7512 s
env0_first_0:                 episode reward: -84.4000,                 loss: 37.8134
env0_second_0:                 episode reward: 84.4000,                 loss: 35.3902
env1_first_0:                 episode reward: -82.5500,                 loss: nan
env1_second_0:                 episode reward: 82.5500,                 loss: nan
Episode: 11321/30000 (37.7367%),                 avg. length: 696.8,                last time consumption/overall running time: 122.8309s / 103967.5821 s
env0_first_0:                 episode reward: -52.6500,                 loss: 36.3380
env0_second_0:                 episode reward: 52.6500,                 loss: 35.8238
env1_first_0:                 episode reward: -70.2500,                 loss: nan
env1_second_0:                 episode reward: 70.2500,                 loss: nan
Episode: 11341/30000 (37.8033%),                 avg. length: 941.6,                last time consumption/overall running time: 169.3725s / 104136.9546 s
env0_first_0:                 episode reward: -56.2000,                 loss: 17.0033
env0_second_0:                 episode reward: 56.2000,                 loss: 18.8270
env1_first_0:                 episode reward: -57.8000,                 loss: nan
env1_second_0:                 episode reward: 57.8000,                 loss: nan
Episode: 11361/30000 (37.8700%),                 avg. length: 325.4,                last time consumption/overall running time: 65.8914s / 104202.8460 s
env0_first_0:                 episode reward: -76.3000,                 loss: 54.2524
env0_second_0:                 episode reward: 76.3000,                 loss: 50.6563
env1_first_0:                 episode reward: -85.4500,                 loss: nan
env1_second_0:                 episode reward: 85.4500,                 loss: nan
Episode: 11381/30000 (37.9367%),                 avg. length: 328.0,                last time consumption/overall running time: 67.0108s / 104269.8568 s
env0_first_0:                 episode reward: -72.5000,                 loss: 45.2207
env0_second_0:                 episode reward: 72.5000,                 loss: 46.0183
env1_first_0:                 episode reward: -77.6500,                 loss: nan
env1_second_0:                 episode reward: 77.6500,                 loss: nan
Episode: 11401/30000 (38.0033%),                 avg. length: 487.4,                last time consumption/overall running time: 92.8997s / 104362.7565 s
env0_first_0:                 episode reward: -81.8500,                 loss: 42.0082
env0_second_0:                 episode reward: 81.8500,                 loss: 43.9293
env1_first_0:                 episode reward: -58.8500,                 loss: nan
env1_second_0:                 episode reward: 58.8500,                 loss: nan
Episode: 11421/30000 (38.0700%),                 avg. length: 295.85,                last time consumption/overall running time: 60.3109s / 104423.0674 s
env0_first_0:                 episode reward: -80.2500,                 loss: 47.6462
env0_second_0:                 episode reward: 80.2500,                 loss: 48.7301
env1_first_0:                 episode reward: -82.0000,                 loss: nan
env1_second_0:                 episode reward: 82.0000,                 loss: nan
Episode: 11441/30000 (38.1367%),                 avg. length: 485.3,                last time consumption/overall running time: 92.2418s / 104515.3092 s
env0_first_0:                 episode reward: -70.2500,                 loss: 46.2869
env0_second_0:                 episode reward: 70.2500,                 loss: 48.8178
env1_first_0:                 episode reward: -66.1500,                 loss: nan
env1_second_0:                 episode reward: 66.1500,                 loss: nan
Episode: 11461/30000 (38.2033%),                 avg. length: 1784.0,                last time consumption/overall running time: 309.7423s / 104825.0515 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.6455
env0_second_0:                 episode reward: 0.1500,                 loss: 3.9313
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 11481/30000 (38.2700%),                 avg. length: 1784.0,                last time consumption/overall running time: 304.6679s / 105129.7194 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.4375
env0_second_0:                 episode reward: 0.9500,                 loss: 3.8035
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 11501/30000 (38.3367%),                 avg. length: 1784.0,                last time consumption/overall running time: 301.9361s / 105431.6555 s
env0_first_0:                 episode reward: -5.3000,                 loss: 0.5965
env0_second_0:                 episode reward: 5.3000,                 loss: 3.0483
env1_first_0:                 episode reward: -1.9000,                 loss: nan
env1_second_0:                 episode reward: 1.9000,                 loss: nan
Episode: 11521/30000 (38.4033%),                 avg. length: 742.1,                last time consumption/overall running time: 132.0224s / 105563.6779 s
env0_first_0:                 episode reward: -57.2500,                 loss: 39.0066
env0_second_0:                 episode reward: 57.2500,                 loss: 49.9123
env1_first_0:                 episode reward: -58.5000,                 loss: nan
env1_second_0:                 episode reward: 58.5000,                 loss: nan
Episode: 11541/30000 (38.4700%),                 avg. length: 744.05,                last time consumption/overall running time: 134.7781s / 105698.4560 s
env0_first_0:                 episode reward: -56.4500,                 loss: 37.2806
env0_second_0:                 episode reward: 56.4500,                 loss: 41.3329
env1_first_0:                 episode reward: -34.8500,                 loss: nan
env1_second_0:                 episode reward: 34.8500,                 loss: nan
Episode: 11561/30000 (38.5367%),                 avg. length: 1239.7,                last time consumption/overall running time: 213.4464s / 105911.9025 s
env0_first_0:                 episode reward: -45.4500,                 loss: 18.8460
env0_second_0:                 episode reward: 45.4500,                 loss: 26.6090
env1_first_0:                 episode reward: -45.7500,                 loss: nan
env1_second_0:                 episode reward: 45.7500,                 loss: nan
Episode: 11581/30000 (38.6033%),                 avg. length: 1182.75,                last time consumption/overall running time: 205.2663s / 106117.1688 s
env0_first_0:                 episode reward: -24.1000,                 loss: 25.7396
env0_second_0:                 episode reward: 24.1000,                 loss: 28.9738
env1_first_0:                 episode reward: -34.4000,                 loss: nan
env1_second_0:                 episode reward: 34.4000,                 loss: nan
Episode: 11601/30000 (38.6700%),                 avg. length: 1117.05,                last time consumption/overall running time: 191.7977s / 106308.9665 s
env0_first_0:                 episode reward: -9.6500,                 loss: 17.9425
env0_second_0:                 episode reward: 9.6500,                 loss: 20.3148
env1_first_0:                 episode reward: -13.7000,                 loss: nan
env1_second_0:                 episode reward: 13.7000,                 loss: nan
Episode: 11621/30000 (38.7367%),                 avg. length: 563.85,                last time consumption/overall running time: 106.9438s / 106415.9102 s
env0_first_0:                 episode reward: -57.2500,                 loss: 51.7283
env0_second_0:                 episode reward: 57.2500,                 loss: 54.0982
env1_first_0:                 episode reward: -37.7500,                 loss: nan
env1_second_0:                 episode reward: 37.7500,                 loss: nan
Episode: 11641/30000 (38.8033%),                 avg. length: 895.7,                last time consumption/overall running time: 158.2189s / 106574.1292 s
env0_first_0:                 episode reward: -43.8000,                 loss: 35.7128
env0_second_0:                 episode reward: 43.8000,                 loss: 37.6406
env1_first_0:                 episode reward: -40.2000,                 loss: nan
env1_second_0:                 episode reward: 40.2000,                 loss: nan
Episode: 11661/30000 (38.8700%),                 avg. length: 533.55,                last time consumption/overall running time: 98.3078s / 106672.4369 s
env0_first_0:                 episode reward: -44.3000,                 loss: 48.2728
env0_second_0:                 episode reward: 44.3000,                 loss: 46.6902
env1_first_0:                 episode reward: -50.7000,                 loss: nan
env1_second_0:                 episode reward: 50.7000,                 loss: nan
Episode: 11681/30000 (38.9367%),                 avg. length: 707.2,                last time consumption/overall running time: 124.4029s / 106796.8398 s
env0_first_0:                 episode reward: -46.5500,                 loss: 36.2569
env0_second_0:                 episode reward: 46.5500,                 loss: 37.9237
env1_first_0:                 episode reward: -62.9500,                 loss: nan
env1_second_0:                 episode reward: 62.9500,                 loss: nan
Episode: 11701/30000 (39.0033%),                 avg. length: 765.95,                last time consumption/overall running time: 132.1092s / 106928.9490 s
env0_first_0:                 episode reward: -52.0500,                 loss: 37.8292
env0_second_0:                 episode reward: 52.0500,                 loss: 40.4669
env1_first_0:                 episode reward: -47.6500,                 loss: nan
env1_second_0:                 episode reward: 47.6500,                 loss: nan
Episode: 11721/30000 (39.0700%),                 avg. length: 1784.0,                last time consumption/overall running time: 301.9187s / 107230.8677 s
env0_first_0:                 episode reward: 0.5500,                 loss: 2.0978
env0_second_0:                 episode reward: -0.5500,                 loss: 4.1510
env1_first_0:                 episode reward: 3.5000,                 loss: nan
env1_second_0:                 episode reward: -3.5000,                 loss: nan
Episode: 11741/30000 (39.1367%),                 avg. length: 1784.0,                last time consumption/overall running time: 302.5301s / 107533.3978 s
env0_first_0:                 episode reward: 3.1500,                 loss: 0.9169
env0_second_0:                 episode reward: -3.1500,                 loss: 3.7059
env1_first_0:                 episode reward: 4.9500,                 loss: nan
env1_second_0:                 episode reward: -4.9500,                 loss: nan
Episode: 11761/30000 (39.2033%),                 avg. length: 1784.0,                last time consumption/overall running time: 295.5183s / 107828.9161 s
env0_first_0:                 episode reward: 12.3500,                 loss: 1.5923
env0_second_0:                 episode reward: -12.3500,                 loss: 3.6414
env1_first_0:                 episode reward: 7.7000,                 loss: nan
env1_second_0:                 episode reward: -7.7000,                 loss: nan
Episode: 11781/30000 (39.2700%),                 avg. length: 1743.05,                last time consumption/overall running time: 291.3610s / 108120.2771 s
env0_first_0:                 episode reward: -4.2500,                 loss: 4.9477
env0_second_0:                 episode reward: 4.2500,                 loss: 7.4493
env1_first_0:                 episode reward: -10.4000,                 loss: nan
env1_second_0:                 episode reward: 10.4000,                 loss: nan
Episode: 11801/30000 (39.3367%),                 avg. length: 619.95,                last time consumption/overall running time: 113.3912s / 108233.6683 s
env0_first_0:                 episode reward: -54.5500,                 loss: 46.5245
env0_second_0:                 episode reward: 54.5500,                 loss: 49.1799
env1_first_0:                 episode reward: -59.4000,                 loss: nan
env1_second_0:                 episode reward: 59.4000,                 loss: nan
Episode: 11821/30000 (39.4033%),                 avg. length: 576.4,                last time consumption/overall running time: 107.4480s / 108341.1163 s
env0_first_0:                 episode reward: -54.4000,                 loss: 47.0420
env0_second_0:                 episode reward: 54.4000,                 loss: 48.6744
env1_first_0:                 episode reward: -70.1500,                 loss: nan
env1_second_0:                 episode reward: 70.1500,                 loss: nan
Episode: 11841/30000 (39.4700%),                 avg. length: 1784.0,                last time consumption/overall running time: 301.4417s / 108642.5580 s
env0_first_0:                 episode reward: -1.3500,                 loss: 1.9113
env0_second_0:                 episode reward: 1.3500,                 loss: 2.3058
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 11861/30000 (39.5367%),                 avg. length: 1784.0,                last time consumption/overall running time: 292.4394s / 108934.9973 s
env0_first_0:                 episode reward: -1.5000,                 loss: 0.2819
env0_second_0:                 episode reward: 1.5000,                 loss: 1.0282
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 11881/30000 (39.6033%),                 avg. length: 1784.0,                last time consumption/overall running time: 285.8460s / 109220.8433 s
env0_first_0:                 episode reward: -1.7000,                 loss: 0.0823
env0_second_0:                 episode reward: 1.7000,                 loss: 1.6667
env1_first_0:                 episode reward: -1.9000,                 loss: nan
env1_second_0:                 episode reward: 1.9000,                 loss: nan
Episode: 11901/30000 (39.6700%),                 avg. length: 702.7,                last time consumption/overall running time: 122.1162s / 109342.9595 s
env0_first_0:                 episode reward: -66.1000,                 loss: 22.7787
env0_second_0:                 episode reward: 66.1000,                 loss: 25.4536
env1_first_0:                 episode reward: -56.5000,                 loss: nan
env1_second_0:                 episode reward: 56.5000,                 loss: nan
Episode: 11921/30000 (39.7367%),                 avg. length: 593.15,                last time consumption/overall running time: 104.0249s / 109446.9844 s
env0_first_0:                 episode reward: -42.6500,                 loss: 37.3164
env0_second_0:                 episode reward: 42.6500,                 loss: 44.8116
env1_first_0:                 episode reward: -66.3500,                 loss: nan
env1_second_0:                 episode reward: 66.3500,                 loss: nan
Episode: 11941/30000 (39.8033%),                 avg. length: 619.5,                last time consumption/overall running time: 115.4953s / 109562.4797 s
env0_first_0:                 episode reward: -41.8000,                 loss: 37.0136
env0_second_0:                 episode reward: 41.8000,                 loss: 40.4160
env1_first_0:                 episode reward: -58.1500,                 loss: nan
env1_second_0:                 episode reward: 58.1500,                 loss: nan
Episode: 11961/30000 (39.8700%),                 avg. length: 389.9,                last time consumption/overall running time: 75.7701s / 109638.2498 s
env0_first_0:                 episode reward: -81.4500,                 loss: 43.9155
env0_second_0:                 episode reward: 81.4500,                 loss: 49.5329
env1_first_0:                 episode reward: -70.0000,                 loss: nan
env1_second_0:                 episode reward: 70.0000,                 loss: nan
Episode: 11981/30000 (39.9367%),                 avg. length: 334.6,                last time consumption/overall running time: 65.5703s / 109703.8201 s
env0_first_0:                 episode reward: -62.5500,                 loss: 38.7021
env0_second_0:                 episode reward: 62.5500,                 loss: 43.5151
env1_first_0:                 episode reward: -82.2500,                 loss: nan
env1_second_0:                 episode reward: 82.2500,                 loss: nan
Episode: 12001/30000 (40.0033%),                 avg. length: 413.0,                last time consumption/overall running time: 83.3196s / 109787.1397 s
env0_first_0:                 episode reward: -61.0000,                 loss: 46.0636
env0_second_0:                 episode reward: 61.0000,                 loss: 49.1217
env1_first_0:                 episode reward: -64.5500,                 loss: nan
env1_second_0:                 episode reward: 64.5500,                 loss: nan
Episode: 12021/30000 (40.0700%),                 avg. length: 456.85,                last time consumption/overall running time: 87.6483s / 109874.7879 s
env0_first_0:                 episode reward: -77.1500,                 loss: 35.4068
env0_second_0:                 episode reward: 77.1500,                 loss: 38.0257
env1_first_0:                 episode reward: -61.0000,                 loss: nan
env1_second_0:                 episode reward: 61.0000,                 loss: nan
Episode: 12041/30000 (40.1367%),                 avg. length: 403.25,                last time consumption/overall running time: 74.1878s / 109948.9757 s
env0_first_0:                 episode reward: -77.5500,                 loss: 37.3784
env0_second_0:                 episode reward: 77.5500,                 loss: 38.5003
env1_first_0:                 episode reward: -56.2000,                 loss: nan
env1_second_0:                 episode reward: 56.2000,                 loss: nan
Episode: 12061/30000 (40.2033%),                 avg. length: 426.25,                last time consumption/overall running time: 81.5473s / 110030.5230 s
env0_first_0:                 episode reward: -76.0000,                 loss: 31.5919
env0_second_0:                 episode reward: 76.0000,                 loss: 33.4284
env1_first_0:                 episode reward: -82.1000,                 loss: nan
env1_second_0:                 episode reward: 82.1000,                 loss: nan
Episode: 12081/30000 (40.2700%),                 avg. length: 364.2,                last time consumption/overall running time: 68.5297s / 110099.0528 s
env0_first_0:                 episode reward: -71.2000,                 loss: 32.7408
env0_second_0:                 episode reward: 71.2000,                 loss: 35.0855
env1_first_0:                 episode reward: -84.1500,                 loss: nan
env1_second_0:                 episode reward: 84.1500,                 loss: nan
Episode: 12101/30000 (40.3367%),                 avg. length: 762.9,                last time consumption/overall running time: 133.7865s / 110232.8392 s
env0_first_0:                 episode reward: -59.8500,                 loss: 24.2299
env0_second_0:                 episode reward: 59.8500,                 loss: 30.2079
env1_first_0:                 episode reward: -64.7000,                 loss: nan
env1_second_0:                 episode reward: 64.7000,                 loss: nan
Episode: 12121/30000 (40.4033%),                 avg. length: 588.25,                last time consumption/overall running time: 102.3865s / 110335.2257 s
env0_first_0:                 episode reward: -58.8500,                 loss: 35.7836
env0_second_0:                 episode reward: 58.8500,                 loss: 37.3034
env1_first_0:                 episode reward: -77.9500,                 loss: nan
env1_second_0:                 episode reward: 77.9500,                 loss: nan
Episode: 12141/30000 (40.4700%),                 avg. length: 571.45,                last time consumption/overall running time: 102.5645s / 110437.7903 s
env0_first_0:                 episode reward: -64.9500,                 loss: 39.9912
env0_second_0:                 episode reward: 64.9500,                 loss: 42.7267
env1_first_0:                 episode reward: -54.7000,                 loss: nan
env1_second_0:                 episode reward: 54.7000,                 loss: nan
Episode: 12161/30000 (40.5367%),                 avg. length: 1662.1,                last time consumption/overall running time: 269.1326s / 110706.9229 s
env0_first_0:                 episode reward: -9.9000,                 loss: 3.4552
env0_second_0:                 episode reward: 9.9000,                 loss: 4.9211
env1_first_0:                 episode reward: -9.1000,                 loss: nan
env1_second_0:                 episode reward: 9.1000,                 loss: nan
Episode: 12181/30000 (40.6033%),                 avg. length: 1706.4,                last time consumption/overall running time: 280.9048s / 110987.8277 s
env0_first_0:                 episode reward: -8.9000,                 loss: 4.7645
env0_second_0:                 episode reward: 8.9000,                 loss: 6.9308
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 12201/30000 (40.6700%),                 avg. length: 1784.0,                last time consumption/overall running time: 298.9754s / 111286.8031 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.9461
env0_second_0:                 episode reward: 3.9000,                 loss: 2.2320
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 12221/30000 (40.7367%),                 avg. length: 1784.0,                last time consumption/overall running time: 298.1700s / 111584.9731 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2648
env0_second_0:                 episode reward: 0.5000,                 loss: 1.1679
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 12241/30000 (40.8033%),                 avg. length: 1784.0,                last time consumption/overall running time: 297.8128s / 111882.7859 s
env0_first_0:                 episode reward: -0.6500,                 loss: -0.0200
env0_second_0:                 episode reward: 0.6500,                 loss: 0.9410
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 12261/30000 (40.8700%),                 avg. length: 1784.0,                last time consumption/overall running time: 295.8878s / 112178.6737 s
env0_first_0:                 episode reward: 0.4000,                 loss: -0.1051
env0_second_0:                 episode reward: -0.4000,                 loss: 4.6753
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 12281/30000 (40.9367%),                 avg. length: 1784.0,                last time consumption/overall running time: 299.6909s / 112478.3646 s
env0_first_0:                 episode reward: 0.5500,                 loss: -0.1086
env0_second_0:                 episode reward: -0.5500,                 loss: 1.6230
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 12301/30000 (41.0033%),                 avg. length: 1784.0,                last time consumption/overall running time: 299.7418s / 112778.1064 s
env0_first_0:                 episode reward: 0.7500,                 loss: -0.1292
env0_second_0:                 episode reward: -0.7500,                 loss: 1.3657
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 12321/30000 (41.0700%),                 avg. length: 1784.0,                last time consumption/overall running time: 301.6092s / 113079.7156 s
env0_first_0:                 episode reward: 0.7000,                 loss: -0.0924
env0_second_0:                 episode reward: -0.7000,                 loss: 4.8141
env1_first_0:                 episode reward: 1.7000,                 loss: nan
env1_second_0:                 episode reward: -1.7000,                 loss: nan
Episode: 12341/30000 (41.1367%),                 avg. length: 1784.0,                last time consumption/overall running time: 295.5068s / 113375.2224 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0267
env0_second_0:                 episode reward: 0.5500,                 loss: 1.6099
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 12361/30000 (41.2033%),                 avg. length: 1784.0,                last time consumption/overall running time: 291.5547s / 113666.7771 s
env0_first_0:                 episode reward: 1.3500,                 loss: 0.0084
env0_second_0:                 episode reward: -1.3500,                 loss: 1.6002
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 12381/30000 (41.2700%),                 avg. length: 1784.0,                last time consumption/overall running time: 302.3372s / 113969.1143 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.6870
env0_second_0:                 episode reward: 1.4000,                 loss: 3.3280
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 12401/30000 (41.3367%),                 avg. length: 725.1,                last time consumption/overall running time: 131.1194s / 114100.2337 s
env0_first_0:                 episode reward: -47.1500,                 loss: 30.8041
env0_second_0:                 episode reward: 47.1500,                 loss: 33.2271
env1_first_0:                 episode reward: -58.7500,                 loss: nan
env1_second_0:                 episode reward: 58.7500,                 loss: nan
Episode: 12421/30000 (41.4033%),                 avg. length: 499.85,                last time consumption/overall running time: 94.3393s / 114194.5729 s
env0_first_0:                 episode reward: -74.2000,                 loss: 43.7580
env0_second_0:                 episode reward: 74.2000,                 loss: 47.2299
env1_first_0:                 episode reward: -71.5500,                 loss: nan
env1_second_0:                 episode reward: 71.5500,                 loss: nan
Episode: 12441/30000 (41.4700%),                 avg. length: 355.45,                last time consumption/overall running time: 65.6667s / 114260.2396 s
env0_first_0:                 episode reward: -70.9500,                 loss: 42.0868
env0_second_0:                 episode reward: 70.9500,                 loss: 45.4159
env1_first_0:                 episode reward: -70.0000,                 loss: nan
env1_second_0:                 episode reward: 70.0000,                 loss: nan
Episode: 12461/30000 (41.5367%),                 avg. length: 446.7,                last time consumption/overall running time: 85.7502s / 114345.9899 s
env0_first_0:                 episode reward: -62.1000,                 loss: 37.8629
env0_second_0:                 episode reward: 62.1000,                 loss: 40.5830
env1_first_0:                 episode reward: -75.7000,                 loss: nan
env1_second_0:                 episode reward: 75.7000,                 loss: nan
Episode: 12481/30000 (41.6033%),                 avg. length: 554.75,                last time consumption/overall running time: 103.7777s / 114449.7675 s
env0_first_0:                 episode reward: -62.4500,                 loss: 35.0473
env0_second_0:                 episode reward: 62.4500,                 loss: 37.6855
env1_first_0:                 episode reward: -70.5000,                 loss: nan
env1_second_0:                 episode reward: 70.5000,                 loss: nan
Episode: 12501/30000 (41.6700%),                 avg. length: 264.0,                last time consumption/overall running time: 53.9401s / 114503.7076 s
env0_first_0:                 episode reward: -74.3000,                 loss: 38.2169
env0_second_0:                 episode reward: 74.3000,                 loss: 39.9857
env1_first_0:                 episode reward: -79.9000,                 loss: nan
env1_second_0:                 episode reward: 79.9000,                 loss: nan
Episode: 12521/30000 (41.7367%),                 avg. length: 351.85,                last time consumption/overall running time: 66.6165s / 114570.3241 s
env0_first_0:                 episode reward: -79.5500,                 loss: 32.7381
env0_second_0:                 episode reward: 79.5500,                 loss: 36.3205
env1_first_0:                 episode reward: -77.2500,                 loss: nan
env1_second_0:                 episode reward: 77.2500,                 loss: nan
Episode: 12541/30000 (41.8033%),                 avg. length: 507.85,                last time consumption/overall running time: 93.5750s / 114663.8992 s
env0_first_0:                 episode reward: -64.2000,                 loss: 39.1104
env0_second_0:                 episode reward: 64.2000,                 loss: 40.1892
env1_first_0:                 episode reward: -50.3000,                 loss: nan
env1_second_0:                 episode reward: 50.3000,                 loss: nan
Episode: 12561/30000 (41.8700%),                 avg. length: 419.05,                last time consumption/overall running time: 80.1521s / 114744.0513 s
env0_first_0:                 episode reward: -63.6500,                 loss: 48.4478
env0_second_0:                 episode reward: 63.6500,                 loss: 51.9322
env1_first_0:                 episode reward: -72.2000,                 loss: nan
env1_second_0:                 episode reward: 72.2000,                 loss: nan
Episode: 12581/30000 (41.9367%),                 avg. length: 389.2,                last time consumption/overall running time: 74.7254s / 114818.7767 s
env0_first_0:                 episode reward: -86.2500,                 loss: 50.5100
env0_second_0:                 episode reward: 86.2500,                 loss: 53.7604
env1_first_0:                 episode reward: -56.2500,                 loss: nan
env1_second_0:                 episode reward: 56.2500,                 loss: nan
Episode: 12601/30000 (42.0033%),                 avg. length: 522.9,                last time consumption/overall running time: 97.3419s / 114916.1186 s
env0_first_0:                 episode reward: -67.5000,                 loss: 34.8317
env0_second_0:                 episode reward: 67.5000,                 loss: 34.2801
env1_first_0:                 episode reward: -72.3500,                 loss: nan
env1_second_0:                 episode reward: 72.3500,                 loss: nan
Episode: 12621/30000 (42.0700%),                 avg. length: 1052.75,                last time consumption/overall running time: 183.1011s / 115099.2198 s
env0_first_0:                 episode reward: -45.0000,                 loss: 21.8922
env0_second_0:                 episode reward: 45.0000,                 loss: 22.9752
env1_first_0:                 episode reward: -49.7500,                 loss: nan
env1_second_0:                 episode reward: 49.7500,                 loss: nan
Episode: 12641/30000 (42.1367%),                 avg. length: 764.7,                last time consumption/overall running time: 136.0361s / 115235.2559 s
env0_first_0:                 episode reward: -35.5000,                 loss: 36.5532
env0_second_0:                 episode reward: 35.5000,                 loss: 37.5791
env1_first_0:                 episode reward: -75.9000,                 loss: nan
env1_second_0:                 episode reward: 75.9000,                 loss: nan
Episode: 12661/30000 (42.2033%),                 avg. length: 428.95,                last time consumption/overall running time: 81.4896s / 115316.7455 s
env0_first_0:                 episode reward: -74.1000,                 loss: 44.9782
env0_second_0:                 episode reward: 74.1000,                 loss: 46.1955
env1_first_0:                 episode reward: -78.7500,                 loss: nan
env1_second_0:                 episode reward: 78.7500,                 loss: nan
Episode: 12681/30000 (42.2700%),                 avg. length: 351.0,                last time consumption/overall running time: 70.0780s / 115386.8235 s
env0_first_0:                 episode reward: -73.1000,                 loss: 46.4081
env0_second_0:                 episode reward: 73.1000,                 loss: 47.8821
env1_first_0:                 episode reward: -78.1000,                 loss: nan
env1_second_0:                 episode reward: 78.1000,                 loss: nan
Episode: 12701/30000 (42.3367%),                 avg. length: 408.6,                last time consumption/overall running time: 79.0219s / 115465.8454 s
env0_first_0:                 episode reward: -67.3500,                 loss: 38.7001
env0_second_0:                 episode reward: 67.3500,                 loss: 217.4847
env1_first_0:                 episode reward: -75.8000,                 loss: nan
env1_second_0:                 episode reward: 75.8000,                 loss: nan
Episode: 12721/30000 (42.4033%),                 avg. length: 277.25,                last time consumption/overall running time: 56.4149s / 115522.2603 s
env0_first_0:                 episode reward: -74.8000,                 loss: 37.9646
env0_second_0:                 episode reward: 74.8000,                 loss: 39.1898
env1_first_0:                 episode reward: -80.3500,                 loss: nan
env1_second_0:                 episode reward: 80.3500,                 loss: nan
Episode: 12741/30000 (42.4700%),                 avg. length: 349.15,                last time consumption/overall running time: 69.0759s / 115591.3362 s
env0_first_0:                 episode reward: -66.0500,                 loss: 32.4551
env0_second_0:                 episode reward: 66.0500,                 loss: 34.5563
env1_first_0:                 episode reward: -76.2500,                 loss: nan
env1_second_0:                 episode reward: 76.2500,                 loss: nan
Episode: 12761/30000 (42.5367%),                 avg. length: 267.15,                last time consumption/overall running time: 54.3152s / 115645.6514 s
env0_first_0:                 episode reward: -83.2500,                 loss: 32.0403
env0_second_0:                 episode reward: 83.2500,                 loss: 35.2210
env1_first_0:                 episode reward: -70.7000,                 loss: nan
env1_second_0:                 episode reward: 70.7000,                 loss: nan
Episode: 12781/30000 (42.6033%),                 avg. length: 260.3,                last time consumption/overall running time: 54.1484s / 115699.7998 s
env0_first_0:                 episode reward: -88.8500,                 loss: 26.9116
env0_second_0:                 episode reward: 88.8500,                 loss: 28.9157
env1_first_0:                 episode reward: -92.4000,                 loss: nan
env1_second_0:                 episode reward: 92.4000,                 loss: nan
Episode: 12801/30000 (42.6700%),                 avg. length: 531.45,                last time consumption/overall running time: 97.2483s / 115797.0482 s
env0_first_0:                 episode reward: -61.0000,                 loss: 33.0048
env0_second_0:                 episode reward: 61.0000,                 loss: 36.2440
env1_first_0:                 episode reward: -60.5500,                 loss: nan
env1_second_0:                 episode reward: 60.5500,                 loss: nan
Episode: 12821/30000 (42.7367%),                 avg. length: 920.95,                last time consumption/overall running time: 161.9526s / 115959.0008 s
env0_first_0:                 episode reward: -49.2000,                 loss: 19.1915
env0_second_0:                 episode reward: 49.2000,                 loss: 21.9879
env1_first_0:                 episode reward: -38.7000,                 loss: nan
env1_second_0:                 episode reward: 38.7000,                 loss: nan
Episode: 12841/30000 (42.8033%),                 avg. length: 449.25,                last time consumption/overall running time: 85.0013s / 116044.0021 s
env0_first_0:                 episode reward: -74.4000,                 loss: 37.1706
env0_second_0:                 episode reward: 74.4000,                 loss: 38.2505
env1_first_0:                 episode reward: -58.4000,                 loss: nan
env1_second_0:                 episode reward: 58.4000,                 loss: nan
Episode: 12861/30000 (42.8700%),                 avg. length: 1106.2,                last time consumption/overall running time: 195.2990s / 116239.3012 s
env0_first_0:                 episode reward: -22.2500,                 loss: 20.1170
env0_second_0:                 episode reward: 22.2500,                 loss: 22.0801
env1_first_0:                 episode reward: -23.0500,                 loss: nan
env1_second_0:                 episode reward: 23.0500,                 loss: nan
Episode: 12881/30000 (42.9367%),                 avg. length: 1334.15,                last time consumption/overall running time: 236.0074s / 116475.3086 s
env0_first_0:                 episode reward: 1.2000,                 loss: 6.8888
env0_second_0:                 episode reward: -1.2000,                 loss: 8.2669
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 12901/30000 (43.0033%),                 avg. length: 1272.6,                last time consumption/overall running time: 225.5152s / 116700.8238 s
env0_first_0:                 episode reward: -3.5500,                 loss: 6.6535
env0_second_0:                 episode reward: 3.5500,                 loss: 8.2715
env1_first_0:                 episode reward: -4.1500,                 loss: nan
env1_second_0:                 episode reward: 4.1500,                 loss: nan
Episode: 12921/30000 (43.0700%),                 avg. length: 954.65,                last time consumption/overall running time: 172.4429s / 116873.2667 s
env0_first_0:                 episode reward: -7.1500,                 loss: 13.0519
env0_second_0:                 episode reward: 7.1500,                 loss: 13.9944
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 12941/30000 (43.1367%),                 avg. length: 871.3,                last time consumption/overall running time: 157.0966s / 117030.3633 s
env0_first_0:                 episode reward: 12.1500,                 loss: 17.8041
env0_second_0:                 episode reward: -12.1500,                 loss: 19.6739
env1_first_0:                 episode reward: -8.6500,                 loss: nan
env1_second_0:                 episode reward: 8.6500,                 loss: nan
Episode: 12961/30000 (43.2033%),                 avg. length: 614.7,                last time consumption/overall running time: 113.0350s / 117143.3983 s
env0_first_0:                 episode reward: -41.2500,                 loss: 37.0829
env0_second_0:                 episode reward: 41.2500,                 loss: 35.6507
env1_first_0:                 episode reward: -40.6500,                 loss: nan
env1_second_0:                 episode reward: 40.6500,                 loss: nan
Episode: 12981/30000 (43.2700%),                 avg. length: 465.15,                last time consumption/overall running time: 89.3493s / 117232.7475 s
env0_first_0:                 episode reward: -61.0500,                 loss: 50.7692
env0_second_0:                 episode reward: 61.0500,                 loss: 49.1434
env1_first_0:                 episode reward: -59.3500,                 loss: nan
env1_second_0:                 episode reward: 59.3500,                 loss: nan
Episode: 13001/30000 (43.3367%),                 avg. length: 775.75,                last time consumption/overall running time: 141.4225s / 117374.1700 s
env0_first_0:                 episode reward: -40.2000,                 loss: 30.2691
env0_second_0:                 episode reward: 40.2000,                 loss: 29.4271
env1_first_0:                 episode reward: -36.9000,                 loss: nan
env1_second_0:                 episode reward: 36.9000,                 loss: nan
Episode: 13021/30000 (43.4033%),                 avg. length: 398.5,                last time consumption/overall running time: 77.4572s / 117451.6272 s
env0_first_0:                 episode reward: -60.4500,                 loss: 41.6010
env0_second_0:                 episode reward: 60.4500,                 loss: 43.4536
env1_first_0:                 episode reward: -74.4000,                 loss: nan
env1_second_0:                 episode reward: 74.4000,                 loss: nan
Episode: 13041/30000 (43.4700%),                 avg. length: 318.85,                last time consumption/overall running time: 62.8749s / 117514.5021 s
env0_first_0:                 episode reward: -68.3000,                 loss: 36.8681
env0_second_0:                 episode reward: 68.3000,                 loss: 39.3040
env1_first_0:                 episode reward: -87.1500,                 loss: nan
env1_second_0:                 episode reward: 87.1500,                 loss: nan
Episode: 13061/30000 (43.5367%),                 avg. length: 239.6,                last time consumption/overall running time: 49.5748s / 117564.0769 s
env0_first_0:                 episode reward: -91.7000,                 loss: 35.0597
env0_second_0:                 episode reward: 91.7000,                 loss: 33.8109
env1_first_0:                 episode reward: -84.7000,                 loss: nan
env1_second_0:                 episode reward: 84.7000,                 loss: nan
Episode: 13081/30000 (43.6033%),                 avg. length: 278.7,                last time consumption/overall running time: 56.9331s / 117621.0100 s
env0_first_0:                 episode reward: -81.1000,                 loss: 31.2016
env0_second_0:                 episode reward: 81.1000,                 loss: 29.4687
env1_first_0:                 episode reward: -81.4000,                 loss: nan
env1_second_0:                 episode reward: 81.4000,                 loss: nan
Episode: 13101/30000 (43.6700%),                 avg. length: 236.95,                last time consumption/overall running time: 49.9071s / 117670.9171 s
env0_first_0:                 episode reward: -85.3500,                 loss: 33.0481
env0_second_0:                 episode reward: 85.3500,                 loss: 34.3873
env1_first_0:                 episode reward: -86.4500,                 loss: nan
env1_second_0:                 episode reward: 86.4500,                 loss: nan
Episode: 13121/30000 (43.7367%),                 avg. length: 300.35,                last time consumption/overall running time: 61.5149s / 117732.4320 s
env0_first_0:                 episode reward: -78.1500,                 loss: 36.9209
env0_second_0:                 episode reward: 78.1500,                 loss: 38.1712
env1_first_0:                 episode reward: -75.0500,                 loss: nan
env1_second_0:                 episode reward: 75.0500,                 loss: nan
Episode: 13141/30000 (43.8033%),                 avg. length: 273.1,                last time consumption/overall running time: 56.1599s / 117788.5919 s
env0_first_0:                 episode reward: -83.0000,                 loss: 36.6422
env0_second_0:                 episode reward: 83.0000,                 loss: 40.1111
env1_first_0:                 episode reward: -79.3500,                 loss: nan
env1_second_0:                 episode reward: 79.3500,                 loss: nan
Episode: 13161/30000 (43.8700%),                 avg. length: 726.05,                last time consumption/overall running time: 132.1834s / 117920.7753 s
env0_first_0:                 episode reward: -47.3500,                 loss: 28.2430
env0_second_0:                 episode reward: 47.3500,                 loss: 29.2062
env1_first_0:                 episode reward: -53.5500,                 loss: nan
env1_second_0:                 episode reward: 53.5500,                 loss: nan
Episode: 13181/30000 (43.9367%),                 avg. length: 306.15,                last time consumption/overall running time: 62.7263s / 117983.5016 s
env0_first_0:                 episode reward: -70.8500,                 loss: 44.3968
env0_second_0:                 episode reward: 70.8500,                 loss: 45.6734
env1_first_0:                 episode reward: -69.2500,                 loss: nan
env1_second_0:                 episode reward: 69.2500,                 loss: nan
Episode: 13201/30000 (44.0033%),                 avg. length: 919.55,                last time consumption/overall running time: 167.0070s / 118150.5086 s
env0_first_0:                 episode reward: -44.1000,                 loss: 24.7512
env0_second_0:                 episode reward: 44.1000,                 loss: 26.9374
env1_first_0:                 episode reward: -35.0500,                 loss: nan
env1_second_0:                 episode reward: 35.0500,                 loss: nan
Episode: 13221/30000 (44.0700%),                 avg. length: 397.2,                last time consumption/overall running time: 78.7151s / 118229.2237 s
env0_first_0:                 episode reward: -69.0500,                 loss: 38.0861
env0_second_0:                 episode reward: 69.0500,                 loss: 39.8428
env1_first_0:                 episode reward: -68.1500,                 loss: nan
env1_second_0:                 episode reward: 68.1500,                 loss: nan
Episode: 13241/30000 (44.1367%),                 avg. length: 390.25,                last time consumption/overall running time: 77.1679s / 118306.3916 s
env0_first_0:                 episode reward: -58.1500,                 loss: 44.6212
env0_second_0:                 episode reward: 58.1500,                 loss: 46.4892
env1_first_0:                 episode reward: -74.4000,                 loss: nan
env1_second_0:                 episode reward: 74.4000,                 loss: nan
Episode: 13261/30000 (44.2033%),                 avg. length: 1784.0,                last time consumption/overall running time: 302.5632s / 118608.9549 s
env0_first_0:                 episode reward: -0.9500,                 loss: 2.7175
env0_second_0:                 episode reward: 0.9500,                 loss: 3.8728
env1_first_0:                 episode reward: -2.3000,                 loss: nan
env1_second_0:                 episode reward: 2.3000,                 loss: nan
Episode: 13281/30000 (44.2700%),                 avg. length: 1784.0,                last time consumption/overall running time: 301.2511s / 118910.2059 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.6221
env0_second_0:                 episode reward: 1.2500,                 loss: 1.6810
env1_first_0:                 episode reward: -1.9500,                 loss: nan
env1_second_0:                 episode reward: 1.9500,                 loss: nan
Episode: 13301/30000 (44.3367%),                 avg. length: 1784.0,                last time consumption/overall running time: 301.6761s / 119211.8820 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.5607
env0_second_0:                 episode reward: 0.1500,                 loss: 2.5280
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 13321/30000 (44.4033%),                 avg. length: 1784.0,                last time consumption/overall running time: 295.7423s / 119507.6243 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.4670
env0_second_0:                 episode reward: 1.0000,                 loss: 2.6526
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 13341/30000 (44.4700%),                 avg. length: 1648.95,                last time consumption/overall running time: 269.3294s / 119776.9536 s
env0_first_0:                 episode reward: -10.4500,                 loss: 4.6716
env0_second_0:                 episode reward: 10.4500,                 loss: 7.7085
env1_first_0:                 episode reward: -12.9500,                 loss: nan
env1_second_0:                 episode reward: 12.9500,                 loss: nan
Episode: 13361/30000 (44.5367%),                 avg. length: 840.95,                last time consumption/overall running time: 143.8372s / 119920.7908 s
env0_first_0:                 episode reward: -54.1500,                 loss: 25.7737
env0_second_0:                 episode reward: 54.1500,                 loss: 29.4238
env1_first_0:                 episode reward: -53.6000,                 loss: nan
env1_second_0:                 episode reward: 53.6000,                 loss: nan
Episode: 13381/30000 (44.6033%),                 avg. length: 1784.0,                last time consumption/overall running time: 288.4830s / 120209.2739 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2053
env0_second_0:                 episode reward: 0.0000,                 loss: 3.1460
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 13401/30000 (44.6700%),                 avg. length: 1784.0,                last time consumption/overall running time: 289.0519s / 120498.3258 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0290
env0_second_0:                 episode reward: 0.0000,                 loss: 2.3955
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 13421/30000 (44.7367%),                 avg. length: 1784.0,                last time consumption/overall running time: 291.0244s / 120789.3502 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0132
env0_second_0:                 episode reward: 0.0000,                 loss: 2.1062
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 13441/30000 (44.8033%),                 avg. length: 1784.0,                last time consumption/overall running time: 291.6559s / 121081.0061 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0318
env0_second_0:                 episode reward: 0.0000,                 loss: 2.4029
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 13461/30000 (44.8700%),                 avg. length: 1784.0,                last time consumption/overall running time: 291.7579s / 121372.7641 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0341
env0_second_0:                 episode reward: 0.0000,                 loss: 2.3072
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 13481/30000 (44.9367%),                 avg. length: 1784.0,                last time consumption/overall running time: 285.0164s / 121657.7805 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0254
env0_second_0:                 episode reward: 0.0000,                 loss: 2.2064
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 13501/30000 (45.0033%),                 avg. length: 306.25,                last time consumption/overall running time: 58.5180s / 121716.2985 s
env0_first_0:                 episode reward: -90.0000,                 loss: 33.8369
env0_second_0:                 episode reward: 90.0000,                 loss: 31.4009
env1_first_0:                 episode reward: -89.4500,                 loss: nan
env1_second_0:                 episode reward: 89.4500,                 loss: nan
Episode: 13521/30000 (45.0700%),                 avg. length: 392.8,                last time consumption/overall running time: 73.7099s / 121790.0084 s
env0_first_0:                 episode reward: -61.0000,                 loss: 29.4233
env0_second_0:                 episode reward: 61.0000,                 loss: 31.0013
env1_first_0:                 episode reward: -68.2500,                 loss: nan
env1_second_0:                 episode reward: 68.2500,                 loss: nan
Episode: 13541/30000 (45.1367%),                 avg. length: 817.35,                last time consumption/overall running time: 140.6293s / 121930.6378 s
env0_first_0:                 episode reward: -17.2500,                 loss: 23.5744
env0_second_0:                 episode reward: 17.2500,                 loss: 27.2585
env1_first_0:                 episode reward: -22.2500,                 loss: nan
env1_second_0:                 episode reward: 22.2500,                 loss: nan
Episode: 13561/30000 (45.2033%),                 avg. length: 923.7,                last time consumption/overall running time: 156.0027s / 122086.6405 s
env0_first_0:                 episode reward: 24.1500,                 loss: 17.4260
env0_second_0:                 episode reward: -24.1500,                 loss: 20.6829
env1_first_0:                 episode reward: 15.6500,                 loss: nan
env1_second_0:                 episode reward: -15.6500,                 loss: nan
Episode: 13581/30000 (45.2700%),                 avg. length: 752.6,                last time consumption/overall running time: 128.9674s / 122215.6078 s
env0_first_0:                 episode reward: -63.7500,                 loss: 28.3259
env0_second_0:                 episode reward: 63.7500,                 loss: 31.0789
env1_first_0:                 episode reward: -39.5500,                 loss: nan
env1_second_0:                 episode reward: 39.5500,                 loss: nan
Episode: 13601/30000 (45.3367%),                 avg. length: 530.6,                last time consumption/overall running time: 97.0556s / 122312.6634 s
env0_first_0:                 episode reward: -60.9500,                 loss: 35.3728
env0_second_0:                 episode reward: 60.9500,                 loss: 37.4936
env1_first_0:                 episode reward: -49.2500,                 loss: nan
env1_second_0:                 episode reward: 49.2500,                 loss: nan
Episode: 13621/30000 (45.4033%),                 avg. length: 1261.7,                last time consumption/overall running time: 214.4788s / 122527.1422 s
env0_first_0:                 episode reward: -25.0500,                 loss: 12.3217
env0_second_0:                 episode reward: 25.0500,                 loss: 13.3447
env1_first_0:                 episode reward: -17.2000,                 loss: nan
env1_second_0:                 episode reward: 17.2000,                 loss: nan
Episode: 13641/30000 (45.4700%),                 avg. length: 426.55,                last time consumption/overall running time: 79.4559s / 122606.5982 s
env0_first_0:                 episode reward: -58.9000,                 loss: 40.5588
env0_second_0:                 episode reward: 58.9000,                 loss: 41.4315
env1_first_0:                 episode reward: -59.9500,                 loss: nan
env1_second_0:                 episode reward: 59.9500,                 loss: nan
Episode: 13661/30000 (45.5367%),                 avg. length: 382.45,                last time consumption/overall running time: 72.9546s / 122679.5527 s
env0_first_0:                 episode reward: -60.1500,                 loss: 46.7027
env0_second_0:                 episode reward: 60.1500,                 loss: 50.3780
env1_first_0:                 episode reward: -50.0000,                 loss: nan
env1_second_0:                 episode reward: 50.0000,                 loss: nan
Episode: 13681/30000 (45.6033%),                 avg. length: 1450.8,                last time consumption/overall running time: 239.3159s / 122918.8686 s
env0_first_0:                 episode reward: -9.4000,                 loss: 12.5152
env0_second_0:                 episode reward: 9.4000,                 loss: 14.3465
env1_first_0:                 episode reward: -17.1000,                 loss: nan
env1_second_0:                 episode reward: 17.1000,                 loss: nan
Episode: 13701/30000 (45.6700%),                 avg. length: 1147.4,                last time consumption/overall running time: 190.9928s / 123109.8614 s
env0_first_0:                 episode reward: 22.3000,                 loss: 12.3070
env0_second_0:                 episode reward: -22.3000,                 loss: 14.3483
env1_first_0:                 episode reward: 16.1000,                 loss: nan
env1_second_0:                 episode reward: -16.1000,                 loss: nan
Episode: 13721/30000 (45.7367%),                 avg. length: 659.25,                last time consumption/overall running time: 114.5616s / 123224.4230 s
env0_first_0:                 episode reward: -23.8500,                 loss: 39.4973
env0_second_0:                 episode reward: 23.8500,                 loss: 42.5161
env1_first_0:                 episode reward: -20.4500,                 loss: nan
env1_second_0:                 episode reward: 20.4500,                 loss: nan
Episode: 13741/30000 (45.8033%),                 avg. length: 845.85,                last time consumption/overall running time: 143.4544s / 123367.8774 s
env0_first_0:                 episode reward: -36.4000,                 loss: 38.0932
env0_second_0:                 episode reward: 36.4000,                 loss: 39.1989
env1_first_0:                 episode reward: -43.5000,                 loss: nan
env1_second_0:                 episode reward: 43.5000,                 loss: nan
Episode: 13761/30000 (45.8700%),                 avg. length: 1095.05,                last time consumption/overall running time: 182.4631s / 123550.3405 s
env0_first_0:                 episode reward: -45.6500,                 loss: 26.0759
env0_second_0:                 episode reward: 45.6500,                 loss: 27.9492
env1_first_0:                 episode reward: -23.0500,                 loss: nan
env1_second_0:                 episode reward: 23.0500,                 loss: nan
Episode: 13781/30000 (45.9367%),                 avg. length: 391.3,                last time consumption/overall running time: 73.7333s / 123624.0738 s
env0_first_0:                 episode reward: -48.2500,                 loss: 53.8305
env0_second_0:                 episode reward: 48.2500,                 loss: 56.0675
env1_first_0:                 episode reward: -71.0000,                 loss: nan
env1_second_0:                 episode reward: 71.0000,                 loss: nan
Episode: 13801/30000 (46.0033%),                 avg. length: 437.15,                last time consumption/overall running time: 82.1817s / 123706.2554 s
env0_first_0:                 episode reward: -51.0500,                 loss: 52.0715
env0_second_0:                 episode reward: 51.0500,                 loss: 52.3599
env1_first_0:                 episode reward: -64.1500,                 loss: nan
env1_second_0:                 episode reward: 64.1500,                 loss: nan
Episode: 13821/30000 (46.0700%),                 avg. length: 670.65,                last time consumption/overall running time: 119.1362s / 123825.3917 s
env0_first_0:                 episode reward: -28.8000,                 loss: 42.0861
env0_second_0:                 episode reward: 28.8000,                 loss: 45.2160
env1_first_0:                 episode reward: -39.2000,                 loss: nan
env1_second_0:                 episode reward: 39.2000,                 loss: nan
Episode: 13841/30000 (46.1367%),                 avg. length: 725.5,                last time consumption/overall running time: 128.8281s / 123954.2198 s
env0_first_0:                 episode reward: -31.9000,                 loss: 32.9926
env0_second_0:                 episode reward: 31.9000,                 loss: 34.7889
env1_first_0:                 episode reward: -31.4000,                 loss: nan
env1_second_0:                 episode reward: 31.4000,                 loss: nan
Episode: 13861/30000 (46.2033%),                 avg. length: 630.9,                last time consumption/overall running time: 112.5247s / 124066.7444 s
env0_first_0:                 episode reward: -48.2000,                 loss: 33.6302
env0_second_0:                 episode reward: 48.2000,                 loss: 33.5837
env1_first_0:                 episode reward: -43.3500,                 loss: nan
env1_second_0:                 episode reward: 43.3500,                 loss: nan
Episode: 13881/30000 (46.2700%),                 avg. length: 704.4,                last time consumption/overall running time: 127.8151s / 124194.5595 s
env0_first_0:                 episode reward: -7.0000,                 loss: 25.7133
env0_second_0:                 episode reward: 7.0000,                 loss: 28.3544
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 13901/30000 (46.3367%),                 avg. length: 772.95,                last time consumption/overall running time: 142.2635s / 124336.8230 s
env0_first_0:                 episode reward: -42.3000,                 loss: 19.1660
env0_second_0:                 episode reward: 42.3000,                 loss: 20.9009
env1_first_0:                 episode reward: -30.9000,                 loss: nan
env1_second_0:                 episode reward: 30.9000,                 loss: nan
Episode: 13921/30000 (46.4033%),                 avg. length: 1071.95,                last time consumption/overall running time: 182.4774s / 124519.3004 s
env0_first_0:                 episode reward: -26.0500,                 loss: 13.5292
env0_second_0:                 episode reward: 26.0500,                 loss: 16.1219
env1_first_0:                 episode reward: -7.8000,                 loss: nan
env1_second_0:                 episode reward: 7.8000,                 loss: nan
Episode: 13941/30000 (46.4700%),                 avg. length: 1034.2,                last time consumption/overall running time: 174.9931s / 124694.2935 s
env0_first_0:                 episode reward: 8.7000,                 loss: 13.9999
env0_second_0:                 episode reward: -8.7000,                 loss: 17.3329
env1_first_0:                 episode reward: -12.7000,                 loss: nan
env1_second_0:                 episode reward: 12.7000,                 loss: nan
Episode: 13961/30000 (46.5367%),                 avg. length: 1271.7,                last time consumption/overall running time: 213.9621s / 124908.2556 s
env0_first_0:                 episode reward: -14.8000,                 loss: 13.4294
env0_second_0:                 episode reward: 14.8000,                 loss: 16.6381
env1_first_0:                 episode reward: 4.9500,                 loss: nan
env1_second_0:                 episode reward: -4.9500,                 loss: nan
Episode: 13981/30000 (46.6033%),                 avg. length: 1441.45,                last time consumption/overall running time: 238.4607s / 125146.7163 s
env0_first_0:                 episode reward: -26.7000,                 loss: 7.5235
env0_second_0:                 episode reward: 26.7000,                 loss: 10.8862
env1_first_0:                 episode reward: -25.7000,                 loss: nan
env1_second_0:                 episode reward: 25.7000,                 loss: nan
Episode: 14001/30000 (46.6700%),                 avg. length: 1548.3,                last time consumption/overall running time: 251.4616s / 125398.1779 s
env0_first_0:                 episode reward: -18.3000,                 loss: 4.8727
env0_second_0:                 episode reward: 18.3000,                 loss: 7.3095
env1_first_0:                 episode reward: -17.1000,                 loss: nan
env1_second_0:                 episode reward: 17.1000,                 loss: nan
Episode: 14021/30000 (46.7367%),                 avg. length: 1784.0,                last time consumption/overall running time: 288.9332s / 125687.1111 s
env0_first_0:                 episode reward: 5.9000,                 loss: 0.2991
env0_second_0:                 episode reward: -5.9000,                 loss: 2.0477
env1_first_0:                 episode reward: 6.4000,                 loss: nan
env1_second_0:                 episode reward: -6.4000,                 loss: nan
Episode: 14041/30000 (46.8033%),                 avg. length: 1778.7,                last time consumption/overall running time: 278.8458s / 125965.9570 s
env0_first_0:                 episode reward: 22.6500,                 loss: 1.4609
env0_second_0:                 episode reward: -22.6500,                 loss: 3.3926
env1_first_0:                 episode reward: 21.6000,                 loss: nan
env1_second_0:                 episode reward: -21.6000,                 loss: nan
Episode: 14061/30000 (46.8700%),                 avg. length: 1784.0,                last time consumption/overall running time: 274.7686s / 126240.7256 s
env0_first_0:                 episode reward: 15.6000,                 loss: 1.3569
env0_second_0:                 episode reward: -15.6000,                 loss: 3.2044
env1_first_0:                 episode reward: 16.3000,                 loss: nan
env1_second_0:                 episode reward: -16.3000,                 loss: nan
Episode: 14081/30000 (46.9367%),                 avg. length: 1784.0,                last time consumption/overall running time: 272.7308s / 126513.4564 s
env0_first_0:                 episode reward: 9.5000,                 loss: 0.8644
env0_second_0:                 episode reward: -9.5000,                 loss: 4.5502
env1_first_0:                 episode reward: 10.1000,                 loss: nan
env1_second_0:                 episode reward: -10.1000,                 loss: nan
Episode: 14101/30000 (47.0033%),                 avg. length: 1784.0,                last time consumption/overall running time: 271.5948s / 126785.0513 s
env0_first_0:                 episode reward: 12.3500,                 loss: 0.6085
env0_second_0:                 episode reward: -12.3500,                 loss: 2.6631
env1_first_0:                 episode reward: 11.3000,                 loss: nan
env1_second_0:                 episode reward: -11.3000,                 loss: nan
Episode: 14121/30000 (47.0700%),                 avg. length: 1784.0,                last time consumption/overall running time: 272.3224s / 127057.3737 s
env0_first_0:                 episode reward: 4.7500,                 loss: 0.3101
env0_second_0:                 episode reward: -4.7500,                 loss: 1.6353
env1_first_0:                 episode reward: 6.5500,                 loss: nan
env1_second_0:                 episode reward: -6.5500,                 loss: nan
Episode: 14141/30000 (47.1367%),                 avg. length: 1784.0,                last time consumption/overall running time: 266.4065s / 127323.7802 s
env0_first_0:                 episode reward: 4.5000,                 loss: 0.4095
env0_second_0:                 episode reward: -4.5000,                 loss: 1.5690
env1_first_0:                 episode reward: 7.5000,                 loss: nan
env1_second_0:                 episode reward: -7.5000,                 loss: nan
Episode: 14161/30000 (47.2033%),                 avg. length: 1784.0,                last time consumption/overall running time: 260.0915s / 127583.8716 s
env0_first_0:                 episode reward: 7.2000,                 loss: 0.4635
env0_second_0:                 episode reward: -7.2000,                 loss: 1.4793
env1_first_0:                 episode reward: 4.2500,                 loss: nan
env1_second_0:                 episode reward: -4.2500,                 loss: nan
Episode: 14181/30000 (47.2700%),                 avg. length: 1784.0,                last time consumption/overall running time: 260.4055s / 127844.2772 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.0807
env0_second_0:                 episode reward: -1.1500,                 loss: 1.1223
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 14201/30000 (47.3367%),                 avg. length: 1784.0,                last time consumption/overall running time: 264.1008s / 128108.3780 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0057
env0_second_0:                 episode reward: -0.5500,                 loss: 0.7403
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 14221/30000 (47.4033%),                 avg. length: 1784.0,                last time consumption/overall running time: 260.1121s / 128368.4902 s
env0_first_0:                 episode reward: 1.5000,                 loss: 0.0127
env0_second_0:                 episode reward: -1.5000,                 loss: 0.6464
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 14241/30000 (47.4700%),                 avg. length: 1784.0,                last time consumption/overall running time: 260.3702s / 128628.8604 s
env0_first_0:                 episode reward: 7.2000,                 loss: 0.2460
env0_second_0:                 episode reward: -7.2000,                 loss: 1.4219
env1_first_0:                 episode reward: 8.2000,                 loss: nan
env1_second_0:                 episode reward: -8.2000,                 loss: nan
Episode: 14261/30000 (47.5367%),                 avg. length: 1784.0,                last time consumption/overall running time: 256.9158s / 128885.7761 s
env0_first_0:                 episode reward: 1.5000,                 loss: 0.0226
env0_second_0:                 episode reward: -1.5000,                 loss: 0.7988
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 14281/30000 (47.6033%),                 avg. length: 1784.0,                last time consumption/overall running time: 256.6132s / 129142.3893 s
env0_first_0:                 episode reward: 1.5000,                 loss: 0.0061
env0_second_0:                 episode reward: -1.5000,                 loss: 1.2768
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 14301/30000 (47.6700%),                 avg. length: 1784.0,                last time consumption/overall running time: 247.2142s / 129389.6035 s
env0_first_0:                 episode reward: 1.9500,                 loss: -0.0307
env0_second_0:                 episode reward: -1.9500,                 loss: 0.7713
env1_first_0:                 episode reward: 1.7500,                 loss: nan
env1_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 14321/30000 (47.7367%),                 avg. length: 1784.0,                last time consumption/overall running time: 226.9071s / 129616.5106 s
env0_first_0:                 episode reward: 1.9000,                 loss: -0.0399
env0_second_0:                 episode reward: -1.9000,                 loss: 0.6982
env1_first_0:                 episode reward: 2.0000,                 loss: nan
env1_second_0:                 episode reward: -2.0000,                 loss: nan
Episode: 14341/30000 (47.8033%),                 avg. length: 1784.0,                last time consumption/overall running time: 245.8896s / 129862.4003 s
env0_first_0:                 episode reward: 1.0500,                 loss: -0.0156
env0_second_0:                 episode reward: -1.0500,                 loss: 1.1000
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 14361/30000 (47.8700%),                 avg. length: 1734.0,                last time consumption/overall running time: 232.3254s / 130094.7257 s
env0_first_0:                 episode reward: -4.1500,                 loss: 1.0351
env0_second_0:                 episode reward: 4.1500,                 loss: 1.4818
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 14381/30000 (47.9367%),                 avg. length: 663.95,                last time consumption/overall running time: 89.5445s / 130184.2702 s
env0_first_0:                 episode reward: -49.7500,                 loss: 47.1129
env0_second_0:                 episode reward: 49.7500,                 loss: 45.3610
env1_first_0:                 episode reward: -67.3500,                 loss: nan
env1_second_0:                 episode reward: 67.3500,                 loss: nan
Episode: 14401/30000 (48.0033%),                 avg. length: 291.9,                last time consumption/overall running time: 50.1340s / 130234.4042 s
env0_first_0:                 episode reward: -80.9000,                 loss: 42.4494
env0_second_0:                 episode reward: 80.9000,                 loss: 37.7415
env1_first_0:                 episode reward: -72.8500,                 loss: nan
env1_second_0:                 episode reward: 72.8500,                 loss: nan
Episode: 14421/30000 (48.0700%),                 avg. length: 446.45,                last time consumption/overall running time: 64.8293s / 130299.2336 s
env0_first_0:                 episode reward: -74.6000,                 loss: 35.6900
env0_second_0:                 episode reward: 74.6000,                 loss: 34.8291
env1_first_0:                 episode reward: -62.3000,                 loss: nan
env1_second_0:                 episode reward: 62.3000,                 loss: nan
Episode: 14441/30000 (48.1367%),                 avg. length: 274.35,                last time consumption/overall running time: 46.3617s / 130345.5953 s
env0_first_0:                 episode reward: -84.7000,                 loss: 31.1012
env0_second_0:                 episode reward: 84.7000,                 loss: 29.3780
env1_first_0:                 episode reward: -91.1000,                 loss: nan
env1_second_0:                 episode reward: 91.1000,                 loss: nan
Episode: 14461/30000 (48.2033%),                 avg. length: 555.95,                last time consumption/overall running time: 81.9888s / 130427.5841 s
env0_first_0:                 episode reward: -75.1500,                 loss: 21.9927
env0_second_0:                 episode reward: 75.1500,                 loss: 24.1420
env1_first_0:                 episode reward: -73.7500,                 loss: nan
env1_second_0:                 episode reward: 73.7500,                 loss: nan
Episode: 14481/30000 (48.2700%),                 avg. length: 289.85,                last time consumption/overall running time: 45.6491s / 130473.2332 s
env0_first_0:                 episode reward: -81.5500,                 loss: 31.4926
env0_second_0:                 episode reward: 81.5500,                 loss: 32.9239
env1_first_0:                 episode reward: -72.4500,                 loss: nan
env1_second_0:                 episode reward: 72.4500,                 loss: nan
Episode: 14501/30000 (48.3367%),                 avg. length: 395.65,                last time consumption/overall running time: 58.0892s / 130531.3224 s
env0_first_0:                 episode reward: -76.1000,                 loss: 28.3828
env0_second_0:                 episode reward: 76.1000,                 loss: 26.0877
env1_first_0:                 episode reward: -77.4000,                 loss: nan
env1_second_0:                 episode reward: 77.4000,                 loss: nan
Episode: 14521/30000 (48.4033%),                 avg. length: 1552.05,                last time consumption/overall running time: 199.7899s / 130731.1123 s
env0_first_0:                 episode reward: -9.7500,                 loss: 7.9913
env0_second_0:                 episode reward: 9.7500,                 loss: 9.5630
env1_first_0:                 episode reward: -13.0000,                 loss: nan
env1_second_0:                 episode reward: 13.0000,                 loss: nan
Episode: 14541/30000 (48.4700%),                 avg. length: 744.05,                last time consumption/overall running time: 104.1825s / 130835.2948 s
env0_first_0:                 episode reward: -56.9500,                 loss: 29.2462
env0_second_0:                 episode reward: 56.9500,                 loss: 30.0294
env1_first_0:                 episode reward: -51.5000,                 loss: nan
env1_second_0:                 episode reward: 51.5000,                 loss: nan
Episode: 14561/30000 (48.5367%),                 avg. length: 718.1,                last time consumption/overall running time: 96.5006s / 130931.7954 s
env0_first_0:                 episode reward: -57.7000,                 loss: 29.8492
env0_second_0:                 episode reward: 57.7000,                 loss: 27.4818
env1_first_0:                 episode reward: -60.4000,                 loss: nan
env1_second_0:                 episode reward: 60.4000,                 loss: nan
Episode: 14581/30000 (48.6033%),                 avg. length: 251.65,                last time consumption/overall running time: 39.8256s / 130971.6210 s
env0_first_0:                 episode reward: -76.9000,                 loss: 32.5775
env0_second_0:                 episode reward: 76.9000,                 loss: 32.7531
env1_first_0:                 episode reward: -85.8000,                 loss: nan
env1_second_0:                 episode reward: 85.8000,                 loss: nan
Episode: 14601/30000 (48.6700%),                 avg. length: 228.3,                last time consumption/overall running time: 36.4227s / 131008.0437 s
env0_first_0:                 episode reward: -80.7000,                 loss: 20.6759
env0_second_0:                 episode reward: 80.7000,                 loss: 19.8335
env1_first_0:                 episode reward: -97.7500,                 loss: nan
env1_second_0:                 episode reward: 97.7500,                 loss: nan
Episode: 14621/30000 (48.7367%),                 avg. length: 849.6,                last time consumption/overall running time: 118.4187s / 131126.4624 s
env0_first_0:                 episode reward: -42.7000,                 loss: 16.0232
env0_second_0:                 episode reward: 42.7000,                 loss: 16.4303
env1_first_0:                 episode reward: -55.9000,                 loss: nan
env1_second_0:                 episode reward: 55.9000,                 loss: nan
Episode: 14641/30000 (48.8033%),                 avg. length: 565.4,                last time consumption/overall running time: 89.2998s / 131215.7622 s
env0_first_0:                 episode reward: -71.5000,                 loss: 22.5142
env0_second_0:                 episode reward: 71.5000,                 loss: 27.1320
env1_first_0:                 episode reward: -76.9500,                 loss: nan
env1_second_0:                 episode reward: 76.9500,                 loss: nan
Episode: 14661/30000 (48.8700%),                 avg. length: 320.5,                last time consumption/overall running time: 49.6910s / 131265.4532 s
env0_first_0:                 episode reward: -90.7500,                 loss: 18.1481
env0_second_0:                 episode reward: 90.7500,                 loss: 20.3946
env1_first_0:                 episode reward: -95.9000,                 loss: nan
env1_second_0:                 episode reward: 95.9000,                 loss: nan
Episode: 14681/30000 (48.9367%),                 avg. length: 220.35,                last time consumption/overall running time: 39.0225s / 131304.4757 s
env0_first_0:                 episode reward: -96.1500,                 loss: 19.0357
env0_second_0:                 episode reward: 96.1500,                 loss: 18.8116
env1_first_0:                 episode reward: -97.7000,                 loss: nan
env1_second_0:                 episode reward: 97.7000,                 loss: nan
Episode: 14701/30000 (49.0033%),                 avg. length: 628.9,                last time consumption/overall running time: 89.2126s / 131393.6883 s
env0_first_0:                 episode reward: -67.7000,                 loss: 24.6213
env0_second_0:                 episode reward: 67.7000,                 loss: 25.1652
env1_first_0:                 episode reward: -50.0000,                 loss: nan
env1_second_0:                 episode reward: 50.0000,                 loss: nan
Episode: 14721/30000 (49.0700%),                 avg. length: 219.0,                last time consumption/overall running time: 40.3404s / 131434.0287 s
env0_first_0:                 episode reward: -93.5000,                 loss: 22.6874
env0_second_0:                 episode reward: 93.5000,                 loss: 20.0212
env1_first_0:                 episode reward: -91.2500,                 loss: nan
env1_second_0:                 episode reward: 91.2500,                 loss: nan
Episode: 14741/30000 (49.1367%),                 avg. length: 479.5,                last time consumption/overall running time: 76.8834s / 131510.9120 s
env0_first_0:                 episode reward: -52.1500,                 loss: 20.9683
env0_second_0:                 episode reward: 52.1500,                 loss: 20.1981
env1_first_0:                 episode reward: -74.0500,                 loss: nan
env1_second_0:                 episode reward: 74.0500,                 loss: nan
Episode: 14761/30000 (49.2033%),                 avg. length: 296.85,                last time consumption/overall running time: 48.4979s / 131559.4099 s
env0_first_0:                 episode reward: -72.7500,                 loss: 22.5116
env0_second_0:                 episode reward: 72.7500,                 loss: 21.3313
env1_first_0:                 episode reward: -83.8000,                 loss: nan
env1_second_0:                 episode reward: 83.8000,                 loss: nan
Episode: 14781/30000 (49.2700%),                 avg. length: 219.95,                last time consumption/overall running time: 39.2252s / 131598.6352 s
env0_first_0:                 episode reward: -98.3000,                 loss: 18.6072
env0_second_0:                 episode reward: 98.3000,                 loss: 20.4752
env1_first_0:                 episode reward: -82.6500,                 loss: nan
env1_second_0:                 episode reward: 82.6500,                 loss: nan
Episode: 14801/30000 (49.3367%),                 avg. length: 221.35,                last time consumption/overall running time: 39.6431s / 131638.2783 s
env0_first_0:                 episode reward: -91.0500,                 loss: 22.2092
env0_second_0:                 episode reward: 91.0500,                 loss: 19.2990
env1_first_0:                 episode reward: -86.2000,                 loss: nan
env1_second_0:                 episode reward: 86.2000,                 loss: nan
Episode: 14821/30000 (49.4033%),                 avg. length: 296.25,                last time consumption/overall running time: 48.2267s / 131686.5050 s
env0_first_0:                 episode reward: -86.6000,                 loss: 24.9161
env0_second_0:                 episode reward: 86.6000,                 loss: 25.4243
env1_first_0:                 episode reward: -73.8000,                 loss: nan
env1_second_0:                 episode reward: 73.8000,                 loss: nan
Episode: 14841/30000 (49.4700%),                 avg. length: 213.65,                last time consumption/overall running time: 37.3309s / 131723.8359 s
env0_first_0:                 episode reward: -80.5500,                 loss: 27.7745
env0_second_0:                 episode reward: 80.5500,                 loss: 25.2829
env1_first_0:                 episode reward: -91.4000,                 loss: nan
env1_second_0:                 episode reward: 91.4000,                 loss: nan
Episode: 14861/30000 (49.5367%),                 avg. length: 417.3,                last time consumption/overall running time: 62.5082s / 131786.3441 s
env0_first_0:                 episode reward: -75.7000,                 loss: 33.7803
env0_second_0:                 episode reward: 75.7000,                 loss: 37.3735
env1_first_0:                 episode reward: -83.6500,                 loss: nan
env1_second_0:                 episode reward: 83.6500,                 loss: nan
Episode: 14881/30000 (49.6033%),                 avg. length: 1784.0,                last time consumption/overall running time: 236.9367s / 132023.2808 s
env0_first_0:                 episode reward: -0.1500,                 loss: 3.0741
env0_second_0:                 episode reward: 0.1500,                 loss: 5.0334
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 14901/30000 (49.6700%),                 avg. length: 1784.0,                last time consumption/overall running time: 231.8582s / 132255.1390 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.6703
env0_second_0:                 episode reward: 1.1500,                 loss: 1.5907
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 14921/30000 (49.7367%),                 avg. length: 1784.0,                last time consumption/overall running time: 232.2425s / 132487.3816 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0928
env0_second_0:                 episode reward: 0.3000,                 loss: 0.4330
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 14941/30000 (49.8033%),                 avg. length: 1784.0,                last time consumption/overall running time: 232.5305s / 132719.9121 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0156
env0_second_0:                 episode reward: 0.0000,                 loss: 0.3302
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 14961/30000 (49.8700%),                 avg. length: 1784.0,                last time consumption/overall running time: 228.4123s / 132948.3245 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0097
env0_second_0:                 episode reward: 0.0000,                 loss: 1.0502
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 14981/30000 (49.9367%),                 avg. length: 1784.0,                last time consumption/overall running time: 239.5065s / 133187.8310 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0046
env0_second_0:                 episode reward: 0.0000,                 loss: 0.4484
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 15001/30000 (50.0033%),                 avg. length: 1784.0,                last time consumption/overall running time: 234.3518s / 133422.1828 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0397
env0_second_0:                 episode reward: 0.4500,                 loss: 0.5089
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 15021/30000 (50.0700%),                 avg. length: 1784.0,                last time consumption/overall running time: 231.6464s / 133653.8292 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0153
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2324
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 15041/30000 (50.1367%),                 avg. length: 1784.0,                last time consumption/overall running time: 230.1039s / 133883.9331 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.1462
env0_second_0:                 episode reward: 1.1500,                 loss: 0.6880
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 15061/30000 (50.2033%),                 avg. length: 1784.0,                last time consumption/overall running time: 232.1546s / 134116.0877 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.0584
env0_second_0:                 episode reward: 1.2500,                 loss: 0.5331
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 15081/30000 (50.2700%),                 avg. length: 1784.0,                last time consumption/overall running time: 231.7825s / 134347.8703 s
env0_first_0:                 episode reward: -2.6000,                 loss: 0.1694
env0_second_0:                 episode reward: 2.6000,                 loss: 0.7729
env1_first_0:                 episode reward: -1.9500,                 loss: nan
env1_second_0:                 episode reward: 1.9500,                 loss: nan
Episode: 15101/30000 (50.3367%),                 avg. length: 1784.0,                last time consumption/overall running time: 235.0654s / 134582.9356 s
env0_first_0:                 episode reward: -1.6500,                 loss: 0.1268
env0_second_0:                 episode reward: 1.6500,                 loss: 1.0749
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 15121/30000 (50.4033%),                 avg. length: 1784.0,                last time consumption/overall running time: 240.2002s / 134823.1358 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.0269
env0_second_0:                 episode reward: 1.1000,                 loss: 0.6314
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 15141/30000 (50.4700%),                 avg. length: 1784.0,                last time consumption/overall running time: 240.9361s / 135064.0719 s
env0_first_0:                 episode reward: -0.6500,                 loss: -0.0119
env0_second_0:                 episode reward: 0.6500,                 loss: 0.9257
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 15161/30000 (50.5367%),                 avg. length: 1784.0,                last time consumption/overall running time: 230.3367s / 135294.4086 s
env0_first_0:                 episode reward: -0.7000,                 loss: -0.0551
env0_second_0:                 episode reward: 0.7000,                 loss: 0.4616
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 15181/30000 (50.6033%),                 avg. length: 1784.0,                last time consumption/overall running time: 241.8685s / 135536.2771 s
env0_first_0:                 episode reward: -2.9000,                 loss: 0.0543
env0_second_0:                 episode reward: 2.9000,                 loss: 0.7650
env1_first_0:                 episode reward: -1.8000,                 loss: nan
env1_second_0:                 episode reward: 1.8000,                 loss: nan
Episode: 15201/30000 (50.6700%),                 avg. length: 1784.0,                last time consumption/overall running time: 224.0313s / 135760.3084 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.0508
env0_second_0:                 episode reward: 0.1500,                 loss: 1.3903
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 15221/30000 (50.7367%),                 avg. length: 1784.0,                last time consumption/overall running time: 227.4908s / 135987.7992 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0703
env0_second_0:                 episode reward: 0.0000,                 loss: 1.3689
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 15241/30000 (50.8033%),                 avg. length: 1784.0,                last time consumption/overall running time: 231.9379s / 136219.7371 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0742
env0_second_0:                 episode reward: 0.0000,                 loss: 1.0304
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 15261/30000 (50.8700%),                 avg. length: 1784.0,                last time consumption/overall running time: 236.2425s / 136455.9796 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0761
env0_second_0:                 episode reward: 0.0000,                 loss: 2.2037
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 15281/30000 (50.9367%),                 avg. length: 1784.0,                last time consumption/overall running time: 233.1834s / 136689.1630 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.0794
env0_second_0:                 episode reward: 0.1000,                 loss: 0.4385
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 15301/30000 (51.0033%),                 avg. length: 1784.0,                last time consumption/overall running time: 228.8359s / 136917.9990 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0731
env0_second_0:                 episode reward: 0.0000,                 loss: 1.3173
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 15321/30000 (51.0700%),                 avg. length: 1784.0,                last time consumption/overall running time: 238.6978s / 137156.6968 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0879
env0_second_0:                 episode reward: 0.0000,                 loss: 0.4160
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 15341/30000 (51.1367%),                 avg. length: 1784.0,                last time consumption/overall running time: 238.0605s / 137394.7572 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0962
env0_second_0:                 episode reward: 0.0000,                 loss: 0.3511
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 15361/30000 (51.2033%),                 avg. length: 1784.0,                last time consumption/overall running time: 247.9625s / 137642.7198 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0834
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2639
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 15381/30000 (51.2700%),                 avg. length: 1784.0,                last time consumption/overall running time: 228.2361s / 137870.9559 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0723
env0_second_0:                 episode reward: 0.0000,                 loss: 0.4770
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 15401/30000 (51.3367%),                 avg. length: 1784.0,                last time consumption/overall running time: 240.6015s / 138111.5574 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0802
env0_second_0:                 episode reward: 0.0000,                 loss: 0.5976
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 15421/30000 (51.4033%),                 avg. length: 1784.0,                last time consumption/overall running time: 238.3109s / 138349.8682 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.0792
env0_second_0:                 episode reward: -0.1000,                 loss: 0.3900
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 15441/30000 (51.4700%),                 avg. length: 1784.0,                last time consumption/overall running time: 225.9693s / 138575.8375 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0869
env0_second_0:                 episode reward: 0.0000,                 loss: 0.4635
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 15461/30000 (51.5367%),                 avg. length: 1784.0,                last time consumption/overall running time: 232.9419s / 138808.7794 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.0632
env0_second_0:                 episode reward: 0.1500,                 loss: 0.3907
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 15481/30000 (51.6033%),                 avg. length: 1784.0,                last time consumption/overall running time: 236.7266s / 139045.5060 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.0920
env0_second_0:                 episode reward: -0.0500,                 loss: 1.0936
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 15501/30000 (51.6700%),                 avg. length: 1784.0,                last time consumption/overall running time: 237.1862s / 139282.6922 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.1055
env0_second_0:                 episode reward: 0.0000,                 loss: 0.7381
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 15521/30000 (51.7367%),                 avg. length: 1784.0,                last time consumption/overall running time: 242.0569s / 139524.7490 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.0858
env0_second_0:                 episode reward: 0.1500,                 loss: 0.8401
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 15541/30000 (51.8033%),                 avg. length: 1784.0,                last time consumption/overall running time: 250.4892s / 139775.2382 s
env0_first_0:                 episode reward: -0.4500,                 loss: -0.0728
env0_second_0:                 episode reward: 0.4500,                 loss: 1.0197
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 15561/30000 (51.8700%),                 avg. length: 1784.0,                last time consumption/overall running time: 241.3866s / 140016.6249 s
env0_first_0:                 episode reward: -0.4000,                 loss: -0.0604
env0_second_0:                 episode reward: 0.4000,                 loss: 1.0033
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 15581/30000 (51.9367%),                 avg. length: 1613.55,                last time consumption/overall running time: 220.3966s / 140237.0214 s
env0_first_0:                 episode reward: -15.0500,                 loss: 2.2770
env0_second_0:                 episode reward: 15.0500,                 loss: 4.0785
env1_first_0:                 episode reward: -15.8000,                 loss: nan
env1_second_0:                 episode reward: 15.8000,                 loss: nan
Episode: 15601/30000 (52.0033%),                 avg. length: 521.65,                last time consumption/overall running time: 88.7394s / 140325.7608 s
env0_first_0:                 episode reward: -76.7500,                 loss: 15.4840
env0_second_0:                 episode reward: 76.7500,                 loss: 15.7599
env1_first_0:                 episode reward: -71.2000,                 loss: nan
env1_second_0:                 episode reward: 71.2000,                 loss: nan
Episode: 15621/30000 (52.0700%),                 avg. length: 626.4,                last time consumption/overall running time: 89.4147s / 140415.1755 s
env0_first_0:                 episode reward: -69.2500,                 loss: 14.1881
env0_second_0:                 episode reward: 69.2500,                 loss: 17.6074
env1_first_0:                 episode reward: -69.1500,                 loss: nan
env1_second_0:                 episode reward: 69.1500,                 loss: nan
Episode: 15641/30000 (52.1367%),                 avg. length: 345.2,                last time consumption/overall running time: 59.5319s / 140474.7074 s
env0_first_0:                 episode reward: -55.8500,                 loss: 37.7389
env0_second_0:                 episode reward: 55.8500,                 loss: 41.7932
env1_first_0:                 episode reward: -80.1500,                 loss: nan
env1_second_0:                 episode reward: 80.1500,                 loss: nan
Episode: 15661/30000 (52.2033%),                 avg. length: 360.05,                last time consumption/overall running time: 59.2757s / 140533.9830 s
env0_first_0:                 episode reward: -55.2000,                 loss: 36.5740
env0_second_0:                 episode reward: 55.2000,                 loss: 40.5856
env1_first_0:                 episode reward: -77.5500,                 loss: nan
env1_second_0:                 episode reward: 77.5500,                 loss: nan
Episode: 15681/30000 (52.2700%),                 avg. length: 433.1,                last time consumption/overall running time: 64.4643s / 140598.4473 s
env0_first_0:                 episode reward: -68.6000,                 loss: 26.9672
env0_second_0:                 episode reward: 68.6000,                 loss: 34.4580
env1_first_0:                 episode reward: -67.5000,                 loss: nan
env1_second_0:                 episode reward: 67.5000,                 loss: nan
Episode: 15701/30000 (52.3367%),                 avg. length: 363.35,                last time consumption/overall running time: 55.7096s / 140654.1569 s
env0_first_0:                 episode reward: -70.5500,                 loss: 36.7697
env0_second_0:                 episode reward: 70.5500,                 loss: 45.1023
env1_first_0:                 episode reward: -70.8500,                 loss: nan
env1_second_0:                 episode reward: 70.8500,                 loss: nan
Episode: 15721/30000 (52.4033%),                 avg. length: 386.55,                last time consumption/overall running time: 59.4022s / 140713.5591 s
env0_first_0:                 episode reward: -70.6000,                 loss: 32.8454
env0_second_0:                 episode reward: 70.6000,                 loss: 34.4637
env1_first_0:                 episode reward: -78.3000,                 loss: nan
env1_second_0:                 episode reward: 78.3000,                 loss: nan
Episode: 15741/30000 (52.4700%),                 avg. length: 392.1,                last time consumption/overall running time: 62.6822s / 140776.2413 s
env0_first_0:                 episode reward: -68.8000,                 loss: 27.0343
env0_second_0:                 episode reward: 68.8000,                 loss: 49.6976
env1_first_0:                 episode reward: -79.1500,                 loss: nan
env1_second_0:                 episode reward: 79.1500,                 loss: nan
Episode: 15761/30000 (52.5367%),                 avg. length: 551.95,                last time consumption/overall running time: 81.9562s / 140858.1975 s
env0_first_0:                 episode reward: -70.2500,                 loss: 22.1075
env0_second_0:                 episode reward: 70.2500,                 loss: 26.6464
env1_first_0:                 episode reward: -69.6500,                 loss: nan
env1_second_0:                 episode reward: 69.6500,                 loss: nan
Episode: 15781/30000 (52.6033%),                 avg. length: 442.25,                last time consumption/overall running time: 69.9784s / 140928.1758 s
env0_first_0:                 episode reward: -82.6500,                 loss: 24.4295
env0_second_0:                 episode reward: 82.6500,                 loss: 30.5342
env1_first_0:                 episode reward: -69.9000,                 loss: nan
env1_second_0:                 episode reward: 69.9000,                 loss: nan
Episode: 15801/30000 (52.6700%),                 avg. length: 361.2,                last time consumption/overall running time: 63.3882s / 140991.5640 s
env0_first_0:                 episode reward: -77.5000,                 loss: 36.3735
env0_second_0:                 episode reward: 77.5000,                 loss: 40.4696
env1_first_0:                 episode reward: -75.3000,                 loss: nan
env1_second_0:                 episode reward: 75.3000,                 loss: nan
Episode: 15821/30000 (52.7367%),                 avg. length: 286.4,                last time consumption/overall running time: 48.4652s / 141040.0292 s
env0_first_0:                 episode reward: -84.8000,                 loss: 25.4754
env0_second_0:                 episode reward: 84.8000,                 loss: 26.8250
env1_first_0:                 episode reward: -83.2000,                 loss: nan
env1_second_0:                 episode reward: 83.2000,                 loss: nan
Episode: 15841/30000 (52.8033%),                 avg. length: 562.9,                last time consumption/overall running time: 89.0223s / 141129.0514 s
env0_first_0:                 episode reward: -71.6000,                 loss: 22.2841
env0_second_0:                 episode reward: 71.6000,                 loss: 24.1554
env1_first_0:                 episode reward: -68.8500,                 loss: nan
env1_second_0:                 episode reward: 68.8500,                 loss: nan
Episode: 15861/30000 (52.8700%),                 avg. length: 1784.0,                last time consumption/overall running time: 238.1227s / 141367.1742 s
env0_first_0:                 episode reward: -4.8500,                 loss: 1.9661
env0_second_0:                 episode reward: 4.8500,                 loss: 4.2726
env1_first_0:                 episode reward: -7.7500,                 loss: nan
env1_second_0:                 episode reward: 7.7500,                 loss: nan
Episode: 15881/30000 (52.9367%),                 avg. length: 604.75,                last time consumption/overall running time: 88.9262s / 141456.1004 s
env0_first_0:                 episode reward: -74.6000,                 loss: 30.0190
env0_second_0:                 episode reward: 74.6000,                 loss: 36.2259
env1_first_0:                 episode reward: -62.1000,                 loss: nan
env1_second_0:                 episode reward: 62.1000,                 loss: nan
Episode: 15901/30000 (53.0033%),                 avg. length: 1784.0,                last time consumption/overall running time: 234.1623s / 141690.2626 s
env0_first_0:                 episode reward: -8.5500,                 loss: 3.3639
env0_second_0:                 episode reward: 8.5500,                 loss: 5.9369
env1_first_0:                 episode reward: -4.8500,                 loss: nan
env1_second_0:                 episode reward: 4.8500,                 loss: nan
Episode: 15921/30000 (53.0700%),                 avg. length: 1784.0,                last time consumption/overall running time: 252.1988s / 141942.4614 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.4660
env0_second_0:                 episode reward: 3.7000,                 loss: 4.4477
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 15941/30000 (53.1367%),                 avg. length: 1784.0,                last time consumption/overall running time: 237.1935s / 142179.6549 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.2238
env0_second_0:                 episode reward: 0.6000,                 loss: 2.6943
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 15961/30000 (53.2033%),                 avg. length: 1784.0,                last time consumption/overall running time: 238.5813s / 142418.2363 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.1389
env0_second_0:                 episode reward: 0.0000,                 loss: 3.3635
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 15981/30000 (53.2700%),                 avg. length: 1784.0,                last time consumption/overall running time: 239.7993s / 142658.0355 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0018
env0_second_0:                 episode reward: 0.0000,                 loss: 2.1830
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 16001/30000 (53.3367%),                 avg. length: 1784.0,                last time consumption/overall running time: 246.9117s / 142904.9472 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0322
env0_second_0:                 episode reward: 0.0000,                 loss: 1.9348
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 16021/30000 (53.4033%),                 avg. length: 1784.0,                last time consumption/overall running time: 241.4246s / 143146.3718 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0400
env0_second_0:                 episode reward: 0.0000,                 loss: 1.9716
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 16041/30000 (53.4700%),                 avg. length: 1784.0,                last time consumption/overall running time: 249.7457s / 143396.1175 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0108
env0_second_0:                 episode reward: 0.0000,                 loss: 1.7379
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 16061/30000 (53.5367%),                 avg. length: 1784.0,                last time consumption/overall running time: 248.9143s / 143645.0318 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0143
env0_second_0:                 episode reward: -0.2000,                 loss: 1.0585
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 16081/30000 (53.6033%),                 avg. length: 1784.0,                last time consumption/overall running time: 247.6227s / 143892.6546 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0598
env0_second_0:                 episode reward: 0.5000,                 loss: 1.1190
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 16101/30000 (53.6700%),                 avg. length: 1784.0,                last time consumption/overall running time: 242.8111s / 144135.4656 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0734
env0_second_0:                 episode reward: -0.8000,                 loss: 2.4336
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 16121/30000 (53.7367%),                 avg. length: 720.05,                last time consumption/overall running time: 101.4764s / 144236.9420 s
env0_first_0:                 episode reward: -66.5000,                 loss: 16.3209
env0_second_0:                 episode reward: 66.5000,                 loss: 18.0066
env1_first_0:                 episode reward: -56.5500,                 loss: nan
env1_second_0:                 episode reward: 56.5500,                 loss: nan
Episode: 16141/30000 (53.8033%),                 avg. length: 527.4,                last time consumption/overall running time: 77.5565s / 144314.4985 s
env0_first_0:                 episode reward: -56.0500,                 loss: 21.1339
env0_second_0:                 episode reward: 56.0500,                 loss: 24.6799
env1_first_0:                 episode reward: -53.2500,                 loss: nan
env1_second_0:                 episode reward: 53.2500,                 loss: nan
Episode: 16161/30000 (53.8700%),                 avg. length: 840.6,                last time consumption/overall running time: 121.3802s / 144435.8787 s
env0_first_0:                 episode reward: -41.7000,                 loss: 10.5958
env0_second_0:                 episode reward: 41.7000,                 loss: 14.0257
env1_first_0:                 episode reward: -39.9500,                 loss: nan
env1_second_0:                 episode reward: 39.9500,                 loss: nan
Episode: 16181/30000 (53.9367%),                 avg. length: 900.85,                last time consumption/overall running time: 129.7791s / 144565.6578 s
env0_first_0:                 episode reward: -48.8000,                 loss: 11.8672
env0_second_0:                 episode reward: 48.8000,                 loss: 16.5224
env1_first_0:                 episode reward: -62.4500,                 loss: nan
env1_second_0:                 episode reward: 62.4500,                 loss: nan
Episode: 16201/30000 (54.0033%),                 avg. length: 1170.6,                last time consumption/overall running time: 162.8928s / 144728.5506 s
env0_first_0:                 episode reward: -66.2000,                 loss: 14.1084
env0_second_0:                 episode reward: 66.2000,                 loss: 16.1663
env1_first_0:                 episode reward: -56.7500,                 loss: nan
env1_second_0:                 episode reward: 56.7500,                 loss: nan
Episode: 16221/30000 (54.0700%),                 avg. length: 1205.7,                last time consumption/overall running time: 171.0473s / 144899.5979 s
env0_first_0:                 episode reward: -71.3000,                 loss: 13.5967
env0_second_0:                 episode reward: 71.3000,                 loss: 15.3492
env1_first_0:                 episode reward: -64.4500,                 loss: nan
env1_second_0:                 episode reward: 64.4500,                 loss: nan
Episode: 16241/30000 (54.1367%),                 avg. length: 591.0,                last time consumption/overall running time: 86.2684s / 144985.8663 s
env0_first_0:                 episode reward: -83.4000,                 loss: 16.6412
env0_second_0:                 episode reward: 83.4000,                 loss: 19.3309
env1_first_0:                 episode reward: -78.8000,                 loss: nan
env1_second_0:                 episode reward: 78.8000,                 loss: nan
Episode: 16261/30000 (54.2033%),                 avg. length: 616.05,                last time consumption/overall running time: 89.8195s / 145075.6858 s
env0_first_0:                 episode reward: -78.1000,                 loss: 14.0177
env0_second_0:                 episode reward: 78.1000,                 loss: 18.7011
env1_first_0:                 episode reward: -76.0500,                 loss: nan
env1_second_0:                 episode reward: 76.0500,                 loss: nan
Episode: 16281/30000 (54.2700%),                 avg. length: 1006.9,                last time consumption/overall running time: 145.3207s / 145221.0065 s
env0_first_0:                 episode reward: -52.4000,                 loss: 14.1947
env0_second_0:                 episode reward: 52.4000,                 loss: 17.6801
env1_first_0:                 episode reward: -47.6500,                 loss: nan
env1_second_0:                 episode reward: 47.6500,                 loss: nan
Episode: 16301/30000 (54.3367%),                 avg. length: 964.6,                last time consumption/overall running time: 135.5693s / 145356.5758 s
env0_first_0:                 episode reward: -44.8000,                 loss: 7.5613
env0_second_0:                 episode reward: 44.8000,                 loss: 10.9592
env1_first_0:                 episode reward: -43.3000,                 loss: nan
env1_second_0:                 episode reward: 43.3000,                 loss: nan
Episode: 16321/30000 (54.4033%),                 avg. length: 505.15,                last time consumption/overall running time: 77.0643s / 145433.6400 s
env0_first_0:                 episode reward: -66.3500,                 loss: 19.8014
env0_second_0:                 episode reward: 66.3500,                 loss: 22.5893
env1_first_0:                 episode reward: -69.2500,                 loss: nan
env1_second_0:                 episode reward: 69.2500,                 loss: nan
Episode: 16341/30000 (54.4700%),                 avg. length: 475.35,                last time consumption/overall running time: 75.5481s / 145509.1882 s
env0_first_0:                 episode reward: -59.4000,                 loss: 30.5438
env0_second_0:                 episode reward: 59.4000,                 loss: 35.4831
env1_first_0:                 episode reward: -82.6000,                 loss: nan
env1_second_0:                 episode reward: 82.6000,                 loss: nan
Episode: 16361/30000 (54.5367%),                 avg. length: 334.7,                last time consumption/overall running time: 54.4111s / 145563.5993 s
env0_first_0:                 episode reward: -81.4500,                 loss: 45.1562
env0_second_0:                 episode reward: 81.4500,                 loss: 51.0126
env1_first_0:                 episode reward: -75.5000,                 loss: nan
env1_second_0:                 episode reward: 75.5000,                 loss: nan
Episode: 16381/30000 (54.6033%),                 avg. length: 416.3,                last time consumption/overall running time: 61.7469s / 145625.3462 s
env0_first_0:                 episode reward: -77.4500,                 loss: 34.7291
env0_second_0:                 episode reward: 77.4500,                 loss: 38.0614
env1_first_0:                 episode reward: -69.8500,                 loss: nan
env1_second_0:                 episode reward: 69.8500,                 loss: nan
Episode: 16401/30000 (54.6700%),                 avg. length: 859.35,                last time consumption/overall running time: 121.0379s / 145746.3841 s
env0_first_0:                 episode reward: -53.0000,                 loss: 16.4022
env0_second_0:                 episode reward: 53.0000,                 loss: 18.5323
env1_first_0:                 episode reward: -56.0500,                 loss: nan
env1_second_0:                 episode reward: 56.0500,                 loss: nan
Episode: 16421/30000 (54.7367%),                 avg. length: 400.2,                last time consumption/overall running time: 63.1307s / 145809.5148 s
env0_first_0:                 episode reward: -67.0000,                 loss: 38.2524
env0_second_0:                 episode reward: 67.0000,                 loss: 39.0725
env1_first_0:                 episode reward: -58.7500,                 loss: nan
env1_second_0:                 episode reward: 58.7500,                 loss: nan
Episode: 16441/30000 (54.8033%),                 avg. length: 566.8,                last time consumption/overall running time: 87.0402s / 145896.5550 s
env0_first_0:                 episode reward: -50.4500,                 loss: 27.6478
env0_second_0:                 episode reward: 50.4500,                 loss: 32.2056
env1_first_0:                 episode reward: -69.7000,                 loss: nan
env1_second_0:                 episode reward: 69.7000,                 loss: nan
Episode: 16461/30000 (54.8700%),                 avg. length: 530.7,                last time consumption/overall running time: 80.1825s / 145976.7375 s
env0_first_0:                 episode reward: -52.9500,                 loss: 35.9343
env0_second_0:                 episode reward: 52.9500,                 loss: 42.7509
env1_first_0:                 episode reward: -72.6000,                 loss: nan
env1_second_0:                 episode reward: 72.6000,                 loss: nan
Episode: 16481/30000 (54.9367%),                 avg. length: 730.6,                last time consumption/overall running time: 109.0605s / 146085.7980 s
env0_first_0:                 episode reward: -55.8000,                 loss: 18.5326
env0_second_0:                 episode reward: 55.8000,                 loss: 22.5453
env1_first_0:                 episode reward: -47.9000,                 loss: nan
env1_second_0:                 episode reward: 47.9000,                 loss: nan
Episode: 16501/30000 (55.0033%),                 avg. length: 1671.35,                last time consumption/overall running time: 238.0435s / 146323.8415 s
env0_first_0:                 episode reward: -2.2000,                 loss: 7.0193
env0_second_0:                 episode reward: 2.2000,                 loss: 10.4422
env1_first_0:                 episode reward: -8.8000,                 loss: nan
env1_second_0:                 episode reward: 8.8000,                 loss: nan
Episode: 16521/30000 (55.0700%),                 avg. length: 1784.0,                last time consumption/overall running time: 240.7367s / 146564.5782 s
env0_first_0:                 episode reward: -8.6500,                 loss: 3.8685
env0_second_0:                 episode reward: 8.6500,                 loss: 6.9782
env1_first_0:                 episode reward: -8.1500,                 loss: nan
env1_second_0:                 episode reward: 8.1500,                 loss: nan
Episode: 16541/30000 (55.1367%),                 avg. length: 870.05,                last time consumption/overall running time: 127.8190s / 146692.3972 s
env0_first_0:                 episode reward: -58.1000,                 loss: 19.8849
env0_second_0:                 episode reward: 58.1000,                 loss: 21.7769
env1_first_0:                 episode reward: -57.3500,                 loss: nan
env1_second_0:                 episode reward: 57.3500,                 loss: nan
Episode: 16561/30000 (55.2033%),                 avg. length: 412.55,                last time consumption/overall running time: 63.7387s / 146756.1359 s
env0_first_0:                 episode reward: -67.0000,                 loss: 40.8907
env0_second_0:                 episode reward: 67.0000,                 loss: 45.4549
env1_first_0:                 episode reward: -74.2000,                 loss: nan
env1_second_0:                 episode reward: 74.2000,                 loss: nan
Episode: 16581/30000 (55.2700%),                 avg. length: 339.75,                last time consumption/overall running time: 57.8558s / 146813.9917 s
env0_first_0:                 episode reward: -80.0500,                 loss: 46.8470
env0_second_0:                 episode reward: 80.0500,                 loss: 51.4326
env1_first_0:                 episode reward: -69.8500,                 loss: nan
env1_second_0:                 episode reward: 69.8500,                 loss: nan
Episode: 16601/30000 (55.3367%),                 avg. length: 610.55,                last time consumption/overall running time: 86.6839s / 146900.6756 s
env0_first_0:                 episode reward: -69.3500,                 loss: 23.2024
env0_second_0:                 episode reward: 69.3500,                 loss: 26.5050
env1_first_0:                 episode reward: -53.2000,                 loss: nan
env1_second_0:                 episode reward: 53.2000,                 loss: nan
Episode: 16621/30000 (55.4033%),                 avg. length: 466.7,                last time consumption/overall running time: 69.8292s / 146970.5048 s
env0_first_0:                 episode reward: -59.1500,                 loss: 31.4983
env0_second_0:                 episode reward: 59.1500,                 loss: 33.5123
env1_first_0:                 episode reward: -69.8500,                 loss: nan
env1_second_0:                 episode reward: 69.8500,                 loss: nan
Episode: 16641/30000 (55.4700%),                 avg. length: 335.65,                last time consumption/overall running time: 52.9580s / 147023.4628 s
env0_first_0:                 episode reward: -69.2500,                 loss: 40.6478
env0_second_0:                 episode reward: 69.2500,                 loss: 45.7963
env1_first_0:                 episode reward: -79.1000,                 loss: nan
env1_second_0:                 episode reward: 79.1000,                 loss: nan
Episode: 16661/30000 (55.5367%),                 avg. length: 1466.85,                last time consumption/overall running time: 202.1462s / 147225.6090 s
env0_first_0:                 episode reward: -21.0500,                 loss: 9.9268
env0_second_0:                 episode reward: 21.0500,                 loss: 13.5844
env1_first_0:                 episode reward: -19.1000,                 loss: nan
env1_second_0:                 episode reward: 19.1000,                 loss: nan
Episode: 16681/30000 (55.6033%),                 avg. length: 487.8,                last time consumption/overall running time: 74.2229s / 147299.8319 s
env0_first_0:                 episode reward: -65.4500,                 loss: 26.4397
env0_second_0:                 episode reward: 65.4500,                 loss: 29.3894
env1_first_0:                 episode reward: -69.0000,                 loss: nan
env1_second_0:                 episode reward: 69.0000,                 loss: nan
Episode: 16701/30000 (55.6700%),                 avg. length: 374.45,                last time consumption/overall running time: 59.9190s / 147359.7509 s
env0_first_0:                 episode reward: -87.0500,                 loss: 39.6141
env0_second_0:                 episode reward: 87.0500,                 loss: 42.6649
env1_first_0:                 episode reward: -61.2500,                 loss: nan
env1_second_0:                 episode reward: 61.2500,                 loss: nan
Episode: 16721/30000 (55.7367%),                 avg. length: 413.75,                last time consumption/overall running time: 65.3100s / 147425.0609 s
env0_first_0:                 episode reward: -76.8500,                 loss: 41.0672
env0_second_0:                 episode reward: 76.8500,                 loss: 43.4173
env1_first_0:                 episode reward: -65.9000,                 loss: nan
env1_second_0:                 episode reward: 65.9000,                 loss: nan
Episode: 16741/30000 (55.8033%),                 avg. length: 267.2,                last time consumption/overall running time: 41.7149s / 147466.7758 s
env0_first_0:                 episode reward: -74.7000,                 loss: 42.4046
env0_second_0:                 episode reward: 74.7000,                 loss: 43.9853
env1_first_0:                 episode reward: -77.0000,                 loss: nan
env1_second_0:                 episode reward: 77.0000,                 loss: nan
Episode: 16761/30000 (55.8700%),                 avg. length: 302.15,                last time consumption/overall running time: 51.3819s / 147518.1577 s
env0_first_0:                 episode reward: -68.9500,                 loss: 42.1887
env0_second_0:                 episode reward: 68.9500,                 loss: 45.9353
env1_first_0:                 episode reward: -78.9000,                 loss: nan
env1_second_0:                 episode reward: 78.9000,                 loss: nan
Episode: 16781/30000 (55.9367%),                 avg. length: 344.75,                last time consumption/overall running time: 58.3266s / 147576.4844 s
env0_first_0:                 episode reward: -75.9000,                 loss: 32.1298
env0_second_0:                 episode reward: 75.9000,                 loss: 34.2301
env1_first_0:                 episode reward: -76.5000,                 loss: nan
env1_second_0:                 episode reward: 76.5000,                 loss: nan
Episode: 16801/30000 (56.0033%),                 avg. length: 430.15,                last time consumption/overall running time: 63.8150s / 147640.2994 s
env0_first_0:                 episode reward: -72.3500,                 loss: 33.0605
env0_second_0:                 episode reward: 72.3500,                 loss: 35.6473
env1_first_0:                 episode reward: -74.2500,                 loss: nan
env1_second_0:                 episode reward: 74.2500,                 loss: nan
Episode: 16821/30000 (56.0700%),                 avg. length: 373.6,                last time consumption/overall running time: 57.5340s / 147697.8334 s
env0_first_0:                 episode reward: -80.4500,                 loss: 32.1190
env0_second_0:                 episode reward: 80.4500,                 loss: 34.9221
env1_first_0:                 episode reward: -76.4500,                 loss: nan
env1_second_0:                 episode reward: 76.4500,                 loss: nan
Episode: 16841/30000 (56.1367%),                 avg. length: 386.9,                last time consumption/overall running time: 61.8954s / 147759.7288 s
env0_first_0:                 episode reward: -72.7000,                 loss: 31.7983
env0_second_0:                 episode reward: 72.7000,                 loss: 34.2090
env1_first_0:                 episode reward: -69.4000,                 loss: nan
env1_second_0:                 episode reward: 69.4000,                 loss: nan
Episode: 16861/30000 (56.2033%),                 avg. length: 396.0,                last time consumption/overall running time: 65.8139s / 147825.5427 s
env0_first_0:                 episode reward: -65.5000,                 loss: 32.7214
env0_second_0:                 episode reward: 65.5000,                 loss: 34.2612
env1_first_0:                 episode reward: -74.9500,                 loss: nan
env1_second_0:                 episode reward: 74.9500,                 loss: nan
Episode: 16881/30000 (56.2700%),                 avg. length: 518.05,                last time consumption/overall running time: 76.5725s / 147902.1152 s
env0_first_0:                 episode reward: -82.8500,                 loss: 29.4910
env0_second_0:                 episode reward: 82.8500,                 loss: 29.2983
env1_first_0:                 episode reward: -62.9500,                 loss: nan
env1_second_0:                 episode reward: 62.9500,                 loss: nan
Episode: 16901/30000 (56.3367%),                 avg. length: 530.7,                last time consumption/overall running time: 79.6556s / 147981.7708 s
env0_first_0:                 episode reward: -80.5000,                 loss: 18.5352
env0_second_0:                 episode reward: 80.5000,                 loss: 21.4710
env1_first_0:                 episode reward: -76.6000,                 loss: nan
env1_second_0:                 episode reward: 76.6000,                 loss: nan
Episode: 16921/30000 (56.4033%),                 avg. length: 770.3,                last time consumption/overall running time: 109.6218s / 148091.3926 s
env0_first_0:                 episode reward: -58.3500,                 loss: 21.7972
env0_second_0:                 episode reward: 58.3500,                 loss: 25.1909
env1_first_0:                 episode reward: -57.6000,                 loss: nan
env1_second_0:                 episode reward: 57.6000,                 loss: nan
Episode: 16941/30000 (56.4700%),                 avg. length: 578.05,                last time consumption/overall running time: 82.8838s / 148174.2764 s
env0_first_0:                 episode reward: -49.0000,                 loss: 28.3751
env0_second_0:                 episode reward: 49.0000,                 loss: 30.5291
env1_first_0:                 episode reward: -63.0500,                 loss: nan
env1_second_0:                 episode reward: 63.0500,                 loss: nan
Episode: 16961/30000 (56.5367%),                 avg. length: 470.75,                last time consumption/overall running time: 67.7707s / 148242.0471 s
env0_first_0:                 episode reward: -62.7000,                 loss: 38.8820
env0_second_0:                 episode reward: 62.7000,                 loss: 42.4708
env1_first_0:                 episode reward: -67.0500,                 loss: nan
env1_second_0:                 episode reward: 67.0500,                 loss: nan
Episode: 16981/30000 (56.6033%),                 avg. length: 444.2,                last time consumption/overall running time: 72.9744s / 148315.0215 s
env0_first_0:                 episode reward: -76.1500,                 loss: 32.7513
env0_second_0:                 episode reward: 76.1500,                 loss: 35.3812
env1_first_0:                 episode reward: -79.4000,                 loss: nan
env1_second_0:                 episode reward: 79.4000,                 loss: nan
Episode: 17001/30000 (56.6700%),                 avg. length: 587.45,                last time consumption/overall running time: 86.6995s / 148401.7209 s
env0_first_0:                 episode reward: -68.2500,                 loss: 23.0868
env0_second_0:                 episode reward: 68.2500,                 loss: 26.0197
env1_first_0:                 episode reward: -75.7500,                 loss: nan
env1_second_0:                 episode reward: 75.7500,                 loss: nan
Episode: 17021/30000 (56.7367%),                 avg. length: 540.75,                last time consumption/overall running time: 76.5334s / 148478.2543 s
env0_first_0:                 episode reward: -61.2500,                 loss: 33.7412
env0_second_0:                 episode reward: 61.2500,                 loss: 36.3847
env1_first_0:                 episode reward: -80.2500,                 loss: nan
env1_second_0:                 episode reward: 80.2500,                 loss: nan
Episode: 17041/30000 (56.8033%),                 avg. length: 480.65,                last time consumption/overall running time: 69.0379s / 148547.2922 s
env0_first_0:                 episode reward: -70.9000,                 loss: 32.9298
env0_second_0:                 episode reward: 70.9000,                 loss: 35.2012
env1_first_0:                 episode reward: -63.2500,                 loss: nan
env1_second_0:                 episode reward: 63.2500,                 loss: nan
Episode: 17061/30000 (56.8700%),                 avg. length: 452.6,                last time consumption/overall running time: 70.2445s / 148617.5367 s
env0_first_0:                 episode reward: -61.6000,                 loss: 30.0742
env0_second_0:                 episode reward: 61.6000,                 loss: 32.6294
env1_first_0:                 episode reward: -70.1500,                 loss: nan
env1_second_0:                 episode reward: 70.1500,                 loss: nan
Episode: 17081/30000 (56.9367%),                 avg. length: 500.6,                last time consumption/overall running time: 76.3349s / 148693.8716 s
env0_first_0:                 episode reward: -66.8000,                 loss: 33.0172
env0_second_0:                 episode reward: 66.8000,                 loss: 35.6680
env1_first_0:                 episode reward: -62.1000,                 loss: nan
env1_second_0:                 episode reward: 62.1000,                 loss: nan
Episode: 17101/30000 (57.0033%),                 avg. length: 844.7,                last time consumption/overall running time: 128.2011s / 148822.0727 s
env0_first_0:                 episode reward: -19.9500,                 loss: 24.8376
env0_second_0:                 episode reward: 19.9500,                 loss: 28.2899
env1_first_0:                 episode reward: -32.8000,                 loss: nan
env1_second_0:                 episode reward: 32.8000,                 loss: nan
Episode: 17121/30000 (57.0700%),                 avg. length: 859.1,                last time consumption/overall running time: 125.4808s / 148947.5535 s
env0_first_0:                 episode reward: -29.4500,                 loss: 25.5157
env0_second_0:                 episode reward: 29.4500,                 loss: 27.8477
env1_first_0:                 episode reward: -35.9000,                 loss: nan
env1_second_0:                 episode reward: 35.9000,                 loss: nan
Episode: 17141/30000 (57.1367%),                 avg. length: 710.0,                last time consumption/overall running time: 101.2368s / 149048.7903 s
env0_first_0:                 episode reward: -59.2500,                 loss: 28.4883
env0_second_0:                 episode reward: 59.2500,                 loss: 31.1190
env1_first_0:                 episode reward: -43.0000,                 loss: nan
env1_second_0:                 episode reward: 43.0000,                 loss: nan
Episode: 17161/30000 (57.2033%),                 avg. length: 730.55,                last time consumption/overall running time: 101.4572s / 149150.2476 s
env0_first_0:                 episode reward: -54.7000,                 loss: 32.2159
env0_second_0:                 episode reward: 54.7000,                 loss: 34.8908
env1_first_0:                 episode reward: -62.8500,                 loss: nan
env1_second_0:                 episode reward: 62.8500,                 loss: nan
Episode: 17181/30000 (57.2700%),                 avg. length: 508.05,                last time consumption/overall running time: 77.3707s / 149227.6183 s
env0_first_0:                 episode reward: -70.5000,                 loss: 41.3649
env0_second_0:                 episode reward: 70.5000,                 loss: 44.0264
env1_first_0:                 episode reward: -66.7000,                 loss: nan
env1_second_0:                 episode reward: 66.7000,                 loss: nan
Episode: 17201/30000 (57.3367%),                 avg. length: 400.2,                last time consumption/overall running time: 60.7933s / 149288.4116 s
env0_first_0:                 episode reward: -66.9000,                 loss: 41.0756
env0_second_0:                 episode reward: 66.9000,                 loss: 43.6302
env1_first_0:                 episode reward: -81.1500,                 loss: nan
env1_second_0:                 episode reward: 81.1500,                 loss: nan
Episode: 17221/30000 (57.4033%),                 avg. length: 607.8,                last time consumption/overall running time: 88.2326s / 149376.6442 s
env0_first_0:                 episode reward: -74.0000,                 loss: 23.4929
env0_second_0:                 episode reward: 74.0000,                 loss: 26.1686
env1_first_0:                 episode reward: -71.6000,                 loss: nan
env1_second_0:                 episode reward: 71.6000,                 loss: nan
Episode: 17241/30000 (57.4700%),                 avg. length: 564.85,                last time consumption/overall running time: 80.4315s / 149457.0756 s
env0_first_0:                 episode reward: -74.9000,                 loss: 30.1233
env0_second_0:                 episode reward: 74.9000,                 loss: 32.2006
env1_first_0:                 episode reward: -71.2500,                 loss: nan
env1_second_0:                 episode reward: 71.2500,                 loss: nan
Episode: 17261/30000 (57.5367%),                 avg. length: 1190.15,                last time consumption/overall running time: 163.0354s / 149620.1110 s
env0_first_0:                 episode reward: -56.5000,                 loss: 16.6978
env0_second_0:                 episode reward: 56.5000,                 loss: 18.7694
env1_first_0:                 episode reward: -62.7000,                 loss: nan
env1_second_0:                 episode reward: 62.7000,                 loss: nan
Episode: 17281/30000 (57.6033%),                 avg. length: 1169.25,                last time consumption/overall running time: 161.2679s / 149781.3789 s
env0_first_0:                 episode reward: -56.9000,                 loss: 18.1843
env0_second_0:                 episode reward: 56.9000,                 loss: 20.9048
env1_first_0:                 episode reward: -56.6000,                 loss: nan
env1_second_0:                 episode reward: 56.6000,                 loss: nan
Episode: 17301/30000 (57.6700%),                 avg. length: 653.1,                last time consumption/overall running time: 97.5450s / 149878.9239 s
env0_first_0:                 episode reward: -63.1000,                 loss: 31.0667
env0_second_0:                 episode reward: 63.1000,                 loss: 33.2415
env1_first_0:                 episode reward: -51.9500,                 loss: nan
env1_second_0:                 episode reward: 51.9500,                 loss: nan
Episode: 17321/30000 (57.7367%),                 avg. length: 597.45,                last time consumption/overall running time: 86.7867s / 149965.7105 s
env0_first_0:                 episode reward: -81.2000,                 loss: 18.8949
env0_second_0:                 episode reward: 81.2000,                 loss: 20.4753
env1_first_0:                 episode reward: -73.0500,                 loss: nan
env1_second_0:                 episode reward: 73.0500,                 loss: nan
Episode: 17341/30000 (57.8033%),                 avg. length: 1535.05,                last time consumption/overall running time: 219.4955s / 150185.2060 s
env0_first_0:                 episode reward: -49.9000,                 loss: 7.8681
env0_second_0:                 episode reward: 49.9000,                 loss: 8.7880
env1_first_0:                 episode reward: -43.4500,                 loss: nan
env1_second_0:                 episode reward: 43.4500,                 loss: nan
Episode: 17361/30000 (57.8700%),                 avg. length: 792.5,                last time consumption/overall running time: 109.7959s / 150295.0019 s
env0_first_0:                 episode reward: -54.3000,                 loss: 31.9430
env0_second_0:                 episode reward: 54.3000,                 loss: 31.7110
env1_first_0:                 episode reward: -65.3000,                 loss: nan
env1_second_0:                 episode reward: 65.3000,                 loss: nan
Episode: 17381/30000 (57.9367%),                 avg. length: 839.0,                last time consumption/overall running time: 121.4779s / 150416.4798 s
env0_first_0:                 episode reward: -43.3000,                 loss: 20.7777
env0_second_0:                 episode reward: 43.3000,                 loss: 22.4931
env1_first_0:                 episode reward: -29.2500,                 loss: nan
env1_second_0:                 episode reward: 29.2500,                 loss: nan
Episode: 17401/30000 (58.0033%),                 avg. length: 454.2,                last time consumption/overall running time: 76.7299s / 150493.2096 s
env0_first_0:                 episode reward: -65.5500,                 loss: 35.3729
env0_second_0:                 episode reward: 65.5500,                 loss: 36.4714
env1_first_0:                 episode reward: -58.4500,                 loss: nan
env1_second_0:                 episode reward: 58.4500,                 loss: nan
Episode: 17421/30000 (58.0700%),                 avg. length: 316.7,                last time consumption/overall running time: 51.7086s / 150544.9182 s
env0_first_0:                 episode reward: -74.9000,                 loss: 48.3248
env0_second_0:                 episode reward: 74.9000,                 loss: 49.8314
env1_first_0:                 episode reward: -67.7000,                 loss: nan
env1_second_0:                 episode reward: 67.7000,                 loss: nan
Episode: 17441/30000 (58.1367%),                 avg. length: 380.95,                last time consumption/overall running time: 57.1923s / 150602.1105 s
env0_first_0:                 episode reward: -62.2000,                 loss: 52.6328
env0_second_0:                 episode reward: 62.2000,                 loss: 54.0477
env1_first_0:                 episode reward: -78.6500,                 loss: nan
env1_second_0:                 episode reward: 78.6500,                 loss: nan
Episode: 17461/30000 (58.2033%),                 avg. length: 563.95,                last time consumption/overall running time: 81.3389s / 150683.4494 s
env0_first_0:                 episode reward: -70.6500,                 loss: 41.9833
env0_second_0:                 episode reward: 70.6500,                 loss: 43.1474
env1_first_0:                 episode reward: -59.6500,                 loss: nan
env1_second_0:                 episode reward: 59.6500,                 loss: nan
Episode: 17481/30000 (58.2700%),                 avg. length: 404.2,                last time consumption/overall running time: 63.4153s / 150746.8647 s
env0_first_0:                 episode reward: -58.2500,                 loss: 48.5304
env0_second_0:                 episode reward: 58.2500,                 loss: 49.1329
env1_first_0:                 episode reward: -75.5500,                 loss: nan
env1_second_0:                 episode reward: 75.5500,                 loss: nan
Episode: 17501/30000 (58.3367%),                 avg. length: 704.75,                last time consumption/overall running time: 103.4700s / 150850.3347 s
env0_first_0:                 episode reward: -59.6000,                 loss: 33.6925
env0_second_0:                 episode reward: 59.6000,                 loss: 33.1239
env1_first_0:                 episode reward: -67.3000,                 loss: nan
env1_second_0:                 episode reward: 67.3000,                 loss: nan
Episode: 17521/30000 (58.4033%),                 avg. length: 1141.15,                last time consumption/overall running time: 156.0573s / 151006.3920 s
env0_first_0:                 episode reward: -44.3000,                 loss: 9.3315
env0_second_0:                 episode reward: 44.3000,                 loss: 10.6185
env1_first_0:                 episode reward: -44.0000,                 loss: nan
env1_second_0:                 episode reward: 44.0000,                 loss: nan
Episode: 17541/30000 (58.4700%),                 avg. length: 1261.5,                last time consumption/overall running time: 175.2128s / 151181.6048 s
env0_first_0:                 episode reward: -44.4000,                 loss: 8.7400
env0_second_0:                 episode reward: 44.4000,                 loss: 9.9321
env1_first_0:                 episode reward: -45.0000,                 loss: nan
env1_second_0:                 episode reward: 45.0000,                 loss: nan
Episode: 17561/30000 (58.5367%),                 avg. length: 1340.55,                last time consumption/overall running time: 196.7914s / 151378.3961 s
env0_first_0:                 episode reward: -40.3500,                 loss: 10.0004
env0_second_0:                 episode reward: 40.3500,                 loss: 11.9771
env1_first_0:                 episode reward: -21.9000,                 loss: nan
env1_second_0:                 episode reward: 21.9000,                 loss: nan
Episode: 17581/30000 (58.6033%),                 avg. length: 736.35,                last time consumption/overall running time: 101.8322s / 151480.2284 s
env0_first_0:                 episode reward: -60.2500,                 loss: 32.2070
env0_second_0:                 episode reward: 60.2500,                 loss: 30.9598
env1_first_0:                 episode reward: -57.2500,                 loss: nan
env1_second_0:                 episode reward: 57.2500,                 loss: nan
Episode: 17601/30000 (58.6700%),                 avg. length: 642.15,                last time consumption/overall running time: 94.6657s / 151574.8941 s
env0_first_0:                 episode reward: -63.4000,                 loss: 38.0535
env0_second_0:                 episode reward: 63.4000,                 loss: 39.7214
env1_first_0:                 episode reward: -74.8000,                 loss: nan
env1_second_0:                 episode reward: 74.8000,                 loss: nan
Episode: 17621/30000 (58.7367%),                 avg. length: 380.0,                last time consumption/overall running time: 58.5282s / 151633.4222 s
env0_first_0:                 episode reward: -74.9500,                 loss: 45.9758
env0_second_0:                 episode reward: 74.9500,                 loss: 45.4396
env1_first_0:                 episode reward: -78.5500,                 loss: nan
env1_second_0:                 episode reward: 78.5500,                 loss: nan
Episode: 17641/30000 (58.8033%),                 avg. length: 323.45,                last time consumption/overall running time: 49.8815s / 151683.3037 s
env0_first_0:                 episode reward: -79.6500,                 loss: 27.5628
env0_second_0:                 episode reward: 79.6500,                 loss: 29.6986
env1_first_0:                 episode reward: -90.2000,                 loss: nan
env1_second_0:                 episode reward: 90.2000,                 loss: nan
Episode: 17661/30000 (58.8700%),                 avg. length: 1030.4,                last time consumption/overall running time: 143.5379s / 151826.8416 s
env0_first_0:                 episode reward: -40.8000,                 loss: 19.1778
env0_second_0:                 episode reward: 40.8000,                 loss: 19.4608
env1_first_0:                 episode reward: -42.7500,                 loss: nan
env1_second_0:                 episode reward: 42.7500,                 loss: nan
Episode: 17681/30000 (58.9367%),                 avg. length: 1478.4,                last time consumption/overall running time: 202.7934s / 152029.6350 s
env0_first_0:                 episode reward: -18.9500,                 loss: 8.7170
env0_second_0:                 episode reward: 18.9500,                 loss: 9.5166
env1_first_0:                 episode reward: -10.0000,                 loss: nan
env1_second_0:                 episode reward: 10.0000,                 loss: nan
Episode: 17701/30000 (59.0033%),                 avg. length: 288.95,                last time consumption/overall running time: 49.2360s / 152078.8710 s
env0_first_0:                 episode reward: -97.1500,                 loss: 24.1478
env0_second_0:                 episode reward: 97.1500,                 loss: 20.9282
env1_first_0:                 episode reward: -95.6000,                 loss: nan
env1_second_0:                 episode reward: 95.6000,                 loss: nan
Episode: 17721/30000 (59.0700%),                 avg. length: 223.0,                last time consumption/overall running time: 35.9309s / 152114.8019 s
env0_first_0:                 episode reward: -90.5000,                 loss: 26.7843
env0_second_0:                 episode reward: 90.5000,                 loss: 23.0303
env1_first_0:                 episode reward: -99.4000,                 loss: nan
env1_second_0:                 episode reward: 99.4000,                 loss: nan
Episode: 17741/30000 (59.1367%),                 avg. length: 241.7,                last time consumption/overall running time: 41.8628s / 152156.6647 s
env0_first_0:                 episode reward: -90.5000,                 loss: 27.3517
env0_second_0:                 episode reward: 90.5000,                 loss: 27.6834
env1_first_0:                 episode reward: -81.7000,                 loss: nan
env1_second_0:                 episode reward: 81.7000,                 loss: nan
Episode: 17761/30000 (59.2033%),                 avg. length: 225.4,                last time consumption/overall running time: 43.1369s / 152199.8016 s
env0_first_0:                 episode reward: -89.2500,                 loss: 26.3495
env0_second_0:                 episode reward: 89.2500,                 loss: 26.3790
env1_first_0:                 episode reward: -93.5500,                 loss: nan
env1_second_0:                 episode reward: 93.5500,                 loss: nan
Episode: 17781/30000 (59.2700%),                 avg. length: 221.0,                last time consumption/overall running time: 38.4494s / 152238.2511 s
env0_first_0:                 episode reward: -94.2500,                 loss: 21.5878
env0_second_0:                 episode reward: 94.2500,                 loss: 20.8216
env1_first_0:                 episode reward: -88.4000,                 loss: nan
env1_second_0:                 episode reward: 88.4000,                 loss: nan
Episode: 17801/30000 (59.3367%),                 avg. length: 227.25,                last time consumption/overall running time: 38.8615s / 152277.1125 s
env0_first_0:                 episode reward: -87.0500,                 loss: 20.0797
env0_second_0:                 episode reward: 87.0500,                 loss: 21.6067
env1_first_0:                 episode reward: -93.1500,                 loss: nan
env1_second_0:                 episode reward: 93.1500,                 loss: nan
Episode: 17821/30000 (59.4033%),                 avg. length: 236.85,                last time consumption/overall running time: 39.5699s / 152316.6824 s
env0_first_0:                 episode reward: -86.6000,                 loss: 26.2809
env0_second_0:                 episode reward: 86.6000,                 loss: 38.8482
env1_first_0:                 episode reward: -89.2000,                 loss: nan
env1_second_0:                 episode reward: 89.2000,                 loss: nan
Episode: 17841/30000 (59.4700%),                 avg. length: 254.65,                last time consumption/overall running time: 43.4365s / 152360.1189 s
env0_first_0:                 episode reward: -80.1500,                 loss: 32.5067
env0_second_0:                 episode reward: 80.1500,                 loss: 36.5190
env1_first_0:                 episode reward: -88.9000,                 loss: nan
env1_second_0:                 episode reward: 88.9000,                 loss: nan
Episode: 17861/30000 (59.5367%),                 avg. length: 261.1,                last time consumption/overall running time: 47.4071s / 152407.5259 s
env0_first_0:                 episode reward: -80.9000,                 loss: 34.2313
env0_second_0:                 episode reward: 80.9000,                 loss: 38.4791
env1_first_0:                 episode reward: -77.1000,                 loss: nan
env1_second_0:                 episode reward: 77.1000,                 loss: nan
Episode: 17881/30000 (59.6033%),                 avg. length: 437.7,                last time consumption/overall running time: 65.0630s / 152472.5889 s
env0_first_0:                 episode reward: -72.2500,                 loss: 31.3952
env0_second_0:                 episode reward: 72.2500,                 loss: 33.5592
env1_first_0:                 episode reward: -80.1500,                 loss: nan
env1_second_0:                 episode reward: 80.1500,                 loss: nan
Episode: 17901/30000 (59.6700%),                 avg. length: 329.5,                last time consumption/overall running time: 54.9648s / 152527.5537 s
env0_first_0:                 episode reward: -73.0000,                 loss: 31.6213
env0_second_0:                 episode reward: 73.0000,                 loss: 33.2845
env1_first_0:                 episode reward: -80.0500,                 loss: nan
env1_second_0:                 episode reward: 80.0500,                 loss: nan
Episode: 17921/30000 (59.7367%),                 avg. length: 329.45,                last time consumption/overall running time: 49.7329s / 152577.2866 s
env0_first_0:                 episode reward: -84.9500,                 loss: 28.5817
env0_second_0:                 episode reward: 84.9500,                 loss: 30.7160
env1_first_0:                 episode reward: -74.8500,                 loss: nan
env1_second_0:                 episode reward: 74.8500,                 loss: nan
Episode: 17941/30000 (59.8033%),                 avg. length: 228.1,                last time consumption/overall running time: 37.8353s / 152615.1219 s
env0_first_0:                 episode reward: -92.3500,                 loss: 24.8001
env0_second_0:                 episode reward: 92.3500,                 loss: 26.0255
env1_first_0:                 episode reward: -89.4000,                 loss: nan
env1_second_0:                 episode reward: 89.4000,                 loss: nan
Episode: 17961/30000 (59.8700%),                 avg. length: 254.4,                last time consumption/overall running time: 43.7164s / 152658.8383 s
env0_first_0:                 episode reward: -90.7000,                 loss: 25.0978
env0_second_0:                 episode reward: 90.7000,                 loss: 26.9590
env1_first_0:                 episode reward: -84.8000,                 loss: nan
env1_second_0:                 episode reward: 84.8000,                 loss: nan
Episode: 17981/30000 (59.9367%),                 avg. length: 260.35,                last time consumption/overall running time: 46.6323s / 152705.4706 s
env0_first_0:                 episode reward: -88.7500,                 loss: 22.5644
env0_second_0:                 episode reward: 88.7500,                 loss: 24.5566
env1_first_0:                 episode reward: -92.0500,                 loss: nan
env1_second_0:                 episode reward: 92.0500,                 loss: nan
Episode: 18001/30000 (60.0033%),                 avg. length: 245.1,                last time consumption/overall running time: 43.2675s / 152748.7381 s
env0_first_0:                 episode reward: -92.9000,                 loss: 21.2065
env0_second_0:                 episode reward: 92.9000,                 loss: 23.0115
env1_first_0:                 episode reward: -91.2000,                 loss: nan
env1_second_0:                 episode reward: 91.2000,                 loss: nan
Episode: 18021/30000 (60.0700%),                 avg. length: 253.3,                last time consumption/overall running time: 41.5735s / 152790.3116 s
env0_first_0:                 episode reward: -90.6000,                 loss: 28.5636
env0_second_0:                 episode reward: 90.6000,                 loss: 30.0749
env1_first_0:                 episode reward: -85.2000,                 loss: nan
env1_second_0:                 episode reward: 85.2000,                 loss: nan
Episode: 18041/30000 (60.1367%),                 avg. length: 654.7,                last time consumption/overall running time: 95.2229s / 152885.5344 s
env0_first_0:                 episode reward: -68.7500,                 loss: 25.5394
env0_second_0:                 episode reward: 68.7500,                 loss: 28.1759
env1_first_0:                 episode reward: -71.1500,                 loss: nan
env1_second_0:                 episode reward: 71.1500,                 loss: nan
Episode: 18061/30000 (60.2033%),                 avg. length: 1045.7,                last time consumption/overall running time: 151.3231s / 153036.8575 s
env0_first_0:                 episode reward: -41.4500,                 loss: 10.5956
env0_second_0:                 episode reward: 41.4500,                 loss: 12.1668
env1_first_0:                 episode reward: -42.2000,                 loss: nan
env1_second_0:                 episode reward: 42.2000,                 loss: nan
Episode: 18081/30000 (60.2700%),                 avg. length: 749.55,                last time consumption/overall running time: 105.9139s / 153142.7714 s
env0_first_0:                 episode reward: -30.1000,                 loss: 19.4806
env0_second_0:                 episode reward: 30.1000,                 loss: 21.2072
env1_first_0:                 episode reward: -39.4500,                 loss: nan
env1_second_0:                 episode reward: 39.4500,                 loss: nan
Episode: 18101/30000 (60.3367%),                 avg. length: 657.55,                last time consumption/overall running time: 94.2025s / 153236.9740 s
env0_first_0:                 episode reward: -52.4000,                 loss: 27.2385
env0_second_0:                 episode reward: 52.4000,                 loss: 30.3245
env1_first_0:                 episode reward: -50.9000,                 loss: nan
env1_second_0:                 episode reward: 50.9000,                 loss: nan
Episode: 18121/30000 (60.4033%),                 avg. length: 679.85,                last time consumption/overall running time: 93.1425s / 153330.1164 s
env0_first_0:                 episode reward: -60.0500,                 loss: 31.4836
env0_second_0:                 episode reward: 60.0500,                 loss: 32.6631
env1_first_0:                 episode reward: -55.3500,                 loss: nan
env1_second_0:                 episode reward: 55.3500,                 loss: nan
Episode: 18141/30000 (60.4700%),                 avg. length: 596.2,                last time consumption/overall running time: 91.5256s / 153421.6421 s
env0_first_0:                 episode reward: -58.5500,                 loss: 33.3622
env0_second_0:                 episode reward: 58.5500,                 loss: 35.9865
env1_first_0:                 episode reward: -60.9000,                 loss: nan
env1_second_0:                 episode reward: 60.9000,                 loss: nan
Episode: 18161/30000 (60.5367%),                 avg. length: 299.95,                last time consumption/overall running time: 47.6939s / 153469.3360 s
env0_first_0:                 episode reward: -76.4500,                 loss: 36.3727
env0_second_0:                 episode reward: 76.4500,                 loss: 37.9941
env1_first_0:                 episode reward: -86.1000,                 loss: nan
env1_second_0:                 episode reward: 86.1000,                 loss: nan
Episode: 18181/30000 (60.6033%),                 avg. length: 546.25,                last time consumption/overall running time: 81.4043s / 153550.7404 s
env0_first_0:                 episode reward: -69.1000,                 loss: 36.6245
env0_second_0:                 episode reward: 69.1000,                 loss: 39.1414
env1_first_0:                 episode reward: -70.2000,                 loss: nan
env1_second_0:                 episode reward: 70.2000,                 loss: nan
Episode: 18201/30000 (60.6700%),                 avg. length: 272.2,                last time consumption/overall running time: 44.2044s / 153594.9448 s
env0_first_0:                 episode reward: -88.4500,                 loss: 38.3535
env0_second_0:                 episode reward: 88.4500,                 loss: 41.8652
env1_first_0:                 episode reward: -73.3000,                 loss: nan
env1_second_0:                 episode reward: 73.3000,                 loss: nan
Episode: 18221/30000 (60.7367%),                 avg. length: 295.35,                last time consumption/overall running time: 48.6280s / 153643.5728 s
env0_first_0:                 episode reward: -72.8000,                 loss: 38.9310
env0_second_0:                 episode reward: 72.8000,                 loss: 42.9708
env1_first_0:                 episode reward: -79.3500,                 loss: nan
env1_second_0:                 episode reward: 79.3500,                 loss: nan
Episode: 18241/30000 (60.8033%),                 avg. length: 271.85,                last time consumption/overall running time: 45.2329s / 153688.8057 s
env0_first_0:                 episode reward: -77.0000,                 loss: 37.0866
env0_second_0:                 episode reward: 77.0000,                 loss: 40.8633
env1_first_0:                 episode reward: -82.4500,                 loss: nan
env1_second_0:                 episode reward: 82.4500,                 loss: nan
Episode: 18261/30000 (60.8700%),                 avg. length: 293.35,                last time consumption/overall running time: 51.0016s / 153739.8072 s
env0_first_0:                 episode reward: -68.7500,                 loss: 37.5408
env0_second_0:                 episode reward: 68.7500,                 loss: 41.0626
env1_first_0:                 episode reward: -73.7500,                 loss: nan
env1_second_0:                 episode reward: 73.7500,                 loss: nan
Episode: 18281/30000 (60.9367%),                 avg. length: 300.0,                last time consumption/overall running time: 49.6565s / 153789.4637 s
env0_first_0:                 episode reward: -77.2500,                 loss: 47.0618
env0_second_0:                 episode reward: 77.2500,                 loss: 51.0493
env1_first_0:                 episode reward: -75.3000,                 loss: nan
env1_second_0:                 episode reward: 75.3000,                 loss: nan
Episode: 18301/30000 (61.0033%),                 avg. length: 353.75,                last time consumption/overall running time: 57.0002s / 153846.4639 s
env0_first_0:                 episode reward: -62.3000,                 loss: 35.1972
env0_second_0:                 episode reward: 62.3000,                 loss: 37.4786
env1_first_0:                 episode reward: -69.5500,                 loss: nan
env1_second_0:                 episode reward: 69.5500,                 loss: nan
Episode: 18321/30000 (61.0700%),                 avg. length: 622.3,                last time consumption/overall running time: 91.2286s / 153937.6926 s
env0_first_0:                 episode reward: -51.9000,                 loss: 29.8971
env0_second_0:                 episode reward: 51.9000,                 loss: 31.5631
env1_first_0:                 episode reward: -50.3500,                 loss: nan
env1_second_0:                 episode reward: 50.3500,                 loss: nan
Episode: 18341/30000 (61.1367%),                 avg. length: 663.65,                last time consumption/overall running time: 99.2017s / 154036.8942 s
env0_first_0:                 episode reward: -56.1000,                 loss: 16.5809
env0_second_0:                 episode reward: 56.1000,                 loss: 20.0582
env1_first_0:                 episode reward: -60.7000,                 loss: nan
env1_second_0:                 episode reward: 60.7000,                 loss: nan
Episode: 18361/30000 (61.2033%),                 avg. length: 550.7,                last time consumption/overall running time: 82.2964s / 154119.1907 s
env0_first_0:                 episode reward: -63.6500,                 loss: 17.3963
env0_second_0:                 episode reward: 63.6500,                 loss: 21.8846
env1_first_0:                 episode reward: -78.7500,                 loss: nan
env1_second_0:                 episode reward: 78.7500,                 loss: nan
Episode: 18381/30000 (61.2700%),                 avg. length: 895.1,                last time consumption/overall running time: 124.9867s / 154244.1773 s
env0_first_0:                 episode reward: -56.2500,                 loss: 14.4953
env0_second_0:                 episode reward: 56.2500,                 loss: 18.6445
env1_first_0:                 episode reward: -37.6000,                 loss: nan
env1_second_0:                 episode reward: 37.6000,                 loss: nan
Episode: 18401/30000 (61.3367%),                 avg. length: 1553.6,                last time consumption/overall running time: 214.5366s / 154458.7139 s
env0_first_0:                 episode reward: 14.9500,                 loss: 6.5496
env0_second_0:                 episode reward: -14.9500,                 loss: 9.7789
env1_first_0:                 episode reward: 26.0500,                 loss: nan
env1_second_0:                 episode reward: -26.0500,                 loss: nan
Episode: 18421/30000 (61.4033%),                 avg. length: 1562.45,                last time consumption/overall running time: 217.1345s / 154675.8484 s
env0_first_0:                 episode reward: 29.9000,                 loss: 4.3726
env0_second_0:                 episode reward: -29.9000,                 loss: 6.9274
env1_first_0:                 episode reward: 21.7500,                 loss: nan
env1_second_0:                 episode reward: -21.7500,                 loss: nan
Episode: 18441/30000 (61.4700%),                 avg. length: 1784.0,                last time consumption/overall running time: 251.7958s / 154927.6443 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.3358
env0_second_0:                 episode reward: 0.7500,                 loss: 2.3421
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 18461/30000 (61.5367%),                 avg. length: 1784.0,                last time consumption/overall running time: 251.7254s / 155179.3696 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0633
env0_second_0:                 episode reward: -0.3000,                 loss: 2.2798
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 18481/30000 (61.6033%),                 avg. length: 1784.0,                last time consumption/overall running time: 248.1587s / 155427.5283 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0247
env0_second_0:                 episode reward: 0.0000,                 loss: 1.6491
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 18501/30000 (61.6700%),                 avg. length: 1784.0,                last time consumption/overall running time: 258.4023s / 155685.9306 s
env0_first_0:                 episode reward: 0.3000,                 loss: -0.0013
env0_second_0:                 episode reward: -0.3000,                 loss: 1.5420
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 18521/30000 (61.7367%),                 avg. length: 1784.0,                last time consumption/overall running time: 241.0320s / 155926.9626 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0508
env0_second_0:                 episode reward: 0.0000,                 loss: 1.8117
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 18541/30000 (61.8033%),                 avg. length: 1784.0,                last time consumption/overall running time: 242.5549s / 156169.5175 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.0196
env0_second_0:                 episode reward: 0.1000,                 loss: 1.9582
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 18561/30000 (61.8700%),                 avg. length: 1784.0,                last time consumption/overall running time: 250.6495s / 156420.1670 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0609
env0_second_0:                 episode reward: -0.2000,                 loss: 1.7767
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 18581/30000 (61.9367%),                 avg. length: 1784.0,                last time consumption/overall running time: 242.7060s / 156662.8730 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.0852
env0_second_0:                 episode reward: -1.1500,                 loss: 1.1515
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 18601/30000 (62.0033%),                 avg. length: 1784.0,                last time consumption/overall running time: 238.1033s / 156900.9763 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0283
env0_second_0:                 episode reward: 0.9000,                 loss: 1.0190
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 18621/30000 (62.0700%),                 avg. length: 1784.0,                last time consumption/overall running time: 243.8399s / 157144.8163 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0518
env0_second_0:                 episode reward: -0.2500,                 loss: 0.8790
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 18641/30000 (62.1367%),                 avg. length: 1784.0,                last time consumption/overall running time: 248.1252s / 157392.9415 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0704
env0_second_0:                 episode reward: 0.7500,                 loss: 1.4132
env1_first_0:                 episode reward: -2.3500,                 loss: nan
env1_second_0:                 episode reward: 2.3500,                 loss: nan
Episode: 18661/30000 (62.2033%),                 avg. length: 1784.0,                last time consumption/overall running time: 251.3924s / 157644.3339 s
env0_first_0:                 episode reward: -0.6000,                 loss: -0.0048
env0_second_0:                 episode reward: 0.6000,                 loss: 1.4704
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 18681/30000 (62.2700%),                 avg. length: 1784.0,                last time consumption/overall running time: 254.6870s / 157899.0208 s
env0_first_0:                 episode reward: 0.7000,                 loss: -0.1046
env0_second_0:                 episode reward: -0.7000,                 loss: 1.4189
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 18701/30000 (62.3367%),                 avg. length: 1784.0,                last time consumption/overall running time: 248.1672s / 158147.1880 s
env0_first_0:                 episode reward: -0.9000,                 loss: -0.0830
env0_second_0:                 episode reward: 0.9000,                 loss: 1.2830
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 18721/30000 (62.4033%),                 avg. length: 1784.0,                last time consumption/overall running time: 247.0822s / 158394.2702 s
env0_first_0:                 episode reward: 0.1500,                 loss: -0.1083
env0_second_0:                 episode reward: -0.1500,                 loss: 1.2609
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 18741/30000 (62.4700%),                 avg. length: 1784.0,                last time consumption/overall running time: 259.3322s / 158653.6024 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0683
env0_second_0:                 episode reward: 0.0000,                 loss: 1.4903
env1_first_0:                 episode reward: -1.8500,                 loss: nan
env1_second_0:                 episode reward: 1.8500,                 loss: nan
Episode: 18761/30000 (62.5367%),                 avg. length: 1784.0,                last time consumption/overall running time: 243.7937s / 158897.3961 s
env0_first_0:                 episode reward: 0.4500,                 loss: -0.0723
env0_second_0:                 episode reward: -0.4500,                 loss: 1.1104
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 18781/30000 (62.6033%),                 avg. length: 1784.0,                last time consumption/overall running time: 256.1752s / 159153.5713 s
env0_first_0:                 episode reward: -0.7000,                 loss: -0.0916
env0_second_0:                 episode reward: 0.7000,                 loss: 0.9090
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 18801/30000 (62.6700%),                 avg. length: 1784.0,                last time consumption/overall running time: 251.0552s / 159404.6265 s
env0_first_0:                 episode reward: -0.7500,                 loss: -0.1059
env0_second_0:                 episode reward: 0.7500,                 loss: 0.9161
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 18821/30000 (62.7367%),                 avg. length: 1784.0,                last time consumption/overall running time: 253.7683s / 159658.3949 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.1580
env0_second_0:                 episode reward: 0.1000,                 loss: 1.0090
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 18841/30000 (62.8033%),                 avg. length: 1784.0,                last time consumption/overall running time: 236.0126s / 159894.4074 s
env0_first_0:                 episode reward: 0.4000,                 loss: -0.1911
env0_second_0:                 episode reward: -0.4000,                 loss: 1.0162
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 18861/30000 (62.8700%),                 avg. length: 1784.0,                last time consumption/overall running time: 248.0148s / 160142.4223 s
env0_first_0:                 episode reward: 1.4500,                 loss: -0.1211
env0_second_0:                 episode reward: -1.4500,                 loss: 1.4804
env1_first_0:                 episode reward: 1.6500,                 loss: nan
env1_second_0:                 episode reward: -1.6500,                 loss: nan
Episode: 18881/30000 (62.9367%),                 avg. length: 1784.0,                last time consumption/overall running time: 252.8340s / 160395.2563 s
env0_first_0:                 episode reward: -1.2000,                 loss: -0.1905
env0_second_0:                 episode reward: 1.2000,                 loss: 2.6232
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 18901/30000 (63.0033%),                 avg. length: 1784.0,                last time consumption/overall running time: 251.0532s / 160646.3095 s
env0_first_0:                 episode reward: -2.8000,                 loss: -0.1590
env0_second_0:                 episode reward: 2.8000,                 loss: 2.2456
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 18921/30000 (63.0700%),                 avg. length: 1784.0,                last time consumption/overall running time: 255.2234s / 160901.5329 s
env0_first_0:                 episode reward: -1.9500,                 loss: -0.2261
env0_second_0:                 episode reward: 1.9500,                 loss: 1.9448
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 18941/30000 (63.1367%),                 avg. length: 1784.0,                last time consumption/overall running time: 256.0265s / 161157.5594 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.2911
env0_second_0:                 episode reward: 0.1500,                 loss: 1.3933
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 18961/30000 (63.2033%),                 avg. length: 1784.0,                last time consumption/overall running time: 250.9454s / 161408.5048 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2782
env0_second_0:                 episode reward: 0.0000,                 loss: 1.6319
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 18981/30000 (63.2700%),                 avg. length: 1784.0,                last time consumption/overall running time: 240.7316s / 161649.2364 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.3034
env0_second_0:                 episode reward: -0.0500,                 loss: 1.6669
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 19001/30000 (63.3367%),                 avg. length: 1784.0,                last time consumption/overall running time: 248.3116s / 161897.5480 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.3146
env0_second_0:                 episode reward: 0.0500,                 loss: 1.8675
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 19021/30000 (63.4033%),                 avg. length: 1784.0,                last time consumption/overall running time: 251.8992s / 162149.4472 s
env0_first_0:                 episode reward: -0.9000,                 loss: -0.3032
env0_second_0:                 episode reward: 0.9000,                 loss: 3.9917
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 19041/30000 (63.4700%),                 avg. length: 1784.0,                last time consumption/overall running time: 247.4314s / 162396.8786 s
env0_first_0:                 episode reward: -0.2500,                 loss: -0.3286
env0_second_0:                 episode reward: 0.2500,                 loss: 3.5742
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 19061/30000 (63.5367%),                 avg. length: 1784.0,                last time consumption/overall running time: 243.5382s / 162640.4168 s
env0_first_0:                 episode reward: -0.4000,                 loss: -0.3104
env0_second_0:                 episode reward: 0.4000,                 loss: 1.1429
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 19081/30000 (63.6033%),                 avg. length: 1784.0,                last time consumption/overall running time: 234.6852s / 162875.1020 s
env0_first_0:                 episode reward: -0.5000,                 loss: -0.3312
env0_second_0:                 episode reward: 0.5000,                 loss: 1.7585
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 19101/30000 (63.6700%),                 avg. length: 1784.0,                last time consumption/overall running time: 243.0033s / 163118.1053 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.3630
env0_second_0:                 episode reward: -0.1000,                 loss: 3.6794
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 19121/30000 (63.7367%),                 avg. length: 1784.0,                last time consumption/overall running time: 239.5430s / 163357.6483 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.3730
env0_second_0:                 episode reward: -0.0500,                 loss: 3.1775
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 19141/30000 (63.8033%),                 avg. length: 1784.0,                last time consumption/overall running time: 244.4800s / 163602.1284 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.3687
env0_second_0:                 episode reward: 0.0000,                 loss: 4.1281
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 19161/30000 (63.8700%),                 avg. length: 1784.0,                last time consumption/overall running time: 245.9824s / 163848.1108 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.3387
env0_second_0:                 episode reward: 0.0000,                 loss: 3.7006
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 19181/30000 (63.9367%),                 avg. length: 1784.0,                last time consumption/overall running time: 244.5365s / 164092.6473 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.3568
env0_second_0:                 episode reward: -0.1000,                 loss: 3.7939
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 19201/30000 (64.0033%),                 avg. length: 1784.0,                last time consumption/overall running time: 246.4250s / 164339.0723 s
env0_first_0:                 episode reward: -1.1000,                 loss: -0.3138
env0_second_0:                 episode reward: 1.1000,                 loss: 4.5450
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 19221/30000 (64.0700%),                 avg. length: 1784.0,                last time consumption/overall running time: 248.5129s / 164587.5852 s
env0_first_0:                 episode reward: -2.4000,                 loss: -0.1314
env0_second_0:                 episode reward: 2.4000,                 loss: 2.0666
env1_first_0:                 episode reward: -2.2000,                 loss: nan
env1_second_0:                 episode reward: 2.2000,                 loss: nan
Episode: 19241/30000 (64.1367%),                 avg. length: 1784.0,                last time consumption/overall running time: 241.8456s / 164829.4308 s
env0_first_0:                 episode reward: -1.6000,                 loss: -0.1571
env0_second_0:                 episode reward: 1.6000,                 loss: 3.2883
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 19261/30000 (64.2033%),                 avg. length: 1650.8,                last time consumption/overall running time: 224.7930s / 165054.2238 s
env0_first_0:                 episode reward: -14.6500,                 loss: 2.4307
env0_second_0:                 episode reward: 14.6500,                 loss: 5.3460
env1_first_0:                 episode reward: -12.8500,                 loss: nan
env1_second_0:                 episode reward: 12.8500,                 loss: nan
Episode: 19281/30000 (64.2700%),                 avg. length: 1082.9,                last time consumption/overall running time: 147.9896s / 165202.2134 s
env0_first_0:                 episode reward: -34.6000,                 loss: 8.3485
env0_second_0:                 episode reward: 34.6000,                 loss: 12.2641
env1_first_0:                 episode reward: -35.8500,                 loss: nan
env1_second_0:                 episode reward: 35.8500,                 loss: nan
Episode: 19301/30000 (64.3367%),                 avg. length: 740.6,                last time consumption/overall running time: 104.7631s / 165306.9766 s
env0_first_0:                 episode reward: -54.5000,                 loss: 14.9229
env0_second_0:                 episode reward: 54.5000,                 loss: 18.2588
env1_first_0:                 episode reward: -57.0500,                 loss: nan
env1_second_0:                 episode reward: 57.0500,                 loss: nan
Episode: 19321/30000 (64.4033%),                 avg. length: 564.35,                last time consumption/overall running time: 89.8379s / 165396.8145 s
env0_first_0:                 episode reward: -67.9500,                 loss: 21.8788
env0_second_0:                 episode reward: 67.9500,                 loss: 24.7418
env1_first_0:                 episode reward: -61.2000,                 loss: nan
env1_second_0:                 episode reward: 61.2000,                 loss: nan
Episode: 19341/30000 (64.4700%),                 avg. length: 386.0,                last time consumption/overall running time: 64.9085s / 165461.7230 s
env0_first_0:                 episode reward: -76.9000,                 loss: 33.7470
env0_second_0:                 episode reward: 76.9000,                 loss: 37.9128
env1_first_0:                 episode reward: -72.2500,                 loss: nan
env1_second_0:                 episode reward: 72.2500,                 loss: nan
Episode: 19361/30000 (64.5367%),                 avg. length: 363.65,                last time consumption/overall running time: 54.2533s / 165515.9763 s
env0_first_0:                 episode reward: -76.8000,                 loss: 33.9878
env0_second_0:                 episode reward: 76.8000,                 loss: 40.1603
env1_first_0:                 episode reward: -76.0500,                 loss: nan
env1_second_0:                 episode reward: 76.0500,                 loss: nan
Episode: 19381/30000 (64.6033%),                 avg. length: 424.2,                last time consumption/overall running time: 64.4826s / 165580.4589 s
env0_first_0:                 episode reward: -71.7000,                 loss: 27.8571
env0_second_0:                 episode reward: 71.7000,                 loss: 32.7445
env1_first_0:                 episode reward: -75.9500,                 loss: nan
env1_second_0:                 episode reward: 75.9500,                 loss: nan
Episode: 19401/30000 (64.6700%),                 avg. length: 386.6,                last time consumption/overall running time: 60.3070s / 165640.7659 s
env0_first_0:                 episode reward: -78.9000,                 loss: 30.1074
env0_second_0:                 episode reward: 78.9000,                 loss: 34.3808
env1_first_0:                 episode reward: -60.4500,                 loss: nan
env1_second_0:                 episode reward: 60.4500,                 loss: nan
Episode: 19421/30000 (64.7367%),                 avg. length: 306.7,                last time consumption/overall running time: 50.7880s / 165691.5539 s
env0_first_0:                 episode reward: -76.5000,                 loss: 33.4735
env0_second_0:                 episode reward: 76.5000,                 loss: 38.0567
env1_first_0:                 episode reward: -78.4500,                 loss: nan
env1_second_0:                 episode reward: 78.4500,                 loss: nan
Episode: 19441/30000 (64.8033%),                 avg. length: 309.05,                last time consumption/overall running time: 51.2148s / 165742.7687 s
env0_first_0:                 episode reward: -74.7500,                 loss: 35.6567
env0_second_0:                 episode reward: 74.7500,                 loss: 41.7555
env1_first_0:                 episode reward: -84.6500,                 loss: nan
env1_second_0:                 episode reward: 84.6500,                 loss: nan
Episode: 19461/30000 (64.8700%),                 avg. length: 316.45,                last time consumption/overall running time: 48.0748s / 165790.8435 s
env0_first_0:                 episode reward: -83.6500,                 loss: 29.0148
env0_second_0:                 episode reward: 83.6500,                 loss: 34.0752
env1_first_0:                 episode reward: -77.4500,                 loss: nan
env1_second_0:                 episode reward: 77.4500,                 loss: nan
Episode: 19481/30000 (64.9367%),                 avg. length: 281.85,                last time consumption/overall running time: 47.9333s / 165838.7769 s
env0_first_0:                 episode reward: -83.5500,                 loss: 32.6611
env0_second_0:                 episode reward: 83.5500,                 loss: 37.3584
env1_first_0:                 episode reward: -85.2000,                 loss: nan
env1_second_0:                 episode reward: 85.2000,                 loss: nan
Episode: 19501/30000 (65.0033%),                 avg. length: 338.5,                last time consumption/overall running time: 52.8018s / 165891.5787 s
env0_first_0:                 episode reward: -73.0000,                 loss: 28.2280
env0_second_0:                 episode reward: 73.0000,                 loss: 32.1558
env1_first_0:                 episode reward: -78.1000,                 loss: nan
env1_second_0:                 episode reward: 78.1000,                 loss: nan
Episode: 19521/30000 (65.0700%),                 avg. length: 294.7,                last time consumption/overall running time: 45.3923s / 165936.9709 s
env0_first_0:                 episode reward: -85.2000,                 loss: 31.2743
env0_second_0:                 episode reward: 85.2000,                 loss: 36.1120
env1_first_0:                 episode reward: -78.0000,                 loss: nan
env1_second_0:                 episode reward: 78.0000,                 loss: nan
Episode: 19541/30000 (65.1367%),                 avg. length: 318.3,                last time consumption/overall running time: 52.2335s / 165989.2044 s
env0_first_0:                 episode reward: -68.0000,                 loss: 31.0574
env0_second_0:                 episode reward: 68.0000,                 loss: 35.3750
env1_first_0:                 episode reward: -90.3500,                 loss: nan
env1_second_0:                 episode reward: 90.3500,                 loss: nan
Episode: 19561/30000 (65.2033%),                 avg. length: 398.8,                last time consumption/overall running time: 57.8242s / 166047.0286 s
env0_first_0:                 episode reward: -77.4000,                 loss: 29.9341
env0_second_0:                 episode reward: 77.4000,                 loss: 34.0352
env1_first_0:                 episode reward: -71.8000,                 loss: nan
env1_second_0:                 episode reward: 71.8000,                 loss: nan
Episode: 19581/30000 (65.2700%),                 avg. length: 360.9,                last time consumption/overall running time: 54.4796s / 166101.5082 s
env0_first_0:                 episode reward: -76.0000,                 loss: 33.5533
env0_second_0:                 episode reward: 76.0000,                 loss: 38.1434
env1_first_0:                 episode reward: -80.7500,                 loss: nan
env1_second_0:                 episode reward: 80.7500,                 loss: nan
Episode: 19601/30000 (65.3367%),                 avg. length: 333.05,                last time consumption/overall running time: 54.0099s / 166155.5181 s
env0_first_0:                 episode reward: -73.0500,                 loss: 43.7643
env0_second_0:                 episode reward: 73.0500,                 loss: 49.1901
env1_first_0:                 episode reward: -73.5000,                 loss: nan
env1_second_0:                 episode reward: 73.5000,                 loss: nan
Episode: 19621/30000 (65.4033%),                 avg. length: 315.2,                last time consumption/overall running time: 49.2765s / 166204.7947 s
env0_first_0:                 episode reward: -79.5000,                 loss: 34.9637
env0_second_0:                 episode reward: 79.5000,                 loss: 41.5028
env1_first_0:                 episode reward: -76.2500,                 loss: nan
env1_second_0:                 episode reward: 76.2500,                 loss: nan
Episode: 19641/30000 (65.4700%),                 avg. length: 272.2,                last time consumption/overall running time: 42.8955s / 166247.6901 s
env0_first_0:                 episode reward: -90.1500,                 loss: 33.1961
env0_second_0:                 episode reward: 90.1500,                 loss: 34.2058
env1_first_0:                 episode reward: -77.5000,                 loss: nan
env1_second_0:                 episode reward: 77.5000,                 loss: nan
Episode: 19661/30000 (65.5367%),                 avg. length: 290.75,                last time consumption/overall running time: 46.2461s / 166293.9363 s
env0_first_0:                 episode reward: -79.2500,                 loss: 34.2071
env0_second_0:                 episode reward: 79.2500,                 loss: 39.0524
env1_first_0:                 episode reward: -80.5500,                 loss: nan
env1_second_0:                 episode reward: 80.5500,                 loss: nan
Episode: 19681/30000 (65.6033%),                 avg. length: 294.35,                last time consumption/overall running time: 52.7982s / 166346.7344 s
env0_first_0:                 episode reward: -75.6500,                 loss: 38.4225
env0_second_0:                 episode reward: 75.6500,                 loss: 42.0579
env1_first_0:                 episode reward: -79.2500,                 loss: nan
env1_second_0:                 episode reward: 79.2500,                 loss: nan
Episode: 19701/30000 (65.6700%),                 avg. length: 1642.85,                last time consumption/overall running time: 234.2912s / 166581.0256 s
env0_first_0:                 episode reward: -15.1000,                 loss: 10.1709
env0_second_0:                 episode reward: 15.1000,                 loss: 13.1972
env1_first_0:                 episode reward: -9.7000,                 loss: nan
env1_second_0:                 episode reward: 9.7000,                 loss: nan
Episode: 19721/30000 (65.7367%),                 avg. length: 1784.0,                last time consumption/overall running time: 244.0480s / 166825.0736 s
env0_first_0:                 episode reward: -6.2500,                 loss: 1.2500
env0_second_0:                 episode reward: 6.2500,                 loss: 4.1287
env1_first_0:                 episode reward: -5.2500,                 loss: nan
env1_second_0:                 episode reward: 5.2500,                 loss: nan
Episode: 19741/30000 (65.8033%),                 avg. length: 1627.0,                last time consumption/overall running time: 241.5861s / 167066.6597 s
env0_first_0:                 episode reward: -11.8000,                 loss: 4.2513
env0_second_0:                 episode reward: 11.8000,                 loss: 8.6804
env1_first_0:                 episode reward: -12.6500,                 loss: nan
env1_second_0:                 episode reward: 12.6500,                 loss: nan
Episode: 19761/30000 (65.8700%),                 avg. length: 821.95,                last time consumption/overall running time: 117.3843s / 167184.0440 s
env0_first_0:                 episode reward: -53.6500,                 loss: 29.1951
env0_second_0:                 episode reward: 53.6500,                 loss: 31.4276
env1_first_0:                 episode reward: -53.3000,                 loss: nan
env1_second_0:                 episode reward: 53.3000,                 loss: nan
Episode: 19781/30000 (65.9367%),                 avg. length: 375.5,                last time consumption/overall running time: 55.8733s / 167239.9174 s
env0_first_0:                 episode reward: -78.5500,                 loss: 34.5198
env0_second_0:                 episode reward: 78.5500,                 loss: 39.2555
env1_first_0:                 episode reward: -70.6000,                 loss: nan
env1_second_0:                 episode reward: 70.6000,                 loss: nan
Episode: 19801/30000 (66.0033%),                 avg. length: 728.75,                last time consumption/overall running time: 101.9053s / 167341.8226 s
env0_first_0:                 episode reward: -23.8000,                 loss: 23.2361
env0_second_0:                 episode reward: 23.8000,                 loss: 29.7618
env1_first_0:                 episode reward: -58.6000,                 loss: nan
env1_second_0:                 episode reward: 58.6000,                 loss: nan
Episode: 19821/30000 (66.0700%),                 avg. length: 1384.8,                last time consumption/overall running time: 194.7302s / 167536.5528 s
env0_first_0:                 episode reward: -9.2000,                 loss: 6.8273
env0_second_0:                 episode reward: 9.2000,                 loss: 10.7014
env1_first_0:                 episode reward: -15.6500,                 loss: nan
env1_second_0:                 episode reward: 15.6500,                 loss: nan
Episode: 19841/30000 (66.1367%),                 avg. length: 1075.1,                last time consumption/overall running time: 143.1110s / 167679.6638 s
env0_first_0:                 episode reward: -20.7500,                 loss: 15.8941
env0_second_0:                 episode reward: 20.7500,                 loss: 20.0137
env1_first_0:                 episode reward: -32.1000,                 loss: nan
env1_second_0:                 episode reward: 32.1000,                 loss: nan
Episode: 19861/30000 (66.2033%),                 avg. length: 982.55,                last time consumption/overall running time: 139.9359s / 167819.5997 s
env0_first_0:                 episode reward: -22.8500,                 loss: 16.9527
env0_second_0:                 episode reward: 22.8500,                 loss: 20.0622
env1_first_0:                 episode reward: -36.1500,                 loss: nan
env1_second_0:                 episode reward: 36.1500,                 loss: nan
Episode: 19881/30000 (66.2700%),                 avg. length: 1305.85,                last time consumption/overall running time: 175.3684s / 167994.9681 s
env0_first_0:                 episode reward: -19.8000,                 loss: 10.8554
env0_second_0:                 episode reward: 19.8000,                 loss: 13.7035
env1_first_0:                 episode reward: -18.3500,                 loss: nan
env1_second_0:                 episode reward: 18.3500,                 loss: nan
Episode: 19901/30000 (66.3367%),                 avg. length: 1048.9,                last time consumption/overall running time: 144.5038s / 168139.4719 s
env0_first_0:                 episode reward: -33.4500,                 loss: 10.8855
env0_second_0:                 episode reward: 33.4500,                 loss: 13.5541
env1_first_0:                 episode reward: -39.1000,                 loss: nan
env1_second_0:                 episode reward: 39.1000,                 loss: nan
Episode: 19921/30000 (66.4033%),                 avg. length: 1074.05,                last time consumption/overall running time: 142.2124s / 168281.6843 s
env0_first_0:                 episode reward: -31.5500,                 loss: 14.1964
env0_second_0:                 episode reward: 31.5500,                 loss: 16.2528
env1_first_0:                 episode reward: -41.6500,                 loss: nan
env1_second_0:                 episode reward: 41.6500,                 loss: nan
Episode: 19941/30000 (66.4700%),                 avg. length: 1440.15,                last time consumption/overall running time: 191.4616s / 168473.1459 s
env0_first_0:                 episode reward: -12.0500,                 loss: 7.1225
env0_second_0:                 episode reward: 12.0500,                 loss: 9.2065
env1_first_0:                 episode reward: -11.2000,                 loss: nan
env1_second_0:                 episode reward: 11.2000,                 loss: nan
Episode: 19961/30000 (66.5367%),                 avg. length: 1551.1,                last time consumption/overall running time: 208.3169s / 168681.4628 s
env0_first_0:                 episode reward: -15.3500,                 loss: 3.6213
env0_second_0:                 episode reward: 15.3500,                 loss: 6.1287
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 19981/30000 (66.6033%),                 avg. length: 1112.6,                last time consumption/overall running time: 153.2933s / 168834.7561 s
env0_first_0:                 episode reward: -20.9500,                 loss: 12.7155
env0_second_0:                 episode reward: 20.9500,                 loss: 15.4849
env1_first_0:                 episode reward: -24.6000,                 loss: nan
env1_second_0:                 episode reward: 24.6000,                 loss: nan
Episode: 20001/30000 (66.6700%),                 avg. length: 456.85,                last time consumption/overall running time: 66.0372s / 168900.7933 s
env0_first_0:                 episode reward: -65.2000,                 loss: 28.1369
env0_second_0:                 episode reward: 65.2000,                 loss: 33.6834
env1_first_0:                 episode reward: -69.8500,                 loss: nan
env1_second_0:                 episode reward: 69.8500,                 loss: nan
Episode: 20021/30000 (66.7367%),                 avg. length: 371.7,                last time consumption/overall running time: 58.5061s / 168959.2994 s
env0_first_0:                 episode reward: -70.9000,                 loss: 32.7003
env0_second_0:                 episode reward: 70.9000,                 loss: 40.3423
env1_first_0:                 episode reward: -72.1500,                 loss: nan
env1_second_0:                 episode reward: 72.1500,                 loss: nan
Episode: 20041/30000 (66.8033%),                 avg. length: 426.2,                last time consumption/overall running time: 65.0144s / 169024.3138 s
env0_first_0:                 episode reward: -63.5000,                 loss: 38.6532
env0_second_0:                 episode reward: 63.5000,                 loss: 43.6933
env1_first_0:                 episode reward: -79.1500,                 loss: nan
env1_second_0:                 episode reward: 79.1500,                 loss: nan
Episode: 20061/30000 (66.8700%),                 avg. length: 416.1,                last time consumption/overall running time: 66.1754s / 169090.4892 s
env0_first_0:                 episode reward: -67.9000,                 loss: 28.3337
env0_second_0:                 episode reward: 67.9000,                 loss: 36.2583
env1_first_0:                 episode reward: -72.7500,                 loss: nan
env1_second_0:                 episode reward: 72.7500,                 loss: nan
Episode: 20081/30000 (66.9367%),                 avg. length: 405.4,                last time consumption/overall running time: 61.3238s / 169151.8130 s
env0_first_0:                 episode reward: -78.3500,                 loss: 30.4215
env0_second_0:                 episode reward: 78.3500,                 loss: 33.1403
env1_first_0:                 episode reward: -78.7500,                 loss: nan
env1_second_0:                 episode reward: 78.7500,                 loss: nan
Episode: 20101/30000 (67.0033%),                 avg. length: 343.35,                last time consumption/overall running time: 50.6980s / 169202.5109 s
env0_first_0:                 episode reward: -70.0000,                 loss: 34.5353
env0_second_0:                 episode reward: 70.0000,                 loss: 38.8435
env1_first_0:                 episode reward: -73.1000,                 loss: nan
env1_second_0:                 episode reward: 73.1000,                 loss: nan
Episode: 20121/30000 (67.0700%),                 avg. length: 877.6,                last time consumption/overall running time: 120.8337s / 169323.3447 s
env0_first_0:                 episode reward: -38.2000,                 loss: 25.0280
env0_second_0:                 episode reward: 38.2000,                 loss: 28.0089
env1_first_0:                 episode reward: -54.6000,                 loss: nan
env1_second_0:                 episode reward: 54.6000,                 loss: nan
Episode: 20141/30000 (67.1367%),                 avg. length: 415.8,                last time consumption/overall running time: 62.8415s / 169386.1862 s
env0_first_0:                 episode reward: -69.6500,                 loss: 32.1912
env0_second_0:                 episode reward: 69.6500,                 loss: 35.8148
env1_first_0:                 episode reward: -61.3500,                 loss: nan
env1_second_0:                 episode reward: 61.3500,                 loss: nan
Episode: 20161/30000 (67.2033%),                 avg. length: 442.4,                last time consumption/overall running time: 64.5659s / 169450.7521 s
env0_first_0:                 episode reward: -68.0500,                 loss: 33.3141
env0_second_0:                 episode reward: 68.0500,                 loss: 36.1090
env1_first_0:                 episode reward: -63.8500,                 loss: nan
env1_second_0:                 episode reward: 63.8500,                 loss: nan
Episode: 20181/30000 (67.2700%),                 avg. length: 352.05,                last time consumption/overall running time: 52.1297s / 169502.8818 s
env0_first_0:                 episode reward: -66.9000,                 loss: 38.2841
env0_second_0:                 episode reward: 66.9000,                 loss: 40.1259
env1_first_0:                 episode reward: -73.0000,                 loss: nan
env1_second_0:                 episode reward: 73.0000,                 loss: nan
Episode: 20201/30000 (67.3367%),                 avg. length: 359.6,                last time consumption/overall running time: 53.8227s / 169556.7045 s
env0_first_0:                 episode reward: -66.7500,                 loss: 37.5995
env0_second_0:                 episode reward: 66.7500,                 loss: 41.2773
env1_first_0:                 episode reward: -79.3000,                 loss: nan
env1_second_0:                 episode reward: 79.3000,                 loss: nan
Episode: 20221/30000 (67.4033%),                 avg. length: 284.85,                last time consumption/overall running time: 44.9150s / 169601.6195 s
env0_first_0:                 episode reward: -75.7000,                 loss: 34.5562
env0_second_0:                 episode reward: 75.7000,                 loss: 37.7379
env1_first_0:                 episode reward: -75.0000,                 loss: nan
env1_second_0:                 episode reward: 75.0000,                 loss: nan
Episode: 20241/30000 (67.4700%),                 avg. length: 1252.35,                last time consumption/overall running time: 159.3599s / 169760.9794 s
env0_first_0:                 episode reward: -27.2000,                 loss: 15.0877
env0_second_0:                 episode reward: 27.2000,                 loss: 16.9054
env1_first_0:                 episode reward: -27.2000,                 loss: nan
env1_second_0:                 episode reward: 27.2000,                 loss: nan
Episode: 20261/30000 (67.5367%),                 avg. length: 1026.6,                last time consumption/overall running time: 146.3389s / 169907.3182 s
env0_first_0:                 episode reward: -56.6500,                 loss: 23.5314
env0_second_0:                 episode reward: 56.6500,                 loss: 23.6991
env1_first_0:                 episode reward: -50.1000,                 loss: nan
env1_second_0:                 episode reward: 50.1000,                 loss: nan
Episode: 20281/30000 (67.6033%),                 avg. length: 474.3,                last time consumption/overall running time: 73.4692s / 169980.7874 s
env0_first_0:                 episode reward: -58.9000,                 loss: 30.3799
env0_second_0:                 episode reward: 58.9000,                 loss: 34.4047
env1_first_0:                 episode reward: -67.7500,                 loss: nan
env1_second_0:                 episode reward: 67.7500,                 loss: nan
Episode: 20301/30000 (67.6700%),                 avg. length: 1784.0,                last time consumption/overall running time: 256.8709s / 170237.6583 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.9831
env0_second_0:                 episode reward: -0.5500,                 loss: 2.6470
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 20321/30000 (67.7367%),                 avg. length: 1784.0,                last time consumption/overall running time: 255.8509s / 170493.5092 s
env0_first_0:                 episode reward: -0.5000,                 loss: 2.1039
env0_second_0:                 episode reward: 0.5000,                 loss: 4.4976
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 20341/30000 (67.8033%),                 avg. length: 691.15,                last time consumption/overall running time: 103.1405s / 170596.6497 s
env0_first_0:                 episode reward: -50.9000,                 loss: 24.3461
env0_second_0:                 episode reward: 50.9000,                 loss: 28.3020
env1_first_0:                 episode reward: -56.0000,                 loss: nan
env1_second_0:                 episode reward: 56.0000,                 loss: nan
Episode: 20361/30000 (67.8700%),                 avg. length: 395.25,                last time consumption/overall running time: 62.7601s / 170659.4097 s
env0_first_0:                 episode reward: -68.2000,                 loss: 35.5468
env0_second_0:                 episode reward: 68.2000,                 loss: 40.6532
env1_first_0:                 episode reward: -70.2500,                 loss: nan
env1_second_0:                 episode reward: 70.2500,                 loss: nan
Episode: 20381/30000 (67.9367%),                 avg. length: 369.6,                last time consumption/overall running time: 59.6915s / 170719.1012 s
env0_first_0:                 episode reward: -67.2000,                 loss: 38.9800
env0_second_0:                 episode reward: 67.2000,                 loss: 43.3031
env1_first_0:                 episode reward: -62.2500,                 loss: nan
env1_second_0:                 episode reward: 62.2500,                 loss: nan
Episode: 20401/30000 (68.0033%),                 avg. length: 713.35,                last time consumption/overall running time: 108.7491s / 170827.8503 s
env0_first_0:                 episode reward: -59.2500,                 loss: 29.7713
env0_second_0:                 episode reward: 59.2500,                 loss: 32.1236
env1_first_0:                 episode reward: -58.8000,                 loss: nan
env1_second_0:                 episode reward: 58.8000,                 loss: nan
Episode: 20421/30000 (68.0700%),                 avg. length: 460.8,                last time consumption/overall running time: 73.9316s / 170901.7819 s
env0_first_0:                 episode reward: -59.0000,                 loss: 29.2295
env0_second_0:                 episode reward: 59.0000,                 loss: 34.0714
env1_first_0:                 episode reward: -71.4500,                 loss: nan
env1_second_0:                 episode reward: 71.4500,                 loss: nan
Episode: 20441/30000 (68.1367%),                 avg. length: 589.45,                last time consumption/overall running time: 92.5873s / 170994.3692 s
env0_first_0:                 episode reward: -55.5500,                 loss: 30.0647
env0_second_0:                 episode reward: 55.5500,                 loss: 35.3449
env1_first_0:                 episode reward: -63.0500,                 loss: nan
env1_second_0:                 episode reward: 63.0500,                 loss: nan
Episode: 20461/30000 (68.2033%),                 avg. length: 645.55,                last time consumption/overall running time: 101.8380s / 171096.2072 s
env0_first_0:                 episode reward: -67.2000,                 loss: 22.4204
env0_second_0:                 episode reward: 67.2000,                 loss: 26.0473
env1_first_0:                 episode reward: -67.4500,                 loss: nan
env1_second_0:                 episode reward: 67.4500,                 loss: nan
Episode: 20481/30000 (68.2700%),                 avg. length: 550.4,                last time consumption/overall running time: 83.5520s / 171179.7592 s
env0_first_0:                 episode reward: -69.7000,                 loss: 27.5390
env0_second_0:                 episode reward: 69.7000,                 loss: 30.1379
env1_first_0:                 episode reward: -63.2000,                 loss: nan
env1_second_0:                 episode reward: 63.2000,                 loss: nan
Episode: 20501/30000 (68.3367%),                 avg. length: 581.85,                last time consumption/overall running time: 90.4763s / 171270.2355 s
env0_first_0:                 episode reward: -66.1000,                 loss: 39.0041
env0_second_0:                 episode reward: 66.1000,                 loss: 40.5651
env1_first_0:                 episode reward: -66.0000,                 loss: nan
env1_second_0:                 episode reward: 66.0000,                 loss: nan
Episode: 20521/30000 (68.4033%),                 avg. length: 462.4,                last time consumption/overall running time: 74.0761s / 171344.3116 s
env0_first_0:                 episode reward: -59.0000,                 loss: 30.8742
env0_second_0:                 episode reward: 59.0000,                 loss: 33.7735
env1_first_0:                 episode reward: -69.1000,                 loss: nan
env1_second_0:                 episode reward: 69.1000,                 loss: nan
Episode: 20541/30000 (68.4700%),                 avg. length: 407.75,                last time consumption/overall running time: 65.4888s / 171409.8003 s
env0_first_0:                 episode reward: -70.9000,                 loss: 34.9478
env0_second_0:                 episode reward: 70.9000,                 loss: 39.0770
env1_first_0:                 episode reward: -75.8500,                 loss: nan
env1_second_0:                 episode reward: 75.8500,                 loss: nan
Episode: 20561/30000 (68.5367%),                 avg. length: 886.6,                last time consumption/overall running time: 131.2785s / 171541.0788 s
env0_first_0:                 episode reward: -41.3000,                 loss: 23.6497
env0_second_0:                 episode reward: 41.3000,                 loss: 27.6953
env1_first_0:                 episode reward: -54.3500,                 loss: nan
env1_second_0:                 episode reward: 54.3500,                 loss: nan
Episode: 20581/30000 (68.6033%),                 avg. length: 1784.0,                last time consumption/overall running time: 260.8451s / 171801.9240 s
env0_first_0:                 episode reward: -5.7000,                 loss: 2.2644
env0_second_0:                 episode reward: 5.7000,                 loss: 6.4137
env1_first_0:                 episode reward: -6.3500,                 loss: nan
env1_second_0:                 episode reward: 6.3500,                 loss: nan
Episode: 20601/30000 (68.6700%),                 avg. length: 1784.0,                last time consumption/overall running time: 258.6486s / 172060.5726 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.3276
env0_second_0:                 episode reward: 0.3500,                 loss: 4.6446
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 20621/30000 (68.7367%),                 avg. length: 1784.0,                last time consumption/overall running time: 254.5971s / 172315.1697 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0761
env0_second_0:                 episode reward: 0.6000,                 loss: 4.6661
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 20641/30000 (68.8033%),                 avg. length: 1784.0,                last time consumption/overall running time: 253.2871s / 172568.4569 s
env0_first_0:                 episode reward: -0.7000,                 loss: -0.0812
env0_second_0:                 episode reward: 0.7000,                 loss: 4.7179
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 20661/30000 (68.8700%),                 avg. length: 1748.6,                last time consumption/overall running time: 251.3911s / 172819.8480 s
env0_first_0:                 episode reward: -1.0000,                 loss: 1.0500
env0_second_0:                 episode reward: 1.0000,                 loss: 5.4983
env1_first_0:                 episode reward: -6.6000,                 loss: nan
env1_second_0:                 episode reward: 6.6000,                 loss: nan
Episode: 20681/30000 (68.9367%),                 avg. length: 891.4,                last time consumption/overall running time: 135.0004s / 172954.8484 s
env0_first_0:                 episode reward: -34.5000,                 loss: 20.8281
env0_second_0:                 episode reward: 34.5000,                 loss: 26.3504
env1_first_0:                 episode reward: -47.8500,                 loss: nan
env1_second_0:                 episode reward: 47.8500,                 loss: nan
Episode: 20701/30000 (69.0033%),                 avg. length: 392.0,                last time consumption/overall running time: 62.2839s / 173017.1323 s
env0_first_0:                 episode reward: -75.5500,                 loss: 39.1401
env0_second_0:                 episode reward: 75.5500,                 loss: 43.4464
env1_first_0:                 episode reward: -81.4000,                 loss: nan
env1_second_0:                 episode reward: 81.4000,                 loss: nan
Episode: 20721/30000 (69.0700%),                 avg. length: 294.0,                last time consumption/overall running time: 51.2618s / 173068.3941 s
env0_first_0:                 episode reward: -80.5500,                 loss: 36.3725
env0_second_0:                 episode reward: 80.5500,                 loss: 41.7816
env1_first_0:                 episode reward: -81.8000,                 loss: nan
env1_second_0:                 episode reward: 81.8000,                 loss: nan
Episode: 20741/30000 (69.1367%),                 avg. length: 315.85,                last time consumption/overall running time: 54.2565s / 173122.6506 s
env0_first_0:                 episode reward: -80.7500,                 loss: 39.2395
env0_second_0:                 episode reward: 80.7500,                 loss: 45.2043
env1_first_0:                 episode reward: -69.0000,                 loss: nan
env1_second_0:                 episode reward: 69.0000,                 loss: nan
Episode: 20761/30000 (69.2033%),                 avg. length: 286.25,                last time consumption/overall running time: 48.6428s / 173171.2934 s
env0_first_0:                 episode reward: -78.9000,                 loss: 39.9969
env0_second_0:                 episode reward: 78.9000,                 loss: 45.4365
env1_first_0:                 episode reward: -80.5500,                 loss: nan
env1_second_0:                 episode reward: 80.5500,                 loss: nan
Episode: 20781/30000 (69.2700%),                 avg. length: 338.55,                last time consumption/overall running time: 55.5624s / 173226.8558 s
env0_first_0:                 episode reward: -80.3500,                 loss: 37.7081
env0_second_0:                 episode reward: 80.3500,                 loss: 49.3420
env1_first_0:                 episode reward: -79.9000,                 loss: nan
env1_second_0:                 episode reward: 79.9000,                 loss: nan
Episode: 20801/30000 (69.3367%),                 avg. length: 364.6,                last time consumption/overall running time: 59.5656s / 173286.4214 s
env0_first_0:                 episode reward: -81.3000,                 loss: 38.9663
env0_second_0:                 episode reward: 81.3000,                 loss: 44.7813
env1_first_0:                 episode reward: -64.3000,                 loss: nan
env1_second_0:                 episode reward: 64.3000,                 loss: nan
Episode: 20821/30000 (69.4033%),                 avg. length: 750.65,                last time consumption/overall running time: 110.9594s / 173397.3808 s
env0_first_0:                 episode reward: -56.7500,                 loss: 30.1069
env0_second_0:                 episode reward: 56.7500,                 loss: 36.8225
env1_first_0:                 episode reward: -50.0500,                 loss: nan
env1_second_0:                 episode reward: 50.0500,                 loss: nan
Episode: 20841/30000 (69.4700%),                 avg. length: 402.5,                last time consumption/overall running time: 73.9246s / 173471.3055 s
env0_first_0:                 episode reward: -63.1000,                 loss: 36.4981
env0_second_0:                 episode reward: 63.1000,                 loss: 42.7504
env1_first_0:                 episode reward: -70.7500,                 loss: nan
env1_second_0:                 episode reward: 70.7500,                 loss: nan
Episode: 20861/30000 (69.5367%),                 avg. length: 513.15,                last time consumption/overall running time: 80.4378s / 173551.7432 s
env0_first_0:                 episode reward: -43.5500,                 loss: 25.8914
env0_second_0:                 episode reward: 43.5500,                 loss: 31.1521
env1_first_0:                 episode reward: -68.7000,                 loss: nan
env1_second_0:                 episode reward: 68.7000,                 loss: nan
Episode: 20881/30000 (69.6033%),                 avg. length: 371.45,                last time consumption/overall running time: 61.2484s / 173612.9917 s
env0_first_0:                 episode reward: -70.3000,                 loss: 41.8354
env0_second_0:                 episode reward: 70.3000,                 loss: 46.0914
env1_first_0:                 episode reward: -72.7000,                 loss: nan
env1_second_0:                 episode reward: 72.7000,                 loss: nan
Episode: 20901/30000 (69.6700%),                 avg. length: 338.5,                last time consumption/overall running time: 55.3980s / 173668.3897 s
env0_first_0:                 episode reward: -74.1500,                 loss: 35.8885
env0_second_0:                 episode reward: 74.1500,                 loss: 40.1387
env1_first_0:                 episode reward: -83.0000,                 loss: nan
env1_second_0:                 episode reward: 83.0000,                 loss: nan
Episode: 20921/30000 (69.7367%),                 avg. length: 334.45,                last time consumption/overall running time: 55.0880s / 173723.4777 s
env0_first_0:                 episode reward: -73.8000,                 loss: 41.9445
env0_second_0:                 episode reward: 73.8000,                 loss: 45.2589
env1_first_0:                 episode reward: -73.6000,                 loss: nan
env1_second_0:                 episode reward: 73.6000,                 loss: nan
Episode: 20941/30000 (69.8033%),                 avg. length: 696.75,                last time consumption/overall running time: 102.7936s / 173826.2712 s
env0_first_0:                 episode reward: -58.0500,                 loss: 34.0706
env0_second_0:                 episode reward: 58.0500,                 loss: 37.1213
env1_first_0:                 episode reward: -41.3500,                 loss: nan
env1_second_0:                 episode reward: 41.3500,                 loss: nan
Episode: 20961/30000 (69.8700%),                 avg. length: 1784.0,                last time consumption/overall running time: 252.1036s / 174078.3748 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.9570
env0_second_0:                 episode reward: 0.1000,                 loss: 2.7926
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 20981/30000 (69.9367%),                 avg. length: 1784.0,                last time consumption/overall running time: 249.2459s / 174327.6207 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.3342
env0_second_0:                 episode reward: -0.1500,                 loss: 2.2531
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 21001/30000 (70.0033%),                 avg. length: 1784.0,                last time consumption/overall running time: 253.8501s / 174581.4708 s
env0_first_0:                 episode reward: 3.0000,                 loss: 4.2989
env0_second_0:                 episode reward: -3.0000,                 loss: 5.6375
env1_first_0:                 episode reward: 3.2000,                 loss: nan
env1_second_0:                 episode reward: -3.2000,                 loss: nan
Episode: 21021/30000 (70.0700%),                 avg. length: 1784.0,                last time consumption/overall running time: 254.5864s / 174836.0572 s
env0_first_0:                 episode reward: 5.7000,                 loss: 2.7979
env0_second_0:                 episode reward: -5.7000,                 loss: 5.0873
env1_first_0:                 episode reward: 6.8000,                 loss: nan
env1_second_0:                 episode reward: -6.8000,                 loss: nan
Episode: 21041/30000 (70.1367%),                 avg. length: 1481.05,                last time consumption/overall running time: 208.3040s / 175044.3612 s
env0_first_0:                 episode reward: -3.5000,                 loss: 8.0240
env0_second_0:                 episode reward: 3.5000,                 loss: 9.4833
env1_first_0:                 episode reward: -16.5000,                 loss: nan
env1_second_0:                 episode reward: 16.5000,                 loss: nan
Episode: 21061/30000 (70.2033%),                 avg. length: 1784.0,                last time consumption/overall running time: 246.9978s / 175291.3590 s
env0_first_0:                 episode reward: 9.7500,                 loss: 1.8175
env0_second_0:                 episode reward: -9.7500,                 loss: 3.3945
env1_first_0:                 episode reward: 2.9500,                 loss: nan
env1_second_0:                 episode reward: -2.9500,                 loss: nan
Episode: 21081/30000 (70.2700%),                 avg. length: 1767.6,                last time consumption/overall running time: 248.2680s / 175539.6270 s
env0_first_0:                 episode reward: -1.2000,                 loss: 1.9558
env0_second_0:                 episode reward: 1.2000,                 loss: 3.9543
env1_first_0:                 episode reward: -1.5000,                 loss: nan
env1_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 21101/30000 (70.3367%),                 avg. length: 1784.0,                last time consumption/overall running time: 248.6146s / 175788.2416 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.3852
env0_second_0:                 episode reward: -1.0000,                 loss: 2.1174
env1_first_0:                 episode reward: 1.5000,                 loss: nan
env1_second_0:                 episode reward: -1.5000,                 loss: nan
Episode: 21121/30000 (70.4033%),                 avg. length: 1784.0,                last time consumption/overall running time: 245.9561s / 176034.1978 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.3314
env0_second_0:                 episode reward: 0.0000,                 loss: 1.8115
env1_first_0:                 episode reward: 4.2000,                 loss: nan
env1_second_0:                 episode reward: -4.2000,                 loss: nan
Episode: 21141/30000 (70.4700%),                 avg. length: 1400.65,                last time consumption/overall running time: 192.9990s / 176227.1967 s
env0_first_0:                 episode reward: -15.7000,                 loss: 13.7424
env0_second_0:                 episode reward: 15.7000,                 loss: 15.6194
env1_first_0:                 episode reward: -28.5500,                 loss: nan
env1_second_0:                 episode reward: 28.5500,                 loss: nan
Episode: 21161/30000 (70.5367%),                 avg. length: 546.1,                last time consumption/overall running time: 82.4060s / 176309.6028 s
env0_first_0:                 episode reward: -70.5000,                 loss: 31.3820
env0_second_0:                 episode reward: 70.5000,                 loss: 34.5585
env1_first_0:                 episode reward: -73.5000,                 loss: nan
env1_second_0:                 episode reward: 73.5000,                 loss: nan
Episode: 21181/30000 (70.6033%),                 avg. length: 1031.0,                last time consumption/overall running time: 151.9224s / 176461.5252 s
env0_first_0:                 episode reward: -46.4000,                 loss: 32.6675
env0_second_0:                 episode reward: 46.4000,                 loss: 37.7827
env1_first_0:                 episode reward: -40.7000,                 loss: nan
env1_second_0:                 episode reward: 40.7000,                 loss: nan
Episode: 21201/30000 (70.6700%),                 avg. length: 1756.0,                last time consumption/overall running time: 243.9100s / 176705.4351 s
env0_first_0:                 episode reward: -6.0000,                 loss: 4.5910
env0_second_0:                 episode reward: 6.0000,                 loss: 8.3501
env1_first_0:                 episode reward: -4.3500,                 loss: nan
env1_second_0:                 episode reward: 4.3500,                 loss: nan
Episode: 21221/30000 (70.7367%),                 avg. length: 1571.75,                last time consumption/overall running time: 220.3110s / 176925.7462 s
env0_first_0:                 episode reward: -1.5000,                 loss: 3.8169
env0_second_0:                 episode reward: 1.5000,                 loss: 6.0837
env1_first_0:                 episode reward: 1.8000,                 loss: nan
env1_second_0:                 episode reward: -1.8000,                 loss: nan
Episode: 21241/30000 (70.8033%),                 avg. length: 1049.6,                last time consumption/overall running time: 155.1282s / 177080.8744 s
env0_first_0:                 episode reward: -21.1500,                 loss: 14.5621
env0_second_0:                 episode reward: 21.1500,                 loss: 15.3961
env1_first_0:                 episode reward: -20.6000,                 loss: nan
env1_second_0:                 episode reward: 20.6000,                 loss: nan
Episode: 21261/30000 (70.8700%),                 avg. length: 886.1,                last time consumption/overall running time: 131.3011s / 177212.1755 s
env0_first_0:                 episode reward: -39.2000,                 loss: 22.4821
env0_second_0:                 episode reward: 39.2000,                 loss: 23.7656
env1_first_0:                 episode reward: -49.7000,                 loss: nan
env1_second_0:                 episode reward: 49.7000,                 loss: nan
Episode: 21281/30000 (70.9367%),                 avg. length: 774.4,                last time consumption/overall running time: 114.0134s / 177326.1889 s
env0_first_0:                 episode reward: -50.1500,                 loss: 24.3906
env0_second_0:                 episode reward: 50.1500,                 loss: 27.6737
env1_first_0:                 episode reward: -56.2500,                 loss: nan
env1_second_0:                 episode reward: 56.2500,                 loss: nan
Episode: 21301/30000 (71.0033%),                 avg. length: 654.65,                last time consumption/overall running time: 97.5309s / 177423.7198 s
env0_first_0:                 episode reward: -50.6500,                 loss: 25.1883
env0_second_0:                 episode reward: 50.6500,                 loss: 26.2470
env1_first_0:                 episode reward: -53.1500,                 loss: nan
env1_second_0:                 episode reward: 53.1500,                 loss: nan
Episode: 21321/30000 (71.0700%),                 avg. length: 427.95,                last time consumption/overall running time: 66.7967s / 177490.5165 s
env0_first_0:                 episode reward: -47.1000,                 loss: 35.8044
env0_second_0:                 episode reward: 47.1000,                 loss: 37.6499
env1_first_0:                 episode reward: -73.2500,                 loss: nan
env1_second_0:                 episode reward: 73.2500,                 loss: nan
Episode: 21341/30000 (71.1367%),                 avg. length: 1131.7,                last time consumption/overall running time: 163.2369s / 177653.7533 s
env0_first_0:                 episode reward: -20.5000,                 loss: 14.9603
env0_second_0:                 episode reward: 20.5000,                 loss: 20.2337
env1_first_0:                 episode reward: -39.0000,                 loss: nan
env1_second_0:                 episode reward: 39.0000,                 loss: nan
Episode: 21361/30000 (71.2033%),                 avg. length: 732.3,                last time consumption/overall running time: 111.3688s / 177765.1221 s
env0_first_0:                 episode reward: -52.2500,                 loss: 21.5533
env0_second_0:                 episode reward: 52.2500,                 loss: -21.6077
env1_first_0:                 episode reward: -42.3500,                 loss: nan
env1_second_0:                 episode reward: 42.3500,                 loss: nan
Episode: 21381/30000 (71.2700%),                 avg. length: 454.85,                last time consumption/overall running time: 70.3642s / 177835.4863 s
env0_first_0:                 episode reward: -49.5000,                 loss: 33.2490
env0_second_0:                 episode reward: 49.5000,                 loss: 47.4226
env1_first_0:                 episode reward: -64.9500,                 loss: nan
env1_second_0:                 episode reward: 64.9500,                 loss: nan
Episode: 21401/30000 (71.3367%),                 avg. length: 441.7,                last time consumption/overall running time: 70.0036s / 177905.4900 s
env0_first_0:                 episode reward: -60.8500,                 loss: 38.3780
env0_second_0:                 episode reward: 60.8500,                 loss: 40.9819
env1_first_0:                 episode reward: -64.3000,                 loss: nan
env1_second_0:                 episode reward: 64.3000,                 loss: nan
Episode: 21421/30000 (71.4033%),                 avg. length: 418.85,                last time consumption/overall running time: 65.2598s / 177970.7497 s
env0_first_0:                 episode reward: -81.1000,                 loss: 36.8664
env0_second_0:                 episode reward: 81.1000,                 loss: 41.4809
env1_first_0:                 episode reward: -55.6000,                 loss: nan
env1_second_0:                 episode reward: 55.6000,                 loss: nan
Episode: 21441/30000 (71.4700%),                 avg. length: 372.15,                last time consumption/overall running time: 59.5720s / 178030.3217 s
env0_first_0:                 episode reward: -70.2000,                 loss: 41.7741
env0_second_0:                 episode reward: 70.2000,                 loss: 46.9029
env1_first_0:                 episode reward: -76.2000,                 loss: nan
env1_second_0:                 episode reward: 76.2000,                 loss: nan
Episode: 21461/30000 (71.5367%),                 avg. length: 382.35,                last time consumption/overall running time: 61.2993s / 178091.6210 s
env0_first_0:                 episode reward: -63.1500,                 loss: 40.0402
env0_second_0:                 episode reward: 63.1500,                 loss: 44.8265
env1_first_0:                 episode reward: -72.7500,                 loss: nan
env1_second_0:                 episode reward: 72.7500,                 loss: nan
Episode: 21481/30000 (71.6033%),                 avg. length: 330.05,                last time consumption/overall running time: 53.6907s / 178145.3117 s
env0_first_0:                 episode reward: -67.4000,                 loss: 33.0185
env0_second_0:                 episode reward: 67.4000,                 loss: 38.2513
env1_first_0:                 episode reward: -77.3500,                 loss: nan
env1_second_0:                 episode reward: 77.3500,                 loss: nan
Episode: 21501/30000 (71.6700%),                 avg. length: 272.45,                last time consumption/overall running time: 46.7228s / 178192.0346 s
env0_first_0:                 episode reward: -83.8500,                 loss: 44.4080
env0_second_0:                 episode reward: 83.8500,                 loss: 44.0891
env1_first_0:                 episode reward: -71.6500,                 loss: nan
env1_second_0:                 episode reward: 71.6500,                 loss: nan
Episode: 21521/30000 (71.7367%),                 avg. length: 1423.6,                last time consumption/overall running time: 198.7666s / 178390.8011 s
env0_first_0:                 episode reward: -14.8000,                 loss: 11.7790
env0_second_0:                 episode reward: 14.8000,                 loss: 15.3451
env1_first_0:                 episode reward: -14.7000,                 loss: nan
env1_second_0:                 episode reward: 14.7000,                 loss: nan
Episode: 21541/30000 (71.8033%),                 avg. length: 806.5,                last time consumption/overall running time: 118.1834s / 178508.9845 s
env0_first_0:                 episode reward: -41.3500,                 loss: 29.7140
env0_second_0:                 episode reward: 41.3500,                 loss: 31.5578
env1_first_0:                 episode reward: -53.3000,                 loss: nan
env1_second_0:                 episode reward: 53.3000,                 loss: nan
Episode: 21561/30000 (71.8700%),                 avg. length: 1402.5,                last time consumption/overall running time: 199.4804s / 178708.4649 s
env0_first_0:                 episode reward: -19.9000,                 loss: 9.0981
env0_second_0:                 episode reward: 19.9000,                 loss: 11.4734
env1_first_0:                 episode reward: -13.1500,                 loss: nan
env1_second_0:                 episode reward: 13.1500,                 loss: nan
Episode: 21581/30000 (71.9367%),                 avg. length: 307.1,                last time consumption/overall running time: 49.7431s / 178758.2080 s
env0_first_0:                 episode reward: -84.5000,                 loss: 27.6901
env0_second_0:                 episode reward: 84.5000,                 loss: 29.5445
env1_first_0:                 episode reward: -86.3000,                 loss: nan
env1_second_0:                 episode reward: 86.3000,                 loss: nan
Episode: 21601/30000 (72.0033%),                 avg. length: 356.4,                last time consumption/overall running time: 56.6946s / 178814.9026 s
env0_first_0:                 episode reward: -81.6000,                 loss: 20.3990
env0_second_0:                 episode reward: 81.6000,                 loss: 23.9977
env1_first_0:                 episode reward: -79.2500,                 loss: nan
env1_second_0:                 episode reward: 79.2500,                 loss: nan
Episode: 21621/30000 (72.0700%),                 avg. length: 496.9,                last time consumption/overall running time: 77.9804s / 178892.8831 s
env0_first_0:                 episode reward: -66.2500,                 loss: 20.7535
env0_second_0:                 episode reward: 66.2500,                 loss: 27.5075
env1_first_0:                 episode reward: -73.9000,                 loss: nan
env1_second_0:                 episode reward: 73.9000,                 loss: nan
Episode: 21641/30000 (72.1367%),                 avg. length: 368.95,                last time consumption/overall running time: 60.4360s / 178953.3191 s
env0_first_0:                 episode reward: -73.8500,                 loss: 23.5411
env0_second_0:                 episode reward: 73.8500,                 loss: 28.0436
env1_first_0:                 episode reward: -76.5000,                 loss: nan
env1_second_0:                 episode reward: 76.5000,                 loss: nan
Episode: 21661/30000 (72.2033%),                 avg. length: 332.2,                last time consumption/overall running time: 53.7294s / 179007.0485 s
env0_first_0:                 episode reward: -64.8500,                 loss: 25.6953
env0_second_0:                 episode reward: 64.8500,                 loss: 29.3253
env1_first_0:                 episode reward: -81.1000,                 loss: nan
env1_second_0:                 episode reward: 81.1000,                 loss: nan
Episode: 21681/30000 (72.2700%),                 avg. length: 344.7,                last time consumption/overall running time: 54.9414s / 179061.9899 s
env0_first_0:                 episode reward: -75.4500,                 loss: 25.0552
env0_second_0:                 episode reward: 75.4500,                 loss: 26.3344
env1_first_0:                 episode reward: -73.2500,                 loss: nan
env1_second_0:                 episode reward: 73.2500,                 loss: nan
Episode: 21701/30000 (72.3367%),                 avg. length: 315.35,                last time consumption/overall running time: 50.9857s / 179112.9756 s
env0_first_0:                 episode reward: -84.3500,                 loss: 25.3762
env0_second_0:                 episode reward: 84.3500,                 loss: 26.0289
env1_first_0:                 episode reward: -83.6000,                 loss: nan
env1_second_0:                 episode reward: 83.6000,                 loss: nan
Episode: 21721/30000 (72.4033%),                 avg. length: 266.5,                last time consumption/overall running time: 43.9284s / 179156.9040 s
env0_first_0:                 episode reward: -86.1500,                 loss: 28.1293
env0_second_0:                 episode reward: 86.1500,                 loss: 29.8378
env1_first_0:                 episode reward: -74.8500,                 loss: nan
env1_second_0:                 episode reward: 74.8500,                 loss: nan
Episode: 21741/30000 (72.4700%),                 avg. length: 354.3,                last time consumption/overall running time: 57.0420s / 179213.9460 s
env0_first_0:                 episode reward: -61.9500,                 loss: 47.1953
env0_second_0:                 episode reward: 61.9500,                 loss: 45.8452
env1_first_0:                 episode reward: -63.8000,                 loss: nan
env1_second_0:                 episode reward: 63.8000,                 loss: nan
Episode: 21761/30000 (72.5367%),                 avg. length: 319.25,                last time consumption/overall running time: 53.4341s / 179267.3801 s
env0_first_0:                 episode reward: -67.2500,                 loss: 48.0421
env0_second_0:                 episode reward: 67.2500,                 loss: 50.2862
env1_first_0:                 episode reward: -70.8500,                 loss: nan
env1_second_0:                 episode reward: 70.8500,                 loss: nan
Episode: 21781/30000 (72.6033%),                 avg. length: 560.95,                last time consumption/overall running time: 86.3570s / 179353.7371 s
env0_first_0:                 episode reward: -60.0500,                 loss: 40.9768
env0_second_0:                 episode reward: 60.0500,                 loss: 43.3327
env1_first_0:                 episode reward: -64.1000,                 loss: nan
env1_second_0:                 episode reward: 64.1000,                 loss: nan
Episode: 21801/30000 (72.6700%),                 avg. length: 1138.45,                last time consumption/overall running time: 160.9045s / 179514.6415 s
env0_first_0:                 episode reward: -33.5000,                 loss: 18.0071
env0_second_0:                 episode reward: 33.5000,                 loss: 22.0305
env1_first_0:                 episode reward: -50.0500,                 loss: nan
env1_second_0:                 episode reward: 50.0500,                 loss: nan
Episode: 21821/30000 (72.7367%),                 avg. length: 1597.9,                last time consumption/overall running time: 217.7913s / 179732.4328 s
env0_first_0:                 episode reward: -17.8500,                 loss: 3.8122
env0_second_0:                 episode reward: 17.8500,                 loss: 5.3845
env1_first_0:                 episode reward: -8.0000,                 loss: nan
env1_second_0:                 episode reward: 8.0000,                 loss: nan
Episode: 21841/30000 (72.8033%),                 avg. length: 1725.75,                last time consumption/overall running time: 230.0587s / 179962.4915 s
env0_first_0:                 episode reward: 1.4000,                 loss: 1.4479
env0_second_0:                 episode reward: -1.4000,                 loss: 3.6796
env1_first_0:                 episode reward: -8.7500,                 loss: nan
env1_second_0:                 episode reward: 8.7500,                 loss: nan
Episode: 21861/30000 (72.8700%),                 avg. length: 1549.75,                last time consumption/overall running time: 209.9535s / 180172.4450 s
env0_first_0:                 episode reward: -15.1000,                 loss: 13.4417
env0_second_0:                 episode reward: 15.1000,                 loss: 16.1370
env1_first_0:                 episode reward: -4.9000,                 loss: nan
env1_second_0:                 episode reward: 4.9000,                 loss: nan
Episode: 21881/30000 (72.9367%),                 avg. length: 1705.45,                last time consumption/overall running time: 234.9112s / 180407.3562 s
env0_first_0:                 episode reward: -6.5500,                 loss: 4.2484
env0_second_0:                 episode reward: 6.5500,                 loss: 5.5534
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 21901/30000 (73.0033%),                 avg. length: 1705.4,                last time consumption/overall running time: 222.0072s / 180629.3634 s
env0_first_0:                 episode reward: -16.7000,                 loss: 8.7796
env0_second_0:                 episode reward: 16.7000,                 loss: 10.4860
env1_first_0:                 episode reward: -15.7500,                 loss: nan
env1_second_0:                 episode reward: 15.7500,                 loss: nan
Episode: 21921/30000 (73.0700%),                 avg. length: 1705.45,                last time consumption/overall running time: 223.3789s / 180852.7423 s
env0_first_0:                 episode reward: -6.3000,                 loss: 4.6160
env0_second_0:                 episode reward: 6.3000,                 loss: 6.3038
env1_first_0:                 episode reward: -6.1000,                 loss: nan
env1_second_0:                 episode reward: 6.1000,                 loss: nan
Episode: 21941/30000 (73.1367%),                 avg. length: 1784.0,                last time consumption/overall running time: 233.8457s / 181086.5881 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.7658
env0_second_0:                 episode reward: 0.9000,                 loss: 1.8496
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 21961/30000 (73.2033%),                 avg. length: 1784.0,                last time consumption/overall running time: 231.9125s / 181318.5006 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2757
env0_second_0:                 episode reward: 0.4000,                 loss: 2.0304
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 21981/30000 (73.2700%),                 avg. length: 1784.0,                last time consumption/overall running time: 234.3408s / 181552.8414 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2045
env0_second_0:                 episode reward: -0.5000,                 loss: 1.8389
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 22001/30000 (73.3367%),                 avg. length: 1784.0,                last time consumption/overall running time: 233.8438s / 181786.6852 s
env0_first_0:                 episode reward: 1.3000,                 loss: 0.1477
env0_second_0:                 episode reward: -1.3000,                 loss: 1.7435
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 22021/30000 (73.4033%),                 avg. length: 1784.0,                last time consumption/overall running time: 236.9148s / 182023.5999 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0379
env0_second_0:                 episode reward: -0.2500,                 loss: 2.5289
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 22041/30000 (73.4700%),                 avg. length: 1654.7,                last time consumption/overall running time: 217.6087s / 182241.2087 s
env0_first_0:                 episode reward: 0.7000,                 loss: 2.4817
env0_second_0:                 episode reward: -0.7000,                 loss: 4.3649
env1_first_0:                 episode reward: -10.6500,                 loss: nan
env1_second_0:                 episode reward: 10.6500,                 loss: nan
Episode: 22061/30000 (73.5367%),                 avg. length: 278.85,                last time consumption/overall running time: 45.0570s / 182286.2657 s
env0_first_0:                 episode reward: -88.1000,                 loss: 43.3807
env0_second_0:                 episode reward: 88.1000,                 loss: 41.6818
env1_first_0:                 episode reward: -88.1000,                 loss: nan
env1_second_0:                 episode reward: 88.1000,                 loss: nan
Episode: 22081/30000 (73.6033%),                 avg. length: 389.75,                last time consumption/overall running time: 59.9288s / 182346.1945 s
env0_first_0:                 episode reward: -87.1000,                 loss: 24.0740
env0_second_0:                 episode reward: 87.1000,                 loss: 23.7099
env1_first_0:                 episode reward: -83.4500,                 loss: nan
env1_second_0:                 episode reward: 83.4500,                 loss: nan
Episode: 22101/30000 (73.6700%),                 avg. length: 605.3,                last time consumption/overall running time: 87.3088s / 182433.5034 s
env0_first_0:                 episode reward: -77.4500,                 loss: 19.7020
env0_second_0:                 episode reward: 77.4500,                 loss: 18.4411
env1_first_0:                 episode reward: -64.5000,                 loss: nan
env1_second_0:                 episode reward: 64.5000,                 loss: nan
Episode: 22121/30000 (73.7367%),                 avg. length: 258.9,                last time consumption/overall running time: 43.9985s / 182477.5019 s
env0_first_0:                 episode reward: -87.4000,                 loss: 25.4367
env0_second_0:                 episode reward: 87.4000,                 loss: 24.5954
env1_first_0:                 episode reward: -89.8500,                 loss: nan
env1_second_0:                 episode reward: 89.8500,                 loss: nan
Episode: 22141/30000 (73.8033%),                 avg. length: 265.45,                last time consumption/overall running time: 45.2176s / 182522.7194 s
env0_first_0:                 episode reward: -84.3000,                 loss: 27.4813
env0_second_0:                 episode reward: 84.3000,                 loss: 30.9393
env1_first_0:                 episode reward: -88.1000,                 loss: nan
env1_second_0:                 episode reward: 88.1000,                 loss: nan
Episode: 22161/30000 (73.8700%),                 avg. length: 224.15,                last time consumption/overall running time: 39.1642s / 182561.8837 s
env0_first_0:                 episode reward: -93.1000,                 loss: 18.1516
env0_second_0:                 episode reward: 93.1000,                 loss: 20.8870
env1_first_0:                 episode reward: -96.3000,                 loss: nan
env1_second_0:                 episode reward: 96.3000,                 loss: nan
Episode: 22181/30000 (73.9367%),                 avg. length: 228.05,                last time consumption/overall running time: 38.7557s / 182600.6394 s
env0_first_0:                 episode reward: -88.8500,                 loss: 19.0278
env0_second_0:                 episode reward: 88.8500,                 loss: 20.5927
env1_first_0:                 episode reward: -86.1000,                 loss: nan
env1_second_0:                 episode reward: 86.1000,                 loss: nan
Episode: 22201/30000 (74.0033%),                 avg. length: 287.65,                last time consumption/overall running time: 47.8771s / 182648.5164 s
env0_first_0:                 episode reward: -77.7000,                 loss: 29.4785
env0_second_0:                 episode reward: 77.7000,                 loss: 31.7040
env1_first_0:                 episode reward: -67.9000,                 loss: nan
env1_second_0:                 episode reward: 67.9000,                 loss: nan
Episode: 22221/30000 (74.0700%),                 avg. length: 264.95,                last time consumption/overall running time: 43.0246s / 182691.5410 s
env0_first_0:                 episode reward: -79.9000,                 loss: 25.7352
env0_second_0:                 episode reward: 79.9000,                 loss: 29.4665
env1_first_0:                 episode reward: -85.6000,                 loss: nan
env1_second_0:                 episode reward: 85.6000,                 loss: nan
Episode: 22241/30000 (74.1367%),                 avg. length: 511.55,                last time consumption/overall running time: 76.1865s / 182767.7275 s
env0_first_0:                 episode reward: -57.7000,                 loss: 28.4984
env0_second_0:                 episode reward: 57.7000,                 loss: 29.8115
env1_first_0:                 episode reward: -71.9500,                 loss: nan
env1_second_0:                 episode reward: 71.9500,                 loss: nan
Episode: 22261/30000 (74.2033%),                 avg. length: 1331.65,                last time consumption/overall running time: 182.8849s / 182950.6125 s
env0_first_0:                 episode reward: -14.3500,                 loss: 10.0168
env0_second_0:                 episode reward: 14.3500,                 loss: 11.5201
env1_first_0:                 episode reward: -14.8000,                 loss: nan
env1_second_0:                 episode reward: 14.8000,                 loss: nan
Episode: 22281/30000 (74.2700%),                 avg. length: 1513.95,                last time consumption/overall running time: 201.1101s / 183151.7225 s
env0_first_0:                 episode reward: -9.8000,                 loss: 7.2408
env0_second_0:                 episode reward: 9.8000,                 loss: 9.1095
env1_first_0:                 episode reward: -15.2000,                 loss: nan
env1_second_0:                 episode reward: 15.2000,                 loss: nan
Episode: 22301/30000 (74.3367%),                 avg. length: 1286.95,                last time consumption/overall running time: 170.0349s / 183321.7574 s
env0_first_0:                 episode reward: -24.4000,                 loss: 17.7379
env0_second_0:                 episode reward: 24.4000,                 loss: 19.9902
env1_first_0:                 episode reward: -29.3500,                 loss: nan
env1_second_0:                 episode reward: 29.3500,                 loss: nan
Episode: 22321/30000 (74.4033%),                 avg. length: 594.9,                last time consumption/overall running time: 86.3802s / 183408.1376 s
env0_first_0:                 episode reward: -58.5000,                 loss: 44.9328
env0_second_0:                 episode reward: 58.5000,                 loss: 48.7470
env1_first_0:                 episode reward: -67.8000,                 loss: nan
env1_second_0:                 episode reward: 67.8000,                 loss: nan
Episode: 22341/30000 (74.4700%),                 avg. length: 324.0,                last time consumption/overall running time: 50.3462s / 183458.4838 s
env0_first_0:                 episode reward: -75.0000,                 loss: 38.3022
env0_second_0:                 episode reward: 75.0000,                 loss: 40.9649
env1_first_0:                 episode reward: -88.3500,                 loss: nan
env1_second_0:                 episode reward: 88.3500,                 loss: nan
Episode: 22361/30000 (74.5367%),                 avg. length: 278.2,                last time consumption/overall running time: 46.6893s / 183505.1731 s
env0_first_0:                 episode reward: -90.4000,                 loss: 26.3147
env0_second_0:                 episode reward: 90.4000,                 loss: 27.0166
env1_first_0:                 episode reward: -90.5500,                 loss: nan
env1_second_0:                 episode reward: 90.5500,                 loss: nan
Episode: 22381/30000 (74.6033%),                 avg. length: 230.6,                last time consumption/overall running time: 40.6558s / 183545.8289 s
env0_first_0:                 episode reward: -94.1500,                 loss: 18.1165
env0_second_0:                 episode reward: 94.1500,                 loss: 20.0918
env1_first_0:                 episode reward: -96.4500,                 loss: nan
env1_second_0:                 episode reward: 96.4500,                 loss: nan
Episode: 22401/30000 (74.6700%),                 avg. length: 261.15,                last time consumption/overall running time: 42.9456s / 183588.7745 s
env0_first_0:                 episode reward: -88.9500,                 loss: 28.3660
env0_second_0:                 episode reward: 88.9500,                 loss: 30.3541
env1_first_0:                 episode reward: -91.0000,                 loss: nan
env1_second_0:                 episode reward: 91.0000,                 loss: nan
Episode: 22421/30000 (74.7367%),                 avg. length: 537.05,                last time consumption/overall running time: 77.1686s / 183665.9431 s
env0_first_0:                 episode reward: -72.4500,                 loss: 15.2766
env0_second_0:                 episode reward: 72.4500,                 loss: 17.4641
env1_first_0:                 episode reward: -76.6000,                 loss: nan
env1_second_0:                 episode reward: 76.6000,                 loss: nan
Episode: 22441/30000 (74.8033%),                 avg. length: 1784.0,                last time consumption/overall running time: 244.5650s / 183910.5081 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.7623
env0_second_0:                 episode reward: 0.0000,                 loss: 3.4109
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 22461/30000 (74.8700%),                 avg. length: 1784.0,                last time consumption/overall running time: 244.9748s / 184155.4829 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.1469
env0_second_0:                 episode reward: 0.0000,                 loss: 1.1570
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 22481/30000 (74.9367%),                 avg. length: 1784.0,                last time consumption/overall running time: 242.5455s / 184398.0284 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0660
env0_second_0:                 episode reward: 0.0000,                 loss: -0.0068
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 22501/30000 (75.0033%),                 avg. length: 1784.0,                last time consumption/overall running time: 236.8637s / 184634.8921 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0249
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2106
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 22521/30000 (75.0700%),                 avg. length: 1784.0,                last time consumption/overall running time: 241.2973s / 184876.1894 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0038
env0_second_0:                 episode reward: 0.0000,                 loss: 0.1882
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 22541/30000 (75.1367%),                 avg. length: 1784.0,                last time consumption/overall running time: 242.9668s / 185119.1562 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0217
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2455
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 22561/30000 (75.2033%),                 avg. length: 1784.0,                last time consumption/overall running time: 236.1228s / 185355.2791 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0517
env0_second_0:                 episode reward: 0.0000,                 loss: 0.5500
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 22581/30000 (75.2700%),                 avg. length: 1731.85,                last time consumption/overall running time: 229.4704s / 185584.7495 s
env0_first_0:                 episode reward: -4.7000,                 loss: 1.0142
env0_second_0:                 episode reward: 4.7000,                 loss: 1.9857
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 22601/30000 (75.3367%),                 avg. length: 1784.0,                last time consumption/overall running time: 244.5883s / 185829.3378 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0718
env0_second_0:                 episode reward: 0.0000,                 loss: 0.5769
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 22621/30000 (75.4033%),                 avg. length: 1784.0,                last time consumption/overall running time: 233.4511s / 186062.7889 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0025
env0_second_0:                 episode reward: 0.0000,                 loss: 0.4321
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 22641/30000 (75.4700%),                 avg. length: 1700.1,                last time consumption/overall running time: 229.4930s / 186292.2819 s
env0_first_0:                 episode reward: 0.0000,                 loss: 3.7382
env0_second_0:                 episode reward: 0.0000,                 loss: 4.2847
env1_first_0:                 episode reward: -9.0000,                 loss: nan
env1_second_0:                 episode reward: 9.0000,                 loss: nan
Episode: 22661/30000 (75.5367%),                 avg. length: 1586.1,                last time consumption/overall running time: 215.1392s / 186507.4211 s
env0_first_0:                 episode reward: -9.2500,                 loss: 5.4522
env0_second_0:                 episode reward: 9.2500,                 loss: 4.9753
env1_first_0:                 episode reward: -4.8000,                 loss: nan
env1_second_0:                 episode reward: 4.8000,                 loss: nan
Episode: 22681/30000 (75.6033%),                 avg. length: 914.2,                last time consumption/overall running time: 131.3681s / 186638.7892 s
env0_first_0:                 episode reward: -33.9500,                 loss: 30.5755
env0_second_0:                 episode reward: 33.9500,                 loss: 28.4832
env1_first_0:                 episode reward: -48.4000,                 loss: nan
env1_second_0:                 episode reward: 48.4000,                 loss: nan
Episode: 22701/30000 (75.6700%),                 avg. length: 1784.0,                last time consumption/overall running time: 244.9136s / 186883.7028 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2350
env0_second_0:                 episode reward: 0.0000,                 loss: 0.6125
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 22721/30000 (75.7367%),                 avg. length: 1784.0,                last time consumption/overall running time: 253.5613s / 187137.2641 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.1470
env0_second_0:                 episode reward: 0.0000,                 loss: 0.8925
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 22741/30000 (75.8033%),                 avg. length: 1784.0,                last time consumption/overall running time: 247.9478s / 187385.2119 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.3727
env0_second_0:                 episode reward: 0.0000,                 loss: 0.9773
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 22761/30000 (75.8700%),                 avg. length: 1784.0,                last time consumption/overall running time: 253.9733s / 187639.1852 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0007
env0_second_0:                 episode reward: 0.0000,                 loss: 0.1498
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 22781/30000 (75.9367%),                 avg. length: 1784.0,                last time consumption/overall running time: 246.1688s / 187885.3540 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0419
env0_second_0:                 episode reward: 0.0000,                 loss: 0.3451
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 22801/30000 (76.0033%),                 avg. length: 1784.0,                last time consumption/overall running time: 235.9515s / 188121.3055 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0815
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2704
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 22821/30000 (76.0700%),                 avg. length: 1784.0,                last time consumption/overall running time: 248.2627s / 188369.5682 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.1460
env0_second_0:                 episode reward: 0.0000,                 loss: 0.3677
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 22841/30000 (76.1367%),                 avg. length: 1784.0,                last time consumption/overall running time: 237.3813s / 188606.9495 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.1549
env0_second_0:                 episode reward: 0.0000,                 loss: 0.5501
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 22861/30000 (76.2033%),                 avg. length: 1784.0,                last time consumption/overall running time: 243.4844s / 188850.4339 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.1701
env0_second_0:                 episode reward: 0.0000,                 loss: 0.3500
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 22881/30000 (76.2700%),                 avg. length: 1784.0,                last time consumption/overall running time: 256.3836s / 189106.8175 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2096
env0_second_0:                 episode reward: 0.0000,                 loss: 5.8888
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 22901/30000 (76.3367%),                 avg. length: 1784.0,                last time consumption/overall running time: 238.3758s / 189345.1933 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2383
env0_second_0:                 episode reward: 0.0000,                 loss: 0.5919
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 22921/30000 (76.4033%),                 avg. length: 1784.0,                last time consumption/overall running time: 237.8709s / 189583.0642 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2487
env0_second_0:                 episode reward: 0.0000,                 loss: 0.4205
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 22941/30000 (76.4700%),                 avg. length: 1784.0,                last time consumption/overall running time: 232.2249s / 189815.2891 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2519
env0_second_0:                 episode reward: 0.0000,                 loss: 0.4003
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 22961/30000 (76.5367%),                 avg. length: 1784.0,                last time consumption/overall running time: 246.0947s / 190061.3838 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2503
env0_second_0:                 episode reward: 0.0000,                 loss: 0.1881
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 22981/30000 (76.6033%),                 avg. length: 1784.0,                last time consumption/overall running time: 238.2005s / 190299.5843 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2563
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2468
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 23001/30000 (76.6700%),                 avg. length: 1784.0,                last time consumption/overall running time: 255.7495s / 190555.3337 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2421
env0_second_0:                 episode reward: 0.0000,                 loss: 0.1595
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 23021/30000 (76.7367%),                 avg. length: 1784.0,                last time consumption/overall running time: 239.6640s / 190794.9977 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2540
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2105
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 23041/30000 (76.8033%),                 avg. length: 1784.0,                last time consumption/overall running time: 242.2465s / 191037.2442 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2461
env0_second_0:                 episode reward: 0.0000,                 loss: 0.3721
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 23061/30000 (76.8700%),                 avg. length: 1784.0,                last time consumption/overall running time: 261.4287s / 191298.6729 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2590
env0_second_0:                 episode reward: 0.0000,                 loss: 0.4504
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 23081/30000 (76.9367%),                 avg. length: 1784.0,                last time consumption/overall running time: 249.8598s / 191548.5327 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2459
env0_second_0:                 episode reward: 0.0000,                 loss: 0.4733
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 23101/30000 (77.0033%),                 avg. length: 1784.0,                last time consumption/overall running time: 236.3490s / 191784.8817 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2534
env0_second_0:                 episode reward: 0.0000,                 loss: 0.3643
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 23121/30000 (77.0700%),                 avg. length: 1784.0,                last time consumption/overall running time: 260.5614s / 192045.4431 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2516
env0_second_0:                 episode reward: 0.0000,                 loss: 0.4375
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 23141/30000 (77.1367%),                 avg. length: 1784.0,                last time consumption/overall running time: 244.4672s / 192289.9103 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2458
env0_second_0:                 episode reward: 0.0000,                 loss: 0.6679
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 23161/30000 (77.2033%),                 avg. length: 1784.0,                last time consumption/overall running time: 245.9785s / 192535.8888 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2466
env0_second_0:                 episode reward: 0.0000,                 loss: 0.7147
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 23181/30000 (77.2700%),                 avg. length: 1784.0,                last time consumption/overall running time: 239.1263s / 192775.0151 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2629
env0_second_0:                 episode reward: 0.0000,                 loss: 0.6486
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 23201/30000 (77.3367%),                 avg. length: 1784.0,                last time consumption/overall running time: 238.8507s / 193013.8658 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2427
env0_second_0:                 episode reward: 0.0000,                 loss: 0.8846
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 23221/30000 (77.4033%),                 avg. length: 1784.0,                last time consumption/overall running time: 239.6442s / 193253.5100 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2636
env0_second_0:                 episode reward: 0.0000,                 loss: 0.7768
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 23241/30000 (77.4700%),                 avg. length: 1784.0,                last time consumption/overall running time: 238.0808s / 193491.5908 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2580
env0_second_0:                 episode reward: 0.0000,                 loss: 0.8312
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 23261/30000 (77.5367%),                 avg. length: 1784.0,                last time consumption/overall running time: 247.2361s / 193738.8269 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2735
env0_second_0:                 episode reward: 0.0000,                 loss: 0.7221
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 23281/30000 (77.6033%),                 avg. length: 1784.0,                last time consumption/overall running time: 249.0818s / 193987.9087 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2691
env0_second_0:                 episode reward: 0.0000,                 loss: 0.6781
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 23301/30000 (77.6700%),                 avg. length: 1784.0,                last time consumption/overall running time: 239.2905s / 194227.1991 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2721
env0_second_0:                 episode reward: 0.0000,                 loss: 0.6387
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 23321/30000 (77.7367%),                 avg. length: 1784.0,                last time consumption/overall running time: 244.1172s / 194471.3164 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2653
env0_second_0:                 episode reward: 0.0000,                 loss: 1.3030
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 23341/30000 (77.8033%),                 avg. length: 1784.0,                last time consumption/overall running time: 236.6776s / 194707.9940 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2765
env0_second_0:                 episode reward: 0.0000,                 loss: 1.0545
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 23361/30000 (77.8700%),                 avg. length: 1784.0,                last time consumption/overall running time: 247.4465s / 194955.4405 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2797
env0_second_0:                 episode reward: 0.0000,                 loss: 1.0607
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 23381/30000 (77.9367%),                 avg. length: 1784.0,                last time consumption/overall running time: 242.8408s / 195198.2813 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2710
env0_second_0:                 episode reward: 0.0000,                 loss: 0.7287
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 23401/30000 (78.0033%),                 avg. length: 1784.0,                last time consumption/overall running time: 235.2370s / 195433.5184 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2547
env0_second_0:                 episode reward: 0.0000,                 loss: 0.5868
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 23421/30000 (78.0700%),                 avg. length: 1784.0,                last time consumption/overall running time: 238.8290s / 195672.3474 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2632
env0_second_0:                 episode reward: 0.0000,                 loss: 0.5252
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 23441/30000 (78.1367%),                 avg. length: 1784.0,                last time consumption/overall running time: 251.6390s / 195923.9864 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2719
env0_second_0:                 episode reward: 0.0000,                 loss: 0.4171
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 23461/30000 (78.2033%),                 avg. length: 1784.0,                last time consumption/overall running time: 238.2909s / 196162.2773 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2806
env0_second_0:                 episode reward: 0.0000,                 loss: 0.3826
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 23481/30000 (78.2700%),                 avg. length: 1784.0,                last time consumption/overall running time: 246.8679s / 196409.1452 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2513
env0_second_0:                 episode reward: 0.0000,                 loss: 0.4488
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 23501/30000 (78.3367%),                 avg. length: 1784.0,                last time consumption/overall running time: 255.0370s / 196664.1822 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2870
env0_second_0:                 episode reward: 0.0000,                 loss: 0.3346
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 23521/30000 (78.4033%),                 avg. length: 1784.0,                last time consumption/overall running time: 244.7970s / 196908.9792 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2847
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2878
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 23541/30000 (78.4700%),                 avg. length: 1784.0,                last time consumption/overall running time: 246.2183s / 197155.1974 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2873
env0_second_0:                 episode reward: 0.0000,                 loss: 0.3230
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 23561/30000 (78.5367%),                 avg. length: 1784.0,                last time consumption/overall running time: 241.3065s / 197396.5039 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2877
env0_second_0:                 episode reward: 0.0000,                 loss: 0.3440
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 23581/30000 (78.6033%),                 avg. length: 1784.0,                last time consumption/overall running time: 242.8079s / 197639.3118 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2948
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2442
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 23601/30000 (78.6700%),                 avg. length: 1784.0,                last time consumption/overall running time: 250.7367s / 197890.0485 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2972
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2802
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 23621/30000 (78.7367%),                 avg. length: 1784.0,                last time consumption/overall running time: 240.2287s / 198130.2772 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2947
env0_second_0:                 episode reward: 0.0000,                 loss: 0.3584
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 23641/30000 (78.8033%),                 avg. length: 1784.0,                last time consumption/overall running time: 243.6293s / 198373.9065 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2951
env0_second_0:                 episode reward: 0.0000,                 loss: 0.7564
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 23661/30000 (78.8700%),                 avg. length: 1784.0,                last time consumption/overall running time: 237.6738s / 198611.5803 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2875
env0_second_0:                 episode reward: 0.0000,                 loss: 1.2517
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 23681/30000 (78.9367%),                 avg. length: 1784.0,                last time consumption/overall running time: 243.4363s / 198855.0167 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.3036
env0_second_0:                 episode reward: 0.0000,                 loss: 0.5297
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 23701/30000 (79.0033%),                 avg. length: 1784.0,                last time consumption/overall running time: 254.1606s / 199109.1773 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2972
env0_second_0:                 episode reward: 0.0000,                 loss: 0.3073
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 23721/30000 (79.0700%),                 avg. length: 1784.0,                last time consumption/overall running time: 240.1368s / 199349.3141 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.3005
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2540
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 23741/30000 (79.1367%),                 avg. length: 1784.0,                last time consumption/overall running time: 246.5997s / 199595.9138 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.3014
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2667
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 23761/30000 (79.2033%),                 avg. length: 1784.0,                last time consumption/overall running time: 251.1564s / 199847.0702 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2991
env0_second_0:                 episode reward: 0.0000,                 loss: 0.1737
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 23781/30000 (79.2700%),                 avg. length: 1784.0,                last time consumption/overall running time: 245.0820s / 200092.1522 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2874
env0_second_0:                 episode reward: 0.0000,                 loss: 0.1141
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 23801/30000 (79.3367%),                 avg. length: 1784.0,                last time consumption/overall running time: 247.1423s / 200339.2945 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2833
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2315
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 23821/30000 (79.4033%),                 avg. length: 1784.0,                last time consumption/overall running time: 237.9771s / 200577.2716 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2795
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2330
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 23841/30000 (79.4700%),                 avg. length: 1784.0,                last time consumption/overall running time: 242.8423s / 200820.1139 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2705
env0_second_0:                 episode reward: 0.0000,                 loss: 3.6821
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 23861/30000 (79.5367%),                 avg. length: 1784.0,                last time consumption/overall running time: 233.2777s / 201053.3915 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2778
env0_second_0:                 episode reward: 0.0000,                 loss: 0.3481
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 23881/30000 (79.6033%),                 avg. length: 1784.0,                last time consumption/overall running time: 237.2912s / 201290.6827 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2938
env0_second_0:                 episode reward: 0.0000,                 loss: 0.3300
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 23901/30000 (79.6700%),                 avg. length: 1784.0,                last time consumption/overall running time: 246.7992s / 201537.4819 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2920
env0_second_0:                 episode reward: 0.0000,                 loss: 0.6354
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 23921/30000 (79.7367%),                 avg. length: 1784.0,                last time consumption/overall running time: 246.0649s / 201783.5468 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2794
env0_second_0:                 episode reward: 0.0000,                 loss: 0.6954
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 23941/30000 (79.8033%),                 avg. length: 1784.0,                last time consumption/overall running time: 247.0063s / 202030.5531 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2732
env0_second_0:                 episode reward: 0.0000,                 loss: 1.4192
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 23961/30000 (79.8700%),                 avg. length: 1784.0,                last time consumption/overall running time: 242.4110s / 202272.9641 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2674
env0_second_0:                 episode reward: 0.0000,                 loss: 1.4568
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 23981/30000 (79.9367%),                 avg. length: 1784.0,                last time consumption/overall running time: 239.2787s / 202512.2428 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2633
env0_second_0:                 episode reward: 0.0000,                 loss: 1.7775
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 24001/30000 (80.0033%),                 avg. length: 1784.0,                last time consumption/overall running time: 242.8268s / 202755.0696 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2704
env0_second_0:                 episode reward: 0.0000,                 loss: 1.6940
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 24021/30000 (80.0700%),                 avg. length: 1784.0,                last time consumption/overall running time: 236.6230s / 202991.6926 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2585
env0_second_0:                 episode reward: 0.0000,                 loss: 0.9581
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 24041/30000 (80.1367%),                 avg. length: 1779.05,                last time consumption/overall running time: 241.9717s / 203233.6643 s
env0_first_0:                 episode reward: -14.6500,                 loss: 1.1995
env0_second_0:                 episode reward: 14.6500,                 loss: 2.1741
env1_first_0:                 episode reward: -15.8000,                 loss: nan
env1_second_0:                 episode reward: 15.8000,                 loss: nan
Episode: 24061/30000 (80.2033%),                 avg. length: 1560.75,                last time consumption/overall running time: 231.7089s / 203465.3732 s
env0_first_0:                 episode reward: -44.9000,                 loss: 4.2402
env0_second_0:                 episode reward: 44.9000,                 loss: 5.5128
env1_first_0:                 episode reward: -40.8000,                 loss: nan
env1_second_0:                 episode reward: 40.8000,                 loss: nan
Episode: 24081/30000 (80.2700%),                 avg. length: 1713.95,                last time consumption/overall running time: 250.0551s / 203715.4282 s
env0_first_0:                 episode reward: -25.5000,                 loss: 1.8917
env0_second_0:                 episode reward: 25.5000,                 loss: 3.3238
env1_first_0:                 episode reward: -23.4500,                 loss: nan
env1_second_0:                 episode reward: 23.4500,                 loss: nan
Episode: 24101/30000 (80.3367%),                 avg. length: 1784.0,                last time consumption/overall running time: 242.7158s / 203958.1441 s
env0_first_0:                 episode reward: -12.1500,                 loss: 0.4188
env0_second_0:                 episode reward: 12.1500,                 loss: 2.1947
env1_first_0:                 episode reward: -12.7500,                 loss: nan
env1_second_0:                 episode reward: 12.7500,                 loss: nan
Episode: 24121/30000 (80.4033%),                 avg. length: 862.55,                last time consumption/overall running time: 119.3321s / 204077.4762 s
env0_first_0:                 episode reward: -69.1500,                 loss: 16.0597
env0_second_0:                 episode reward: 69.1500,                 loss: 18.7657
env1_first_0:                 episode reward: -67.8500,                 loss: nan
env1_second_0:                 episode reward: 67.8500,                 loss: nan
Episode: 24141/30000 (80.4700%),                 avg. length: 537.85,                last time consumption/overall running time: 79.2243s / 204156.7005 s
env0_first_0:                 episode reward: -67.0500,                 loss: 28.3433
env0_second_0:                 episode reward: 67.0500,                 loss: 31.5745
env1_first_0:                 episode reward: -81.5000,                 loss: nan
env1_second_0:                 episode reward: 81.5000,                 loss: nan
Episode: 24161/30000 (80.5367%),                 avg. length: 290.0,                last time consumption/overall running time: 47.3866s / 204204.0871 s
env0_first_0:                 episode reward: -83.3500,                 loss: 42.0156
env0_second_0:                 episode reward: 83.3500,                 loss: 44.7760
env1_first_0:                 episode reward: -81.4500,                 loss: nan
env1_second_0:                 episode reward: 81.4500,                 loss: nan
Episode: 24181/30000 (80.6033%),                 avg. length: 263.75,                last time consumption/overall running time: 43.5555s / 204247.6426 s
env0_first_0:                 episode reward: -85.3000,                 loss: 32.2980
env0_second_0:                 episode reward: 85.3000,                 loss: 35.9097
env1_first_0:                 episode reward: -87.2000,                 loss: nan
env1_second_0:                 episode reward: 87.2000,                 loss: nan
Episode: 24201/30000 (80.6700%),                 avg. length: 290.1,                last time consumption/overall running time: 47.1463s / 204294.7889 s
env0_first_0:                 episode reward: -79.8500,                 loss: 29.2320
env0_second_0:                 episode reward: 79.8500,                 loss: 36.8336
env1_first_0:                 episode reward: -75.9500,                 loss: nan
env1_second_0:                 episode reward: 75.9500,                 loss: nan
Episode: 24221/30000 (80.7367%),                 avg. length: 254.25,                last time consumption/overall running time: 42.9483s / 204337.7373 s
env0_first_0:                 episode reward: -84.5000,                 loss: 32.4327
env0_second_0:                 episode reward: 84.5000,                 loss: 39.5542
env1_first_0:                 episode reward: -84.7000,                 loss: nan
env1_second_0:                 episode reward: 84.7000,                 loss: nan
Episode: 24241/30000 (80.8033%),                 avg. length: 268.95,                last time consumption/overall running time: 43.9556s / 204381.6929 s
env0_first_0:                 episode reward: -84.4000,                 loss: 36.7464
env0_second_0:                 episode reward: 84.4000,                 loss: 42.3794
env1_first_0:                 episode reward: -71.2000,                 loss: nan
env1_second_0:                 episode reward: 71.2000,                 loss: nan
Episode: 24261/30000 (80.8700%),                 avg. length: 342.2,                last time consumption/overall running time: 53.1242s / 204434.8171 s
env0_first_0:                 episode reward: -82.7500,                 loss: 32.3175
env0_second_0:                 episode reward: 82.7500,                 loss: 35.0544
env1_first_0:                 episode reward: -78.6500,                 loss: nan
env1_second_0:                 episode reward: 78.6500,                 loss: nan
Episode: 24281/30000 (80.9367%),                 avg. length: 393.5,                last time consumption/overall running time: 61.2408s / 204496.0579 s
env0_first_0:                 episode reward: -65.0500,                 loss: 34.2410
env0_second_0:                 episode reward: 65.0500,                 loss: 38.4074
env1_first_0:                 episode reward: -69.6500,                 loss: nan
env1_second_0:                 episode reward: 69.6500,                 loss: nan
Episode: 24301/30000 (81.0033%),                 avg. length: 463.05,                last time consumption/overall running time: 72.1510s / 204568.2088 s
env0_first_0:                 episode reward: -76.0000,                 loss: 34.5806
env0_second_0:                 episode reward: 76.0000,                 loss: 39.3588
env1_first_0:                 episode reward: -72.4000,                 loss: nan
env1_second_0:                 episode reward: 72.4000,                 loss: nan
Episode: 24321/30000 (81.0700%),                 avg. length: 390.7,                last time consumption/overall running time: 60.1360s / 204628.3448 s
env0_first_0:                 episode reward: -69.6500,                 loss: 44.4540
env0_second_0:                 episode reward: 69.6500,                 loss: 49.1625
env1_first_0:                 episode reward: -59.7000,                 loss: nan
env1_second_0:                 episode reward: 59.7000,                 loss: nan
Episode: 24341/30000 (81.1367%),                 avg. length: 327.25,                last time consumption/overall running time: 51.9151s / 204680.2599 s
env0_first_0:                 episode reward: -55.8500,                 loss: 50.9456
env0_second_0:                 episode reward: 55.8500,                 loss: 54.7162
env1_first_0:                 episode reward: -73.5500,                 loss: nan
env1_second_0:                 episode reward: 73.5500,                 loss: nan
Episode: 24361/30000 (81.2033%),                 avg. length: 631.25,                last time consumption/overall running time: 92.1030s / 204772.3629 s
env0_first_0:                 episode reward: -58.2500,                 loss: 27.1901
env0_second_0:                 episode reward: 58.2500,                 loss: 29.2952
env1_first_0:                 episode reward: -61.7000,                 loss: nan
env1_second_0:                 episode reward: 61.7000,                 loss: nan
Episode: 24381/30000 (81.2700%),                 avg. length: 389.7,                last time consumption/overall running time: 60.1856s / 204832.5485 s
env0_first_0:                 episode reward: -82.1500,                 loss: 38.1046
env0_second_0:                 episode reward: 82.1500,                 loss: 43.3062
env1_first_0:                 episode reward: -66.1500,                 loss: nan
env1_second_0:                 episode reward: 66.1500,                 loss: nan
Episode: 24401/30000 (81.3367%),                 avg. length: 365.95,                last time consumption/overall running time: 58.1179s / 204890.6664 s
env0_first_0:                 episode reward: -59.6000,                 loss: 41.1307
env0_second_0:                 episode reward: 59.6000,                 loss: 46.6167
env1_first_0:                 episode reward: -70.1500,                 loss: nan
env1_second_0:                 episode reward: 70.1500,                 loss: nan
Episode: 24421/30000 (81.4033%),                 avg. length: 474.0,                last time consumption/overall running time: 72.6681s / 204963.3345 s
env0_first_0:                 episode reward: -58.3000,                 loss: 38.1589
env0_second_0:                 episode reward: 58.3000,                 loss: 42.2844
env1_first_0:                 episode reward: -64.8000,                 loss: nan
env1_second_0:                 episode reward: 64.8000,                 loss: nan
Episode: 24441/30000 (81.4700%),                 avg. length: 532.4,                last time consumption/overall running time: 79.8469s / 205043.1813 s
env0_first_0:                 episode reward: -51.7000,                 loss: 38.2190
env0_second_0:                 episode reward: 51.7000,                 loss: 42.2760
env1_first_0:                 episode reward: -54.4500,                 loss: nan
env1_second_0:                 episode reward: 54.4500,                 loss: nan
Episode: 24461/30000 (81.5367%),                 avg. length: 836.55,                last time consumption/overall running time: 131.0882s / 205174.2695 s
env0_first_0:                 episode reward: -36.9000,                 loss: 25.1821
env0_second_0:                 episode reward: 36.9000,                 loss: 28.1062
env1_first_0:                 episode reward: -35.6000,                 loss: nan
env1_second_0:                 episode reward: 35.6000,                 loss: nan
Episode: 24481/30000 (81.6033%),                 avg. length: 803.55,                last time consumption/overall running time: 111.1522s / 205285.4217 s
env0_first_0:                 episode reward: -46.6000,                 loss: 27.6848
env0_second_0:                 episode reward: 46.6000,                 loss: 31.6178
env1_first_0:                 episode reward: -34.9000,                 loss: nan
env1_second_0:                 episode reward: 34.9000,                 loss: nan
Episode: 24501/30000 (81.6700%),                 avg. length: 507.5,                last time consumption/overall running time: 76.4238s / 205361.8456 s
env0_first_0:                 episode reward: -67.3500,                 loss: 36.3128
env0_second_0:                 episode reward: 67.3500,                 loss: 39.2661
env1_first_0:                 episode reward: -44.3000,                 loss: nan
env1_second_0:                 episode reward: 44.3000,                 loss: nan
Episode: 24521/30000 (81.7367%),                 avg. length: 481.6,                last time consumption/overall running time: 76.9443s / 205438.7899 s
env0_first_0:                 episode reward: -54.4500,                 loss: 35.6059
env0_second_0:                 episode reward: 54.4500,                 loss: 37.0211
env1_first_0:                 episode reward: -64.9000,                 loss: nan
env1_second_0:                 episode reward: 64.9000,                 loss: nan
Episode: 24541/30000 (81.8033%),                 avg. length: 494.3,                last time consumption/overall running time: 72.5552s / 205511.3451 s
env0_first_0:                 episode reward: -42.2500,                 loss: 39.9175
env0_second_0:                 episode reward: 42.2500,                 loss: 42.7487
env1_first_0:                 episode reward: -76.2000,                 loss: nan
env1_second_0:                 episode reward: 76.2000,                 loss: nan
Episode: 24561/30000 (81.8700%),                 avg. length: 758.7,                last time consumption/overall running time: 108.1771s / 205619.5222 s
env0_first_0:                 episode reward: -57.8000,                 loss: 33.4344
env0_second_0:                 episode reward: 57.8000,                 loss: 34.0825
env1_first_0:                 episode reward: -57.0000,                 loss: nan
env1_second_0:                 episode reward: 57.0000,                 loss: nan
Episode: 24581/30000 (81.9367%),                 avg. length: 996.7,                last time consumption/overall running time: 134.5264s / 205754.0486 s
env0_first_0:                 episode reward: -50.1000,                 loss: 19.9481
env0_second_0:                 episode reward: 50.1000,                 loss: 21.7800
env1_first_0:                 episode reward: -40.6000,                 loss: nan
env1_second_0:                 episode reward: 40.6000,                 loss: nan
Episode: 24601/30000 (82.0033%),                 avg. length: 559.8,                last time consumption/overall running time: 84.4962s / 205838.5448 s
env0_first_0:                 episode reward: -55.3500,                 loss: 36.4502
env0_second_0:                 episode reward: 55.3500,                 loss: 38.5002
env1_first_0:                 episode reward: -59.8000,                 loss: nan
env1_second_0:                 episode reward: 59.8000,                 loss: nan
Episode: 24621/30000 (82.0700%),                 avg. length: 612.65,                last time consumption/overall running time: 88.2913s / 205926.8361 s
env0_first_0:                 episode reward: -49.1000,                 loss: 36.2765
env0_second_0:                 episode reward: 49.1000,                 loss: 38.4484
env1_first_0:                 episode reward: -50.3500,                 loss: nan
env1_second_0:                 episode reward: 50.3500,                 loss: nan
Episode: 24641/30000 (82.1367%),                 avg. length: 408.4,                last time consumption/overall running time: 61.9218s / 205988.7580 s
env0_first_0:                 episode reward: -71.9500,                 loss: 49.8914
env0_second_0:                 episode reward: 71.9500,                 loss: 54.7862
env1_first_0:                 episode reward: -50.2000,                 loss: nan
env1_second_0:                 episode reward: 50.2000,                 loss: nan
Episode: 24661/30000 (82.2033%),                 avg. length: 839.35,                last time consumption/overall running time: 115.8846s / 206104.6426 s
env0_first_0:                 episode reward: -39.8500,                 loss: 31.2088
env0_second_0:                 episode reward: 39.8500,                 loss: 34.0278
env1_first_0:                 episode reward: -41.4000,                 loss: nan
env1_second_0:                 episode reward: 41.4000,                 loss: nan
Episode: 24681/30000 (82.2700%),                 avg. length: 573.9,                last time consumption/overall running time: 83.3460s / 206187.9886 s
env0_first_0:                 episode reward: -51.4500,                 loss: 41.9122
env0_second_0:                 episode reward: 51.4500,                 loss: 42.1943
env1_first_0:                 episode reward: -59.7500,                 loss: nan
env1_second_0:                 episode reward: 59.7500,                 loss: nan
Episode: 24701/30000 (82.3367%),                 avg. length: 611.25,                last time consumption/overall running time: 90.9576s / 206278.9462 s
env0_first_0:                 episode reward: -52.7000,                 loss: 42.8817
env0_second_0:                 episode reward: 52.7000,                 loss: 45.1665
env1_first_0:                 episode reward: -48.1500,                 loss: nan
env1_second_0:                 episode reward: 48.1500,                 loss: nan
Episode: 24721/30000 (82.4033%),                 avg. length: 749.25,                last time consumption/overall running time: 105.4997s / 206384.4459 s
env0_first_0:                 episode reward: -65.0500,                 loss: 29.6777
env0_second_0:                 episode reward: 65.0500,                 loss: 30.7156
env1_first_0:                 episode reward: -50.9000,                 loss: nan
env1_second_0:                 episode reward: 50.9000,                 loss: nan
Episode: 24741/30000 (82.4700%),                 avg. length: 418.0,                last time consumption/overall running time: 62.6256s / 206447.0715 s
env0_first_0:                 episode reward: -68.2500,                 loss: 47.4555
env0_second_0:                 episode reward: 68.2500,                 loss: 50.1459
env1_first_0:                 episode reward: -60.9500,                 loss: nan
env1_second_0:                 episode reward: 60.9500,                 loss: nan
Episode: 24761/30000 (82.5367%),                 avg. length: 775.3,                last time consumption/overall running time: 107.4639s / 206554.5354 s
env0_first_0:                 episode reward: -27.6500,                 loss: 41.8654
env0_second_0:                 episode reward: 27.6500,                 loss: 45.6037
env1_first_0:                 episode reward: -37.5000,                 loss: nan
env1_second_0:                 episode reward: 37.5000,                 loss: nan
Episode: 24781/30000 (82.6033%),                 avg. length: 1291.6,                last time consumption/overall running time: 177.7235s / 206732.2589 s
env0_first_0:                 episode reward: 0.1500,                 loss: 10.8863
env0_second_0:                 episode reward: -0.1500,                 loss: 18.5306
env1_first_0:                 episode reward: 18.0000,                 loss: nan
env1_second_0:                 episode reward: -18.0000,                 loss: nan
Episode: 24801/30000 (82.6700%),                 avg. length: 1573.45,                last time consumption/overall running time: 216.8271s / 206949.0860 s
env0_first_0:                 episode reward: -2.3500,                 loss: 4.9778
env0_second_0:                 episode reward: 2.3500,                 loss: 9.8868
env1_first_0:                 episode reward: -2.3000,                 loss: nan
env1_second_0:                 episode reward: 2.3000,                 loss: nan
Episode: 24821/30000 (82.7367%),                 avg. length: 1443.25,                last time consumption/overall running time: 193.0469s / 207142.1329 s
env0_first_0:                 episode reward: -7.0500,                 loss: 7.1111
env0_second_0:                 episode reward: 7.0500,                 loss: 11.2774
env1_first_0:                 episode reward: -13.4500,                 loss: nan
env1_second_0:                 episode reward: 13.4500,                 loss: nan
Episode: 24841/30000 (82.8033%),                 avg. length: 1253.75,                last time consumption/overall running time: 173.7329s / 207315.8659 s
env0_first_0:                 episode reward: -0.4500,                 loss: 15.5693
env0_second_0:                 episode reward: 0.4500,                 loss: 20.4673
env1_first_0:                 episode reward: -12.8500,                 loss: nan
env1_second_0:                 episode reward: 12.8500,                 loss: nan
Episode: 24861/30000 (82.8700%),                 avg. length: 1478.35,                last time consumption/overall running time: 198.5333s / 207514.3991 s
env0_first_0:                 episode reward: -19.4500,                 loss: 14.3811
env0_second_0:                 episode reward: 19.4500,                 loss: 17.0775
env1_first_0:                 episode reward: -11.8000,                 loss: nan
env1_second_0:                 episode reward: 11.8000,                 loss: nan
Episode: 24881/30000 (82.9367%),                 avg. length: 1331.2,                last time consumption/overall running time: 176.6906s / 207691.0898 s
env0_first_0:                 episode reward: -25.6500,                 loss: 15.0744
env0_second_0:                 episode reward: 25.6500,                 loss: 17.6447
env1_first_0:                 episode reward: -8.4000,                 loss: nan
env1_second_0:                 episode reward: 8.4000,                 loss: nan
Episode: 24901/30000 (83.0033%),                 avg. length: 1111.35,                last time consumption/overall running time: 151.0028s / 207842.0926 s
env0_first_0:                 episode reward: -33.3500,                 loss: 28.2799
env0_second_0:                 episode reward: 33.3500,                 loss: 33.6359
env1_first_0:                 episode reward: -32.8500,                 loss: nan
env1_second_0:                 episode reward: 32.8500,                 loss: nan
Episode: 24921/30000 (83.0700%),                 avg. length: 786.75,                last time consumption/overall running time: 111.9547s / 207954.0473 s
env0_first_0:                 episode reward: -53.0000,                 loss: 32.3112
env0_second_0:                 episode reward: 53.0000,                 loss: 35.9751
env1_first_0:                 episode reward: -60.1500,                 loss: nan
env1_second_0:                 episode reward: 60.1500,                 loss: nan
Episode: 24941/30000 (83.1367%),                 avg. length: 796.55,                last time consumption/overall running time: 111.0309s / 208065.0782 s
env0_first_0:                 episode reward: -59.2500,                 loss: 34.1202
env0_second_0:                 episode reward: 59.2500,                 loss: 37.8186
env1_first_0:                 episode reward: -56.1000,                 loss: nan
env1_second_0:                 episode reward: 56.1000,                 loss: nan
Episode: 24961/30000 (83.2033%),                 avg. length: 427.45,                last time consumption/overall running time: 65.2558s / 208130.3340 s
env0_first_0:                 episode reward: -56.3000,                 loss: 46.8507
env0_second_0:                 episode reward: 56.3000,                 loss: 50.8300
env1_first_0:                 episode reward: -70.1000,                 loss: nan
env1_second_0:                 episode reward: 70.1000,                 loss: nan
Episode: 24981/30000 (83.2700%),                 avg. length: 437.4,                last time consumption/overall running time: 67.3935s / 208197.7275 s
env0_first_0:                 episode reward: -67.3000,                 loss: 35.3281
env0_second_0:                 episode reward: 67.3000,                 loss: 40.3988
env1_first_0:                 episode reward: -60.4500,                 loss: nan
env1_second_0:                 episode reward: 60.4500,                 loss: nan
Episode: 25001/30000 (83.3367%),                 avg. length: 317.45,                last time consumption/overall running time: 54.0000s / 208251.7275 s
env0_first_0:                 episode reward: -52.6500,                 loss: 50.7766
env0_second_0:                 episode reward: 52.6500,                 loss: 56.3335
env1_first_0:                 episode reward: -80.4000,                 loss: nan
env1_second_0:                 episode reward: 80.4000,                 loss: nan
Episode: 25021/30000 (83.4033%),                 avg. length: 360.8,                last time consumption/overall running time: 55.5011s / 208307.2286 s
env0_first_0:                 episode reward: -66.9000,                 loss: 42.5447
env0_second_0:                 episode reward: 66.9000,                 loss: 46.1755
env1_first_0:                 episode reward: -71.9500,                 loss: nan
env1_second_0:                 episode reward: 71.9500,                 loss: nan
Episode: 25041/30000 (83.4700%),                 avg. length: 538.15,                last time consumption/overall running time: 77.8034s / 208385.0319 s
env0_first_0:                 episode reward: -56.6000,                 loss: 26.9606
env0_second_0:                 episode reward: 56.6000,                 loss: 28.4118
env1_first_0:                 episode reward: -53.2500,                 loss: nan
env1_second_0:                 episode reward: 53.2500,                 loss: nan
Episode: 25061/30000 (83.5367%),                 avg. length: 488.55,                last time consumption/overall running time: 72.2508s / 208457.2827 s
env0_first_0:                 episode reward: -58.8500,                 loss: 36.5778
env0_second_0:                 episode reward: 58.8500,                 loss: 40.9997
env1_first_0:                 episode reward: -62.7500,                 loss: nan
env1_second_0:                 episode reward: 62.7500,                 loss: nan
Episode: 25081/30000 (83.6033%),                 avg. length: 625.2,                last time consumption/overall running time: 92.1831s / 208549.4658 s
env0_first_0:                 episode reward: -47.6500,                 loss: 35.1672
env0_second_0:                 episode reward: 47.6500,                 loss: 37.5765
env1_first_0:                 episode reward: -50.7000,                 loss: nan
env1_second_0:                 episode reward: 50.7000,                 loss: nan
Episode: 25101/30000 (83.6700%),                 avg. length: 856.35,                last time consumption/overall running time: 121.8310s / 208671.2968 s
env0_first_0:                 episode reward: -29.3500,                 loss: 22.4317
env0_second_0:                 episode reward: 29.3500,                 loss: 25.0522
env1_first_0:                 episode reward: -44.1500,                 loss: nan
env1_second_0:                 episode reward: 44.1500,                 loss: nan
Episode: 25121/30000 (83.7367%),                 avg. length: 625.7,                last time consumption/overall running time: 87.9711s / 208759.2679 s
env0_first_0:                 episode reward: -58.8500,                 loss: 39.8712
env0_second_0:                 episode reward: 58.8500,                 loss: 42.3561
env1_first_0:                 episode reward: -34.2000,                 loss: nan
env1_second_0:                 episode reward: 34.2000,                 loss: nan
Episode: 25141/30000 (83.8033%),                 avg. length: 567.05,                last time consumption/overall running time: 85.1628s / 208844.4307 s
env0_first_0:                 episode reward: -75.1000,                 loss: 48.7516
env0_second_0:                 episode reward: 75.1000,                 loss: 50.0029
env1_first_0:                 episode reward: -41.7500,                 loss: nan
env1_second_0:                 episode reward: 41.7500,                 loss: nan
Episode: 25161/30000 (83.8700%),                 avg. length: 651.65,                last time consumption/overall running time: 92.1826s / 208936.6133 s
env0_first_0:                 episode reward: -53.1000,                 loss: 44.7950
env0_second_0:                 episode reward: 53.1000,                 loss: 48.9998
env1_first_0:                 episode reward: -56.7000,                 loss: nan
env1_second_0:                 episode reward: 56.7000,                 loss: nan
Episode: 25181/30000 (83.9367%),                 avg. length: 784.95,                last time consumption/overall running time: 108.4710s / 209045.0843 s
env0_first_0:                 episode reward: -54.7500,                 loss: 38.2310
env0_second_0:                 episode reward: 54.7500,                 loss: 39.5376
env1_first_0:                 episode reward: -42.2000,                 loss: nan
env1_second_0:                 episode reward: 42.2000,                 loss: nan
Episode: 25201/30000 (84.0033%),                 avg. length: 372.35,                last time consumption/overall running time: 58.6199s / 209103.7043 s
env0_first_0:                 episode reward: -56.6000,                 loss: 63.3312
env0_second_0:                 episode reward: 56.6000,                 loss: 66.3737
env1_first_0:                 episode reward: -61.3500,                 loss: nan
env1_second_0:                 episode reward: 61.3500,                 loss: nan
Episode: 25221/30000 (84.0700%),                 avg. length: 722.85,                last time consumption/overall running time: 103.2828s / 209206.9871 s
env0_first_0:                 episode reward: -53.0500,                 loss: 46.8386
env0_second_0:                 episode reward: 53.0500,                 loss: 48.4524
env1_first_0:                 episode reward: -43.0000,                 loss: nan
env1_second_0:                 episode reward: 43.0000,                 loss: nan
Episode: 25241/30000 (84.1367%),                 avg. length: 422.95,                last time consumption/overall running time: 64.5487s / 209271.5358 s
env0_first_0:                 episode reward: -61.4500,                 loss: 50.8490
env0_second_0:                 episode reward: 61.4500,                 loss: 55.2528
env1_first_0:                 episode reward: -79.4500,                 loss: nan
env1_second_0:                 episode reward: 79.4500,                 loss: nan
Episode: 25261/30000 (84.2033%),                 avg. length: 787.45,                last time consumption/overall running time: 109.2237s / 209380.7595 s
env0_first_0:                 episode reward: -44.3500,                 loss: 36.9470
env0_second_0:                 episode reward: 44.3500,                 loss: 40.5384
env1_first_0:                 episode reward: -46.8000,                 loss: nan
env1_second_0:                 episode reward: 46.8000,                 loss: nan
Episode: 25281/30000 (84.2700%),                 avg. length: 719.25,                last time consumption/overall running time: 103.7395s / 209484.4990 s
env0_first_0:                 episode reward: -37.9000,                 loss: 34.5390
env0_second_0:                 episode reward: 37.9000,                 loss: 38.2459
env1_first_0:                 episode reward: -41.7500,                 loss: nan
env1_second_0:                 episode reward: 41.7500,                 loss: nan
Episode: 25301/30000 (84.3367%),                 avg. length: 874.5,                last time consumption/overall running time: 120.8048s / 209605.3038 s
env0_first_0:                 episode reward: -49.7500,                 loss: 33.1762
env0_second_0:                 episode reward: 49.7500,                 loss: 36.4547
env1_first_0:                 episode reward: -6.9000,                 loss: nan
env1_second_0:                 episode reward: 6.9000,                 loss: nan
Episode: 25321/30000 (84.4033%),                 avg. length: 1451.25,                last time consumption/overall running time: 195.8137s / 209801.1175 s
env0_first_0:                 episode reward: -6.3000,                 loss: 12.6882
env0_second_0:                 episode reward: 6.3000,                 loss: 14.7375
env1_first_0:                 episode reward: -4.4500,                 loss: nan
env1_second_0:                 episode reward: 4.4500,                 loss: nan
Episode: 25341/30000 (84.4700%),                 avg. length: 1313.25,                last time consumption/overall running time: 178.5197s / 209979.6372 s
env0_first_0:                 episode reward: -23.5000,                 loss: 10.2798
env0_second_0:                 episode reward: 23.5000,                 loss: 12.0576
env1_first_0:                 episode reward: -16.1000,                 loss: nan
env1_second_0:                 episode reward: 16.1000,                 loss: nan
Episode: 25361/30000 (84.5367%),                 avg. length: 1784.0,                last time consumption/overall running time: 238.2085s / 210217.8458 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.4354
env0_second_0:                 episode reward: 0.1000,                 loss: 0.9180
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 25381/30000 (84.6033%),                 avg. length: 1784.0,                last time consumption/overall running time: 232.1133s / 210449.9591 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.1177
env0_second_0:                 episode reward: 0.0000,                 loss: 0.6387
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 25401/30000 (84.6700%),                 avg. length: 1678.7,                last time consumption/overall running time: 227.3128s / 210677.2719 s
env0_first_0:                 episode reward: -14.6000,                 loss: 7.9205
env0_second_0:                 episode reward: 14.6000,                 loss: 8.9761
env1_first_0:                 episode reward: -15.4000,                 loss: nan
env1_second_0:                 episode reward: 15.4000,                 loss: nan
Episode: 25421/30000 (84.7367%),                 avg. length: 888.55,                last time consumption/overall running time: 123.7038s / 210800.9757 s
env0_first_0:                 episode reward: -41.8500,                 loss: 29.8091
env0_second_0:                 episode reward: 41.8500,                 loss: 32.2691
env1_first_0:                 episode reward: -36.8500,                 loss: nan
env1_second_0:                 episode reward: 36.8500,                 loss: nan
Episode: 25441/30000 (84.8033%),                 avg. length: 249.9,                last time consumption/overall running time: 41.7525s / 210842.7282 s
env0_first_0:                 episode reward: -94.2500,                 loss: 24.8424
env0_second_0:                 episode reward: 94.2500,                 loss: 24.3328
env1_first_0:                 episode reward: -94.6500,                 loss: nan
env1_second_0:                 episode reward: 94.6500,                 loss: nan
Episode: 25461/30000 (84.8700%),                 avg. length: 239.4,                last time consumption/overall running time: 41.9060s / 210884.6341 s
env0_first_0:                 episode reward: -97.4500,                 loss: 31.9292
env0_second_0:                 episode reward: 97.4500,                 loss: 32.4560
env1_first_0:                 episode reward: -77.6500,                 loss: nan
env1_second_0:                 episode reward: 77.6500,                 loss: nan
Episode: 25481/30000 (84.9367%),                 avg. length: 249.45,                last time consumption/overall running time: 42.6554s / 210927.2896 s
env0_first_0:                 episode reward: -89.6500,                 loss: 23.6780
env0_second_0:                 episode reward: 89.6500,                 loss: 22.8280
env1_first_0:                 episode reward: -90.3500,                 loss: nan
env1_second_0:                 episode reward: 90.3500,                 loss: nan
Episode: 25501/30000 (85.0033%),                 avg. length: 226.7,                last time consumption/overall running time: 39.5364s / 210966.8259 s
env0_first_0:                 episode reward: -95.4000,                 loss: 15.3190
env0_second_0:                 episode reward: 95.4000,                 loss: 14.1383
env1_first_0:                 episode reward: -99.1000,                 loss: nan
env1_second_0:                 episode reward: 99.1000,                 loss: nan
Episode: 25521/30000 (85.0700%),                 avg. length: 225.3,                last time consumption/overall running time: 38.5602s / 211005.3861 s
env0_first_0:                 episode reward: -92.4000,                 loss: 16.1432
env0_second_0:                 episode reward: 92.4000,                 loss: 14.2072
env1_first_0:                 episode reward: -99.5500,                 loss: nan
env1_second_0:                 episode reward: 99.5500,                 loss: nan
Episode: 25541/30000 (85.1367%),                 avg. length: 222.9,                last time consumption/overall running time: 38.8335s / 211044.2197 s
env0_first_0:                 episode reward: -99.3500,                 loss: 10.3703
env0_second_0:                 episode reward: 99.3500,                 loss: 10.1478
env1_first_0:                 episode reward: -99.1500,                 loss: nan
env1_second_0:                 episode reward: 99.1500,                 loss: nan
Episode: 25561/30000 (85.2033%),                 avg. length: 225.0,                last time consumption/overall running time: 39.2605s / 211083.4802 s
env0_first_0:                 episode reward: -96.8500,                 loss: 13.1650
env0_second_0:                 episode reward: 96.8500,                 loss: 13.4255
env1_first_0:                 episode reward: -94.0500,                 loss: nan
env1_second_0:                 episode reward: 94.0500,                 loss: nan
Episode: 25581/30000 (85.2700%),                 avg. length: 234.5,                last time consumption/overall running time: 40.0879s / 211123.5680 s
env0_first_0:                 episode reward: -84.7000,                 loss: 22.3155
env0_second_0:                 episode reward: 84.7000,                 loss: 25.1418
env1_first_0:                 episode reward: -82.5500,                 loss: nan
env1_second_0:                 episode reward: 82.5500,                 loss: nan
Episode: 25601/30000 (85.3367%),                 avg. length: 221.25,                last time consumption/overall running time: 38.7449s / 211162.3129 s
env0_first_0:                 episode reward: -95.4000,                 loss: 15.5390
env0_second_0:                 episode reward: 95.4000,                 loss: 14.1491
env1_first_0:                 episode reward: -94.7000,                 loss: nan
env1_second_0:                 episode reward: 94.7000,                 loss: nan
Episode: 25621/30000 (85.4033%),                 avg. length: 219.45,                last time consumption/overall running time: 37.7615s / 211200.0745 s
env0_first_0:                 episode reward: -99.6000,                 loss: 9.7350
env0_second_0:                 episode reward: 99.6000,                 loss: 9.2899
env1_first_0:                 episode reward: -97.1500,                 loss: nan
env1_second_0:                 episode reward: 97.1500,                 loss: nan
Episode: 25641/30000 (85.4700%),                 avg. length: 226.7,                last time consumption/overall running time: 37.5118s / 211237.5863 s
env0_first_0:                 episode reward: -93.5000,                 loss: 13.2476
env0_second_0:                 episode reward: 93.5000,                 loss: 12.6993
env1_first_0:                 episode reward: -93.3000,                 loss: nan
env1_second_0:                 episode reward: 93.3000,                 loss: nan
Episode: 25661/30000 (85.5367%),                 avg. length: 1081.5,                last time consumption/overall running time: 141.8692s / 211379.4555 s
env0_first_0:                 episode reward: -37.0500,                 loss: 9.8490
env0_second_0:                 episode reward: 37.0500,                 loss: 10.1830
env1_first_0:                 episode reward: -40.5500,                 loss: nan
env1_second_0:                 episode reward: 40.5500,                 loss: nan
Episode: 25681/30000 (85.6033%),                 avg. length: 834.65,                last time consumption/overall running time: 111.9333s / 211491.3887 s
env0_first_0:                 episode reward: -63.2000,                 loss: 23.9627
env0_second_0:                 episode reward: 63.2000,                 loss: 22.8422
env1_first_0:                 episode reward: -57.3500,                 loss: nan
env1_second_0:                 episode reward: 57.3500,                 loss: nan
Episode: 25701/30000 (85.6700%),                 avg. length: 1784.0,                last time consumption/overall running time: 236.6307s / 211728.0195 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.7932
env0_second_0:                 episode reward: 0.0000,                 loss: 0.6283
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 25721/30000 (85.7367%),                 avg. length: 1784.0,                last time consumption/overall running time: 242.0410s / 211970.0605 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2575
env0_second_0:                 episode reward: 0.0000,                 loss: 0.3221
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 25741/30000 (85.8033%),                 avg. length: 1705.55,                last time consumption/overall running time: 240.4991s / 212210.5596 s
env0_first_0:                 episode reward: -5.0000,                 loss: 3.8748
env0_second_0:                 episode reward: 5.0000,                 loss: 4.2977
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 25761/30000 (85.8700%),                 avg. length: 1784.0,                last time consumption/overall running time: 245.5711s / 212456.1307 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.1636
env0_second_0:                 episode reward: 0.0000,                 loss: 0.9767
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 25781/30000 (85.9367%),                 avg. length: 416.1,                last time consumption/overall running time: 61.1776s / 212517.3083 s
env0_first_0:                 episode reward: -68.0000,                 loss: 44.2882
env0_second_0:                 episode reward: 68.0000,                 loss: 41.6988
env1_first_0:                 episode reward: -71.9500,                 loss: nan
env1_second_0:                 episode reward: 71.9500,                 loss: nan
Episode: 25801/30000 (86.0033%),                 avg. length: 238.95,                last time consumption/overall running time: 38.9425s / 212556.2508 s
env0_first_0:                 episode reward: -91.8500,                 loss: 22.4372
env0_second_0:                 episode reward: 91.8500,                 loss: 22.9488
env1_first_0:                 episode reward: -94.3500,                 loss: nan
env1_second_0:                 episode reward: 94.3500,                 loss: nan
Episode: 25821/30000 (86.0700%),                 avg. length: 335.7,                last time consumption/overall running time: 51.6336s / 212607.8844 s
env0_first_0:                 episode reward: -79.3500,                 loss: 44.7448
env0_second_0:                 episode reward: 79.3500,                 loss: 43.9195
env1_first_0:                 episode reward: -68.9000,                 loss: nan
env1_second_0:                 episode reward: 68.9000,                 loss: nan
Episode: 25841/30000 (86.1367%),                 avg. length: 620.85,                last time consumption/overall running time: 86.9076s / 212694.7920 s
env0_first_0:                 episode reward: -58.5500,                 loss: 31.2678
env0_second_0:                 episode reward: 58.5500,                 loss: 33.1081
env1_first_0:                 episode reward: -69.7000,                 loss: nan
env1_second_0:                 episode reward: 69.7000,                 loss: nan
Episode: 25861/30000 (86.2033%),                 avg. length: 400.35,                last time consumption/overall running time: 60.2248s / 212755.0168 s
env0_first_0:                 episode reward: -54.5500,                 loss: 36.3289
env0_second_0:                 episode reward: 54.5500,                 loss: 36.6713
env1_first_0:                 episode reward: -70.7500,                 loss: nan
env1_second_0:                 episode reward: 70.7500,                 loss: nan
Episode: 25881/30000 (86.2700%),                 avg. length: 339.8,                last time consumption/overall running time: 50.4967s / 212805.5134 s
env0_first_0:                 episode reward: -74.0000,                 loss: 35.8764
env0_second_0:                 episode reward: 74.0000,                 loss: 38.5841
env1_first_0:                 episode reward: -60.8500,                 loss: nan
env1_second_0:                 episode reward: 60.8500,                 loss: nan
Episode: 25901/30000 (86.3367%),                 avg. length: 388.85,                last time consumption/overall running time: 58.4165s / 212863.9299 s
env0_first_0:                 episode reward: -66.6500,                 loss: 41.8232
env0_second_0:                 episode reward: 66.6500,                 loss: 46.4364
env1_first_0:                 episode reward: -69.1500,                 loss: nan
env1_second_0:                 episode reward: 69.1500,                 loss: nan
Episode: 25921/30000 (86.4033%),                 avg. length: 490.1,                last time consumption/overall running time: 70.4527s / 212934.3826 s
env0_first_0:                 episode reward: -43.1500,                 loss: 44.8197
env0_second_0:                 episode reward: 43.1500,                 loss: 48.8137
env1_first_0:                 episode reward: -74.2000,                 loss: nan
env1_second_0:                 episode reward: 74.2000,                 loss: nan
Episode: 25941/30000 (86.4700%),                 avg. length: 1287.25,                last time consumption/overall running time: 168.6001s / 213102.9827 s
env0_first_0:                 episode reward: -25.3500,                 loss: 12.1848
env0_second_0:                 episode reward: 25.3500,                 loss: 14.7381
env1_first_0:                 episode reward: -10.8500,                 loss: nan
env1_second_0:                 episode reward: 10.8500,                 loss: nan
Episode: 25961/30000 (86.5367%),                 avg. length: 1248.65,                last time consumption/overall running time: 163.8595s / 213266.8422 s
env0_first_0:                 episode reward: -25.7500,                 loss: 21.0224
env0_second_0:                 episode reward: 25.7500,                 loss: 21.9080
env1_first_0:                 episode reward: -20.4000,                 loss: nan
env1_second_0:                 episode reward: 20.4000,                 loss: nan
Episode: 25981/30000 (86.6033%),                 avg. length: 1265.65,                last time consumption/overall running time: 165.3099s / 213432.1521 s
env0_first_0:                 episode reward: -22.3500,                 loss: 21.6008
env0_second_0:                 episode reward: 22.3500,                 loss: 22.1184
env1_first_0:                 episode reward: -18.6500,                 loss: nan
env1_second_0:                 episode reward: 18.6500,                 loss: nan
Episode: 26001/30000 (86.6700%),                 avg. length: 1625.05,                last time consumption/overall running time: 214.2434s / 213646.3955 s
env0_first_0:                 episode reward: -6.1500,                 loss: 9.3435
env0_second_0:                 episode reward: 6.1500,                 loss: 9.8520
env1_first_0:                 episode reward: -10.6500,                 loss: nan
env1_second_0:                 episode reward: 10.6500,                 loss: nan
Episode: 26021/30000 (86.7367%),                 avg. length: 892.8,                last time consumption/overall running time: 121.5338s / 213767.9293 s
env0_first_0:                 episode reward: -21.4000,                 loss: 36.5100
env0_second_0:                 episode reward: 21.4000,                 loss: 38.7179
env1_first_0:                 episode reward: -53.8000,                 loss: nan
env1_second_0:                 episode reward: 53.8000,                 loss: nan
Episode: 26041/30000 (86.8033%),                 avg. length: 630.35,                last time consumption/overall running time: 87.9268s / 213855.8562 s
env0_first_0:                 episode reward: -53.8500,                 loss: 48.5902
env0_second_0:                 episode reward: 53.8500,                 loss: 51.7378
env1_first_0:                 episode reward: -53.0500,                 loss: nan
env1_second_0:                 episode reward: 53.0500,                 loss: nan
Episode: 26061/30000 (86.8700%),                 avg. length: 1560.2,                last time consumption/overall running time: 199.5497s / 214055.4059 s
env0_first_0:                 episode reward: -20.9500,                 loss: 9.4179
env0_second_0:                 episode reward: 20.9500,                 loss: 11.0060
env1_first_0:                 episode reward: -16.0000,                 loss: nan
env1_second_0:                 episode reward: 16.0000,                 loss: nan
Episode: 26081/30000 (86.9367%),                 avg. length: 1522.1,                last time consumption/overall running time: 198.2006s / 214253.6065 s
env0_first_0:                 episode reward: -7.1500,                 loss: 13.5271
env0_second_0:                 episode reward: 7.1500,                 loss: 16.5997
env1_first_0:                 episode reward: -15.6500,                 loss: nan
env1_second_0:                 episode reward: 15.6500,                 loss: nan
Episode: 26101/30000 (87.0033%),                 avg. length: 1740.65,                last time consumption/overall running time: 227.2595s / 214480.8660 s
env0_first_0:                 episode reward: -10.1000,                 loss: 3.7954
env0_second_0:                 episode reward: 10.1000,                 loss: 4.8486
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 26121/30000 (87.0700%),                 avg. length: 1549.9,                last time consumption/overall running time: 209.9238s / 214690.7898 s
env0_first_0:                 episode reward: -20.1500,                 loss: 10.0250
env0_second_0:                 episode reward: 20.1500,                 loss: 11.2555
env1_first_0:                 episode reward: -9.1500,                 loss: nan
env1_second_0:                 episode reward: 9.1500,                 loss: nan
Episode: 26141/30000 (87.1367%),                 avg. length: 1784.0,                last time consumption/overall running time: 233.3593s / 214924.1492 s
env0_first_0:                 episode reward: -13.1500,                 loss: 12.7143
env0_second_0:                 episode reward: 13.1500,                 loss: 17.1829
env1_first_0:                 episode reward: -12.2000,                 loss: nan
env1_second_0:                 episode reward: 12.2000,                 loss: nan
Episode: 26161/30000 (87.2033%),                 avg. length: 1784.0,                last time consumption/overall running time: 229.5965s / 215153.7457 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2402
env0_second_0:                 episode reward: 0.0000,                 loss: 1.2791
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 26181/30000 (87.2700%),                 avg. length: 1784.0,                last time consumption/overall running time: 231.2711s / 215385.0167 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.1023
env0_second_0:                 episode reward: 0.0000,                 loss: 0.4619
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 26201/30000 (87.3367%),                 avg. length: 1784.0,                last time consumption/overall running time: 245.3437s / 215630.3604 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.1159
env0_second_0:                 episode reward: 0.0000,                 loss: 0.1568
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 26221/30000 (87.4033%),                 avg. length: 1784.0,                last time consumption/overall running time: 232.0239s / 215862.3843 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0323
env0_second_0:                 episode reward: 0.0000,                 loss: 0.1394
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 26241/30000 (87.4700%),                 avg. length: 1784.0,                last time consumption/overall running time: 239.4078s / 216101.7921 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0079
env0_second_0:                 episode reward: 0.0000,                 loss: 0.1979
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 26261/30000 (87.5367%),                 avg. length: 1784.0,                last time consumption/overall running time: 240.6363s / 216342.4284 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0034
env0_second_0:                 episode reward: 0.0000,                 loss: 0.3164
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 26281/30000 (87.6033%),                 avg. length: 1784.0,                last time consumption/overall running time: 237.7885s / 216580.2170 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0141
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2166
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 26301/30000 (87.6700%),                 avg. length: 1784.0,                last time consumption/overall running time: 234.9287s / 216815.1456 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0248
env0_second_0:                 episode reward: 0.0000,                 loss: 0.1353
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 26321/30000 (87.7367%),                 avg. length: 1784.0,                last time consumption/overall running time: 228.4293s / 217043.5749 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0257
env0_second_0:                 episode reward: 0.0000,                 loss: 0.5115
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 26341/30000 (87.8033%),                 avg. length: 1784.0,                last time consumption/overall running time: 228.7656s / 217272.3405 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0364
env0_second_0:                 episode reward: 0.0000,                 loss: 0.1794
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 26361/30000 (87.8700%),                 avg. length: 1784.0,                last time consumption/overall running time: 233.6679s / 217506.0084 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0373
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0888
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 26381/30000 (87.9367%),                 avg. length: 1784.0,                last time consumption/overall running time: 234.2071s / 217740.2155 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0370
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0315
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 26401/30000 (88.0033%),                 avg. length: 1784.0,                last time consumption/overall running time: 232.0670s / 217972.2825 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0418
env0_second_0:                 episode reward: 0.0000,                 loss: -0.0353
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 26421/30000 (88.0700%),                 avg. length: 1784.0,                last time consumption/overall running time: 229.5484s / 218201.8310 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0388
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0256
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 26441/30000 (88.1367%),                 avg. length: 1784.0,                last time consumption/overall running time: 230.1110s / 218431.9420 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0331
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0546
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 26461/30000 (88.2033%),                 avg. length: 1784.0,                last time consumption/overall running time: 234.8642s / 218666.8062 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0365
env0_second_0:                 episode reward: 0.0000,                 loss: 0.1205
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 26481/30000 (88.2700%),                 avg. length: 1784.0,                last time consumption/overall running time: 229.9446s / 218896.7507 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0434
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2344
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 26501/30000 (88.3367%),                 avg. length: 1784.0,                last time consumption/overall running time: 228.6573s / 219125.4080 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0522
env0_second_0:                 episode reward: 0.0000,                 loss: 0.3259
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 26521/30000 (88.4033%),                 avg. length: 1784.0,                last time consumption/overall running time: 227.4201s / 219352.8282 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.0507
env0_second_0:                 episode reward: 0.1000,                 loss: 0.4321
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 26541/30000 (88.4700%),                 avg. length: 934.75,                last time consumption/overall running time: 126.1691s / 219478.9973 s
env0_first_0:                 episode reward: -38.0500,                 loss: 37.3406
env0_second_0:                 episode reward: 38.0500,                 loss: 37.2661
env1_first_0:                 episode reward: -34.9000,                 loss: nan
env1_second_0:                 episode reward: 34.9000,                 loss: nan
Episode: 26561/30000 (88.5367%),                 avg. length: 1550.45,                last time consumption/overall running time: 213.4820s / 219692.4793 s
env0_first_0:                 episode reward: -3.8000,                 loss: 21.3661
env0_second_0:                 episode reward: 3.8000,                 loss: 22.0349
env1_first_0:                 episode reward: -7.4000,                 loss: nan
env1_second_0:                 episode reward: 7.4000,                 loss: nan
Episode: 26581/30000 (88.6033%),                 avg. length: 1019.7,                last time consumption/overall running time: 139.7244s / 219832.2037 s
env0_first_0:                 episode reward: -42.5000,                 loss: 28.5318
env0_second_0:                 episode reward: 42.5000,                 loss: 26.9715
env1_first_0:                 episode reward: -32.0500,                 loss: nan
env1_second_0:                 episode reward: 32.0500,                 loss: nan
Episode: 26601/30000 (88.6700%),                 avg. length: 1234.6,                last time consumption/overall running time: 160.1347s / 219992.3385 s
env0_first_0:                 episode reward: -26.9500,                 loss: 18.4350
env0_second_0:                 episode reward: 26.9500,                 loss: 15.7299
env1_first_0:                 episode reward: -16.2000,                 loss: nan
env1_second_0:                 episode reward: 16.2000,                 loss: nan
Episode: 26621/30000 (88.7367%),                 avg. length: 1508.75,                last time consumption/overall running time: 208.8031s / 220201.1416 s
env0_first_0:                 episode reward: -13.5000,                 loss: 20.6817
env0_second_0:                 episode reward: 13.5000,                 loss: 21.9490
env1_first_0:                 episode reward: -26.6000,                 loss: nan
env1_second_0:                 episode reward: 26.6000,                 loss: nan
Episode: 26641/30000 (88.8033%),                 avg. length: 1443.75,                last time consumption/overall running time: 188.0735s / 220389.2151 s
env0_first_0:                 episode reward: -25.3500,                 loss: 20.2651
env0_second_0:                 episode reward: 25.3500,                 loss: 22.1786
env1_first_0:                 episode reward: -26.2000,                 loss: nan
env1_second_0:                 episode reward: 26.2000,                 loss: nan
Episode: 26661/30000 (88.8700%),                 avg. length: 1019.75,                last time consumption/overall running time: 141.4858s / 220530.7009 s
env0_first_0:                 episode reward: -30.3000,                 loss: 38.2257
env0_second_0:                 episode reward: 30.3000,                 loss: 38.1607
env1_first_0:                 episode reward: -46.2500,                 loss: nan
env1_second_0:                 episode reward: 46.2500,                 loss: nan
Episode: 26681/30000 (88.9367%),                 avg. length: 1784.0,                last time consumption/overall running time: 237.9058s / 220768.6067 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.5682
env0_second_0:                 episode reward: 0.0000,                 loss: 0.1882
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 26701/30000 (89.0033%),                 avg. length: 1784.0,                last time consumption/overall running time: 230.4968s / 220999.1034 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2089
env0_second_0:                 episode reward: 0.0000,                 loss: -0.1556
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 26721/30000 (89.0700%),                 avg. length: 1784.0,                last time consumption/overall running time: 233.0296s / 221232.1331 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.1094
env0_second_0:                 episode reward: 0.0000,                 loss: -0.2200
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 26741/30000 (89.1367%),                 avg. length: 1784.0,                last time consumption/overall running time: 234.6590s / 221466.7921 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0322
env0_second_0:                 episode reward: 0.0000,                 loss: -0.0031
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 26761/30000 (89.2033%),                 avg. length: 1784.0,                last time consumption/overall running time: 228.6754s / 221695.4675 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0040
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0008
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 26781/30000 (89.2700%),                 avg. length: 1784.0,                last time consumption/overall running time: 231.6317s / 221927.0992 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0431
env0_second_0:                 episode reward: 0.0000,                 loss: -0.2398
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 26801/30000 (89.3367%),                 avg. length: 1784.0,                last time consumption/overall running time: 237.7954s / 222164.8946 s
env0_first_0:                 episode reward: 0.2000,                 loss: -0.0471
env0_second_0:                 episode reward: -0.2000,                 loss: -0.1212
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 26821/30000 (89.4033%),                 avg. length: 1784.0,                last time consumption/overall running time: 230.6996s / 222395.5942 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0630
env0_second_0:                 episode reward: 0.0000,                 loss: -0.1538
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 26841/30000 (89.4700%),                 avg. length: 1784.0,                last time consumption/overall running time: 233.6508s / 222629.2450 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0573
env0_second_0:                 episode reward: 0.0000,                 loss: -0.3794
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 26861/30000 (89.5367%),                 avg. length: 1784.0,                last time consumption/overall running time: 230.0139s / 222859.2589 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0592
env0_second_0:                 episode reward: 0.0000,                 loss: 0.6020
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 26881/30000 (89.6033%),                 avg. length: 1784.0,                last time consumption/overall running time: 226.1204s / 223085.3794 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0606
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0251
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 26901/30000 (89.6700%),                 avg. length: 1784.0,                last time consumption/overall running time: 239.5973s / 223324.9767 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0589
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0838
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 26921/30000 (89.7367%),                 avg. length: 1784.0,                last time consumption/overall running time: 233.9886s / 223558.9654 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0606
env0_second_0:                 episode reward: 0.0000,                 loss: 0.8583
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 26941/30000 (89.8033%),                 avg. length: 1784.0,                last time consumption/overall running time: 238.1203s / 223797.0856 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0623
env0_second_0:                 episode reward: 0.0000,                 loss: 1.6933
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 26961/30000 (89.8700%),                 avg. length: 1784.0,                last time consumption/overall running time: 242.8301s / 224039.9157 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0708
env0_second_0:                 episode reward: 0.0000,                 loss: 1.4408
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 26981/30000 (89.9367%),                 avg. length: 1784.0,                last time consumption/overall running time: 238.8045s / 224278.7203 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0662
env0_second_0:                 episode reward: 0.0000,                 loss: 0.6014
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 27001/30000 (90.0033%),                 avg. length: 1784.0,                last time consumption/overall running time: 246.3224s / 224525.0427 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0783
env0_second_0:                 episode reward: 0.0000,                 loss: 0.6451
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 27021/30000 (90.0700%),                 avg. length: 1784.0,                last time consumption/overall running time: 234.5092s / 224759.5519 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0772
env0_second_0:                 episode reward: 0.0000,                 loss: 1.6697
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 27041/30000 (90.1367%),                 avg. length: 1784.0,                last time consumption/overall running time: 231.4232s / 224990.9751 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0769
env0_second_0:                 episode reward: 0.0000,                 loss: 1.8772
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 27061/30000 (90.2033%),                 avg. length: 1784.0,                last time consumption/overall running time: 239.5559s / 225230.5310 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0498
env0_second_0:                 episode reward: 0.0000,                 loss: 1.3189
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 27081/30000 (90.2700%),                 avg. length: 1784.0,                last time consumption/overall running time: 228.4909s / 225459.0219 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0685
env0_second_0:                 episode reward: 0.0000,                 loss: 0.7590
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 27101/30000 (90.3367%),                 avg. length: 1784.0,                last time consumption/overall running time: 230.7285s / 225689.7504 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0727
env0_second_0:                 episode reward: 0.0000,                 loss: 0.4887
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 27121/30000 (90.4033%),                 avg. length: 1784.0,                last time consumption/overall running time: 236.2222s / 225925.9726 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0605
env0_second_0:                 episode reward: 0.0000,                 loss: 0.5475
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 27141/30000 (90.4700%),                 avg. length: 1784.0,                last time consumption/overall running time: 229.5363s / 226155.5089 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0652
env0_second_0:                 episode reward: 0.0000,                 loss: 0.5634
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 27161/30000 (90.5367%),                 avg. length: 1784.0,                last time consumption/overall running time: 236.6356s / 226392.1445 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0642
env0_second_0:                 episode reward: 0.0000,                 loss: 0.8794
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 27181/30000 (90.6033%),                 avg. length: 1784.0,                last time consumption/overall running time: 245.9026s / 226638.0471 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0914
env0_second_0:                 episode reward: 0.0000,                 loss: 1.8814
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 27201/30000 (90.6700%),                 avg. length: 1784.0,                last time consumption/overall running time: 237.1131s / 226875.1602 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.2448
env0_second_0:                 episode reward: 3.7000,                 loss: 2.6176
env1_first_0:                 episode reward: -6.2000,                 loss: nan
env1_second_0:                 episode reward: 6.2000,                 loss: nan
Episode: 27221/30000 (90.7367%),                 avg. length: 1569.1,                last time consumption/overall running time: 209.1380s / 227084.2982 s
env0_first_0:                 episode reward: -31.4000,                 loss: 5.3172
env0_second_0:                 episode reward: 31.4000,                 loss: 7.2787
env1_first_0:                 episode reward: -29.1500,                 loss: nan
env1_second_0:                 episode reward: 29.1500,                 loss: nan
Episode: 27241/30000 (90.8033%),                 avg. length: 1729.3,                last time consumption/overall running time: 240.8339s / 227325.1321 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.6454
env0_second_0:                 episode reward: 1.2000,                 loss: 3.9286
env1_first_0:                 episode reward: -8.7500,                 loss: nan
env1_second_0:                 episode reward: 8.7500,                 loss: nan
Episode: 27261/30000 (90.8700%),                 avg. length: 1784.0,                last time consumption/overall running time: 240.6724s / 227565.8044 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.1027
env0_second_0:                 episode reward: 0.0000,                 loss: 3.2475
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 27281/30000 (90.9367%),                 avg. length: 1784.0,                last time consumption/overall running time: 239.4867s / 227805.2912 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.1209
env0_second_0:                 episode reward: 0.0000,                 loss: 3.8796
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 27301/30000 (91.0033%),                 avg. length: 1784.0,                last time consumption/overall running time: 237.2376s / 228042.5288 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0976
env0_second_0:                 episode reward: 0.0000,                 loss: 3.8280
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 27321/30000 (91.0700%),                 avg. length: 1784.0,                last time consumption/overall running time: 238.3629s / 228280.8917 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.1107
env0_second_0:                 episode reward: 0.0000,                 loss: 3.6828
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 27341/30000 (91.1367%),                 avg. length: 1784.0,                last time consumption/overall running time: 240.5970s / 228521.4887 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0861
env0_second_0:                 episode reward: 0.0000,                 loss: 3.3237
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 27361/30000 (91.2033%),                 avg. length: 1784.0,                last time consumption/overall running time: 241.7523s / 228763.2410 s
env0_first_0:                 episode reward: -2.8500,                 loss: 0.1458
env0_second_0:                 episode reward: 2.8500,                 loss: 1.8341
env1_first_0:                 episode reward: -3.0500,                 loss: nan
env1_second_0:                 episode reward: 3.0500,                 loss: nan
Episode: 27381/30000 (91.2700%),                 avg. length: 542.55,                last time consumption/overall running time: 80.6201s / 228843.8611 s
env0_first_0:                 episode reward: -63.8500,                 loss: 24.8765
env0_second_0:                 episode reward: 63.8500,                 loss: 28.8900
env1_first_0:                 episode reward: -80.4000,                 loss: nan
env1_second_0:                 episode reward: 80.4000,                 loss: nan
Episode: 27401/30000 (91.3367%),                 avg. length: 265.35,                last time consumption/overall running time: 43.1292s / 228886.9903 s
env0_first_0:                 episode reward: -84.9000,                 loss: 37.8862
env0_second_0:                 episode reward: 84.9000,                 loss: 39.9613
env1_first_0:                 episode reward: -82.4000,                 loss: nan
env1_second_0:                 episode reward: 82.4000,                 loss: nan
Episode: 27421/30000 (91.4033%),                 avg. length: 288.7,                last time consumption/overall running time: 46.4468s / 228933.4372 s
env0_first_0:                 episode reward: -90.1500,                 loss: 30.0216
env0_second_0:                 episode reward: 90.1500,                 loss: 32.3551
env1_first_0:                 episode reward: -81.8500,                 loss: nan
env1_second_0:                 episode reward: 81.8500,                 loss: nan
Episode: 27441/30000 (91.4700%),                 avg. length: 1764.1,                last time consumption/overall running time: 259.6450s / 229193.0821 s
env0_first_0:                 episode reward: 12.9500,                 loss: 5.4422
env0_second_0:                 episode reward: -12.9500,                 loss: 11.0498
env1_first_0:                 episode reward: 19.5500,                 loss: nan
env1_second_0:                 episode reward: -19.5500,                 loss: nan
Episode: 27461/30000 (91.5367%),                 avg. length: 504.6,                last time consumption/overall running time: 72.2478s / 229265.3299 s
env0_first_0:                 episode reward: -65.9500,                 loss: 37.9672
env0_second_0:                 episode reward: 65.9500,                 loss: 45.5769
env1_first_0:                 episode reward: -57.2500,                 loss: nan
env1_second_0:                 episode reward: 57.2500,                 loss: nan
Episode: 27481/30000 (91.6033%),                 avg. length: 672.7,                last time consumption/overall running time: 94.5821s / 229359.9121 s
env0_first_0:                 episode reward: -49.4500,                 loss: 30.0371
env0_second_0:                 episode reward: 49.4500,                 loss: 37.6017
env1_first_0:                 episode reward: -65.2500,                 loss: nan
env1_second_0:                 episode reward: 65.2500,                 loss: nan
Episode: 27501/30000 (91.6700%),                 avg. length: 670.55,                last time consumption/overall running time: 95.3952s / 229455.3073 s
env0_first_0:                 episode reward: -52.6500,                 loss: 27.7843
env0_second_0:                 episode reward: 52.6500,                 loss: 27.8880
env1_first_0:                 episode reward: -54.3500,                 loss: nan
env1_second_0:                 episode reward: 54.3500,                 loss: nan
Episode: 27521/30000 (91.7367%),                 avg. length: 349.95,                last time consumption/overall running time: 51.7700s / 229507.0773 s
env0_first_0:                 episode reward: -82.0000,                 loss: 32.9431
env0_second_0:                 episode reward: 82.0000,                 loss: 35.7584
env1_first_0:                 episode reward: -76.8500,                 loss: nan
env1_second_0:                 episode reward: 76.8500,                 loss: nan
Episode: 27541/30000 (91.8033%),                 avg. length: 588.4,                last time consumption/overall running time: 84.7399s / 229591.8172 s
env0_first_0:                 episode reward: -61.4500,                 loss: 28.1739
env0_second_0:                 episode reward: 61.4500,                 loss: 32.9582
env1_first_0:                 episode reward: -74.5000,                 loss: nan
env1_second_0:                 episode reward: 74.5000,                 loss: nan
Episode: 27561/30000 (91.8700%),                 avg. length: 395.2,                last time consumption/overall running time: 61.0448s / 229652.8620 s
env0_first_0:                 episode reward: -82.6000,                 loss: 27.5794
env0_second_0:                 episode reward: 82.6000,                 loss: 30.3415
env1_first_0:                 episode reward: -80.1000,                 loss: nan
env1_second_0:                 episode reward: 80.1000,                 loss: nan
Episode: 27581/30000 (91.9367%),                 avg. length: 476.8,                last time consumption/overall running time: 72.1984s / 229725.0604 s
env0_first_0:                 episode reward: -67.8000,                 loss: 28.2692
env0_second_0:                 episode reward: 67.8000,                 loss: 54.1061
env1_first_0:                 episode reward: -60.2500,                 loss: nan
env1_second_0:                 episode reward: 60.2500,                 loss: nan
Episode: 27601/30000 (92.0033%),                 avg. length: 426.0,                last time consumption/overall running time: 63.6654s / 229788.7258 s
env0_first_0:                 episode reward: -64.0000,                 loss: 33.8983
env0_second_0:                 episode reward: 64.0000,                 loss: 39.1495
env1_first_0:                 episode reward: -44.6000,                 loss: nan
env1_second_0:                 episode reward: 44.6000,                 loss: nan
Episode: 27621/30000 (92.0700%),                 avg. length: 533.5,                last time consumption/overall running time: 76.3546s / 229865.0804 s
env0_first_0:                 episode reward: -64.3000,                 loss: 52.5994
env0_second_0:                 episode reward: 64.3000,                 loss: 51.7167
env1_first_0:                 episode reward: -57.2500,                 loss: nan
env1_second_0:                 episode reward: 57.2500,                 loss: nan
Episode: 27641/30000 (92.1367%),                 avg. length: 311.05,                last time consumption/overall running time: 48.7652s / 229913.8456 s
env0_first_0:                 episode reward: -73.2000,                 loss: 54.4358
env0_second_0:                 episode reward: 73.2000,                 loss: 58.7823
env1_first_0:                 episode reward: -63.0000,                 loss: nan
env1_second_0:                 episode reward: 63.0000,                 loss: nan
Episode: 27661/30000 (92.2033%),                 avg. length: 299.35,                last time consumption/overall running time: 47.5069s / 229961.3525 s
env0_first_0:                 episode reward: -77.6000,                 loss: 50.1267
env0_second_0:                 episode reward: 77.6000,                 loss: 50.0841
env1_first_0:                 episode reward: -64.8500,                 loss: nan
env1_second_0:                 episode reward: 64.8500,                 loss: nan
Episode: 27681/30000 (92.2700%),                 avg. length: 336.35,                last time consumption/overall running time: 52.5057s / 230013.8582 s
env0_first_0:                 episode reward: -77.5000,                 loss: 38.8240
env0_second_0:                 episode reward: 77.5000,                 loss: 39.8489
env1_first_0:                 episode reward: -70.9000,                 loss: nan
env1_second_0:                 episode reward: 70.9000,                 loss: nan
Episode: 27701/30000 (92.3367%),                 avg. length: 337.6,                last time consumption/overall running time: 51.4031s / 230065.2613 s
env0_first_0:                 episode reward: -76.7000,                 loss: 37.2035
env0_second_0:                 episode reward: 76.7000,                 loss: 38.9720
env1_first_0:                 episode reward: -74.3500,                 loss: nan
env1_second_0:                 episode reward: 74.3500,                 loss: nan
Episode: 27721/30000 (92.4033%),                 avg. length: 522.55,                last time consumption/overall running time: 76.4927s / 230141.7540 s
env0_first_0:                 episode reward: -44.3500,                 loss: 33.6541
env0_second_0:                 episode reward: 44.3500,                 loss: 34.7489
env1_first_0:                 episode reward: -68.2500,                 loss: nan
env1_second_0:                 episode reward: 68.2500,                 loss: nan
Episode: 27741/30000 (92.4700%),                 avg. length: 717.2,                last time consumption/overall running time: 103.5067s / 230245.2607 s
env0_first_0:                 episode reward: -41.2000,                 loss: 31.1168
env0_second_0:                 episode reward: 41.2000,                 loss: 32.3884
env1_first_0:                 episode reward: -49.1500,                 loss: nan
env1_second_0:                 episode reward: 49.1500,                 loss: nan
Episode: 27761/30000 (92.5367%),                 avg. length: 725.5,                last time consumption/overall running time: 102.1572s / 230347.4179 s
env0_first_0:                 episode reward: -37.8000,                 loss: 28.2726
env0_second_0:                 episode reward: 37.8000,                 loss: 31.2160
env1_first_0:                 episode reward: -51.0000,                 loss: nan
env1_second_0:                 episode reward: 51.0000,                 loss: nan
Episode: 27781/30000 (92.6033%),                 avg. length: 321.85,                last time consumption/overall running time: 54.1380s / 230401.5559 s
env0_first_0:                 episode reward: -75.4500,                 loss: 45.0967
env0_second_0:                 episode reward: 75.4500,                 loss: 43.8466
env1_first_0:                 episode reward: -72.9000,                 loss: nan
env1_second_0:                 episode reward: 72.9000,                 loss: nan
Episode: 27801/30000 (92.6700%),                 avg. length: 429.35,                last time consumption/overall running time: 63.3335s / 230464.8894 s
env0_first_0:                 episode reward: -69.4500,                 loss: 37.7346
env0_second_0:                 episode reward: 69.4500,                 loss: 38.9381
env1_first_0:                 episode reward: -73.1500,                 loss: nan
env1_second_0:                 episode reward: 73.1500,                 loss: nan
Episode: 27821/30000 (92.7367%),                 avg. length: 1188.05,                last time consumption/overall running time: 162.2968s / 230627.1862 s
env0_first_0:                 episode reward: -19.4500,                 loss: 17.9224
env0_second_0:                 episode reward: 19.4500,                 loss: 18.9564
env1_first_0:                 episode reward: -33.6500,                 loss: nan
env1_second_0:                 episode reward: 33.6500,                 loss: nan
Episode: 27841/30000 (92.8033%),                 avg. length: 533.7,                last time consumption/overall running time: 74.4245s / 230701.6106 s
env0_first_0:                 episode reward: -37.9500,                 loss: 32.3917
env0_second_0:                 episode reward: 37.9500,                 loss: 32.0925
env1_first_0:                 episode reward: -63.7500,                 loss: nan
env1_second_0:                 episode reward: 63.7500,                 loss: nan
Episode: 27861/30000 (92.8700%),                 avg. length: 583.3,                last time consumption/overall running time: 83.7293s / 230785.3399 s
env0_first_0:                 episode reward: -54.1000,                 loss: 25.1051
env0_second_0:                 episode reward: 54.1000,                 loss: 26.4290
env1_first_0:                 episode reward: -62.2500,                 loss: nan
env1_second_0:                 episode reward: 62.2500,                 loss: nan
Episode: 27881/30000 (92.9367%),                 avg. length: 407.0,                last time consumption/overall running time: 60.9210s / 230846.2609 s
env0_first_0:                 episode reward: -68.3000,                 loss: 42.3931
env0_second_0:                 episode reward: 68.3000,                 loss: 41.6106
env1_first_0:                 episode reward: -67.1500,                 loss: nan
env1_second_0:                 episode reward: 67.1500,                 loss: nan
Episode: 27901/30000 (93.0033%),                 avg. length: 572.95,                last time consumption/overall running time: 80.6985s / 230926.9593 s
env0_first_0:                 episode reward: -52.9500,                 loss: 30.1437
env0_second_0:                 episode reward: 52.9500,                 loss: 32.1038
env1_first_0:                 episode reward: -62.5500,                 loss: nan
env1_second_0:                 episode reward: 62.5500,                 loss: nan
Episode: 27921/30000 (93.0700%),                 avg. length: 723.75,                last time consumption/overall running time: 100.6935s / 231027.6528 s
env0_first_0:                 episode reward: -57.8500,                 loss: 28.6275
env0_second_0:                 episode reward: 57.8500,                 loss: 31.2655
env1_first_0:                 episode reward: -51.5500,                 loss: nan
env1_second_0:                 episode reward: 51.5500,                 loss: nan
Episode: 27941/30000 (93.1367%),                 avg. length: 753.55,                last time consumption/overall running time: 104.4977s / 231132.1506 s
env0_first_0:                 episode reward: -49.0500,                 loss: 26.2832
env0_second_0:                 episode reward: 49.0500,                 loss: 28.3283
env1_first_0:                 episode reward: -57.1500,                 loss: nan
env1_second_0:                 episode reward: 57.1500,                 loss: nan
Episode: 27961/30000 (93.2033%),                 avg. length: 1111.85,                last time consumption/overall running time: 152.6848s / 231284.8353 s
env0_first_0:                 episode reward: -41.0500,                 loss: 23.9896
env0_second_0:                 episode reward: 41.0500,                 loss: 27.1523
env1_first_0:                 episode reward: -45.9500,                 loss: nan
env1_second_0:                 episode reward: 45.9500,                 loss: nan
Episode: 27981/30000 (93.2700%),                 avg. length: 1464.65,                last time consumption/overall running time: 194.5168s / 231479.3522 s
env0_first_0:                 episode reward: -10.4500,                 loss: 7.4125
env0_second_0:                 episode reward: 10.4500,                 loss: 9.8698
env1_first_0:                 episode reward: -16.4000,                 loss: nan
env1_second_0:                 episode reward: 16.4000,                 loss: nan
Episode: 28001/30000 (93.3367%),                 avg. length: 1712.4,                last time consumption/overall running time: 228.4457s / 231707.7979 s
env0_first_0:                 episode reward: -22.8500,                 loss: 7.0798
env0_second_0:                 episode reward: 22.8500,                 loss: 8.3857
env1_first_0:                 episode reward: -15.9500,                 loss: nan
env1_second_0:                 episode reward: 15.9500,                 loss: nan
Episode: 28021/30000 (93.4033%),                 avg. length: 1709.75,                last time consumption/overall running time: 234.4029s / 231942.2008 s
env0_first_0:                 episode reward: -14.5000,                 loss: 5.8690
env0_second_0:                 episode reward: 14.5000,                 loss: 7.0908
env1_first_0:                 episode reward: -15.5000,                 loss: nan
env1_second_0:                 episode reward: 15.5000,                 loss: nan
Episode: 28041/30000 (93.4700%),                 avg. length: 1627.8,                last time consumption/overall running time: 215.5208s / 232157.7216 s
env0_first_0:                 episode reward: -13.8500,                 loss: 10.3385
env0_second_0:                 episode reward: 13.8500,                 loss: 10.5553
env1_first_0:                 episode reward: -15.2500,                 loss: nan
env1_second_0:                 episode reward: 15.2500,                 loss: nan
Episode: 28061/30000 (93.5367%),                 avg. length: 1141.85,                last time consumption/overall running time: 156.2172s / 232313.9388 s
env0_first_0:                 episode reward: -31.4000,                 loss: 27.7882
env0_second_0:                 episode reward: 31.4000,                 loss: 29.9669
env1_first_0:                 episode reward: -42.6000,                 loss: nan
env1_second_0:                 episode reward: 42.6000,                 loss: nan
Episode: 28081/30000 (93.6033%),                 avg. length: 824.05,                last time consumption/overall running time: 117.1515s / 232431.0902 s
env0_first_0:                 episode reward: -46.6000,                 loss: 26.5718
env0_second_0:                 episode reward: 46.6000,                 loss: 28.0261
env1_first_0:                 episode reward: -47.7000,                 loss: nan
env1_second_0:                 episode reward: 47.7000,                 loss: nan
Episode: 28101/30000 (93.6700%),                 avg. length: 440.5,                last time consumption/overall running time: 63.6246s / 232494.7148 s
env0_first_0:                 episode reward: -57.1500,                 loss: 38.8805
env0_second_0:                 episode reward: 57.1500,                 loss: 42.2487
env1_first_0:                 episode reward: -70.7000,                 loss: nan
env1_second_0:                 episode reward: 70.7000,                 loss: nan
Episode: 28121/30000 (93.7367%),                 avg. length: 287.4,                last time consumption/overall running time: 45.2140s / 232539.9288 s
env0_first_0:                 episode reward: -83.3000,                 loss: 38.3921
env0_second_0:                 episode reward: 83.3000,                 loss: 39.9796
env1_first_0:                 episode reward: -76.8500,                 loss: nan
env1_second_0:                 episode reward: 76.8500,                 loss: nan
Episode: 28141/30000 (93.8033%),                 avg. length: 243.1,                last time consumption/overall running time: 38.8990s / 232578.8278 s
env0_first_0:                 episode reward: -79.5500,                 loss: 30.1530
env0_second_0:                 episode reward: 79.5500,                 loss: 32.8448
env1_first_0:                 episode reward: -85.8500,                 loss: nan
env1_second_0:                 episode reward: 85.8500,                 loss: nan
Episode: 28161/30000 (93.8700%),                 avg. length: 238.2,                last time consumption/overall running time: 38.1197s / 232616.9475 s
env0_first_0:                 episode reward: -89.9500,                 loss: 27.5069
env0_second_0:                 episode reward: 89.9500,                 loss: 28.9912
env1_first_0:                 episode reward: -84.8000,                 loss: nan
env1_second_0:                 episode reward: 84.8000,                 loss: nan
Episode: 28181/30000 (93.9367%),                 avg. length: 243.85,                last time consumption/overall running time: 39.6652s / 232656.6127 s
env0_first_0:                 episode reward: -90.5500,                 loss: 23.0508
env0_second_0:                 episode reward: 90.5500,                 loss: 26.4471
env1_first_0:                 episode reward: -85.0500,                 loss: nan
env1_second_0:                 episode reward: 85.0500,                 loss: nan
Episode: 28201/30000 (94.0033%),                 avg. length: 301.6,                last time consumption/overall running time: 46.3386s / 232702.9512 s
env0_first_0:                 episode reward: -83.5000,                 loss: 23.6695
env0_second_0:                 episode reward: 83.5000,                 loss: 25.8393
env1_first_0:                 episode reward: -83.0500,                 loss: nan
env1_second_0:                 episode reward: 83.0500,                 loss: nan
Episode: 28221/30000 (94.0700%),                 avg. length: 244.55,                last time consumption/overall running time: 39.2881s / 232742.2393 s
env0_first_0:                 episode reward: -93.9000,                 loss: 15.5625
env0_second_0:                 episode reward: 93.9000,                 loss: 18.0453
env1_first_0:                 episode reward: -93.2000,                 loss: nan
env1_second_0:                 episode reward: 93.2000,                 loss: nan
Episode: 28241/30000 (94.1367%),                 avg. length: 242.25,                last time consumption/overall running time: 39.1015s / 232781.3408 s
env0_first_0:                 episode reward: -95.0000,                 loss: 13.5429
env0_second_0:                 episode reward: 95.0000,                 loss: 16.0174
env1_first_0:                 episode reward: -91.5500,                 loss: nan
env1_second_0:                 episode reward: 91.5500,                 loss: nan
Episode: 28261/30000 (94.2033%),                 avg. length: 235.2,                last time consumption/overall running time: 38.1697s / 232819.5105 s
env0_first_0:                 episode reward: -85.7500,                 loss: 14.9733
env0_second_0:                 episode reward: 85.7500,                 loss: 15.8683
env1_first_0:                 episode reward: -91.5000,                 loss: nan
env1_second_0:                 episode reward: 91.5000,                 loss: nan
Episode: 28281/30000 (94.2700%),                 avg. length: 315.2,                last time consumption/overall running time: 48.4584s / 232867.9690 s
env0_first_0:                 episode reward: -81.4000,                 loss: 20.2473
env0_second_0:                 episode reward: 81.4000,                 loss: 22.3667
env1_first_0:                 episode reward: -80.4000,                 loss: nan
env1_second_0:                 episode reward: 80.4000,                 loss: nan
Episode: 28301/30000 (94.3367%),                 avg. length: 275.8,                last time consumption/overall running time: 44.4419s / 232912.4109 s
env0_first_0:                 episode reward: -91.4500,                 loss: 17.5959
env0_second_0:                 episode reward: 91.4500,                 loss: 20.1379
env1_first_0:                 episode reward: -89.5500,                 loss: nan
env1_second_0:                 episode reward: 89.5500,                 loss: nan
Episode: 28321/30000 (94.4033%),                 avg. length: 255.85,                last time consumption/overall running time: 44.6384s / 232957.0493 s
env0_first_0:                 episode reward: -94.2000,                 loss: 18.0569
env0_second_0:                 episode reward: 94.2000,                 loss: 20.3832
env1_first_0:                 episode reward: -91.7000,                 loss: nan
env1_second_0:                 episode reward: 91.7000,                 loss: nan
Episode: 28341/30000 (94.4700%),                 avg. length: 237.7,                last time consumption/overall running time: 39.9883s / 232997.0376 s
env0_first_0:                 episode reward: -95.6000,                 loss: 13.5876
env0_second_0:                 episode reward: 95.6000,                 loss: 16.3403
env1_first_0:                 episode reward: -92.7500,                 loss: nan
env1_second_0:                 episode reward: 92.7500,                 loss: nan
Episode: 28361/30000 (94.5367%),                 avg. length: 250.5,                last time consumption/overall running time: 40.6153s / 233037.6529 s
env0_first_0:                 episode reward: -93.5000,                 loss: 15.9037
env0_second_0:                 episode reward: 93.5000,                 loss: 19.2233
env1_first_0:                 episode reward: -89.6500,                 loss: nan
env1_second_0:                 episode reward: 89.6500,                 loss: nan
Episode: 28381/30000 (94.6033%),                 avg. length: 234.35,                last time consumption/overall running time: 39.2675s / 233076.9204 s
env0_first_0:                 episode reward: -92.9500,                 loss: 13.7343
env0_second_0:                 episode reward: 92.9500,                 loss: 16.1786
env1_first_0:                 episode reward: -89.9000,                 loss: nan
env1_second_0:                 episode reward: 89.9000,                 loss: nan
Episode: 28401/30000 (94.6700%),                 avg. length: 253.85,                last time consumption/overall running time: 41.6926s / 233118.6129 s
env0_first_0:                 episode reward: -92.3500,                 loss: 15.3586
env0_second_0:                 episode reward: 92.3500,                 loss: 19.2911
env1_first_0:                 episode reward: -89.4500,                 loss: nan
env1_second_0:                 episode reward: 89.4500,                 loss: nan
Episode: 28421/30000 (94.7367%),                 avg. length: 242.35,                last time consumption/overall running time: 42.5076s / 233161.1205 s
env0_first_0:                 episode reward: -89.1000,                 loss: 17.4433
env0_second_0:                 episode reward: 89.1000,                 loss: 21.6994
env1_first_0:                 episode reward: -81.4500,                 loss: nan
env1_second_0:                 episode reward: 81.4500,                 loss: nan
Episode: 28441/30000 (94.8033%),                 avg. length: 228.05,                last time consumption/overall running time: 37.7378s / 233198.8583 s
env0_first_0:                 episode reward: -95.4000,                 loss: 12.9247
env0_second_0:                 episode reward: 95.4000,                 loss: 16.1081
env1_first_0:                 episode reward: -92.2000,                 loss: nan
env1_second_0:                 episode reward: 92.2000,                 loss: nan
Episode: 28461/30000 (94.8700%),                 avg. length: 322.55,                last time consumption/overall running time: 50.6530s / 233249.5113 s
env0_first_0:                 episode reward: -91.4500,                 loss: 15.1645
env0_second_0:                 episode reward: 91.4500,                 loss: 17.5901
env1_first_0:                 episode reward: -87.3500,                 loss: nan
env1_second_0:                 episode reward: 87.3500,                 loss: nan
Episode: 28481/30000 (94.9367%),                 avg. length: 328.0,                last time consumption/overall running time: 50.7033s / 233300.2146 s
env0_first_0:                 episode reward: -92.5500,                 loss: 14.5014
env0_second_0:                 episode reward: 92.5500,                 loss: 17.9283
env1_first_0:                 episode reward: -94.6000,                 loss: nan
env1_second_0:                 episode reward: 94.6000,                 loss: nan
Episode: 28501/30000 (95.0033%),                 avg. length: 273.7,                last time consumption/overall running time: 43.9661s / 233344.1807 s
env0_first_0:                 episode reward: -94.2000,                 loss: 13.7301
env0_second_0:                 episode reward: 94.2000,                 loss: 17.9396
env1_first_0:                 episode reward: -89.3500,                 loss: nan
env1_second_0:                 episode reward: 89.3500,                 loss: nan
Episode: 28521/30000 (95.0700%),                 avg. length: 243.3,                last time consumption/overall running time: 39.5689s / 233383.7496 s
env0_first_0:                 episode reward: -92.0500,                 loss: 16.7456
env0_second_0:                 episode reward: 92.0500,                 loss: 19.5253
env1_first_0:                 episode reward: -86.0000,                 loss: nan
env1_second_0:                 episode reward: 86.0000,                 loss: nan
Episode: 28541/30000 (95.1367%),                 avg. length: 234.2,                last time consumption/overall running time: 38.0080s / 233421.7576 s
env0_first_0:                 episode reward: -94.6500,                 loss: 15.1936
env0_second_0:                 episode reward: 94.6500,                 loss: 18.7253
env1_first_0:                 episode reward: -89.4500,                 loss: nan
env1_second_0:                 episode reward: 89.4500,                 loss: nan
Episode: 28561/30000 (95.2033%),                 avg. length: 239.7,                last time consumption/overall running time: 39.0526s / 233460.8103 s
env0_first_0:                 episode reward: -90.6000,                 loss: 15.7545
env0_second_0:                 episode reward: 90.6000,                 loss: 19.5014
env1_first_0:                 episode reward: -93.1000,                 loss: nan
env1_second_0:                 episode reward: 93.1000,                 loss: nan
Episode: 28581/30000 (95.2700%),                 avg. length: 229.5,                last time consumption/overall running time: 42.3216s / 233503.1319 s
env0_first_0:                 episode reward: -95.7000,                 loss: 12.8635
env0_second_0:                 episode reward: 95.7000,                 loss: 15.6256
env1_first_0:                 episode reward: -94.9500,                 loss: nan
env1_second_0:                 episode reward: 94.9500,                 loss: nan
Episode: 28601/30000 (95.3367%),                 avg. length: 262.3,                last time consumption/overall running time: 44.5848s / 233547.7167 s
env0_first_0:                 episode reward: -90.4000,                 loss: 13.9814
env0_second_0:                 episode reward: 90.4000,                 loss: 16.7710
env1_first_0:                 episode reward: -86.3000,                 loss: nan
env1_second_0:                 episode reward: 86.3000,                 loss: nan
Episode: 28621/30000 (95.4033%),                 avg. length: 231.5,                last time consumption/overall running time: 39.3948s / 233587.1115 s
env0_first_0:                 episode reward: -91.5000,                 loss: 16.2667
env0_second_0:                 episode reward: 91.5000,                 loss: 19.1442
env1_first_0:                 episode reward: -93.6000,                 loss: nan
env1_second_0:                 episode reward: 93.6000,                 loss: nan
Episode: 28641/30000 (95.4700%),                 avg. length: 224.95,                last time consumption/overall running time: 38.0859s / 233625.1973 s
env0_first_0:                 episode reward: -96.3000,                 loss: 9.5195
env0_second_0:                 episode reward: 96.3000,                 loss: 12.0036
env1_first_0:                 episode reward: -97.1500,                 loss: nan
env1_second_0:                 episode reward: 97.1500,                 loss: nan
Episode: 28661/30000 (95.5367%),                 avg. length: 225.25,                last time consumption/overall running time: 37.8222s / 233663.0196 s
env0_first_0:                 episode reward: -92.7000,                 loss: 8.7850
env0_second_0:                 episode reward: 92.7000,                 loss: 10.7084
env1_first_0:                 episode reward: -98.2000,                 loss: nan
env1_second_0:                 episode reward: 98.2000,                 loss: nan
Episode: 28681/30000 (95.6033%),                 avg. length: 378.3,                last time consumption/overall running time: 55.6633s / 233718.6829 s
env0_first_0:                 episode reward: -93.6000,                 loss: 19.4960
env0_second_0:                 episode reward: 93.6000,                 loss: 20.8728
env1_first_0:                 episode reward: -88.0500,                 loss: nan
env1_second_0:                 episode reward: 88.0500,                 loss: nan
Episode: 28701/30000 (95.6700%),                 avg. length: 231.0,                last time consumption/overall running time: 38.0444s / 233756.7273 s
env0_first_0:                 episode reward: -98.0500,                 loss: 13.2093
env0_second_0:                 episode reward: 98.0500,                 loss: 14.8966
env1_first_0:                 episode reward: -97.0500,                 loss: nan
env1_second_0:                 episode reward: 97.0500,                 loss: nan
Episode: 28721/30000 (95.7367%),                 avg. length: 229.0,                last time consumption/overall running time: 38.3130s / 233795.0403 s
env0_first_0:                 episode reward: -98.2500,                 loss: 8.4217
env0_second_0:                 episode reward: 98.2500,                 loss: 10.2519
env1_first_0:                 episode reward: -97.1000,                 loss: nan
env1_second_0:                 episode reward: 97.1000,                 loss: nan
Episode: 28741/30000 (95.8033%),                 avg. length: 230.4,                last time consumption/overall running time: 37.8421s / 233832.8824 s
env0_first_0:                 episode reward: -98.7500,                 loss: 8.5792
env0_second_0:                 episode reward: 98.7500,                 loss: 10.2817
env1_first_0:                 episode reward: -97.7500,                 loss: nan
env1_second_0:                 episode reward: 97.7500,                 loss: nan
Episode: 28761/30000 (95.8700%),                 avg. length: 232.4,                last time consumption/overall running time: 37.8314s / 233870.7138 s
env0_first_0:                 episode reward: -94.7000,                 loss: 9.1662
env0_second_0:                 episode reward: 94.7000,                 loss: 10.9932
env1_first_0:                 episode reward: -97.0500,                 loss: nan
env1_second_0:                 episode reward: 97.0500,                 loss: nan
Episode: 28781/30000 (95.9367%),                 avg. length: 230.1,                last time consumption/overall running time: 38.9016s / 233909.6154 s
env0_first_0:                 episode reward: -97.2500,                 loss: 7.8306
env0_second_0:                 episode reward: 97.2500,                 loss: 10.4566
env1_first_0:                 episode reward: -98.3500,                 loss: nan
env1_second_0:                 episode reward: 98.3500,                 loss: nan
Episode: 28801/30000 (96.0033%),                 avg. length: 931.15,                last time consumption/overall running time: 136.7728s / 234046.3882 s
env0_first_0:                 episode reward: -53.9500,                 loss: 6.4675
env0_second_0:                 episode reward: 53.9500,                 loss: 8.2719
env1_first_0:                 episode reward: -57.7000,                 loss: nan
env1_second_0:                 episode reward: 57.7000,                 loss: nan
Episode: 28821/30000 (96.0700%),                 avg. length: 1784.0,                last time consumption/overall running time: 249.1528s / 234295.5411 s
env0_first_0:                 episode reward: -2.6000,                 loss: 0.4026
env0_second_0:                 episode reward: 2.6000,                 loss: 2.2175
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 28841/30000 (96.1367%),                 avg. length: 1784.0,                last time consumption/overall running time: 256.4784s / 234552.0195 s
env0_first_0:                 episode reward: -2.8500,                 loss: 0.1539
env0_second_0:                 episode reward: 2.8500,                 loss: 1.7976
env1_first_0:                 episode reward: -2.7000,                 loss: nan
env1_second_0:                 episode reward: 2.7000,                 loss: nan
Episode: 28861/30000 (96.2033%),                 avg. length: 1689.55,                last time consumption/overall running time: 221.8578s / 234773.8773 s
env0_first_0:                 episode reward: -45.4000,                 loss: 2.1156
env0_second_0:                 episode reward: 45.4000,                 loss: 3.9102
env1_first_0:                 episode reward: -43.3500,                 loss: nan
env1_second_0:                 episode reward: 43.3500,                 loss: nan
Episode: 28881/30000 (96.2700%),                 avg. length: 392.9,                last time consumption/overall running time: 58.1038s / 234831.9811 s
env0_first_0:                 episode reward: -72.1500,                 loss: 18.7741
env0_second_0:                 episode reward: 72.1500,                 loss: 20.8091
env1_first_0:                 episode reward: -85.0000,                 loss: nan
env1_second_0:                 episode reward: 85.0000,                 loss: nan
Episode: 28901/30000 (96.3367%),                 avg. length: 235.45,                last time consumption/overall running time: 38.1438s / 234870.1249 s
env0_first_0:                 episode reward: -83.2000,                 loss: 15.9528
env0_second_0:                 episode reward: 83.2000,                 loss: 20.4983
env1_first_0:                 episode reward: -96.2000,                 loss: nan
env1_second_0:                 episode reward: 96.2000,                 loss: nan
Episode: 28921/30000 (96.4033%),                 avg. length: 1159.3,                last time consumption/overall running time: 155.5414s / 235025.6663 s
env0_first_0:                 episode reward: -38.0500,                 loss: 6.7454
env0_second_0:                 episode reward: 38.0500,                 loss: 9.7359
env1_first_0:                 episode reward: -36.9500,                 loss: nan
env1_second_0:                 episode reward: 36.9500,                 loss: nan
Episode: 28941/30000 (96.4700%),                 avg. length: 1187.55,                last time consumption/overall running time: 160.1178s / 235185.7842 s
env0_first_0:                 episode reward: 31.0500,                 loss: 6.0905
env0_second_0:                 episode reward: -31.0500,                 loss: 10.0327
env1_first_0:                 episode reward: 22.3000,                 loss: nan
env1_second_0:                 episode reward: -22.3000,                 loss: nan
Episode: 28961/30000 (96.5367%),                 avg. length: 539.45,                last time consumption/overall running time: 77.5281s / 235263.3123 s
env0_first_0:                 episode reward: -74.3500,                 loss: 20.0556
env0_second_0:                 episode reward: 74.3500,                 loss: 23.1800
env1_first_0:                 episode reward: -58.6500,                 loss: nan
env1_second_0:                 episode reward: 58.6500,                 loss: nan
Episode: 28981/30000 (96.6033%),                 avg. length: 222.0,                last time consumption/overall running time: 37.6445s / 235300.9568 s
env0_first_0:                 episode reward: -98.8000,                 loss: 9.9470
env0_second_0:                 episode reward: 98.8000,                 loss: 13.7569
env1_first_0:                 episode reward: -98.8500,                 loss: nan
env1_second_0:                 episode reward: 98.8500,                 loss: nan
Episode: 29001/30000 (96.6700%),                 avg. length: 220.95,                last time consumption/overall running time: 37.2805s / 235338.2372 s
env0_first_0:                 episode reward: -97.9000,                 loss: 9.4994
env0_second_0:                 episode reward: 97.9000,                 loss: 12.8305
env1_first_0:                 episode reward: -91.0500,                 loss: nan
env1_second_0:                 episode reward: 91.0500,                 loss: nan
Episode: 29021/30000 (96.7367%),                 avg. length: 235.4,                last time consumption/overall running time: 38.8058s / 235377.0431 s
env0_first_0:                 episode reward: -91.7000,                 loss: 13.5361
env0_second_0:                 episode reward: 91.7000,                 loss: 16.6944
env1_first_0:                 episode reward: -92.8500,                 loss: nan
env1_second_0:                 episode reward: 92.8500,                 loss: nan
Episode: 29041/30000 (96.8033%),                 avg. length: 231.8,                last time consumption/overall running time: 38.4972s / 235415.5403 s
env0_first_0:                 episode reward: -91.8000,                 loss: 12.8161
env0_second_0:                 episode reward: 91.8000,                 loss: 16.2943
env1_first_0:                 episode reward: -92.1500,                 loss: nan
env1_second_0:                 episode reward: 92.1500,                 loss: nan
Episode: 29061/30000 (96.8700%),                 avg. length: 239.65,                last time consumption/overall running time: 40.5780s / 235456.1183 s
env0_first_0:                 episode reward: -84.1000,                 loss: 17.6522
env0_second_0:                 episode reward: 84.1000,                 loss: 20.5261
env1_first_0:                 episode reward: -92.0500,                 loss: nan
env1_second_0:                 episode reward: 92.0500,                 loss: nan
Episode: 29081/30000 (96.9367%),                 avg. length: 236.55,                last time consumption/overall running time: 40.0993s / 235496.2175 s
env0_first_0:                 episode reward: -93.4500,                 loss: 17.3878
env0_second_0:                 episode reward: 93.4500,                 loss: 19.3625
env1_first_0:                 episode reward: -87.8000,                 loss: nan
env1_second_0:                 episode reward: 87.8000,                 loss: nan
Episode: 29101/30000 (97.0033%),                 avg. length: 239.85,                last time consumption/overall running time: 41.7477s / 235537.9652 s
env0_first_0:                 episode reward: -88.3500,                 loss: 14.8555
env0_second_0:                 episode reward: 88.3500,                 loss: 16.8544
env1_first_0:                 episode reward: -93.4500,                 loss: nan
env1_second_0:                 episode reward: 93.4500,                 loss: nan
Episode: 29121/30000 (97.0700%),                 avg. length: 239.45,                last time consumption/overall running time: 40.2917s / 235578.2569 s
env0_first_0:                 episode reward: -94.7000,                 loss: 11.5985
env0_second_0:                 episode reward: 94.7000,                 loss: 13.8734
env1_first_0:                 episode reward: -93.7000,                 loss: nan
env1_second_0:                 episode reward: 93.7000,                 loss: nan
Episode: 29141/30000 (97.1367%),                 avg. length: 246.25,                last time consumption/overall running time: 41.5711s / 235619.8281 s
env0_first_0:                 episode reward: -92.6500,                 loss: 13.5814
env0_second_0:                 episode reward: 92.6500,                 loss: 15.0670
env1_first_0:                 episode reward: -96.1000,                 loss: nan
env1_second_0:                 episode reward: 96.1000,                 loss: nan
Episode: 29161/30000 (97.2033%),                 avg. length: 266.15,                last time consumption/overall running time: 44.0093s / 235663.8374 s
env0_first_0:                 episode reward: -86.7500,                 loss: 15.6482
env0_second_0:                 episode reward: 86.7500,                 loss: 17.1779
env1_first_0:                 episode reward: -91.0000,                 loss: nan
env1_second_0:                 episode reward: 91.0000,                 loss: nan
Episode: 29181/30000 (97.2700%),                 avg. length: 274.9,                last time consumption/overall running time: 45.4051s / 235709.2425 s
env0_first_0:                 episode reward: -95.2500,                 loss: 16.6904
env0_second_0:                 episode reward: 95.2500,                 loss: 19.1627
env1_first_0:                 episode reward: -89.8000,                 loss: nan
env1_second_0:                 episode reward: 89.8000,                 loss: nan
Episode: 29201/30000 (97.3367%),                 avg. length: 609.55,                last time consumption/overall running time: 85.5090s / 235794.7515 s
env0_first_0:                 episode reward: -75.4000,                 loss: 20.5197
env0_second_0:                 episode reward: 75.4000,                 loss: 22.3006
env1_first_0:                 episode reward: -78.9000,                 loss: nan
env1_second_0:                 episode reward: 78.9000,                 loss: nan
Episode: 29221/30000 (97.4033%),                 avg. length: 264.65,                last time consumption/overall running time: 41.6416s / 235836.3930 s
env0_first_0:                 episode reward: -77.0000,                 loss: 29.9040
env0_second_0:                 episode reward: 77.0000,                 loss: 30.8267
env1_first_0:                 episode reward: -82.0000,                 loss: nan
env1_second_0:                 episode reward: 82.0000,                 loss: nan
Episode: 29241/30000 (97.4700%),                 avg. length: 407.8,                last time consumption/overall running time: 60.2507s / 235896.6437 s
env0_first_0:                 episode reward: -68.6000,                 loss: 27.7115
env0_second_0:                 episode reward: 68.6000,                 loss: 30.9092
env1_first_0:                 episode reward: -80.0500,                 loss: nan
env1_second_0:                 episode reward: 80.0500,                 loss: nan
Episode: 29261/30000 (97.5367%),                 avg. length: 1303.35,                last time consumption/overall running time: 175.3626s / 236072.0064 s
env0_first_0:                 episode reward: -54.0500,                 loss: 9.1380
env0_second_0:                 episode reward: 54.0500,                 loss: 13.6938
env1_first_0:                 episode reward: -46.0000,                 loss: nan
env1_second_0:                 episode reward: 46.0000,                 loss: nan
Episode: 29281/30000 (97.6033%),                 avg. length: 343.35,                last time consumption/overall running time: 54.4890s / 236126.4954 s
env0_first_0:                 episode reward: -89.6500,                 loss: 23.4205
env0_second_0:                 episode reward: 89.6500,                 loss: 24.8895
env1_first_0:                 episode reward: -85.3500,                 loss: nan
env1_second_0:                 episode reward: 85.3500,                 loss: nan
Episode: 29301/30000 (97.6700%),                 avg. length: 345.4,                last time consumption/overall running time: 54.1464s / 236180.6418 s
env0_first_0:                 episode reward: -80.4000,                 loss: 33.9139
env0_second_0:                 episode reward: 80.4000,                 loss: 37.1508
env1_first_0:                 episode reward: -76.0500,                 loss: nan
env1_second_0:                 episode reward: 76.0500,                 loss: nan
Episode: 29321/30000 (97.7367%),                 avg. length: 320.3,                last time consumption/overall running time: 49.6200s / 236230.2618 s
env0_first_0:                 episode reward: -78.8500,                 loss: 38.6539
env0_second_0:                 episode reward: 78.8500,                 loss: 39.0958
env1_first_0:                 episode reward: -79.6000,                 loss: nan
env1_second_0:                 episode reward: 79.6000,                 loss: nan
Episode: 29341/30000 (97.8033%),                 avg. length: 346.75,                last time consumption/overall running time: 53.2011s / 236283.4629 s
env0_first_0:                 episode reward: -72.4000,                 loss: 41.4901
env0_second_0:                 episode reward: 72.4000,                 loss: 42.9416
env1_first_0:                 episode reward: -81.8500,                 loss: nan
env1_second_0:                 episode reward: 81.8500,                 loss: nan
Episode: 29361/30000 (97.8700%),                 avg. length: 291.7,                last time consumption/overall running time: 47.2412s / 236330.7041 s
env0_first_0:                 episode reward: -80.4500,                 loss: 54.2444
env0_second_0:                 episode reward: 80.4500,                 loss: 54.9764
env1_first_0:                 episode reward: -68.6500,                 loss: nan
env1_second_0:                 episode reward: 68.6500,                 loss: nan
Episode: 29381/30000 (97.9367%),                 avg. length: 978.9,                last time consumption/overall running time: 130.4935s / 236461.1976 s
env0_first_0:                 episode reward: -47.0500,                 loss: 31.4807
env0_second_0:                 episode reward: 47.0500,                 loss: 34.0566
env1_first_0:                 episode reward: -38.4000,                 loss: nan
env1_second_0:                 episode reward: 38.4000,                 loss: nan
Episode: 29401/30000 (98.0033%),                 avg. length: 1401.3,                last time consumption/overall running time: 182.3359s / 236643.5335 s
env0_first_0:                 episode reward: -23.0000,                 loss: 10.9847
env0_second_0:                 episode reward: 23.0000,                 loss: 14.5209
env1_first_0:                 episode reward: -5.5000,                 loss: nan
env1_second_0:                 episode reward: 5.5000,                 loss: nan
Episode: 29421/30000 (98.0700%),                 avg. length: 1389.05,                last time consumption/overall running time: 183.8375s / 236827.3709 s
env0_first_0:                 episode reward: -4.5000,                 loss: 24.5646
env0_second_0:                 episode reward: 4.5000,                 loss: 26.3475
env1_first_0:                 episode reward: -7.8000,                 loss: nan
env1_second_0:                 episode reward: 7.8000,                 loss: nan
Episode: 29441/30000 (98.1367%),                 avg. length: 1252.95,                last time consumption/overall running time: 168.6394s / 236996.0104 s
env0_first_0:                 episode reward: -22.8000,                 loss: 26.8187
env0_second_0:                 episode reward: 22.8000,                 loss: 31.9270
env1_first_0:                 episode reward: -12.1500,                 loss: nan
env1_second_0:                 episode reward: 12.1500,                 loss: nan
Episode: 29461/30000 (98.2033%),                 avg. length: 1256.6,                last time consumption/overall running time: 164.3290s / 237160.3393 s
env0_first_0:                 episode reward: -20.4500,                 loss: 26.2593
env0_second_0:                 episode reward: 20.4500,                 loss: 28.8295
env1_first_0:                 episode reward: -24.9500,                 loss: nan
env1_second_0:                 episode reward: 24.9500,                 loss: nan
Episode: 29481/30000 (98.2700%),                 avg. length: 1689.6,                last time consumption/overall running time: 223.7272s / 237384.0665 s
env0_first_0:                 episode reward: 15.0500,                 loss: 9.1476
env0_second_0:                 episode reward: -15.0500,                 loss: 11.9619
env1_first_0:                 episode reward: 24.1000,                 loss: nan
env1_second_0:                 episode reward: -24.1000,                 loss: nan
Episode: 29501/30000 (98.3367%),                 avg. length: 1667.0,                last time consumption/overall running time: 225.1915s / 237609.2580 s
env0_first_0:                 episode reward: 30.4500,                 loss: 5.6244
env0_second_0:                 episode reward: -30.4500,                 loss: 8.2057
env1_first_0:                 episode reward: 26.4000,                 loss: nan
env1_second_0:                 episode reward: -26.4000,                 loss: nan
Episode: 29521/30000 (98.4033%),                 avg. length: 1645.45,                last time consumption/overall running time: 210.1377s / 237819.3957 s
env0_first_0:                 episode reward: 31.3500,                 loss: 7.0381
env0_second_0:                 episode reward: -31.3500,                 loss: 8.8008
env1_first_0:                 episode reward: 30.8500,                 loss: nan
env1_second_0:                 episode reward: -30.8500,                 loss: nan
Episode: 29541/30000 (98.4700%),                 avg. length: 1784.0,                last time consumption/overall running time: 232.0654s / 238051.4611 s
env0_first_0:                 episode reward: 45.1000,                 loss: 2.9684
env0_second_0:                 episode reward: -45.1000,                 loss: 5.1255
env1_first_0:                 episode reward: 44.0000,                 loss: nan
env1_second_0:                 episode reward: -44.0000,                 loss: nan
Episode: 29561/30000 (98.5367%),                 avg. length: 1784.0,                last time consumption/overall running time: 259.7098s / 238311.1708 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.1829
env0_second_0:                 episode reward: 0.0000,                 loss: 2.4979
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 29581/30000 (98.6033%),                 avg. length: 1784.0,                last time consumption/overall running time: 229.9426s / 238541.1134 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.1088
env0_second_0:                 episode reward: 0.0000,                 loss: 2.4343
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 29601/30000 (98.6700%),                 avg. length: 1702.3,                last time consumption/overall running time: 226.9288s / 238768.0422 s
env0_first_0:                 episode reward: 30.0500,                 loss: 2.8969
env0_second_0:                 episode reward: -30.0500,                 loss: 4.8264
env1_first_0:                 episode reward: 27.6000,                 loss: nan
env1_second_0:                 episode reward: -27.6000,                 loss: nan
Episode: 29621/30000 (98.7367%),                 avg. length: 1743.2,                last time consumption/overall running time: 228.2875s / 238996.3297 s
env0_first_0:                 episode reward: 49.0500,                 loss: 3.3116
env0_second_0:                 episode reward: -49.0500,                 loss: 5.3852
env1_first_0:                 episode reward: 48.5000,                 loss: nan
env1_second_0:                 episode reward: -48.5000,                 loss: nan
Episode: 29641/30000 (98.8033%),                 avg. length: 1632.45,                last time consumption/overall running time: 216.0754s / 239212.4051 s
env0_first_0:                 episode reward: 65.4500,                 loss: 4.6263
env0_second_0:                 episode reward: -65.4500,                 loss: 7.0637
env1_first_0:                 episode reward: 65.9000,                 loss: nan
env1_second_0:                 episode reward: -65.9000,                 loss: nan
Episode: 29661/30000 (98.8700%),                 avg. length: 1128.35,                last time consumption/overall running time: 150.1950s / 239362.6000 s
env0_first_0:                 episode reward: 65.7500,                 loss: 6.6291
env0_second_0:                 episode reward: -65.7500,                 loss: 9.5280
env1_first_0:                 episode reward: 67.6500,                 loss: nan
env1_second_0:                 episode reward: -67.6500,                 loss: nan
Episode: 29681/30000 (98.9367%),                 avg. length: 1011.4,                last time consumption/overall running time: 137.6444s / 239500.2444 s
env0_first_0:                 episode reward: 65.3000,                 loss: 6.8436
env0_second_0:                 episode reward: -65.3000,                 loss: 9.5324
env1_first_0:                 episode reward: 69.7000,                 loss: nan
env1_second_0:                 episode reward: -69.7000,                 loss: nan
Episode: 29701/30000 (99.0033%),                 avg. length: 1017.45,                last time consumption/overall running time: 137.6853s / 239637.9297 s
env0_first_0:                 episode reward: 70.9500,                 loss: 6.0137
env0_second_0:                 episode reward: -70.9500,                 loss: 9.0307
env1_first_0:                 episode reward: 72.2500,                 loss: nan
env1_second_0:                 episode reward: -72.2500,                 loss: nan
Episode: 29721/30000 (99.0700%),                 avg. length: 967.55,                last time consumption/overall running time: 136.8686s / 239774.7984 s
env0_first_0:                 episode reward: 69.0500,                 loss: 6.0852
env0_second_0:                 episode reward: -69.0500,                 loss: 8.2587
env1_first_0:                 episode reward: 75.4000,                 loss: nan
env1_second_0:                 episode reward: -75.4000,                 loss: nan
Episode: 29741/30000 (99.1367%),                 avg. length: 1153.95,                last time consumption/overall running time: 163.1276s / 239937.9260 s
env0_first_0:                 episode reward: 64.8000,                 loss: 6.0334
env0_second_0:                 episode reward: -64.8000,                 loss: 8.1239
env1_first_0:                 episode reward: 68.3500,                 loss: nan
env1_second_0:                 episode reward: -68.3500,                 loss: nan
Episode: 29761/30000 (99.2033%),                 avg. length: 1464.05,                last time consumption/overall running time: 195.5991s / 240133.5251 s
env0_first_0:                 episode reward: 28.1500,                 loss: 11.2184
env0_second_0:                 episode reward: -28.1500,                 loss: 13.0965
env1_first_0:                 episode reward: 50.4000,                 loss: nan
env1_second_0:                 episode reward: -50.4000,                 loss: nan
Episode: 29781/30000 (99.2700%),                 avg. length: 699.7,                last time consumption/overall running time: 98.9368s / 240232.4619 s
env0_first_0:                 episode reward: -12.0000,                 loss: 44.8039
env0_second_0:                 episode reward: 12.0000,                 loss: 49.2769
env1_first_0:                 episode reward: 20.7500,                 loss: nan
env1_second_0:                 episode reward: -20.7500,                 loss: nan
Episode: 29801/30000 (99.3367%),                 avg. length: 763.05,                last time consumption/overall running time: 107.9991s / 240340.4610 s
env0_first_0:                 episode reward: 36.9000,                 loss: 32.4193
env0_second_0:                 episode reward: -36.9000,                 loss: 32.9917
env1_first_0:                 episode reward: 31.4000,                 loss: nan
env1_second_0:                 episode reward: -31.4000,                 loss: nan
Episode: 29821/30000 (99.4033%),                 avg. length: 458.35,                last time consumption/overall running time: 66.8814s / 240407.3424 s
env0_first_0:                 episode reward: -43.5500,                 loss: 91.2662
env0_second_0:                 episode reward: 43.5500,                 loss: 89.3897
env1_first_0:                 episode reward: -11.7000,                 loss: nan
env1_second_0:                 episode reward: 11.7000,                 loss: nan
Episode: 29841/30000 (99.4700%),                 avg. length: 519.6,                last time consumption/overall running time: 74.8647s / 240482.2071 sLoad boxing_v1 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
Load boxing_v1 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
/home/zihan/research/MARS/mars/rl/agents/nash_ppo.py:181: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1641801999604/work/torch/csrc/utils/tensor_new.cpp:210.)
  s,a,r,s_prime,prob_a,done_mask =    torch.tensor(s_lst, dtype=torch.float).to(self.device), torch.tensor(a_lst).to(self.device), \
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

env0_first_0:                 episode reward: -51.1000,                 loss: 61.0093
env0_second_0:                 episode reward: 51.1000,                 loss: 63.5929
env1_first_0:                 episode reward: -45.5500,                 loss: nan
env1_second_0:                 episode reward: 45.5500,                 loss: nan
Episode: 29861/30000 (99.5367%),                 avg. length: 378.1,                last time consumption/overall running time: 56.6171s / 240538.8242 s
env0_first_0:                 episode reward: -57.0500,                 loss: 60.6021
env0_second_0:                 episode reward: 57.0500,                 loss: 58.8846
env1_first_0:                 episode reward: -71.4000,                 loss: nan
env1_second_0:                 episode reward: 71.4000,                 loss: nan
Episode: 29881/30000 (99.6033%),                 avg. length: 339.75,                last time consumption/overall running time: 51.4538s / 240590.2780 s
env0_first_0:                 episode reward: -69.6000,                 loss: 59.8123
env0_second_0:                 episode reward: 69.6000,                 loss: 63.3044
env1_first_0:                 episode reward: -68.9500,                 loss: nan
env1_second_0:                 episode reward: 68.9500,                 loss: nan
Episode: 29901/30000 (99.6700%),                 avg. length: 302.45,                last time consumption/overall running time: 46.8262s / 240637.1042 s
env0_first_0:                 episode reward: -56.4000,                 loss: 59.2507
env0_second_0:                 episode reward: 56.4000,                 loss: 62.6183
env1_first_0:                 episode reward: -63.7500,                 loss: nan
env1_second_0:                 episode reward: 63.7500,                 loss: nan
Episode: 29921/30000 (99.7367%),                 avg. length: 376.5,                last time consumption/overall running time: 56.9778s / 240694.0821 s
env0_first_0:                 episode reward: -69.2000,                 loss: 58.1722
env0_second_0:                 episode reward: 69.2000,                 loss: 58.8357
env1_first_0:                 episode reward: -59.1500,                 loss: nan
env1_second_0:                 episode reward: 59.1500,                 loss: nan
Episode: 29941/30000 (99.8033%),                 avg. length: 378.1,                last time consumption/overall running time: 58.2330s / 240752.3151 s
env0_first_0:                 episode reward: -61.5500,                 loss: 53.7006
env0_second_0:                 episode reward: 61.5500,                 loss: 54.1365
env1_first_0:                 episode reward: -67.2000,                 loss: nan
env1_second_0:                 episode reward: 67.2000,                 loss: nan
Episode: 29961/30000 (99.8700%),                 avg. length: 445.4,                last time consumption/overall running time: 66.0403s / 240818.3554 s
env0_first_0:                 episode reward: -42.0500,                 loss: 55.6297
env0_second_0:                 episode reward: 42.0500,                 loss: 58.0484
env1_first_0:                 episode reward: -33.6000,                 loss: nan
env1_second_0:                 episode reward: 33.6000,                 loss: nan
Episode: 29981/30000 (99.9367%),                 avg. length: 540.7,                last time consumption/overall running time: 79.7409s / 240898.0963 s
env0_first_0:                 episode reward: 34.2000,                 loss: 45.2405
env0_second_0:                 episode reward: -34.2000,                 loss: 46.6554
env1_first_0:                 episode reward: 19.2000,                 loss: nan
env1_second_0:                 episode reward: -19.2000,                 loss: nan
