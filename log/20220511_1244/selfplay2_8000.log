2022-05-11 12:51:09.763771: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia:/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia
2022-05-11 12:51:09.763835: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia:/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia
2022-05-11 12:51:09.763840: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
pygame 2.0.1 (SDL 2.0.14, Python 3.6.13)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 12.0, (1,), float32) action space: Discrete(3)
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7fd3c2147518>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=32, bias=True)
      (3): ReLU()
      (4): Linear(in_features=32, out_features=32, bias=True)
      (5): ReLU()
      (6): Linear(in_features=32, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=32, bias=True)
      (3): ReLU()
      (4): Linear(in_features=32, out_features=32, bias=True)
      (5): ReLU()
      (6): Linear(in_features=32, out_features=3, bias=True)
    )
  )
)
Error: no exploited model index given!
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  data/model/20220511124050/mdp_arbitrary_mdp_selfplay2/8000_0
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': 1, 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 1.0, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 8000}, 'num_process': 1, 'batch_size': 640, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220511124050/mdp_arbitrary_mdp_selfplay2/8000_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 1000, 'net_architecture': {'hidden_dim_list': [32, 32, 32], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'selfplay2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'selfplay_score_delta': 1.5, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'against_baseline': False}
Save models to : /home/quantumiracle/research/MARS/data/model/20220511124050_exploit_8000/mdp_arbitrary_mdp_selfplay2. 
 Save logs to: /home/quantumiracle/research/MARS/data/log/20220511124050_exploit_8000/mdp_arbitrary_mdp_selfplay2.
Episode: 1/10000 (0.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7655s / 0.7655 s
agent0:                 episode reward: 2.0538,                 loss: nan
agent1:                 episode reward: -2.0538,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0226s / 0.7881 s
agent0:                 episode reward: 0.2648,                 loss: nan
agent1:                 episode reward: -0.2648,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0210s / 0.8091 s
agent0:                 episode reward: 0.5756,                 loss: nan
agent1:                 episode reward: -0.5756,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0216s / 0.8307 s
agent0:                 episode reward: 0.2248,                 loss: nan
agent1:                 episode reward: -0.2248,                 loss: nan
Episode: 81/10000 (0.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0213s / 0.8521 s
agent0:                 episode reward: 0.1112,                 loss: nan
agent1:                 episode reward: -0.1112,                 loss: nan
Episode: 101/10000 (1.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0215s / 0.8735 s
agent0:                 episode reward: 0.1852,                 loss: nan
agent1:                 episode reward: -0.1852,                 loss: nan
Episode: 121/10000 (1.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0216s / 0.8952 s
agent0:                 episode reward: -0.1170,                 loss: nan
agent1:                 episode reward: 0.1170,                 loss: nan
Episode: 141/10000 (1.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0223s / 0.9175 s
agent0:                 episode reward: -0.0686,                 loss: nan
agent1:                 episode reward: 0.0686,                 loss: nan
Episode: 161/10000 (1.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0227s / 0.9403 s
agent0:                 episode reward: -0.1318,                 loss: nan
agent1:                 episode reward: 0.1318,                 loss: nan
Episode: 181/10000 (1.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0223s / 0.9625 s
agent0:                 episode reward: 0.3709,                 loss: nan
agent1:                 episode reward: -0.3709,                 loss: nan
Episode: 201/10000 (2.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0218s / 0.9844 s
agent0:                 episode reward: 0.1725,                 loss: nan
agent1:                 episode reward: -0.1725,                 loss: nan
Episode: 221/10000 (2.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0948s / 1.0792 s
agent0:                 episode reward: 0.1828,                 loss: nan
agent1:                 episode reward: -0.1828,                 loss: 0.4557
Episode: 241/10000 (2.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1960s / 1.2752 s
agent0:                 episode reward: 0.0136,                 loss: nan
agent1:                 episode reward: -0.0136,                 loss: 0.4493
Episode: 261/10000 (2.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2370s / 1.5122 s
agent0:                 episode reward: 0.3944,                 loss: nan
agent1:                 episode reward: -0.3944,                 loss: 0.4460
Episode: 281/10000 (2.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2009s / 1.7131 s
agent0:                 episode reward: 0.1321,                 loss: nan
agent1:                 episode reward: -0.1321,                 loss: 0.4429
Episode: 301/10000 (3.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1952s / 1.9082 s
agent0:                 episode reward: 0.1727,                 loss: nan
agent1:                 episode reward: -0.1727,                 loss: 0.4392
Episode: 321/10000 (3.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1991s / 2.1073 s
agent0:                 episode reward: -0.1798,                 loss: nan
agent1:                 episode reward: 0.1798,                 loss: 0.4362
Episode: 341/10000 (3.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1979s / 2.3052 s
agent0:                 episode reward: 0.4048,                 loss: nan
agent1:                 episode reward: -0.4048,                 loss: 0.4319
Episode: 361/10000 (3.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1929s / 2.4981 s
agent0:                 episode reward: 0.1498,                 loss: nan
agent1:                 episode reward: -0.1498,                 loss: 0.4294
Episode: 381/10000 (3.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1993s / 2.6974 s
agent0:                 episode reward: 0.2356,                 loss: nan
agent1:                 episode reward: -0.2356,                 loss: 0.4235
Episode: 401/10000 (4.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1991s / 2.8966 s
agent0:                 episode reward: 0.4100,                 loss: nan
agent1:                 episode reward: -0.4100,                 loss: 0.4190
Episode: 421/10000 (4.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1987s / 3.0953 s
agent0:                 episode reward: -0.1885,                 loss: nan
agent1:                 episode reward: 0.1885,                 loss: 0.4174
Episode: 441/10000 (4.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1999s / 3.2952 s
agent0:                 episode reward: -0.0308,                 loss: nan
agent1:                 episode reward: 0.0308,                 loss: 0.4112
Episode: 461/10000 (4.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1976s / 3.4928 s
agent0:                 episode reward: -0.3576,                 loss: nan
agent1:                 episode reward: 0.3576,                 loss: 0.4068
Episode: 481/10000 (4.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2078s / 3.7006 s
agent0:                 episode reward: 0.4005,                 loss: nan
agent1:                 episode reward: -0.4005,                 loss: 0.4024
Episode: 501/10000 (5.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1981s / 3.8987 s
agent0:                 episode reward: -0.2452,                 loss: nan
agent1:                 episode reward: 0.2452,                 loss: 0.3961
Episode: 521/10000 (5.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2028s / 4.1015 s
agent0:                 episode reward: 0.2063,                 loss: nan
agent1:                 episode reward: -0.2063,                 loss: 0.3932
Episode: 541/10000 (5.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2019s / 4.3034 s
agent0:                 episode reward: 0.0014,                 loss: nan
agent1:                 episode reward: -0.0014,                 loss: 0.3891
Episode: 561/10000 (5.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1972s / 4.5006 s
agent0:                 episode reward: 0.4164,                 loss: nan
agent1:                 episode reward: -0.4164,                 loss: 0.3738
Episode: 581/10000 (5.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2018s / 4.7023 s
agent0:                 episode reward: -0.3829,                 loss: nan
agent1:                 episode reward: 0.3829,                 loss: 0.3617
Episode: 601/10000 (6.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2022s / 4.9046 s
agent0:                 episode reward: 0.4085,                 loss: nan
agent1:                 episode reward: -0.4085,                 loss: 0.3556
Episode: 621/10000 (6.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2026s / 5.1072 s
agent0:                 episode reward: -0.1239,                 loss: nan
agent1:                 episode reward: 0.1239,                 loss: 0.3532
Episode: 641/10000 (6.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2023s / 5.3095 s
agent0:                 episode reward: 0.2207,                 loss: nan
agent1:                 episode reward: -0.2207,                 loss: 0.3475
Episode: 661/10000 (6.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1985s / 5.5080 s
agent0:                 episode reward: -0.1735,                 loss: nan
agent1:                 episode reward: 0.1735,                 loss: 0.3438
Episode: 681/10000 (6.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2040s / 5.7120 s
agent0:                 episode reward: -0.0584,                 loss: nan
agent1:                 episode reward: 0.0584,                 loss: 0.3436
Episode: 701/10000 (7.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2022s / 5.9142 s
agent0:                 episode reward: 0.1623,                 loss: nan
agent1:                 episode reward: -0.1623,                 loss: 0.3398
Episode: 721/10000 (7.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2234s / 6.1376 s
agent0:                 episode reward: -0.3004,                 loss: nan
agent1:                 episode reward: 0.3004,                 loss: 0.3392
Episode: 741/10000 (7.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2054s / 6.3430 s
agent0:                 episode reward: -0.3807,                 loss: nan
agent1:                 episode reward: 0.3807,                 loss: 0.3336
Episode: 761/10000 (7.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2109s / 6.5538 s
agent0:                 episode reward: -0.0655,                 loss: nan
agent1:                 episode reward: 0.0655,                 loss: 0.3321
Episode: 781/10000 (7.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2016s / 6.7554 s
agent0:                 episode reward: 0.3552,                 loss: nan
agent1:                 episode reward: -0.3552,                 loss: 0.3287
Episode: 801/10000 (8.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2036s / 6.9590 s
agent0:                 episode reward: 0.2921,                 loss: nan
agent1:                 episode reward: -0.2921,                 loss: 0.3315
Episode: 821/10000 (8.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2071s / 7.1661 s
agent0:                 episode reward: -0.2017,                 loss: nan
agent1:                 episode reward: 0.2017,                 loss: 0.3277
Episode: 841/10000 (8.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2074s / 7.3734 s
agent0:                 episode reward: -0.0826,                 loss: nan
agent1:                 episode reward: 0.0826,                 loss: 0.3298
Episode: 861/10000 (8.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2062s / 7.5796 s
agent0:                 episode reward: -0.0381,                 loss: nan
agent1:                 episode reward: 0.0381,                 loss: 0.3280
Episode: 881/10000 (8.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2048s / 7.7844 s
agent0:                 episode reward: 0.0700,                 loss: nan
agent1:                 episode reward: -0.0700,                 loss: 0.3301
Episode: 901/10000 (9.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2022s / 7.9866 s
agent0:                 episode reward: -0.3978,                 loss: nan
agent1:                 episode reward: 0.3978,                 loss: 0.3314
Episode: 921/10000 (9.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2066s / 8.1932 s
agent0:                 episode reward: 0.1396,                 loss: nan
agent1:                 episode reward: -0.1396,                 loss: 0.3293
Episode: 941/10000 (9.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2074s / 8.4007 s
agent0:                 episode reward: -0.1273,                 loss: nan
agent1:                 episode reward: 0.1273,                 loss: 0.3252
Episode: 961/10000 (9.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2090s / 8.6097 s
agent0:                 episode reward: -0.2026,                 loss: nan
agent1:                 episode reward: 0.2026,                 loss: 0.3242
Episode: 981/10000 (9.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2079s / 8.8176 s
agent0:                 episode reward: 0.2924,                 loss: nan
agent1:                 episode reward: -0.2924,                 loss: 0.3289
Episode: 1001/10000 (10.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2046s / 9.0222 s
agent0:                 episode reward: 0.1513,                 loss: nan
agent1:                 episode reward: -0.1513,                 loss: 0.3216
Episode: 1021/10000 (10.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2078s / 9.2300 s
agent0:                 episode reward: 0.3228,                 loss: nan
agent1:                 episode reward: -0.3228,                 loss: 0.3220
Episode: 1041/10000 (10.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2091s / 9.4391 s
agent0:                 episode reward: -0.3642,                 loss: nan
agent1:                 episode reward: 0.3642,                 loss: 0.3210
Episode: 1061/10000 (10.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2193s / 9.6584 s
agent0:                 episode reward: 0.0628,                 loss: nan
agent1:                 episode reward: -0.0628,                 loss: 0.3174
Episode: 1081/10000 (10.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2118s / 9.8702 s
agent0:                 episode reward: -0.3077,                 loss: nan
agent1:                 episode reward: 0.3077,                 loss: 0.3152
Episode: 1101/10000 (11.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2121s / 10.0823 s
agent0:                 episode reward: -0.1210,                 loss: nan
agent1:                 episode reward: 0.1210,                 loss: 0.3152
Episode: 1121/10000 (11.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2110s / 10.2933 s
agent0:                 episode reward: -0.1678,                 loss: nan
agent1:                 episode reward: 0.1678,                 loss: 0.3136
Episode: 1141/10000 (11.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2084s / 10.5017 s
agent0:                 episode reward: -0.2879,                 loss: nan
agent1:                 episode reward: 0.2879,                 loss: 0.3102
Episode: 1161/10000 (11.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2126s / 10.7143 s
agent0:                 episode reward: -0.0856,                 loss: nan
agent1:                 episode reward: 0.0856,                 loss: 0.3078
Episode: 1181/10000 (11.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2109s / 10.9251 s
agent0:                 episode reward: -0.2857,                 loss: nan
agent1:                 episode reward: 0.2857,                 loss: 0.3070
Episode: 1201/10000 (12.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2092s / 11.1343 s
agent0:                 episode reward: -0.0346,                 loss: nan
agent1:                 episode reward: 0.0346,                 loss: 0.3095
Episode: 1221/10000 (12.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2112s / 11.3455 s
agent0:                 episode reward: 0.0840,                 loss: nan
agent1:                 episode reward: -0.0840,                 loss: 0.3069
Episode: 1241/10000 (12.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2120s / 11.5575 s
agent0:                 episode reward: -0.2523,                 loss: nan
agent1:                 episode reward: 0.2523,                 loss: 0.2933
Episode: 1261/10000 (12.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2629s / 11.8204 s
agent0:                 episode reward: -0.3880,                 loss: nan
agent1:                 episode reward: 0.3880,                 loss: 0.2920
Episode: 1281/10000 (12.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2071s / 12.0276 s
agent0:                 episode reward: -0.2948,                 loss: nan
agent1:                 episode reward: 0.2948,                 loss: 0.2863
Episode: 1301/10000 (13.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2121s / 12.2397 s
agent0:                 episode reward: -0.2748,                 loss: nan
agent1:                 episode reward: 0.2748,                 loss: 0.2883
Episode: 1321/10000 (13.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2122s / 12.4519 s
agent0:                 episode reward: -0.2779,                 loss: nan
agent1:                 episode reward: 0.2779,                 loss: 0.2839
Episode: 1341/10000 (13.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2240s / 12.6759 s
agent0:                 episode reward: -0.1352,                 loss: nan
agent1:                 episode reward: 0.1352,                 loss: 0.2874
Episode: 1361/10000 (13.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2139s / 12.8898 s
agent0:                 episode reward: -0.4701,                 loss: nan
agent1:                 episode reward: 0.4701,                 loss: 0.2853
Episode: 1381/10000 (13.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2140s / 13.1038 s
agent0:                 episode reward: 0.2395,                 loss: nan
agent1:                 episode reward: -0.2395,                 loss: 0.2866
Episode: 1401/10000 (14.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2160s / 13.3198 s
agent0:                 episode reward: -0.2534,                 loss: nan
agent1:                 episode reward: 0.2534,                 loss: 0.2868
Episode: 1421/10000 (14.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2097s / 13.5295 s
agent0:                 episode reward: -0.3479,                 loss: nan
agent1:                 episode reward: 0.3479,                 loss: 0.2825
Episode: 1441/10000 (14.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2181s / 13.7476 s
agent0:                 episode reward: -0.0774,                 loss: nan
agent1:                 episode reward: 0.0774,                 loss: 0.2846
Episode: 1461/10000 (14.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2172s / 13.9648 s
agent0:                 episode reward: -0.2578,                 loss: nan
agent1:                 episode reward: 0.2578,                 loss: 0.2847
Episode: 1481/10000 (14.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2150s / 14.1798 s
agent0:                 episode reward: -0.2626,                 loss: nan
agent1:                 episode reward: 0.2626,                 loss: 0.2822
Episode: 1501/10000 (15.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2343s / 14.4141 s
agent0:                 episode reward: -0.0200,                 loss: nan
agent1:                 episode reward: 0.0200,                 loss: 0.2779
Episode: 1521/10000 (15.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2186s / 14.6326 s
agent0:                 episode reward: -0.3722,                 loss: nan
agent1:                 episode reward: 0.3722,                 loss: 0.2796
Episode: 1541/10000 (15.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2176s / 14.8502 s
agent0:                 episode reward: -0.4440,                 loss: nan
agent1:                 episode reward: 0.4440,                 loss: 0.2758
Episode: 1561/10000 (15.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2143s / 15.0646 s
agent0:                 episode reward: -0.7389,                 loss: nan
agent1:                 episode reward: 0.7389,                 loss: 0.2709
Episode: 1581/10000 (15.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2150s / 15.2796 s
agent0:                 episode reward: -0.1741,                 loss: nan
agent1:                 episode reward: 0.1741,                 loss: 0.2648
Episode: 1601/10000 (16.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2163s / 15.4959 s
agent0:                 episode reward: -0.5757,                 loss: nan
agent1:                 episode reward: 0.5757,                 loss: 0.2650
Episode: 1621/10000 (16.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2521s / 15.7480 s
agent0:                 episode reward: -0.0957,                 loss: nan
agent1:                 episode reward: 0.0957,                 loss: 0.2667
Episode: 1641/10000 (16.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2192s / 15.9671 s
agent0:                 episode reward: -0.7055,                 loss: nan
agent1:                 episode reward: 0.7055,                 loss: 0.2641
Episode: 1661/10000 (16.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2211s / 16.1883 s
agent0:                 episode reward: -0.7973,                 loss: nan
agent1:                 episode reward: 0.7973,                 loss: 0.2658
Episode: 1681/10000 (16.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2188s / 16.4071 s
agent0:                 episode reward: -0.5676,                 loss: nan
agent1:                 episode reward: 0.5676,                 loss: 0.2586
Episode: 1701/10000 (17.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2347s / 16.6418 s
agent0:                 episode reward: -0.4185,                 loss: nan
agent1:                 episode reward: 0.4185,                 loss: 0.2593
Episode: 1721/10000 (17.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2302s / 16.8720 s
agent0:                 episode reward: -0.1394,                 loss: nan
agent1:                 episode reward: 0.1394,                 loss: 0.2592
Episode: 1741/10000 (17.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2194s / 17.0914 s
agent0:                 episode reward: -0.1804,                 loss: nan
agent1:                 episode reward: 0.1804,                 loss: 0.2571
Episode: 1761/10000 (17.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2215s / 17.3129 s
agent0:                 episode reward: -0.1821,                 loss: nan
agent1:                 episode reward: 0.1821,                 loss: 0.2602
Episode: 1781/10000 (17.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2176s / 17.5305 s
agent0:                 episode reward: -0.6273,                 loss: nan
agent1:                 episode reward: 0.6273,                 loss: 0.2587
Episode: 1801/10000 (18.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2189s / 17.7494 s
agent0:                 episode reward: 0.1146,                 loss: nan
agent1:                 episode reward: -0.1146,                 loss: 0.2591
Episode: 1821/10000 (18.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2209s / 17.9704 s
agent0:                 episode reward: 0.1096,                 loss: nan
agent1:                 episode reward: -0.1096,                 loss: 0.2560
Episode: 1841/10000 (18.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2217s / 18.1921 s
agent0:                 episode reward: -0.7119,                 loss: nan
agent1:                 episode reward: 0.7119,                 loss: 0.2561
Episode: 1861/10000 (18.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2225s / 18.4145 s
agent0:                 episode reward: -0.1468,                 loss: nan
agent1:                 episode reward: 0.1468,                 loss: 0.2585
Episode: 1881/10000 (18.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2263s / 18.6408 s
agent0:                 episode reward: -0.3531,                 loss: nan
agent1:                 episode reward: 0.3531,                 loss: 0.2542
Episode: 1901/10000 (19.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2261s / 18.8669 s
agent0:                 episode reward: -0.1608,                 loss: nan
agent1:                 episode reward: 0.1608,                 loss: 0.2500
Episode: 1921/10000 (19.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2232s / 19.0902 s
agent0:                 episode reward: -0.1655,                 loss: nan
agent1:                 episode reward: 0.1655,                 loss: 0.2485
Episode: 1941/10000 (19.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2228s / 19.3130 s
agent0:                 episode reward: -0.6394,                 loss: nan
agent1:                 episode reward: 0.6394,                 loss: 0.2484
Episode: 1961/10000 (19.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2260s / 19.5390 s
agent0:                 episode reward: -0.2855,                 loss: nan
agent1:                 episode reward: 0.2855,                 loss: 0.2473
Episode: 1981/10000 (19.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2193s / 19.7583 s
agent0:                 episode reward: -0.3189,                 loss: nan
agent1:                 episode reward: 0.3189,                 loss: 0.2507
Episode: 2001/10000 (20.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2213s / 19.9797 s
agent0:                 episode reward: -0.1874,                 loss: nan
agent1:                 episode reward: 0.1874,                 loss: 0.2461
Episode: 2021/10000 (20.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2260s / 20.2057 s
agent0:                 episode reward: -0.4214,                 loss: nan
agent1:                 episode reward: 0.4214,                 loss: 0.2463
Episode: 2041/10000 (20.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2233s / 20.4290 s
agent0:                 episode reward: -0.6479,                 loss: nan
agent1:                 episode reward: 0.6479,                 loss: 0.2462
Episode: 2061/10000 (20.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2229s / 20.6518 s
agent0:                 episode reward: -0.2248,                 loss: nan
agent1:                 episode reward: 0.2248,                 loss: 0.2460
Episode: 2081/10000 (20.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2272s / 20.8791 s
agent0:                 episode reward: -0.4510,                 loss: nan
agent1:                 episode reward: 0.4510,                 loss: 0.2443
Episode: 2101/10000 (21.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2273s / 21.1064 s
agent0:                 episode reward: -0.2481,                 loss: nan
agent1:                 episode reward: 0.2481,                 loss: 0.2460
Episode: 2121/10000 (21.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2246s / 21.3310 s
agent0:                 episode reward: -0.5383,                 loss: nan
agent1:                 episode reward: 0.5383,                 loss: 0.2464
Episode: 2141/10000 (21.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2263s / 21.5573 s
agent0:                 episode reward: -0.2953,                 loss: nan
agent1:                 episode reward: 0.2953,                 loss: 0.2462
Episode: 2161/10000 (21.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2371s / 21.7943 s
agent0:                 episode reward: -0.2194,                 loss: nan
agent1:                 episode reward: 0.2194,                 loss: 0.2414
Episode: 2181/10000 (21.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2794s / 22.0738 s
agent0:                 episode reward: -0.5360,                 loss: nan
agent1:                 episode reward: 0.5360,                 loss: 0.2417
Episode: 2201/10000 (22.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2246s / 22.2983 s
agent0:                 episode reward: -0.2577,                 loss: nan
agent1:                 episode reward: 0.2577,                 loss: 0.2456
Episode: 2221/10000 (22.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2248s / 22.5232 s
agent0:                 episode reward: -0.2168,                 loss: nan
agent1:                 episode reward: 0.2168,                 loss: 0.2441
Episode: 2241/10000 (22.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2709s / 22.7941 s
agent0:                 episode reward: -0.4171,                 loss: nan
agent1:                 episode reward: 0.4171,                 loss: 0.2505
Episode: 2261/10000 (22.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2298s / 23.0239 s
agent0:                 episode reward: -0.6263,                 loss: nan
agent1:                 episode reward: 0.6263,                 loss: 0.2487
Episode: 2281/10000 (22.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2285s / 23.2524 s
agent0:                 episode reward: -0.0756,                 loss: nan
agent1:                 episode reward: 0.0756,                 loss: 0.2454
Episode: 2301/10000 (23.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2284s / 23.4809 s
agent0:                 episode reward: -0.0372,                 loss: nan
agent1:                 episode reward: 0.0372,                 loss: 0.2470
Episode: 2321/10000 (23.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2288s / 23.7097 s
agent0:                 episode reward: -0.6156,                 loss: nan
agent1:                 episode reward: 0.6156,                 loss: 0.2490
Episode: 2341/10000 (23.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2296s / 23.9393 s
agent0:                 episode reward: -0.4212,                 loss: nan
agent1:                 episode reward: 0.4212,                 loss: 0.2481
Episode: 2361/10000 (23.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2278s / 24.1671 s
agent0:                 episode reward: -0.3085,                 loss: nan
agent1:                 episode reward: 0.3085,                 loss: 0.2491
Episode: 2381/10000 (23.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2313s / 24.3984 s
agent0:                 episode reward: -0.4688,                 loss: nan
agent1:                 episode reward: 0.4688,                 loss: 0.2510
Episode: 2401/10000 (24.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2303s / 24.6287 s
agent0:                 episode reward: -0.5735,                 loss: nan
agent1:                 episode reward: 0.5735,                 loss: 0.2493
Episode: 2421/10000 (24.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2421s / 24.8708 s
agent0:                 episode reward: -0.4653,                 loss: nan
agent1:                 episode reward: 0.4653,                 loss: 0.2500
Episode: 2441/10000 (24.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2307s / 25.1015 s
agent0:                 episode reward: -0.8512,                 loss: nan
agent1:                 episode reward: 0.8512,                 loss: 0.2457
Episode: 2461/10000 (24.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2330s / 25.3345 s
agent0:                 episode reward: -0.6046,                 loss: nan
agent1:                 episode reward: 0.6046,                 loss: 0.2507
Episode: 2481/10000 (24.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2286s / 25.5631 s
agent0:                 episode reward: -0.5242,                 loss: nan
agent1:                 episode reward: 0.5242,                 loss: 0.2465
Episode: 2501/10000 (25.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2306s / 25.7936 s
agent0:                 episode reward: -0.3832,                 loss: nan
agent1:                 episode reward: 0.3832,                 loss: 0.2509
Episode: 2521/10000 (25.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2327s / 26.0263 s
agent0:                 episode reward: -0.4275,                 loss: nan
agent1:                 episode reward: 0.4275,                 loss: 0.2500
Episode: 2541/10000 (25.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2348s / 26.2612 s
agent0:                 episode reward: -1.0366,                 loss: nan
agent1:                 episode reward: 1.0366,                 loss: 0.2493
Episode: 2561/10000 (25.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2325s / 26.4937 s
agent0:                 episode reward: -0.2251,                 loss: nan
agent1:                 episode reward: 0.2251,                 loss: 0.2540
Episode: 2581/10000 (25.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2398s / 26.7334 s
agent0:                 episode reward: -0.6523,                 loss: nan
agent1:                 episode reward: 0.6523,                 loss: 0.2589
Episode: 2601/10000 (26.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2385s / 26.9720 s
agent0:                 episode reward: -0.3336,                 loss: nan
agent1:                 episode reward: 0.3336,                 loss: 0.2571
Episode: 2621/10000 (26.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2336s / 27.2056 s
agent0:                 episode reward: -0.2690,                 loss: nan
agent1:                 episode reward: 0.2690,                 loss: 0.2583
Episode: 2641/10000 (26.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2329s / 27.4384 s
agent0:                 episode reward: -0.1682,                 loss: nan
agent1:                 episode reward: 0.1682,                 loss: 0.2575
Episode: 2661/10000 (26.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2383s / 27.6767 s
agent0:                 episode reward: -0.8258,                 loss: nan
agent1:                 episode reward: 0.8258,                 loss: 0.2561
Episode: 2681/10000 (26.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2403s / 27.9170 s
agent0:                 episode reward: -0.6153,                 loss: nan
agent1:                 episode reward: 0.6153,                 loss: 0.2563
Episode: 2701/10000 (27.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2348s / 28.1518 s
agent0:                 episode reward: -0.1097,                 loss: nan
agent1:                 episode reward: 0.1097,                 loss: 0.2580
Episode: 2721/10000 (27.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2374s / 28.3892 s
agent0:                 episode reward: -0.5622,                 loss: nan
agent1:                 episode reward: 0.5622,                 loss: 0.2579
Episode: 2741/10000 (27.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2392s / 28.6284 s
agent0:                 episode reward: -0.8507,                 loss: nan
agent1:                 episode reward: 0.8507,                 loss: 0.2573
Episode: 2761/10000 (27.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2366s / 28.8650 s
agent0:                 episode reward: -0.5152,                 loss: nan
agent1:                 episode reward: 0.5152,                 loss: 0.2555
Episode: 2781/10000 (27.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2347s / 29.0997 s
agent0:                 episode reward: -0.5994,                 loss: nan
agent1:                 episode reward: 0.5994,                 loss: 0.2553
Episode: 2801/10000 (28.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2348s / 29.3345 s
agent0:                 episode reward: -0.6037,                 loss: nan
agent1:                 episode reward: 0.6037,                 loss: 0.2578
Episode: 2821/10000 (28.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2388s / 29.5733 s
agent0:                 episode reward: 0.0059,                 loss: nan
agent1:                 episode reward: -0.0059,                 loss: 0.2552
Episode: 2841/10000 (28.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2383s / 29.8116 s
agent0:                 episode reward: -0.7837,                 loss: nan
agent1:                 episode reward: 0.7837,                 loss: 0.2550
Episode: 2861/10000 (28.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2293s / 30.0410 s
agent0:                 episode reward: -0.9712,                 loss: nan
agent1:                 episode reward: 0.9712,                 loss: 0.2522
Episode: 2881/10000 (28.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2370s / 30.2779 s
agent0:                 episode reward: -0.8926,                 loss: nan
agent1:                 episode reward: 0.8926,                 loss: 0.2554
Episode: 2901/10000 (29.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2396s / 30.5175 s
agent0:                 episode reward: -0.6324,                 loss: nan
agent1:                 episode reward: 0.6324,                 loss: 0.2638
Episode: 2921/10000 (29.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2457s / 30.7632 s
agent0:                 episode reward: -0.8660,                 loss: nan
agent1:                 episode reward: 0.8660,                 loss: 0.2653
Episode: 2941/10000 (29.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2608s / 31.0240 s
agent0:                 episode reward: -0.9778,                 loss: nan
agent1:                 episode reward: 0.9778,                 loss: 0.2661
Episode: 2961/10000 (29.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2393s / 31.2633 s
agent0:                 episode reward: -0.5611,                 loss: nan
agent1:                 episode reward: 0.5611,                 loss: 0.2646
Episode: 2981/10000 (29.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2371s / 31.5004 s
agent0:                 episode reward: -0.1784,                 loss: nan
agent1:                 episode reward: 0.1784,                 loss: 0.2615
Episode: 3001/10000 (30.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2410s / 31.7414 s
agent0:                 episode reward: -0.6325,                 loss: nan
agent1:                 episode reward: 0.6325,                 loss: 0.2636
Episode: 3021/10000 (30.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2431s / 31.9845 s
agent0:                 episode reward: -0.8101,                 loss: nan
agent1:                 episode reward: 0.8101,                 loss: 0.2677
Episode: 3041/10000 (30.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2985s / 32.2831 s
agent0:                 episode reward: -0.7022,                 loss: nan
agent1:                 episode reward: 0.7022,                 loss: 0.2618
Episode: 3061/10000 (30.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2425s / 32.5255 s
agent0:                 episode reward: -0.6657,                 loss: nan
agent1:                 episode reward: 0.6657,                 loss: 0.2643
Episode: 3081/10000 (30.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2418s / 32.7673 s
agent0:                 episode reward: -0.5085,                 loss: nan
agent1:                 episode reward: 0.5085,                 loss: 0.2632
Episode: 3101/10000 (31.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2419s / 33.0092 s
agent0:                 episode reward: -0.6040,                 loss: nan
agent1:                 episode reward: 0.6040,                 loss: 0.2664
Episode: 3121/10000 (31.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2438s / 33.2531 s
agent0:                 episode reward: -0.8748,                 loss: nan
agent1:                 episode reward: 0.8748,                 loss: 0.2607
Episode: 3141/10000 (31.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2429s / 33.4959 s
agent0:                 episode reward: -0.2875,                 loss: nan
agent1:                 episode reward: 0.2875,                 loss: 0.2608
Episode: 3161/10000 (31.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2470s / 33.7430 s
agent0:                 episode reward: -0.5548,                 loss: nan
agent1:                 episode reward: 0.5548,                 loss: 0.2605
Episode: 3181/10000 (31.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2650s / 34.0079 s
agent0:                 episode reward: -0.4139,                 loss: nan
agent1:                 episode reward: 0.4139,                 loss: 0.2618
Episode: 3201/10000 (32.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2432s / 34.2512 s
agent0:                 episode reward: -0.3139,                 loss: nan
agent1:                 episode reward: 0.3139,                 loss: 0.2635
Episode: 3221/10000 (32.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2438s / 34.4950 s
agent0:                 episode reward: -0.7837,                 loss: nan
agent1:                 episode reward: 0.7837,                 loss: 0.2611
Episode: 3241/10000 (32.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2429s / 34.7379 s
agent0:                 episode reward: -0.9119,                 loss: nan
agent1:                 episode reward: 0.9119,                 loss: 0.2580
Episode: 3261/10000 (32.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2407s / 34.9786 s
agent0:                 episode reward: -0.5742,                 loss: nan
agent1:                 episode reward: 0.5742,                 loss: 0.2595
Episode: 3281/10000 (32.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2421s / 35.2207 s
agent0:                 episode reward: -0.7800,                 loss: nan
agent1:                 episode reward: 0.7800,                 loss: 0.2615
Episode: 3301/10000 (33.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2423s / 35.4631 s
agent0:                 episode reward: -0.5025,                 loss: nan
agent1:                 episode reward: 0.5025,                 loss: 0.2582
Episode: 3321/10000 (33.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2472s / 35.7103 s
agent0:                 episode reward: -0.5056,                 loss: nan
agent1:                 episode reward: 0.5056,                 loss: 0.2595
Episode: 3341/10000 (33.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2462s / 35.9565 s
agent0:                 episode reward: -0.6368,                 loss: nan
agent1:                 episode reward: 0.6368,                 loss: 0.2600
Episode: 3361/10000 (33.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2481s / 36.2046 s
agent0:                 episode reward: -0.4291,                 loss: nan
agent1:                 episode reward: 0.4291,                 loss: 0.2629
Episode: 3381/10000 (33.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2470s / 36.4515 s
agent0:                 episode reward: -0.7862,                 loss: nan
agent1:                 episode reward: 0.7862,                 loss: 0.2593
Episode: 3401/10000 (34.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2468s / 36.6983 s
agent0:                 episode reward: -0.7990,                 loss: nan
agent1:                 episode reward: 0.7990,                 loss: 0.2606
Episode: 3421/10000 (34.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2660s / 36.9643 s
agent0:                 episode reward: -0.0484,                 loss: nan
agent1:                 episode reward: 0.0484,                 loss: 0.2612
Episode: 3441/10000 (34.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2650s / 37.2293 s
agent0:                 episode reward: -0.1977,                 loss: nan
agent1:                 episode reward: 0.1977,                 loss: 0.2602
Episode: 3461/10000 (34.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2450s / 37.4743 s
agent0:                 episode reward: -0.6426,                 loss: nan
agent1:                 episode reward: 0.6426,                 loss: 0.2582
Episode: 3481/10000 (34.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2490s / 37.7233 s
agent0:                 episode reward: -0.7639,                 loss: nan
agent1:                 episode reward: 0.7639,                 loss: 0.2613
Episode: 3501/10000 (35.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2432s / 37.9665 s
agent0:                 episode reward: -0.3362,                 loss: nan
agent1:                 episode reward: 0.3362,                 loss: 0.2599
Episode: 3521/10000 (35.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2491s / 38.2156 s
agent0:                 episode reward: -0.4703,                 loss: nan
agent1:                 episode reward: 0.4703,                 loss: 0.2608
Episode: 3541/10000 (35.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2483s / 38.4639 s
agent0:                 episode reward: -0.6606,                 loss: nan
agent1:                 episode reward: 0.6606,                 loss: 0.2600
Episode: 3561/10000 (35.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2515s / 38.7155 s
agent0:                 episode reward: -0.4686,                 loss: nan
agent1:                 episode reward: 0.4686,                 loss: 0.2602
Episode: 3581/10000 (35.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2485s / 38.9639 s
agent0:                 episode reward: -0.3613,                 loss: nan
agent1:                 episode reward: 0.3613,                 loss: 0.2622
Episode: 3601/10000 (36.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2498s / 39.2137 s
agent0:                 episode reward: -0.7024,                 loss: nan
agent1:                 episode reward: 0.7024,                 loss: 0.2599
Episode: 3621/10000 (36.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2631s / 39.4769 s
agent0:                 episode reward: -0.6941,                 loss: nan
agent1:                 episode reward: 0.6941,                 loss: 0.2608
Episode: 3641/10000 (36.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2489s / 39.7258 s
agent0:                 episode reward: -0.6023,                 loss: nan
agent1:                 episode reward: 0.6023,                 loss: 0.2637
Episode: 3661/10000 (36.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2586s / 39.9844 s
agent0:                 episode reward: -0.5813,                 loss: nan
agent1:                 episode reward: 0.5813,                 loss: 0.2592
Episode: 3681/10000 (36.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2486s / 40.2330 s
agent0:                 episode reward: -0.9340,                 loss: nan
agent1:                 episode reward: 0.9340,                 loss: 0.2613
Episode: 3701/10000 (37.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2466s / 40.4796 s
agent0:                 episode reward: -0.6296,                 loss: nan
agent1:                 episode reward: 0.6296,                 loss: 0.2584
Episode: 3721/10000 (37.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2515s / 40.7311 s
agent0:                 episode reward: -0.9493,                 loss: nan
agent1:                 episode reward: 0.9493,                 loss: 0.2593
Episode: 3741/10000 (37.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2530s / 40.9841 s
agent0:                 episode reward: -0.5775,                 loss: nan
agent1:                 episode reward: 0.5775,                 loss: 0.2579
Episode: 3761/10000 (37.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2509s / 41.2350 s
agent0:                 episode reward: -0.4028,                 loss: nan
agent1:                 episode reward: 0.4028,                 loss: 0.2606
Episode: 3781/10000 (37.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2501s / 41.4851 s
agent0:                 episode reward: -0.2959,                 loss: nan
agent1:                 episode reward: 0.2959,                 loss: 0.2548
Episode: 3801/10000 (38.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2546s / 41.7397 s
agent0:                 episode reward: -0.7201,                 loss: nan
agent1:                 episode reward: 0.7201,                 loss: 0.2564
Episode: 3821/10000 (38.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2490s / 41.9886 s
agent0:                 episode reward: -0.6642,                 loss: nan
agent1:                 episode reward: 0.6642,                 loss: 0.2593
Episode: 3841/10000 (38.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2537s / 42.2423 s
agent0:                 episode reward: -0.5997,                 loss: nan
agent1:                 episode reward: 0.5997,                 loss: 0.2574
Episode: 3861/10000 (38.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2912s / 42.5335 s
agent0:                 episode reward: -0.1030,                 loss: nan
agent1:                 episode reward: 0.1030,                 loss: 0.2565
Episode: 3881/10000 (38.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2538s / 42.7874 s
agent0:                 episode reward: -0.6230,                 loss: nan
agent1:                 episode reward: 0.6230,                 loss: 0.2572
Episode: 3901/10000 (39.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2594s / 43.0468 s
agent0:                 episode reward: -0.8860,                 loss: nan
agent1:                 episode reward: 0.8860,                 loss: 0.2576
Episode: 3921/10000 (39.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2535s / 43.3002 s
agent0:                 episode reward: -1.0041,                 loss: nan
agent1:                 episode reward: 1.0041,                 loss: 0.2579
Episode: 3941/10000 (39.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2542s / 43.5545 s
agent0:                 episode reward: -0.7594,                 loss: nan
agent1:                 episode reward: 0.7594,                 loss: 0.2569
Episode: 3961/10000 (39.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2591s / 43.8135 s
agent0:                 episode reward: -0.3758,                 loss: nan
agent1:                 episode reward: 0.3758,                 loss: 0.2595
Episode: 3981/10000 (39.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2503s / 44.0638 s
agent0:                 episode reward: -0.4404,                 loss: nan
agent1:                 episode reward: 0.4404,                 loss: 0.2597
Episode: 4001/10000 (40.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2550s / 44.3188 s
agent0:                 episode reward: -0.4312,                 loss: nan
agent1:                 episode reward: 0.4312,                 loss: 0.2610
Episode: 4021/10000 (40.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2561s / 44.5750 s
agent0:                 episode reward: -0.7064,                 loss: nan
agent1:                 episode reward: 0.7064,                 loss: 0.2580
Episode: 4041/10000 (40.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2524s / 44.8274 s
agent0:                 episode reward: -0.7495,                 loss: nan
agent1:                 episode reward: 0.7495,                 loss: 0.2584
Episode: 4061/10000 (40.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2491s / 45.0765 s
agent0:                 episode reward: -0.6952,                 loss: nan
agent1:                 episode reward: 0.6952,                 loss: 0.2626
Episode: 4081/10000 (40.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2494s / 45.3259 s
agent0:                 episode reward: -0.1683,                 loss: nan
agent1:                 episode reward: 0.1683,                 loss: 0.2570
Episode: 4101/10000 (41.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2512s / 45.5771 s
agent0:                 episode reward: -0.7709,                 loss: nan
agent1:                 episode reward: 0.7709,                 loss: 0.2575
Episode: 4121/10000 (41.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2568s / 45.8339 s
agent0:                 episode reward: -0.5306,                 loss: nan
agent1:                 episode reward: 0.5306,                 loss: 0.2567
Episode: 4141/10000 (41.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2667s / 46.1006 s
agent0:                 episode reward: -0.3865,                 loss: nan
agent1:                 episode reward: 0.3865,                 loss: 0.2610
Episode: 4161/10000 (41.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2584s / 46.3590 s
agent0:                 episode reward: -0.7636,                 loss: nan
agent1:                 episode reward: 0.7636,                 loss: 0.2582
Episode: 4181/10000 (41.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2554s / 46.6144 s
agent0:                 episode reward: -0.7585,                 loss: nan
agent1:                 episode reward: 0.7585,                 loss: 0.2564
Episode: 4201/10000 (42.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2581s / 46.8725 s
agent0:                 episode reward: -0.5771,                 loss: nan
agent1:                 episode reward: 0.5771,                 loss: 0.2566
Episode: 4221/10000 (42.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2678s / 47.1403 s
agent0:                 episode reward: -0.3781,                 loss: nan
agent1:                 episode reward: 0.3781,                 loss: 0.2585
Episode: 4241/10000 (42.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2579s / 47.3982 s
agent0:                 episode reward: -0.7070,                 loss: nan
agent1:                 episode reward: 0.7070,                 loss: 0.2586
Episode: 4261/10000 (42.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2771s / 47.6752 s
agent0:                 episode reward: -0.5748,                 loss: nan
agent1:                 episode reward: 0.5748,                 loss: 0.2592
Episode: 4281/10000 (42.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2603s / 47.9355 s
agent0:                 episode reward: -0.2086,                 loss: nan
agent1:                 episode reward: 0.2086,                 loss: 0.2582
Episode: 4301/10000 (43.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2555s / 48.1910 s
agent0:                 episode reward: -0.8207,                 loss: nan
agent1:                 episode reward: 0.8207,                 loss: 0.2589
Episode: 4321/10000 (43.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2585s / 48.4495 s
agent0:                 episode reward: -0.9045,                 loss: nan
agent1:                 episode reward: 0.9045,                 loss: 0.2604
Episode: 4341/10000 (43.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2599s / 48.7094 s
agent0:                 episode reward: -0.8254,                 loss: nan
agent1:                 episode reward: 0.8254,                 loss: 0.2567
Episode: 4361/10000 (43.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2674s / 48.9769 s
agent0:                 episode reward: -0.7182,                 loss: nan
agent1:                 episode reward: 0.7182,                 loss: 0.2582
Episode: 4381/10000 (43.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2609s / 49.2378 s
agent0:                 episode reward: -0.2932,                 loss: nan
agent1:                 episode reward: 0.2932,                 loss: 0.2552
Episode: 4401/10000 (44.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2612s / 49.4990 s
agent0:                 episode reward: -0.3435,                 loss: nan
agent1:                 episode reward: 0.3435,                 loss: 0.2569
Episode: 4421/10000 (44.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2605s / 49.7595 s
agent0:                 episode reward: -0.7490,                 loss: nan
agent1:                 episode reward: 0.7490,                 loss: 0.2610
Episode: 4441/10000 (44.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2629s / 50.0224 s
agent0:                 episode reward: -0.8491,                 loss: nan
agent1:                 episode reward: 0.8491,                 loss: 0.2564
Episode: 4461/10000 (44.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2608s / 50.2833 s
agent0:                 episode reward: -0.7864,                 loss: nan
agent1:                 episode reward: 0.7864,                 loss: 0.2574
Episode: 4481/10000 (44.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2598s / 50.5431 s
agent0:                 episode reward: -0.5992,                 loss: nan
agent1:                 episode reward: 0.5992,                 loss: 0.2596
Episode: 4501/10000 (45.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2639s / 50.8069 s
agent0:                 episode reward: -0.6079,                 loss: nan
agent1:                 episode reward: 0.6079,                 loss: 0.2548
Episode: 4521/10000 (45.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2586s / 51.0655 s
agent0:                 episode reward: -0.7702,                 loss: nan
agent1:                 episode reward: 0.7702,                 loss: 0.2581
Episode: 4541/10000 (45.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2621s / 51.3276 s
agent0:                 episode reward: -0.7314,                 loss: nan
agent1:                 episode reward: 0.7314,                 loss: 0.2563
Episode: 4561/10000 (45.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2595s / 51.5871 s
agent0:                 episode reward: -0.4950,                 loss: nan
agent1:                 episode reward: 0.4950,                 loss: 0.2606
Episode: 4581/10000 (45.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2614s / 51.8485 s
agent0:                 episode reward: -0.5531,                 loss: nan
agent1:                 episode reward: 0.5531,                 loss: 0.2606
Episode: 4601/10000 (46.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2946s / 52.1431 s
agent0:                 episode reward: -0.3162,                 loss: nan
agent1:                 episode reward: 0.3162,                 loss: 0.2651
Episode: 4621/10000 (46.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2642s / 52.4073 s
agent0:                 episode reward: -1.0092,                 loss: nan
agent1:                 episode reward: 1.0092,                 loss: 0.2597
Episode: 4641/10000 (46.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3173s / 52.7247 s
agent0:                 episode reward: -0.6026,                 loss: nan
agent1:                 episode reward: 0.6026,                 loss: 0.2623
Episode: 4661/10000 (46.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2623s / 52.9870 s
agent0:                 episode reward: -0.6349,                 loss: nan
agent1:                 episode reward: 0.6349,                 loss: 0.2616
Episode: 4681/10000 (46.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2644s / 53.2514 s
agent0:                 episode reward: -0.5253,                 loss: nan
agent1:                 episode reward: 0.5253,                 loss: 0.2653
Episode: 4701/10000 (47.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2626s / 53.5140 s
agent0:                 episode reward: -0.9740,                 loss: nan
agent1:                 episode reward: 0.9740,                 loss: 0.2656
Episode: 4721/10000 (47.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2612s / 53.7752 s
agent0:                 episode reward: -0.3760,                 loss: nan
agent1:                 episode reward: 0.3760,                 loss: 0.2603
Episode: 4741/10000 (47.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2613s / 54.0365 s
agent0:                 episode reward: -0.4145,                 loss: nan
agent1:                 episode reward: 0.4145,                 loss: 0.2647
Episode: 4761/10000 (47.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2628s / 54.2993 s
agent0:                 episode reward: -0.8960,                 loss: nan
agent1:                 episode reward: 0.8960,                 loss: 0.2618
Episode: 4781/10000 (47.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2621s / 54.5614 s
agent0:                 episode reward: -0.4077,                 loss: nan
agent1:                 episode reward: 0.4077,                 loss: 0.2633
Episode: 4801/10000 (48.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2656s / 54.8270 s
agent0:                 episode reward: -0.1092,                 loss: nan
agent1:                 episode reward: 0.1092,                 loss: 0.2635
Episode: 4821/10000 (48.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2717s / 55.0987 s
agent0:                 episode reward: -0.8103,                 loss: nan
agent1:                 episode reward: 0.8103,                 loss: 0.2629
Episode: 4841/10000 (48.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2738s / 55.3725 s
agent0:                 episode reward: -0.5120,                 loss: nan
agent1:                 episode reward: 0.5120,                 loss: 0.2612
Episode: 4861/10000 (48.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2708s / 55.6433 s
agent0:                 episode reward: -0.7931,                 loss: nan
agent1:                 episode reward: 0.7931,                 loss: 0.2675
Episode: 4881/10000 (48.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2680s / 55.9113 s
agent0:                 episode reward: -0.9287,                 loss: nan
agent1:                 episode reward: 0.9287,                 loss: 0.2596
Episode: 4901/10000 (49.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2828s / 56.1941 s
agent0:                 episode reward: -0.7712,                 loss: nan
agent1:                 episode reward: 0.7712,                 loss: 0.2673
Episode: 4921/10000 (49.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2653s / 56.4594 s
agent0:                 episode reward: -0.6219,                 loss: nan
agent1:                 episode reward: 0.6219,                 loss: 0.2678
Episode: 4941/10000 (49.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2659s / 56.7253 s
agent0:                 episode reward: -0.6535,                 loss: nan
agent1:                 episode reward: 0.6535,                 loss: 0.2661
Episode: 4961/10000 (49.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2621s / 56.9874 s
agent0:                 episode reward: -0.7289,                 loss: nan
agent1:                 episode reward: 0.7289,                 loss: 0.2677
Episode: 4981/10000 (49.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2780s / 57.2654 s
agent0:                 episode reward: -0.7305,                 loss: nan
agent1:                 episode reward: 0.7305,                 loss: 0.2677
Episode: 5001/10000 (50.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2628s / 57.5281 s
agent0:                 episode reward: -0.8337,                 loss: nan
agent1:                 episode reward: 0.8337,                 loss: 0.2673
Episode: 5021/10000 (50.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2682s / 57.7963 s
agent0:                 episode reward: -0.5659,                 loss: nan
agent1:                 episode reward: 0.5659,                 loss: 0.2690
Episode: 5041/10000 (50.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2754s / 58.0717 s
agent0:                 episode reward: -0.6076,                 loss: nan
agent1:                 episode reward: 0.6076,                 loss: 0.2652
Episode: 5061/10000 (50.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2794s / 58.3511 s
agent0:                 episode reward: -0.4382,                 loss: nan
agent1:                 episode reward: 0.4382,                 loss: 0.2677
Episode: 5081/10000 (50.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2686s / 58.6197 s
agent0:                 episode reward: -0.7866,                 loss: nan
agent1:                 episode reward: 0.7866,                 loss: 0.2681
Episode: 5101/10000 (51.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2700s / 58.8896 s
agent0:                 episode reward: -0.2771,                 loss: nan
agent1:                 episode reward: 0.2771,                 loss: 0.2669
Episode: 5121/10000 (51.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2671s / 59.1568 s
agent0:                 episode reward: -0.3811,                 loss: nan
agent1:                 episode reward: 0.3811,                 loss: 0.2668
Episode: 5141/10000 (51.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2711s / 59.4279 s
agent0:                 episode reward: -0.5614,                 loss: nan
agent1:                 episode reward: 0.5614,                 loss: 0.2700
Episode: 5161/10000 (51.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2693s / 59.6972 s
agent0:                 episode reward: -0.8631,                 loss: nan
agent1:                 episode reward: 0.8631,                 loss: 0.2691
Episode: 5181/10000 (51.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2682s / 59.9654 s
agent0:                 episode reward: -0.7355,                 loss: nan
agent1:                 episode reward: 0.7355,                 loss: 0.2696
Episode: 5201/10000 (52.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2727s / 60.2381 s
agent0:                 episode reward: -0.9534,                 loss: nan
agent1:                 episode reward: 0.9534,                 loss: 0.2701
Episode: 5221/10000 (52.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2720s / 60.5101 s
agent0:                 episode reward: -0.3883,                 loss: nan
agent1:                 episode reward: 0.3883,                 loss: 0.2683
Episode: 5241/10000 (52.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2713s / 60.7814 s
agent0:                 episode reward: -0.8744,                 loss: nan
agent1:                 episode reward: 0.8744,                 loss: 0.2701
Episode: 5261/10000 (52.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2727s / 61.0541 s
agent0:                 episode reward: -0.6981,                 loss: nan
agent1:                 episode reward: 0.6981,                 loss: 0.2733
Episode: 5281/10000 (52.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2795s / 61.3335 s
agent0:                 episode reward: -0.7094,                 loss: nan
agent1:                 episode reward: 0.7094,                 loss: 0.2663
Episode: 5301/10000 (53.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2672s / 61.6007 s
agent0:                 episode reward: -0.8489,                 loss: nan
agent1:                 episode reward: 0.8489,                 loss: 0.2696
Episode: 5321/10000 (53.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2691s / 61.8698 s
agent0:                 episode reward: -1.0621,                 loss: nan
agent1:                 episode reward: 1.0621,                 loss: 0.2696
Episode: 5341/10000 (53.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2675s / 62.1373 s
agent0:                 episode reward: -0.8922,                 loss: nan
agent1:                 episode reward: 0.8922,                 loss: 0.2692
Episode: 5361/10000 (53.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2705s / 62.4078 s
agent0:                 episode reward: -0.4351,                 loss: nan
agent1:                 episode reward: 0.4351,                 loss: 0.2692
Episode: 5381/10000 (53.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2696s / 62.6774 s
agent0:                 episode reward: -1.0168,                 loss: nan
agent1:                 episode reward: 1.0168,                 loss: 0.2708
Episode: 5401/10000 (54.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3223s / 62.9997 s
agent0:                 episode reward: -0.9446,                 loss: nan
agent1:                 episode reward: 0.9446,                 loss: 0.2699
Episode: 5421/10000 (54.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2721s / 63.2718 s
agent0:                 episode reward: -0.9611,                 loss: nan
agent1:                 episode reward: 0.9611,                 loss: 0.2717
Episode: 5441/10000 (54.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2722s / 63.5441 s
agent0:                 episode reward: -0.9963,                 loss: nan
agent1:                 episode reward: 0.9963,                 loss: 0.2690
Episode: 5461/10000 (54.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2709s / 63.8150 s
agent0:                 episode reward: -1.0164,                 loss: nan
agent1:                 episode reward: 1.0164,                 loss: 0.2681
Episode: 5481/10000 (54.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2799s / 64.0948 s
agent0:                 episode reward: -0.9859,                 loss: nan
agent1:                 episode reward: 0.9859,                 loss: 0.2703
Episode: 5501/10000 (55.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3024s / 64.3973 s
agent0:                 episode reward: -0.5506,                 loss: nan
agent1:                 episode reward: 0.5506,                 loss: 0.2696
Episode: 5521/10000 (55.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2771s / 64.6744 s
agent0:                 episode reward: -0.9160,                 loss: nan
agent1:                 episode reward: 0.9160,                 loss: 0.2673
Episode: 5541/10000 (55.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2788s / 64.9531 s
agent0:                 episode reward: -0.5788,                 loss: nan
agent1:                 episode reward: 0.5788,                 loss: 0.2660
Episode: 5561/10000 (55.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2771s / 65.2302 s
agent0:                 episode reward: -0.5983,                 loss: nan
agent1:                 episode reward: 0.5983,                 loss: 0.2728
Episode: 5581/10000 (55.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2752s / 65.5055 s
agent0:                 episode reward: -0.8659,                 loss: nan
agent1:                 episode reward: 0.8659,                 loss: 0.2684
Episode: 5601/10000 (56.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2763s / 65.7818 s
agent0:                 episode reward: -0.2792,                 loss: nan
agent1:                 episode reward: 0.2792,                 loss: 0.2718
Episode: 5621/10000 (56.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2740s / 66.0558 s
agent0:                 episode reward: -0.7251,                 loss: nan
agent1:                 episode reward: 0.7251,                 loss: 0.2708
Episode: 5641/10000 (56.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2768s / 66.3326 s
agent0:                 episode reward: -0.5339,                 loss: nan
agent1:                 episode reward: 0.5339,                 loss: 0.2671
Episode: 5661/10000 (56.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2760s / 66.6086 s
agent0:                 episode reward: -0.6605,                 loss: nan
agent1:                 episode reward: 0.6605,                 loss: 0.2689
Episode: 5681/10000 (56.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2787s / 66.8873 s
agent0:                 episode reward: -0.5918,                 loss: nan
agent1:                 episode reward: 0.5918,                 loss: 0.2697
Episode: 5701/10000 (57.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2854s / 67.1727 s
agent0:                 episode reward: -0.7876,                 loss: nan
agent1:                 episode reward: 0.7876,                 loss: 0.2689
Episode: 5721/10000 (57.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2903s / 67.4630 s
agent0:                 episode reward: -0.6171,                 loss: nan
agent1:                 episode reward: 0.6171,                 loss: 0.2713
Episode: 5741/10000 (57.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2790s / 67.7420 s
agent0:                 episode reward: -0.5977,                 loss: nan
agent1:                 episode reward: 0.5977,                 loss: 0.2687
Episode: 5761/10000 (57.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2744s / 68.0163 s
agent0:                 episode reward: -0.6723,                 loss: nan
agent1:                 episode reward: 0.6723,                 loss: 0.2688
Episode: 5781/10000 (57.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2795s / 68.2958 s
agent0:                 episode reward: -0.9704,                 loss: nan
agent1:                 episode reward: 0.9704,                 loss: 0.2679
Episode: 5801/10000 (58.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2798s / 68.5757 s
agent0:                 episode reward: -0.9827,                 loss: nan
agent1:                 episode reward: 0.9827,                 loss: 0.2690
Episode: 5821/10000 (58.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2822s / 68.8579 s
agent0:                 episode reward: -0.5448,                 loss: nan
agent1:                 episode reward: 0.5448,                 loss: 0.2684
Episode: 5841/10000 (58.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2824s / 69.1403 s
agent0:                 episode reward: -0.2416,                 loss: nan
agent1:                 episode reward: 0.2416,                 loss: 0.2681
Episode: 5861/10000 (58.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2799s / 69.4203 s
agent0:                 episode reward: -0.7288,                 loss: nan
agent1:                 episode reward: 0.7288,                 loss: 0.2710
Episode: 5881/10000 (58.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2803s / 69.7006 s
agent0:                 episode reward: -1.1297,                 loss: nan
agent1:                 episode reward: 1.1297,                 loss: 0.2694
Episode: 5901/10000 (59.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2778s / 69.9784 s
agent0:                 episode reward: -1.0681,                 loss: nan
agent1:                 episode reward: 1.0681,                 loss: 0.2660
Episode: 5921/10000 (59.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3098s / 70.2882 s
agent0:                 episode reward: -0.8638,                 loss: nan
agent1:                 episode reward: 0.8638,                 loss: 0.2669
Episode: 5941/10000 (59.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2820s / 70.5702 s
agent0:                 episode reward: -0.7310,                 loss: nan
agent1:                 episode reward: 0.7310,                 loss: 0.2692
Episode: 5961/10000 (59.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2831s / 70.8532 s
agent0:                 episode reward: -0.7404,                 loss: nan
agent1:                 episode reward: 0.7404,                 loss: 0.2680
Episode: 5981/10000 (59.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2792s / 71.1324 s
agent0:                 episode reward: -0.4478,                 loss: nan
agent1:                 episode reward: 0.4478,                 loss: 0.2677
Episode: 6001/10000 (60.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2802s / 71.4127 s
agent0:                 episode reward: -0.5658,                 loss: nan
agent1:                 episode reward: 0.5658,                 loss: 0.2687
Episode: 6021/10000 (60.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2810s / 71.6937 s
agent0:                 episode reward: -0.5226,                 loss: nan
agent1:                 episode reward: 0.5226,                 loss: 0.2665
Episode: 6041/10000 (60.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2809s / 71.9746 s
agent0:                 episode reward: -1.1014,                 loss: nan
agent1:                 episode reward: 1.1014,                 loss: 0.2683
Episode: 6061/10000 (60.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2798s / 72.2544 s
agent0:                 episode reward: -0.5151,                 loss: nan
agent1:                 episode reward: 0.5151,                 loss: 0.2706
Episode: 6081/10000 (60.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2795s / 72.5339 s
agent0:                 episode reward: -0.1055,                 loss: nan
agent1:                 episode reward: 0.1055,                 loss: 0.2712
Episode: 6101/10000 (61.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2997s / 72.8336 s
agent0:                 episode reward: -0.7851,                 loss: nan
agent1:                 episode reward: 0.7851,                 loss: 0.2683
Episode: 6121/10000 (61.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3350s / 73.1686 s
agent0:                 episode reward: -0.9889,                 loss: nan
agent1:                 episode reward: 0.9889,                 loss: 0.2702
Episode: 6141/10000 (61.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2960s / 73.4646 s
agent0:                 episode reward: -0.7288,                 loss: nan
agent1:                 episode reward: 0.7288,                 loss: 0.2664
Episode: 6161/10000 (61.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2893s / 73.7539 s
agent0:                 episode reward: -1.1518,                 loss: nan
agent1:                 episode reward: 1.1518,                 loss: 0.2670
Episode: 6181/10000 (61.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2802s / 74.0341 s
agent0:                 episode reward: -0.8166,                 loss: nan
agent1:                 episode reward: 0.8166,                 loss: 0.2683
Episode: 6201/10000 (62.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2826s / 74.3167 s
agent0:                 episode reward: -0.8458,                 loss: nan
agent1:                 episode reward: 0.8458,                 loss: 0.2679
Episode: 6221/10000 (62.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2839s / 74.6006 s
agent0:                 episode reward: -0.6866,                 loss: nan
agent1:                 episode reward: 0.6866,                 loss: 0.2705
Episode: 6241/10000 (62.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2889s / 74.8894 s
agent0:                 episode reward: -0.7296,                 loss: nan
agent1:                 episode reward: 0.7296,                 loss: 0.2707
Episode: 6261/10000 (62.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2816s / 75.1711 s
agent0:                 episode reward: -1.1513,                 loss: nan
agent1:                 episode reward: 1.1513,                 loss: 0.2698
Episode: 6281/10000 (62.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2859s / 75.4569 s
agent0:                 episode reward: -1.0136,                 loss: nan
agent1:                 episode reward: 1.0136,                 loss: 0.2733
Episode: 6301/10000 (63.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2873s / 75.7442 s
agent0:                 episode reward: -0.9248,                 loss: nan
agent1:                 episode reward: 0.9248,                 loss: 0.2686
Episode: 6321/10000 (63.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2831s / 76.0273 s
agent0:                 episode reward: -0.9127,                 loss: nan
agent1:                 episode reward: 0.9127,                 loss: 0.2697
Episode: 6341/10000 (63.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2972s / 76.3245 s
agent0:                 episode reward: -1.0630,                 loss: nan
agent1:                 episode reward: 1.0630,                 loss: 0.2716
Episode: 6361/10000 (63.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2875s / 76.6120 s
agent0:                 episode reward: -0.8935,                 loss: nan
agent1:                 episode reward: 0.8935,                 loss: 0.2683
Episode: 6381/10000 (63.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2889s / 76.9010 s
agent0:                 episode reward: -0.9121,                 loss: nan
agent1:                 episode reward: 0.9121,                 loss: 0.2671
Episode: 6401/10000 (64.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2848s / 77.1858 s
agent0:                 episode reward: -0.6487,                 loss: nan
agent1:                 episode reward: 0.6487,                 loss: 0.2688
Episode: 6421/10000 (64.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3960s / 77.5818 s
agent0:                 episode reward: -0.4496,                 loss: nan
agent1:                 episode reward: 0.4496,                 loss: 0.2691
Episode: 6441/10000 (64.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2841s / 77.8659 s
agent0:                 episode reward: -0.7579,                 loss: nan
agent1:                 episode reward: 0.7579,                 loss: 0.2737
Episode: 6461/10000 (64.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2864s / 78.1523 s
agent0:                 episode reward: -0.5973,                 loss: nan
agent1:                 episode reward: 0.5973,                 loss: 0.2708
Episode: 6481/10000 (64.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2866s / 78.4389 s
agent0:                 episode reward: -0.8557,                 loss: nan
agent1:                 episode reward: 0.8557,                 loss: 0.2697
Episode: 6501/10000 (65.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2877s / 78.7265 s
agent0:                 episode reward: -0.6167,                 loss: nan
agent1:                 episode reward: 0.6167,                 loss: 0.2677
Episode: 6521/10000 (65.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3154s / 79.0419 s
agent0:                 episode reward: -0.7875,                 loss: nan
agent1:                 episode reward: 0.7875,                 loss: 0.2709
Episode: 6541/10000 (65.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2955s / 79.3375 s
agent0:                 episode reward: -0.9635,                 loss: nan
agent1:                 episode reward: 0.9635,                 loss: 0.2679
Episode: 6561/10000 (65.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2889s / 79.6264 s
agent0:                 episode reward: -0.8410,                 loss: nan
agent1:                 episode reward: 0.8410,                 loss: 0.2690
Episode: 6581/10000 (65.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2859s / 79.9123 s
agent0:                 episode reward: -0.6662,                 loss: nan
agent1:                 episode reward: 0.6662,                 loss: 0.2711
Episode: 6601/10000 (66.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2881s / 80.2004 s
agent0:                 episode reward: -0.7713,                 loss: nan
agent1:                 episode reward: 0.7713,                 loss: 0.2702
Episode: 6621/10000 (66.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2906s / 80.4910 s
agent0:                 episode reward: -0.6649,                 loss: nan
agent1:                 episode reward: 0.6649,                 loss: 0.2648
Episode: 6641/10000 (66.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2895s / 80.7805 s
agent0:                 episode reward: -0.9641,                 loss: nan
agent1:                 episode reward: 0.9641,                 loss: 0.2685
Episode: 6661/10000 (66.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3063s / 81.0868 s
agent0:                 episode reward: -0.8371,                 loss: nan
agent1:                 episode reward: 0.8371,                 loss: 0.2681
Episode: 6681/10000 (66.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2936s / 81.3804 s
agent0:                 episode reward: -0.8061,                 loss: nan
agent1:                 episode reward: 0.8061,                 loss: 0.2690
Episode: 6701/10000 (67.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2860s / 81.6664 s
agent0:                 episode reward: -0.6203,                 loss: nan
agent1:                 episode reward: 0.6203,                 loss: 0.2696
Episode: 6721/10000 (67.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2891s / 81.9555 s
agent0:                 episode reward: -0.6824,                 loss: nan
agent1:                 episode reward: 0.6824,                 loss: 0.2686
Episode: 6741/10000 (67.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2887s / 82.2442 s
agent0:                 episode reward: -1.0869,                 loss: nan
agent1:                 episode reward: 1.0869,                 loss: 0.2680
Episode: 6761/10000 (67.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2892s / 82.5333 s
agent0:                 episode reward: -0.6527,                 loss: nan
agent1:                 episode reward: 0.6527,                 loss: 0.2676
Episode: 6781/10000 (67.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2937s / 82.8270 s
agent0:                 episode reward: -0.9721,                 loss: nan
agent1:                 episode reward: 0.9721,                 loss: 0.2679
Episode: 6801/10000 (68.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2902s / 83.1173 s
agent0:                 episode reward: -0.5998,                 loss: nan
agent1:                 episode reward: 0.5998,                 loss: 0.2685
Episode: 6821/10000 (68.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3606s / 83.4779 s
agent0:                 episode reward: -1.0115,                 loss: nan
agent1:                 episode reward: 1.0115,                 loss: 0.2695
Episode: 6841/10000 (68.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2922s / 83.7701 s
agent0:                 episode reward: -0.9324,                 loss: nan
agent1:                 episode reward: 0.9324,                 loss: 0.2687
Episode: 6861/10000 (68.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2895s / 84.0595 s
agent0:                 episode reward: -0.6258,                 loss: nan
agent1:                 episode reward: 0.6258,                 loss: 0.2661
Episode: 6881/10000 (68.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2927s / 84.3522 s
agent0:                 episode reward: -0.8265,                 loss: nan
agent1:                 episode reward: 0.8265,                 loss: 0.2686
Episode: 6901/10000 (69.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2937s / 84.6459 s
agent0:                 episode reward: -0.8415,                 loss: nan
agent1:                 episode reward: 0.8415,                 loss: 0.2630
Episode: 6921/10000 (69.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2954s / 84.9413 s
agent0:                 episode reward: -0.7512,                 loss: nan
agent1:                 episode reward: 0.7512,                 loss: 0.2665
Episode: 6941/10000 (69.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3036s / 85.2449 s
agent0:                 episode reward: -0.7358,                 loss: nan
agent1:                 episode reward: 0.7358,                 loss: 0.2643
Episode: 6961/10000 (69.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2939s / 85.5388 s
agent0:                 episode reward: -0.8944,                 loss: nan
agent1:                 episode reward: 0.8944,                 loss: 0.2659
Episode: 6981/10000 (69.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2947s / 85.8335 s
agent0:                 episode reward: -0.8727,                 loss: nan
agent1:                 episode reward: 0.8727,                 loss: 0.2685
Episode: 7001/10000 (70.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2951s / 86.1286 s
agent0:                 episode reward: -0.7930,                 loss: nan
agent1:                 episode reward: 0.7930,                 loss: 0.2655
Episode: 7021/10000 (70.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2975s / 86.4261 s
agent0:                 episode reward: -1.0318,                 loss: nan
agent1:                 episode reward: 1.0318,                 loss: 0.2672
Episode: 7041/10000 (70.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2986s / 86.7247 s
agent0:                 episode reward: -0.9054,                 loss: nan
agent1:                 episode reward: 0.9054,                 loss: 0.2652
Episode: 7061/10000 (70.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2952s / 87.0199 s
agent0:                 episode reward: -0.5711,                 loss: nan
agent1:                 episode reward: 0.5711,                 loss: 0.2644
Episode: 7081/10000 (70.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2972s / 87.3171 s
agent0:                 episode reward: -0.7370,                 loss: nan
agent1:                 episode reward: 0.7370,                 loss: 0.2660
Episode: 7101/10000 (71.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3044s / 87.6215 s
agent0:                 episode reward: -0.5734,                 loss: nan
agent1:                 episode reward: 0.5734,                 loss: 0.2633
Episode: 7121/10000 (71.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2971s / 87.9186 s
agent0:                 episode reward: -0.5570,                 loss: nan
agent1:                 episode reward: 0.5570,                 loss: 0.2694
Episode: 7141/10000 (71.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3051s / 88.2237 s
agent0:                 episode reward: -0.9257,                 loss: nan
agent1:                 episode reward: 0.9257,                 loss: 0.2643
Episode: 7161/10000 (71.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3009s / 88.5246 s
agent0:                 episode reward: -0.5171,                 loss: nan
agent1:                 episode reward: 0.5171,                 loss: 0.2681
Episode: 7181/10000 (71.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2997s / 88.8243 s
agent0:                 episode reward: -1.0133,                 loss: nan
agent1:                 episode reward: 1.0133,                 loss: 0.2644
Episode: 7201/10000 (72.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2941s / 89.1184 s
agent0:                 episode reward: -0.9013,                 loss: nan
agent1:                 episode reward: 0.9013,                 loss: 0.2670
Episode: 7221/10000 (72.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3198s / 89.4382 s
agent0:                 episode reward: -1.3142,                 loss: nan
agent1:                 episode reward: 1.3142,                 loss: 0.2702
Episode: 7241/10000 (72.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2981s / 89.7364 s
agent0:                 episode reward: -0.8675,                 loss: nan
agent1:                 episode reward: 0.8675,                 loss: 0.2722
Episode: 7261/10000 (72.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2934s / 90.0298 s
agent0:                 episode reward: -1.2969,                 loss: nan
agent1:                 episode reward: 1.2969,                 loss: 0.2711
Episode: 7281/10000 (72.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2980s / 90.3278 s
agent0:                 episode reward: -0.9834,                 loss: nan
agent1:                 episode reward: 0.9834,                 loss: 0.2734
Episode: 7301/10000 (73.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2977s / 90.6255 s
agent0:                 episode reward: -0.9741,                 loss: nan
agent1:                 episode reward: 0.9741,                 loss: 0.2744
Episode: 7321/10000 (73.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2970s / 90.9224 s
agent0:                 episode reward: -0.7460,                 loss: nan
agent1:                 episode reward: 0.7460,                 loss: 0.2736
Episode: 7341/10000 (73.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2989s / 91.2213 s
agent0:                 episode reward: -0.9839,                 loss: nan
agent1:                 episode reward: 0.9839,                 loss: 0.2716
Episode: 7361/10000 (73.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2951s / 91.5164 s
agent0:                 episode reward: -0.6627,                 loss: nan
agent1:                 episode reward: 0.6627,                 loss: 0.2743
Episode: 7381/10000 (73.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2966s / 91.8131 s
agent0:                 episode reward: -0.8426,                 loss: nan
agent1:                 episode reward: 0.8426,                 loss: 0.2709
Episode: 7401/10000 (74.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2964s / 92.1095 s
agent0:                 episode reward: -0.6304,                 loss: nan
agent1:                 episode reward: 0.6304,                 loss: 0.2728
Episode: 7421/10000 (74.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2977s / 92.4072 s
agent0:                 episode reward: -0.4458,                 loss: nan
agent1:                 episode reward: 0.4458,                 loss: 0.2700
Episode: 7441/10000 (74.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3049s / 92.7121 s
agent0:                 episode reward: -1.0436,                 loss: nan
agent1:                 episode reward: 1.0436,                 loss: 0.2717
Episode: 7461/10000 (74.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3015s / 93.0136 s
agent0:                 episode reward: -0.8136,                 loss: nan
agent1:                 episode reward: 0.8136,                 loss: 0.2717
Episode: 7481/10000 (74.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2988s / 93.3124 s
agent0:                 episode reward: -0.6211,                 loss: nan
agent1:                 episode reward: 0.6211,                 loss: 0.2684
Episode: 7501/10000 (75.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3517s / 93.6641 s
agent0:                 episode reward: -0.7133,                 loss: nan
agent1:                 episode reward: 0.7133,                 loss: 0.2730
Episode: 7521/10000 (75.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3051s / 93.9692 s
agent0:                 episode reward: -1.1063,                 loss: nan
agent1:                 episode reward: 1.1063,                 loss: 0.2716
Episode: 7541/10000 (75.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3317s / 94.3009 s
agent0:                 episode reward: -0.4348,                 loss: nan
agent1:                 episode reward: 0.4348,                 loss: 0.2716
Episode: 7561/10000 (75.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3011s / 94.6020 s
agent0:                 episode reward: -0.8046,                 loss: nan
agent1:                 episode reward: 0.8046,                 loss: 0.2717
Episode: 7581/10000 (75.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3036s / 94.9056 s
agent0:                 episode reward: -0.9774,                 loss: nan
agent1:                 episode reward: 0.9774,                 loss: 0.2752
Episode: 7601/10000 (76.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3044s / 95.2100 s
agent0:                 episode reward: -0.9584,                 loss: nan
agent1:                 episode reward: 0.9584,                 loss: 0.2753
Episode: 7621/10000 (76.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3025s / 95.5125 s
agent0:                 episode reward: -1.0113,                 loss: nan
agent1:                 episode reward: 1.0113,                 loss: 0.2734
Episode: 7641/10000 (76.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3018s / 95.8143 s
agent0:                 episode reward: -0.8018,                 loss: nan
agent1:                 episode reward: 0.8018,                 loss: 0.2730
Episode: 7661/10000 (76.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3024s / 96.1167 s
agent0:                 episode reward: -0.7956,                 loss: nan
agent1:                 episode reward: 0.7956,                 loss: 0.2724
Episode: 7681/10000 (76.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3031s / 96.4198 s
agent0:                 episode reward: -0.7170,                 loss: nan
agent1:                 episode reward: 0.7170,                 loss: 0.2740
Episode: 7701/10000 (77.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3068s / 96.7266 s
agent0:                 episode reward: -0.6403,                 loss: nan
agent1:                 episode reward: 0.6403,                 loss: 0.2749
Episode: 7721/10000 (77.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3039s / 97.0304 s
agent0:                 episode reward: -0.7263,                 loss: nan
agent1:                 episode reward: 0.7263,                 loss: 0.2690
Episode: 7741/10000 (77.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3147s / 97.3452 s
agent0:                 episode reward: -0.9828,                 loss: nan
agent1:                 episode reward: 0.9828,                 loss: 0.2744
Episode: 7761/10000 (77.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3274s / 97.6726 s
agent0:                 episode reward: -0.7664,                 loss: nan
agent1:                 episode reward: 0.7664,                 loss: 0.2724
Episode: 7781/10000 (77.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3103s / 97.9829 s
agent0:                 episode reward: -0.7653,                 loss: nan
agent1:                 episode reward: 0.7653,                 loss: 0.2729
Episode: 7801/10000 (78.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3039s / 98.2868 s
agent0:                 episode reward: -0.8159,                 loss: nan
agent1:                 episode reward: 0.8159,                 loss: 0.2725
Episode: 7821/10000 (78.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3039s / 98.5908 s
agent0:                 episode reward: -0.8634,                 loss: nan
agent1:                 episode reward: 0.8634,                 loss: 0.2732
Episode: 7841/10000 (78.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3046s / 98.8954 s
agent0:                 episode reward: -0.9063,                 loss: nan
agent1:                 episode reward: 0.9063,                 loss: 0.2694
Episode: 7861/10000 (78.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3096s / 99.2049 s
agent0:                 episode reward: -0.8112,                 loss: nan
agent1:                 episode reward: 0.8112,                 loss: 0.2733
Episode: 7881/10000 (78.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3052s / 99.5101 s
agent0:                 episode reward: -0.8481,                 loss: nan
agent1:                 episode reward: 0.8481,                 loss: 0.2722
Episode: 7901/10000 (79.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3055s / 99.8156 s
agent0:                 episode reward: -1.0393,                 loss: nan
agent1:                 episode reward: 1.0393,                 loss: 0.2689
Episode: 7921/10000 (79.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3053s / 100.1209 s
agent0:                 episode reward: -0.7793,                 loss: nan
agent1:                 episode reward: 0.7793,                 loss: 0.2709
Episode: 7941/10000 (79.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3176s / 100.4385 s
agent0:                 episode reward: -0.7879,                 loss: nan
agent1:                 episode reward: 0.7879,                 loss: 0.2696
Episode: 7961/10000 (79.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3086s / 100.7471 s
agent0:                 episode reward: -0.9836,                 loss: nan
agent1:                 episode reward: 0.9836,                 loss: 0.2677
Episode: 7981/10000 (79.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3060s / 101.0531 s
agent0:                 episode reward: -1.0547,                 loss: nan
agent1:                 episode reward: 1.0547,                 loss: 0.2694
Episode: 8001/10000 (80.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3079s / 101.3610 s
agent0:                 episode reward: -0.7013,                 loss: nan
agent1:                 episode reward: 0.7013,                 loss: 0.2718
Episode: 8021/10000 (80.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3071s / 101.6680 s
agent0:                 episode reward: -1.1225,                 loss: nan
agent1:                 episode reward: 1.1225,                 loss: 0.2717
Episode: 8041/10000 (80.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3127s / 101.9807 s
agent0:                 episode reward: -0.8109,                 loss: nan
agent1:                 episode reward: 0.8109,                 loss: 0.2686
Episode: 8061/10000 (80.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3078s / 102.2885 s
agent0:                 episode reward: -0.5219,                 loss: nan
agent1:                 episode reward: 0.5219,                 loss: 0.2691
Episode: 8081/10000 (80.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3096s / 102.5981 s
agent0:                 episode reward: -0.8311,                 loss: nan
agent1:                 episode reward: 0.8311,                 loss: 0.2689
Episode: 8101/10000 (81.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3073s / 102.9053 s
agent0:                 episode reward: -0.8649,                 loss: nan
agent1:                 episode reward: 0.8649,                 loss: 0.2702
Episode: 8121/10000 (81.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3162s / 103.2215 s
agent0:                 episode reward: -0.9085,                 loss: nan
agent1:                 episode reward: 0.9085,                 loss: 0.2714
Episode: 8141/10000 (81.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3147s / 103.5362 s
agent0:                 episode reward: -0.3623,                 loss: nan
agent1:                 episode reward: 0.3623,                 loss: 0.2721
Episode: 8161/10000 (81.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3599s / 103.8961 s
agent0:                 episode reward: -0.9954,                 loss: nan
agent1:                 episode reward: 0.9954,                 loss: 0.2687
Episode: 8181/10000 (81.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3124s / 104.2085 s
agent0:                 episode reward: -0.4842,                 loss: nan
agent1:                 episode reward: 0.4842,                 loss: 0.2709
Episode: 8201/10000 (82.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3113s / 104.5198 s
agent0:                 episode reward: -0.6653,                 loss: nan
agent1:                 episode reward: 0.6653,                 loss: 0.2703
Episode: 8221/10000 (82.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3152s / 104.8351 s
agent0:                 episode reward: -0.6194,                 loss: nan
agent1:                 episode reward: 0.6194,                 loss: 0.2758
Episode: 8241/10000 (82.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3116s / 105.1467 s
agent0:                 episode reward: -0.6351,                 loss: nan
agent1:                 episode reward: 0.6351,                 loss: 0.2739
Episode: 8261/10000 (82.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3094s / 105.4561 s
agent0:                 episode reward: -0.9637,                 loss: nan
agent1:                 episode reward: 0.9637,                 loss: 0.2756
Episode: 8281/10000 (82.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3088s / 105.7648 s
agent0:                 episode reward: -0.9881,                 loss: nan
agent1:                 episode reward: 0.9881,                 loss: 0.2762
Episode: 8301/10000 (83.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3291s / 106.0939 s
agent0:                 episode reward: -0.7616,                 loss: nan
agent1:                 episode reward: 0.7616,                 loss: 0.2750
Episode: 8321/10000 (83.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3243s / 106.4182 s
agent0:                 episode reward: -0.7358,                 loss: nan
agent1:                 episode reward: 0.7358,                 loss: 0.2749
Episode: 8341/10000 (83.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3078s / 106.7261 s
agent0:                 episode reward: -1.0275,                 loss: nan
agent1:                 episode reward: 1.0275,                 loss: 0.2749
Episode: 8361/10000 (83.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3118s / 107.0378 s
agent0:                 episode reward: -0.7687,                 loss: nan
agent1:                 episode reward: 0.7687,                 loss: 0.2744
Episode: 8381/10000 (83.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3103s / 107.3481 s
agent0:                 episode reward: -0.7968,                 loss: nan
agent1:                 episode reward: 0.7968,                 loss: 0.2750
Episode: 8401/10000 (84.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3113s / 107.6593 s
agent0:                 episode reward: -1.1165,                 loss: nan
agent1:                 episode reward: 1.1165,                 loss: 0.2729
Episode: 8421/10000 (84.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3201s / 107.9795 s
agent0:                 episode reward: -1.0808,                 loss: nan
agent1:                 episode reward: 1.0808,                 loss: 0.2762
Episode: 8441/10000 (84.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3148s / 108.2943 s
agent0:                 episode reward: -1.0083,                 loss: nan
agent1:                 episode reward: 1.0083,                 loss: 0.2722
Episode: 8461/10000 (84.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3108s / 108.6051 s
agent0:                 episode reward: -0.9898,                 loss: nan
agent1:                 episode reward: 0.9898,                 loss: 0.2751
Episode: 8481/10000 (84.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3150s / 108.9200 s
agent0:                 episode reward: -0.4908,                 loss: nan
agent1:                 episode reward: 0.4908,                 loss: 0.2729
Episode: 8501/10000 (85.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3137s / 109.2338 s
agent0:                 episode reward: -0.7385,                 loss: nan
agent1:                 episode reward: 0.7385,                 loss: 0.2753
Episode: 8521/10000 (85.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3199s / 109.5536 s
agent0:                 episode reward: -0.8376,                 loss: nan
agent1:                 episode reward: 0.8376,                 loss: 0.2787
Episode: 8541/10000 (85.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3104s / 109.8640 s
agent0:                 episode reward: -1.0914,                 loss: nan
agent1:                 episode reward: 1.0914,                 loss: 0.2722
Episode: 8561/10000 (85.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3104s / 110.1744 s
agent0:                 episode reward: -1.0216,                 loss: nan
agent1:                 episode reward: 1.0216,                 loss: 0.2701
Episode: 8581/10000 (85.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3116s / 110.4860 s
agent0:                 episode reward: -0.9832,                 loss: nan
agent1:                 episode reward: 0.9832,                 loss: 0.2660
Episode: 8601/10000 (86.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3169s / 110.8030 s
agent0:                 episode reward: -0.5988,                 loss: nan
agent1:                 episode reward: 0.5988,                 loss: 0.2703
Episode: 8621/10000 (86.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3133s / 111.1163 s
agent0:                 episode reward: -0.9704,                 loss: nan
agent1:                 episode reward: 0.9704,                 loss: 0.2645
Episode: 8641/10000 (86.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3176s / 111.4339 s
agent0:                 episode reward: -0.3022,                 loss: nan
agent1:                 episode reward: 0.3022,                 loss: 0.2675
Episode: 8661/10000 (86.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3187s / 111.7526 s
agent0:                 episode reward: -0.9712,                 loss: nan
agent1:                 episode reward: 0.9712,                 loss: 0.2689
Episode: 8681/10000 (86.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3135s / 112.0660 s
agent0:                 episode reward: -0.4291,                 loss: nan
agent1:                 episode reward: 0.4291,                 loss: 0.2645
Episode: 8701/10000 (87.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3169s / 112.3830 s
agent0:                 episode reward: -0.5841,                 loss: nan
agent1:                 episode reward: 0.5841,                 loss: 0.2680
Episode: 8721/10000 (87.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3138s / 112.6968 s
agent0:                 episode reward: -0.9125,                 loss: nan
agent1:                 episode reward: 0.9125,                 loss: 0.2702
Episode: 8741/10000 (87.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3166s / 113.0133 s
agent0:                 episode reward: -0.7150,                 loss: nan
agent1:                 episode reward: 0.7150,                 loss: 0.2672
Episode: 8761/10000 (87.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3180s / 113.3313 s
agent0:                 episode reward: -0.9519,                 loss: nan
agent1:                 episode reward: 0.9519,                 loss: 0.2665
Episode: 8781/10000 (87.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3135s / 113.6448 s
agent0:                 episode reward: -1.0909,                 loss: nan
agent1:                 episode reward: 1.0909,                 loss: 0.2646
Episode: 8801/10000 (88.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3394s / 113.9841 s
agent0:                 episode reward: -0.8896,                 loss: nan
agent1:                 episode reward: 0.8896,                 loss: 0.2659
Episode: 8821/10000 (88.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3735s / 114.3577 s
agent0:                 episode reward: -0.9729,                 loss: nan
agent1:                 episode reward: 0.9729,                 loss: 0.2684
Episode: 8841/10000 (88.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3151s / 114.6728 s
agent0:                 episode reward: -0.8294,                 loss: nan
agent1:                 episode reward: 0.8294,                 loss: 0.2690
Episode: 8861/10000 (88.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3161s / 114.9889 s
agent0:                 episode reward: -0.6448,                 loss: nan
agent1:                 episode reward: 0.6448,                 loss: 0.2671
Episode: 8881/10000 (88.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3439s / 115.3328 s
agent0:                 episode reward: -0.7468,                 loss: nan
agent1:                 episode reward: 0.7468,                 loss: 0.2630
Episode: 8901/10000 (89.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3192s / 115.6520 s
agent0:                 episode reward: -0.7766,                 loss: nan
agent1:                 episode reward: 0.7766,                 loss: 0.2684
Episode: 8921/10000 (89.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3164s / 115.9684 s
agent0:                 episode reward: -0.9584,                 loss: nan
agent1:                 episode reward: 0.9584,                 loss: 0.2737
Episode: 8941/10000 (89.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3215s / 116.2899 s
agent0:                 episode reward: -0.6381,                 loss: nan
agent1:                 episode reward: 0.6381,                 loss: 0.2694
Episode: 8961/10000 (89.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3151s / 116.6050 s
agent0:                 episode reward: -1.1782,                 loss: nan
agent1:                 episode reward: 1.1782,                 loss: 0.2714
Episode: 8981/10000 (89.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3206s / 116.9256 s
agent0:                 episode reward: -0.6508,                 loss: nan
agent1:                 episode reward: 0.6508,                 loss: 0.2694
Episode: 9001/10000 (90.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3245s / 117.2501 s
agent0:                 episode reward: -0.8077,                 loss: nan
agent1:                 episode reward: 0.8077,                 loss: 0.2716
Episode: 9021/10000 (90.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3201s / 117.5702 s
agent0:                 episode reward: -0.9468,                 loss: nan
agent1:                 episode reward: 0.9468,                 loss: 0.2733
Episode: 9041/10000 (90.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3236s / 117.8938 s
agent0:                 episode reward: -0.7286,                 loss: nan
agent1:                 episode reward: 0.7286,                 loss: 0.2705
Episode: 9061/10000 (90.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3255s / 118.2193 s
agent0:                 episode reward: -0.9742,                 loss: nan
agent1:                 episode reward: 0.9742,                 loss: 0.2687
Episode: 9081/10000 (90.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3286s / 118.5479 s
agent0:                 episode reward: -0.8435,                 loss: nan
agent1:                 episode reward: 0.8435,                 loss: 0.2751
Episode: 9101/10000 (91.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3238s / 118.8717 s
agent0:                 episode reward: -0.7228,                 loss: nan
agent1:                 episode reward: 0.7228,                 loss: 0.2687
Episode: 9121/10000 (91.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3204s / 119.1921 s
agent0:                 episode reward: -0.7921,                 loss: nan
agent1:                 episode reward: 0.7921,                 loss: 0.2699
Episode: 9141/10000 (91.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3241s / 119.5162 s
agent0:                 episode reward: -0.9224,                 loss: nan
agent1:                 episode reward: 0.9224,                 loss: 0.2729
Episode: 9161/10000 (91.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3225s / 119.8387 s
agent0:                 episode reward: -0.8541,                 loss: nan
agent1:                 episode reward: 0.8541,                 loss: 0.2732
Episode: 9181/10000 (91.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3164s / 120.1550 s
agent0:                 episode reward: -0.6469,                 loss: nan
agent1:                 episode reward: 0.6469,                 loss: 0.2705
Episode: 9201/10000 (92.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3205s / 120.4755 s
agent0:                 episode reward: -0.9467,                 loss: nan
agent1:                 episode reward: 0.9467,                 loss: 0.2714
Episode: 9221/10000 (92.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3235s / 120.7991 s
agent0:                 episode reward: -1.0509,                 loss: nan
agent1:                 episode reward: 1.0509,                 loss: 0.2676
Episode: 9241/10000 (92.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3248s / 121.1239 s
agent0:                 episode reward: -0.7851,                 loss: nan
agent1:                 episode reward: 0.7851,                 loss: 0.2695
Episode: 9261/10000 (92.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3316s / 121.4555 s
agent0:                 episode reward: -0.9949,                 loss: nan
agent1:                 episode reward: 0.9949,                 loss: 0.2731
Episode: 9281/10000 (92.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3218s / 121.7773 s
agent0:                 episode reward: -0.9210,                 loss: nan
agent1:                 episode reward: 0.9210,                 loss: 0.2687
Episode: 9301/10000 (93.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3184s / 122.0957 s
agent0:                 episode reward: -0.9258,                 loss: nan
agent1:                 episode reward: 0.9258,                 loss: 0.2694
Episode: 9321/10000 (93.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3206s / 122.4163 s
agent0:                 episode reward: -0.4759,                 loss: nan
agent1:                 episode reward: 0.4759,                 loss: 0.2699
Episode: 9341/10000 (93.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3446s / 122.7609 s
agent0:                 episode reward: -0.6605,                 loss: nan
agent1:                 episode reward: 0.6605,                 loss: 0.2734
Episode: 9361/10000 (93.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3194s / 123.0803 s
agent0:                 episode reward: -0.9122,                 loss: nan
agent1:                 episode reward: 0.9122,                 loss: 0.2701
Episode: 9381/10000 (93.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3206s / 123.4008 s
agent0:                 episode reward: -0.7397,                 loss: nan
agent1:                 episode reward: 0.7397,                 loss: 0.2742
Episode: 9401/10000 (94.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3293s / 123.7302 s
agent0:                 episode reward: -0.5506,                 loss: nan
agent1:                 episode reward: 0.5506,                 loss: 0.2721
Episode: 9421/10000 (94.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3233s / 124.0535 s
agent0:                 episode reward: -0.9648,                 loss: nan
agent1:                 episode reward: 0.9648,                 loss: 0.2727
Episode: 9441/10000 (94.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3808s / 124.4342 s
agent0:                 episode reward: -0.9235,                 loss: nan
agent1:                 episode reward: 0.9235,                 loss: 0.2672
Episode: 9461/10000 (94.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3257s / 124.7599 s
agent0:                 episode reward: -0.7910,                 loss: nan
agent1:                 episode reward: 0.7910,                 loss: 0.2675
Episode: 9481/10000 (94.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3226s / 125.0825 s
agent0:                 episode reward: -1.2294,                 loss: nan
agent1:                 episode reward: 1.2294,                 loss: 0.2701
Episode: 9501/10000 (95.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3276s / 125.4101 s
agent0:                 episode reward: -0.5473,                 loss: nan
agent1:                 episode reward: 0.5473,                 loss: 0.2708
Episode: 9521/10000 (95.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3266s / 125.7367 s
agent0:                 episode reward: -0.9348,                 loss: nan
agent1:                 episode reward: 0.9348,                 loss: 0.2774
Episode: 9541/10000 (95.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3207s / 126.0574 s
agent0:                 episode reward: -1.0491,                 loss: nan
agent1:                 episode reward: 1.0491,                 loss: 0.2720
Episode: 9561/10000 (95.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3236s / 126.3811 s
agent0:                 episode reward: -0.7889,                 loss: nan
agent1:                 episode reward: 0.7889,                 loss: 0.2714
Episode: 9581/10000 (95.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3218s / 126.7028 s
agent0:                 episode reward: -0.9587,                 loss: nan
agent1:                 episode reward: 0.9587,                 loss: 0.2693
Episode: 9601/10000 (96.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3274s / 127.0302 s
agent0:                 episode reward: -1.0494,                 loss: nan
agent1:                 episode reward: 1.0494,                 loss: 0.2697
Episode: 9621/10000 (96.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3314s / 127.3616 s
agent0:                 episode reward: -0.5659,                 loss: nan
agent1:                 episode reward: 0.5659,                 loss: 0.2695
Episode: 9641/10000 (96.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3269s / 127.6885 s
agent0:                 episode reward: -0.9569,                 loss: nan
agent1:                 episode reward: 0.9569,                 loss: 0.2705
Episode: 9661/10000 (96.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3287s / 128.0172 s
agent0:                 episode reward: -0.9483,                 loss: nan
agent1:                 episode reward: 0.9483,                 loss: 0.2666
Episode: 9681/10000 (96.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3310s / 128.3482 s
agent0:                 episode reward: -0.9072,                 loss: nan
agent1:                 episode reward: 0.9072,                 loss: 0.2703
Episode: 9701/10000 (97.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3258s / 128.6740 s
agent0:                 episode reward: -0.7996,                 loss: nan
agent1:                 episode reward: 0.7996,                 loss: 0.2710
Episode: 9721/10000 (97.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3315s / 129.0055 s
agent0:                 episode reward: -0.8007,                 loss: nan
agent1:                 episode reward: 0.8007,                 loss: 0.2711
Episode: 9741/10000 (97.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3273s / 129.3328 s
agent0:                 episode reward: -0.7635,                 loss: nan
agent1:                 episode reward: 0.7635,                 loss: 0.2655
Episode: 9761/10000 (97.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3245s / 129.6574 s
agent0:                 episode reward: -0.8444,                 loss: nan
agent1:                 episode reward: 0.8444,                 loss: 0.2682
Episode: 9781/10000 (97.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3301s / 129.9874 s
agent0:                 episode reward: -0.6990,                 loss: nan
agent1:                 episode reward: 0.6990,                 loss: 0.2684
Episode: 9801/10000 (98.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3269s / 130.3143 s
agent0:                 episode reward: -1.0922,                 loss: nan
agent1:                 episode reward: 1.0922,                 loss: 0.2690
Episode: 9821/10000 (98.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3239s / 130.6383 s
agent0:                 episode reward: -0.7803,                 loss: nan
agent1:                 episode reward: 0.7803,                 loss: 0.2691
Episode: 9841/10000 (98.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3533s / 130.9916 s
agent0:                 episode reward: -0.9917,                 loss: nan
agent1:                 episode reward: 0.9917,                 loss: 0.2710
Episode: 9861/10000 (98.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3320s / 131.3236 s
agent0:                 episode reward: -0.8784,                 loss: nan
agent1:                 episode reward: 0.8784,                 loss: 0.2666/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

Episode: 9881/10000 (98.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3267s / 131.6503 s
agent0:                 episode reward: -0.7357,                 loss: nan
agent1:                 episode reward: 0.7357,                 loss: 0.2677
Episode: 9901/10000 (99.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3297s / 131.9800 s
agent0:                 episode reward: -1.1143,                 loss: nan
agent1:                 episode reward: 1.1143,                 loss: 0.2711
Episode: 9921/10000 (99.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3277s / 132.3076 s
agent0:                 episode reward: -0.5709,                 loss: nan
agent1:                 episode reward: 0.5709,                 loss: 0.2752
Episode: 9941/10000 (99.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3260s / 132.6337 s
agent0:                 episode reward: -0.6114,                 loss: nan
agent1:                 episode reward: 0.6114,                 loss: 0.2726
Episode: 9961/10000 (99.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3285s / 132.9622 s
agent0:                 episode reward: -1.2997,                 loss: nan
agent1:                 episode reward: 1.2997,                 loss: 0.2734
Episode: 9981/10000 (99.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3365s / 133.2987 s
agent0:                 episode reward: -0.8347,                 loss: nan
agent1:                 episode reward: 0.8347,                 loss: 0.2717
