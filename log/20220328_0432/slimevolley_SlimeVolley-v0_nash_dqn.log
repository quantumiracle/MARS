Traceback (most recent call last):
  File "/home/zihan/research/MARS/general_train.py", line 1, in <module>
    from mars.utils.func import LoadYAML2Dict
  File "/home/zihan/research/MARS/mars/utils/func.py", line 7, in <module>
    from mars.rl.agents  import *
  File "/home/zihan/research/MARS/mars/rl/agents/__init__.py", line 1, in <module>
    from .dqn import DQN
  File "/home/zihan/research/MARS/mars/rl/agents/dqn.py", line 1, in <module>
    import torch
ModuleNotFoundError: No module named 'torch'
pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
SlimeVolley-v0 slimevolley
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
random seed: [23, 24]
<SubprocVectorEnv instance>
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=12, out_features=128, bias=True)
      (1): Tanh()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): Tanh()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): Tanh()
      (6): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=12, out_features=128, bias=True)
      (1): Tanh()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): Tanh()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): Tanh()
      (6): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
No agent are not learnable.
Arguments:  {'env_name': 'SlimeVolley-v0', 'env_type': 'slimevolley', 'num_envs': 2, 'ram': True, 'seed': 'random', 'against_baseline': False, 'algorithm': 'NashDQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 1000000}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 50000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'Tanh', 'output_activation': False}, 'marl_method': 'nash_dqn', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}}
Save models to : /home/zihan/research/MARS/data/model/20220328_0432/slimevolley_SlimeVolley-v0_nash_dqn. 
 Save logs to: /home/zihan/research/MARS/data/log/20220328_0432/slimevolley_SlimeVolley-v0_nash_dqn.
Episode: 1/50000 (0.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 6.2027s / 6.2027 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0057
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0063
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 21/50000 (0.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 199.5844s / 205.7871 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0069
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0072
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 41/50000 (0.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 203.4052s / 409.1923 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0106
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0103
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 61/50000 (0.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 206.2995s / 615.4918 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0141
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0140
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 81/50000 (0.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 210.5753s / 826.0672 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0139
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0140
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 101/50000 (0.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 212.6558s / 1038.7229 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0133
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0137
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 121/50000 (0.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 214.4636s / 1253.1865 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0136
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0138
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 141/50000 (0.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 220.7011s / 1473.8876 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.0135
env0_second_0:                 episode reward: -1.2500,                 loss: 0.0147
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 161/50000 (0.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 223.0545s / 1696.9421 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0134
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0143
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 181/50000 (0.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 226.0971s / 1923.0391 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0129
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0140
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 201/50000 (0.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 230.6883s / 2153.7274 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0132
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0139
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 221/50000 (0.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 231.1542s / 2384.8817 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0137
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0137
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 241/50000 (0.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 237.0567s / 2621.9383 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0140
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0134
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 261/50000 (0.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 241.9761s / 2863.9144 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0144
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0143
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 281/50000 (0.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 245.1248s / 3109.0392 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0139
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0144
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 301/50000 (0.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 248.9414s / 3357.9806 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0146
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0148
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 321/50000 (0.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 254.0271s / 3612.0077 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0144
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0144
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 341/50000 (0.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 256.9709s / 3868.9786 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0142
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0148
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 361/50000 (0.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 258.2790s / 4127.2575 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0147
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0150
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 381/50000 (0.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 258.5672s / 4385.8247 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0149
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0153
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 401/50000 (0.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 257.8103s / 4643.6350 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0155
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0151
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 421/50000 (0.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 260.0731s / 4903.7082 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0154
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0156
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 441/50000 (0.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 260.7872s / 5164.4954 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0158
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0155
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 461/50000 (0.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 260.1360s / 5424.6313 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0152
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0155
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 481/50000 (0.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 259.6167s / 5684.2480 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0151
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0153
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 501/50000 (1.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 259.9527s / 5944.2007 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0152
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0149
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 521/50000 (1.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 259.5650s / 6203.7656 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0152
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0153
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 541/50000 (1.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 259.6147s / 6463.3803 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0151
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0150
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 561/50000 (1.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 260.0197s / 6723.4000 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0147
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0152
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 581/50000 (1.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 259.7074s / 6983.1074 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0156
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0147
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 601/50000 (1.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 261.1324s / 7244.2398 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0148
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0143
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 621/50000 (1.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 259.0677s / 7503.3075 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.0146
env0_second_0:                 episode reward: -1.2500,                 loss: 0.0147
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 641/50000 (1.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 259.4806s / 7762.7881 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0146
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0152
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 661/50000 (1.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 258.8374s / 8021.6255 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0144
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0149
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 681/50000 (1.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 260.7046s / 8282.3301 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0146
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0146
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 701/50000 (1.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 259.3385s / 8541.6686 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0145
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0146
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 721/50000 (1.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 261.0781s / 8802.7467 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0142
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0145
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 741/50000 (1.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 263.3974s / 9066.1441 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0143
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0144
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 761/50000 (1.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 260.3962s / 9326.5403 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0141
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0138
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 781/50000 (1.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 260.8717s / 9587.4120 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0138
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0134
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 801/50000 (1.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 261.3912s / 9848.8032 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0143
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0136
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 821/50000 (1.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 262.3093s / 10111.1125 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0139
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0132
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 841/50000 (1.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 260.6316s / 10371.7441 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0145
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0131
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 861/50000 (1.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 262.0568s / 10633.8008 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.0139
env0_second_0:                 episode reward: 1.1500,                 loss: 0.0135
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 881/50000 (1.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 261.1021s / 10894.9029 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0137
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0136
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 901/50000 (1.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 262.3095s / 11157.2125 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0138
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0136
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 921/50000 (1.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 260.5838s / 11417.7963 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0136
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0131
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 941/50000 (1.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 261.7529s / 11679.5492 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0132
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0132
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 961/50000 (1.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 262.4667s / 11942.0159 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0136
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0133
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 981/50000 (1.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 262.4336s / 12204.4495 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0136
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0125
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1001/50000 (2.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 261.8483s / 12466.2979 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0130
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0129
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 1021/50000 (2.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 261.5973s / 12727.8951 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0128
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0128
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 1041/50000 (2.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 262.2732s / 12990.1683 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0129
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0132
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 1061/50000 (2.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 261.7276s / 13251.8960 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0126
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0123
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 1081/50000 (2.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 262.5782s / 13514.4742 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0127
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0124
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 1101/50000 (2.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 263.0336s / 13777.5078 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0122
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0124
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 1121/50000 (2.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 262.7769s / 14040.2847 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0125
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0122
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 1141/50000 (2.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 264.0894s / 14304.3741 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.0116
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0120
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 1161/50000 (2.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 263.3144s / 14567.6885 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0118
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0121
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 1181/50000 (2.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 262.0596s / 14829.7481 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0119
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0121
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 1201/50000 (2.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 262.1069s / 15091.8550 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0124
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0121
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 1221/50000 (2.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 264.1765s / 15356.0315 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0125
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0121
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 1241/50000 (2.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 263.0356s / 15619.0671 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0123
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0118
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 1261/50000 (2.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 263.5011s / 15882.5682 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0122
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0118
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1281/50000 (2.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 262.2903s / 16144.8585 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0122
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0120
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 1301/50000 (2.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 264.0861s / 16408.9446 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0121
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0123
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 1321/50000 (2.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 262.8732s / 16671.8178 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0115
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0119
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 1341/50000 (2.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 263.2295s / 16935.0473 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0120
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0121
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1361/50000 (2.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 263.9891s / 17199.0364 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0121
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0122
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 1381/50000 (2.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 264.5819s / 17463.6183 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0116
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0115
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 1401/50000 (2.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 265.1083s / 17728.7266 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0115
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0119
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1421/50000 (2.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 264.5859s / 17993.3125 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0117
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0119
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 1441/50000 (2.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 263.7498s / 18257.0623 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0118
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0115
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 1461/50000 (2.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 264.8110s / 18521.8734 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0118
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0117
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1481/50000 (2.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 263.6169s / 18785.4903 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0113
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0112
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 1501/50000 (3.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 264.6104s / 19050.1007 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0113
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0116
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 1521/50000 (3.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 266.4596s / 19316.5604 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0111
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0114
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 1541/50000 (3.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 264.6630s / 19581.2233 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0107
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0117
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 1561/50000 (3.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 265.8438s / 19847.0672 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0109
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0113
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 1581/50000 (3.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 266.6064s / 20113.6736 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0110
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0115
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 1601/50000 (3.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 265.8171s / 20379.4906 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0101
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0114
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 1621/50000 (3.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 265.5472s / 20645.0379 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0102
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0114
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 1641/50000 (3.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 265.3728s / 20910.4107 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0103
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0115
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1661/50000 (3.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 265.3362s / 21175.7469 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0105
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0113
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1681/50000 (3.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 263.0129s / 21438.7598 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0107
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0113
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 1701/50000 (3.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 264.3421s / 21703.1018 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0111
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0114
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 1721/50000 (3.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 264.8358s / 21967.9377 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0105
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0115
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 1741/50000 (3.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 264.1056s / 22232.0433 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0104
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0114
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 1761/50000 (3.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 264.0949s / 22496.1382 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0105
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0113
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 1781/50000 (3.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 263.1088s / 22759.2470 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0102
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0109
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 1801/50000 (3.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 266.5226s / 23025.7696 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0107
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0106
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 1821/50000 (3.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 265.1708s / 23290.9404 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.0110
env0_second_0:                 episode reward: 1.3000,                 loss: 0.0105
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 1841/50000 (3.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 264.3200s / 23555.2604 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0105
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0110
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 1861/50000 (3.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 264.8318s / 23820.0922 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0107
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0109
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1881/50000 (3.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 265.2283s / 24085.3204 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0103
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0108
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 1901/50000 (3.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 265.9315s / 24351.2519 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0105
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0105
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 1921/50000 (3.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 264.4081s / 24615.6600 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0104
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0107
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 1941/50000 (3.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 263.3147s / 24878.9747 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0099
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0108
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 1961/50000 (3.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 265.0864s / 25144.0611 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0101
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0109
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1981/50000 (3.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.9275s / 25411.9885 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0099
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0107
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 2001/50000 (4.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.8173s / 25679.8059 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0102
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0107
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 2021/50000 (4.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 302.7797s / 25982.5856 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0102
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0106
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 2041/50000 (4.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 283.9650s / 26266.5506 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0101
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0110
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 2061/50000 (4.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.3011s / 26534.8517 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0101
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0108
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2081/50000 (4.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 266.5140s / 26801.3658 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0100
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0108
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 2101/50000 (4.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 265.6178s / 27066.9836 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0102
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0107
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 2121/50000 (4.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 264.0499s / 27331.0335 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0102
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0102
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 2141/50000 (4.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 264.9025s / 27595.9360 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0100
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0105
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 2161/50000 (4.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 267.2541s / 27863.1900 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0099
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0103
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 2181/50000 (4.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 265.0138s / 28128.2038 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0100
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0105
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 2201/50000 (4.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 265.6608s / 28393.8647 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0096
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0103
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 2221/50000 (4.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 265.4647s / 28659.3294 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0099
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0104
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 2241/50000 (4.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 266.8081s / 28926.1375 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0099
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0100
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 2261/50000 (4.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 265.3109s / 29191.4484 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0104
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0100
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 2281/50000 (4.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 266.1868s / 29457.6352 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0102
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0099
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 2301/50000 (4.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 264.8806s / 29722.5158 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0099
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0100
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 2321/50000 (4.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 264.7846s / 29987.3004 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0098
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0101
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 2341/50000 (4.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 265.0610s / 30252.3613 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0095
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0103
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 2361/50000 (4.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.7642s / 30521.1255 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0094
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0106
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 2381/50000 (4.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 268.6227s / 30789.7483 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0094
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0105
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 2401/50000 (4.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.5112s / 31057.2595 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0093
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0103
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 2421/50000 (4.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 266.7771s / 31324.0365 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0093
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0103
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 2441/50000 (4.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.0439s / 31591.0805 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0096
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0106
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 2461/50000 (4.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.7328s / 31859.8133 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0095
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0106
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 2481/50000 (4.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 265.6110s / 32125.4243 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0094
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0103
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 2501/50000 (5.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.2930s / 32392.7173 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0095
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0102
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 2521/50000 (5.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 267.9264s / 32660.6437 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0097
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0101
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 2541/50000 (5.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.7057s / 32928.3494 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0094
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0104
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 2561/50000 (5.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 267.5779s / 33195.9274 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0094
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0100
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2581/50000 (5.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 268.4986s / 33464.4260 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0094
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0094
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 2601/50000 (5.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 268.3228s / 33732.7488 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0095
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0094
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 2621/50000 (5.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 267.7381s / 34000.4869 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0094
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0092
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 2641/50000 (5.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.2955s / 34267.7825 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0092
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0096
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 2661/50000 (5.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.4032s / 34536.1856 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0096
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0097
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 2681/50000 (5.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.8526s / 34804.0382 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0095
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0098
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 2701/50000 (5.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 269.2380s / 35073.2762 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0096
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0096
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 2721/50000 (5.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 269.2493s / 35342.5255 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0099
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0100
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 2741/50000 (5.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 266.9111s / 35609.4366 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0097
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0095
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2761/50000 (5.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 269.1670s / 35878.6035 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0093
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0098
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 2781/50000 (5.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 269.1756s / 36147.7791 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0094
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0098
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 2801/50000 (5.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 276.8968s / 36424.6759 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0096
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0097
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 2821/50000 (5.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 300.8123s / 36725.4882 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0096
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0096
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 2841/50000 (5.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 301.0464s / 37026.5346 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0099
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0096
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 2861/50000 (5.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 301.2334s / 37327.7680 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0099
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0096
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 2881/50000 (5.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 297.8382s / 37625.6062 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0103
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0096
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 2901/50000 (5.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 298.6542s / 37924.2604 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0100
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0098
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 2921/50000 (5.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 299.5096s / 38223.7700 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0103
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0099
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 2941/50000 (5.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 298.9561s / 38522.7261 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0102
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0102
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 2961/50000 (5.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 296.4039s / 38819.1300 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0104
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0103
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 2981/50000 (5.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 299.1019s / 39118.2319 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0101
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0105
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 3001/50000 (6.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 297.7085s / 39415.9404 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0105
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0102
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 3021/50000 (6.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 298.6876s / 39714.6280 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0102
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0105
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 3041/50000 (6.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 299.8144s / 40014.4424 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0107
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0106
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 3061/50000 (6.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 299.6565s / 40314.0989 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0106
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0107
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 3081/50000 (6.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 300.2697s / 40614.3686 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0107
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0108
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 3101/50000 (6.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 312.5433s / 40926.9119 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0105
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0108
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 3121/50000 (6.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 305.1279s / 41232.0398 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0106
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0110
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 3141/50000 (6.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 301.5037s / 41533.5435 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0103
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0101
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 3161/50000 (6.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 299.1259s / 41832.6694 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0101
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0106
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 3181/50000 (6.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 297.8131s / 42130.4825 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0102
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0104
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 3201/50000 (6.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 298.4380s / 42428.9205 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0103
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0105
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 3221/50000 (6.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 300.6443s / 42729.5648 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0103
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0101
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 3241/50000 (6.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 301.0096s / 43030.5745 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0105
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0103
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3261/50000 (6.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 298.2034s / 43328.7778 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0107
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0103
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 3281/50000 (6.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 298.3575s / 43627.1354 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0107
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0102
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 3301/50000 (6.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 298.8648s / 43926.0001 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0106
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0106
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 3321/50000 (6.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 299.2547s / 44225.2548 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0105
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0104
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 3341/50000 (6.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 298.9680s / 44524.2228 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0103
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0104
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 3361/50000 (6.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 299.0666s / 44823.2894 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0099
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0107
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 3381/50000 (6.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 298.1304s / 45121.4199 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0099
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0104
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 3401/50000 (6.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 300.2083s / 45421.6282 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0096
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0106
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 3421/50000 (6.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 300.6600s / 45722.2882 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0098
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0106
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 3441/50000 (6.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 300.0781s / 46022.3663 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0096
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0101
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 3461/50000 (6.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 302.7810s / 46325.1473 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0099
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0101
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 3481/50000 (6.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 301.2383s / 46626.3856 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0103
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0106
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 3501/50000 (7.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 299.7979s / 46926.1835 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0102
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0103
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 3521/50000 (7.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 300.4845s / 47226.6680 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0106
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0104
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 3541/50000 (7.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 301.7371s / 47528.4051 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0104
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0103
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 3561/50000 (7.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 300.5818s / 47828.9870 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0102
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0103
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 3581/50000 (7.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 300.8975s / 48129.8845 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0100
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0103
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 3601/50000 (7.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 301.9730s / 48431.8575 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0103
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0107
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 3621/50000 (7.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 300.7400s / 48732.5975 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0102
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0110
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 3641/50000 (7.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 301.5313s / 49034.1288 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0099
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0103
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 3661/50000 (7.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 300.4601s / 49334.5889 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0099
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0106
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 3681/50000 (7.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 300.7058s / 49635.2947 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0101
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0109
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 3701/50000 (7.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 302.0321s / 49937.3267 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0101
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0109
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 3721/50000 (7.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 301.1439s / 50238.4706 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0103
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0106
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 3741/50000 (7.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 302.0157s / 50540.4863 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0100
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0107
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 3761/50000 (7.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 303.0250s / 50843.5113 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0101
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0106
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 3781/50000 (7.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 300.6001s / 51144.1114 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0101
env0_second_0:                 episode reward: 0.9500,                 loss: 0.0105
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 3801/50000 (7.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 301.7370s / 51445.8485 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0101
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0105
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 3821/50000 (7.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 301.3709s / 51747.2193 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0103
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0110
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 3841/50000 (7.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 300.7776s / 52047.9970 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0100
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0108
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 3861/50000 (7.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 301.4516s / 52349.4485 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0103
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0109
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 3881/50000 (7.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 300.7071s / 52650.1556 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0104
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0108
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 3901/50000 (7.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 303.3545s / 52953.5101 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0108
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0109
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 3921/50000 (7.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 300.4501s / 53253.9602 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0109
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0114
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 3941/50000 (7.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 300.9971s / 53554.9573 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0111
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0113
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 3961/50000 (7.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 301.0764s / 53856.0338 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0110
env0_second_0:                 episode reward: 1.0000,                 loss: 0.0113
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 3981/50000 (7.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 302.3295s / 54158.3633 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0107
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0109
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 4001/50000 (8.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 303.2986s / 54461.6619 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0106
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0111
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 4021/50000 (8.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 301.4002s / 54763.0621 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0107
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0109
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 4041/50000 (8.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 302.1093s / 55065.1714 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0111
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0108
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 4061/50000 (8.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 302.2271s / 55367.3985 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0108
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0103
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 4081/50000 (8.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 301.8815s / 55669.2800 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0109
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0105
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 4101/50000 (8.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 303.1368s / 55972.4168 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0108
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0104
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 4121/50000 (8.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 301.3220s / 56273.7388 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0105
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0103
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 4141/50000 (8.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 298.8182s / 56572.5569 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0111
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0101
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 4161/50000 (8.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 301.1825s / 56873.7394 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0112
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0107
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4181/50000 (8.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 302.2266s / 57175.9660 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0109
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0105
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 4201/50000 (8.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 303.6987s / 57479.6647 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0114
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0105
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 4221/50000 (8.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 302.1732s / 57781.8378 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0108
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0105
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 4241/50000 (8.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 303.4893s / 58085.3271 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0111
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0104
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 4261/50000 (8.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 302.7575s / 58388.0846 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0111
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0101
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 4281/50000 (8.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 312.0291s / 58700.1138 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0105
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0098
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 4301/50000 (8.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 301.5394s / 59001.6531 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0102
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0099
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 4321/50000 (8.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 299.7043s / 59301.3575 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0104
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0100
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 4341/50000 (8.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 300.9074s / 59602.2649 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0106
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0101
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 4361/50000 (8.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 300.9659s / 59903.2308 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0107
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0101
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 4381/50000 (8.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 299.3777s / 60202.6085 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0105
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0102
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 4401/50000 (8.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 301.1147s / 60503.7232 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0106
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0102
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 4421/50000 (8.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 299.3820s / 60803.1052 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0106
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0099
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 4441/50000 (8.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 301.3914s / 61104.4965 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0103
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0101
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 4461/50000 (8.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 297.6754s / 61402.1720 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0106
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0102
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 4481/50000 (8.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 299.2292s / 61701.4011 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0107
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0106
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 4501/50000 (9.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 294.7411s / 61996.1423 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0106
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0106
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 4521/50000 (9.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 297.9706s / 62294.1129 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0109
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0111
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 4541/50000 (9.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 298.5271s / 62592.6400 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0106
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0107
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 4561/50000 (9.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 298.7662s / 62891.4061 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0109
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0110
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 4581/50000 (9.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 300.2304s / 63191.6366 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0106
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0104
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 4601/50000 (9.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 299.0988s / 63490.7354 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0106
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0105
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 4621/50000 (9.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 300.5641s / 63791.2995 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0101
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0109
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 4641/50000 (9.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 298.2484s / 64089.5479 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0108
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0107
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 4661/50000 (9.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 297.4018s / 64386.9497 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0105
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0107
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 4681/50000 (9.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 299.4040s / 64686.3537 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0110
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0107
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 4701/50000 (9.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 297.6564s / 64984.0100 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0111
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0110
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 4721/50000 (9.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 298.8674s / 65282.8774 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0111
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0106
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 4741/50000 (9.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 297.9310s / 65580.8084 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0109
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0107
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 4761/50000 (9.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 300.6463s / 65881.4546 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0110
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0105
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4781/50000 (9.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 297.5553s / 66179.0099 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0111
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0103
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 4801/50000 (9.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 299.2828s / 66478.2927 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.0111
env0_second_0:                 episode reward: -0.9500,                 loss: 0.0104
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 4821/50000 (9.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 299.7216s / 66778.0143 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0111
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0101
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 4841/50000 (9.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 298.5650s / 67076.5794 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0109
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0100
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 4861/50000 (9.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 300.4209s / 67377.0002 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0108
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0103
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 4881/50000 (9.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 298.0709s / 67675.0711 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0107
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0101
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 4901/50000 (9.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 301.1749s / 67976.2460 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0112
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0103
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 4921/50000 (9.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 299.5953s / 68275.8413 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0107
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0102
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 4941/50000 (9.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 300.7099s / 68576.5512 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0107
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0103
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 4961/50000 (9.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 300.8782s / 68877.4294 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0107
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0100
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 4981/50000 (9.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 300.0117s / 69177.4411 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0105
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0101
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 5001/50000 (10.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 298.4282s / 69475.8693 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0106
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0103
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 5021/50000 (10.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 299.7898s / 69775.6591 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0104
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0103
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 5041/50000 (10.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 299.9764s / 70075.6356 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0103
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0106
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 5061/50000 (10.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 301.9663s / 70377.6018 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0104
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0104
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 5081/50000 (10.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 298.8520s / 70676.4538 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0104
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0103
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5101/50000 (10.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 301.2852s / 70977.7390 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0103
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0103
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 5121/50000 (10.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 297.7801s / 71275.5191 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0105
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0106
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 5141/50000 (10.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 299.2503s / 71574.7694 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0102
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0109
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 5161/50000 (10.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 299.3326s / 71874.1020 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0100
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0111
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 5181/50000 (10.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 299.6889s / 72173.7909 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0101
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0109
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 5201/50000 (10.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 299.4797s / 72473.2706 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0102
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0106
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 5221/50000 (10.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 298.6139s / 72771.8845 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0098
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0109
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 5241/50000 (10.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 301.4304s / 73073.3149 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.0096
env0_second_0:                 episode reward: -1.0500,                 loss: 0.0109
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 5261/50000 (10.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 301.0404s / 73374.3553 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0099
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0110
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 5281/50000 (10.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 299.7802s / 73674.1356 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0098
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0106
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 5301/50000 (10.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 300.2256s / 73974.3612 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0100
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0104
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 5321/50000 (10.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 301.2810s / 74275.6422 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0100
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0108
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 5341/50000 (10.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 299.4708s / 74575.1130 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0097
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0109
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 5361/50000 (10.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 300.8379s / 74875.9509 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0099
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0108
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5381/50000 (10.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 299.1279s / 75175.0788 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0100
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0108
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 5401/50000 (10.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 299.2981s / 75474.3769 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0100
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0110
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 5421/50000 (10.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 300.5748s / 75774.9517 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0102
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0108
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 5441/50000 (10.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 301.3414s / 76076.2931 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0103
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0109
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 5461/50000 (10.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 303.6770s / 76379.9701 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0101
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0108
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 5481/50000 (10.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 328.6244s / 76708.5945 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0099
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0105
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 5501/50000 (11.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 302.0892s / 77010.6837 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0101
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0102
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 5521/50000 (11.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 304.3855s / 77315.0693 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0101
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0105
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 5541/50000 (11.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 300.9745s / 77616.0437 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0106
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0105
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 5561/50000 (11.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 299.9083s / 77915.9520 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0106
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0104
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 5581/50000 (11.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 301.9431s / 78217.8951 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0104
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0105
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 5601/50000 (11.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 300.2786s / 78518.1737 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0102
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0106
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 5621/50000 (11.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 301.7195s / 78819.8932 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0102
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0108
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 5641/50000 (11.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 299.5421s / 79119.4354 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0099
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0109
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5661/50000 (11.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 332.5834s / 79452.0188 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0099
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0108
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 5681/50000 (11.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 337.8216s / 79789.8404 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0103
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0110
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 5701/50000 (11.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 340.8260s / 80130.6664 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0104
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0109
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 5721/50000 (11.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 378.5303s / 80509.1966 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0100
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0112
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 5741/50000 (11.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 385.8474s / 80895.0440 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0100
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0114
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 5761/50000 (11.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 388.1524s / 81283.1964 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0098
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0116
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 5781/50000 (11.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 387.1826s / 81670.3790 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0100
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0115
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 5801/50000 (11.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 389.1403s / 82059.5192 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0101
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0117
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 5821/50000 (11.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 385.5517s / 82445.0709 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0102
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0118
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 5841/50000 (11.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 386.4936s / 82831.5645 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0100
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0118
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 5861/50000 (11.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 389.3672s / 83220.9317 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0104
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0116
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 5881/50000 (11.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 385.6551s / 83606.5868 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0104
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0112
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 5901/50000 (11.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 387.9384s / 83994.5252 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0104
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0111
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 5921/50000 (11.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 389.6002s / 84384.1254 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0105
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0112
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 5941/50000 (11.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 388.8792s / 84773.0045 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0108
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0114
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 5961/50000 (11.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 385.9655s / 85158.9700 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0108
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0113
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 5981/50000 (11.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 388.1568s / 85547.1268 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0109
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0114
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 6001/50000 (12.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 385.8507s / 85932.9775 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0108
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0107
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 6021/50000 (12.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 387.6194s / 86320.5969 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0108
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0110
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 6041/50000 (12.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 387.8486s / 86708.4455 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0107
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0114
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 6061/50000 (12.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 389.6579s / 87098.1035 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0109
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0115
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 6081/50000 (12.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 389.5757s / 87487.6791 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0107
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0116
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 6101/50000 (12.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 387.7114s / 87875.3905 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0109
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0115
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 6121/50000 (12.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 387.2973s / 88262.6878 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0110
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0117
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 6141/50000 (12.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 389.2428s / 88651.9306 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0113
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0117
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 6161/50000 (12.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 388.7377s / 89040.6683 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0112
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0115
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 6181/50000 (12.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 387.4735s / 89428.1418 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0112
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0108
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 6201/50000 (12.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 390.6494s / 89818.7911 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0112
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0113
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 6221/50000 (12.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 388.3486s / 90207.1398 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0112
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0111
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 6241/50000 (12.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 389.5284s / 90596.6682 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0115
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0113
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 6261/50000 (12.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 387.2971s / 90983.9653 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0112
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0112
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 6281/50000 (12.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 391.0263s / 91374.9916 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0113
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0109
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 6301/50000 (12.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 388.3360s / 91763.3276 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0116
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0110
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 6321/50000 (12.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 387.4964s / 92150.8240 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0111
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0109
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 6341/50000 (12.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 386.8033s / 92537.6273 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0111
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0108
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 6361/50000 (12.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 389.8871s / 92927.5144 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0108
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0107
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 6381/50000 (12.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 390.6998s / 93318.2142 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0112
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0109
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 6401/50000 (12.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 387.1117s / 93705.3259 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0108
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0114
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 6421/50000 (12.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 389.6547s / 94094.9805 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0107
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0112
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 6441/50000 (12.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 389.6702s / 94484.6508 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0107
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0111
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 6461/50000 (12.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 388.0439s / 94872.6946 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0105
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0111
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 6481/50000 (12.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 390.8342s / 95263.5288 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0108
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0107
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 6501/50000 (13.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 391.3835s / 95654.9123 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0107
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0110
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 6521/50000 (13.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 389.7290s / 96044.6413 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0107
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0109
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 6541/50000 (13.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 389.2504s / 96433.8917 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0106
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0111
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 6561/50000 (13.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 393.8734s / 96827.7651 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0106
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0111
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 6581/50000 (13.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 390.7180s / 97218.4831 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0107
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0107
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 6601/50000 (13.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 387.9343s / 97606.4173 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0107
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0110
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 6621/50000 (13.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 390.3474s / 97996.7648 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0108
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0110
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 6641/50000 (13.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 390.0196s / 98386.7844 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0108
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0108
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 6661/50000 (13.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 388.2191s / 98775.0034 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0110
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0107
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 6681/50000 (13.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 389.4465s / 99164.4500 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0108
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0108
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 6701/50000 (13.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 390.4941s / 99554.9441 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0109
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0109
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 6721/50000 (13.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 390.9326s / 99945.8767 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0105
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0109
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 6741/50000 (13.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 390.2420s / 100336.1187 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0105
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0109
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 6761/50000 (13.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 390.2425s / 100726.3612 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0107
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0108
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 6781/50000 (13.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 388.0123s / 101114.3735 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0108
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0107
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 6801/50000 (13.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 392.1040s / 101506.4775 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0106
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0111
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 6821/50000 (13.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 388.0496s / 101894.5271 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0106
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0111
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 6841/50000 (13.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 390.1467s / 102284.6737 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0105
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0111
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 6861/50000 (13.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 389.5490s / 102674.2227 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0111
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0107
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 6881/50000 (13.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 388.3099s / 103062.5327 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.0108
env0_second_0:                 episode reward: 1.1000,                 loss: 0.0104
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 6901/50000 (13.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 389.6622s / 103452.1949 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0107
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0106
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 6921/50000 (13.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 388.1427s / 103840.3376 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0109
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0111
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 6941/50000 (13.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 383.8925s / 104224.2301 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0108
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0107
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 6961/50000 (13.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 391.2517s / 104615.4818 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0110
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0108
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 6981/50000 (13.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 388.5628s / 105004.0446 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0108
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0108
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 7001/50000 (14.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 389.6680s / 105393.7125 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0108
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0109
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 7021/50000 (14.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 390.1869s / 105783.8994 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0106
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0112
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 7041/50000 (14.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 387.9893s / 106171.8887 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.0110
env0_second_0:                 episode reward: 1.1000,                 loss: 0.0112
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 7061/50000 (14.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 386.6683s / 106558.5570 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0108
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0114
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 7081/50000 (14.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 386.2379s / 106944.7949 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0110
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0116
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 7101/50000 (14.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 387.5649s / 107332.3598 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0114
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0114
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 7121/50000 (14.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 389.3374s / 107721.6972 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0115
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0116
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 7141/50000 (14.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 389.7078s / 108111.4050 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0108
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0111
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 7161/50000 (14.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 389.5054s / 108500.9104 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0111
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0113
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 7181/50000 (14.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 390.0338s / 108890.9442 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0114
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0114
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 7201/50000 (14.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 388.4093s / 109279.3534 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0115
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0111
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 7221/50000 (14.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 387.5201s / 109666.8735 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0112
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0113
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 7241/50000 (14.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 389.8659s / 110056.7394 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0116
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0112
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 7261/50000 (14.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 389.6316s / 110446.3710 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0113
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0110
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 7281/50000 (14.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 387.9875s / 110834.3585 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0109
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0108
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 7301/50000 (14.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 388.5870s / 111222.9455 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0112
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0112
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 7321/50000 (14.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 388.5481s / 111611.4936 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0115
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0113
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 7341/50000 (14.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 389.3751s / 112000.8687 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0112
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0115
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 7361/50000 (14.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 389.1789s / 112390.0476 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0115
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0113
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 7381/50000 (14.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 388.5493s / 112778.5969 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0115
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0117
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 7401/50000 (14.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 388.5446s / 113167.1415 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0114
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0114
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 7421/50000 (14.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 387.9016s / 113555.0431 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0116
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0115
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 7441/50000 (14.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 385.6295s / 113940.6725 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0111
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0108
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 7461/50000 (14.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 385.7569s / 114326.4294 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0116
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0110
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 7481/50000 (14.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 387.2364s / 114713.6658 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0115
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0112
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 7501/50000 (15.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 387.7000s / 115101.3658 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0109
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0115
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 7521/50000 (15.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 387.2618s / 115488.6277 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0111
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0115
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 7541/50000 (15.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 390.8181s / 115879.4457 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0110
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0115
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 7561/50000 (15.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 389.5616s / 116269.0074 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0109
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0116
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 7581/50000 (15.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 387.7286s / 116656.7359 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0106
env0_second_0:                 episode reward: 0.9500,                 loss: 0.0118
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 7601/50000 (15.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 388.6193s / 117045.3552 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0108
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0116
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 7621/50000 (15.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 388.0562s / 117433.4114 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0114
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0114
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 7641/50000 (15.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 386.8893s / 117820.3006 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0111
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0118
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 7661/50000 (15.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 386.3642s / 118206.6648 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0113
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0115
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 7681/50000 (15.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 390.2427s / 118596.9075 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0111
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0108
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 7701/50000 (15.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 391.8008s / 118988.7083 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0112
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0109
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 7721/50000 (15.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 391.2127s / 119379.9210 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0113
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0105
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 7741/50000 (15.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 389.5920s / 119769.5129 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0111
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0109
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 7761/50000 (15.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 387.4739s / 120156.9869 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0114
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0108
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 7781/50000 (15.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 389.0962s / 120546.0831 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0114
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0107
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan